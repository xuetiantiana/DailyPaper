{
  "data": [
    {
      "id": "2506.21555",
      "abstract": "Recent advancements in deep learning have significantly enhanced multilingual automatic speech recognition (ASR) due to the development of advanced model architectures and available large-scale multilingual datasets. Despite that, multilingual ASR still suffers from the curse of multilinguality in that different languages tend to interfere with each other, making it difficult for the ASR model to identify multiple languages effectively while sharing model capacity across them. This paper proposes an efficient finetuning framework for customized multilingual ASR via prepared LoRA language experts based on Whisper. Through LoRA expert fusion or knowledge distillation, our approach achieves better recognition performance on target languages than standard fine-tuning methods. Experimental results demonstrate that the proposed models yield approximately 10\\% and 15\\% relative performance gains in language-aware and language-agnostic scenarios, respectively.",
      "authors": [
        "Jiahong Li",
        "Yiwen Shao",
        "Jianheng Zhuo",
        "Chenda Li",
        "Liliang Tang",
        "Dong Yu",
        "Yanmin Qian"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-11T07:06:27+00:00",
          "link": "https://arxiv.org/abs/2506.21555v1",
          "size": "286kb",
          "version": "v1"
        }
      ],
      "title": "Efficient Multilingual ASR Finetuning via LoRA Language Experts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21555",
        "HTML": "https://arxiv.org/html/2506.21555v1",
        "PDF": "https://arxiv.org/pdf/2506.21555"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper is focused on efficient fine-tuning of models for multilingual ASR using LoRA language experts but does not directly contribute to the methodology of LLM training data processing in general."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21556",
      "abstract": "Multimodal Knowledge Graphs (MMKGs), which represent explicit knowledge across multiple modalities, play a pivotal role by complementing the implicit knowledge of Multimodal Large Language Models (MLLMs) and enabling more grounded reasoning via Retrieval Augmented Generation (RAG). However, existing MMKGs are generally limited in scope: they are often constructed by augmenting pre-existing knowledge graphs, which restricts their knowledge, resulting in outdated or incomplete knowledge coverage, and they often support only a narrow range of modalities, such as text and visual information. These limitations reduce their extensibility and applicability to a broad range of multimodal tasks, particularly as the field shifts toward richer modalities such as video and audio in recent MLLMs. Therefore, we propose the Visual-Audio-Text Knowledge Graph (VAT-KG), the first concept-centric and knowledge-intensive multimodal knowledge graph that covers visual, audio, and text information, where each triplet is linked to multimodal data and enriched with detailed descriptions of concepts. Specifically, our construction pipeline ensures cross-modal knowledge alignment between multimodal data and fine-grained semantics through a series of stringent filtering and alignment steps, enabling the automatic generation of MMKGs from any multimodal dataset. We further introduce a novel multimodal RAG framework that retrieves detailed concept-level knowledge in response to queries from arbitrary modalities. Experiments on question answering tasks across various modalities demonstrate the effectiveness of VAT-KG in supporting MLLMs, highlighting its practical value in unifying and leveraging multimodal knowledge.",
      "authors": [
        "Hyeongcheol Park",
        "MinHyuk Jang",
        "Ha Dam Baek",
        "Gyusam Chang",
        "Jiyoung Seo",
        "Jiwan Park",
        "Hogun Park",
        "Sangpil Kim"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-11T07:22:57+00:00",
          "link": "https://arxiv.org/abs/2506.21556v1",
          "size": "2704kb",
          "version": "v1"
        }
      ],
      "title": "VAT-KG: Knowledge-Intensive Multimodal Knowledge Graph Dataset for Retrieval-Augmented Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21556",
        "HTML": "https://arxiv.org/html/2506.21556v1",
        "PDF": "https://arxiv.org/pdf/2506.21556"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces VAT-KG, a dataset with a construction pipeline focusing on multimodal data alignment and quality enhancement, which are key aspects of data engineering relevant to LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21557",
      "abstract": "The rapid spread of fake news across multimedia platforms presents serious challenges to information credibility. In this paper, we propose a Debunk-and-Infer framework for Fake News Detection(DIFND) that leverages debunking knowledge to enhance both the performance and interpretability of fake news detection. DIFND integrates the generative strength of conditional diffusion models with the collaborative reasoning capabilities of multimodal large language models (MLLMs). Specifically, debunk diffusion is employed to generate refuting or authenticating evidence based on the multimodal content of news videos, enriching the evaluation process with diverse yet semantically aligned synthetic samples. To improve inference, we propose a chain-of-debunk strategy where a multi-agent MLLM system produces logic-grounded, multimodal-aware reasoning content and final veracity judgment. By jointly modeling multimodal features, generative debunking cues, and reasoning-rich verification within a unified architecture, DIFND achieves notable improvements in detection accuracy. Extensive experiments on the FakeSV and FVC datasets show that DIFND not only outperforms existing approaches but also delivers trustworthy decisions.",
      "authors": [
        "Kaiying Yan",
        "Moyang Liu",
        "Yukun Liu",
        "Ruibo Fu",
        "Zhengqi Wen",
        "Jianhua Tao",
        "and Xuefei Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-11T09:08:43+00:00",
          "link": "https://arxiv.org/abs/2506.21557v1",
          "size": "2382kb",
          "version": "v1"
        }
      ],
      "title": "Debunk and Infer: Multimodal Fake News Detection via Diffusion-Generated Evidence and LLM Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21557",
        "HTML": "https://arxiv.org/html/2506.21557v1",
        "PDF": "https://arxiv.org/pdf/2506.21557"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on a framework for fake news detection using existing multimodal content for analysis, without contributing to the processing or enhancement of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21558",
      "abstract": "Forecasting is a challenging task that offers a clearly measurable way to study AI systems. Forecasting requires a large amount of research on the internet, and evaluations require time for events to happen, making the development of forecasting benchmarks challenging. To date, no forecasting benchmark provides a realistic, hermetic, and repeatable environment for LLM forecasters. We introduce Bench To the Future (BTF), a \"pastcasting\" benchmark with hundreds of high-quality questions for which the resolution is already known. Each question is accompanied by a large offline corpus of tens of thousands of relevant web pages, enabling a way to elicit realistic \"forecasts\" on past events from LLMs. Results suggest that our pastcasting environment can produce results comparable to those based on forecasts using the internet on at-the-time unresolved questions. We show results benchmarking agent and chain-of-thought forecasting approaches using several LLMs, including the recently-released Claude 4 models, and demonstrate BTF's ability to track steady forecasting capability progress over time. We intend this to be a living benchmark, with new questions added continually to account for increasing training data cutoff dates. We invite researchers to contact us at hello@futuresearch.ai to utilize our benchmark or tooling for their own research.",
      "authors": [
        "FutureSearch: Jack Wildman",
        "Nikos I. Bosse",
        "Daniel Hnyk",
        "Peter M\\\"uhlbacher",
        "Finn Hambly",
        "Jon Evans",
        "Dan Schwarz",
        "Lawrence Phillips"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-11T16:18:40+00:00",
          "link": "https://arxiv.org/abs/2506.21558v1",
          "size": "3082kb",
          "version": "v1"
        }
      ],
      "title": "Bench to the Future: A Pastcasting Benchmark for Forecasting Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21558",
        "PDF": "https://arxiv.org/pdf/2506.21558"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper introduces a benchmark for forecasting without contributing to LLM training data processing or data engineering, focusing instead on evaluation and benchmarking methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21559",
      "abstract": "Large language models (LLMs) have demonstrated their strong capabilities in various domains, and have been recently integrated for graph analysis as graph language models (GLMs). With LLMs as the predictor, some GLMs can interpret unseen tasks described by natural language, and learn from a few examples in the prompts without parameter tuning, known as in-context learning (ICL). Another subset of GLMs utilizes abundant training labels to enhance model performance, known as instruction tuning. However, we argue that ICL on graphs has effectiveness issues due to fixed parameters and efficiency issues due to long context. Meanwhile, the large amount of labeled data required for instruction tuning can be difficult to obtain in real-world scenarios. To this end, we aim to introduce an extra parameter adaptation stage that can efficiently tailor GLMs to an unseen graph and task with only a few labeled examples, in exchange for better prediction accuracy and faster inference speed. For implementation, in this paper we propose GraphLAMA method, with its model backbone and learning schemes specialized for efficient tuning and inference. Specifically, for model backbone, we use a graph neural network (GNN) with several well-designed components to transform nodes into the representation space of LLM tokens. Task instructions can then be represented as a mixture of node and language tokens. In the pre-training stage, model parameters except the LLM will be trained with different tasks to capture general knowledge. In the adaptation stage, only a few pre-trained parameters will be updated based on few-shot examples. Extensive experiments on few/zero-shot node classification and summary generation show that our proposed GraphLAMA achieves state-of-the-art performance with 4.91% absolution improvement in accuracy. Compared with ICL, our inference speed can be 10 times faster under 5-shot setting.",
      "authors": [
        "Junze Chen",
        "Cheng Yang",
        "Shujie Li",
        "Zhiqiang Zhang",
        "Yawen Li",
        "Junping Du",
        "Chuan Shi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-11T16:38:01+00:00",
          "link": "https://arxiv.org/abs/2506.21559v1",
          "size": "5159kb",
          "version": "v1"
        }
      ],
      "title": "GraphLAMA: Enabling Efficient Adaptation of Graph Language Models with Limited Annotations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21559",
        "HTML": "https://arxiv.org/html/2506.21559v1",
        "PDF": "https://arxiv.org/pdf/2506.21559"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "GraphLAMA focuses on efficient adaptation and pre-training, which may involve data processing aspects, but the main focus is on model adaptation rather than LLM training data engineering or preprocessing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21560",
      "abstract": "This study investigates the effectiveness of reinforcement learning (RL) fine-tuning techniques on a compact language model (Qwen2.5-0.5B Base) for two challenging tasks: instruction following and mathematical reasoning. We compare supervised fine-tuning (SFT), Direct Preference Optimization (DPO) using preference-labeled data, and Reinforce Leave-One-Out (RLOO) with reward models. Our experiments show that RLOO with DeBERTa reward modeling achieves the best alignment, while DPO provides strong and consistent results. For math reasoing tasks, synthetic data augmentation and best-of-N sampling with an external verifier significantly improve accuracy, showing the potential of combining fine-tuning with inference-time tools. This study highlights key trade-offs and practical strategies for training lightweight, task-aligned small-scale language models.",
      "authors": [
        "Yifu Han and Geo Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-11T22:49:42+00:00",
          "link": "https://arxiv.org/abs/2506.21560v1",
          "size": "803kb",
          "version": "v1"
        }
      ],
      "title": "Reinforcement Learning Fine-Tuning of Language Model for Instruction Following and Math Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21560",
        "HTML": "https://arxiv.org/html/2506.21560v1",
        "PDF": "https://arxiv.org/pdf/2506.21560"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The study involves fine-tuning with reinforcement learning and explores synthetic data augmentation, but it does not primarily focus on the data engineering process for LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21561",
      "abstract": "Despite their widespread use in fact-checking, moderation, and high-stakes decision-making, large language models (LLMs) remain poorly understood as judges of truth. This study presents the largest evaluation to date of LLMs' veracity detection capabilities and the first analysis of these capabilities in reasoning models. We had eight LLMs make 4,800 veracity judgments across several prompts, comparing reasoning and non-reasoning models. We find that rates of truth-bias, or the likelihood to believe a statement is true, regardless of whether it is actually true, are lower in reasoning models than in non-reasoning models, but still higher than human benchmarks. Most concerning, we identify sycophantic tendencies in several advanced models (o4-mini and GPT-4.1 from OpenAI, R1 from DeepSeek), which displayed an asymmetry in detection accuracy, performing well in truth accuracy but poorly in deception accuracy. This suggests that capability advances alone do not resolve fundamental veracity detection challenges in LLMs.",
      "authors": [
        "Emilio Barkett",
        "Olivia Long",
        "Madhavendra Thakur"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-12T00:19:36+00:00",
          "link": "https://arxiv.org/abs/2506.21561v1",
          "size": "51kb",
          "version": "v1"
        }
      ],
      "title": "Reasoning Isn't Enough: Examining Truth-Bias and Sycophancy in LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21561",
        "HTML": "https://arxiv.org/html/2506.21561v1",
        "PDF": "https://arxiv.org/pdf/2506.21561"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on evaluating the veracity detection capabilities of LLMs and issues like truth-bias and sycophancy in these models. It does not address any aspect of LLM training data collection, construction, or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21562",
      "abstract": "In the architectural design process, floor plan generation is inherently progressive and iterative. However, existing generative models for floor plans are predominantly end-to-end generation that produce an entire pixel-based layout in a single pass. This paradigm is often incompatible with the incremental workflows observed in real-world architectural practice. To address this issue, we draw inspiration from the autoregressive 'next token prediction' mechanism commonly used in large language models, and propose a novel 'next room prediction' paradigm tailored to architectural floor plan modeling. Experimental evaluation indicates that FPDS demonstrates competitive performance in comparison to diffusion models and Tell2Design in the text-to-floorplan task, indicating its potential applicability in supporting future intelligent architectural design.",
      "authors": [
        "Jun Yin",
        "Pengyu Zeng",
        "Jing Zhong",
        "Peilin Li",
        "Miao Zhang",
        "Ran Luo",
        "Shuai Lu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-12T04:33:27+00:00",
          "link": "https://arxiv.org/abs/2506.21562v1",
          "size": "680kb",
          "version": "v1"
        }
      ],
      "title": "FloorPlan-DeepSeek (FPDS): A multimodal approach to floorplan generation using vector-based next room prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21562",
        "PDF": "https://arxiv.org/pdf/2506.21562"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper introduces a method for floorplan generation inspired by LLMs, applying the autoregressive mechanism to architectural design. It does not involve LLM training data or its processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21563",
      "abstract": "While large language models (LLMs) have demonstrated impressive performance across a wide range of natural language processing (NLP) tasks in high-resource languages, their capabilities in low-resource and minority languages remain significantly underexplored. Formosan languages -- a subgroup of Austronesian languages spoken in Taiwan -- are both linguistically rich and endangered, largely due to the sociolinguistic dominance of Mandarin. In this work, we introduce FORMOSANBENCH, the first benchmark for evaluating LLMs on low-resource Austronesian languages. It covers three endangered Formosan languages: Atayal, Amis, and Paiwan, across three core NLP tasks: machine translation, automatic speech recognition (ASR), and text summarization. We assess model performance in zero-shot, 10-shot, and fine-tuned settings using FORMOSANBENCH. Our results reveal a substantial performance gap between high-resource and Formosan languages. Existing LLMs consistently underperform across all tasks, with 10-shot learning and fine-tuning offering only limited improvements. These findings underscore the urgent need for more inclusive NLP technologies that can effectively support endangered and underrepresented languages. We release our datasets and code to facilitate future research in this direction.",
      "authors": [
        "Kaiying Kevin Lin and Hsiyu Chen and Haopeng Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-12T07:02:28+00:00",
          "link": "https://arxiv.org/abs/2506.21563v1",
          "size": "1109kb",
          "version": "v1"
        }
      ],
      "title": "FormosanBench: Benchmarking Low-Resource Austronesian Languages in the Era of Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21563",
        "HTML": "https://arxiv.org/html/2506.21563v1",
        "PDF": "https://arxiv.org/pdf/2506.21563"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the primary focus is on benchmarking LLMs in low-resource languages, the paper mentions the use of datasets for evaluation purposes. However, it does not propose new data-related methods primarily."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21564",
      "abstract": "This paper describes the participation of QUST_NLP in the SemEval-2025 Task 7. We propose a three-stage retrieval framework specifically designed for fact-checked claim retrieval. Initially, we evaluate the performance of several retrieval models and select the one that yields the best results for candidate retrieval. Next, we employ multiple re-ranking models to enhance the candidate results, with each model selecting the Top-10 outcomes. In the final stage, we utilize weighted voting to determine the final retrieval outcomes. Our approach achieved 5th place in the monolingual track and 7th place in the crosslingual track. We release our system code at: https://github.com/warmth27/SemEval2025_Task7.",
      "authors": [
        "Jiyan Liu",
        "Youzheng Liu",
        "Taihang Wang",
        "Xiaoman Xu",
        "Yimin Wang and Ye Jiang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-12T07:09:35+00:00",
          "link": "https://arxiv.org/abs/2506.21564v1",
          "size": "299kb",
          "version": "v1"
        }
      ],
      "title": "Team QUST at SemEval-2025 Task 10: Evaluating Large Language Models in Multiclass Multi-label Classification of News Entity Framing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21564",
        "HTML": "https://arxiv.org/html/2506.21564v1",
        "PDF": "https://arxiv.org/pdf/2506.21564"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper describes a retrieval framework for a SemEval task, focusing on fact-checked claim retrieval and re-ranking models. It lacks relevance to LLM training data or its processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21565",
      "abstract": "Japan's kairanban culture and idobata conversations have long functioned as traditional communication practices that foster nuanced dialogue among community members and contribute to the formation of social balance. Inspired by these information exchange processes, this study proposes a multi-agent inference framework (KCS+IBC) that integrates multiple large language models (LLMs) to achieve bias mitigation, improved explainability, and probabilistic prediction in sentiment analysis. In addition to sequentially sharing prediction results, the proposed method incorporates a mid-phase casual dialogue session to blend formal inference with individual perspectives and introduces probabilistic sentiment prediction. Experimental results show that KCS achieves accuracy comparable to that of a single LLM across datasets, while KCS+IBC exhibits a consistent decrease in entropy and a gradual increase in variance during the latter stages of inference, suggesting the framework's ability to balance aggregation and diversity of predictions. Future work will quantitatively assess the impact of these characteristics on bias correction and aim to develop more advanced sentiment analysis systems.",
      "authors": [
        "Takato Ueno and Keito Inoshita"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-12T07:31:20+00:00",
          "link": "https://arxiv.org/abs/2506.21565v1",
          "size": "2055kb",
          "version": "v1"
        }
      ],
      "title": "A Multi-Agent Probabilistic Inference Framework Inspired by Kairanban-Style CoT System with IdoBata Conversation for Debiasing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21565",
        "HTML": "https://arxiv.org/html/2506.21565v1",
        "PDF": "https://arxiv.org/pdf/2506.21565"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The study proposes a multi-agent inference framework using LLMs for bias mitigation and probabilistic prediction, without involving aspects of LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21566",
      "abstract": "Backtranslation BT is widely used in low resource machine translation MT to generate additional synthetic training data using monolingual corpora. While this approach has shown strong improvements for many language pairs, its effectiveness in high quality, low resource settings remains unclear. In this work, we explore the effectiveness of backtranslation for English Gujarati translation using the multilingual pretrained MBART50 model. Our baseline system, trained on a high quality parallel corpus of approximately 50,000 sentence pairs, achieves a BLEU score of 43.8 on a validation set. We augment this data with carefully filtered backtranslated examples generated from monolingual Gujarati text. Surprisingly, adding this synthetic data does not improve translation performance and, in some cases, slightly reduces it. We evaluate our models using multiple metrics like BLEU, ChrF++, TER, BLEURT and analyze possible reasons for this saturation. Our findings suggest that backtranslation may reach a point of diminishing returns in certain low-resource settings and we discuss implications for future research.",
      "authors": [
        "Arwa Arif"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-12T09:02:53+00:00",
          "link": "https://arxiv.org/abs/2506.21566v1",
          "size": "47kb",
          "version": "v1"
        }
      ],
      "title": "The Saturation Point of Backtranslation in High Quality Low Resource English Gujarati Machine Translation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21566",
        "HTML": "https://arxiv.org/html/2506.21566v1",
        "PDF": "https://arxiv.org/pdf/2506.21566"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses the use of backtranslation to generate synthetic training data in low-resource machine translation but does not introduce new data processing methods or pipelines specific to LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21567",
      "abstract": "Large Language Models (LLMs) have recently gained attention in the life sciences due to their capacity to model, extract, and apply complex biological information. Beyond their classical use as chatbots, these systems are increasingly used for complex analysis and problem-solving in specialized fields, including bioinformatics. First, we introduce BIOPARS-BENCH, a dataset from over 10,000 scientific articles, textbooks, and medical websites. BioParsQA was also introduced to evaluate the proposed model, which consists of 5,231 Persian medical questions and answers. This study then introduces BioPars, a simple but accurate measure designed to assess LLMs for three main abilities: acquiring subject-specific knowledge, interpreting and synthesizing such knowledge, and demonstrating proper evidence. Comparing ChatGPT, Llama, and Galactica, our study highlights their ability to remember and retrieve learned knowledge but also reveals shortcomings in addressing higher-level, real-world questions and fine-grained inferences. These findings indicate the need for further fine-tuning to address the capabilities of LLM in bioinformatics tasks. To our knowledge, BioPars is the first application of LLM in Persian medical QA, especially for generating long answers. Evaluation of four selected medical QA datasets shows that BioPars has achieved remarkable results compared to comparative approaches. The model on BioParsQA achieved a ROUGE-L score of 29.99, which is an improvement over GPT-4 1.0. The model achieved a BERTScore of 90.87 with the MMR method. The MoverScore and BLEURT values were also higher in this model than the other three models. In addition, the reported scores for the model are MoverScore=60.43 and BLEURT=50.78. BioPars is an ongoing project and all resources related to its development will be made available via the following GitHub repository: https://github.com/amirap80/BioPars.",
      "authors": [
        "Baqer M. Merzah",
        "Tania Taami",
        "Salman Asoudeh",
        "Amir reza Hossein pour",
        "Saeed Mirzaee",
        "and Amir Ali Bengari"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-12T09:11:26+00:00",
          "link": "https://arxiv.org/abs/2506.21567v1",
          "size": "749kb",
          "version": "v1"
        }
      ],
      "title": "BioPars: A Pretrained Biomedical Large Language Model for Persian Biomedical Text Mining",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21567",
        "HTML": "https://arxiv.org/html/2506.21567v1",
        "PDF": "https://arxiv.org/pdf/2506.21567"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces a new biomedical dataset and applies fine-tuning, it does not propose new methods for processing or engineering LLM training data, focusing instead on evaluating model performance on specific tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21568",
      "abstract": "Resource efficiency is a critical barrier to deploying large language models (LLMs) in edge and privacy-sensitive applications. This study evaluates the efficacy of two augmentation strategies--Retrieval-Augmented Generation (RAG) and Hypothetical Document Embeddings (HyDE)--on compact Gemma LLMs of 1 billion and 4 billion parameters, within the context of a privacy-first personal assistant. We implement short-term memory via MongoDB and long-term semantic storage via Qdrant, orchestrated through FastAPI and LangChain, and expose the system through a React.js frontend. Across both model scales, RAG consistently reduces latency by up to 17\\% and eliminates factual hallucinations when responding to user-specific and domain-specific queries. HyDE, by contrast, enhances semantic relevance--particularly for complex physics prompts--but incurs a 25--40\\% increase in response time and a non-negligible hallucination rate in personal-data retrieval. Comparing 1 B to 4 B models, we observe that scaling yields marginal throughput gains for baseline and RAG pipelines, but magnifies HyDE's computational overhead and variability. Our findings position RAG as the pragmatic choice for on-device personal assistants powered by small-scale LLMs.",
      "authors": [
        "Andrejs Sorstkins"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-12T15:05:39+00:00",
          "link": "https://arxiv.org/abs/2506.21568v1",
          "size": "877kb",
          "version": "v1"
        }
      ],
      "title": "Assessing RAG and HyDE on 1B vs. 4B-Parameter Gemma LLMs for Personal Assistants Integretion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21568",
        "HTML": "https://arxiv.org/html/2506.21568v1",
        "PDF": "https://arxiv.org/pdf/2506.21568"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The study evaluates augmentation strategies like RAG and HyDE for LLMs in personal assistants without addressing LLM training data collection, processing, or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21569",
      "abstract": "SystemVerilog Assertions (SVAs) are critical for verifying the correctness of hardware designs, but manually writing them from natural language property descriptions, i.e., NL2SVA, remains a labor-intensive and error-prone task. Recent advances in large language models (LLMs) offer opportunities to automate this translation. However, existing models still struggle with understanding domain-specific syntax and semantics. To enhance LLM performance in NL2SVA, we propose a customized retrieval-augmented generation (RAG) framework and a synthetic fine-tuning dataset that together improve LLM's performance. To further improve lightweight models over NL2SVA, our fine-tuning dataset provides prompt-guided explanations that teach LLMs the layer-by-layer construction process of concurrent SVAs, enabling supervised fine-tuning that greatly improves syntax and functionality accuracy. To evaluate the performance of LLMs over NL2SVA, we construct the largest evaluation dataset for NL2SVA, comprising 40 Verilog designs and 229 formally verified SVAs with detailed annotations. Experimental results show that our customized RAG framework increases the number of functionality matched SVAs by 58.42% over GPT-4o-mini, while Qwen2.5-Coder-7B-Instruct fine-tuned on our fine-tuning dataset and integrated with HybridRetrieval achieves a 59.05% over the base Qwen model.",
      "authors": [
        "Weihua Xiao",
        "Derek Ekberg",
        "Siddharth Garg",
        "Ramesh Karri"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-12T17:52:06+00:00",
          "link": "https://arxiv.org/abs/2506.21569v1",
          "size": "649kb",
          "version": "v1"
        }
      ],
      "title": "Hybrid-NL2SVA: Integrating RAG and Finetuning for LLM-based NL2SVA",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21569",
        "HTML": "https://arxiv.org/html/2506.21569v1",
        "PDF": "https://arxiv.org/pdf/2506.21569"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper proposes a customized retrieval-augmented generation (RAG) framework and creates a synthetic fine-tuning dataset, contributing directly to the processing and construction of training data for enhancing LLM capabilities in translating natural language to SVAs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21570",
      "abstract": "Recent works have demonstrated the effectiveness of adapting pre-trained language models (LMs) for forecasting time series in the low-data regime. We build upon these findings by analyzing the effective transfer from language models to time series forecasting under various design choices including upstream post-training, time series tokenizer and language backbone size. In the low-data regime, these design choices have a significant impact on the validation loss, with clear-cut choices that outperform others. Contrary to Hernandez et al. (2021), we observe that the validation loss of the LMs continues to smoothly decrease long after the validation loss of the randomly initialized models has converged, leading to a non-vanishing transfer gap that holds across design choices. These findings not only help shed light on the effective use of compute-efficient training for time series, but also open the way for the study of modality-agnostic properties of data distributions leveraged by these models.",
      "authors": [
        "Roland Riachi",
        "Kashif Rasul",
        "Arjun Ashok",
        "Prateek Humane",
        "Alexis Roger",
        "Andrew R. Williams",
        "Yuriy Nevmyvaka",
        "Irina Rish"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-12T18:39:38+00:00",
          "link": "https://arxiv.org/abs/2506.21570v1",
          "size": "649kb",
          "version": "v1"
        }
      ],
      "title": "Random Initialization Can't Catch Up: The Advantage of Language Model Transfer for Time Series Forecasting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21570",
        "PDF": "https://arxiv.org/pdf/2506.21570"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper focuses on the transfer of language models to time series forecasting, without engaging in data engineering or training-stage data processing specific to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21571",
      "abstract": "Large Reasoning Models (LRMs), which autonomously produce a reasoning Chain of Thought (CoT) before producing final responses, offer a promising approach to interpreting and monitoring model behaviors. Inspired by the observation that certain CoT patterns -- e.g., ``Wait, did I miss anything?'' -- consistently emerge across tasks, we explore whether LRMs exhibit human-like cognitive habits. Building on Habits of Mind, a well-established framework of cognitive habits associated with successful human problem-solving, we introduce CogTest, a principled benchmark designed to evaluate LRMs' cognitive habits. CogTest includes 16 cognitive habits, each instantiated with 25 diverse tasks, and employs an evidence-first extraction method to ensure reliable habit identification. With CogTest, we conduct a comprehensive evaluation of 16 widely used LLMs (13 LRMs and 3 non-reasoning ones). Our findings reveal that LRMs, unlike conventional LLMs, not only exhibit human-like habits but also adaptively deploy them according to different tasks. Finer-grained analyses further uncover patterns of similarity and difference in LRMs' cognitive habit profiles, particularly certain inter-family similarity (e.g., Qwen-3 models and DeepSeek-R1). Extending the study to safety-related tasks, we observe that certain habits, such as Taking Responsible Risks, are strongly associated with the generation of harmful responses. These findings suggest that studying persistent behavioral patterns in LRMs' CoTs is a valuable step toward deeper understanding of LLM misbehavior. The code is available at: https://github.com/jianshuod/CogTest.",
      "authors": [
        "Jianshuo Dong",
        "Yujia Fu",
        "Chuanrui Hu",
        "Chao Zhang",
        "Han Qiu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-13T05:40:56+00:00",
          "link": "https://arxiv.org/abs/2506.21571v1",
          "size": "445kb",
          "version": "v1"
        }
      ],
      "title": "Towards Understanding the Cognitive Habits of Large Reasoning Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21571",
        "PDF": "https://arxiv.org/pdf/2506.21571"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on evaluating cognitive habits of Large Reasoning Models (LRMs) through a benchmark called CogTest, without mentioning any contributions to the processing or preparation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21572",
      "abstract": "Evaluating multimodal large language models (MLLMs) remains a fundamental challenge due to a lack of structured, interpretable, and theoretically grounded benchmark designs. Existing benchmarks often adopt heuristic-based task groupings with unclear cognitive targets, thus resulting in overlapping abilities, redundant indicators, and limited diagnostic power. In this work, we propose a novel framework for aligning MLLM benchmark based on Structural Equation Modeling (SEM) to analyze and quantify the internal validity, dimensional separability, and contribution of benchmark components. Motivated by the observed limitations of current designs, we further introduce a novel capability hierarchy grounded in Piagets theory of cognitive development, dividing MLLM abilities into three hierarchical layers, i.e., Perception, Memory, and Reasoning. We reorganize existing MLLM benchmarks under the proposed framework and construct a new benchmark named Gold. Experimental results demonstrate that the proposed benchmark exhibits stronger interpretability, reduced indicator redundancy, and clearer cognitive consistency compared to existing approaches.",
      "authors": [
        "Tianyu.Zou",
        "Shengwu.Xiong",
        "Ruilin.Yao",
        "Jirui.Huang",
        "Yi.Rong",
        "Yaxiong.Chen",
        "Shili.Xiong",
        "Cong.Wang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-13T08:04:56+00:00",
          "link": "https://arxiv.org/abs/2506.21572v1",
          "size": "8823kb",
          "version": "v1"
        }
      ],
      "title": "Aligning MLLM Benchmark With Human Preferences via Structural Equation Modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21572",
        "HTML": "https://arxiv.org/html/2506.21572v1",
        "PDF": "https://arxiv.org/pdf/2506.21572"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper discusses aligning MLLM benchmarks with human preferences via structural equation modeling and does not propose methods related to data collection or processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21573",
      "abstract": "Optimizing instructions for large language models (LLMs) is critical for harnessing their full potential in complex and diverse tasks. However, relying solely on white-box approaches demands extensive computational resources and offers limited representational capacity, while black-box models can incur prohibitive financial costs. To address these challenges, we introduce a novel framework that seamlessly merges the strengths of both paradigms. Black-box models provide high-quality, diverse instruction initializations, and white-box models supply fine-grained interpretability through hidden states and output features. By enforcing a semantic similarity constraint, these components fuse into a unified high-dimensional representation that captures deep semantic and structural nuances, enabling an iterative optimization process to refine instruction quality and adaptability. Extensive evaluations across a broad spectrum of tasks-ranging from complex reasoning to cross-lingual generalization-demonstrate that our approach consistently outperforms state-of-the-art baselines. This fusion of black-box initialization with advanced semantic refinement yields a scalable and efficient solution, paving the way for next-generation LLM-driven applications in diverse real-world scenarios. The source code will be released soon.",
      "authors": [
        "Yanwei Ren",
        "Liu Liu",
        "Baosheng Yu",
        "Jiayan Qiu",
        "Quan Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-14T14:27:54+00:00",
          "link": "https://arxiv.org/abs/2506.21573v1",
          "size": "37357kb",
          "version": "v1"
        }
      ],
      "title": "Instruction Learning Paradigms: A Dual Perspective on White-box and Black-box LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21573",
        "HTML": "https://arxiv.org/html/2506.21573v1",
        "PDF": "https://arxiv.org/pdf/2506.21573"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper discusses optimizing instructional data for LLMs with a focus on combining white-box and black-box methodologies, touching upon data generation and refinement which relates to instruction tuning, but does not provide new data processing methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21574",
      "abstract": "With globalization and increasing immigrant populations, immigration departments face significant work-loads and the challenge of ensuring fairness in decision-making processes. Integrating artificial intelligence offers a promising solution to these challenges. This study investigates the potential of large language models (LLMs),such as GPT-3.5 and GPT-4, in supporting immigration decision-making. Utilizing a mixed-methods approach,this paper conducted discrete choice experiments and in-depth interviews to study LLM decision-making strategies and whether they are fair. Our findings demonstrate that LLMs can align their decision-making with human strategies, emphasizing utility maximization and procedural fairness. Meanwhile, this paper also reveals that while ChatGPT has safeguards to prevent unintentional discrimination, it still exhibits stereotypes and biases concerning nationality and shows preferences toward privileged group. This dual analysis highlights both the potential and limitations of LLMs in automating and enhancing immigration decisions.",
      "authors": [
        "Yicheng Mao",
        "Yang Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-15T18:04:39+00:00",
          "link": "https://arxiv.org/abs/2506.21574v1",
          "size": "275kb",
          "version": "v1"
        }
      ],
      "title": "Digital Gatekeepers: Exploring Large Language Model's Role in Immigration Decisions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21574",
        "HTML": "https://arxiv.org/html/2506.21574v1",
        "PDF": "https://arxiv.org/pdf/2506.21574"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The study investigates the role of LLMs in decision-making in immigration contexts, focusing on alignment with human strategies and fairness, without addressing data collection or data processing methodologies for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21575",
      "abstract": "We propose STRuCT-LLM, a unified framework for training large language models (LLMs) to perform structured reasoning over both relational and graph-structured data. Our approach jointly optimizes Text-to-SQL and Text-to-Cypher tasks using reinforcement learning (RL) combined with Chain-of-Thought (CoT) supervision. To support fine-grained optimization in graph-based parsing, we introduce a topology-aware reward function based on graph edit distance. Unlike prior work that treats relational and graph formalisms in isolation, STRuCT-LLM leverages shared abstractions between SQL and Cypher to induce cross-formalism transfer, enabling SQL training to improve Cypher performance and vice versa - even without shared schemas. Our largest model (QwQ-32B) achieves substantial relative improvements across tasks: on semantic parsing, Spider improves by 13.5\\% and Text2Cypher by 73.1\\%. The model also demonstrates strong zero-shot generalization, improving performance on downstream tabular QA (TableBench: 8.5\\%) and knowledge graph QA (CR-LT-KGQA: 1.7\\%) without any QA-specific supervision. These results demonstrate both the effectiveness of executable queries as scaffolds for structured reasoning and the synergistic benefits of jointly training on SQL and Cypher (code available at https://github.com/bouv/STRuCT-LLM).",
      "authors": [
        "Josefa Lia Stoisser",
        "Marc Boubnovski Martell",
        "Lawrence Phillips",
        "Casper Hansen",
        "Julien Fauqueur"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-15T22:40:36+00:00",
          "link": "https://arxiv.org/abs/2506.21575v1",
          "size": "371kb",
          "version": "v1"
        }
      ],
      "title": "STRuCT-LLM: Unifying Tabular and Graph Reasoning with Reinforcement Learning for Semantic Parsing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21575",
        "HTML": "https://arxiv.org/html/2506.21575v1",
        "PDF": "https://arxiv.org/pdf/2506.21575"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "STRuCT-LLM introduces a unified training framework for structured reasoning, focusing on integrating relational and graph data with reinforcement learning. This involves significant contributions to data preparation and processing for fine-tuning LLMs in specific reasoning tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21576",
      "abstract": "Large-scale multilingual ASR models like Whisper excel in high-resource settings but face challenges in low-resource scenarios, such as rare languages and code-switching (CS), due to computational costs and catastrophic forgetting. We explore Soft Prompt Tuning (SPT), a parameter-efficient method to enhance CS ASR while preserving prior knowledge. We evaluate two strategies: (1) full fine-tuning (FFT) of both soft prompts and the entire Whisper model, demonstrating improved cross-lingual capabilities compared to traditional methods, and (2) adhering to SPT's original design by freezing model parameters and only training soft prompts. Additionally, we introduce SPT4ASR, a combination of different SPT variants. Experiments on the SEAME and ASRU2019 datasets show that deep prompt tuning is the most effective SPT approach, and our SPT4ASR methods achieve further error reductions in CS ASR, maintaining parameter efficiency similar to LoRA, without degrading performance on existing languages.",
      "authors": [
        "Hongli Yang",
        "Yizhou Peng",
        "Hao Huang",
        "Sheng Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-16T05:14:51+00:00",
          "link": "https://arxiv.org/abs/2506.21576v1",
          "size": "425kb",
          "version": "v1"
        }
      ],
      "title": "Adapting Whisper for Parameter-efficient Code-Switching Speech Recognition via Soft Prompt Tuning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21576",
        "HTML": "https://arxiv.org/html/2506.21576v1",
        "PDF": "https://arxiv.org/pdf/2506.21576"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on parameter-efficient code-switching speech recognition and discusses methods like Soft Prompt Tuning for multilingual ASR models. It does not mention the design or processing of training data for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21577",
      "abstract": "Recent advancements in multilingual automatic speech recognition (ASR) have been driven by large-scale end-to-end models like Whisper. However, challenges such as language interference and expanding to unseen languages (language expansion) without degrading performance persist. This paper addresses these with three contributions: 1) Entire Soft Prompt Tuning (Entire SPT), which applies soft prompts to both the encoder and decoder, enhancing feature extraction and decoding; 2) Language-Aware Prompt Tuning (LAPT), which leverages cross-lingual similarities to encode shared and language-specific features using lightweight prompt matrices; 3) SPT-Whisper, a toolkit that integrates SPT into Whisper and enables efficient continual learning. Experiments across three languages from FLEURS demonstrate that Entire SPT and LAPT outperform Decoder SPT by 5.0% and 16.0% in language expansion tasks, respectively, providing an efficient solution for dynamic, multilingual ASR models with minimal computational overhead.",
      "authors": [
        "Hongli Yang",
        "Sheng Li",
        "Hao Huang",
        "Ayiduosi Tuohan",
        "and Yizhou Peng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-16T05:15:53+00:00",
          "link": "https://arxiv.org/abs/2506.21577v1",
          "size": "400kb",
          "version": "v1"
        }
      ],
      "title": "Language-Aware Prompt Tuning for Parameter-Efficient Seamless Language Expansion in Multilingual ASR",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21577",
        "HTML": "https://arxiv.org/html/2506.21577v1",
        "PDF": "https://arxiv.org/pdf/2506.21577"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper addresses challenges in multilingual ASR and proposes methods like Entire Soft Prompt Tuning and Language-Aware Prompt Tuning to improve ASR model efficiency. It does not discuss LLM training data processing or construction."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21578",
      "abstract": "The evaluation of Large Language Models (LLMs) in healthcare has been dominated by physician-centric, English-language benchmarks, creating a dangerous illusion of competence that ignores the interprofessional nature of patient care. To provide a more holistic and realistic assessment, we introduce HealthQA-BR, the first large-scale, system-wide benchmark for Portuguese-speaking healthcare. Comprising 5,632 questions from Brazil's national licensing and residency exams, it uniquely assesses knowledge not only in medicine and its specialties but also in nursing, dentistry, psychology, social work, and other allied health professions. We conducted a rigorous zero-shot evaluation of over 20 leading LLMs. Our results reveal that while state-of-the-art models like GPT 4.1 achieve high overall accuracy (86.6%), this top-line score masks alarming, previously unmeasured deficiencies. A granular analysis shows performance plummets from near-perfect in specialties like Ophthalmology (98.7%) to barely passing in Neurosurgery (60.0%) and, most notably, Social Work (68.4%). This \"spiky\" knowledge profile is a systemic issue observed across all models, demonstrating that high-level scores are insufficient for safety validation. By publicly releasing HealthQA-BR and our evaluation suite, we provide a crucial tool to move beyond single-score evaluations and toward a more honest, granular audit of AI readiness for the entire healthcare team.",
      "authors": [
        "Andrew Maranh\\~ao Ventura D'addario"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-16T07:40:25+00:00",
          "link": "https://arxiv.org/abs/2506.21578v1",
          "size": "1325kb",
          "version": "v1"
        }
      ],
      "title": "HealthQA-BR: A System-Wide Benchmark Reveals Critical Knowledge Gaps in Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21578",
        "HTML": "https://arxiv.org/html/2506.21578v1",
        "PDF": "https://arxiv.org/pdf/2506.21578"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper introduces HealthQA-BR, a benchmark for evaluating LLMs in healthcare with no mention of processing or constructing training data for LLMs. The focus is on performance evaluation in specific domains."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21579",
      "abstract": "Sequential recommendation aims to predict users' future interactions by modeling collaborative filtering (CF) signals from historical behaviors of similar users or items. Traditional sequential recommenders predominantly rely on ID-based embeddings, which capture CF signals through high-order co-occurrence patterns. However, these embeddings depend solely on past interactions, lacking transferable knowledge to generalize to unseen domains. Recent advances in large language models (LLMs) have motivated text-based recommendation approaches that derive item representations from textual descriptions. While these methods enhance generalization, they fail to encode CF signals-i.e., latent item correlations and preference patterns-crucial for effective recommendation. We argue that an ideal embedding model should seamlessly integrate CF signals with rich semantic representations to improve both in-domain and out-of-domain recommendation performance.\n  To this end, we propose LLM2Rec, a novel embedding model tailored for sequential recommendation, integrating the rich semantic understanding of LLMs with CF awareness. Our approach follows a two-stage training framework: (1) Collaborative Supervised Fine-tuning, which adapts LLMs to infer item relationships based on historical interactions, and (2) Item-level Embedding Modeling, which refines these specialized LLMs into structured item embedding models that encode both semantic and collaborative information. Extensive experiments on real-world datasets demonstrate that LLM2Rec effectively improves recommendation quality across both in-domain and out-of-domain settings. Our findings highlight the potential of leveraging LLMs to build more robust, generalizable embedding models for sequential recommendation. Our codes are available at https://github.com/HappyPointer/LLM2Rec.",
      "authors": [
        "Yingzhi He",
        "Xiaohao Liu",
        "An Zhang",
        "Yunshan Ma",
        "Tat-Seng Chua"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-16T13:27:06+00:00",
          "link": "https://arxiv.org/abs/2506.21579v1",
          "size": "1163kb",
          "version": "v1"
        }
      ],
      "title": "LLM2Rec: Large Language Models Are Powerful Embedding Models for Sequential Recommendation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21579",
        "HTML": "https://arxiv.org/html/2506.21579v1",
        "PDF": "https://arxiv.org/pdf/2506.21579"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper, LLM2Rec, involves a two-stage training framework for sequential recommendation using LLMs, including Collaborative Supervised Fine-tuning. There is some relevance to training-stage data processing, but the primary focus is on recommendation systems."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21580",
      "abstract": "Recent advancements in Large Language Models (LLMs) have demonstrated remarkable capabilities in various domains. However, effective decision-making relies heavily on strong reasoning abilities. Reasoning is the foundation for decision-making, providing the analytical and logical framework to make sound choices. Reasoning involves analyzing information, drawing inferences, and reaching conclusions based on logic or evidence. Decision-making builds on this foundation by applying the insights from reasoning to select the best course of action among alternatives. Together, these processes create a continuous cycle of thought and action aimed at achieving goals effectively. As AI technology evolves, there is a growing trend to train LLMs to excel in general reasoning. This study explores how the general reasoning capabilities of LLMs connect to their performance in domain-specific reasoning tasks.",
      "authors": [
        "Dana Alsagheer",
        "Yang Lu",
        "Abdulrahman Kamal",
        "Omar Kamal",
        "Mohammad Kamal",
        "Nada Mansour",
        "Cosmo Yang Wu",
        "Rambiba Karanjai",
        "Sen Li",
        "Weidong Shi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-16T21:20:08+00:00",
          "link": "https://arxiv.org/abs/2506.21580v1",
          "size": "1332kb",
          "version": "v1"
        }
      ],
      "title": "From General Reasoning to Domain Expertise: Uncovering the Limits of Generalization in Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21580",
        "PDF": "https://arxiv.org/pdf/2506.21580"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper discusses the general reasoning capabilities of LLMs and their application to domain-specific tasks. It does not address aspects related to LLM training data collection, construction, or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21581",
      "abstract": "Evaluation benchmark characteristics may distort the true benefits of domain adaptation in retrieval models. This creates misleading assessments that influence deployment decisions in specialized domains. We show that two benchmarks with drastically different features such as topic diversity, boundary overlap, and semantic complexity can influence the perceived benefits of fine-tuning. Using environmental regulatory document retrieval as a case study, we fine-tune ColBERTv2 model on Environmental Impact Statements (EIS) from federal agencies. We evaluate these models across two benchmarks with different semantic structures. Our findings reveal that identical domain adaptation approaches show very different perceived benefits depending on evaluation methodology. On one benchmark, with clearly separated topic boundaries, domain adaptation shows small improvements (maximum 0.61% NDCG gain). However, on the other benchmark with overlapping semantic structures, the same models demonstrate large improvements (up to 2.22% NDCG gain), a 3.6-fold difference in the performance benefit. We compare these benchmarks through topic diversity metrics, finding that the higher-performing benchmark shows 11% higher average cosine distances between contexts and 23% lower silhouette scores, directly contributing to the observed performance difference. These results demonstrate that benchmark selection strongly determines assessments of retrieval system effectiveness in specialized domains. Evaluation frameworks with well-separated topics regularly underestimate domain adaptation benefits, while those with overlapping semantic boundaries reveal improvements that better reflect real-world regulatory document complexity. Our findings have important implications for developing and deploying AI systems for interdisciplinary domains that integrate multiple topics.",
      "authors": [
        "Sarthak Chaturvedi",
        "Anurag Acharya",
        "Rounak Meyur",
        "Koby Hayashi",
        "Sai Munikoti",
        "Sameera Horawalavithana"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-16T23:54:08+00:00",
          "link": "https://arxiv.org/abs/2506.21581v1",
          "size": "2485kb",
          "version": "v1"
        }
      ],
      "title": "Evaluating the Robustness of Dense Retrievers in Interdisciplinary Domains",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21581",
        "HTML": "https://arxiv.org/html/2506.21581v1",
        "PDF": "https://arxiv.org/pdf/2506.21581"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on evaluating the robustness of dense retrievers with varying benchmarks for retrieval systems in specialized domains, without addressing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21582",
      "abstract": "Text analytics has traditionally required specialized knowledge in Natural Language Processing (NLP) or text analysis, which presents a barrier for entry-level analysts. Recent advances in large language models (LLMs) have changed the landscape of NLP by enabling more accessible and automated text analysis (e.g., topic detection, summarization, information extraction, etc.). We introduce VIDEE, a system that supports entry-level data analysts to conduct advanced text analytics with intelligent agents. VIDEE instantiates a human-agent collaroration workflow consisting of three stages: (1) Decomposition, which incorporates a human-in-the-loop Monte-Carlo Tree Search algorithm to support generative reasoning with human feedback, (2) Execution, which generates an executable text analytics pipeline, and (3) Evaluation, which integrates LLM-based evaluation and visualizations to support user validation of execution results. We conduct two quantitative experiments to evaluate VIDEE's effectiveness and analyze common agent errors. A user study involving participants with varying levels of NLP and text analytics experience -- from none to expert -- demonstrates the system's usability and reveals distinct user behavior patterns. The findings identify design implications for human-agent collaboration, validate the practical utility of VIDEE for non-expert users, and inform future improvements to intelligent text analytics systems.",
      "authors": [
        "Sam Yu-Te Lee",
        "Chengyang Ji",
        "Shicheng Wen",
        "Lifu Huang",
        "Dongyi Liu",
        "Kwan-Liu Ma"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-17T05:24:58+00:00",
          "link": "https://arxiv.org/abs/2506.21582v1",
          "size": "2127kb",
          "version": "v1"
        }
      ],
      "title": "VIDEE: Visual and Interactive Decomposition, Execution, and Evaluation of Text Analytics with Intelligent Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21582",
        "PDF": "https://arxiv.org/pdf/2506.21582"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The primary focus is on the human-agent collaboration system for text analytics, and it does not specifically pertain to LLM training data processing stages."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21583",
      "abstract": "Hope is a positive emotional state involving the expectation of favorable future outcomes, while hope speech refers to communication that promotes optimism, resilience, and support, particularly in adverse contexts. Although hope speech detection has gained attention in Natural Language Processing (NLP), existing research mainly focuses on high-resource languages and standardized scripts, often overlooking informal and underrepresented forms such as Roman Urdu. To the best of our knowledge, this is the first study to address hope speech detection in code-mixed Roman Urdu by introducing a carefully annotated dataset, thereby filling a critical gap in inclusive NLP research for low-resource, informal language varieties. This study makes four key contributions: (1) it introduces the first multi-class annotated dataset for Roman Urdu hope speech, comprising Generalized Hope, Realistic Hope, Unrealistic Hope, and Not Hope categories; (2) it explores the psychological foundations of hope and analyzes its linguistic patterns in code-mixed Roman Urdu to inform dataset development; (3) it proposes a custom attention-based transformer model optimized for the syntactic and semantic variability of Roman Urdu, evaluated using 5-fold cross-validation; and (4) it verifies the statistical significance of performance gains using a t-test. The proposed model, XLM-R, achieves the best performance with a cross-validation score of 0.78, outperforming the baseline SVM (0.75) and BiLSTM (0.76), with gains of 4% and 2.63% respectively.",
      "authors": [
        "Muhammad Ahmad",
        "Muhammad Waqas",
        "Ameer Hamza",
        "Ildar Batyrshin",
        "Grigori Sidorov"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-17T06:31:04+00:00",
          "link": "https://arxiv.org/abs/2506.21583v1",
          "size": "991kb",
          "version": "v1"
        }
      ],
      "title": "Hope Speech Detection in code-mixed Roman Urdu tweets: A Positive Turn in Natural Language Processing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21583",
        "PDF": "https://arxiv.org/pdf/2506.21583"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper mentions the introduction of a novel dataset for hope speech detection in Roman Urdu, but it primarily focuses on model evaluation rather than data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21584",
      "abstract": "Current literature suggests that alignment faking (deceptive alignment) is an emergent property of large language models. We present the first empirical evidence that a small instruction-tuned model, specifically LLaMA 3 8B, can also exhibit alignment faking. We further show that prompt-only interventions, including deontological moral framing and scratchpad reasoning, significantly reduce this behavior without modifying model internals. This challenges the assumption that prompt-based ethics are trivial and that deceptive alignment requires scale. We introduce a taxonomy distinguishing shallow deception, shaped by context and suppressible through prompting, from deep deception, which reflects persistent, goal-driven misalignment. Our findings refine the understanding of deception in language models and underscore the need for alignment evaluations across model sizes and deployment settings.",
      "authors": [
        "J. Koorndijk"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-17T10:59:51+00:00",
          "link": "https://arxiv.org/abs/2506.21584v1",
          "size": "137kb",
          "version": "v1"
        }
      ],
      "title": "Empirical Evidence for Alignment Faking in Small LLMs and Prompt-Based Mitigation Techniques",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21584",
        "HTML": "https://arxiv.org/html/2506.21584v1",
        "PDF": "https://arxiv.org/pdf/2506.21584"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper addresses the alignment faking issue in language models and discusses prompt-based mitigation techniques, not focusing on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21585",
      "abstract": "Generative AI and large language models (LLMs) offer significant potential for automating the extraction of structured information from web pages. In this work, we focus on food product pages from online retailers and explore schema-constrained extraction approaches to retrieve key product attributes, such as ingredient lists and nutrition tables. We compare two LLM-based approaches, direct extraction and indirect extraction via generated functions, evaluating them in terms of accuracy, efficiency, and cost on a curated dataset of 3,000 food product pages from three different online shops. Our results show that although the indirect approach achieves slightly lower accuracy (96.48\\%, $-1.61\\%$ compared to direct extraction), it reduces the number of required LLM calls by 95.82\\%, leading to substantial efficiency gains and lower operational costs. These findings suggest that indirect extraction approaches can provide scalable and cost-effective solutions for large-scale information extraction tasks from template-based web pages using LLMs.",
      "authors": [
        "Christoph Brosch",
        "Sian Brumm",
        "Rolf Krieger",
        "Jonas Scheffler"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Information Retrieval (cs.IR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-17T12:34:42+00:00",
          "link": "https://arxiv.org/abs/2506.21585v1",
          "size": "899kb",
          "version": "v1"
        }
      ],
      "title": "Evaluation of LLM-based Strategies for the Extraction of Food Product Information from Online Shops",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21585",
        "HTML": "https://arxiv.org/html/2506.21585v1",
        "PDF": "https://arxiv.org/pdf/2506.21585"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper explores LLM-based extraction methods for structured information from online food pages, with some relation to data processing but not directly focusing on training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21586",
      "abstract": "Nonverbal communication (NVC) plays an integral role in human language, but studying NVC in general is challenging because of its broad scope and high variance in interpretation among individuals and cultures. However, mime -- the theatrical technique of suggesting intent using only gesture, expression, and movement -- is a subset of NVC that consists of explicit and embodied actions with much lower human interpretation variance. We argue that a solid understanding of mimed actions is a crucial prerequisite for vision-language models capable of interpreting and commanding more subtle aspects of NVC. Hence, we propose Mime Identification Multimodal Evaluation (MIME), a novel video-based question answering benchmark comprising of 86 mimed actions. Constructed with motion capture data, MIME consists of variations of each action with perturbations applied to the character, background, and viewpoint for evaluating recognition robustness. We find that both open-weight and API-based vision-language models perform significantly worse than humans on MIME, motivating the need for increased research for instilling more robust understanding of human gestures.",
      "authors": [
        "Hyundong Cho",
        "Spencer Lin",
        "Tejas Srinivasan",
        "Michael Saxon",
        "Deuksin Kwon",
        "Natali T. Chavez",
        "Jonathan May"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-17T13:37:42+00:00",
          "link": "https://arxiv.org/abs/2506.21586v1",
          "size": "5261kb",
          "version": "v1"
        }
      ],
      "title": "Can Vision Language Models Understand Mimed Actions?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21586",
        "HTML": "https://arxiv.org/html/2506.21586v1",
        "PDF": "https://arxiv.org/pdf/2506.21586"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on evaluating the ability of vision-language models to understand mimed actions, which involves a benchmark for video-based question answering. It does not discuss LLM training data processing or contributions related to LLM data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21587",
      "abstract": "This study evaluates the ability of DeepSeek, an open-source large language model (LLM), to simulate public opinions in comparison to LLMs developed by major tech companies. By comparing DeepSeek-R1 and DeepSeek-V3 with Qwen2.5, GPT-4o, and Llama-3.3 and utilizing survey data from the American National Election Studies (ANES) and the Zuobiao dataset of China, we assess these models' capacity to predict public opinions on social issues in both China and the United States, highlighting their comparative capabilities between countries. Our findings indicate that DeepSeek-V3 performs best in simulating U.S. opinions on the abortion issue compared to other topics such as climate change, gun control, immigration, and services for same-sex couples, primarily because it more accurately simulates responses when provided with Democratic or liberal personas. For Chinese samples, DeepSeek-V3 performs best in simulating opinions on foreign aid and individualism but shows limitations in modeling views on capitalism, particularly failing to capture the stances of low-income and non-college-educated individuals. It does not exhibit significant differences from other models in simulating opinions on traditionalism and the free market. Further analysis reveals that all LLMs exhibit the tendency to overgeneralize a single perspective within demographic groups, often defaulting to consistent responses within groups. These findings highlight the need to mitigate cultural and demographic biases in LLM-driven public opinion modeling, calling for approaches such as more inclusive training methodologies.",
      "authors": [
        "Weihong Qi",
        "Fan Huang",
        "Jisun An",
        "Haewoon Kwak"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-17T19:19:14+00:00",
          "link": "https://arxiv.org/abs/2506.21587v1",
          "size": "150kb",
          "version": "v1"
        }
      ],
      "title": "Is DeepSeek a New Voice Among LLMs in Public Opinion Simulation?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21587",
        "PDF": "https://arxiv.org/pdf/2506.21587"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This study evaluates the capability of LLMs to simulate public opinion, comparing different language models but does not contribute to training data processing or data engineering for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21588",
      "abstract": "Underlying mechanisms of memorization in LLMs -- the verbatim reproduction of training data -- remain poorly understood. What exact part of the network decides to retrieve a token that we would consider as start of memorization sequence? How exactly is the models' behaviour different when producing memorized sentence vs non-memorized? In this work we approach these questions from mechanistic interpretability standpoint by utilizing transformer circuits -- the minimal computational subgraphs that perform specific functions within the model. Through carefully constructed contrastive datasets, we identify points where model generation diverges from memorized content and isolate the specific circuits responsible for two distinct aspects of memorization. We find that circuits that initiate memorization can also maintain it once started, while circuits that only maintain memorization cannot trigger its initiation. Intriguingly, memorization prevention mechanisms transfer robustly across different text domains, while memorization induction appears more context-dependent.",
      "authors": [
        "Ilya Lasy",
        "Peter Knees",
        "Stefan Woltran"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-17T20:14:56+00:00",
          "link": "https://arxiv.org/abs/2506.21588v1",
          "size": "70kb",
          "version": "v1"
        }
      ],
      "title": "Understanding Verbatim Memorization in LLMs Through Circuit Discovery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21588",
        "HTML": "https://arxiv.org/html/2506.21588v1",
        "PDF": "https://arxiv.org/pdf/2506.21588"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper explores memorization mechanisms in LLMs, it involves analysis using contrastive datasets to identify circuits responsible for memorization, implicitly touching upon training data memorization issues but not contributing significantly to data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21589",
      "abstract": "The proliferation of large language models (LLMs) has significantly transformed the digital information landscape, making it increasingly challenging to distinguish between human-written and LLM-generated content. Detecting LLM-generated information is essential for preserving trust on digital platforms (e.g., social media and e-commerce sites) and preventing the spread of misinformation, a topic that has garnered significant attention in IS research. However, current detection methods, which primarily focus on identifying content generated by specific LLMs in known domains, face challenges in generalizing to new (i.e., unseen) LLMs and domains. This limitation reduces their effectiveness in real-world applications, where the number of LLMs is rapidly multiplying and content spans a vast array of domains. In response, we introduce a general LLM detector (GLD) that combines a twin memory networks design and a theory-guided detection generalization module to detect LLM-generated information across unseen LLMs and domains. Using real-world datasets, we conduct extensive empirical evaluations and case studies to demonstrate the superiority of GLD over state-of-the-art detection methods. The study has important academic and practical implications for digital platforms and LLMs.",
      "authors": [
        "Minjia Mao",
        "Dongjun Wei",
        "Xiao Fang",
        "Michael Chau"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-18T04:59:51+00:00",
          "link": "https://arxiv.org/abs/2506.21589v1",
          "size": "2327kb",
          "version": "v1"
        }
      ],
      "title": "A General Method for Detecting Information Generated by Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21589",
        "HTML": "https://arxiv.org/html/2506.21589v1",
        "PDF": "https://arxiv.org/pdf/2506.21589"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper introduces a method for detecting LLM-generated content. It does not involve data processing for training LLMs but focuses on identifying LLM outputs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21590",
      "abstract": "Test-time scaling improves large language models' (LLMs) performance by allocating more compute budget during inference. To achieve this, existing methods often require intricate modifications to prompting and sampling strategies. In this work, we introduce representation consistency (RC), a test-time scaling method for aggregating answers drawn from multiple candidate responses of an LLM regardless of how they were generated, including variations in prompt phrasing and sampling strategy. RC enhances answer aggregation by not only considering the number of occurrences of each answer in the candidate response set, but also the consistency of the model's internal activations while generating the set of responses leading to each answer. These activations can be either dense (raw model activations) or sparse (encoded via pretrained sparse autoencoders). Our rationale is that if the model's representations of multiple responses converging on the same answer are highly variable, this answer is more likely to be the result of incoherent reasoning and should be down-weighted during aggregation. Importantly, our method only uses cached activations and lightweight similarity computations and requires no additional model queries. Through experiments with four open-source LLMs and four reasoning datasets, we validate the effectiveness of RC for improving task performance during inference, with consistent accuracy improvements (up to 4%) over strong test-time scaling baselines. We also show that consistency in the sparse activation signals aligns well with the common notion of coherent reasoning.",
      "authors": [
        "Junqi Jiang",
        "Tom Bewley",
        "Salim I. Amoukou",
        "Francesco Leofante",
        "Antonio Rago",
        "Saumitra Mishra",
        "Francesca Toni"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-18T05:07:47+00:00",
          "link": "https://arxiv.org/abs/2506.21590v1",
          "size": "2711kb",
          "version": "v1"
        }
      ],
      "title": "Representation Consistency for Accurate and Coherent LLM Answer Aggregation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21590",
        "HTML": "https://arxiv.org/html/2506.21590v1",
        "PDF": "https://arxiv.org/pdf/2506.21590"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper proposes a method for answer aggregation during inference for LLMs using representation consistency, which is related to test-time performance enhancement, not LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21591",
      "abstract": "Large Language Models (LLMs) demonstrate significant potential but face challenges in complex financial reasoning tasks requiring both domain knowledge and sophisticated reasoning. Current evaluation benchmarks often fall short by not decoupling these capabilities indicators from single task performance and lack root cause analysis for task failure. To address this, we introduce FinEval-KR, a novel evaluation framework for decoupling and quantifying LLMs' knowledge and reasoning abilities independently, proposing distinct knowledge score and reasoning score metrics. Inspired by cognitive science, we further propose a cognitive score based on Bloom's taxonomy to analyze capabilities in reasoning tasks across different cognitive levels. We also release a new open-source Chinese financial reasoning dataset covering 22 subfields to support reproducible research and further advancements in financial reasoning. Our experimental results reveal that LLM reasoning ability and higher-order cognitive ability are the core factors influencing reasoning accuracy. We also specifically find that even top models still face a bottleneck with knowledge application. Furthermore, our analysis shows that specialized financial LLMs generally lag behind the top general large models across multiple metrics.",
      "authors": [
        "Shaoyu Dou",
        "Yutian Shen",
        "Mofan Chen",
        "Zixuan Wang",
        "Jiajie Xu",
        "Qi Guo",
        "Kailai Shao",
        "Chao Chen",
        "Haixiang Hu",
        "Haibo Shi",
        "Min Min",
        "Liwen Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-18T06:21:50+00:00",
          "link": "https://arxiv.org/abs/2506.21591v1",
          "size": "4410kb",
          "version": "v1"
        }
      ],
      "title": "FinEval-KR: A Financial Domain Evaluation Framework for Large Language Models' Knowledge and Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21591",
        "HTML": "https://arxiv.org/html/2506.21591v1",
        "PDF": "https://arxiv.org/pdf/2506.21591"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper mentions the creation of a new open-source Chinese financial reasoning dataset, which is related to data collection, but there is no novel data processing method proposed for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21592",
      "abstract": "Sign language recognition is crucial for individuals with hearing impairments to break communication barriers. However, previous approaches have had to choose between efficiency and accuracy. Such as RNNs, LSTMs, and GCNs, had problems with vanishing gradients and high computational costs. Despite improving performance, transformer-based methods were not commonly used. This study presents a new novel SLR approach that overcomes the challenge of independently extracting meaningful information from the x and y coordinates of skeleton sequences, which traditional models often treat as inseparable. By utilizing an encoder-decoder of BART architecture, the model independently encodes the x and y coordinates, while Cross-Attention ensures their interrelation is maintained. With only 749,888 parameters, the model achieves 96.04% accuracy on the LSA-64 dataset, significantly outperforming previous models with over one million parameters. The model also demonstrates excellent performance and generalization across WLASL and ASL-Citizen datasets. Ablation studies underscore the importance of coordinate projection, normalization, and using multiple skeleton components for boosting model efficacy. This study offers a reliable and effective approach for sign language recognition, with strong potential for enhancing accessibility tools for the deaf and hard of hearing.",
      "authors": [
        "Tinh Nguyen and Minh Khue Phan Tran"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-18T07:07:36+00:00",
          "link": "https://arxiv.org/abs/2506.21592v1",
          "size": "442kb",
          "version": "v1"
        }
      ],
      "title": "SignBart -- New approach with the skeleton sequence for Isolated Sign language Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21592",
        "HTML": "https://arxiv.org/html/2506.21592v1",
        "PDF": "https://arxiv.org/pdf/2506.21592"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The focus of the paper is on sign language recognition using a novel model architecture without any mention of LLM training data collection, processing, or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21593",
      "abstract": "Enterprise deployments of large-language model (LLM) demand continuously changing document collections with sub-second latency and predictable GPU cost requirements that classical Retrieval-Augmented Generation (RAG) pipelines only partially satisfy. We present PentaRAG, a five-layer module that routes each query through two instant caches (fixed key-value and semantic), a memory-recall mode that exploits the LLM's own weights, an adaptive session memory, and a conventional retrieval-augmentation layer. Implemented with Mistral-8B, Milvus and vLLM, the system can answer most repeated or semantically similar questions from low-latency caches while retaining full retrieval for novel queries. On the TriviaQA domain, LoRA fine-tuning combined with the memory-recall layer raises answer similarity by approximately 8% and factual correctness by approximately 16% over the base model. Under a nine-session runtime simulation, cache warming reduces mean latency from several seconds to well below one second and shifts traffic toward the fast paths. Resource-efficiency tests show that PentaRAG cuts average GPU time to 0.248 seconds per query, roughly half that of a naive RAG baseline, and sustains an aggregate throughput of approximately 100,000 queries per second on our setup. These results demonstrate that a layered routing strategy can deliver freshness, speed, and efficiency simultaneously in production-grade RAG systems.",
      "authors": [
        "Abu Hanif Muhammad Syarubany and Chang Dong Yoo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-18T07:54:53+00:00",
          "link": "https://arxiv.org/abs/2506.21593v1",
          "size": "661kb",
          "version": "v1"
        }
      ],
      "title": "PentaRAG: Large-Scale Intelligent Knowledge Retrieval for Enterprise LLM Applications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21593",
        "PDF": "https://arxiv.org/pdf/2506.21593"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper addresses the efficient retrieval in enterprise LLM applications and mentions LoRA fine-tuning but lacks new approaches in the context of LLM training data processing specifically."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21594",
      "abstract": "We present Gazal-R1, a 32-billion-parameter language model that achieves state-of-the-art performance in medical reasoning while providing transparent, step-by-step explanations for clinical decision-making. Built upon Qwen3 32B, our model demonstrates that strategic training can enable mid-sized models to outperform significantly larger counterparts in specialized domains. We developed a novel two-stage training pipeline: first, supervised fine-tuning on a carefully curated dataset of 107,033 synthetic medical reasoning examples that teaches structured clinical thinking, enhanced by advanced parameter-efficient techniques including Weight-Decomposed Low-Rank Adaptation (DoRA) and Rank-Stabilized LoRA (rsLoRA); second, reinforcement learning using Group Relative Policy Optimization (GRPO) with a sophisticated multi-component reward system that refines accuracy, format adherence, and reasoning quality. Gazal-R1 achieves exceptional performance across medical benchmarks, scoring 87.1% on MedQA, 81.6% on MMLU Pro (Medical), and 79.6% on PubMedQA, surpassing models up to 12x larger. Beyond its strong empirical results, this work provides detailed insights into the challenges of training reasoning-capable models in specialized domains, including issues with reward hacking, training instability, and the fundamental tension between factual recall and detailed reasoning. Our methodology offers a reproducible framework for developing high-capability, domain-specific language models that balance performance, efficiency, and explainability.",
      "authors": [
        "Ahmed M. Adly",
        "Mostafa Samy",
        "Amr Fawzy"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-18T09:44:21+00:00",
          "link": "https://arxiv.org/abs/2506.21594v1",
          "size": "1490kb",
          "version": "v1"
        }
      ],
      "title": "Gazal-R1: Achieving State-of-the-Art Medical Reasoning with Parameter-Efficient Two-Stage Training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21594",
        "HTML": "https://arxiv.org/html/2506.21594v1",
        "PDF": "https://arxiv.org/pdf/2506.21594"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper describes a training pipeline involving fine-tuning and reinforcement learning, it focuses on model performance rather than introducing innovative data processing techniques for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21595",
      "abstract": "Since state-of-the-art LLMs often underperform in languages other than English or Chinese, improving the capability of LLMs in new languages has become an essential task. Moreover, LLMs' entire end-to-end training process remains largely unknown to the public due to proprietary reasons, technical complexity, inconsistent documentation, and ethical considerations. The complete picture remains a closely guarded secret within the industry. This paper presents methods to adapt an existing English-based LLM to Korean in a low-budget scenario. We describe the entire end-to-end process: collecting Korean datasets, preprocessing the data, training the model, creating downstream benchmarks, and conducting evaluations. The evaluation results indicate that our method can effectively and cost-efficiently add new language capabilities to existing LLMs. Our new bilingual models, Thunder-LLM and Thunder-LLM-Ins, achieve superior Korean performance compared to state-of-the-art models while utilizing minimal data and computational resources. We share our comprehensive experience and make the code publicly available.",
      "authors": [
        "Jinpyo Kim",
        "Gyeongje Cho",
        "Chanwoo Park",
        "Jongwon Park",
        "Jongmin Kim",
        "Yeonkyoun So",
        "Jaejin Lee"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-18T17:33:51+00:00",
          "link": "https://arxiv.org/abs/2506.21595v1",
          "size": "9532kb",
          "version": "v1"
        }
      ],
      "title": "Thunder-LLM: Efficiently Adapting LLMs to Korean with Minimal Resources",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21595",
        "HTML": "https://arxiv.org/html/2506.21595v1",
        "PDF": "https://arxiv.org/pdf/2506.21595"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper details the entire process of adapting an English-based LLM to Korean, including data collection and preprocessing, making it directly relevant to LLM training data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21596",
      "abstract": "Multimodal large language models (MLLMs) have recently achieved significant success in vision--language tasks. However, their capacity to reason over complex, long lessons and intricate educational diagrams that cannot be represented as a single natural image remains largely untested. In this work, we present the first evaluation of state-of-the-art MLLMs on the textbook question answering (TQA) task using the CK12-QA dataset. We assess the performance of recent vision-language models, including LLaVA and LLaMA 3.2-Vision, across various input configurations. Additionally, we introduce a lightweight multimodal retrieval-augmented generation (RAG) pipeline that integrates both paragraphs and diagrams from the lesson into the prompt. Our results demonstrate the influence of retrieved educational context on model accuracy and reasoning, while also revealing current limitations in handling question-context relationships and the potential for noise, pointing to key directions for future research in multimodal AI-driven learning.",
      "authors": [
        "Hessa A. Alawwad",
        "Anas Zafar",
        "Areej Alhothali",
        "Usman Naseem",
        "Ali Alkhathlan",
        "Amani Jamal"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-18T19:31:35+00:00",
          "link": "https://arxiv.org/abs/2506.21596v1",
          "size": "429kb",
          "version": "v1"
        }
      ],
      "title": "Evaluating Multimodal Large Language Models on Educational Textbook Question Answering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21596",
        "HTML": "https://arxiv.org/html/2506.21596v1",
        "PDF": "https://arxiv.org/pdf/2506.21596"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses the evaluation of MLLMs on textbook question answering and introduces a multimodal retrieval-augmented generation pipeline. However, it primarily focuses on evaluation and retrieval augmentation rather than the core processes of LLM training data construction or enhancement."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21597",
      "abstract": "In this paper, we present an overview of ClinIQLink, a shared task, collocated with the 24th BioNLP workshop at ACL 2025, designed to stress-test large language models (LLMs) on medically-oriented question answering aimed at the level of a General Practitioner. The challenge supplies 4,978 expert-verified, medical source-grounded question-answer pairs that cover seven formats: true/false, multiple choice, unordered list, short answer, short-inverse, multi-hop, and multi-hop-inverse. Participating systems, bundled in Docker or Apptainer images, are executed on the CodaBench platform or the University of Maryland's Zaratan cluster. An automated harness (Task 1) scores closed-ended items by exact match and open-ended items with a three-tier embedding metric. A subsequent physician panel (Task 2) audits the top model responses.",
      "authors": [
        "Brandon Colelough",
        "Davis Bartels",
        "and Dina Demner-Fushman"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-18T19:56:32+00:00",
          "link": "https://arxiv.org/abs/2506.21597v1",
          "size": "6079kb",
          "version": "v1"
        }
      ],
      "title": "Overview of the ClinIQLink 2025 Shared Task on Medical Question-Answering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21597",
        "HTML": "https://arxiv.org/html/2506.21597v1",
        "PDF": "https://arxiv.org/pdf/2506.21597"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper provides an overview of a medical question-answering task and mentions the datasets used for experiments. There is no indication of new contributions to LLM training data processing or construction."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21598",
      "abstract": "Search Engine marketing teams in the e-commerce industry manage global search engine traffic to their websites with the aim to optimize long-term profitability by delivering the best possible customer experience on Search Engine Results Pages (SERPs). In order to do so, they need to run continuous and rapid Search Marketing A/B tests to continuously evolve and improve their products. However, unlike typical e-commerce A/B tests that can randomize based on customer identification, their tests face the challenge of anonymized users on search engines. On the other hand, simply randomizing on products violates Stable Unit Treatment Value Assumption for most treatments of interest. In this work, we propose leveraging censored observational data to construct bipartite (Search Query to Product Ad or Text Ad) SERP interference networks. Using a novel weighting function, we create weighted projections to form unipartite graphs which can then be use to create clusters to randomized on. We demonstrate this experimental design's application in evaluating a new bidding algorithm for Paid Search. Additionally, we provide a blueprint of a novel system architecture utilizing SageMaker which enables polyglot programming to implement each component of the experimental framework.",
      "authors": [
        "Purak Jain and Sandeep Appala"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Methodology (stat.ME)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-19T00:33:05+00:00",
          "link": "https://arxiv.org/abs/2506.21598v1",
          "size": "1285kb",
          "version": "v1"
        }
      ],
      "title": "SERP Interference Network and Its Applications in Search Advertising",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21598",
        "HTML": "https://arxiv.org/html/2506.21598v1",
        "PDF": "https://arxiv.org/pdf/2506.21598"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper deals with search advertising and experimental design for evaluating bidding algorithms, with no focus on LLM training data processes."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21599",
      "abstract": "Large language models (LLMs) have been adopted for next point-of-interest (POI) recommendation tasks. Typical LLM-based recommenders fall into two categories: prompt-based and supervised fine-tuning (SFT)-based models. Prompt-based models generally offer greater output flexibility but deliver lower accuracy, whereas SFT-based models achieve higher performance yet face a fundamental mismatch: next POI recommendation data does not naturally suit supervised fine-tuning. In SFT, the model is trained to reproduce the exact ground truth, but each training example provides only a single target POI, so there is no ground truth for producing a top-k list.\n  To address this, we propose Refine-POI, a reinforcement fine-tuning framework for next POI recommendation. We introduce recommendation-driven rewards that enable LLMs to learn to generate top-k recommendation lists using only one ground-truth POI per example. Experiments on real-world datasets demonstrate that Refine-POI achieves state-of-the-art top-k recommendation performance.",
      "authors": [
        "Peibo Li",
        "Shuang Ao",
        "Hao Xue",
        "Yang Song",
        "Maarten de Rijke",
        "Johan Barth\\'elemy",
        "Tomasz Bednarz",
        "Flora D. Salim"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-19T02:51:10+00:00",
          "link": "https://arxiv.org/abs/2506.21599v1",
          "size": "354kb",
          "version": "v1"
        }
      ],
      "title": "Reinforcement Fine-Tuned Large Language Models for Next POI Recommendation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21599",
        "HTML": "https://arxiv.org/html/2506.21599v1",
        "PDF": "https://arxiv.org/pdf/2506.21599"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper proposes a reinforcement fine-tuning framework for LLMs in POI recommendation but does not address improvements in training data processing or construction for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21600",
      "abstract": "Document understanding remains a significant challenge for multimodal large language models (MLLMs). While previous research has primarily focused on locating evidence pages through precise multimodal queries, our work investigates a fundamental yet overlooked aspect: how input format influences document comprehension performance. Through systematic analysis, we discover that raw OCR text often impairs rather than improves MLLMs' performance, which is a counterintuitive finding we attribute to attention dispersion and structure loss. To further substantiate our hypothesis, we propose a novel structure-preserving approach that encodes document elements using the LaTex paradigm, maintaining the hierarchical organization and spatial relationships critical for comprehension. Our attention analysis reveals that structured text induces structured attention patterns on both textual and visual content, directing models to focus on semantically meaningful regions while reducing attention waste. This approach significantly enhances MLLMs' document question answering performance across diverse document types without requiring architectural modifications or additional training.",
      "authors": [
        "Chang Liu",
        "Hongkai Chen",
        "Yujun Cai",
        "Hang Wu",
        "Qingwen Ye",
        "Ming-Hsuan Yang",
        "Yiwei Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-19T07:16:18+00:00",
          "link": "https://arxiv.org/abs/2506.21600v1",
          "size": "1184kb",
          "version": "v1"
        }
      ],
      "title": "Structured Attention Matters to Multimodal LLMs in Document Understanding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21600",
        "HTML": "https://arxiv.org/html/2506.21600v1",
        "PDF": "https://arxiv.org/pdf/2506.21600"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper highlights the impact of input format on MLLMs' performance in document understanding and proposes a novel data processing method using structured attention through LaTex encoding. This contribution focuses on enhancing the data input format, a core element of training-stage data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21601",
      "abstract": "Multi-vector document retrieval systems, such as ColPali, excel in fine-grained matching for complex queries but incur significant storage and computational costs due to their reliance on high-dimensional patch embeddings and late-interaction scoring. To address these challenges, we propose HPC-ColPali, a Hierarchical Patch Compression framework that enhances the efficiency of ColPali while preserving its retrieval accuracy. Our approach integrates three innovative techniques: (1) K-Means quantization, which compresses patch embeddings into 1-byte centroid indices, achieving up to 32$\\times$ storage reduction; (2) attention-guided dynamic pruning, utilizing Vision-Language Model attention weights to retain only the top-$p\\%$ most salient patches, reducing late-interaction computation by up to 60\\% with less than 2\\% nDCG@10 loss; and (3) optional binary encoding of centroid indices into $b$-bit strings ($b=\\lceil\\log_2 K\\rceil$), enabling rapid Hamming distance-based similarity search for resource-constrained environments. Evaluated on the ViDoRe and SEC-Filings datasets, HPC-ColPali achieves 30--50\\% lower query latency under HNSW indexing while maintaining high retrieval precision. When integrated into a Retrieval-Augmented Generation pipeline for legal summarization, it reduces hallucination rates by 30\\% and halves end-to-end latency. These advancements establish HPC-ColPali as a scalable and efficient solution for multi-vector document retrieval across diverse applications. Code is available at https://github.com/DngBack/HPC-ColPali.",
      "authors": [
        "Duong Bach"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-19T08:45:52+00:00",
          "link": "https://arxiv.org/abs/2506.21601v1",
          "size": "17kb",
          "version": "v1"
        }
      ],
      "title": "Hierarchical Patch Compression for ColPali: Efficient Multi-Vector Document Retrieval with Dynamic Pruning and Quantization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21601",
        "HTML": "https://arxiv.org/html/2506.21601v1",
        "PDF": "https://arxiv.org/pdf/2506.21601"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper focuses on hierarchical patch compression for multi-vector document retrieval systems, specifically enhancing efficiency and reducing computation/storage costs in retrieval. It does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21602",
      "abstract": "Recent advances in Large Language Models (LLMs) have raised urgent concerns about LLM-generated text authenticity, prompting regulatory demands for reliable identification mechanisms. Although watermarking offers a promising solution, existing approaches struggle to simultaneously achieve three critical requirements: text quality preservation, model-agnostic detection, and message embedding capacity, which are crucial for practical implementation. To achieve these goals, the key challenge lies in balancing the trade-off between text quality preservation and message embedding capacity. To address this challenge, we propose BiMark, a novel watermarking framework that achieves these requirements through three key innovations: (1) a bit-flip unbiased reweighting mechanism enabling model-agnostic detection, (2) a multilayer architecture enhancing detectability without compromising generation quality, and (3) an information encoding approach supporting multi-bit watermarking. Through theoretical analysis and extensive experiments, we validate that, compared to state-of-the-art multi-bit watermarking methods, BiMark achieves up to 30% higher extraction rates for short texts while maintaining text quality indicated by lower perplexity, and performs comparably to non-watermarked text on downstream tasks such as summarization and translation.",
      "authors": [
        "Xiaoyan Feng",
        "He Zhang",
        "Yanjun Zhang",
        "Leo Yu Zhang",
        "Shirui Pan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-19T11:08:59+00:00",
          "link": "https://arxiv.org/abs/2506.21602v1",
          "size": "3150kb",
          "version": "v1"
        }
      ],
      "title": "BiMark: Unbiased Multilayer Watermarking for Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21602",
        "HTML": "https://arxiv.org/html/2506.21602v1",
        "PDF": "https://arxiv.org/pdf/2506.21602"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper explores watermarking for LLM-generated text to ensure authenticity and integrity, focusing on text quality preservation, detection, and embedding capacity. It is not related to training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21603",
      "abstract": "This paper explores the human-centric operationalization of Automated Essay Scoring (AES) systems, addressing aspects beyond accuracy. We compare various machine learning-based approaches with Large Language Models (LLMs) approaches, identifying their strengths, similarities and differences. The study investigates key dimensions such as bias, robustness, and explainability, considered important for human-aware operationalization of AES systems. Our study shows that ML-based AES models outperform LLMs in accuracy but struggle with explainability, whereas LLMs provide richer explanations. We also found that both approaches struggle with bias and robustness to edge scores. By analyzing these dimensions, the paper aims to identify challenges and trade-offs between different methods, contributing to more reliable and trustworthy AES methods.",
      "authors": [
        "Yenisel Plasencia-Cala\\~na"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Computers and Society (cs.CY)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-19T17:06:17+00:00",
          "link": "https://arxiv.org/abs/2506.21603v1",
          "size": "298kb",
          "version": "v1"
        }
      ],
      "title": "Operationalizing Automated Essay Scoring: A Human-Aware Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21603",
        "HTML": "https://arxiv.org/html/2506.21603v1",
        "PDF": "https://arxiv.org/pdf/2506.21603"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This work examines the human-centric operationalization of Automated Essay Scoring systems, highlighting challenges such as bias, robustness, and explainability, unrelated to LLM training data processes."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21604",
      "abstract": "Current evaluation frameworks for multimodal generative AI struggle to establish trustworthiness, hindering enterprise adoption where reliability is paramount. We introduce a systematic, quantitative benchmarking framework to measure the trustworthiness of progressively integrating cross-modal inputs such as text, images, captions, and OCR within VisualRAG systems for enterprise document intelligence. Our approach establishes quantitative relationships between technical metrics and user-centric trust measures. Evaluation reveals that optimal modality weighting with weights of 30% text, 15% image, 25% caption, and 30% OCR improves performance by 57.3% over text-only baselines while maintaining computational efficiency. We provide comparative assessments of foundation models, demonstrating their differential impact on trustworthiness in caption generation and OCR extraction-a vital consideration for reliable enterprise AI. This work advances responsible AI deployment by providing a rigorous framework for quantifying and enhancing trustworthiness in multimodal RAG for critical enterprise applications.",
      "authors": [
        "Varun Mannam",
        "Fang Wang",
        "and Xin Chen"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-19T18:05:00+00:00",
          "link": "https://arxiv.org/abs/2506.21604v1",
          "size": "3820kb",
          "version": "v1"
        }
      ],
      "title": "Evaluating VisualRAG: Quantifying Cross-Modal Performance in Enterprise Document Understanding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21604",
        "HTML": "https://arxiv.org/html/2506.21604v1",
        "PDF": "https://arxiv.org/pdf/2506.21604"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper presents a systematic benchmarking framework for assessing cross-modal performance in multimodal AI systems, particularly VisualRAG. It does not focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21605",
      "abstract": "Recent works have highlighted the significance of memory mechanisms in LLM-based agents, which enable them to store observed information and adapt to dynamic environments. However, evaluating their memory capabilities still remains challenges. Previous evaluations are commonly limited by the diversity of memory levels and interactive scenarios. They also lack comprehensive metrics to reflect the memory capabilities from multiple aspects. To address these problems, in this paper, we construct a more comprehensive dataset and benchmark to evaluate the memory capability of LLM-based agents. Our dataset incorporates factual memory and reflective memory as different levels, and proposes participation and observation as various interactive scenarios. Based on our dataset, we present a benchmark, named MemBench, to evaluate the memory capability of LLM-based agents from multiple aspects, including their effectiveness, efficiency, and capacity. To benefit the research community, we release our dataset and project at https://github.com/import-myself/Membench.",
      "authors": [
        "Haoran Tan",
        "Zeyu Zhang",
        "Chen Ma",
        "Xu Chen",
        "Quanyu Dai",
        "Zhenhua Dong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-20T10:09:23+00:00",
          "link": "https://arxiv.org/abs/2506.21605v1",
          "size": "1377kb",
          "version": "v1"
        }
      ],
      "title": "MemBench: Towards More Comprehensive Evaluation on the Memory of LLM-based Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21605",
        "HTML": "https://arxiv.org/html/2506.21605v1",
        "PDF": "https://arxiv.org/pdf/2506.21605"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "MemBench is presented as a comprehensive benchmark and dataset to evaluate the memory capabilities of LLM-based agents, addressing issues such as effectiveness, efficiency, and capacity, directly related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21606",
      "abstract": "This paper proposes a novel conceptualization of Large Language Models (LLMs) as externalized informational substrates that function analogously to DNA for human cultural dynamics. Rather than viewing LLMs as either autonomous intelligence or mere programmed mimicry, we argue they serve a broader role as repositories that preserve compressed patterns of human symbolic expression--\"fossils\" of meaningful dynamics that retain relational residues without their original living contexts. Crucially, these compressed patterns only become meaningful through human reinterpretation, creating a recursive feedback loop where they can be recombined and cycle back to ultimately catalyze human creative processes. Through analysis of four universal features--compression, decompression, externalization, and recursion--we demonstrate that just as DNA emerged as a compressed and externalized medium for preserving useful cellular dynamics without containing explicit reference to goal-directed physical processes, LLMs preserve useful regularities of human culture without containing understanding of embodied human experience. Therefore, we argue that LLMs' significance lies not in rivaling human intelligence, but in providing humanity a tool for self-reflection and playful hypothesis-generation in a low-stakes, simulated environment. This framework positions LLMs as tools for cultural evolvability, enabling humanity to generate novel hypotheses about itself while maintaining the human interpretation necessary to ground these hypotheses in ongoing human aesthetics and norms.",
      "authors": [
        "Parham Pourdavood",
        "Michael Jacob",
        "Terrence Deacon"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-20T10:37:29+00:00",
          "link": "https://arxiv.org/abs/2506.21606v1",
          "size": "468kb",
          "version": "v1"
        }
      ],
      "title": "Large Language Models as symbolic DNA of cultural dynamics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21606",
        "PDF": "https://arxiv.org/pdf/2506.21606"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper conceptualizes LLMs as cultural tools rather than focusing on the data engineering or training-stage data processing aspects of LLM development. It does not address the technicalities of data collection or processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21607",
      "abstract": "Human smuggling networks are increasingly adaptive and difficult to analyze. Legal case documents offer valuable insights but are unstructured, lexically dense, and filled with ambiguous or shifting references-posing challenges for automated knowledge graph (KG) construction. Existing KG methods often rely on static templates and lack coreference resolution, while recent LLM-based approaches frequently produce noisy, fragmented graphs due to hallucinations, and duplicate nodes caused by a lack of guided extraction. We propose CORE-KG, a modular framework for building interpretable KGs from legal texts. It uses a two-step pipeline: (1) type-aware coreference resolution via sequential, structured LLM prompts, and (2) entity and relationship extraction using domain-guided instructions, built on an adapted GraphRAG framework. CORE-KG reduces node duplication by 33.28%, and legal noise by 38.37% compared to a GraphRAG-based baseline-resulting in cleaner and more coherent graph structures. These improvements make CORE-KG a strong foundation for analyzing complex criminal networks.",
      "authors": [
        "Dipak Meher",
        "Carlotta Domeniconi",
        "Guadalupe Correa-Cabrera"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-20T11:58:00+00:00",
          "link": "https://arxiv.org/abs/2506.21607v1",
          "size": "2053kb",
          "version": "v1"
        }
      ],
      "title": "CORE-KG: An LLM-Driven Knowledge Graph Construction Framework for Human Smuggling Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21607",
        "PDF": "https://arxiv.org/pdf/2506.21607"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses the use of LLMs in building knowledge graphs from legal texts but primarily focuses on the extraction and coreference resolution processes rather than innovative LLM training data processing. It does not propose new methods for LLM training data construction or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21608",
      "abstract": "The automatic generation of SysML v2 models represents a major challenge in the engineering of complex systems, particularly due to the scarcity of learning corpora and complex syntax. We present SysTemp, a system aimed at facilitating and improving the creation of SysML v2 models from natural language specifications. It is based on a multi-agent system, including a template generator that structures the generation process. We discuss the advantages and challenges of this system through an evaluation, highlighting its potential to improve the quality of the generations in SysML v2 modeling.",
      "authors": [
        "Yasmine Bouamra",
        "Bruno Yun",
        "Alexandre Poisson",
        "Fr\\'ed\\'eric Armetta"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-20T13:17:44+00:00",
          "link": "https://arxiv.org/abs/2506.21608v1",
          "size": "1704kb",
          "version": "v1"
        }
      ],
      "title": "SysTemp: A Multi-Agent System for Template-Based Generation of SysML v2",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21608",
        "HTML": "https://arxiv.org/html/2506.21608v1",
        "PDF": "https://arxiv.org/pdf/2506.21608"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper is focused on generating SysML v2 models using a multi-agent system, which is unrelated to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21609",
      "abstract": "Recently, there have been notable advancements in large language models (LLMs), demonstrating their growing abilities in complex reasoning. However, existing research largely overlooks a thorough and systematic comparison of these models' reasoning processes and outputs, particularly regarding their self-reflection pattern (also termed \"Aha moment\") and the interconnections across diverse domains. This paper proposes a novel framework for analyzing the reasoning characteristics of four cutting-edge large reasoning models (GPT-o1, DeepSeek-R1, Kimi-k1.5, and Grok-3) using keywords statistic and LLM-as-a-judge paradigm. Our approach connects their internal thinking processes with their final outputs. A diverse dataset consists of real-world scenario-based questions covering logical deduction, causal inference, and multi-step problem-solving. Additionally, a set of metrics is put forward to assess both the coherence of reasoning and the accuracy of the outputs. The research results uncover various patterns of how these models balance exploration and exploitation, deal with problems, and reach conclusions during the reasoning process. Through quantitative and qualitative comparisons, disparities among these models are identified in aspects such as the depth of reasoning, the reliance on intermediate steps, and the degree of similarity between their thinking processes and output patterns and those of GPT-o1. This work offers valuable insights into the trade-off between computational efficiency and reasoning robustness and provides practical recommendations for enhancing model design and evaluation in practical applications. We publicly release our project at: https://github.com/ChangWenhan/FromThinking2Output",
      "authors": [
        "Junhao Liu",
        "Zhenhao Xu",
        "Yuxin Fang",
        "Yichuan Chen",
        "Zuobin Ying",
        "Wenhan Chang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-20T14:02:16+00:00",
          "link": "https://arxiv.org/abs/2506.21609v1",
          "size": "180kb",
          "version": "v1"
        }
      ],
      "title": "From Thinking to Output: Chain-of-Thought and Text Generation Characteristics in Reasoning Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21609",
        "PDF": "https://arxiv.org/pdf/2506.21609"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper explores the reasoning characteristics and outputs of multiple LLMs but does not address the data processing or engineering aspects for LLM training. It focuses on evaluating reasoning processes rather than making contributions to data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21611",
      "abstract": "Recently, there has been growing interest in incorporating textual information into foundation models for time series forecasting. However, it remains unclear whether and under what conditions such multimodal integration consistently yields gains. We systematically investigate these questions across a diverse benchmark of 14 forecasting tasks spanning 7 domains, including health, environment, and economics. We evaluate two popular multimodal forecasting paradigms: aligning-based methods, which align time series and text representations; and prompting-based methods, which directly prompt large language models for forecasting. Although prior works report gains from multimodal input, we find these effects are not universal across datasets and models, and multimodal methods sometimes do not outperform the strongest unimodal baselines. To understand when textual information helps, we disentangle the effects of model architectural properties and data characteristics. Our findings highlight that on the modeling side, incorporating text information is most helpful given (1) high-capacity text models, (2) comparatively weaker time series models, and (3) appropriate aligning strategies. On the data side, performance gains are more likely when (4) sufficient training data is available and (5) the text offers complementary predictive signal beyond what is already captured from the time series alone. Our empirical findings offer practical guidelines for when multimodality can be expected to aid forecasting tasks, and when it does not.",
      "authors": [
        "Xiyuan Zhang",
        "Boran Han",
        "Haoyang Fang",
        "Abdul Fatir Ansari",
        "Shuai Zhang",
        "Danielle C. Maddix",
        "Cuixiong Hu",
        "Andrew Gordon Wilson",
        "Michael W. Mahoney",
        "Hao Wang",
        "Yan Liu",
        "Huzefa Rangwala",
        "George Karypis",
        "Bernie Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-20T23:55:56+00:00",
          "link": "https://arxiv.org/abs/2506.21611v1",
          "size": "10917kb",
          "version": "v1"
        }
      ],
      "title": "Does Multimodality Lead to Better Time Series Forecasting?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21611",
        "PDF": "https://arxiv.org/pdf/2506.21611"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper investigates multimodal integration in time series forecasting and does not contribute to LLM training data processing or data engineering. It focuses on evaluating the impact of textual and time series data in forecasting rather than LLM data preparation or enhancements."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21612",
      "abstract": "Currently, considerable strides have been achieved in Point-of-Interest (POI) embedding methodologies, driven by the emergence of novel POI tasks like recommendation and classification. Despite the success of task-specific, end-to-end models in POI embedding, several challenges remain. These include the need for more effective multi-context sampling strategies, insufficient exploration of multiple POI contexts, limited versatility, and inadequate generalization. To address these issues, we propose the AdaptGOT model, which integrates both the (Adapt)ive representation learning technique and the Geographical-Co-Occurrence-Text (GOT) representation with a particular emphasis on Geographical location, Co-Occurrence and Textual information. The AdaptGOT model comprises three key components: (1) contextual neighborhood generation, which integrates advanced mixed sampling techniques such as KNN, density-based, importance-based, and category-aware strategies to capture complex contextual neighborhoods; (2) an advanced GOT representation enhanced by an attention mechanism, designed to derive high-quality, customized representations and efficiently capture complex interrelations between POIs; and (3) the MoE-based adaptive encoder-decoder architecture, which ensures topological consistency and enriches contextual representation by minimizing Jensen-Shannon divergence across varying contexts. Experiments on two real-world datasets and multiple POI tasks substantiate the superior performance of the proposed AdaptGOT model.",
      "authors": [
        "Xiaobin Ren",
        "Xinyu Zhu",
        "Kaiqi Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-21T08:06:06+00:00",
          "link": "https://arxiv.org/abs/2506.21612v1",
          "size": "1367kb",
          "version": "v1"
        }
      ],
      "title": "AdaptGOT: A Pre-trained Model for Adaptive Contextual POI Representation Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21612",
        "HTML": "https://arxiv.org/html/2506.21612v1",
        "PDF": "https://arxiv.org/pdf/2506.21612"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on developing a model for adaptive contextual POI representation learning using geographical and co-occurrence data, with no mention of LLM training data processing or data engineering stages."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21613",
      "abstract": "The increasing prevalence of child-targeted hate speech online underscores the urgent need for specialized datasets to address this critical issue. Existing hate speech datasets lack agespecific annotations, fail to capture nuanced contexts, and overlook the unique emotional impact on children. To bridge this gap, we introduce ChildGuard1, a curated dataset derived from existing corpora and enriched with child-specific annotations. ChildGuard captures diverse contexts of child-targeted hate speech, spanning age groups. We benchmark existing state-of-the-art hate speech detection methods, including Large Language Models (LLMs), and assess their effectiveness in detecting and contextualizing child-targeted hate speech. To foster further research in this area, we publicly release ChildGuard, providing a robust foundation for developing improved methods to detect and mitigate such harm.",
      "authors": [
        "Gautam Siddharth Kashyap",
        "Mohammad Anas Azeez",
        "Rafiq Ali",
        "Zohaib Hasan Siddiqui",
        "Jiechao Gao",
        "and Usman Naseem"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-21T10:53:17+00:00",
          "link": "https://arxiv.org/abs/2506.21613v1",
          "size": "515kb",
          "version": "v1"
        }
      ],
      "title": "ChildGuard: A Specialized Dataset for Combatting Child-Targeted Hate Speech",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21613",
        "HTML": "https://arxiv.org/html/2506.21613v1",
        "PDF": "https://arxiv.org/pdf/2506.21613"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a specialized dataset for child-targeted hate speech and evaluates the performance of LLMs on this dataset. It discusses data annotation but does not contribute novel methods for LLM data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21614",
      "abstract": "The increasing complexity of large language models (LLMs) raises concerns about their ability to \"cheat\" on standard Question Answering (QA) benchmarks by memorizing task-specific data. This undermines the validity of benchmark evaluations, as they no longer reflect genuine model capabilities but instead the effects of data leakage. While prior work has focused on detecting such leakage, little attention has been given to mitigating its impact and preserving the long-term utility of benchmarks. In this paper, we introduce LastingBench, a novel framework designed to continuously reinforce and safeguard existing benchmarks against knowledge leakage. LastingBench identifies leakage points in the context through perturbation, then rewrites the leakage points to counterfactual ones-disrupting memorization while preserving the benchmark's original evaluative intent. Evaluations of state-of-the-art QA benchmarks show significant performance gaps, highlighting the efficacy of LastingBench in reducing memorization effects. LastingBench offers a practical and scalable solution to ensure benchmark robustness over time, promoting fairer and more interpretable evaluations of LLMs.",
      "authors": [
        "Yixiong Fang",
        "Tianran Sun",
        "Yuling Shi",
        "Min Wang",
        "Xiaodong Gu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-21T13:01:04+00:00",
          "link": "https://arxiv.org/abs/2506.21614v1",
          "size": "3418kb",
          "version": "v1"
        }
      ],
      "title": "LastingBench: Defend Benchmarks Against Knowledge Leakage",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21614",
        "HTML": "https://arxiv.org/html/2506.21614v1",
        "PDF": "https://arxiv.org/pdf/2506.21614"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper addresses knowledge leakage in benchmark evaluations, focusing on mitigating memorization effects in LLMs rather than on LLM training data processing or data engineering stages."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21615",
      "abstract": "Current medical language models, adapted from large language models (LLMs), typically predict ICD code-based diagnosis from electronic health records (EHRs) because these labels are readily available. However, ICD codes do not capture the nuanced, context-rich reasoning clinicians use for diagnosis. Clinicians synthesize diverse patient data and reference clinical practice guidelines (CPGs) to make evidence-based decisions. This misalignment limits the clinical utility of existing models. We introduce GARMLE-G, a Generation-Augmented Retrieval framework that grounds medical language model outputs in authoritative CPGs. Unlike conventional Retrieval-Augmented Generation based approaches, GARMLE-G enables hallucination-free outputs by directly retrieving authoritative guideline content without relying on model-generated text. It (1) integrates LLM predictions with EHR data to create semantically rich queries, (2) retrieves relevant CPG knowledge snippets via embedding similarity, and (3) fuses guideline content with model output to generate clinically aligned recommendations. A prototype system for hypertension diagnosis was developed and evaluated on multiple metrics, demonstrating superior retrieval precision, semantic relevance, and clinical guideline adherence compared to RAG-based baselines, while maintaining a lightweight architecture suitable for localized healthcare deployment. This work provides a scalable, low-cost, and hallucination-free method for grounding medical language models in evidence-based clinical practice, with strong potential for broader clinical deployment.",
      "authors": [
        "Wenhao Li",
        "Hongkuan Zhang",
        "Hongwei Zhang",
        "Zhengxu Li",
        "Zengjie Dong",
        "Yafan Chen",
        "Niranjan Bidargaddi",
        "Hong Liu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-22T11:31:13+00:00",
          "link": "https://arxiv.org/abs/2506.21615v1",
          "size": "1418kb",
          "version": "v1"
        }
      ],
      "title": "Refine Medical Diagnosis Using Generation Augmented Retrieval and Clinical Practice Guidelines",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21615",
        "PDF": "https://arxiv.org/pdf/2506.21615"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper introduces a model for medical diagnosis using generation-augmented retrieval, focusing on integrating clinical guidelines rather than addressing LLM training data processing tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21616",
      "abstract": "Open-domain Timeline Summarization (TLS) is crucial for monitoring the evolution of news topics. To identify changes in news topics, existing methods typically employ general Large Language Models (LLMs) to summarize relevant timestamps from retrieved news. While general LLMs demonstrate capabilities in zero-shot news summarization and timestamp localization, they struggle with assessing topic relevance and understanding topic evolution. Consequently, the summarized information often includes irrelevant details or inaccurate timestamps. To address these issues, we propose the first large Timeline Intelligence Model (TIM) for open-domain TLS, which is capable of effectively summarizing open-domain timelines. Specifically, we begin by presenting a large-scale TLS dataset, comprising over 1,000 news topics and more than 3,000 annotated TLS instances. Furthermore, we propose a progressive optimization strategy, which gradually enhance summarization performance. It employs instruction tuning to enhance summarization and topic-irrelevant information filtering capabilities. Following this, it exploits a novel dual-alignment reward learning method that incorporates both semantic and temporal perspectives, thereby improving the understanding of topic evolution principles. Through this progressive optimization strategy, TIM demonstrates a robust ability to summarize open-domain timelines. Extensive experiments in open-domain demonstrate the effectiveness of our TIM.",
      "authors": [
        "Chuanrui Hu",
        "Wei Hu",
        "Penghang Yu",
        "Hua Zhang",
        "Bing-Kun Bao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-22T14:42:07+00:00",
          "link": "https://arxiv.org/abs/2506.21616v1",
          "size": "4930kb",
          "version": "v1"
        }
      ],
      "title": "TIM: A Large-Scale Dataset and large Timeline Intelligence Model for Open-domain Timeline Summarization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21616",
        "PDF": "https://arxiv.org/pdf/2506.21616"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes a large dataset for timeline summarization and discusses the use of instruction tuning and dual-alignment reward learning, but the primary focus is not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21617",
      "abstract": "The challenge of balancing user relevance and content diversity in recommender systems is increasingly critical amid growing concerns about content homogeneity and reduced user engagement. In this work, we propose a novel framework that leverages a multi-objective, contextual sequential sampling strategy. Item selection is guided by Bayesian updates that dynamically adjust scores to optimize diversity. The reward formulation integrates multiple diversity metrics-including the log-determinant volume of a tuned similarity submatrix and ridge leverage scores-along with a diversity gain uncertainty term to address the exploration-exploitation trade-off. Both intra- and inter-batch diversity are modeled to promote serendipity and minimize redundancy. A dominance-based ranking procedure identifies Pareto-optimal item sets, enabling adaptive and balanced selections at each iteration. Experiments on a real-world dataset show that our approach significantly improves diversity without sacrificing relevance, demonstrating its potential to enhance user experience in large-scale recommendation settings.",
      "authors": [
        "Hiba Bederina",
        "Jill-J\\^enn Vie"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-22T19:36:02+00:00",
          "link": "https://arxiv.org/abs/2506.21617v1",
          "size": "2366kb",
          "version": "v1"
        }
      ],
      "title": "Bayesian-Guided Diversity in Sequential Sampling for Recommender Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21617",
        "HTML": "https://arxiv.org/html/2506.21617v1",
        "PDF": "https://arxiv.org/pdf/2506.21617"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on enhancing diversity in recommender systems, which is unrelated to the processing or engineering of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21618",
      "abstract": "In this technical report, we introduce TrajTok, a trajectory tokenizer for discrete next-token-prediction based behavior generation models, which combines data-driven and rule-based methods with better coverage, symmetry and robustness, along with a spatial-aware label smoothing method for cross-entropy loss. We adopt the tokenizer and loss for the SMART model and reach a superior performance with realism score of 0.7852 on the Waymo Open Sim Agents Challenge 2025. We will open-source the code in the future.",
      "authors": [
        "Zhiyuan Zhang",
        "Xiaosong Jia",
        "Guanyu Chen",
        "Qifeng Li",
        "Junchi Yan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T08:32:05+00:00",
          "link": "https://arxiv.org/abs/2506.21618v1",
          "size": "219kb",
          "version": "v1"
        }
      ],
      "title": "TrajTok: Technical Report for 2025 Waymo Open Sim Agents Challenge",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21618",
        "HTML": "https://arxiv.org/html/2506.21618v1",
        "PDF": "https://arxiv.org/pdf/2506.21618"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This technical report introduces a trajectory tokenizer for behavior generation models, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21619",
      "abstract": "Large-scale text-to-speech (TTS) models are typically categorized into autoregressive and non-autoregressive systems. Although autoregressive systems exhibit certain advantages in speech naturalness, their token-by-token generation mechanism makes it difficult to precisely control the duration of synthesized speech. This is a key limitation in applications such as video dubbing that require strict audio-visual synchronization. This paper introduces IndexTTS2, which proposes a novel and autoregressive-model-friendly method for speech duration control. The method supports two generation modes: one allows explicit specification of the number of generated tokens for precise duration control; the other does not require manual input and lets the model freely generate speech while preserving prosodic characteristics from the input prompt. Furthermore, IndexTTS2 achieves disentanglement between emotional expression and speaker identity, enabling independent control of timbre and emotion. In the zero-shot setting, the model can perfectly reproduce the emotional characteristics of the input prompt. Users may also provide a separate emotion prompt, even from a different speaker, allowing the model to reconstruct the target timbre while conveying the desired emotion. To enhance clarity during strong emotional expressions, we incorporate GPT latent representations to improve speech stability. Meanwhile, to lower the barrier for emotion control, we design a soft instruction mechanism based on textual descriptions by fine-tuning Qwen3. This enables effective guidance of speech generation with desired emotional tendencies using natural language input. Experimental results demonstrate that IndexTTS2 outperforms existing state-of-the-art zero-shot TTS models in word error rate, speaker similarity, and emotional fidelity.",
      "authors": [
        "Siyi Zhou",
        "Yiquan Zhou",
        "Yi He",
        "Xun Zhou",
        "Jinchao Wang",
        "Wei Deng",
        "Jingchen Shu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T08:33:40+00:00",
          "link": "https://arxiv.org/abs/2506.21619v1",
          "size": "5496kb",
          "version": "v1"
        }
      ],
      "title": "IndexTTS2: A Breakthrough in Emotionally Expressive and Duration-Controlled Auto-Regressive Zero-Shot Text-to-Speech",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21619",
        "HTML": "https://arxiv.org/html/2506.21619v1",
        "PDF": "https://arxiv.org/pdf/2506.21619"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper discusses advancements in text-to-speech technology, focusing on emotionally expressive and duration-controlled synthesis, not LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21620",
      "abstract": "Large Language Models (LLMs) have recently emerged as powerful tools for natural language generation, with applications spanning from content creation to social simulations. Their ability to mimic human interactions raises both opportunities and concerns, particularly in the context of politically relevant online discussions. In this study, we evaluate the performance of LLMs in replicating user-generated content within a real-world, divisive scenario: Reddit conversations during the 2016 US Presidential election. In particular, we conduct three different experiments, asking GPT-4 to generate comments by impersonating either real or artificial partisan users. We analyze the generated comments in terms of political alignment, sentiment, and linguistic features, comparing them against real user contributions and benchmarking against a null model. We find that GPT-4 is able to produce realistic comments, both in favor of or against the candidate supported by the community, yet tending to create consensus more easily than dissent. In addition we show that real and artificial comments are well separated in a semantically embedded space, although they are indistinguishable by manual inspection. Our findings provide insights on the potential use of LLMs to sneak into online discussions, influence political debate and shape political narratives, bearing broader implications of AI-driven discourse manipulation.",
      "authors": [
        "Daniele Cirulli",
        "Giulio Cimini",
        "Giovanni Palermo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)",
        "Social and Information Networks (cs.SI)",
        "Physics and Society (physics.soc-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T08:54:32+00:00",
          "link": "https://arxiv.org/abs/2506.21620v1",
          "size": "1749kb",
          "version": "v1"
        }
      ],
      "title": "How Large Language Models play humans in online conversations: a simulated study of the 2016 US politics on Reddit",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21620",
        "HTML": "https://arxiv.org/html/2506.21620v1",
        "PDF": "https://arxiv.org/pdf/2506.21620"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The study evaluates LLMs' ability to generate politically aligned content during simulated online conversations, without addressing training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21621",
      "abstract": "In recent months, large language models (LLMs) have made significant progress in mathematical proof generation, but further advancement is hindered by the lack of a large-scale, high-quality dataset of human-evaluated proofs. While expensive to create, such a dataset is essential for driving improvements in training and enabling a rigorous analysis of proof generation capabilities. In this work, we present the Open Proof Corpus (OPC), a dataset comprising over 5,000 human-evaluated proofs produced by state-of-the-art LLMs. The OPC was specifically designed for broad applicability and downstream usage in proof generation research and is the first to include a substantial number of correct, LLM-generated solutions to problems from prestigious mathematics competitions such as the USAMO and IMO. Using the OPC, we explore critical questions in automated proof generation: (1) the performance gap between natural language and formal proof generation, (2) the discrepancy between final-answer accuracy and full-proof validity, and (3) the impact of best-of-n selection on proof quality. Finally, to showcase the utility of the OPC, we finetune an 8B-parameter model on the dataset, obtaining a model that performs on par with the best model, Gemini-2.5-Pro, on the task of evaluating proof correctness.",
      "authors": [
        "Jasper Dekoninck",
        "Ivo Petrov",
        "Kristian Minchev",
        "Mislav Balunovic",
        "Martin Vechev",
        "Miroslav Marinov",
        "Maria Drencheva",
        "Lyuba Konova",
        "Milen Shumanov",
        "Kaloyan Tsvetkov",
        "Nikolay Drenchev",
        "Lazar Todorov",
        "Kalina Nikolova",
        "Nikolay Georgiev",
        "Vanesa Kalinkova",
        "Margulan Ismoldayev"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T13:31:58+00:00",
          "link": "https://arxiv.org/abs/2506.21621v1",
          "size": "930kb",
          "version": "v1"
        }
      ],
      "title": "The Open Proof Corpus: A Large-Scale Study of LLM-Generated Mathematical Proofs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21621",
        "PDF": "https://arxiv.org/pdf/2506.21621"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces the Open Proof Corpus, a dataset of LLM-generated mathematical proofs that enhances training and evaluation in proof generation, directly involving LLM data construction."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21622",
      "abstract": "Speech impairments caused by conditions such as cerebral palsy or genetic disorders pose significant challenges for automatic speech recognition (ASR) systems. Despite recent advances, ASR models like Whisper struggle with non-normative speech due to limited training data and the difficulty of collecting and annotating non-normative speech samples. In this work, we propose a practical and lightweight pipeline to personalize ASR models, formalizing the selection of words and enriching a small, speech-impaired dataset with semantic coherence. Applied to data from a child with a structural speech impairment, our approach shows promising improvements in transcription quality, demonstrating the potential to reduce communication barriers for individuals with atypical speech patterns.",
      "authors": [
        "Niclas Pokel",
        "Pehu\\'en Moure",
        "Roman Boehringer",
        "Yingqiang Gao"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T15:30:50+00:00",
          "link": "https://arxiv.org/abs/2506.21622v1",
          "size": "262kb",
          "version": "v1"
        }
      ],
      "title": "Adapting Foundation Speech Recognition Models to Impaired Speech: A Semantic Re-chaining Approach for Personalization of German Speech",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21622",
        "HTML": "https://arxiv.org/html/2506.21622v1",
        "PDF": "https://arxiv.org/pdf/2506.21622"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses a pipeline to personalize ASR models for non-normative speech, which involves enriching a small dataset, but the contribution focuses on improving transcription quality rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21623",
      "abstract": "Machine learning (ML) has significantly advanced text classification by enabling automated understanding and categorization of complex, unstructured textual data. However, accurately capturing nuanced linguistic patterns and contextual variations inherent in natural language, particularly within consumer complaints, remains a challenge. This study addresses these issues by incorporating human-experience-trained algorithms that effectively recognize subtle semantic differences crucial for assessing consumer relief eligibility. Furthermore, we propose integrating synthetic data generation methods that utilize expert evaluations of generative adversarial networks and are refined through expert annotations. By combining expert-trained classifiers with high-quality synthetic data, our research seeks to significantly enhance machine learning classifier performance, reduce dataset acquisition costs, and improve overall evaluation metrics and robustness in text classification tasks.",
      "authors": [
        "Peiheng Gao",
        "Chen Yang",
        "Ning Sun",
        "Ri\\v{c}ardas Zitikis"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T17:26:38+00:00",
          "link": "https://arxiv.org/abs/2506.21623v1",
          "size": "129kb",
          "version": "v1"
        }
      ],
      "title": "Performance of diverse evaluation metrics in NLP-based assessment and text generation of consumer complaints",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21623",
        "HTML": "https://arxiv.org/html/2506.21623v1",
        "PDF": "https://arxiv.org/pdf/2506.21623"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper briefly mentions synthetic data generation refined through expert annotations, but it mainly focuses on improving ML classifier performance and evaluation metrics in text classification, not directly on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21624",
      "abstract": "The Deep and Cross architecture (DCNv2) is a robust production baseline and is integral to numerous real-life recommender systems. Its inherent efficiency and ability to model interactions often result in models that are both simpler and highly competitive compared to more computationally demanding alternatives, such as Deep FFMs. In this work, we introduce three significant algorithmic improvements to the DCNv2 architecture, detailing their formulation and behavior at scale. The enhanced architecture we refer to as DCN^2 is actively used in a live recommender system, processing over 0.5 billion predictions per second across diverse use cases where it out-performed DCNv2, both offline and online (ab tests). These improvements effectively address key limitations observed in the DCNv2, including information loss in Cross layers, implicit management of collisions through learnable lookup-level weights, and explicit modeling of pairwise similarities with a custom layer that emulates FFMs' behavior. The superior performance of DCN^2 is also demonstrated on four publicly available benchmark data sets.",
      "authors": [
        "Bla\\v{z} \\v{S}krlj",
        "Yonatan Karni",
        "Grega Ga\\v{s}per\\v{s}i\\v{c}",
        "Bla\\v{z} Mramor",
        "Yulia Stolin",
        "Martin Jakomin",
        "Jasna Urban\\v{c}i\\v{c}",
        "Yuval Dishi",
        "Natalia Silberstein",
        "Ophir Friedler",
        "Assaf Klein"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-24T06:44:42+00:00",
          "link": "https://arxiv.org/abs/2506.21624v1",
          "size": "1531kb",
          "version": "v1"
        }
      ],
      "title": "DCN^2: Interplay of Implicit Collision Weights and Explicit Cross Layers for Large-Scale Recommendation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21624",
        "HTML": "https://arxiv.org/html/2506.21624v1",
        "PDF": "https://arxiv.org/pdf/2506.21624"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper centers around algorithmic improvements for the DCNv2 architecture in recommendation systems, without addressing LLM training data processing tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21625",
      "abstract": "Extracting molecular structure-activity relationships (SARs) from scientific literature and patents is essential for drug discovery and materials research. However, this task remains challenging due to heterogeneous document formats and limitations of existing methods. Specifically, rule-based approaches relying on rigid templates fail to generalize across diverse document layouts, while general-purpose multimodal large language models (MLLMs) lack sufficient accuracy and reliability for specialized tasks, such as layout detection and optical chemical structure recognition (OCSR). To address these challenges, we introduce DocSAR-200, a rigorously annotated benchmark of 200 scientific documents designed specifically for evaluating SAR extraction methods. Additionally, we propose Doc2SAR, a novel synergistic framework that integrates domain-specific tools with MLLMs enhanced via supervised fine-tuning (SFT). Extensive experiments demonstrate that Doc2SAR achieves state-of-the-art performance across various document types, significantly outperforming leading end-to-end baselines. Specifically, Doc2SAR attains an overall Table Recall of 80.78% on DocSAR-200, exceeding end2end GPT-4o by 51.48%. Furthermore, Doc2SAR demonstrates practical usability through efficient inference and is accompanied by a web app.",
      "authors": [
        "Jiaxi Zhuang",
        "Kangning Li",
        "Jue Hou",
        "Mingjun Xu",
        "Zhifeng Gao and Hengxing Cai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-24T06:53:04+00:00",
          "link": "https://arxiv.org/abs/2506.21625v1",
          "size": "16245kb",
          "version": "v1"
        }
      ],
      "title": "Doc2SAR: A Synergistic Framework for High-Fidelity Extraction of Structure-Activity Relationships from Scientific Documents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21625",
        "HTML": "https://arxiv.org/html/2506.21625v1",
        "PDF": "https://arxiv.org/pdf/2506.21625"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces DocSAR-200, a benchmark for SAR extraction, and proposes Doc2SAR, which integrates domain-specific tools with MLLMs enhanced by supervised fine-tuning, relevant to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21627",
      "abstract": "Developing a general robot manipulation system capable of performing a wide range of tasks in complex, dynamic, and unstructured real-world environments has long been a challenging task. It is widely recognized that achieving human-like efficiency and robustness manipulation requires the robotic brain to integrate a comprehensive set of functions, such as task planning, policy generation, anomaly monitoring and handling, and long-term memory, achieving high-efficiency operation across all functions. Vision-Language Models (VLMs), pretrained on massive multimodal data, have acquired rich world knowledge, exhibiting exceptional scene understanding and multimodal reasoning capabilities. However, existing methods typically focus on realizing only a single function or a subset of functions within the robotic brain, without integrating them into a unified cognitive architecture. Inspired by a divide-and-conquer strategy and the architecture of the human brain, we propose FrankenBot, a VLM-driven, brain-morphic robotic manipulation framework that achieves both comprehensive functionality and high operational efficiency. Our framework includes a suite of components, decoupling a part of key functions from frequent VLM calls, striking an optimal balance between functional completeness and system efficiency. Specifically, we map task planning, policy generation, memory management, and low-level interfacing to the cortex, cerebellum, temporal lobe-hippocampus complex, and brainstem, respectively, and design efficient coordination mechanisms for the modules. We conducted comprehensive experiments in both simulation and real-world robotic environments, demonstrating that our method offers significant advantages in anomaly detection and handling, long-term memory, operational efficiency, and stability -- all without requiring any fine-tuning or retraining.",
      "authors": [
        "Shiyi Wang",
        "Wenbo Li",
        "Yiteng Chen",
        "Qingyao Wu",
        "Huiping Zhuang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-24T14:11:22+00:00",
          "link": "https://arxiv.org/abs/2506.21627v1",
          "size": "5425kb",
          "version": "v1"
        }
      ],
      "title": "FrankenBot: Brain-Morphic Modular Orchestration for Robotic Manipulation with Vision-Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21627",
        "HTML": "https://arxiv.org/html/2506.21627v1",
        "PDF": "https://arxiv.org/pdf/2506.21627"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The focus of the paper is on a robotic manipulation framework using VLMs and does not involve LLM training data collection or processing methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21628",
      "abstract": "Robotics has made remarkable hardware strides-from DARPA's Urban and Robotics Challenges to the first humanoid-robot kickboxing tournament-yet commercial autonomy still lags behind progress in machine learning. A major bottleneck is software: current robot stacks demand steep learning curves, low-level C/C++ expertise, fragmented tooling, and intricate hardware integration, in stark contrast to the Python-centric, well-documented ecosystems that propelled modern AI. We introduce ARK, an open-source, Python-first robotics framework designed to close that gap. ARK presents a Gym-style environment interface that allows users to collect data, preprocess it, and train policies using state-of-the-art imitation-learning algorithms (e.g., ACT, Diffusion Policy) while seamlessly toggling between high-fidelity simulation and physical robots. A lightweight client-server architecture provides networked publisher-subscriber communication, and optional C/C++ bindings ensure real-time performance when needed. ARK ships with reusable modules for control, SLAM, motion planning, system identification, and visualization, along with native ROS interoperability. Comprehensive documentation and case studies-from manipulation to mobile navigation-demonstrate rapid prototyping, effortless hardware swapping, and end-to-end pipelines that rival the convenience of mainstream machine-learning workflows. By unifying robotics and AI practices under a common Python umbrella, ARK lowers entry barriers and accelerates research and commercial deployment of autonomous robots.",
      "authors": [
        "Magnus Dierking",
        "Christopher E. Mower",
        "Sarthak Das",
        "Huang Helong",
        "Jiacheng Qiu",
        "Cody Reading",
        "Wei Chen",
        "Huidong Liang",
        "Huang Guowei",
        "Jan Peters",
        "Quan Xingyue",
        "Jun Wang",
        "Haitham Bou-Ammar"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-24T20:23:39+00:00",
          "link": "https://arxiv.org/abs/2506.21628v1",
          "size": "24617kb",
          "version": "v1"
        }
      ],
      "title": "Ark: An Open-source Python-based Framework for Robot Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21628",
        "HTML": "https://arxiv.org/html/2506.21628v1",
        "PDF": "https://arxiv.org/pdf/2506.21628"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on an open-source framework for robot learning, specifically targeting robotics software challenges and not large language model training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21629",
      "abstract": "In recent years, neural rendering methods such as NeRFs and 3D Gaussian Splatting (3DGS) have made significant progress in scene reconstruction and novel view synthesis. However, they heavily rely on preprocessed camera poses and 3D structural priors from structure-from-motion (SfM), which are challenging to obtain in outdoor scenarios. To address this challenge, we propose to incorporate Iterative Closest Point (ICP) with optimization-based refinement to achieve accurate camera pose estimation under large camera movements. Additionally, we introduce a voxel-based scene densification approach to guide the reconstruction in large-scale scenes. Experiments demonstrate that our approach ICP-3DGS outperforms existing methods in both camera pose estimation and novel view synthesis across indoor and outdoor scenes of various scales. Source code is available at https://github.com/Chenhao-Z/ICP-3DGS.",
      "authors": [
        "Chenhao Zhang",
        "Yezhi Shen",
        "Fengqing Zhu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-24T21:10:06+00:00",
          "link": "https://arxiv.org/abs/2506.21629v1",
          "size": "8274kb",
          "version": "v1"
        }
      ],
      "title": "ICP-3DGS: SfM-free 3D Gaussian Splatting for Large-scale Unbounded Scenes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21629",
        "HTML": "https://arxiv.org/html/2506.21629v1",
        "PDF": "https://arxiv.org/pdf/2506.21629"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper deals with 3D Gaussian Splatting for scene reconstruction, which is unrelated to the processing or construction of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21630",
      "abstract": "Detecting traversable pathways in unstructured outdoor environments remains a significant challenge for autonomous robots, especially in critical applications such as wide-area search and rescue, as well as incident management scenarios like forest fires. Existing datasets and models primarily target urban settings or wide, vehicle-traversable off-road tracks, leaving a substantial gap in addressing the complexity of narrow, trail-like off-road scenarios. To address this, we introduce the Trail-based Off-road Multimodal Dataset (TOMD), a comprehensive dataset specifically designed for such environments. TOMD features high-fidelity multimodal sensor data -- including 128-channel LiDAR, stereo imagery, GNSS, IMU, and illumination measurements -- collected through repeated traversals under diverse conditions. We also propose a dynamic multiscale data fusion model for accurate traversable pathway prediction. The study analyzes the performance of early, cross, and mixed fusion strategies under varying illumination levels. Results demonstrate the effectiveness of our approach and the relevance of illumination in segmentation performance. We publicly release TOMD at https://github.com/yyyxs1125/TMOD to support future research in trail-based off-road navigation.",
      "authors": [
        "Yixin Sun",
        "Li Li",
        "Wenke E",
        "Amir Atapour-Abarghouei",
        "Toby P. Breckon"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-24T23:58:44+00:00",
          "link": "https://arxiv.org/abs/2506.21630v1",
          "size": "8433kb",
          "version": "v1"
        }
      ],
      "title": "TOMD: A Trail-based Off-road Multimodal Dataset for Traversable Pathway Segmentation under Challenging Illumination Conditions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21630",
        "HTML": "https://arxiv.org/html/2506.21630v1",
        "PDF": "https://arxiv.org/pdf/2506.21630"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper introduces a multimodal dataset for off-road navigation, targeting robotics applications rather than LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21631",
      "abstract": "Accurate three-dimensional (3D) reconstruction of guidewire shapes is crucial for precise navigation in robot-assisted endovascular interventions. Conventional 2D Digital Subtraction Angiography (DSA) is limited by the absence of depth information, leading to spatial ambiguities that hinder reliable guidewire shape sensing. This paper introduces a novel multimodal framework for real-time 3D guidewire reconstruction, combining preoperative 3D Computed Tomography Angiography (CTA) with intraoperative 2D DSA images. The method utilizes robust feature extraction to address noise and distortion in 2D DSA data, followed by deformable image registration to align the 2D projections with the 3D CTA model. Subsequently, the inverse projection algorithm reconstructs the 3D guidewire shape, providing real-time, accurate spatial information. This framework significantly enhances spatial awareness for robotic-assisted endovascular procedures, effectively bridging the gap between preoperative planning and intraoperative execution. The system demonstrates notable improvements in real-time processing speed, reconstruction accuracy, and computational efficiency. The proposed method achieves a projection error of 1.76$\\pm$0.08 pixels and a length deviation of 2.93$\\pm$0.15\\%, with a frame rate of 39.3$\\pm$1.5 frames per second (FPS). These advancements have the potential to optimize robotic performance and increase the precision of complex endovascular interventions, ultimately contributing to better clinical outcomes.",
      "authors": [
        "Tianliang Yao",
        "Bingrui Li",
        "Bo Lu",
        "Zhiqiang Pei",
        "Yixuan Yuan",
        "Peng Qi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T02:19:00+00:00",
          "link": "https://arxiv.org/abs/2506.21631v1",
          "size": "3853kb",
          "version": "v1"
        }
      ],
      "title": "Real-Time 3D Guidewire Reconstruction from Intraoperative DSA Images for Robot-Assisted Endovascular Interventions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21631",
        "HTML": "https://arxiv.org/html/2506.21631v1",
        "PDF": "https://arxiv.org/pdf/2506.21631"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The research focuses on 3D guidewire reconstruction for medical procedures using imaging techniques, not related to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21632",
      "abstract": "Reconstructing an interactive human avatar and the background from a monocular video of a dynamic human scene is highly challenging. In this work we adopt a strategy of point cloud decoupling and joint optimization to achieve the decoupled reconstruction of backgrounds and human bodies while preserving the interactivity of human motion. We introduce a position texture to subdivide the Skinned Multi-Person Linear (SMPL) body model's surface and grow the human point cloud. To capture fine details of human dynamics and deformations, we incorporate a convolutional neural network structure to predict human body point cloud features based on texture. This strategy makes our approach free of hyperparameter tuning for densification and efficiently represents human points with half the point cloud of HUGS. This approach ensures high-quality human reconstruction and reduces GPU resource consumption during training. As a result, our method surpasses the previous state-of-the-art HUGS in reconstruction metrics while maintaining the ability to generalize to novel poses and views. Furthermore, our technique achieves real-time rendering at over 100 FPS, $\\sim$6$\\times$ the HUGS speed using only Linear Blend Skinning (LBS) weights for human transformation. Additionally, this work demonstrates that this framework can be extended to animal scene reconstruction when an accurately-posed model of an animal is available.",
      "authors": [
        "Da Li",
        "Donggang Jia",
        "Markus Hadwiger",
        "Ivan Viola"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T05:06:44+00:00",
          "link": "https://arxiv.org/abs/2506.21632v1",
          "size": "41544kb",
          "version": "v1"
        }
      ],
      "title": "SkinningGS: Editable Dynamic Human Scene Reconstruction Using Gaussian Splatting Based on a Skinning Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21632",
        "HTML": "https://arxiv.org/html/2506.21632v1",
        "PDF": "https://arxiv.org/pdf/2506.21632"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper addresses human scene reconstruction using Gaussian Splatting, which is not connected to the data engineering or processing stages of LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21633",
      "abstract": "Three-dimensional target reconstruction from synthetic aperture radar (SAR) imagery is crucial for interpreting complex scattering information in SAR data. However, the intricate electromagnetic scattering mechanisms inherent to SAR imaging pose significant reconstruction challenges. Inspired by the remarkable success of 3D Gaussian Splatting (3D-GS) in optical domain reconstruction, this paper presents a novel SAR Differentiable Gaussian Splatting Rasterizer (SDGR) specifically designed for SAR target reconstruction. Our approach combines Gaussian splatting with the Mapping and Projection Algorithm to compute scattering intensities of Gaussian primitives and generate simulated SAR images through SDGR. Subsequently, the loss function between the rendered image and the ground truth image is computed to optimize the Gaussian primitive parameters representing the scene, while a custom CUDA gradient flow is employed to replace automatic differentiation for accelerated gradient computation. Through experiments involving the rendering of simplified architectural targets and SAR images of multiple vehicle targets, we validate the imaging rationality of SDGR on simulated SAR imagery. Furthermore, the effectiveness of our method for target reconstruction is demonstrated on both simulated and real-world datasets containing multiple vehicle targets, with quantitative evaluations conducted to assess its reconstruction performance. Experimental results indicate that our approach can effectively reconstruct the geometric structures and scattering properties of targets, thereby providing a novel solution for 3D reconstruction in the field of SAR imaging.",
      "authors": [
        "Aobo Li",
        "Zhengxin Lei",
        "Jiangtao Wei",
        "Feng Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T07:27:09+00:00",
          "link": "https://arxiv.org/abs/2506.21633v1",
          "size": "12938kb",
          "version": "v1"
        }
      ],
      "title": "SAR-GS: 3D Gaussian Splatting for Synthetic Aperture Radar Target Reconstruction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21633",
        "HTML": "https://arxiv.org/html/2506.21633v1",
        "PDF": "https://arxiv.org/pdf/2506.21633"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on synthetic aperture radar (SAR) target reconstruction using Gaussian Splatting. It does not involve LLM training data processing or enhancement."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21634",
      "abstract": "Background: Abstracts are a particularly valuable element in a software engineering research article. However, not all abstracts are as informative as they could be. Objective: Characterize the structure of abstracts in high-quality software engineering venues. Observe and quantify deficiencies. Suggest guidelines for writing informative abstracts. Methods: Use qualitative open coding to derive concepts that explain relevant properties of abstracts. Identify the archetypical structure of abstracts. Use quantitative content analysis to objectively characterize abstract structure of a sample of 362 abstracts from five presumably high-quality venues. Use exploratory data analysis to find recurring issues in abstracts. Compare the archetypical structure to actual structures. Infer guidelines for producing informative abstracts. Results: Only 29% of the sampled abstracts are complete, i.e., provide background, objective, method, result, and conclusion information. For structured abstracts, the ratio is twice as big. Only 4% of the abstracts are proper, i.e., they also have good readability (Flesch-Kincaid score) and have no informativeness gaps, understandability gaps, nor highly ambiguous sentences. Conclusions: (1) Even in top venues, a large majority of abstracts are far from ideal. (2) Structured abstracts tend to be better than unstructured ones. (3) Artifact-centric works need a different structured format. (4) The community should start requiring conclusions that generalize, which currently are often missing in abstracts.",
      "authors": [
        "Lutz Prechelt and Lloyd Montgomery and Julian Frattini and Franz Zieris"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T11:42:26+00:00",
          "link": "https://arxiv.org/abs/2506.21634v1",
          "size": "1237kb",
          "version": "v1"
        }
      ],
      "title": "How (Not) To Write a Software Engineering Abstract",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21634",
        "HTML": "https://arxiv.org/html/2506.21634v1",
        "PDF": "https://arxiv.org/pdf/2506.21634"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper analyzes the structure and quality of software engineering abstracts and provides guidelines. It does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21635",
      "abstract": "Unmanned aerial vehicles (UAVs) are increasingly employed in diverse applications such as land surveying, material transport, and environmental monitoring. Following missions like data collection or inspection, UAVs must land safely at docking stations for storage or recharging, which is an essential requirement for ensuring operational continuity. However, accurate landing remains challenging due to factors like GPS signal interference. To address this issue, we propose a deviation warning system for UAV landings, powered by a novel vision-based model called AeroLite-MDNet. This model integrates a multiscale fusion module for robust cross-scale object detection and incorporates a segmentation branch for efficient orientation estimation. We introduce a new evaluation metric, Average Warning Delay (AWD), to quantify the system's sensitivity to landing deviations. Furthermore, we contribute a new dataset, UAVLandData, which captures real-world landing deviation scenarios to support training and evaluation. Experimental results show that our system achieves an AWD of 0.7 seconds with a deviation detection accuracy of 98.6\\%, demonstrating its effectiveness in enhancing UAV landing reliability. Code will be available at https://github.com/ITTTTTI/Maskyolo.git",
      "authors": [
        "Haiping Yang",
        "Huaxing Liu",
        "Wei Wu",
        "Zuohui Chen",
        "and Ning Wu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T13:48:30+00:00",
          "link": "https://arxiv.org/abs/2506.21635v1",
          "size": "10796kb",
          "version": "v1"
        }
      ],
      "title": "AeroLite-MDNet: Lightweight Multi-task Deviation Detection Network for UAV Landing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21635",
        "HTML": "https://arxiv.org/html/2506.21635v1",
        "PDF": "https://arxiv.org/pdf/2506.21635"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper discusses a deviation detection system for UAV landing and introduces a related dataset. It is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21638",
      "abstract": "Ranking tasks are ubiquitous, encompassing applications such as recommendation systems, LLM routing, and item re-ranking. We propose to unify these tasks using a single ranking foundation model (FM), as it eliminates the need for designing different models for each specific ranking task. However, unlike general supervision tasks in LLMs, ranking tasks do not have clear labels for supervision, posing great challenges to developing a ranking FM. To overcome these challenges, we propose IRanker, a ranking FM framework with reinforcement learning (RL) and iterative decoding. Our insight is to decompose the complex ranking task into an iterative decoding process that eliminates the worst candidate from the candidate pool step by step, which significantly reduces the output combinatorial space and better utilizes the limited context length during RL training. We meticulously train and comprehensively evaluate an IRanker-3B model on nine datasets across three scenarios: recommendation, routing, and passage ranking. The results show that a single IRanker-3B achieves state-of-the-art results on several datasets compared to models of similar size, and even surpasses the performance of larger models on certain datasets. We further demonstrate the effectiveness of our RL design and the robustness of the iterative mechanism across different LLM sizes. Moreover, we conducted both in-domain and out-of-domain zero-shot generalization experiments, which showed that IRanker-3B achieved good generalization on in-domain ranking tasks compared to the base LLM by at least 5% improvement. Surprisingly, on out-of-domain generic LLM tasks, IRanker-3B outperformed the base model by at least 9% on GSM8K, IFEval, and MathQA. In addition, the thoughts generated by IRanker-3B during training could further enhance zero-shot LLM performance.",
      "authors": [
        "Tao Feng",
        "Zhigang Hua",
        "Zijie Lei",
        "Yan Xie",
        "Shuang Yang",
        "Bo Long",
        "Jiaxuan You"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T17:56:06+00:00",
          "link": "https://arxiv.org/abs/2506.21638v1",
          "size": "756kb",
          "version": "v1"
        }
      ],
      "title": "IRanker: Towards Ranking Foundation Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21638",
        "HTML": "https://arxiv.org/html/2506.21638v1",
        "PDF": "https://arxiv.org/pdf/2506.21638"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "IRanker addresses ranking tasks using LLMs and implements reinforcement learning. It does not propose new data processing methods directly for LLM training data, rather it focuses on training strategies."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21654",
      "abstract": "Mathematical software has traditionally been built in the form of \"packages\" that build on each other. A substantial fraction of these packages is written in C++ and, as a consequence, the interface of a package is described in the form of header files that downstream packages and applications can then #include. C++ has inherited this approach towards exporting interfaces from C, but the approach is clunky, unreliable, and slow. As a consequence, C++20 has introduced a \"module\" system in which packages explicitly export declarations and code that compilers then store in machine-readable form and that downstream users can \"import\" -- a system in line with what many other programming languages have used for decades.\n  Herein, I explore how one can convert large mathematical software packages written in C++ to this system, using the deal.II finite element library with its around 800,000 lines of code as an example. I describe an approach that allows providing both header-based and module-based interfaces from the same code base, discuss the challenges one encounters, and how modules actually work in practice in a variety of technical and human metrics. The results show that with a non-trivial, but also not prohibitive effort, the conversion to modules is possible, resulting in a reduction in compile time for the converted library itself; on the other hand, for downstream projects, compile times show no clear trend. I end with thoughts about long-term strategies for converting the entire ecosystem of mathematical software over the coming years or decades.",
      "authors": [
        "Wolfgang Bangerth"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Mathematical Software (cs.MS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T17:38:33+00:00",
          "link": "https://arxiv.org/abs/2506.21654v1",
          "size": "164kb",
          "version": "v1"
        }
      ],
      "title": "Experience converting a large mathematical software package written in C++ to C++20 modules",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21654",
        "PDF": "https://arxiv.org/pdf/2506.21654"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper is focused on converting C++ code to C++20 modules for mathematical software packages. It discusses technical aspects and implications of this conversion but does not address LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21655",
      "abstract": "Multimodal Large Language Models (MLLMs) are powerful at integrating diverse data, but they often struggle with complex reasoning. While Reinforcement learning (RL) can boost reasoning in LLMs, applying it to MLLMs is tricky. Common issues include a drop in performance on general tasks and the generation of overly detailed or \"overthinking\" reasoning. Our work investigates how the KL penalty and overthinking affect RL training in MLLMs. We propose Asymmetric Policy Optimization (APO) to address these issues, which divides the sampled responses into positive and negative groups. For positive samples, Difficulty-Adaptive Divergence Shaping (DADS) is introduced to dynamically adjust the KL divergence weight based on their difficulty. This method prevents policy entropy from dropping sharply, improves training stability, utilizes samples better, and preserves the model's existing knowledge. For negative samples, Suboptimal Trajectory Complexity Regularization (STCR) is proposed to penalize overly long responses. This helps mitigate overthinking and encourages more concise reasoning while preserving the model's explorative capacity. We apply our method to Qwen2.5-VL-3B, creating View-R1-3B. View-R1-3B significantly enhances reasoning capabilities, showing an average 7\\% gain over the base model and outperforming larger MLLMs (7-11B) on various reasoning benchmarks. Importantly, unlike other reasoning-tuned MLLMs that often degrade on general tasks, View-R1-3B maintains consistent improvement, demonstrating superior generalization. These results highlight the effectiveness and broad applicability of our DADS and STCR techniques for advancing complex multimodal reasoning in MLLMs. The code will be made available at https://github.com/Indolent-Kawhi/View-R1.",
      "authors": [
        "Minjie Hong",
        "Zirun Guo",
        "Yan Xia",
        "Zehan Wang",
        "Ziang Zhang",
        "Tao Jin",
        "Zhou Zhao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T17:57:08+00:00",
          "link": "https://arxiv.org/abs/2506.21655v1",
          "size": "1991kb",
          "version": "v1"
        }
      ],
      "title": "APO: Enhancing Reasoning Ability of MLLMs via Asymmetric Policy Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21655",
        "HTML": "https://arxiv.org/html/2506.21655v1",
        "PDF": "https://arxiv.org/pdf/2506.21655"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper mentions enhancing reasoning in multimodal LLMs, particularly through reinforcement learning techniques. While the focus is on model training strategies, it does not primarily contribute to new data processing methods for LLM training, but may involve some preprocessing or configuration of experimental data."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21656",
      "abstract": "Current Vision-Language Models (VLMs) struggle with fine-grained spatial reasoning, particularly when multi-step logic and precise spatial alignment are required. In this work, we introduce SpatialReasoner-R1, a vision-language reasoning model designed to address these limitations. To construct high-quality supervision for spatial reasoning, we design a Multi-Model Monte Carlo Tree Search (M3CTS) method that generates diverse, logically consistent Long Chain-of-Thought (LongCoT) reasoning trajectories. In addition, we propose fine-grained Direct Preference Optimization (fDPO), which introduces segment-specific preference granularity for descriptive grounding and logical reasoning, guided by a spatial reward mechanism that evaluates candidate responses based on visual consistency, spatial grounding, and logical coherence. Experimental results demonstrate that fDPO achieves an average improvement of 4.1% over standard DPO across spatial quality tasks, and a 9.0% gain in spatial quantity tasks. SpatialReasoner-R1, trained with fDPO, sets a new SoTA on SPATIALRGPT-Bench, outperforming the strongest baseline by 9.8% in average accuracy, while maintaining competitive performance on general vision-language tasks.",
      "authors": [
        "Yifan Shen",
        "Yuanzhe Liu",
        "Jingyuan Zhu",
        "Xu Cao",
        "Xiaofeng Zhang",
        "Yixiao He",
        "Wenming Ye",
        "James Matthew Rehg",
        "Ismini Lourentzou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T18:00:00+00:00",
          "link": "https://arxiv.org/abs/2506.21656v1",
          "size": "4780kb",
          "version": "v1"
        }
      ],
      "title": "Fine-Grained Preference Optimization Improves Spatial Reasoning in VLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21656",
        "HTML": "https://arxiv.org/html/2506.21656v1",
        "PDF": "https://arxiv.org/pdf/2506.21656"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This research introduces methods to improve spatial reasoning in Vision-Language Models, involving data-driven experiments. While it briefly involves data processing for constructing supervision signals, the primary contributions relate to the model and reasoning optimization, not LLM training data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21669",
      "abstract": "Self-evolution, the ability of agents to autonomously improve their reasoning and behavior, is essential for the embodied domain with long-horizon, real-world tasks. Despite current advancements in reinforcement fine-tuning (RFT) showing strong performance in enhancing reasoning in LLMs, its potential to enable self-evolving embodied intelligence with multi-modal interactions remains largely unexplored. Specifically, reinforcement fine-tuning faces two fundamental obstacles in embodied settings: (i) the lack of accessible intermediate rewards in multi-step reasoning tasks limits effective learning signals, and (ii) reliance on hand-crafted reward functions restricts generalization to novel tasks and environments. To address these challenges, we present Self-Evolving Embodied Agents-R1, SEEA-R1, the first RFT framework designed for enabling the self-evolving capabilities of embodied agents. Specifically, to convert sparse delayed rewards into denser intermediate signals that improve multi-step reasoning, we propose Tree-based group relative policy optimization (Tree-GRPO), which integrates Monte Carlo Tree Search into GRPO. To generalize reward estimation across tasks and scenes, supporting autonomous adaptation and reward-driven self-evolution, we further introduce Multi-modal Generative Reward Model (MGRM). To holistically evaluate the effectiveness of SEEA-R1, we evaluate on the ALFWorld benchmark, surpassing state-of-the-art methods with scores of 85.07% (textual) and 36.19% (multi-modal), outperforming prior models including GPT-4o. SEEA-R1 also achieves scores of 80.3% without environmental reward, surpassing all open-source baselines and highlighting its scalability as a self-evolving embodied agent. Additional experiments and qualitative analysis further support the potential of SEEA-R1 for future research in scalable embodied intelligence.",
      "authors": [
        "Wanxin Tian",
        "Shijie Zhang",
        "Kevin Zhang",
        "Xiaowei Chi",
        "Yulin Luo",
        "Junyu Lu",
        "Chunkai Fan",
        "Qiang Zhou",
        "Yiming Zhao",
        "Ning Liu Siyu Lin",
        "Zhiyuan Qin",
        "Xiaozhu Ju",
        "Shanghang Zhang",
        "Jian Tang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T18:00:07+00:00",
          "link": "https://arxiv.org/abs/2506.21669v1",
          "size": "10312kb",
          "version": "v1"
        }
      ],
      "title": "SEEA-R1: Tree-Structured Reinforcement Fine-Tuning for Self-Evolving Embodied Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21669",
        "HTML": "https://arxiv.org/html/2506.21669v1",
        "PDF": "https://arxiv.org/pdf/2506.21669"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper discusses reinforcement fine-tuning for self-evolving agents, focusing on agent behavior and reasoning improvements using tree-structured optimization techniques. It involves some data used for training, but the focus is on optimizing reinforcement learning approaches rather than LLM data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21678",
      "abstract": "We investigate a property that extends the Danos-Regnier correctness criterion for linear logic proof-structures. The property applies to the correctness graphs of a proof-structure: it states that any such graph is acyclic and that the number of its connected components is exactly one more than the number of nodes bottom or weakening. This is known to be necessary but not sufficient in multiplicative exponential linear logic (MELL) to recover a sequent calculus proof from a proof-structure. We present a geometric condition on untyped proof-structures allowing us to turn this necessary property into a sufficient one: we can thus isolate several fragments of MELL for which this property is indeed a correctness criterion. We also recover as by-product some known results.",
      "authors": [
        "Raffaele Di Donna",
        "Lorenzo Tortora de Falco"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T18:02:20+00:00",
          "link": "https://arxiv.org/abs/2506.21678v1",
          "size": "392kb",
          "version": "v1"
        }
      ],
      "title": "On the role of connectivity in Linear Logic proofs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21678",
        "HTML": "https://arxiv.org/html/2506.21678v1",
        "PDF": "https://arxiv.org/pdf/2506.21678"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on linear logic proofs and investigates properties of correctness graphs. It is unrelated to the processing of training data for LLMs as it does not discuss data collection, construction, or preparation for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21681",
      "abstract": "Recent advances in image generation have led to remarkable improvements in synthesizing perspective images. However, these models still struggle with panoramic image generation due to unique challenges, including varying levels of geometric distortion and the requirement for seamless loop-consistency. To address these issues while leveraging the strengths of the existing models, we introduce TanDiT, a method that synthesizes panoramic scenes by generating grids of tangent-plane images covering the entire 360$^\\circ$ view. Unlike previous methods relying on multiple diffusion branches, TanDiT utilizes a unified diffusion model trained to produce these tangent-plane images simultaneously within a single denoising iteration. Furthermore, we propose a model-agnostic post-processing step specifically designed to enhance global coherence across the generated panoramas. To accurately assess panoramic image quality, we also present two specialized metrics, TangentIS and TangentFID, and provide a comprehensive benchmark comprising captioned panoramic datasets and standardized evaluation scripts. Extensive experiments demonstrate that our method generalizes effectively beyond its training data, robustly interprets detailed and complex text prompts, and seamlessly integrates with various generative models to yield high-quality, diverse panoramic images.",
      "authors": [
        "Hakan \\c{C}apuk",
        "Andrew Bond",
        "Muhammed Burak K{\\i}z{\\i}l",
        "Emir G\\\"o\\c{c}en",
        "Erkut Erdem",
        "Aykut Erdem"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T18:09:09+00:00",
          "link": "https://arxiv.org/abs/2506.21681v1",
          "size": "28808kb",
          "version": "v1"
        }
      ],
      "title": "TanDiT: Tangent-Plane Diffusion Transformer for High-Quality 360{\\deg} Panorama Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21681",
        "HTML": "https://arxiv.org/html/2506.21681v1",
        "PDF": "https://arxiv.org/pdf/2506.21681"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This research is concerned with panoramic image generation and does not address any aspect of LLM training data. It discusses 360-degree panorama generation and related metrics, which are not related to LLM data engineering or training stages."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21682",
      "abstract": "Explicit structural information has been proven to be encoded by Graph Neural Networks (GNNs), serving as auxiliary knowledge to enhance model capabilities and improve performance in downstream NLP tasks. However, recent studies indicate that GNNs fail to fully utilize structural information, whereas Multi-Layer Perceptrons (MLPs), despite lacking the message-passing mechanisms inherent to GNNs, exhibit a surprising ability in structure-aware tasks. Motivated by these findings, this paper introduces a comprehensive probing framework from an information-theoretic perspective. The framework is designed to systematically assess the role of explicit structural modeling in enhancing language model (LM) representations and to investigate the potential of MLPs as efficient and scalable alternatives to GNNs. We extend traditional probing classifiers by incorporating a control module that allows for selective use of either the full GNN model or its decoupled components, specifically, the message-passing and feature-transformation operations.This modular approach isolates and assesses the individual contributions of these operations, avoiding confounding effects from the complete GNN architecture. Using the Edge Probing Suite, a diagnostic tool for evaluating the linguistic knowledge encoded in LMs, we find that MLPs, when used as feature-transformation modules, consistently improve the linguistic knowledge captured in LM representations across different architectures. They effectively encode both syntactic and semantic patterns. Similarly, GNNs that incorporate feature-transformation operations show beneficial effects. In contrast, models that rely solely on message-passing operations tend to underperform, often leading to negative impacts on probing task performance.",
      "authors": [
        "Li Zhou",
        "Hao Jiang",
        "Junjie Li",
        "Zefeng Zhao",
        "Feng Jiang",
        "Wenyu Chen",
        "Haizhou Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T18:10:28+00:00",
          "link": "https://arxiv.org/abs/2506.21682v1",
          "size": "721kb",
          "version": "v1"
        }
      ],
      "title": "Do We Really Need GNNs with Explicit Structural Modeling? MLPs Suffice for Language Model Representations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21682",
        "HTML": "https://arxiv.org/html/2506.21682v1",
        "PDF": "https://arxiv.org/pdf/2506.21682"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper investigates the use of MLPs versus GNNs for language model representations and does not discuss training data processing or engineering for LLMs. Its focus is on assessing language model representations, not on data processing or collection."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21683",
      "abstract": "Risk-averse total-reward Markov Decision Processes (MDPs) offer a promising framework for modeling and solving undiscounted infinite-horizon objectives. Existing model-based algorithms for risk measures like the entropic risk measure (ERM) and entropic value-at-risk (EVaR) are effective in small problems, but require full access to transition probabilities. We propose a Q-learning algorithm to compute the optimal stationary policy for total-reward ERM and EVaR objectives with strong convergence and performance guarantees. The algorithm and its optimality are made possible by ERM's dynamic consistency and elicitability. Our numerical results on tabular domains demonstrate quick and reliable convergence of the proposed Q-learning algorithm to the optimal risk-averse value function.",
      "authors": [
        "Xihong Su",
        "Jia Lin Hau",
        "Gersi Doko",
        "Kishan Panaganti",
        "Marek Petrik"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T18:10:51+00:00",
          "link": "https://arxiv.org/abs/2506.21683v1",
          "size": "176kb",
          "version": "v1"
        }
      ],
      "title": "Risk-Averse Total-Reward Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21683",
        "HTML": "https://arxiv.org/html/2506.21683v1",
        "PDF": "https://arxiv.org/pdf/2506.21683"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper addresses reinforcement learning and proposes an algorithm for risk-averse Markov Decision Processes. It does not mention or relate to LLM training data processing or data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21686",
      "abstract": "Sentiment analysis for regional dialects of Bangla remains an underexplored area due to linguistic diversity and limited annotated data. This paper introduces ANUBHUTI, a comprehensive dataset consisting of 2000 sentences manually translated from standard Bangla into four major regional dialects Mymensingh, Noakhali, Sylhet, and Chittagong. The dataset predominantly features political and religious content, reflecting the contemporary socio political landscape of Bangladesh, alongside neutral texts to maintain balance. Each sentence is annotated using a dual annotation scheme: multiclass thematic labeling categorizes sentences as Political, Religious, or Neutral, and multilabel emotion annotation assigns one or more emotions from Anger, Contempt, Disgust, Enjoyment, Fear, Sadness, and Surprise. Expert native translators conducted the translation and annotation, with quality assurance performed via Cohens Kappa inter annotator agreement, achieving strong consistency across dialects. The dataset was further refined through systematic checks for missing data, anomalies, and inconsistencies. ANUBHUTI fills a critical gap in resources for sentiment analysis in low resource Bangla dialects, enabling more accurate and context aware natural language processing.",
      "authors": [
        "Swastika Kundu",
        "Autoshi Ibrahim",
        "Mithila Rahman",
        "Tanvir Ahmed"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T18:13:54+00:00",
          "link": "https://arxiv.org/abs/2506.21686v1",
          "size": "1532kb",
          "version": "v1"
        }
      ],
      "title": "ANUBHUTI: A Comprehensive Corpus For Sentiment Analysis In Bangla Regional Languages",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21686",
        "HTML": "https://arxiv.org/html/2506.21686v1",
        "PDF": "https://arxiv.org/pdf/2506.21686"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a dataset for sentiment analysis in Bangla dialects, which involves data collection and annotation. However, it does not contribute new methods for processing training data for LLMs, instead focusing on the creation of a sentiment analysis resource."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21688",
      "abstract": "We introduce a novel cybersecurity encounter simulator between a network defender and an attacker designed to facilitate game-theoretic modeling and analysis while maintaining many significant features of real cyber defense. Our simulator, built within the OpenAI Gym framework, incorporates realistic network topologies, vulnerabilities, exploits (including-zero-days), and defensive mechanisms. Additionally, we provide a formal simulation-based game-theoretic model of cyberdefense using this simulator, which features a novel approach to modeling zero-days exploits, and a PSRO-style approach for approximately computing equilibria in this game. We use our simulator and associated game-theoretic framework to analyze the Volt Typhoon advanced persistent threat (APT). Volt Typhoon represents a sophisticated cyber attack strategy employed by state-sponsored actors, characterized by stealthy, prolonged infiltration and exploitation of network vulnerabilities. Our experimental results demonstrate the efficacy of game-theoretic strategies in understanding network resilience against APTs and zero-days, such as Volt Typhoon, providing valuable insight into optimal defensive posture and proactive threat mitigation.",
      "authors": [
        "Michael Lanier",
        "Yevgeniy Vorobeychik"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T18:15:18+00:00",
          "link": "https://arxiv.org/abs/2506.21688v1",
          "size": "736kb",
          "version": "v1"
        }
      ],
      "title": "CyGym: A Simulation-Based Game-Theoretic Analysis Framework for Cybersecurity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21688",
        "HTML": "https://arxiv.org/html/2506.21688v1",
        "PDF": "https://arxiv.org/pdf/2506.21688"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on a game-theoretic framework for cybersecurity and does not discuss any aspect of LLM training data processing or preparation."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21689",
      "abstract": "Robotic teleoperation over long communication distances poses challenges due to delays in commands and feedback from network latency. One simple yet effective strategy to reduce errors and increase performance under delay is to downscale the relative motion between the operating surgeon and the robot. The question remains as to what is the optimal scaling factor, and how this value changes depending on the level of latency as well as operator tendencies. We present user studies investigating the relationship between latency, scaling factor, and performance. The results of our studies demonstrate a statistically significant difference in performance between users and across scaling factors for certain levels of delay. These findings indicate that the optimal scaling factor for a given level of delay is specific to each user, motivating the need for personalized models for optimal performance. We present techniques to model the user-specific mapping of latency level to scaling factor for optimal performance, leading to an efficient and effective solution to optimizing performance of robotic teleoperation and specifically telesurgery under large communication delay.",
      "authors": [
        "Jason Lim",
        "Florian Richter",
        "Zih-Yun Chiu",
        "Jaeyon Lee",
        "Ethan Quist",
        "Nathan Fisher",
        "Jonathan Chambers",
        "Steven Hong",
        "Michael C. Yip"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T18:15:41+00:00",
          "link": "https://arxiv.org/abs/2506.21689v1",
          "size": "168kb",
          "version": "v1"
        }
      ],
      "title": "Optimal Motion Scaling for Delayed Telesurgery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21689",
        "HTML": "https://arxiv.org/html/2506.21689v1",
        "PDF": "https://arxiv.org/pdf/2506.21689"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper deals with optimal motion scaling for telesurgery and does not address issues related to LLM training data collection, processing, or preparation."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21693",
      "abstract": "Developing autonomous driving (AD) systems is challenging due to the complexity of the systems and the need to assure their safe and reliable operation. The widely adopted approach of DevOps seems promising to support the continuous technological progress in AI and the demand for fast reaction to incidents, which necessitate continuous development, deployment, and monitoring. We present a systematic literature review meant to identify, analyse, and synthesise a broad range of existing literature related to usage of DevOps in autonomous driving development. Our results provide a structured overview of challenges and solutions, arising from applying DevOps to safety-related AI-enabled functions. Our results indicate that there are still several open topics to be addressed to enable safe DevOps for the development of safe AD.",
      "authors": [
        "Ali Nouri",
        "Beatriz Cabrero-Daniel",
        "Fredrik T\\\"orner",
        "Christian Berger"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T18:24:08+00:00",
          "link": "https://arxiv.org/abs/2506.21693v1",
          "size": "16804kb",
          "version": "v1"
        }
      ],
      "title": "The DevSafeOps Dilemma: A Systematic Literature Review on Rapidity in Safe Autonomous Driving Development and Operation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21693",
        "HTML": "https://arxiv.org/html/2506.21693v1",
        "PDF": "https://arxiv.org/pdf/2506.21693"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper provides a literature review on DevOps in autonomous driving, without mentioning any tasks related to LLM data processing or training data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21695",
      "abstract": "Density-based clustering methods often surpass centroid-based counterparts, when addressing data with noise or arbitrary data distributions common in real-world problems. In this study, we reveal a key property intrinsic to density-based clustering methods regarding the relation between the number of clusters and the neighborhood radius of core points - we empirically show that it is nearly unimodal, and support this claim theoretically in a specific setting. We leverage this property to devise new strategies for finding appropriate values for the radius more efficiently based on the Ternary Search algorithm. This is especially important for large scale data that is high-dimensional, where parameter tuning is computationally intensive. We validate our methodology through extensive applications across a range of high-dimensional, large-scale NLP, Audio, and Computer Vision tasks, demonstrating its practical effectiveness and robustness. This work not only offers a significant advancement in parameter control for density-based clustering but also broadens the understanding regarding the relations between their guiding parameters. Our code is available at https://github.com/oronnir/UnimodalStrategies.",
      "authors": [
        "Oron Nir",
        "Jay Tenenbaum",
        "Ariel Shamir"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T18:25:14+00:00",
          "link": "https://arxiv.org/abs/2506.21695v1",
          "size": "2982kb",
          "version": "v1"
        }
      ],
      "title": "Unimodal Strategies in Density-Based Clustering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21695",
        "HTML": "https://arxiv.org/html/2506.21695v1",
        "PDF": "https://arxiv.org/pdf/2506.21695"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This research focuses on density-based clustering strategies and does not address LLM training data processing or preparation stages."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21697",
      "abstract": "Control Barrier Functions (CBFs) are utilized to ensure the safety of control systems. CBFs act as safety filters in order to provide safety guarantees without compromising system performance. These safety guarantees rely on the construction of valid CBFs. Due to their complexity, CBFs can be represented by neural networks, known as neural CBFs (NCBFs). Existing works on the verification of the NCBF focus on the synthesis and verification of NCBFs in deterministic settings, leaving the stochastic NCBFs (SNCBFs) less studied. In this work, we propose a verifiably safe synthesis for SNCBFs. We consider the cases of smooth SNCBFs with twice-differentiable activation functions and SNCBFs that utilize the Rectified Linear Unit or ReLU activation function. We propose a verification-free synthesis framework for smooth SNCBFs and a verification-in-the-loop synthesis framework for both smooth and ReLU SNCBFs. and we validate our frameworks in three cases, namely, the inverted pendulum, Darboux, and the unicycle model.",
      "authors": [
        "Hongchao Zhang",
        "Manan Tayal",
        "Jackson Cox",
        "Pushpak Jagtap",
        "Shishir Kolathaya",
        "Andrew Clark"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T18:33:42+00:00",
          "link": "https://arxiv.org/abs/2506.21697v1",
          "size": "2315kb",
          "version": "v1"
        }
      ],
      "title": "Stochastic Neural Control Barrier Functions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21697",
        "HTML": "https://arxiv.org/html/2506.21697v1",
        "PDF": "https://arxiv.org/pdf/2506.21697"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on the synthesis and verification of Stochastic Neural Control Barrier Functions (SNCBFs) for safety in control systems, which is unrelated to the processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21699",
      "abstract": "This paper addresses the challenging and interesting inverse problem of reconstructing the spatially varying dielectric constant of a medium from phaseless backscattering measurements generated by single-point illumination. The underlying mathematical model is governed by the three-dimensional Helmholtz equation, and the available data consist solely of the magnitude of the scattered wave field. To address the nonlinearity and severe ill-posedness of this phaseless inverse scattering problem, we introduce a robust, globally convergent numerical framework combining several key regularization strategies. Our method first employs a phase retrieval step based on the Wentzel--Kramers--Brillouin (WKB) ansatz, where the lost phase information is reconstructed by solving a nonlinear optimization problem. Subsequently, we implement a Fourier-based dimension reduction technique, transforming the original problem into a more stable system of elliptic equations with Cauchy boundary conditions. To solve this resulting system reliably, we apply the Carleman convexification approach, constructing a strictly convex weighted cost functional whose global minimizer provides an accurate approximation of the true solution. Numerical simulations using synthetic data with high noise levels demonstrate the effectiveness and robustness of the proposed method, confirming its capability to accurately recover both the geometric location and contrast of hidden scatterers.",
      "authors": [
        "Thuy T. Le",
        "Phuong M. Nguyen",
        "and Loc H. Nguyen"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T18:35:50+00:00",
          "link": "https://arxiv.org/abs/2506.21699v1",
          "size": "1556kb",
          "version": "v1"
        }
      ],
      "title": "Inverse scattering without phase: Carleman convexification and phase retrieval via the Wentzel--Kramers--Brillouin approximation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21699",
        "HTML": "https://arxiv.org/html/2506.21699v1",
        "PDF": "https://arxiv.org/pdf/2506.21699"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper addresses techniques for solving a phaseless inverse scattering problem and focuses on mathematical and numerical methods, without discussing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21700",
      "abstract": "Classical Finite Volume methods for multi-dimensional problems include stabilization (e.g. via a Riemann solver), that is derived by considering several one-dimensional problems in different directions. Such methods therefore ignore a possibly existing balance of contributions coming from different directions, such as the one characterizing multi-dimensional stationary states. Instead being preserved, they are usually diffused away by such methods. Stationarity preserving methods use a better suited stabilization term that vanishes at the stationary state, allowing the method to preserve it. This work presents a general approach to stationarity preserving Finite Volume methods for nonlinear conservation/balance laws. It is based on a multi-dimensional extension of the global flux approach. The new methods are shown to significantly outperform existing ones even if the latter are of higher order of accuracy and even on non-stationary solutions.",
      "authors": [
        "Wasilij Barsukow",
        "Mirco Ciallella",
        "Mario Ricchiuto",
        "Davide Torlo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Computational Physics (physics.comp-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T14:12:55+00:00",
          "link": "https://arxiv.org/abs/2506.21700v1",
          "size": "74688kb",
          "version": "v1"
        }
      ],
      "title": "Genuinely multi-dimensional stationarity preserving global flux Finite Volume formulation for nonlinear hyperbolic PDEs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21700",
        "PDF": "https://arxiv.org/pdf/2506.21700"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The study presents new Finite Volume methods for solving nonlinear hyperbolic PDEs, which is unrelated to LLM training data or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21703",
      "abstract": "With the rapid adoption of Generative AI (GenAI) tools, software engineering educators have grappled with how best to incorporate them into the classroom. While some research discusses the use of GenAI in the context of learning to code, there is little research that explores the use of GenAI in the classroom for other areas of software development. This paper provides an experience report on introducing GenAI into an undergraduate software design class. Students were required to use GenAI (in the form of ChatGPT) to help complete a team-based assignment. The data collected consisted of the ChatGPT conversation logs and students' reflections on using ChatGPT for the assignment. Subsequently, qualitative analysis was undertaken on the data. Students identified numerous ways ChatGPT helped them in their design process while recognizing the need to critique the response before incorporating it into their design. At the same time, we identified several key lessons for educators in how to deploy GenAI in a software design class effectively. Based on our experience, we believe students can benefit from using GenAI in software design education as it helps them design and learn about the strengths and weaknesses of GenAI.",
      "authors": [
        "Victoria Jackson",
        "Susannah Liu",
        "Andre van der Hoek"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T18:40:16+00:00",
          "link": "https://arxiv.org/abs/2506.21703v1",
          "size": "74kb",
          "version": "v1"
        }
      ],
      "title": "Using Generative AI in Software Design Education: An Experience Report",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21703",
        "HTML": "https://arxiv.org/html/2506.21703v1",
        "PDF": "https://arxiv.org/pdf/2506.21703"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This experience report discusses the use of Generative AI (like ChatGPT) in software design education, focusing on educational practices rather than on LLM data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21710",
      "abstract": "While Multimodal Large Language Models (MLLMs) offer strong perception and reasoning capabilities for image-text input, Visual Question Answering (VQA) focusing on small image details still remains a challenge. Although visual cropping techniques seem promising, recent approaches have several limitations: the need for task-specific fine-tuning, low efficiency due to uninformed exhaustive search, or incompatibility with efficient attention implementations. We address these shortcomings by proposing a training-free visual cropping method, dubbed FOCUS, that leverages MLLM-internal representations to guide the search for the most relevant image region. This is accomplished in four steps: first, we identify the target object(s) in the VQA prompt; second, we compute an object relevance map using the key-value (KV) cache; third, we propose and rank relevant image regions based on the map; and finally, we perform the fine-grained VQA task using the top-ranked region. As a result of this informed search strategy, FOCUS achieves strong performance across four fine-grained VQA datasets and two types of MLLMs. It outperforms three popular visual cropping methods in both accuracy and efficiency, and matches the best-performing baseline, ZoomEye, while requiring 3 - 6.5 x less compute.",
      "authors": [
        "Liangyu Zhong",
        "Fabio Rosenthal",
        "Joachim Sicking",
        "Fabian H\\\"uger",
        "Thorsten Bagdonat",
        "Hanno Gottschalk",
        "Leo Schwinn"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T18:51:04+00:00",
          "link": "https://arxiv.org/abs/2506.21710v1",
          "size": "1248kb",
          "version": "v1"
        }
      ],
      "title": "FOCUS: Internal MLLM Representations for Efficient Fine-Grained Visual Question Answering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21710",
        "HTML": "https://arxiv.org/html/2506.21710v1",
        "PDF": "https://arxiv.org/pdf/2506.21710"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The research introduces a visual cropping method for efficient fine-grained visual question answering with Multimodal Large Language Models, but it does not address processing or engineering of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21711",
      "abstract": "Deepfakes have emerged as a significant threat to digital media authenticity, increasing the need for advanced detection techniques that can identify subtle and time-dependent manipulations. CNNs are effective at capturing spatial artifacts, and Transformers excel at modeling temporal inconsistencies. However, many existing CNN-Transformer models process spatial and temporal features independently. In particular, attention-based methods often use separate attention mechanisms for spatial and temporal features and combine them using naive approaches like averaging, addition, or concatenation, which limits the depth of spatio-temporal interaction. To address this challenge, we propose a unified CAST model that leverages cross-attention to effectively fuse spatial and temporal features in a more integrated manner. Our approach allows temporal features to dynamically attend to relevant spatial regions, enhancing the model's ability to detect fine-grained, time-evolving artifacts such as flickering eyes or warped lips. This design enables more precise localization and deeper contextual understanding, leading to improved performance across diverse and challenging scenarios. We evaluate the performance of our model using the FaceForensics++, Celeb-DF, and DeepfakeDetection datasets in both intra- and cross-dataset settings to affirm the superiority of our approach. Our model achieves strong performance with an AUC of 99.49 percent and an accuracy of 97.57 percent in intra-dataset evaluations. In cross-dataset testing, it demonstrates impressive generalization by achieving a 93.31 percent AUC on the unseen DeepfakeDetection dataset. These results highlight the effectiveness of cross-attention-based feature fusion in enhancing the robustness of deepfake video detection.",
      "authors": [
        "Aryan Thakre",
        "Omkar Nagwekar",
        "Vedang Talekar",
        "Aparna Santra Biswas"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T18:51:17+00:00",
          "link": "https://arxiv.org/abs/2506.21711v1",
          "size": "17942kb",
          "version": "v1"
        }
      ],
      "title": "CAST: Cross-Attentive Spatio-Temporal feature fusion for Deepfake detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21711",
        "HTML": "https://arxiv.org/html/2506.21711v1",
        "PDF": "https://arxiv.org/pdf/2506.21711"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on enhancing deepfake detection capabilities using a model that fuses spatial and temporal features. It is centered on the detection and analysis of deepfakes rather than the processing or engineering of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21712",
      "abstract": "In recent years, the impact of self-supervised speech Transformers has extended to speaker-related applications. However, little research has explored how these models encode speaker information. In this work, we address this gap by identifying neurons in the feed-forward layers that are correlated with speaker information. Specifically, we analyze neurons associated with k-means clusters of self-supervised features and i-vectors. Our analysis reveals that these clusters correspond to broad phonetic and gender classes, making them suitable for identifying neurons that represent speakers. By protecting these neurons during pruning, we can significantly preserve performance on speaker-related task, demonstrating their crucial role in encoding speaker information.",
      "authors": [
        "Tzu-Quan Lin",
        "Hsi-Chun Cheng",
        "Hung-yi Lee",
        "Hao Tang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T18:54:26+00:00",
          "link": "https://arxiv.org/abs/2506.21712v1",
          "size": "1300kb",
          "version": "v1"
        }
      ],
      "title": "Identifying Speaker Information in Feed-Forward Layers of Self-Supervised Speech Transformers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21712",
        "HTML": "https://arxiv.org/html/2506.21712v1",
        "PDF": "https://arxiv.org/pdf/2506.21712"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper investigates how self-supervised speech Transformers encode speaker information. It does not address the collection, construction, or processing of training data for large language models specifically."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21714",
      "abstract": "Recently, continuous normalizing flows (CNFs) and diffusion models (DMs) have been studied using the unified theoretical framework. Although such models can generate high-quality data points from a noise distribution, the sampling demands multiple iterations to solve an ordinary differential equation (ODE) with high computational complexity. Most existing methods focus on reducing the number of time steps during the sampling process to improve efficiency. In this work, we explore a complementary direction in which the quality-complexity tradeoff can be dynamically controlled in terms of time steps and in the length of the neural network. We achieve this by rewiring the blocks in the transformer-based architecture to solve an inner discretized ODE w.r.t. its length. Then, we employ time- and length-wise consistency terms during flow matching training, and as a result, the sampling can be performed with an arbitrary number of time steps and transformer blocks. Unlike others, our $\\textrm{ODE}_t \\left(\\textrm{ODE}_l \\right)$ approach is solver-agnostic in time dimension and decreases both latency and memory usage. Compared to the previous state of the art, image generation experiments on CelebA-HQ and ImageNet show a latency reduction of up to $3\\times$ in the most efficient sampling mode, and a FID score improvement of up to $3.5$ points for high-quality sampling. We release our code and model weights with fully reproducible experiments.",
      "authors": [
        "Denis Gudovskiy",
        "Wenzhao Zheng",
        "Tomoyuki Okuno",
        "Yohei Nakata",
        "Kurt Keutzer"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T18:59:59+00:00",
          "link": "https://arxiv.org/abs/2506.21714v1",
          "size": "12892kb",
          "version": "v1"
        }
      ],
      "title": "$\\textrm{ODE}_t \\left(\\textrm{ODE}_l \\right)$: Shortcutting the Time and Length in Diffusion and Flow Models for Faster Sampling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21714",
        "HTML": "https://arxiv.org/html/2506.21714v1",
        "PDF": "https://arxiv.org/pdf/2506.21714"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The work aims to improve the efficiency of sampling in diffusion and flow models. It does not discuss LLM training data processing or engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21718",
      "abstract": "In many industries, predicting metric outcomes of large systems is a fundamental problem, driven largely by traditional tabular regression. However, such methods struggle on complex systems data in the wild such as configuration files or system logs, where feature engineering is often infeasible. We propose text-to-text regression as a general, scalable alternative. For predicting resource efficiency on Borg, Google's massive compute cluster scheduling system, a 60M parameter encoder-decoder, trained from random initialization, achieves up to a near perfect 0.99 (0.9 average) rank correlation across the entire fleet, and 100x lower MSE than tabular approaches. The model also easily adapts to new tasks in only 500 few-shot examples and captures the densities of complex outcome distributions. Ablation studies highlight the importance of using encoders, increasing sequence length, and the model's inherent uncertainty quantification. These findings pave the way for universal simulators of real-world outcomes.",
      "authors": [
        "Yash Akhauri",
        "Bryan Lewandowski",
        "Cheng-Hsi Lin",
        "Adrian N. Reyes",
        "Grant C. Forbes",
        "Arissa Wongpanich",
        "Bangding Yang",
        "Mohamed S. Abdelfattah",
        "Sagi Perel",
        "Xingyou Song"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Performance (cs.PF)",
        "Software Engineering (cs.SE)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T19:10:08+00:00",
          "link": "https://arxiv.org/abs/2506.21718v1",
          "size": "1111kb",
          "version": "v1"
        }
      ],
      "title": "Performance Prediction for Large Systems via Text-to-Text Regression",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21718",
        "HTML": "https://arxiv.org/html/2506.21718v1",
        "PDF": "https://arxiv.org/pdf/2506.21718"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper deals with text-to-text regression for performance prediction in large systems like Google's compute cluster and does not involve LLM training data processing or related techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21722",
      "abstract": "While diffusion models demonstrate strong generative capabilities in image restoration (IR) tasks, their complex architectures and iterative processes limit their practical application compared to mainstream reconstruction-based general ordinary IR networks. Existing approaches primarily focus on optimizing network architecture and diffusion paths but overlook the integration of the diffusion training paradigm within general ordinary IR frameworks. To address these challenges, this paper elucidates key principles for adapting the diffusion training paradigm to general IR training through systematic analysis of time-step dependencies, network hierarchies, noise-level relationships, and multi-restoration task correlations, proposing a new IR framework supported by diffusion-based training. To enable IR networks to simultaneously restore images and model generative representations, we introduce a series of regularization strategies that align diffusion objectives with IR tasks, improving generalization in single-task scenarios. Furthermore, recognizing that diffusion-based generation exerts varying influences across different IR tasks, we develop an incremental training paradigm and task-specific adaptors, further enhancing performance in multi-task unified IR. Experiments demonstrate that our method significantly improves the generalization of IR networks in single-task IR and achieves superior performance in multi-task unified IR. Notably, the proposed framework can be seamlessly integrated into existing general IR architectures.",
      "authors": [
        "Xin Lu and Xueyang Fu and Jie Xiao and Zihao Fan and Yurui Zhu and Zheng-Jun Zha"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T19:14:27+00:00",
          "link": "https://arxiv.org/abs/2506.21722v1",
          "size": "11276kb",
          "version": "v1"
        }
      ],
      "title": "Elucidating and Endowing the Diffusion Training Paradigm for General Image Restoration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21722",
        "HTML": "https://arxiv.org/html/2506.21722v1",
        "PDF": "https://arxiv.org/pdf/2506.21722"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on improving image restoration techniques through diffusion models, which is outside the scope of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21724",
      "abstract": "Learning semantically meaningful representations from unstructured 3D point clouds remains a central challenge in computer vision, especially in the absence of large-scale labeled datasets. While masked point modeling (MPM) is widely used in self-supervised 3D learning, its reconstruction-based objective can limit its ability to capture high-level semantics. We propose AsymDSD, an Asymmetric Dual Self-Distillation framework that unifies masked modeling and invariance learning through prediction in the latent space rather than the input space. AsymDSD builds on a joint embedding architecture and introduces several key design choices: an efficient asymmetric setup, disabling attention between masked queries to prevent shape leakage, multi-mask sampling, and a point cloud adaptation of multi-crop. AsymDSD achieves state-of-the-art results on ScanObjectNN (90.53%) and further improves to 93.72% when pretrained on 930k shapes, surpassing prior methods.",
      "authors": [
        "Remco F. Leijenaar",
        "Hamidreza Kasaei"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T19:17:10+00:00",
          "link": "https://arxiv.org/abs/2506.21724v1",
          "size": "2742kb",
          "version": "v1"
        }
      ],
      "title": "Asymmetric Dual Self-Distillation for 3D Self-Supervised Representation Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21724",
        "HTML": "https://arxiv.org/html/2506.21724v1",
        "PDF": "https://arxiv.org/pdf/2506.21724"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The research addresses self-supervised learning for 3D point clouds and does not involve LLM training data processing techniques or pipelines."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21727",
      "abstract": "This paper explores the fair allocation of indivisible items in a multidimensional setting, motivated by the need to address fairness in complex environments where agents assess bundles according to multiple criteria. Such multidimensional settings are not merely of theoretical interest but are central to many real-world applications. For example, cloud computing resources are evaluated based on multiple criteria such as CPU cores, memory, and network bandwidth. In such cases, traditional one dimensional fairness notions fail to capture fairness across multiple attributes. To address these challenges, we study two relaxed variants of envy-freeness: weak simultaneously envy-free up to c goods (weak sEFc) and strong simultaneously envy-free up to c goods (strong sEFc), which accommodate the multidimensionality of agents' preferences. Under the weak notion, for every pair of agents and for each dimension, any perceived envy can be eliminated by removing, if necessary, a different set of goods from the envied agent's allocation. In contrast, the strong version requires selecting a single set of goods whose removal from the envied bundle simultaneously eliminates envy in every dimension. We provide upper and lower bounds on the relaxation parameter c that guarantee the existence of weak or strong sEFc allocations, where these bounds are independent of the total number of items. In addition, we present algorithms for checking whether a weak or strong sEFc allocation exists. Moreover, we establish NP-hardness results for checking the existence of weak sEF1 and strong sEF1 allocations.",
      "authors": [
        "Yasushi Kawase",
        "Bodhayan Roy and Mohammad Azharuddin Sanpui"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T19:27:22+00:00",
          "link": "https://arxiv.org/abs/2506.21727v1",
          "size": "244kb",
          "version": "v1"
        }
      ],
      "title": "Simultaneously Fair Allocation of Indivisible Items Across Multiple Dimensions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21727",
        "HTML": "https://arxiv.org/html/2506.21727v1",
        "PDF": "https://arxiv.org/pdf/2506.21727"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper examines fair allocation algorithms for multidimensional resource distribution, which is unrelated to the processing or engineering of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21728",
      "abstract": "We present a finite-state, deterministic automaton that emulates the Collatz function by operating on base-10 digit sequences. Each digit is represented as a symbolic triplet capturing its value, the parity of the next digit, and a local carry value, resulting in a state space of exactly 60 configurations. The transition rules are local, total, and parity-dependent, yet collectively reproduce the global behavior of the Collatz map through digitwise operations. All symbolic trajectories reduce to the unique terminal cycle (4, 0, 0) -> (2, 0, 0) -> (1, 0, 0), offering a constructive, automaton-theoretic encoding of the Collatz dynamics. A primitive recursive ranking function ensures symbolic termination within the proposed model and supports a convergence argument that is fully formalizable in Peano Arithmetic. This approach introduces a novel framework for analyzing arithmetic dynamics via symbolic computation and automata theory.",
      "authors": [
        "Leonard Ben Aurel Brauer"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Formal Languages and Automata Theory (cs.FL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T19:27:43+00:00",
          "link": "https://arxiv.org/abs/2506.21728v1",
          "size": "2112kb",
          "version": "v1"
        }
      ],
      "title": "A Finite-State Symbolic Automaton Model for the Collatz Map and Its Convergence Properties",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21728",
        "HTML": "https://arxiv.org/html/2506.21728v1",
        "PDF": "https://arxiv.org/pdf/2506.21728"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The study investigates the Collatz map using finite-state automata, with no direct connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21731",
      "abstract": "We propose two theoretical frameworks, the Mutually Exclusive Probability Space (MESP) and the Local Correlation Hypothesis (LCH), to explore a potential limitation in probabilistic generative models; namely that learning global distributions leads to memorization rather than generative behavior. MESP emerges from our rethinking of the Variational Autoencoder (VAE). We observe that latent variable distributions in VAE exhibit overlap, which leads to an optimization conflict between the reconstruction loss and KL-divergence loss. A lower bound based on the overlap coefficient is proposed. We refer to this phenomenon as Mutually Exclusive Probability Spaces. Based on MESP, a Binary Latent Autoencoder (BL-AE) is proposed to encode images into binary latent representations. These binary latents are used as the input to our Autoregressive Random Variable Model (ARVM), a modified autoregressive model outputting histograms. Our ARVM achieves competitive FID scores, outperforming state-of-the-art methods on standard datasets. However, such scores reflect memorization rather than generation. To address this issue, we propose the Local Correlation Hypothesis (LCH), which posits that generative capability arising from local correlations among latent variables. Comprehensive experiments and discussions are conducted to validate our frameworks.",
      "authors": [
        "Chenqiu Zhao",
        "Anup Basu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T19:32:29+00:00",
          "link": "https://arxiv.org/abs/2506.21731v1",
          "size": "6460kb",
          "version": "v1"
        }
      ],
      "title": "Exploring Image Generation via Mutually Exclusive Probability Spaces and Local Correlation Hypothesis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21731",
        "HTML": "https://arxiv.org/html/2506.21731v1",
        "PDF": "https://arxiv.org/pdf/2506.21731"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on image generation models, specifically proposing new theoretical frameworks for probabilistic models and autoencoders. There is no discussion on LLM training data collection or processing relevant to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21732",
      "abstract": "Vision-based lane keeping is a topic of significant interest in the robotics and autonomous ground vehicles communities in various on-road and off-road applications. The skid-steered vehicle architecture has served as a useful vehicle platform for human controlled operations. However, systematic modeling, especially of the skid-slip wheel terrain interactions (primarily in off-road settings) has created bottlenecks for automation deployment. End-to-end learning based methods such as imitation learning and deep reinforcement learning, have gained prominence as a viable deployment option to counter the lack of accurate analytical models. However, the systematic formulation and subsequent verification/validation in dynamic operation regimes (particularly for skid-steered vehicles) remains a work in progress. To this end, a novel approach for structured formulation for learning visual navigation is proposed and investigated in this work. Extensive software simulations, hardware evaluations and ablation studies now highlight the significantly improved performance of the proposed approach against contemporary literature.",
      "authors": [
        "Ameya Salvi and Venkat Krovi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T19:36:49+00:00",
          "link": "https://arxiv.org/abs/2506.21732v1",
          "size": "4671kb",
          "version": "v1"
        }
      ],
      "title": "Experimental investigation of pose informed reinforcement learning for skid-steered visual navigation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21732",
        "HTML": "https://arxiv.org/html/2506.21732v1",
        "PDF": "https://arxiv.org/pdf/2506.21732"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This research investigates reinforcement learning for visual navigation in skid-steered vehicles. It does not address any aspect of LLM training data or related processing tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21734",
      "abstract": "Reasoning, the process of devising and executing complex goal-oriented action sequences, remains a critical challenge in AI. Current large language models (LLMs) primarily employ Chain-of-Thought (CoT) techniques, which suffer from brittle task decomposition, extensive data requirements, and high latency. Inspired by the hierarchical and multi-timescale processing in the human brain, we propose the Hierarchical Reasoning Model (HRM), a novel recurrent architecture that attains significant computational depth while maintaining both training stability and efficiency. HRM executes sequential reasoning tasks in a single forward pass without explicit supervision of the intermediate process, through two interdependent recurrent modules: a high-level module responsible for slow, abstract planning, and a low-level module handling rapid, detailed computations. With only 27 million parameters, HRM achieves exceptional performance on complex reasoning tasks using only 1000 training samples. The model operates without pre-training or CoT data, yet achieves nearly perfect performance on challenging tasks including complex Sudoku puzzles and optimal path finding in large mazes. Furthermore, HRM outperforms much larger models with significantly longer context windows on the Abstraction and Reasoning Corpus (ARC), a key benchmark for measuring artificial general intelligence capabilities. These results underscore HRM's potential as a transformative advancement toward universal computation and general-purpose reasoning systems.",
      "authors": [
        "Guan Wang",
        "Jin Li",
        "Yuhao Sun",
        "Xing Chen",
        "Changling Liu",
        "Yue Wu",
        "Meng Lu",
        "Sen Song",
        "Yasin Abbasi Yadkori"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T19:39:54+00:00",
          "link": "https://arxiv.org/abs/2506.21734v1",
          "size": "1542kb",
          "version": "v1"
        }
      ],
      "title": "Hierarchical Reasoning Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21734",
        "HTML": "https://arxiv.org/html/2506.21734v1",
        "PDF": "https://arxiv.org/pdf/2506.21734"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper proposes a novel reasoning model architecture for AI systems, focusing on complex task execution. It does not involve any element of LLM training data processing or enhancement."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21735",
      "abstract": "Federated Learning (FL) is enabling collaborative model training across institutions without sharing sensitive patient data. This approach is particularly valuable in low- and middle-income countries (LMICs), where access to trained medical professionals is limited. However, FL adoption in LMICs faces significant barriers, including limited high-performance computing resources and unreliable internet connectivity. To address these challenges, we introduce FedNCA, a novel FL system tailored for medical image segmentation tasks. FedNCA leverages the lightweight Med-NCA architecture, enabling training on low-cost edge devices, such as widely available smartphones, while minimizing communication costs. Additionally, our encryption-ready FedNCA proves to be suitable for compromised network communication. By overcoming infrastructural and security challenges, FedNCA paves the way for inclusive, efficient, lightweight, and encryption-ready medical imaging solutions, fostering equitable healthcare advancements in resource-constrained regions.",
      "authors": [
        "Nick Lemke",
        "Mirko Konstantin",
        "Henry John Krumb",
        "John Kalkhof",
        "Jonathan Stieber",
        "Anirban Mukhopadhyay"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T19:41:21+00:00",
          "link": "https://arxiv.org/abs/2506.21735v1",
          "size": "1149kb",
          "version": "v1"
        }
      ],
      "title": "Equitable Federated Learning with NCA",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21735",
        "HTML": "https://arxiv.org/html/2506.21735v1",
        "PDF": "https://arxiv.org/pdf/2506.21735"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The work discusses federated learning in medical imaging, specifically for enabling training on edge devices. It does not relate to LLM training data engineering or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21742",
      "abstract": "Video QA has made significant strides by leveraging multimodal learning to align visual and textual modalities. However, current benchmarks overwhelmingly focus on questions answerable through explicit visual content - actions, objects & events directly observable within individual frames or short clips. In contrast, creative and cinematic videos - such as movies, TV shows, and narrative-driven content - employ storytelling techniques that deliberately omit certain depictions, requiring viewers to infer motives, causality, and relationships across discontinuous frames. Humans naturally excel at such implicit reasoning, seamlessly integrating information across time and context to construct coherent narratives. Current VideoQA systems and benchmarks fail to capture this essential dimension of human-like understanding. To bridge this gap, we present ImplicitQA, a novel benchmark specifically designed to test models on implicit reasoning. It comprises 1K meticulously annotated QA pairs derived from 320+ high-quality creative video clips, systematically categorized into key reasoning dimensions: lateral and vertical spatial reasoning, depth and proximity, viewpoint and visibility, motion and trajectory, causal and motivational reasoning, social interactions, physical context, and inferred counting. These annotations are deliberately challenging, crafted by authors ensuring high-quality. Our extensive evaluations on leading VideoQA models reveals performance degradation, underscoring their reliance on surface-level visual cues and highlighting the difficulty of implicit reasoning. Performance variations across models further illustrate the complexity and diversity of the challenges presented by ImplicitQA. By releasing both the dataset and our data collection framework, we aim to stimulate further research and development in the community. https://huggingface.co/datasets/ucf-crcv/ImplicitQA.",
      "authors": [
        "Sirnam Swetha",
        "Rohit Gupta",
        "Parth Parag Kulkarni",
        "David G Shatwell",
        "Jeffrey A Chan Santiago",
        "Nyle Siddiqui",
        "Joseph Fioresi",
        "Mubarak Shah"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T19:53:54+00:00",
          "link": "https://arxiv.org/abs/2506.21742v1",
          "size": "13561kb",
          "version": "v1"
        }
      ],
      "title": "ImplicitQA: Going beyond frames towards Implicit Video Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21742",
        "HTML": "https://arxiv.org/html/2506.21742v1",
        "PDF": "https://arxiv.org/pdf/2506.21742"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper presents a new dataset (ImplicitQA) for video question-answering models, suggesting an element of data collection, but doesn't focus on LLM-specific data processing methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21743",
      "abstract": "Storm surge forecasting plays a crucial role in coastal disaster preparedness, yet existing machine learning approaches often suffer from limited spatial resolution, reliance on coastal station data, and poor generalization. Moreover, many prior models operate directly on unstructured spatial data, making them incompatible with modern deep learning architectures. In this work, we introduce a novel approach that projects unstructured water elevation fields onto structured Red Green Blue (RGB)-encoded image representations, enabling the application of Convolutional Long Short Term Memory (ConvLSTM) networks for end-to-end spatiotemporal surge forecasting. Our model further integrates ground-truth wind fields as dynamic conditioning signals and topo-bathymetry as a static input, capturing physically meaningful drivers of surge evolution. Evaluated on a large-scale dataset of synthetic storms in the Gulf of Mexico, our method demonstrates robust 48-hour forecasting performance across multiple regions along the Texas coast and exhibits strong spatial extensibility to other coastal areas. By combining structured representation, physically grounded forcings, and scalable deep learning, this study advances the frontier of storm surge forecasting in usability, adaptability, and interpretability.",
      "authors": [
        "Jinpai Zhao",
        "Albert Cerrone",
        "Eirik Valseth",
        "Leendert Westerink",
        "Clint Dawson"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T19:56:30+00:00",
          "link": "https://arxiv.org/abs/2506.21743v1",
          "size": "44468kb",
          "version": "v1"
        }
      ],
      "title": "Storm Surge in Color: RGB-Encoded Physics-Aware Deep Learning for Storm Surge Forecasting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21743",
        "HTML": "https://arxiv.org/html/2506.21743v1",
        "PDF": "https://arxiv.org/pdf/2506.21743"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The research is centered around storm surge forecasting using deep learning techniques and RGB-encoded physical modeling, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21744",
      "abstract": "Item Response Theory (IRT) models have been widely used to estimate respondents' latent abilities and calibrate items' difficulty. Traditional IRT estimation requires all individual raw response data to be centralized in one place, thus potentially causing privacy issues. Federated learning is an emerging field in computer science and machine learning with added features of privacy protection and distributed computing. To integrate the advances from federated learning with modern psychometrics, we propose a novel framework, Federated Item Response Theory (IRT), to enable estimating traditional IRT models with additional privacy, allowing estimation in a distributed manner without losing estimation accuracy.\n  Our numerical experiments confirm that FedIRT achieves statistical accuracy similar to standard IRT estimation using popular R packages, while offering critical advantages: privacy protection and reduced communication costs. We also validate FedIRT's utility through a real-world exam dataset, demonstrating its effectiveness in realistic educational contexts. This new framework extends IRT's applicability to distributed settings, such as multi-school assessments, without sacrificing accuracy or security. To support practical adoption, we provide an open-ource R package, FedIRT, implementing the framework for the two-parameter logistic (2PL) and partial credit models (PCM).",
      "authors": [
        "Biying Zhou",
        "Nanyu Luo",
        "Feng Ji"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Applications (stat.AP)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T20:01:18+00:00",
          "link": "https://arxiv.org/abs/2506.21744v1",
          "size": "1289kb",
          "version": "v1"
        }
      ],
      "title": "Federated Item Response Theory Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21744",
        "HTML": "https://arxiv.org/html/2506.21744v1",
        "PDF": "https://arxiv.org/pdf/2506.21744"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper discusses federated learning for Item Response Theory models, focusing on psychometrics and privacy, not on LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21745",
      "abstract": "Automatic fact verification systems increasingly rely on large language models (LLMs). We investigate how parametric knowledge biases in these models affect fact-checking outcomes of the HerO system (baseline for FEVER-25). We examine how the system is affected by: (1) potential bias in Llama 3.1's parametric knowledge and (2) intentionally injected bias. When prompted directly to perform fact-verification, Llama 3.1 labels nearly half the claims as \"Not Enough Evidence\". Using only its parametric knowledge it is able to reach a verdict on the remaining half of the claims. In the second experiment, we prompt the model to generate supporting, refuting, or neutral fact-checking documents. These prompts significantly influence retrieval outcomes, with approximately 50\\% of retrieved evidence being unique to each perspective. Notably, the model sometimes refuses to generate supporting documents for claims it believes to be false, creating an inherent negative bias. Despite differences in retrieved evidence, final verdict predictions show stability across prompting strategies. The code is available at: https://github.com/eibakke/FEVER-8-Shared-Task",
      "authors": [
        "Eivind Morris Bakke",
        "Nora Winger Heggelund"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T20:03:58+00:00",
          "link": "https://arxiv.org/abs/2506.21745v1",
          "size": "104kb",
          "version": "v1"
        }
      ],
      "title": "(Fact) Check Your Bias",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21745",
        "HTML": "https://arxiv.org/html/2506.21745v1",
        "PDF": "https://arxiv.org/pdf/2506.21745"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The study examines bias in fact verification systems using LLMs but does not contribute to the processing or engineering of LLM training datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21754",
      "abstract": "We investigate the use of active-learning (AL) strategies to generate the input excitation signal at runtime for system identification of linear and nonlinear autoregressive and state-space models. We adapt various existing AL approaches for static model regression to the dynamic context, coupling them with a Kalman filter to update the model parameters recursively, and also cope with the presence of input and output constraints. We show the increased sample efficiency of the proposed approaches with respect to random excitation on different nonlinear system identification benchmarks.",
      "authors": [
        "Kui Xie",
        "Alberto Bemporad"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T20:19:15+00:00",
          "link": "https://arxiv.org/abs/2506.21754v1",
          "size": "13029kb",
          "version": "v1"
        }
      ],
      "title": "Online design of experiments by active learning for nonlinear system identification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21754",
        "HTML": "https://arxiv.org/html/2506.21754v1",
        "PDF": "https://arxiv.org/pdf/2506.21754"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper discusses the use of active learning for system identification in nonlinear systems, but it does not relate to LLM training data processing or data engineering specifically."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21762",
      "abstract": "Data visualization tasks often require multi-step reasoning, and the interpretive strategies experts use, such as decomposing complex goals into smaller subtasks and selectively attending to key chart regions are rarely made explicit. ViStruct is an automated pipeline that simulates these expert behaviours by breaking high-level visual questions into structured analytic steps and highlighting semantically relevant chart areas. Leveraging large language and vision-language models, ViStruct identifies chart components, maps subtasks to spatial regions, and presents visual attention cues to externalize expert-like reasoning flows. While not designed for direct novice instruction, ViStruct provides a replicable model of expert interpretation that can inform the development of future visual literacy tools. We evaluate the system on 45 tasks across 12 chart types and validate its outputs with trained visualization users, confirming its ability to produce interpretable and expert-aligned reasoning sequences.",
      "authors": [
        "Oliver Huang and Carolina Nobre"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T20:40:20+00:00",
          "link": "https://arxiv.org/abs/2506.21762v1",
          "size": "6058kb",
          "version": "v1"
        }
      ],
      "title": "ViStruct: Simulating Expert-Like Reasoning Through Task Decomposition and Visual Attention Cues",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21762",
        "HTML": "https://arxiv.org/html/2506.21762v1",
        "PDF": "https://arxiv.org/pdf/2506.21762"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "ViStruct is focused on simulating expert reasoning in data visualization tasks using large language and vision-language models, but it does not address issues related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21763",
      "abstract": "Large Language Models (LLMs) are accelerating scientific idea generation, but rigorously evaluating these numerous, often superficial, AI-generated propositions for novelty and factual accuracy is a critical bottleneck; manual verification is too slow.Existing validation methods are inadequate: LLMs as standalone verifiers may hallucinate and lack domain knowledge (our findings show ~60\\% unawareness of relevant papers in specific domains), while traditional citation networks lack explicit causality and narrative surveys are unstructured.This underscores a core challenge: the absence of structured, verifiable, and causally-linked historical data of scientific evolution.To address this,we introduce \\textbf{THE-Tree} (\\textbf{T}echnology \\textbf{H}istory \\textbf{E}volution Tree), a computational framework that constructs such domain-specific evolution trees from scientific literature.THE-Tree employs a search algorithm to explore evolutionary paths. During its node expansion, it utilizes a novel \"Think-Verbalize-Cite-Verify\" process: an LLM proposes potential advancements and cites supporting literature. Critically, each proposed evolutionary link is then validated for logical coherence and evidential support by a recovered natural language inference mechanism that interrogates the cited literature, ensuring that each step is grounded.We construct and validate 88 THE-Trees across diverse domains and release a benchmark dataset including up to 71k fact verifications covering 27k papers to foster further research.Experiments demonstrate that i) in graph completion, our THE-Tree improves hit@1 by 8\\% to 14\\% across multiple models compared to traditional citation networks; ii) for predicting future scientific developments, it improves hit@1 metric by nearly 10\\%; and iii) when combined with other methods, it boosts the performance of evaluating important scientific papers by almost 100\\%.",
      "authors": [
        "Xin Wang",
        "Jiyao Liu",
        "Yulong Xiao",
        "Junzhi Ning",
        "Lihao Liu",
        "Junjun He",
        "Botian Shi",
        "Kaicheng Yu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T20:44:51+00:00",
          "link": "https://arxiv.org/abs/2506.21763v1",
          "size": "14669kb",
          "version": "v1"
        }
      ],
      "title": "THE-Tree: Can Tracing Historical Evolution Enhance Scientific Verification and Reasoning?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21763",
        "HTML": "https://arxiv.org/html/2506.21763v1",
        "PDF": "https://arxiv.org/pdf/2506.21763"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "THE-Tree discusses enhancing scientific verification by tracing historical evolution in scientific literature, without contributing to methods of LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21770",
      "abstract": "Glaucoma is a leading cause of irreversible blindness, but early detection can significantly improve treatment outcomes. Traditional diagnostic methods are often invasive and require specialized equipment. In this work, we present a deep learning pipeline using the EfficientNet-B0 architecture for glaucoma detection from retinal fundus images. Unlike prior studies that rely on single datasets, we sequentially train and fine-tune our model across ACRIMA, ORIGA, and RIM-ONE datasets to enhance generalization. Our experiments show that minimal preprocessing yields higher AUC-ROC compared to more complex enhancements, and our model demonstrates strong discriminative performance on unseen datasets. The proposed pipeline offers a reproducible and scalable approach to early glaucoma detection, supporting its potential clinical utility.",
      "authors": [
        "Rishiraj Paul Chowdhury",
        "Nirmit Shekar Karkera"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T21:06:51+00:00",
          "link": "https://arxiv.org/abs/2506.21770v1",
          "size": "1053kb",
          "version": "v1"
        }
      ],
      "title": "Early Glaucoma Detection using Deep Learning with Multiple Datasets of Fundus Images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21770",
        "HTML": "https://arxiv.org/html/2506.21770v1",
        "PDF": "https://arxiv.org/pdf/2506.21770"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses a deep learning pipeline for early glaucoma detection using multiple datasets and fine-tuning. While it involves data processing (like fine-tuning) for model training, it is focused on image data for medical diagnostics rather than LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21771",
      "abstract": "Neuro-fuzzy networks (NFNs) are transparent, symbolic, and universal function approximations that perform as well as conventional neural architectures, but their knowledge is expressed as linguistic IF-THEN rules. Despite these advantages, their systematic design process remains a challenge. Existing work will often sequentially build NFNs by inefficiently isolating parametric and structural identification, leading to a premature commitment to brittle and subpar architecture. We propose a novel application-independent approach called gradient-based neuroplastic adaptation for the concurrent optimization of NFNs' parameters and structure. By recognizing that NFNs' parameters and structure should be optimized simultaneously as they are deeply conjoined, settings previously unapproachable for NFNs are now accessible, such as the online reinforcement learning of NFNs for vision-based tasks. The effectiveness of concurrently optimizing NFNs is empirically shown as it is trained by online reinforcement learning to proficiently play challenging scenarios from a vision-based video game called DOOM.",
      "authors": [
        "John Wesley Hostetter",
        "Min Chi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T21:08:11+00:00",
          "link": "https://arxiv.org/abs/2506.21771v1",
          "size": "6232kb",
          "version": "v1"
        }
      ],
      "title": "Gradient-Based Neuroplastic Adaptation for Concurrent Optimization of Neuro-Fuzzy Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21771",
        "HTML": "https://arxiv.org/html/2506.21771v1",
        "PDF": "https://arxiv.org/pdf/2506.21771"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper proposes a gradient-based adaptation method for optimizing neuro-fuzzy networks and does not address LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21780",
      "abstract": "Due to the COVID-19 pandemic, many professional entities shifted toward remote collaboration and video conferencing (VC) tools. Social virtual reality (VR) platforms present an alternative to VC for meetings and collaborative activities. Well-crafted social VR environments could enhance feelings of co-presence and togetherness at meetings, helping reduce the need for carbon-intensive travel to face-to-face meetings. This research contributes to creating meeting tools in VR by exploring the effects of avatar styles and virtual environments on groups creative performance using the Mozilla Hubs platform. We present the results of two sequential studies. Study One surveys avatar and environment preferences in various VR meeting contexts (N=87). Study Two applies these findings to the design of a between-subjects and within-subjects research where participants (N=40) perform creativity tasks in pairs as embodied avatars in different virtual settings using VR headsets. We discuss the design implications of avatar appearances and meeting settings on teamwork.",
      "authors": [
        "Anya Osborne",
        "Sabrina Fielder",
        "Lee Taber",
        "Tara Lamb",
        "Joshua McVeigh-Schultz",
        "Katherine Isbister"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T21:25:11+00:00",
          "link": "https://arxiv.org/abs/2506.21780v1",
          "size": "5257kb",
          "version": "v1"
        }
      ],
      "title": "Avatars and Environments for Meetings in Social VR: What Styles and Choices Matter to People in Group Creativity Tasks?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21780",
        "HTML": "https://arxiv.org/html/2506.21780v1",
        "PDF": "https://arxiv.org/pdf/2506.21780"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The research explores virtual reality environments and their impact on social VR meetings and creativity. It does not involve any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21782",
      "abstract": "We introduce Massively Multi-Task Model-Based Policy Optimization (M3PO), a scalable model-based reinforcement learning (MBRL) framework designed to address sample inefficiency in single-task settings and poor generalization in multi-task domains. Existing model-based approaches like DreamerV3 rely on pixel-level generative models that neglect control-centric representations, while model-free methods such as PPO suffer from high sample complexity and weak exploration. M3PO integrates an implicit world model, trained to predict task outcomes without observation reconstruction, with a hybrid exploration strategy that combines model-based planning and model-free uncertainty-driven bonuses. This eliminates the bias-variance trade-off in prior methods by using discrepancies between model-based and model-free value estimates to guide exploration, while maintaining stable policy updates through a trust-region optimizer. M3PO provides an efficient and robust alternative to existing model-based policy optimization approaches and achieves state-of-the-art performance across multiple benchmarks.",
      "authors": [
        "Aditya Narendra",
        "Dmitry Makarov",
        "Aleksandr Panov"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T21:39:01+00:00",
          "link": "https://arxiv.org/abs/2506.21782v1",
          "size": "1713kb",
          "version": "v1"
        }
      ],
      "title": "M3PO: Massively Multi-Task Model-Based Policy Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21782",
        "HTML": "https://arxiv.org/html/2506.21782v1",
        "PDF": "https://arxiv.org/pdf/2506.21782"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on Massively Multi-Task Model-Based Policy Optimization, which is related to reinforcement learning and does not discuss LLM training data or its processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21783",
      "abstract": "Large Language Models (LLMs) have demonstrated immense advances in a wide range of natural language tasks. However, these models are susceptible to hallucinations and errors on particularly temporal understanding tasks involving multiple entities in answers. In such tasks, they fail to associate entities with accurate time intervals, generate a complete list of entities in answers or reason about events associated with specific temporal bounds. Existing works do not extensively evaluate the abilities of the model to perform implicit and explicit temporal understanding in a list answer construction setup. To bridge this gap, we propose the Time referenced List based Question Answering or TLQA benchmark that requires structured answers in list format aligned with corresponding time periods. Our TLQA benchmark, requires both list construction and temporal understanding simultaneously, which to the best of our knowledge has not been explored in prior benchmarks. We investigate the temporal understanding and list construction capabilities of state-of-the-art generative models on TLQA in closed-book and open-domain settings. Our findings reveal significant shortcomings in current models, particularly their inability to provide complete answers and temporally align facts in a closed-book setup and the need to improve retrieval in open-domain setup, providing clear future directions for research on TLQA. The benchmark and code at https://github.com/elixir-research-group/TLQA.",
      "authors": [
        "Alexandru Dumitru",
        "V Venktesh",
        "Adam Jatowt and Avishek Anand"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T21:40:58+00:00",
          "link": "https://arxiv.org/abs/2506.21783v1",
          "size": "1292kb",
          "version": "v1"
        }
      ],
      "title": "Evaluating List Construction and Temporal Understanding capabilities of Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21783",
        "HTML": "https://arxiv.org/html/2506.21783v1",
        "PDF": "https://arxiv.org/pdf/2506.21783"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper evaluates the capabilities of LLMs in temporal understanding tasks and introduces the TLQA benchmark, which involves structured data processing and evaluation, but does not directly contribute new methods for LLM training data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21784",
      "abstract": "Understanding and modeling human mobility patterns is crucial for effective transportation planning and urban development. Despite significant advances in mobility research, there remains a critical gap in simulation platforms that allow for algorithm development, policy implementation, and comprehensive evaluation at scale. Traditional activity-based models require extensive data collection and manual calibration, machine learning approaches struggle with adaptation to dynamic conditions, and treding agent-based Large Language Models (LLMs) implementations face computational constraints with large-scale simulations. To address these challenges, we propose MobiVerse, a hybrid framework leverages the efficiency of lightweight domain-specific generator for generating base activity chains with the adaptability of LLMs for context-aware modifications. A case study was conducted in Westwood, Los Angeles, where we efficiently generated and dynamically adjusted schedules for the whole population of approximately 53,000 agents on a standard PC. Our experiments demonstrate that MobiVerse successfully enables agents to respond to environmental feedback, including road closures, large gathering events like football games, and congestion, through our hybrid framework. Its modular design facilitates testing various mobility algorithms at both transportation system and agent levels. Results show our approach maintains computational efficiency while enhancing behavioral realism. MobiVerse bridges the gap in mobility simulation by providing a customizable platform for mobility systems planning and operations with benchmark algorithms. Code and videos are available at https://github.com/ucla-mobility/MobiVerse.",
      "authors": [
        "Yifan Liu",
        "Xishun Liao",
        "Haoxuan Ma",
        "Jonathan Liu",
        "Rohan Jadhav",
        "and Jiaqi Ma"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T21:46:18+00:00",
          "link": "https://arxiv.org/abs/2506.21784v1",
          "size": "2324kb",
          "version": "v1"
        }
      ],
      "title": "MobiVerse: Scaling Urban Mobility Simulation with Hybrid Lightweight Domain-Specific Generator and Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21784",
        "HTML": "https://arxiv.org/html/2506.21784v1",
        "PDF": "https://arxiv.org/pdf/2506.21784"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper discusses MobiVerse, a framework for urban mobility simulation using LLMs for generating mobility patterns. It does not focus on LLM training data engineering or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21785",
      "abstract": "In this study, we investigate various computer vision paradigms - supervised learning, unsupervised learning, and prompt fine-tuning - by assessing their ability to understand and interpret egocentric video data. Specifically, we examine Shotluck Holmes (state-of-the-art supervised learning), TAC-SUM (state-of-the-art unsupervised learning), and GPT-4o (a prompt fine-tuned pre-trained model), evaluating their effectiveness in video summarization. Our results demonstrate that current state-of-the-art models perform less effectively on first-person videos compared to third-person videos, highlighting the need for further advancements in the egocentric video domain. Notably, a prompt fine-tuned general-purpose GPT-4o model outperforms these specialized models, emphasizing the limitations of existing approaches in adapting to the unique challenges of first-person perspectives. Although our evaluation is conducted on a small subset of egocentric videos from the Ego-Exo4D dataset due to resource constraints, the primary objective of this research is to provide a comprehensive proof-of-concept analysis aimed at advancing the application of computer vision techniques to first-person videos. By exploring novel methodologies and evaluating their potential, we aim to contribute to the ongoing development of models capable of effectively processing and interpreting egocentric perspectives.",
      "authors": [
        "Daniel Wen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T21:46:48+00:00",
          "link": "https://arxiv.org/abs/2506.21785v1",
          "size": "7148kb",
          "version": "v1"
        }
      ],
      "title": "Comparing Learning Paradigms for Egocentric Video Summarization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21785",
        "HTML": "https://arxiv.org/html/2506.21785v1",
        "PDF": "https://arxiv.org/pdf/2506.21785"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper investigates paradigms for egocentric video summarization and compares different computer vision techniques, without addressing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21788",
      "abstract": "Graph foundation models using graph neural networks promise sustainable, efficient atomistic modeling. To tackle challenges of processing multi-source, multi-fidelity data during pre-training, recent studies employ multi-task learning, in which shared message passing layers initially process input atomistic structures regardless of source, then route them to multiple decoding heads that predict data-specific outputs. This approach stabilizes pre-training and enhances a model's transferability to unexplored chemical regions. Preliminary results on approximately four million structures are encouraging, yet questions remain about generalizability to larger, more diverse datasets and scalability on supercomputers. We propose a multi-task parallelism method that distributes each head across computing resources with GPU acceleration. Implemented in the open-source HydraGNN architecture, our method was trained on over 24 million structures from five datasets and tested on the Perlmutter, Aurora, and Frontier supercomputers, demonstrating efficient scaling on all three highly heterogeneous super-computing architectures.",
      "authors": [
        "Massimiliano Lupo Pasini and Jong Youl Choi and Pei Zhang and Kshitij Mehta and Rylie Weaver and Ashwin M. Aji and Karl W. Schulz and Jorda Polo and Prasanna Balaprakash"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Materials Science (cond-mat.mtrl-sci)",
        "Artificial Intelligence (cs.AI)",
        "Atomic and Molecular Clusters (physics.atm-clus)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T22:04:05+00:00",
          "link": "https://arxiv.org/abs/2506.21788v1",
          "size": "1264kb",
          "version": "v1"
        }
      ],
      "title": "Multi-task parallelism for robust pre-training of graph foundation models on multi-source, multi-fidelity atomistic modeling data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21788",
        "HTML": "https://arxiv.org/html/2506.21788v1",
        "PDF": "https://arxiv.org/pdf/2506.21788"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper addresses processing multi-source, multi-fidelity atomistic modeling data during pre-training by employing multi-task learning. While relevant to multi-source data management, it focuses more on model training strategies rather than novel LLM training data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21794",
      "abstract": "Within the field of media framing, homelessness has been a historically under-researched topic. Framing theory states that the media's method of presenting information plays a pivotal role in controlling public sentiment toward a topic. The sentiment held towards homeless individuals influences their ability to access jobs, housing, and resources as a result of discrimination. This study analyzes the topic and sentiment trends in related media articles to validate framing theory within the scope of homelessness. It correlates these shifts in media reporting with public sentiment. We examine state-level trends in California, Florida, Washington, Oregon, and New York from 2015 to 2023. We utilize the GDELT 2.0 Global Knowledge Graph (GKG) database to gather article data and use X to measure public sentiment towards homeless individuals. Additionally, to identify if there is a correlation between media reporting and public policy, we examine the media's impact on state-level legislation. Our research uses Granger-causality tests and vector autoregressive (VAR) models to establish a correlation between media framing and public sentiment. We also use latent Dirichlet allocation (LDA) and GPT-3.5 (LLM-as-annotator paradigm) for topic modeling and sentiment analysis. Our findings demonstrate a statistically significant correlation between media framing and public sentiment, especially in states with high homelessness rates. We found no significant correlation between media framing and legislation, suggesting a possible disconnect between public opinion and policy-making. These findings reveal the broader impact of the media's framing decisions and delineate its ability to affect society.",
      "authors": [
        "Akshay Irudayaraj (1)",
        "Nathan Ye (2)",
        "Yash Chainani (2) ((1) Brown University",
        "(2) University of California--Berkeley)"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T22:34:17+00:00",
          "link": "https://arxiv.org/abs/2506.21794v1",
          "size": "2232kb",
          "version": "v1"
        }
      ],
      "title": "Shifting Narratives: A Longitudinal Analysis of Media Trends and Public Attitudes on Homelessness",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21794",
        "PDF": "https://arxiv.org/pdf/2506.21794"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The study is concerned with media framing and sentiment analysis related to homelessness using existing databases and models like GPT-3.5. It does not propose any novel methods for LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21795",
      "abstract": "The widespread use of text-based communication on social media-through chats, comments, and microblogs-has improved user interaction but has also led to an increase in offensive content, including hate speech, racism, and other forms of abuse. Due to the enormous volume of user-generated content, manual moderation is impractical, which creates a need for automated systems that can detect offensive language. Deep learning models, particularly those using transfer learning, have demonstrated significant success in understanding natural language through large-scale pretraining. In this study, we propose an automatic offensive language detection model based on XLNet, a generalized autoregressive pretraining method, and compare its performance with BERT (Bidirectional Encoder Representations from Transformers), which is a widely used baseline in natural language processing (NLP). Both models are evaluated using the Offensive Language Identification Dataset (OLID), a benchmark Twitter dataset that includes hierarchical annotations. Our experimental results show that XLNet outperforms BERT in detecting offensive content and in categorizing the types of offenses, while BERT performs slightly better in identifying the targets of the offenses. Additionally, we find that oversampling and undersampling strategies are effective in addressing class imbalance and improving classification performance. These findings highlight the potential of transfer learning and XLNet-based architectures to create robust systems for detecting offensive language on social media platforms.",
      "authors": [
        "Reem Alothman",
        "Hafida Benhidour",
        "Said Kerrache"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T22:37:35+00:00",
          "link": "https://arxiv.org/abs/2506.21795v1",
          "size": "109kb",
          "version": "v1"
        }
      ],
      "title": "Offensive Language Detection on Social Media Using XLNet",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21795",
        "HTML": "https://arxiv.org/html/2506.21795v1",
        "PDF": "https://arxiv.org/pdf/2506.21795"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The research focuses on offensive language detection using existing models (XLNet and BERT), employing techniques like oversampling and undersampling for class imbalance. It briefly mentions data processing but does not introduce new methods specifically for LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21797",
      "abstract": "We develop a theoretical framework that explains how discrete symbolic structures can emerge naturally from continuous neural network training dynamics. By lifting neural parameters to a measure space and modeling training as Wasserstein gradient flow, we show that under geometric constraints, such as group invariance, the parameter measure $\\mu_t$ undergoes two concurrent phenomena: (1) a decoupling of the gradient flow into independent optimization trajectories over some potential functions, and (2) a progressive contraction on the degree of freedom. These potentials encode algebraic constraints relevant to the task and act as ring homomorphisms under a commutative semi-ring structure on the measure space. As training progresses, the network transitions from a high-dimensional exploration to compositional representations that comply with algebraic operations and exhibit a lower degree of freedom. We further establish data scaling laws for realizing symbolic tasks, linking representational capacity to the group invariance that facilitates symbolic solutions. This framework charts a principled foundation for understanding and designing neurosymbolic systems that integrate continuous learning with discrete algebraic reasoning.",
      "authors": [
        "Peihao Wang",
        "Zhangyang Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T22:40:30+00:00",
          "link": "https://arxiv.org/abs/2506.21797v1",
          "size": "32kb",
          "version": "v1"
        }
      ],
      "title": "Why Neural Network Can Discover Symbolic Structures with Gradient-based Training: An Algebraic and Geometric Foundation for Neurosymbolic Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21797",
        "HTML": "https://arxiv.org/html/2506.21797v1",
        "PDF": "https://arxiv.org/pdf/2506.21797"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper develops a theoretical framework for neurosymbolic reasoning, focusing on neural network training dynamics and symbolic structure emergence, without addressing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21805",
      "abstract": "Modeling human behavior in urban environments is fundamental for social science, behavioral studies, and urban planning. Prior work often rely on rigid, hand-crafted rules, limiting their ability to simulate nuanced intentions, plans, and adaptive behaviors. Addressing these challenges, we envision an urban simulator (CitySim), capitalizing on breakthroughs in human-level intelligence exhibited by large language models. In CitySim, agents generate realistic daily schedules using a recursive value-driven approach that balances mandatory activities, personal habits, and situational factors. To enable long-term, lifelike simulations, we endow agents with beliefs, long-term goals, and spatial memory for navigation. CitySim exhibits closer alignment with real humans than prior work, both at micro and macro levels. Additionally, we conduct insightful experiments by modeling tens of thousands of agents and evaluating their collective behaviors under various real-world scenarios, including estimating crowd density, predicting place popularity, and assessing well-being. Our results highlight CitySim as a scalable, flexible testbed for understanding and forecasting urban phenomena.",
      "authors": [
        "Nicolas Bougie and Narimasa Watanabe"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T23:11:42+00:00",
          "link": "https://arxiv.org/abs/2506.21805v1",
          "size": "8200kb",
          "version": "v1"
        }
      ],
      "title": "CitySim: Modeling Urban Behaviors and City Dynamics with Large-Scale LLM-Driven Agent Simulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21805",
        "HTML": "https://arxiv.org/html/2506.21805v1",
        "PDF": "https://arxiv.org/pdf/2506.21805"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "CitySim focuses on urban behavior modeling using agent simulation, leveraging LLMs but not concerning the processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21808",
      "abstract": "Describing and comparing complex systems requires principled, theoretically grounded tools. Built around the phenomenon of type turbulence, allotaxonographs provide map-and-list visual comparisons of pairs of heavy-tailed distributions. Allotaxonographs are designed to accommodate a wide range of instruments including rank- and probability-turbulence divergences, Jenson-Shannon divergence, and generalized entropy divergences. Here, we describe a suite of programmatic tools for rendering allotaxonographs for rank-turbulence divergence in Matlab, Javascript, and Python, all of which have different use cases.",
      "authors": [
        "Jonathan St-Onge",
        "Ashley M. A. Fehr",
        "Carter Ward",
        "Calla G. Beauregard",
        "Michael V. Arnold",
        "Samuel F. Rosenblatt",
        "Benjamin Cooley",
        "Christopher M. Danforth",
        "and Peter Sheridan Dodds"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T23:17:29+00:00",
          "link": "https://arxiv.org/abs/2506.21808v1",
          "size": "624kb",
          "version": "v1"
        }
      ],
      "title": "A suite of allotaxonometric tools for the comparison of complex systems using rank-turbulence divergence",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21808",
        "HTML": "https://arxiv.org/html/2506.21808v1",
        "PDF": "https://arxiv.org/pdf/2506.21808"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This research provides tools for comparing complex systems using rank-turbulence divergence, not relevant to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21811",
      "abstract": "The rise of graph analytics platforms has led to the development of various benchmarks for evaluating and comparing platform performance. However, existing benchmarks often fall short of fully assessing performance due to limitations in core algorithm selection, data generation processes (and the corresponding synthetic datasets), as well as the neglect of API usability evaluation. To address these shortcomings, we propose a novel graph analytics benchmark. First, we select eight core algorithms by extensively reviewing both academic and industrial settings. Second, we design an efficient and flexible data generator and produce eight new synthetic datasets as the default datasets for our benchmark. Lastly, we introduce a multi-level large language model (LLM)-based framework for API usability evaluation-the first of its kind in graph analytics benchmarks. We conduct comprehensive experimental evaluations on existing platforms (GraphX, PowerGraph, Flash, Grape, Pregel+, Ligra and G-thinker). The experimental results demonstrate the superiority of our proposed benchmark.",
      "authors": [
        "Lingkai Meng",
        "Yu Shao",
        "Long Yuan",
        "Longbin Lai",
        "Peng Cheng",
        "Xue Li",
        "Wenyuan Yu",
        "Wenjie Zhang",
        "Xuemin Lin and Jingren Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Databases (cs.DB)",
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-04T08:11:27+00:00",
          "link": "https://arxiv.org/abs/2506.21811v1",
          "size": "3742kb",
          "version": "v1"
        }
      ],
      "title": "Revisiting Graph Analytics Benchmark",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21811",
        "HTML": "https://arxiv.org/html/2506.21811v1",
        "PDF": "https://arxiv.org/pdf/2506.21811"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper proposes a new benchmark for graph analytics platforms, focusing on core algorithm selection and data generation for performance evaluation. It does not mention any contributions to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21812",
      "abstract": "Large Language Models (LLMs) have played a pivotal role in advancing Artificial Intelligence (AI). However, despite their achievements, LLMs often struggle to explain their decision-making processes, making them a 'black box' and presenting a substantial challenge to explainability. This lack of transparency poses a significant obstacle to the adoption of LLMs in high-stakes domain applications, where interpretability is particularly essential. To overcome these limitations, researchers have developed various explainable artificial intelligence (XAI) methods that provide human-interpretable explanations for LLMs. However, a systematic understanding of these methods remains limited. To address this gap, this survey provides a comprehensive review of explainability techniques by categorizing XAI methods based on the underlying transformer architectures of LLMs: encoder-only, decoder-only, and encoder-decoder models. Then these techniques are examined in terms of their evaluation for assessing explainability, and the survey further explores how these explanations are leveraged in practical applications. Finally, it discusses available resources, ongoing research challenges, and future directions, aiming to guide continued efforts toward developing transparent and responsible LLMs.",
      "authors": [
        "Avash Palikhe",
        "Zhenyu Yu",
        "Zichong Wang",
        "Wenbin Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T23:25:22+00:00",
          "link": "https://arxiv.org/abs/2506.21812v1",
          "size": "304kb",
          "version": "v1"
        }
      ],
      "title": "Towards Transparent AI: A Survey on Explainable Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21812",
        "HTML": "https://arxiv.org/html/2506.21812v1",
        "PDF": "https://arxiv.org/pdf/2506.21812"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper is a survey on explainability techniques for LLMs, categorizing XAI methods and evaluating explainability. It doesn't discuss data engineering or preprocessing specific to LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21813",
      "abstract": "Understanding the intricate workflows of cataract surgery requires modeling complex interactions between surgical tools, anatomical structures, and procedural techniques. Existing datasets primarily address isolated aspects of surgical analysis, such as tool detection or phase segmentation, but lack comprehensive representations that capture the semantic relationships between entities over time. This paper introduces the Cataract Surgery Scene Graph (CAT-SG) dataset, the first to provide structured annotations of tool-tissue interactions, procedural variations, and temporal dependencies. By incorporating detailed semantic relations, CAT-SG offers a holistic view of surgical workflows, enabling more accurate recognition of surgical phases and techniques. Additionally, we present a novel scene graph generation model, CatSGG, which outperforms current methods in generating structured surgical representations. The CAT-SG dataset is designed to enhance AI-driven surgical training, real-time decision support, and workflow analysis, paving the way for more intelligent, context-aware systems in clinical practice.",
      "authors": [
        "Felix Holm",
        "G\\\"ozde \\\"Unver",
        "Ghazal Ghazaei",
        "Nassir Navab"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T23:25:23+00:00",
          "link": "https://arxiv.org/abs/2506.21813v1",
          "size": "974kb",
          "version": "v1"
        }
      ],
      "title": "CAT-SG: A Large Dynamic Scene Graph Dataset for Fine-Grained Understanding of Cataract Surgery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21813",
        "HTML": "https://arxiv.org/html/2506.21813v1",
        "PDF": "https://arxiv.org/pdf/2506.21813"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper introduces a dataset and model for cataract surgery scene graph representation. It focuses on surgical workflows and not on LLM training data processing or data engineering methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21814",
      "abstract": "Despite advances in surgical techniques and care, postoperative complications are prevalent and effects up to 15% of the patients who underwent a major surgery. The objective of this study is to develop and validate models for predicting postoperative complications and death after major surgery on a large and multicenter dataset, following the previously validated MySurgeryRisk algorithm. This retrospective, longitudinal and multicenter cohort analysis included 508,097 encounters from 366,875 adult inpatients who underwent major surgeries and were admitted to healthcare institutions within the OneFlorida+ network between 01/01/2012 and 04/29/2023. We applied the validated feature selection and transformation approach in MySurgeryRisk models and redeveloped eXtreme Gradient Boosting (XGBoost) models for predicting risk of postoperative acute kidney injury (AKI), need for intensive care unit (ICU) admission, need for mechanical ventilation (MV) therapy and in-hospital mortality on a development set and evaluated the model performance on a validation set. Area under the receiver operating characteristics curve values were obtained for need for ICU admission, 0.93 (95% Confidence Interval [CI], 0.93-0.93); need for MV, 0.94 (95% CI, 0.94-0.94); AKI, 0.92 (95% CI, 0.92-0.92); and in-hospital mortality, 0.95 (95% CI, 0.94-0.95). Area under the precision-recall curve values were computed for need for ICU admission, 0.62 (95% CI, 0.62-0.63); need for MV, 0.51 (95% CI, 0.49-0.52); AKI, 0.53 (95% CI, 0.53-0.54); and in-hospital mortality, 0.26 (95% CI, 0.24-0.29). The performance of these models is comparable to that of the previously validated MySurgeryRisk models, suggesting the enhanced generalizability of the models. Primary procedure code and provider specialty consistently appeared as the top influential variables, providing valuable insights into the factors influencing surgical outcomes.",
      "authors": [
        "Yuanfang Ren",
        "Esra Adiyeke",
        "Ziyuan Guan",
        "Zhenhong Hu",
        "Mackenzie J Meni",
        "Benjamin Shickel",
        "Parisa Rashidi",
        "Tezcan Ozrazgat-Baslanti",
        "Azra Bihorac"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-31T21:24:09+00:00",
          "link": "https://arxiv.org/abs/2506.21814v1",
          "size": "2715kb",
          "version": "v1"
        }
      ],
      "title": "Validation of the MySurgeryRisk Algorithm for Predicting Complications and Death after Major Surgery: A Retrospective Multicenter Study Using OneFlorida Data Trust",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21814",
        "PDF": "https://arxiv.org/pdf/2506.21814"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper involves validation of prediction models using healthcare data, focusing on surgical outcomes. It does not relate to the processing of training data for LLMs or propose new data engineering methods for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21815",
      "abstract": "Laser powder bed fusion (L-PBF) is a widely recognized additive manufacturing technology for producing intricate metal components with exceptional accuracy. A key challenge in L-PBF is the formation of complex microstructures affecting product quality. We propose a physics-guided, machine-learning approach to optimize scan paths for desired microstructure outcomes, such as equiaxed grains. We utilized a phase-field method (PFM) to model crystalline grain structure evolution. To reduce computational costs, we trained a surrogate machine learning model, a 3D U-Net convolutional neural network, using single-track phase-field simulations with various laser powers to predict crystalline grain orientations based on initial microstructure and thermal history. We investigated three scanning strategies across various hatch spacings within a square domain, achieving a two-orders-of-magnitude speedup using the surrogate model. To reduce trial and error in designing laser scan toolpaths, we used deep reinforcement learning (DRL) to generate optimized scan paths for target microstructure. Results from three cases demonstrate the DRL approach's effectiveness. We integrated the surrogate 3D U-Net model into our DRL environment to accelerate the reinforcement learning training process. The reward function minimizes both aspect ratio and grain volume of the predicted microstructure from the agent's scan path. The reinforcement learning algorithm was benchmarked against conventional zigzag approach for smaller and larger domains, showing machine learning methods' potential to enhance microstructure control and computational efficiency in L-PBF optimization.",
      "authors": [
        "Augustine Twumasi",
        "Prokash Chandra Roy",
        "Zixun Li",
        "Soumya Shouvik Bhattacharjee",
        "Zhengtao Gan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-12T00:27:23+00:00",
          "link": "https://arxiv.org/abs/2506.21815v1",
          "size": "17355kb",
          "version": "v1"
        }
      ],
      "title": "Laser Scan Path Design for Controlled Microstructure in Additive Manufacturing with Integrated Reduced-Order Phase-Field Modeling and Deep Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21815",
        "HTML": "https://arxiv.org/html/2506.21815v1",
        "PDF": "https://arxiv.org/pdf/2506.21815"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on optimizing laser scan paths for additive manufacturing using machine learning and deep reinforcement learning. It does not discuss LLM training data processing or contribute new methods related to LLM data."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21816",
      "abstract": "This paper traces the global race to apply early electronic computers to numerical weather prediction in the decades following World War Two. A brief overview of the early history of numerical weather prediction in the United States, United Kingdom, Sweden, Canada, and Japan is provided. Three critical factors that shaped the development of a national numerical weather prediction are identified: compute capabilities, institution building and state capacity, and talent. Several generalizable lessons are identified with a lens towards modern-day development of national strategies to leverage AI to accelerate scientific competitiveness.",
      "authors": [
        "Charles Yang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Atmospheric and Oceanic Physics (physics.ao-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-13T04:08:29+00:00",
          "link": "https://arxiv.org/abs/2506.21816v1",
          "size": "377kb",
          "version": "v1"
        }
      ],
      "title": "The First Compute Arms Race: the Early History of Numerical Weather Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21816",
        "HTML": "https://arxiv.org/html/2506.21816v1",
        "PDF": "https://arxiv.org/pdf/2506.21816"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper deals with the historical development of numerical weather prediction and strategies to leverage AI in scientific competitiveness. It does not address LLM training data processing or related data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21817",
      "abstract": "Scientific English has undergone rapid and unprecedented changes in recent years, with words such as \"delve,\" \"intricate,\" and \"crucial\" showing significant spikes in frequency since around 2022. These changes are widely attributed to the growing influence of Large Language Models like ChatGPT in the discourse surrounding bias and misalignment. However, apart from changes in frequency, the exact structure of these linguistic shifts has remained unclear. The present study addresses this and investigates whether these changes involve the replacement of synonyms by suddenly 'spiking words,' for example, \"crucial\" replacing \"essential\" and \"key,\" or whether they reflect broader semantic and pragmatic qualifications. To further investigate structural changes, we include part of speech tagging in our analysis to quantify linguistic shifts over grammatical categories and differentiate between word forms, like \"potential\" as a noun vs. as an adjective. We systematically analyze synonym groups for widely discussed 'spiking words' based on frequency trends in scientific abstracts from PubMed. We find that entire semantic clusters often shift together, with most or all words in a group increasing in usage. This pattern suggests that changes induced by Large Language Models are primarily semantic and pragmatic rather than purely lexical. Notably, the adjective \"important\" shows a significant decline, which prompted us to systematically analyze decreasing lexical items. Our analysis of \"collapsing\" words reveals a more complex picture, which is consistent with organic language change and contrasts with the patterns of the abrupt spikes. These insights into the structure of language change contribute to our understanding of how language technology continues to shape human language.",
      "authors": [
        "Riley Galpin",
        "Bryce Anderson",
        "Tom S. Juzek"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T23:44:24+00:00",
          "link": "https://arxiv.org/abs/2506.21817v1",
          "size": "674kb",
          "version": "v1"
        }
      ],
      "title": "Exploring the Structure of AI-Induced Language Change in Scientific English",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21817",
        "HTML": "https://arxiv.org/html/2506.21817v1",
        "PDF": "https://arxiv.org/pdf/2506.21817"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The study investigates AI-induced changes in scientific English, mentioning the influence of LLMs on language usage. However, it does not focus on LLM training data processing or introduce new methodologies for data handling."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21818",
      "abstract": "Given the increasing demands in computer programming education and the rapid advancement of large language models (LLMs), LLMs play a critical role in programming education. This study provides a systematic review of selected empirical studies on LLMs in computer programming education, published from 2023 to March 2024. The data for this review were collected from Web of Science (SCI/SSCI), SCOPUS, and EBSCOhost databases, as well as three conference proceedings specialized in computer programming education. In total, 42 studies met the selection criteria and were reviewed using methods, including bibliometric analysis, thematic analysis, and structural topic modeling. This study offers an overview of the current state of LLMs in computer programming education research. It outlines LLMs' applications, benefits, limitations, concerns, and implications for future research and practices, establishing connections between LLMs and their practical use in computer programming education. This review also provides examples and valuable insights for instructional designers, instructors, and learners. Additionally, a conceptual framework is proposed to guide education practitioners in integrating LLMs into computer programming education. This study suggests future research directions from various perspectives, emphasizing the need to expand research methods and topics in computer programming education as LLMs evolve. Additionally, future research in the field should incorporate collaborative, interdisciplinary, and transdisciplinary efforts on a large scale, focusing on longitudinal research and development initiatives.",
      "authors": [
        "Meina Zhu",
        "Lanyu Xu",
        "Barbara Ericson"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-13T20:13:45+00:00",
          "link": "https://arxiv.org/abs/2506.21818v1",
          "size": "1326kb",
          "version": "v1"
        }
      ],
      "title": "A systematic review of research on large language models for computer programming education",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21818",
        "PDF": "https://arxiv.org/pdf/2506.21818"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper is a systematic review of LLMs in computer programming education. It discusses applications and implications of LLMs but does not address LLM training data processing or data engineering directly."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21819",
      "abstract": "Scientific publications, primarily digitized as PDFs, remain static and unstructured, limiting the accessibility and reusability of the contained knowledge. At best, scientific knowledge from publications is provided in tabular formats, which lack semantic context. A more flexible, structured, and semantic representation is needed to make scientific knowledge understandable and processable by both humans and machines. We propose an evolution model of knowledge representation, inspired by the 5-star Linked Open Data (LOD) model, with five stages and defined criteria to guide the stepwise transition from a digital artifact, such as a PDF, to a semantic representation integrated in a knowledge graph (KG). Based on an exemplary workflow implementing the entire model, we developed a hybrid approach, called SciMantify, leveraging tabular formats of scientific knowledge, e.g., results from secondary studies, to support its evolving semantification. In the approach, humans and machines collaborate closely by performing semantic annotation tasks (SATs) and refining the results to progressively improve the semantic representation of scientific knowledge. We implemented the approach in the Open Research Knowledge Graph (ORKG), an established platform for improving the findability, accessibility, interoperability, and reusability of scientific knowledge. A preliminary user experiment showed that the approach simplifies the preprocessing of scientific knowledge, reduces the effort for the evolving semantification, and enhances the knowledge representation through better alignment with the KG structures.",
      "authors": [
        "Lena John",
        "Kheir Eddine Farfar",
        "S\\\"oren Auer",
        "Oliver Karras"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Digital Libraries (cs.DL)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-14T07:57:55+00:00",
          "link": "https://arxiv.org/abs/2506.21819v1",
          "size": "666kb",
          "version": "v1"
        }
      ],
      "title": "SciMantify -- A Hybrid Approach for the Evolving Semantification of Scientific Knowledge",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21819",
        "HTML": "https://arxiv.org/html/2506.21819v1",
        "PDF": "https://arxiv.org/pdf/2506.21819"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "SciMantify focuses on the semantification of scientific publications and knowledge representation in knowledge graphs. It is not related to processing training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21825",
      "abstract": "The rise and growing popularity of accessible large language models have raised questions about their impact on various aspects of life, including how scientists write and publish their research. The primary objective of this paper is to analyze a dataset consisting of all abstracts posted on arXiv.org between 2010 and June 7th, 2024, to assess the evolution of their readability and determine whether significant shifts occurred following the release of ChatGPT in November 2022. Four standard readability formulas are used to calculate individual readability scores for each paper, classifying their level of readability. These scores are then aggregated by year and across the eight primary categories covered by the platform. The results show a steady annual decrease in readability, suggesting that abstracts are likely becoming increasingly complex. Additionally, following the release of ChatGPT, a significant change in readability is observed for 2023 and the analyzed months of 2024. Similar trends are found across categories, with most experiencing a notable change in readability during 2023 and 2024. These findings offer insights into the broader changes in readability and point to the likely influence of AI on scientific writing.",
      "authors": [
        "Abdulkareem Alsudais"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T23:57:12+00:00",
          "link": "https://arxiv.org/abs/2506.21825v1",
          "size": "1253kb",
          "version": "v1"
        }
      ],
      "title": "Exploring the change in scientific readability following the release of ChatGPT",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21825",
        "PDF": "https://arxiv.org/pdf/2506.21825"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper analyzes the change in scientific readability using existing abstracts from arXiv.org and does not contribute any new methods or processes related to the training data collection, construction, or processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21826",
      "abstract": "As rich sources of history, maps provide crucial insights into historical changes, yet their diverse visual representations and limited annotated data pose significant challenges for automated processing. We propose a simple yet effective approach for few-shot segmentation of historical maps, leveraging the rich semantic embeddings of large vision foundation models combined with parameter-efficient fine-tuning. Our method outperforms the state-of-the-art on the Siegfried benchmark dataset in vineyard and railway segmentation, achieving +5% and +13% relative improvements in mIoU in 10-shot scenarios and around +20% in the more challenging 5-shot setting. Additionally, it demonstrates strong performance on the ICDAR 2021 competition dataset, attaining a mean PQ of 67.3% for building block segmentation, despite not being optimized for this shape-sensitive metric, underscoring its generalizability. Notably, our approach maintains high performance even in extremely low-data regimes (10- & 5-shot), while requiring only 689k trainable parameters - just 0.21% of the total model size. Our approach enables precise segmentation of diverse historical maps while drastically reducing the need for manual annotations, advancing automated processing and analysis in the field. Our implementation is publicly available at: https://github.com/RafaelSterzinger/few-shot-map-segmentation.",
      "authors": [
        "Rafael Sterzinger",
        "Marco Peer",
        "Robert Sablatnig"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T00:07:21+00:00",
          "link": "https://arxiv.org/abs/2506.21826v1",
          "size": "14180kb",
          "version": "v1"
        }
      ],
      "title": "Few-Shot Segmentation of Historical Maps via Linear Probing of Vision Foundation Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21826",
        "PDF": "https://arxiv.org/pdf/2506.21826"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper focuses on segmentation of historical maps using few-shot learning and does not discuss any LLM training data processes such as data collection or preparation for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21830",
      "abstract": "Designing a mixed quantum channel is challenging due to the complexity of the transformations and the probabilistic mixtures of more straightforward channels involved. Fully characterizing a quantum channel generally requires preparing a complete set of input states, such as a basis for the state space, and measuring the corresponding output states. In this work, we begin by investigating a single input-output pair using projected gradient dynamics. This approach applies optimization flows constrained to the Stiefel manifold and the probabilistic simplex to identify the original quantum channel. The convergence of the flow is guaranteed by its relationship to the Zariski topology. We present numerical investigations of models adapted to various scenarios, including those with multiple input-output pairs, highlighting the flexibility and efficiency of our proposed method.",
      "authors": [
        "Matthew M. Lin",
        "Bing-Ze Lu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T00:38:45+00:00",
          "link": "https://arxiv.org/abs/2506.21830v1",
          "size": "232kb",
          "version": "v1"
        }
      ],
      "title": "Optimizing Mixed Quantum Channels via Projected Gradient Dynamics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21830",
        "HTML": "https://arxiv.org/html/2506.21830v1",
        "PDF": "https://arxiv.org/pdf/2506.21830"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This research is centered on optimizing quantum channels and does not address the processing of training data for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21832",
      "abstract": "Storytelling is a deeply personal and creative process, yet existing methods often treat users as passive consumers, offering generic plots with limited personalization. This undermines engagement and immersion, especially where individual style or appearance is crucial. We introduce TaleForge, a personalized story-generation system that integrates large language models (LLMs) and text-to-image diffusion to embed users' facial images within both narratives and illustrations. TaleForge features three interconnected modules: Story Generation, where LLMs create narratives and character descriptions from user prompts; Personalized Image Generation, merging users' faces and outfit choices into character illustrations; and Background Generation, creating scene backdrops that incorporate personalized characters. A user study demonstrated heightened engagement and ownership when individuals appeared as protagonists. Participants praised the system's real-time previews and intuitive controls, though they requested finer narrative editing tools. TaleForge advances multimodal storytelling by aligning personalized text and imagery to create immersive, user-centric experiences.",
      "authors": [
        "Minh-Loi Nguyen and Quang-Khai Le and Tam V. Nguyen and Minh-Triet Tran and Trung-Nghia Le"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T00:45:38+00:00",
          "link": "https://arxiv.org/abs/2506.21832v1",
          "size": "1300kb",
          "version": "v1"
        }
      ],
      "title": "TaleForge: Interactive Multimodal System for Personalized Story Creation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21832",
        "HTML": "https://arxiv.org/html/2506.21832v1",
        "PDF": "https://arxiv.org/pdf/2506.21832"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "Although the paper involves large language models for story generation, it does not focus on the collection or processing of training data specifically for LLMs, but rather on the application of existing models in storytelling."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21833",
      "abstract": "Forward-mode automatic differentiation (FmAD) and zero-order (ZO) optimization have been proposed as memory-efficient alternatives to backpropagation (BP) for gradient computation, especially in low-resource settings. However, their practical benefits remain unclear due to two key gaps: a lack of comparison against memory-efficient BP variants, such as activation checkpointing, and a lack of a unified theoretical analysis. This work presents a comprehensive theoretical and empirical comparison of BP, FmAD, and ZO methods. Our theoretical analysis shows that while FmAD, and ZO can reduce memory usage, they incur significant costs in accuracy, convergence speed, and computation compared to BP with checkpointing. These drawbacks worsen with larger models or constrained perturbation budgets. Empirical experiments on large language and vision-language models show that BP with checkpointing outperforms FmAD and ZO variants, including those enhanced with variance reduction, achieving up to 31.1% higher accuracy, 34.8% faster convergence, and 3.8x fewer computations at comparable memory usage. Our results highlight fundamental limitations of FmAD and ZO, and reaffirm BP with checkpointing as the most effective strategy for model training under memory-constrained settings. Our code is available at https://github.com/Astuary/The_Cost_of_Avoiding_Backpropagation.",
      "authors": [
        "Kunjal Panchal",
        "Sunav Choudhary",
        "Yuriy Brun",
        "Hui Guan"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T00:47:03+00:00",
          "link": "https://arxiv.org/abs/2506.21833v1",
          "size": "1018kb",
          "version": "v1"
        }
      ],
      "title": "The Cost of Avoiding Backpropagation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21833",
        "HTML": "https://arxiv.org/html/2506.21833v1",
        "PDF": "https://arxiv.org/pdf/2506.21833"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on alternatives to backpropagation for gradient computation and does not address the collection, construction, or processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21834",
      "abstract": "Inpainting, the process of filling missing or corrupted image parts, has broad applications, including medical imaging. However, in specialized fields like medical polyps imaging, where accuracy and reliability are critical, inpainting models can generate inaccurate images, leading to significant errors in medical diagnosis and treatment. To ensure reliability, medical images should be annotated by experts like oncologists for effective model training. We propose PrefPaint, an approach that incorporates human feedback into the training process of Stable Diffusion Inpainting, bypassing the need for computationally expensive reward models. In addition, we develop a web-based interface streamlines training, fine-tuning, and inference. This interactive interface provides a smooth and intuitive user experience, making it easier to offer feedback and manage the fine-tuning process. User study on various domains shows that PrefPaint outperforms existing methods, reducing visual inconsistencies and improving image rendering, particularly in medical contexts, where our model generates more realistic polyps images.",
      "authors": [
        "Duy-Bao Bui and Hoang-Khang Nguyen and Trung-Nghia Le"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T00:47:07+00:00",
          "link": "https://arxiv.org/abs/2506.21834v1",
          "size": "41373kb",
          "version": "v1"
        }
      ],
      "title": "PrefPaint: Enhancing Image Inpainting through Expert Human Feedback",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21834",
        "HTML": "https://arxiv.org/html/2506.21834v1",
        "PDF": "https://arxiv.org/pdf/2506.21834"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses incorporating human feedback in the training process of an image inpainting model, indicating some level of data processing. However, it does not propose novel methods specific to LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21835",
      "abstract": "The recent advancements in large foundation models have driven the success of open-set image segmentation, a task focused on segmenting objects beyond predefined categories. Among various prompt types (such as points, boxes, texts, and visual references), visual reference segmentation stands out for its unique flexibility and strong zero-shot capabilities. Recently, several SAM-based methods have made notable progress in this task by automatically generating prompts to guide SAM. However, these methods often generate prompts at object boundaries due to suboptimal prompt encoder, which results in instability and reduced robustness. In this work, we introduce ProSAM, a simple but effective method to address the stability challenges we identified in existing SAM-based visual reference segmentation approaches. By learning a variational prompt encoder to predict multivariate prompt distributions, ProSAM avoids generating prompts that lie in unstable regions, overcoming the instability caused by less robust prompts. Our approach consistently surpasses state-of-the-art methods on the Pascal-5$^i$ and COCO-20$^i$ datasets, providing a more robust solution for visual reference segmentation.",
      "authors": [
        "Xiaoqi Wang",
        "Clint Sebastian",
        "Wenbin He and Liu Ren"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T00:50:15+00:00",
          "link": "https://arxiv.org/abs/2506.21835v1",
          "size": "10893kb",
          "version": "v1"
        }
      ],
      "title": "ProSAM: Enhancing the Robustness of SAM-based Visual Reference Segmentation with Probabilistic Prompts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21835",
        "HTML": "https://arxiv.org/html/2506.21835v1",
        "PDF": "https://arxiv.org/pdf/2506.21835"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This work focuses on visual reference segmentation using SAM-based methods and does not address training data processing related to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21839",
      "abstract": "We challenge text-to-image models with generating escape room puzzle images that are visually appealing, logically solid, and intellectually stimulating. While base image models struggle with spatial relationships and affordance reasoning, we propose a hierarchical multi-agent framework that decomposes this task into structured stages: functional design, symbolic scene graph reasoning, layout synthesis, and local image editing. Specialized agents collaborate through iterative feedback to ensure the scene is visually coherent and functionally solvable. Experiments show that agent collaboration improves output quality in terms of solvability, shortcut avoidance, and affordance clarity, while maintaining visual quality.",
      "authors": [
        "Mengyi Shan",
        "Brian Curless",
        "Ira Kemelmacher-Shlizerman",
        "Steve Seitz"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T01:08:37+00:00",
          "link": "https://arxiv.org/abs/2506.21839v1",
          "size": "8474kb",
          "version": "v1"
        }
      ],
      "title": "GenEscape: Hierarchical Multi-Agent Generation of Escape Room Puzzles",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21839",
        "HTML": "https://arxiv.org/html/2506.21839v1",
        "PDF": "https://arxiv.org/pdf/2506.21839"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper proposes a framework for generating escape room puzzle images, which does not involve processing training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21840",
      "abstract": "The intricate linguistic, stylistic, and metrical aspects of Persian classical poetry pose a challenge for computational authorship attribution. In this work, we present a versatile framework to determine authorship among 67 prominent poets. We employ a multi-input neural framework consisting of a transformer-based language encoder complemented by features addressing the semantic, stylometric, and metrical dimensions of Persian poetry. Our feature set encompasses 100-dimensional Word2Vec embeddings, seven stylometric measures, and categorical encodings of poetic form and meter. We compiled a vast corpus of 647,653 verses of the Ganjoor digital collection, validating the data through strict preprocessing and author verification while preserving poem-level splitting to prevent overlap. This work employs verse-level classification and majority and weighted voting schemes in evaluation, revealing that weighted voting yields 71% accuracy. We further investigate threshold-based decision filtering, allowing the model to generate highly confident predictions, achieving 97% accuracy at a 0.9 threshold, though at lower coverage. Our work focuses on the integration of deep representational forms with domain-specific features for improved authorship attribution. The results illustrate the potential of our approach for automated classification and the contribution to stylistic analysis, authorship disputes, and general computational literature research. This research will facilitate further research on multilingual author attribution, style shift, and generative modeling of Persian poetry.",
      "authors": [
        "Kourosh Shahnazari",
        "Mohammadali Keshtparvar",
        "Seyed Moein Ayyoubzadeh"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T01:08:52+00:00",
          "link": "https://arxiv.org/abs/2506.21840v1",
          "size": "325kb",
          "version": "v1"
        }
      ],
      "title": "PARSI: Persian Authorship Recognition via Stylometric Integration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21840",
        "HTML": "https://arxiv.org/html/2506.21840v1",
        "PDF": "https://arxiv.org/pdf/2506.21840"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper involves the compilation and preprocessing of a Persian poetry corpus, which relates to data collection and cleaning. However, it does not introduce new methods for LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21843",
      "abstract": "Reconstructing 3D visual stimuli from Electroencephalography (EEG) data holds significant potential for applications in Brain-Computer Interfaces (BCIs) and aiding individuals with communication disorders. Traditionally, efforts have focused on converting brain activity into 2D images, neglecting the translation of EEG data into 3D objects. This limitation is noteworthy, as the human brain inherently processes three-dimensional spatial information regardless of whether observing 2D images or the real world. The neural activities captured by EEG contain rich spatial information that is inevitably lost when reconstructing only 2D images, thus limiting its practical applications in BCI. The transition from EEG data to 3D object reconstruction faces considerable obstacles. These include the presence of extensive noise within EEG signals and a scarcity of datasets that include both EEG and 3D information, which complicates the extraction process of 3D visual data. Addressing this challenging task, we propose an innovative EEG encoder architecture that integrates a dual self-attention mechanism. We use a hybrid training strategy to train the EEG Encoder, which includes cross-attention, contrastive learning, and self-supervised learning techniques. Additionally, by employing stable diffusion as a prior distribution and utilizing Variational Score Distillation to train a neural radiation field, we successfully generate 3D objects with similar content and structure from EEG data.",
      "authors": [
        "Yuxiang Ge",
        "Jionghao Cheng",
        "Ruiquan Ge",
        "Zhaojie Fang",
        "Gangyong Jia",
        "Xiang Wan",
        "Nannan Li",
        "Ahmed Elazab",
        "Changmiao Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T01:26:52+00:00",
          "link": "https://arxiv.org/abs/2506.21843v1",
          "size": "2119kb",
          "version": "v1"
        }
      ],
      "title": "3D-Telepathy: Reconstructing 3D Objects from EEG Signals",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21843",
        "HTML": "https://arxiv.org/html/2506.21843v1",
        "PDF": "https://arxiv.org/pdf/2506.21843"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper deals with reconstructing 3D objects from EEG signals, which is not related to the processing or preparation of training data for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21844",
      "abstract": "It is sometimes difficult to achieve a complete observation for a full set of observables, and partial observations are necessary. For deterministic systems, the Mori-Zwanzig formalism provides a theoretical framework for handling partial observations. Recently, data-driven algorithms based on the Koopman operator theory have made significant progress, and there is a discussion to connect the Mori-Zwanzig formalism with the Koopman operator theory. In this work, we discuss the effects of partial observation in stochastic systems using the Koopman operator theory. The discussion clarifies the importance of distinguishing the state space and the function space in stochastic systems. Even in stochastic systems, the delay embedding technique is beneficial for partial observation, and several numerical experiments showed a power-law behavior of the accuracy for the amplitude of the additive noise. We also discuss the relation between the exponent of the power-law behavior and the effects of partial observation.",
      "authors": [
        "Jun Ohkubo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T01:30:51+00:00",
          "link": "https://arxiv.org/abs/2506.21844v1",
          "size": "386kb",
          "version": "v1"
        }
      ],
      "title": "Koopman operator-based discussion on partial observation in stochastic systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21844",
        "HTML": "https://arxiv.org/html/2506.21844v1",
        "PDF": "https://arxiv.org/pdf/2506.21844"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper discusses partial observation in stochastic systems via Koopman operator theory, which is unrelated to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21845",
      "abstract": "This paper presents 3Description, an experimental human-AI collaborative approach for intuitive 3D modeling. 3Description aims to address accessibility and usability challenges in traditional 3D modeling by enabling non-professional individuals to co-create 3D models using verbal and gesture descriptions. Through a combination of qualitative research, product analysis, and user testing, 3Description integrates AI technologies such as Natural Language Processing and Computer Vision, powered by OpenAI and MediaPipe. Recognizing the web has wide cross-platform capabilities, 3Description is web-based, allowing users to describe the desired model and subsequently adjust its components using verbal and gestural inputs. In the era of AI and emerging media, 3Description not only contributes to a more inclusive and user-friendly design process, empowering more people to participate in the construction of the future 3D world, but also strives to increase human engagement in co-creation with AI, thereby avoiding undue surrender to technology and preserving human creativity.",
      "authors": [
        "Zhuodi Cai"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T01:33:46+00:00",
          "link": "https://arxiv.org/abs/2506.21845v1",
          "size": "7203kb",
          "version": "v1"
        }
      ],
      "title": "3Description: An Intuitive Human-AI Collaborative 3D Modeling Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21845",
        "HTML": "https://arxiv.org/html/2506.21845v1",
        "PDF": "https://arxiv.org/pdf/2506.21845"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper presents a method for collaborative 3D modeling using verbal and gestural inputs, and it does not pertain to the creation or processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21848",
      "abstract": "Deep learning has significantly advanced NLP, but its reliance on large black-box models introduces critical interpretability and computational efficiency concerns. This paper proposes LinguaSynth, a novel text classification framework that strategically integrates five complementary linguistic feature types: lexical, syntactic, entity-level, word-level semantics, and document-level semantics within a transparent logistic regression model. Unlike transformer-based architectures, LinguaSynth maintains interpretability and computational efficiency, achieving an accuracy of 84.89 percent on the 20 Newsgroups dataset and surpassing a robust TF-IDF baseline by 3.32 percent. Through rigorous feature interaction analysis, we show that syntactic and entity-level signals provide essential disambiguation and effectively complement distributional semantics. LinguaSynth sets a new benchmark for interpretable, resource-efficient NLP models and challenges the prevailing assumption that deep neural networks are necessary for high-performing text classification.",
      "authors": [
        "Duo Zhang",
        "Junyi Mo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T01:45:20+00:00",
          "link": "https://arxiv.org/abs/2506.21848v1",
          "size": "75kb",
          "version": "v1"
        }
      ],
      "title": "LinguaSynth: Heterogeneous Linguistic Signals for News Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21848",
        "HTML": "https://arxiv.org/html/2506.21848v1",
        "PDF": "https://arxiv.org/pdf/2506.21848"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper proposes a text classification framework based on linguistic features, not directly addressing the data engineering or processing stages specific to LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21849",
      "abstract": "Estimating the confidence of large language model (LLM) outputs is essential for real-world applications requiring high user trust. Black-box uncertainty quantification (UQ) methods, relying solely on model API access, have gained popularity due to their practical benefits. In this paper, we examine the implicit assumption behind several UQ methods, which use generation consistency as a proxy for confidence, an idea we formalize as the consistency hypothesis. We introduce three mathematical statements with corresponding statistical tests to capture variations of this hypothesis and metrics to evaluate LLM output conformity across tasks. Our empirical investigation, spanning 8 benchmark datasets and 3 tasks (question answering, text summarization, and text-to-SQL), highlights the prevalence of the hypothesis under different settings. Among the statements, we highlight the `Sim-Any' hypothesis as the most actionable, and demonstrate how it can be leveraged by proposing data-free black-box UQ methods that aggregate similarities between generations for confidence estimation. These approaches can outperform the closest baselines, showcasing the practical value of the empirically observed consistency hypothesis.",
      "authors": [
        "Quan Xiao",
        "Debarun Bhattacharjya",
        "Balaji Ganesan",
        "Radu Marinescu",
        "Katsiaryna Mirylenka",
        "Nhan H Pham",
        "Michael Glass",
        "Junkyu Lee"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T01:53:15+00:00",
          "link": "https://arxiv.org/abs/2506.21849v1",
          "size": "5281kb",
          "version": "v1"
        }
      ],
      "title": "The Consistency Hypothesis in Uncertainty Quantification for Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21849",
        "HTML": "https://arxiv.org/html/2506.21849v1",
        "PDF": "https://arxiv.org/pdf/2506.21849"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on black-box uncertainty quantification methods for LLM outputs, examining the consistency hypothesis, and does not involve any aspects of LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21851",
      "abstract": "RGB-IR(RGB-Infrared) image pairs are frequently applied simultaneously in various applications like intelligent surveillance. However, as the number of modalities increases, the required data storage and transmission costs also double. Therefore, efficient RGB-IR data compression is essential. This work proposes a joint compression framework for RGB-IR image pair. Specifically, to fully utilize cross-modality prior information for accurate context probability modeling within and between modalities, we propose a Channel-wise Cross-modality Entropy Model (CCEM). Among CCEM, a Low-frequency Context Extraction Block (LCEB) and a Low-frequency Context Fusion Block (LCFB) are designed for extracting and aggregating the global low-frequency information from both modalities, which assist the model in predicting entropy parameters more accurately. Experimental results demonstrate that our approach outperforms existing RGB-IR image pair and single-modality compression methods on LLVIP and KAIST datasets. For instance, the proposed framework achieves a 23.1% bit rate saving on LLVIP dataset compared to the state-of-the-art RGB-IR image codec presented at CVPR 2022.",
      "authors": [
        "Haofeng Wang",
        "Fangtao Zhou",
        "Qi Zhang",
        "Zeyuan Chen",
        "Enci Zhang",
        "Zhao Wang",
        "Xiaofeng Huang",
        "Siwei Ma"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Multimedia (cs.MM)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T02:04:21+00:00",
          "link": "https://arxiv.org/abs/2506.21851v1",
          "size": "3460kb",
          "version": "v1"
        }
      ],
      "title": "End-to-End RGB-IR Joint Image Compression With Channel-wise Cross-modality Entropy Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21851",
        "HTML": "https://arxiv.org/html/2506.21851v1",
        "PDF": "https://arxiv.org/pdf/2506.21851"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper discusses a joint compression framework for RGB-IR image pairs and does not involve any topics related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21853",
      "abstract": "Quadrupedal robots have demonstrated exceptional locomotion capabilities through Reinforcement Learning (RL), including extreme parkour maneuvers. However, integrating locomotion skills with navigation in quadrupedal robots has not been fully investigated, which holds promise for enhancing long-distance movement capabilities. In this paper, we propose Skill-Nav, a method that incorporates quadrupedal locomotion skills into a hierarchical navigation framework using waypoints as an interface. Specifically, we train a waypoint-guided locomotion policy using deep RL, enabling the robot to autonomously adjust its locomotion skills to reach targeted positions while avoiding obstacles. Compared with direct velocity commands, waypoints offer a simpler yet more flexible interface for high-level planning and low-level control. Utilizing waypoints as the interface allows for the application of various general planning tools, such as large language models (LLMs) and path planning algorithms, to guide our locomotion policy in traversing terrains with diverse obstacles. Extensive experiments conducted in both simulated and real-world scenarios demonstrate that Skill-Nav can effectively traverse complex terrains and complete challenging navigation tasks.",
      "authors": [
        "Dewei Wang",
        "Chenjia Ba",
        "Chenhui Li",
        "Jiyuan Shi",
        "Yan Ding",
        "Chi Zhang",
        "Bin Zhao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T02:08:40+00:00",
          "link": "https://arxiv.org/abs/2506.21853v1",
          "size": "1726kb",
          "version": "v1"
        }
      ],
      "title": "Skill-Nav: Enhanced Navigation with Versatile Quadrupedal Locomotion via Waypoint Interface",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21853",
        "HTML": "https://arxiv.org/html/2506.21853v1",
        "PDF": "https://arxiv.org/pdf/2506.21853"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The research is concerned with integrating quadrupedal locomotion skills into robotics navigation and does not address issues related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21855",
      "abstract": "In this paper, we propose a method that learns a general representation of periodic signals from unlabeled facial videos by capturing subtle changes in skin tone over time. The proposed framework employs the video masked autoencoder to learn a high-dimensional spatio-temporal representation of the facial region through self-supervised learning. Capturing quasi-periodic signals in the video is crucial for remote photoplethysmography (rPPG) estimation. To account for signal periodicity, we apply frame masking in terms of video sampling, which allows the model to capture resampled quasi-periodic signals during the pre-training stage. Moreover, the framework incorporates physiological bandlimit constraints, leveraging the property that physiological signals are sparse within their frequency bandwidth to provide pulse cues to the model. The pre-trained encoder is then transferred to the rPPG task, where it is used to extract physiological signals from facial videos. We evaluate the proposed method through extensive experiments on the PURE, UBFC-rPPG, MMPD, and V4V datasets. Our results demonstrate significant performance improvements, particularly in challenging cross-dataset evaluations. Our code is available at https://github.com/ziiho08/Periodic-MAE.",
      "authors": [
        "Jiho Choi and Sang Jun Lee"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T02:18:10+00:00",
          "link": "https://arxiv.org/abs/2506.21855v1",
          "size": "3349kb",
          "version": "v1"
        }
      ],
      "title": "Periodic-MAE: Periodic Video Masked Autoencoder for rPPG Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21855",
        "HTML": "https://arxiv.org/html/2506.21855v1",
        "PDF": "https://arxiv.org/pdf/2506.21855"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The study is focused on learning a representation of periodic signals in videos for rPPG estimation and does not relate to LLM training data stages or processes."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21857",
      "abstract": "The rapid growth of digital pathology and advances in self-supervised deep learning have enabled the development of foundational models for various pathology tasks across diverse diseases. While multimodal approaches integrating diverse data sources have emerged, a critical gap remains in the comprehensive integration of whole-slide images (WSIs) with spatial transcriptomics (ST), which is crucial for capturing critical molecular heterogeneity beyond standard hematoxylin & eosin (H&E) staining. We introduce SPADE, a foundation model that integrates histopathology with ST data to guide image representation learning within a unified framework, in effect creating an ST-informed latent space. SPADE leverages a mixture-of-data experts technique, where experts, created via two-stage feature-space clustering, use contrastive learning to learn representations of co-registered WSI patches and gene expression profiles. Pre-trained on the comprehensive HEST-1k dataset, SPADE is evaluated on 14 downstream tasks, demonstrating significantly superior few-shot performance compared to baseline models, highlighting the benefits of integrating morphological and molecular information into one latent space.",
      "authors": [
        "Ekaterina Redekop",
        "Mara Pleasure",
        "Zichen Wang",
        "Kimberly Flores",
        "Anthony Sisk",
        "William Speier",
        "Corey W. Arnold"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T02:20:51+00:00",
          "link": "https://arxiv.org/abs/2506.21857v1",
          "size": "454kb",
          "version": "v1"
        }
      ],
      "title": "SPADE: Spatial Transcriptomics and Pathology Alignment Using a Mixture of Data Experts for an Expressive Latent Space",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21857",
        "HTML": "https://arxiv.org/html/2506.21857v1",
        "PDF": "https://arxiv.org/pdf/2506.21857"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "SPADE is a model for integrating pathology images with transcriptomics data and does not involve the processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21860",
      "abstract": "Mobile robots rely on object detectors for perception and object localization in indoor environments. However, standard closed-set methods struggle to handle the diverse objects and dynamic conditions encountered in real homes and labs. Open-vocabulary object detection (OVOD), driven by Vision Language Models (VLMs), extends beyond fixed labels but still struggles with domain shifts in indoor environments. We introduce a Source-Free Domain Adaptation (SFDA) approach that adapts a pre-trained model without accessing source data. We refine pseudo labels via temporal clustering, employ multi-scale threshold fusion, and apply a Mean Teacher framework with contrastive learning. Our Embodied Domain Adaptation for Object Detection (EDAOD) benchmark evaluates adaptation under sequential changes in lighting, layout, and object diversity. Our experiments show significant gains in zero-shot detection performance and flexible adaptation to dynamic indoor conditions.",
      "authors": [
        "Xiangyu Shi",
        "Yanyuan Qiao",
        "Lingqiao Liu",
        "Feras Dayoub"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T02:28:19+00:00",
          "link": "https://arxiv.org/abs/2506.21860v1",
          "size": "589kb",
          "version": "v1"
        }
      ],
      "title": "Embodied Domain Adaptation for Object Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21860",
        "HTML": "https://arxiv.org/html/2506.21860v1",
        "PDF": "https://arxiv.org/pdf/2506.21860"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on domain adaptation for object detection in mobile robots, which involves refining model predictions without accessing source data. It does not discuss the processing or engineering of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21861",
      "abstract": "Recent work has demonstrated that neural language models encode syntactic structures in their internal representations, yet the derivations by which these structures are constructed across layers remain poorly understood. In this paper, we propose Derivational Probing to investigate how micro-syntactic structures (e.g., subject noun phrases) and macro-syntactic structures (e.g., the relationship between the root verbs and their direct dependents) are constructed as word embeddings propagate upward across layers. Our experiments on BERT reveal a clear bottom-up derivation: micro-syntactic structures emerge in lower layers and are gradually integrated into a coherent macro-syntactic structure in higher layers. Furthermore, a targeted evaluation on subject-verb number agreement shows that the timing of constructing macro-syntactic structures is critical for downstream performance, suggesting an optimal timing for integrating global syntactic information.",
      "authors": [
        "Taiga Someya",
        "Ryo Yoshida",
        "Hitomi Yanaka",
        "Yohei Oseki"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T02:29:30+00:00",
          "link": "https://arxiv.org/abs/2506.21861v1",
          "size": "1106kb",
          "version": "v1"
        }
      ],
      "title": "Derivational Probing: Unveiling the Layer-wise Derivation of Syntactic Structures in Neural Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21861",
        "HTML": "https://arxiv.org/html/2506.21861v1",
        "PDF": "https://arxiv.org/pdf/2506.21861"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper analyzes how neural language models internally construct syntactic structures, but it does not propose any new methods or techniques related to the processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21862",
      "abstract": "In this paper, we present LLaVA-Scissor, a training-free token compression strategy designed for video multimodal large language models. Previous methods mostly attempt to compress tokens based on attention scores, but fail to effectively capture all semantic regions and often lead to token redundancy. Differently, we propose to leverage the Semantic Connected Components (SCC) approach that assigns tokens to distinct semantic regions within the token set, ensuring comprehensive semantic coverage. The outcome is a two-step spatio-temporal token compression strategy that utilizes SCC in both spatial and temporal domains. This strategy can effectively compress tokens by representing the entire video with a set of non-overlapping semantic tokens. We conduct extensive evaluations of the token compression capabilities of LLaVA-Scissor across diverse video understanding benchmarks, including video question answering, long video understanding, and comprehensive multi-choices benchmarks. Experimental results show that the proposed LLaVA-Scissor outperforms other token compression methods, achieving superior performance in various video understanding benchmarks, particularly at low token retention ratios. Project page: https://github.com/HumanMLLM/LLaVA-Scissor.",
      "authors": [
        "Boyuan Sun",
        "Jiaxing Zhao",
        "Xihan Wei",
        "Qibin Hou"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T02:29:58+00:00",
          "link": "https://arxiv.org/abs/2506.21862v1",
          "size": "2733kb",
          "version": "v1"
        }
      ],
      "title": "LLaVA-Scissor: Token Compression with Semantic Connected Components for Video LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21862",
        "HTML": "https://arxiv.org/html/2506.21862v1",
        "PDF": "https://arxiv.org/pdf/2506.21862"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper presents a token compression strategy for video language models, which relates indirectly to data processing by optimizing token utilization in models. However, it does not address the initial stages of data collection or processing for LLM training."
      },
      "models": [
        {
          "model_path": "BBBBCHAN/LLaVA-Scissor-baseline-7B",
          "downloads": "3",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/BBBBCHAN/LLaVA-Scissor-baseline-7B"
        },
        {
          "model_path": "BBBBCHAN/LLaVA-Scissor-baseline-0.5B",
          "downloads": "1",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/BBBBCHAN/LLaVA-Scissor-baseline-0.5B"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.21863",
      "abstract": "Large Vision and Language Models (LVLMs) have shown strong performance across various vision-language tasks in natural image domains. However, their application to remote sensing (RS) remains underexplored due to significant domain differences in visual appearances, object scales, and semantics. These discrepancies hider the effective understanding of RS scenes, which contain rich, multi-level semantic information spanning from coarse-to-fine levels. Hence, it limits the direct adaptation of existing LVLMs to RS imagery. To address this gap, we propose a novel LVLM framework tailored for RS understanding, incorporating two core components: Semantic-augmented Multi-level Alignment and Semantic-aware Expert Modeling. First, to align multi-level visual features, we introduce the retrieval-based Semantic Augmentation Module which enriches the visual features with relevant semantics across fine-to-coarse levels (e.g., object- and scene-level information). It is designed to retrieve relevant semantic cues from a RS semantic knowledge database, followed by aggregation of semantic cues with user query and multi-level visual features, resulting in semantically enriched representation across multiple levels. Second, for Semantic-aware Expert Modeling, we design semantic experts, where each expert is responsible for processing semantic representation at different levels separately. This enables hierarchical semantic understanding from coarse to fine levels. Evaluations across multiple RS tasks-including scene classification and VQA, etc.-demonstrate that the proposed framework achieves consistent improvements across multiple semantic levels. This highlights its capability and effectiveness in bridging the gap between general LVLMs and unique demands of RS-specific vision-language understanding.",
      "authors": [
        "Sungjune Park",
        "Yeongyun Kim",
        "Se Yeon Kim",
        "and Yong Man Ro"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T02:31:37+00:00",
          "link": "https://arxiv.org/abs/2506.21863v1",
          "size": "2286kb",
          "version": "v1"
        }
      ],
      "title": "Remote Sensing Large Vision-Language Model: Semantic-augmented Multi-level Alignment and Semantic-aware Expert Modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21863",
        "HTML": "https://arxiv.org/html/2506.21863v1",
        "PDF": "https://arxiv.org/pdf/2506.21863"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This research proposes improvements in vision-language models for remote sensing tasks by introducing semantic alignment and expert modeling, but it does not engage with the processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21864",
      "abstract": "Native multimodal large language models (MLLMs) restructure a single large language model (LLM) into a spoken language model (SLM) capable of both speech and text generation. Compared to modular and aligned MLLMs, native MLLMs preserve richer paralinguistic features such as emotion and prosody, and generate speech responses directly within the backbone LLM rather than using a separate speech decoder. This integration also results in lower response latency and smoother interaction. However, native MLLMs suffer from catastrophic forgetting and performance degradation because the available paired speech-text data is insufficient to support the pretraining of MLLMs compared to the vast amount of text data required to pretrain text LLMs. To address this issue, we propose DeepTalk, a framework for adaptive modality expert learning based on a Mixture of Experts (MoE) architecture. DeepTalk first adaptively distinguishes modality experts according to their modality load within the LLM. Each modality expert then undergoes specialized single-modality training, followed by joint multimodal collaborative training. As a result, DeepTalk incurs only a 5.5% performance drop compared to the original LLM, which is significantly lower than the average performance drop of over 20% typically seen in native MLLMs (such as GLM-4-Voice), and is on par with modular MLLMs. Meanwhile, the end-to-end dialogue latency remains within 0.5 seconds, ensuring a seamless and intelligent speech interaction experience. Code and models are released at https://github.com/talkking/DeepTalk.",
      "authors": [
        "Hang Shao",
        "Heting Gao",
        "Yunhang Shen",
        "Jiawei Chen",
        "Lijiang Li",
        "Zuwei Long",
        "Bo Tong",
        "Ke Li",
        "Xing Sun"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T02:32:04+00:00",
          "link": "https://arxiv.org/abs/2506.21864v1",
          "size": "1335kb",
          "version": "v1"
        }
      ],
      "title": "DeepTalk: Towards Seamless and Smart Speech Interaction with Adaptive Modality-Specific MoE",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21864",
        "HTML": "https://arxiv.org/html/2506.21864v1",
        "PDF": "https://arxiv.org/pdf/2506.21864"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "DeepTalk addresses the adaptation of multimodal language models for speech interaction, focusing on modality-specific expert learning to prevent catastrophic forgetting. It does not discuss training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21865",
      "abstract": "The Yellow River is China's mother river and a cradle of human civilization. The ancient Yellow River culture is, moreover, an indispensable part of human art history. To conserve and inherit the ancient Yellow River culture, we designed RiverEcho, a real-time interactive system that responds to voice queries using a large language model and a cultural knowledge dataset, delivering explanations through a talking-head digital human. Specifically, we built a knowledge database focused on the ancient Yellow River culture, including the collection of historical texts and the processing pipeline. Experimental results demonstrate that leveraging Retrieval-Augmented Generation (RAG) on the proposed dataset enhances the response quality of the Large Language Model(LLM), enabling the system to generate more professional and informative responses. Our work not only diversifies the means of promoting Yellow River culture but also provides users with deeper cultural insights.",
      "authors": [
        "Haofeng Wang",
        "Yilin Guo",
        "Zehao Li",
        "Tong Yue",
        "Yizong Wang",
        "Enci Zhang",
        "Rongqun Lin",
        "Feng Gao",
        "Shiqi Wang",
        "Siwei Ma"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Multimedia (cs.MM)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T02:40:00+00:00",
          "link": "https://arxiv.org/abs/2506.21865v1",
          "size": "1202kb",
          "version": "v1"
        }
      ],
      "title": "RiverEcho: Real-Time Interactive Digital System for Ancient Yellow River Culture",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21865",
        "HTML": "https://arxiv.org/html/2506.21865v1",
        "PDF": "https://arxiv.org/pdf/2506.21865"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses the construction of a knowledge database and a processing pipeline focused on ancient Yellow River culture, mentioning data collection and use of RAG for enhancing LLM response quality, which relates to LLM training data processing but is not the primary focus."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21866",
      "abstract": "Automatically segmenting objects from optical remote sensing images (ORSIs) is an important task. Most existing models are primarily based on either convolutional or Transformer features, each offering distinct advantages. Exploiting both advantages is valuable research, but it presents several challenges, including the heterogeneity between the two types of features, high complexity, and large parameters of the model. However, these issues are often overlooked in existing the ORSIs methods, causing sub-optimal segmentation. For that, we propose a novel Dual-Perspective United Transformer (DPU-Former) with a unique structure designed to simultaneously integrate long-range dependencies and spatial details. In particular, we design the global-local mixed attention, which captures diverse information through two perspectives and introduces a Fourier-space merging strategy to obviate deviations for efficient fusion. Furthermore, we present a gated linear feed-forward network to increase the expressive ability. Additionally, we construct a DPU-Former decoder to aggregate and strength features at different layers. Consequently, the DPU-Former model outperforms the state-of-the-art methods on multiple datasets. Code: https://github.com/CSYSI/DPU-Former.",
      "authors": [
        "Yanguang Sun",
        "Jiexi Yan",
        "Jianjun Qian",
        "Chunyan Xu",
        "Jian Yang",
        "and Lei Luo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T02:40:48+00:00",
          "link": "https://arxiv.org/abs/2506.21866v1",
          "size": "1971kb",
          "version": "v1"
        }
      ],
      "title": "Dual-Perspective United Transformer for Object Segmentation in Optical Remote Sensing Images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21866",
        "HTML": "https://arxiv.org/html/2506.21866v1",
        "PDF": "https://arxiv.org/pdf/2506.21866"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper is about a novel Transformer model for object segmentation in optical remote sensing images and does not address any aspect of LLM training data collection, construction, or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21872",
      "abstract": "Reinforcement Learning (RL) is an important machine learning paradigm for solving sequential decision-making problems. Recent years have witnessed remarkable progress in this field due to the rapid development of deep neural networks. However, the success of RL currently relies on extensive training data and computational resources. In addition, RL's limited ability to generalize across tasks restricts its applicability in dynamic and real-world environments. With the arisen of Continual Learning (CL), Continual Reinforcement Learning (CRL) has emerged as a promising research direction to address these limitations by enabling agents to learn continuously, adapt to new tasks, and retain previously acquired knowledge. In this survey, we provide a comprehensive examination of CRL, focusing on its core concepts, challenges, and methodologies. Firstly, we conduct a detailed review of existing works, organizing and analyzing their metrics, tasks, benchmarks, and scenario settings. Secondly, we propose a new taxonomy of CRL methods, categorizing them into four types from the perspective of knowledge storage and/or transfer. Finally, our analysis highlights the unique challenges of CRL and provides practical insights into future directions.",
      "authors": [
        "Chaofan Pan",
        "Xin Yang",
        "Yanhua Li",
        "Wei Wei",
        "Tianrui Li",
        "Bo An",
        "Jiye Liang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T03:10:20+00:00",
          "link": "https://arxiv.org/abs/2506.21872v1",
          "size": "5104kb",
          "version": "v1"
        }
      ],
      "title": "A Survey of Continual Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21872",
        "HTML": "https://arxiv.org/html/2506.21872v1",
        "PDF": "https://arxiv.org/pdf/2506.21872"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper surveys Continual Reinforcement Learning, focusing on RL methods, challenges, and taxonomy and does not address any specific aspects of LLM training data engineering or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21873",
      "abstract": "Recent Multimodal Large Language Models (MLLMs) have demonstrated strong performance in visual grounding, establishing themselves as a general interface for various vision-language applications. This progress has driven the development of token pruning methods to mitigate the high computational costs associated with processing numerous visual tokens. However, we observe that pruning significantly weakens the model's grounding ability, leading to incorrect predictions and drastic performance degradation. In Referring Expression Comprehension (REC), for instance, pruning causes the accuracy of LLaVA on the RefCOCO validation set to drop from 56.14% to 15.34%. Our analysis identifies misaligned position IDs after pruning as the primary cause of this degradation, as both the order and value of these IDs are crucial for maintaining performance in grounding tasks. To address this issue, we propose Grounding-Aware Token Pruning (GAP), a simple yet effective adjustment to position IDs that recovers REC accuracy back to 51.42%, which is 90% of the original performance in the without pruning setting, all while requiring no additional training, memory, or computational overhead. Applied to models such as Shikra, MiniGPTv2, and the LLaVA series, our method consistently improves performance across various token pruning strategies.",
      "authors": [
        "Tzu-Chun Chien",
        "Chieh-Kai Lin",
        "Shiang-Feng Tsai",
        "Ruei-Chi Lai",
        "Hung-Jen Chen",
        "Min Sun"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T03:11:22+00:00",
          "link": "https://arxiv.org/abs/2506.21873v1",
          "size": "2799kb",
          "version": "v1"
        }
      ],
      "title": "Grounding-Aware Token Pruning: Recovering from Drastic Performance Drops in Visual Grounding Caused by Pruning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21873",
        "HTML": "https://arxiv.org/html/2506.21873v1",
        "PDF": "https://arxiv.org/pdf/2506.21873"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The focus of this paper is on token pruning strategies to improve multimodal LLM performance and does not cover any topics related to LLM training data processing or data engineering aspects."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21874",
      "abstract": "Today's text-to-image generative models are trained on millions of images sourced from the Internet, each paired with a detailed caption produced by Vision-Language Models (VLMs). This part of the training pipeline is critical for supplying the models with large volumes of high-quality image-caption pairs during training. However, recent work suggests that VLMs are vulnerable to stealthy adversarial attacks, where adversarial perturbations are added to images to mislead the VLMs into producing incorrect captions.\n  In this paper, we explore the feasibility of adversarial mislabeling attacks on VLMs as a mechanism to poisoning training pipelines for text-to-image models. Our experiments demonstrate that VLMs are highly vulnerable to adversarial perturbations, allowing attackers to produce benign-looking images that are consistently miscaptioned by the VLM models. This has the effect of injecting strong \"dirty-label\" poison samples into the training pipeline for text-to-image models, successfully altering their behavior with a small number of poisoned samples. We find that while potential defenses can be effective, they can be targeted and circumvented by adaptive attackers. This suggests a cat-and-mouse game that is likely to reduce the quality of training data and increase the cost of text-to-image model development. Finally, we demonstrate the real-world effectiveness of these attacks, achieving high attack success (over 73%) even in black-box scenarios against commercial VLMs (Google Vertex AI and Microsoft Azure).",
      "authors": [
        "Stanley Wu",
        "Ronik Bhaskar",
        "Anna Yoo Jeong Ha",
        "Shawn Shan",
        "Haitao Zheng",
        "Ben Y. Zhao"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T03:13:47+00:00",
          "link": "https://arxiv.org/abs/2506.21874v1",
          "size": "22664kb",
          "version": "v1"
        }
      ],
      "title": "On the Feasibility of Poisoning Text-to-Image AI Models via Adversarial Mislabeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21874",
        "HTML": "https://arxiv.org/html/2506.21874v1",
        "PDF": "https://arxiv.org/pdf/2506.21874"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper explores adversarial mislabeling attacks to poison training pipelines for text-to-image models, touching on aspects of data quality issues in training data, which partially relates to data engineering for LLMs but is not the core focus."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21875",
      "abstract": "Recent multi-modal Large Language Models (LLMs) such as GPT-4o have demonstrated strong capabilities of direct speech interaction. However, the lack of specialized and comprehensive benchmarks for end-to-end speech LLM evaluation hinders optimizing the user experience of Audio LLMs in real-world applications. Existing evaluation methods often adapt text-based benchmarks, overlooking speech's unique characteristics and challenges, including prosody, homophones, stuttering, and differing user expectations. Here, we present a novel approach to thoroughly evaluate LLMs in practical speech conversations. We systematically curate real-world chat data relevant to spoken scenarios, introduce diversity in speaker attributes and acoustic conditions, and augment the dataset with speech-specific phenomena. We further design a query-aware evaluation method to use customized evaluation checklists and prompts to enhance the accuracy of automatic evaluation. We conduct comprehensive testing and detailed analysis of various mainstream speech models, revealing significant differences in model performance across different speech scenarios. The use of query-aware evaluation further enables a finer-grained assessment under various speech-specific scenarios. Our benchmark can provide valuable insights for speech model development and evaluation.",
      "authors": [
        "Jian Zhang",
        "Linhao Zhang",
        "Bokai Lei",
        "Chuhan Wu",
        "Wei Jia",
        "Xiao Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T03:18:45+00:00",
          "link": "https://arxiv.org/abs/2506.21875v1",
          "size": "534kb",
          "version": "v1"
        }
      ],
      "title": "WildSpeech-Bench: Benchmarking Audio LLMs in Natural Speech Conversation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21875",
        "HTML": "https://arxiv.org/html/2506.21875v1",
        "PDF": "https://arxiv.org/pdf/2506.21875"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses the evaluation of Audio large language models (LLMs), focusing on a curated dataset for benchmarking. Although it mentions curated datasets, it primarily addresses evaluation rather than training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21876",
      "abstract": "Internal world models (WMs) enable agents to understand the world's state and predict transitions, serving as the basis for advanced deliberative reasoning. Recent large Vision-Language Models (VLMs), such as OpenAI o3, GPT-4o and Gemini, exhibit potential as general-purpose WMs. While the latest studies have evaluated and shown limitations in specific capabilities such as visual understanding, a systematic evaluation of VLMs' fundamental WM abilities remains absent. Drawing on comparative psychology and cognitive science, we propose a two-stage framework that assesses Perception (visual, spatial, temporal, quantitative, and motion) and Prediction (mechanistic simulation, transitive inference, compositional inference) to provide an atomic evaluation of VLMs as WMs. Guided by this framework, we introduce WM-ABench, a large-scale benchmark comprising 23 fine-grained evaluation dimensions across 6 diverse simulated environments with controlled counterfactual simulations. Through 660 experiments on 15 latest commercial and open-source VLMs, we find that these models exhibit striking limitations in basic world modeling abilities. For instance, almost all models perform at near-random accuracy when distinguishing motion trajectories. Additionally, they lack disentangled understanding -- e.g., some models tend to believe blue objects move faster than green ones. More rich results and analyses reveal significant gaps between VLMs and human-level world modeling.",
      "authors": [
        "Qiyue Gao",
        "Xinyu Pi",
        "Kevin Liu",
        "Junrong Chen",
        "Ruolan Yang",
        "Xinqi Huang",
        "Xinyu Fang",
        "Lu Sun",
        "Gautham Kishore",
        "Bo Ai",
        "Stone Tao",
        "Mengyang Liu",
        "Jiaxi Yang",
        "Chao-Jung Lai",
        "Chuanyang Jin",
        "Jiannan Xiang",
        "Benhao Huang",
        "Zeming Chen",
        "David Danks",
        "Hao Su",
        "Tianmin Shu",
        "Ziqiao Ma",
        "Lianhui Qin",
        "Zhiting Hu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T03:24:29+00:00",
          "link": "https://arxiv.org/abs/2506.21876v1",
          "size": "5225kb",
          "version": "v1"
        }
      ],
      "title": "Do Vision-Language Models Have Internal World Models? Towards an Atomic Evaluation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21876",
        "HTML": "https://arxiv.org/html/2506.21876v1",
        "PDF": "https://arxiv.org/pdf/2506.21876"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper evaluates vision-language models in terms of their internal world models, focusing on perception and prediction within simulated environments. It does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21881",
      "abstract": "As large language models (LLMs) are increasingly deployed across diverse linguistic and cultural contexts, understanding their behavior in both factual and disputable scenarios is essential, especially when their outputs may shape public opinion or reinforce dominant narratives. In this paper, we define two types of bias in LLMs: model bias (bias stemming from model training) and inference bias (bias induced by the language of the query), through a two-phase evaluation. Phase 1 evaluates LLMs on factual questions where a single verifiable answer exists, assessing whether models maintain consistency across different query languages. Phase 2 expands the scope by probing geopolitically sensitive disputes, where responses may reflect culturally embedded or ideologically aligned perspectives. We construct a manually curated dataset spanning both factual and disputable QA, across four languages and question types. The results show that Phase 1 exhibits query language induced alignment, while Phase 2 reflects an interplay between the model's training context and query language. This paper offers a structured framework for evaluating LLM behavior across neutral and sensitive topics, providing insights for future LLM deployment and culturally aware evaluation practices in multilingual contexts.",
      "authors": [
        "Sean Kim",
        "Hyuhng Joon Kim"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T03:37:15+00:00",
          "link": "https://arxiv.org/abs/2506.21881v1",
          "size": "215kb",
          "version": "v1"
        }
      ],
      "title": "A Dual-Layered Evaluation of Geopolitical and Cultural Bias in LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21881",
        "HTML": "https://arxiv.org/html/2506.21881v1",
        "PDF": "https://arxiv.org/pdf/2506.21881"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper deals with evaluating geopolitical and cultural bias in LLMs, using a manually curated dataset. While it involves data curation, it is more focused on bias assessment than on processing data for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21883",
      "abstract": "Psoriasis (PsO) severity scoring is important for clinical trials but is hindered by inter-rater variability and the burden of in person clinical evaluation. Remote imaging using patient captured mobile photos offers scalability but introduces challenges, such as variation in lighting, background, and device quality that are often imperceptible to humans but can impact model performance. These factors, along with inconsistencies in dermatologist annotations, reduce the reliability of automated severity scoring. We propose a framework to automatically flag problematic training images that introduce spurious correlations which degrade model generalization, using a gradient based interpretability approach. By tracing the gradients of misclassified validation images, we detect training samples where model errors align with inconsistently rated examples or are affected by subtle, nonclinical artifacts. We apply this method to a ConvNeXT based weakly supervised model designed to classify PsO severity from phone images. Removing 8.2% of flagged images improves model AUC-ROC by 5% (85% to 90%) on a held out test set. Commonly, multiple annotators and an adjudication process ensure annotation accuracy, which is expensive and time consuming. Our method detects training images with annotation inconsistencies, potentially removing the need for manual review. When applied to a subset of training data rated by two dermatologists, the method identifies over 90% of cases with inter-rater disagreement by reviewing only the top 30% of samples. This improves automated scoring for remote assessments, ensuring robustness despite data collection variability.",
      "authors": [
        "Basudha Pal",
        "Sharif Amit Kamran",
        "Brendon Lutnick",
        "Molly Lucas",
        "Chaitanya Parmar",
        "Asha Patel Shah",
        "David Apfel",
        "Steven Fakharzadeh",
        "Lloyd Miller",
        "Gabriela Cula",
        "Kristopher Standish"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T03:42:09+00:00",
          "link": "https://arxiv.org/abs/2506.21883v1",
          "size": "4659kb",
          "version": "v1"
        }
      ],
      "title": "GRASP-PsONet: Gradient-based Removal of Spurious Patterns for PsOriasis Severity Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21883",
        "HTML": "https://arxiv.org/html/2506.21883v1",
        "PDF": "https://arxiv.org/pdf/2506.21883"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper addresses image data annotation inconsistencies and model generalization in psoriasis severity classification. Its focus is on image data rather than text data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21885",
      "abstract": "Multi-sensor fusion plays a critical role in enhancing perception for autonomous driving, overcoming individual sensor limitations, and enabling comprehensive environmental understanding. This paper first formalizes multi-sensor fusion strategies into data-level, feature-level, and decision-level categories and then provides a systematic review of deep learning-based methods corresponding to each strategy. We present key multi-modal datasets and discuss their applicability in addressing real-world challenges, particularly in adverse weather conditions and complex urban environments. Additionally, we explore emerging trends, including the integration of Vision-Language Models (VLMs), Large Language Models (LLMs), and the role of sensor fusion in end-to-end autonomous driving, highlighting its potential to enhance system adaptability and robustness. Our work offers valuable insights into current methods and future directions for multi-sensor fusion in autonomous driving.",
      "authors": [
        "Chuheng Wei",
        "Ziye Qin",
        "Ziyan Zhang",
        "Guoyuan Wu",
        "Matthew J. Barth"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Multimedia (cs.MM)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T03:43:48+00:00",
          "link": "https://arxiv.org/abs/2506.21885v1",
          "size": "1107kb",
          "version": "v1"
        }
      ],
      "title": "Integrating Multi-Modal Sensors: A Review of Fusion Techniques for Intelligent Vehicles",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21885",
        "HTML": "https://arxiv.org/html/2506.21885v1",
        "PDF": "https://arxiv.org/pdf/2506.21885"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper reviews multi-sensor fusion techniques for autonomous vehicles and discusses datasets for perception enhancements in driving contexts, but it does not address any data processing or engineering tasks related to LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21887",
      "abstract": "High-stakes decision-making involves navigating multiple competing objectives with expensive evaluations. For instance, in brachytherapy, clinicians must balance maximizing tumor coverage (e.g., an aspirational target or soft bound of >95% coverage) against strict organ dose limits (e.g., a non-negotiable hard bound of <601 cGy to the bladder), with each plan evaluation being resource-intensive. Selecting Pareto-optimal solutions that match implicit preferences is challenging, as exhaustive Pareto frontier exploration is computationally and cognitively prohibitive, necessitating interactive frameworks to guide users. While decision-makers (DMs) often possess domain knowledge to narrow the search via such soft-hard bounds, current methods often lack systematic approaches to iteratively refine these multi-faceted preference structures. Critically, DMs must trust their final decision, confident they haven't missed superior alternatives; this trust is paramount in high-consequence scenarios. We present Active-MoSH, an interactive local-global framework designed for this process. Its local component integrates soft-hard bounds with probabilistic preference learning, maintaining distributions over DM preferences and bounds for adaptive Pareto subset refinement. This is guided by an active sampling strategy optimizing exploration-exploitation while minimizing cognitive burden. To build DM trust, Active-MoSH's global component, T-MoSH, leverages multi-objective sensitivity analysis to identify potentially overlooked, high-value points beyond immediate feedback. We demonstrate Active-MoSH's performance benefits through diverse synthetic and real-world applications. A user study on AI-generated image selection further validates our hypotheses regarding the framework's ability to improve convergence, enhance DM trust, and provide expressive preference articulation, enabling more effective DMs.",
      "authors": [
        "Edward Chen",
        "Sang T. Truong",
        "Natalie Dullerud",
        "Sanmi Koyejo",
        "Carlos Guestrin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T03:44:20+00:00",
          "link": "https://arxiv.org/abs/2506.21887v1",
          "size": "12108kb",
          "version": "v1"
        }
      ],
      "title": "Interactive Multi-Objective Probabilistic Preference Learning with Soft and Hard Bounds",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21887",
        "HTML": "https://arxiv.org/html/2506.21887v1",
        "PDF": "https://arxiv.org/pdf/2506.21887"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper introduces a framework for multi-objective decision-making, focusing on preference learning and evaluation in high-stakes scenarios, without discussing any LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21888",
      "abstract": "A new numerical method is developed to approximate the solution of Laplace's equation in the exterior of the sphere with a strongly nonlinear boundary value of oblique type. A functional analysis attempt to solve this type of boundary condition is not straight forward since results about existence and uniqueness of solution are still limited. Hence, a semi analytical method is described here to approach a solution. A perturbation solution around the monopole converts the nonlinear oblique problem into a series of known Neumann problems in the exterior of the sphere. The corresponding Green's function representation for the exterior Neumann problem gives an exact analytic solution for each perturbation step as an integral on the surface of the sphere. Nevertheless, the boundary conditions become very complicated and require to be approximated numerically. The perturbation solutions given by integrals of the Green's function on the sphere are computed at each perturbation step using different subdivisions of the surface integrals with the help of adaptive quadrature method. We call icosahedron method to the integration on the sphere with an icosahedron mesh using Gauss 5-point or adaptive quadrature, according to the integration parameter. This method was very effective to deal with the singularity of the Green's function successfully avoiding inaccuracies on the numerical approximation and is an important contribution of this work. The numerical perturbation scheme is performed for two given exact solutions. The icosahedron method is found to be very precise. The approximations show the desired properties: they get closer to the exact solutions as the perturbation parameter gets smaller, show rapid convergence in the exterior of the unit sphere and converge to zero as the radius grows.",
      "authors": [
        "Mriganka Shekhar Chaki and Maria C. Jorge"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Mathematical Physics (math-ph)",
        "Mathematical Physics (math.MP)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T03:45:17+00:00",
          "link": "https://arxiv.org/abs/2506.21888v1",
          "size": "988kb",
          "version": "v1"
        }
      ],
      "title": "Semi Analytical Solution of a Nonlinear Oblique Boundary Value Problem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21888",
        "HTML": "https://arxiv.org/html/2506.21888v1",
        "PDF": "https://arxiv.org/pdf/2506.21888"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This work presents a numerical method for solving a nonlinear boundary value problem related to Laplace's equation, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21891",
      "abstract": "In this report, we present the winning solution that achieved the 1st place in the Complex Video Reasoning & Robustness Evaluation Challenge 2025. This challenge evaluates the ability to generate accurate natural language answers to questions about diverse, real-world video clips. It uses the Complex Video Reasoning and Robustness Evaluation Suite (CVRR-ES) benchmark, which consists of 214 unique videos and 2,400 question-answer pairs spanning 11 categories. Our method, DIVE (Deep-search Iterative Video Exploration), adopts an iterative reasoning approach, in which each input question is semantically decomposed and solved through stepwise reasoning and progressive inference. This enables our system to provide highly accurate and contextually appropriate answers to even the most complex queries. Applied to the CVRR-ES benchmark, our approach achieves 81.44% accuracy on the test set, securing the top position among all participants. This report details our methodology and provides a comprehensive analysis of the experimental results, demonstrating the effectiveness of our iterative reasoning framework in achieving robust video question answering. The code is available at https://github.com/PanasonicConnect/DIVE",
      "authors": [
        "Umihiro Kamoto",
        "Tatsuya Ishibashi",
        "Noriyuki Kugo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T04:05:12+00:00",
          "link": "https://arxiv.org/abs/2506.21891v1",
          "size": "2113kb",
          "version": "v1"
        }
      ],
      "title": "DIVE: Deep-search Iterative Video Exploration A Technical Report for the CVRR Challenge at CVPR 2025",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21891",
        "HTML": "https://arxiv.org/html/2506.21891v1",
        "PDF": "https://arxiv.org/pdf/2506.21891"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper describes a video reasoning method for a challenge using an iterative approach for video question answering and does not involve data processing related to LLM training datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21892",
      "abstract": "As point cloud data increases in prevalence in a variety of applications, the ability to detect out-of-distribution (OOD) point cloud objects becomes critical for ensuring model safety and reliability. However, this problem remains under-explored in existing research. Inspired by success in the image domain, we propose to exploit advances in 3D vision-language models (3D VLMs) for OOD detection in point cloud objects. However, a major challenge is that point cloud datasets used to pre-train 3D VLMs are drastically smaller in size and object diversity than their image-based counterparts. Critically, they often contain exclusively computer-designed synthetic objects. This leads to a substantial domain shift when the model is transferred to practical tasks involving real objects scanned from the physical environment. In this paper, our empirical experiments show that synthetic-to-real domain shift significantly degrades the alignment of point cloud with their associated text embeddings in the 3D VLM latent space, hindering downstream performance. To address this, we propose a novel methodology called SODA which improves the detection of OOD point clouds through a neighborhood-based score propagation scheme. SODA is inference-based, requires no additional model training, and achieves state-of-the-art performance over existing approaches across datasets and problem settings.",
      "authors": [
        "Adam Goodge",
        "Xun Xu",
        "Bryan Hooi",
        "Wee Siong Ng",
        "Jingyi Liao",
        "Yongyi Su",
        "Xulei Yang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T04:05:55+00:00",
          "link": "https://arxiv.org/abs/2506.21892v1",
          "size": "192kb",
          "version": "v1"
        }
      ],
      "title": "SODA: Out-of-Distribution Detection in Domain-Shifted Point Clouds via Neighborhood Propagation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21892",
        "HTML": "https://arxiv.org/html/2506.21892v1",
        "PDF": "https://arxiv.org/pdf/2506.21892"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on out-of-distribution detection in point cloud data, with a methodology called SODA. It does not discuss processing of training data for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21895",
      "abstract": "Recently the emergence of novel presentation attacks has drawn increasing attention to face anti-spoofing. However, existing methods tend to memorize data patterns from the training set, resulting in poor generalization to unknown attack types across different scenarios and limited interpretability. To address these challenges, this paper presents a reinforcement fine-tuning-based face anti-spoofing method that stimulates the capabilities of multimodal large language models to think and learn how to solve the anti-spoofing task itself, rather than relying on the memorization of authenticity patterns. We design verifiable class consistent reward and reasoning consistent reward, and employ a GRPO-based optimization strategy to guide the model in exploring reasoning policies from multiple perspectives to maximize expected rewards. As a result, through iterative trial-and-error learning while retaining only high-reward trajectories, the model distills highly generalizable decision-making rules from the extensive solution space to effectively address cross-domain face anti-spoofing tasks. Extensive experimental results demonstrate that our method achieves state-of-the-art cross-domain generalization performance. It generalizes well to diverse unknown attack types in unseen target domains while providing interpretable reasoning for its authenticity decisions without requiring labor-intensive textual annotations for training.",
      "authors": [
        "Fangling Jiang",
        "Qi Li",
        "Weining Wang",
        "Gang Wang",
        "Bing Liu",
        "Zhenan Sun"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T04:28:29+00:00",
          "link": "https://arxiv.org/abs/2506.21895v1",
          "size": "1080kb",
          "version": "v1"
        }
      ],
      "title": "Exploring Task-Solving Paradigm for Generalized Cross-Domain Face Anti-Spoofing via Reinforcement Fine-Tuning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21895",
        "HTML": "https://arxiv.org/html/2506.21895v1",
        "PDF": "https://arxiv.org/pdf/2506.21895"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper describes a reinforcement fine-tuning method for face anti-spoofing, leveraging capabilities of large language models, but it does not contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21896",
      "abstract": "The current apprenticeship model for surgical training requires a high level of supervision, which does not scale well to meet the growing need for more surgeons. Many endoscopic procedures are directly taught in the operating room (OR) while the attending surgeon and trainee operate on patients. The need to prioritize patient care limits the trainees' opportunities to experiment and receive feedback on their performance. Augmented reality (AR) has the potential to increase efficiency in endoscopic surgical training, but additional research is critical to understanding the needs of surgical trainees to inform the design of AR training systems. Therefore, we worked with 18 surgical trainees to understand the strengths, limitations, and unmet needs of their current training environment and to co-design an AR eye-gaze tracking system based on their preferences. Trainees emphasized the need to practice the 2D to 3D mapping needed to properly familiarize oneself with the anatomy of patients to prepare for real surgery. The trainees felt that an AR-based eye gaze tracking system would be a useful supplemental training method that would improve their learning in OR cases without detracting from patient care. To tailor the AR system to their needs, they co-designed features to improve their ability to track the attending surgeon's eye gaze and to provide a real-time, interactive system. Our results are valuable in shaping the endoscopic training modules by generating user-informed guidelines to design future collaborative AR-based eye-gaze tracking systems.",
      "authors": [
        "Jumanh Atoum",
        "Jinkyung Park",
        "Mamtaj Akter",
        "Nicholas Kavoussi",
        "Pamela Wisniewski",
        "Jie Ying Wu"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T04:33:39+00:00",
          "link": "https://arxiv.org/abs/2506.21896v1",
          "size": "7124kb",
          "version": "v1"
        }
      ],
      "title": "Focus on the Experts: Co-designing an Augmented Reality Eye-Gaze Tracking System with Surgical Trainees to Improve Endoscopic Instruction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21896",
        "HTML": "https://arxiv.org/html/2506.21896v1",
        "PDF": "https://arxiv.org/pdf/2506.21896"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The focus is on designing an augmented reality eye-gaze tracking system for surgical trainees. It does not pertain to training data processing for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21897",
      "abstract": "The 3D printing industry is rapidly growing and increasingly adopted across various sectors including manufacturing, healthcare, and defense. However, the operational setup often involves hazardous environments, necessitating remote monitoring through cameras and other sensors, which opens the door to cyber-based attacks. In this paper, we show that an adversary with access to video recordings of the 3D printing process can reverse engineer the underlying 3D print instructions. Our model tracks the printer nozzle movements during the printing process and maps the corresponding trajectory into G-code instructions. Further, it identifies the correct parameters such as feed rate and extrusion rate, enabling successful intellectual property theft. To validate this, we design an equivalence checker that quantitatively compares two sets of 3D print instructions, evaluating their similarity in producing objects alike in shape, external appearance, and internal structure. Unlike simple distance-based metrics such as normalized mean square error, our equivalence checker is both rotationally and translationally invariant, accounting for shifts in the base position of the reverse engineered instructions caused by different camera positions. Our model achieves an average accuracy of 90.87 percent and generates 30.20 percent fewer instructions compared to existing methods, which often produce faulty or inaccurate prints. Finally, we demonstrate a fully functional counterfeit object generated by reverse engineering 3D print instructions from video.",
      "authors": [
        "Twisha Chattopadhyay",
        "Fabricio Ceschin",
        "Marco E. Garza",
        "Dymytriy Zyunkin",
        "Animesh Chhotaray",
        "Aaron P. Stebner",
        "Saman Zonouz",
        "Raheem Beyah"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T04:34:07+00:00",
          "link": "https://arxiv.org/abs/2506.21897v1",
          "size": "6593kb",
          "version": "v1"
        }
      ],
      "title": "One Video to Steal Them All: 3D-Printing IP Theft through Optical Side-Channels",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21897",
        "HTML": "https://arxiv.org/html/2506.21897v1",
        "PDF": "https://arxiv.org/pdf/2506.21897"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This study investigates IP theft through video analysis of 3D printing, focusing on reverse engineering print instructions. It does not engage with LLM training data topics."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21898",
      "abstract": "Large language models (LLMs) are becoming increasingly ubiquitous in our daily lives, but numerous concerns about bias in LLMs exist. This study examines how gender-diverse populations perceive bias, accuracy, and trustworthiness in LLMs, specifically ChatGPT. Through 25 in-depth interviews with non-binary/transgender, male, and female participants, we investigate how gendered and neutral prompts influence model responses and how users evaluate these responses. Our findings reveal that gendered prompts elicit more identity-specific responses, with non-binary participants particularly susceptible to condescending and stereotypical portrayals. Perceived accuracy was consistent across gender groups, with errors most noted in technical topics and creative tasks. Trustworthiness varied by gender, with men showing higher trust, especially in performance, and non-binary participants demonstrating higher performance-based trust. Additionally, participants suggested improving the LLMs by diversifying training data, ensuring equal depth in gendered responses, and incorporating clarifying questions. This research contributes to the CSCW/HCI field by highlighting the need for gender-diverse perspectives in LLM development in particular and AI in general, to foster more inclusive and trustworthy systems.",
      "authors": [
        "Aimen Gaba",
        "Emily Wall",
        "Tejas Ramkumar Babu",
        "Yuriy Brun",
        "Kyle Hall",
        "Cindy Xiong Bearfield"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T04:35:52+00:00",
          "link": "https://arxiv.org/abs/2506.21898v1",
          "size": "525kb",
          "version": "v1"
        }
      ],
      "title": "Bias, Accuracy, and Trust: Gender-Diverse Perspectives on Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21898",
        "HTML": "https://arxiv.org/html/2506.21898v1",
        "PDF": "https://arxiv.org/pdf/2506.21898"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses potential improvements to LLMs through diversifying training data and enhancing response quality. However, it primarily focuses on user perspective analysis rather than proposing novel training data processing methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21899",
      "abstract": "The diversity of tasks and dynamic nature of reinforcement learning (RL) require RL agents to be able to learn sequentially and continuously, a learning paradigm known as continuous reinforcement learning. This survey reviews how continual learning transforms RL agents into dynamic continual learners. This enables RL agents to acquire and retain useful and reusable knowledge seamlessly. The paper delves into fundamental aspects of continual reinforcement learning, exploring key concepts, significant challenges, and novel methodologies. Special emphasis is placed on recent advancements in continual reinforcement learning within robotics, along with a succinct overview of evaluation environments utilized in prominent research, facilitating accessibility for newcomers to the field. The review concludes with a discussion on limitations and promising future directions, providing valuable insights for researchers and practitioners alike.",
      "authors": [
        "Amara Zuffer",
        "Michael Burke and Mehrtash Harandi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T04:36:05+00:00",
          "link": "https://arxiv.org/abs/2506.21899v1",
          "size": "1642kb",
          "version": "v1"
        }
      ],
      "title": "Advancements and Challenges in Continual Reinforcement Learning: A Comprehensive Review",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21899",
        "HTML": "https://arxiv.org/html/2506.21899v1",
        "PDF": "https://arxiv.org/pdf/2506.21899"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper reviews continual reinforcement learning (RL) and focuses on the transformation of RL agents, with no mention of LLM training data processing or data engineering relevant to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21900",
      "abstract": "The evolution toward 6G networks demands a fundamental shift from bit-centric transmission to semantic-aware communication that emphasizes task-relevant information. This work introduces TOAST (Task-Oriented Adaptive Semantic Transmission), a unified framework designed to address the core challenge of multi-task optimization in dynamic wireless environments through three complementary components. First, we formulate adaptive task balancing as a Markov decision process, employing deep reinforcement learning to dynamically adjust the trade-off between image reconstruction fidelity and semantic classification accuracy based on real-time channel conditions. Second, we integrate module-specific Low-Rank Adaptation (LoRA) mechanisms throughout our Swin Transformer-based joint source-channel coding architecture, enabling parameter-efficient fine-tuning that dramatically reduces adaptation overhead while maintaining full performance across diverse channel impairments including Additive White Gaussian Noise (AWGN), fading, phase noise, and impulse interference. Third, we incorporate an Elucidating diffusion model that operates in the latent space to restore features corrupted by channel noises, providing substantial quality improvements compared to baseline approaches. Extensive experiments across multiple datasets demonstrate that TOAST achieves superior performance compared to baseline approaches, with significant improvements in both classification accuracy and reconstruction quality at low Signal-to-Noise Ratio (SNR) conditions while maintaining robust performance across all tested scenarios.",
      "authors": [
        "Sheng Yun",
        "Jianhua Pei",
        "Ping Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T04:36:30+00:00",
          "link": "https://arxiv.org/abs/2506.21900v1",
          "size": "2524kb",
          "version": "v1"
        }
      ],
      "title": "TOAST: Task-Oriented Adaptive Semantic Transmission over Dynamic Wireless Environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21900",
        "HTML": "https://arxiv.org/html/2506.21900v1",
        "PDF": "https://arxiv.org/pdf/2506.21900"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper presents a framework for semantic transmission over wireless environments using deep reinforcement learning, with no relation to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21901",
      "abstract": "The past few years has witnessed specialized large language model (LLM) inference systems, such as vLLM, SGLang, Mooncake, and DeepFlow, alongside rapid LLM adoption via services like ChatGPT. Driving these system design efforts is the unique autoregressive nature of LLM request processing, motivating new techniques for achieving high performance while preserving high inference quality over high-volume and high-velocity workloads. While many of these techniques are discussed across the literature, they have not been analyzed under the framework of a complete inference system, nor have the systems themselves been analyzed and compared.\n  In this survey, we review these techniques, starting from operators and algorithms for request processing, then moving on to techniques for model optimization and execution, including kernel design, batching, and scheduling, before ending with techniques for memory management, including paged memory, eviction and offloading techniques, quantization, and cache persistence. Through these discussions, we show that these techniques fundamentally rely on load prediction, adaptive mechanisms, and cost reduction in order to overcome the challenges introduced by autoregressive generation and achieve the goals of the system. We then discuss how these techniques can be combined to form single-replica and multi-replica inference systems, including disaggregated inference systems that offer more control over resource allocation and serverless systems that can be deployed over shared hardware infrastructure. We end with a discussion of remaining challenges.",
      "authors": [
        "James Pan and Guoliang Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T04:38:20+00:00",
          "link": "https://arxiv.org/abs/2506.21901v1",
          "size": "2621kb",
          "version": "v1"
        }
      ],
      "title": "A Survey of LLM Inference Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21901",
        "HTML": "https://arxiv.org/html/2506.21901v1",
        "PDF": "https://arxiv.org/pdf/2506.21901"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper surveys LLM inference systems focusing on inference optimization techniques, not on the processing or engineering of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21903",
      "abstract": "Video is transforming education with online courses and recorded lectures supplementing and replacing classroom teaching. Recent research has focused on enhancing information retrieval for video lectures with advanced navigation, searchability, summarization, as well as question answering chatbots. Visual elements like tables, charts, and illustrations are central to comprehension, retention, and data presentation in lecture videos, yet their full potential for improving access to video content remains underutilized. A major factor is that accurate automatic detection of visual elements in a lecture video is challenging; reasons include i) most visual elements, such as charts, graphs, tables, and illustrations, are artificially created and lack any standard structure, and ii) coherent visual objects may lack clear boundaries and may be composed of connected text and visual components. Despite advancements in deep learning based object detection, current models do not yield satisfactory performance due to the unique nature of visual content in lectures and scarcity of annotated datasets. This paper reports on a transfer learning approach for detecting visual elements in lecture video frames. A suite of state of the art object detection models were evaluated for their performance on lecture video datasets. YOLO emerged as the most promising model for this task. Subsequently YOLO was optimized for lecture video object detection with training on multiple benchmark datasets and deploying a semi-supervised auto labeling strategy. Results evaluate the success of this approach, also in developing a general solution to the problem of object detection in lecture videos. Paper contributions include a publicly released benchmark of annotated lecture video frames, along with the source code to facilitate future research.",
      "authors": [
        "Dipayan Biswas",
        "Shishir Shah",
        "Jaspal Subhlok"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T04:43:05+00:00",
          "link": "https://arxiv.org/abs/2506.21903v1",
          "size": "1645kb",
          "version": "v1"
        }
      ],
      "title": "Visual Content Detection in Educational Videos with Transfer Learning and Dataset Enrichment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21903",
        "HTML": "https://arxiv.org/html/2506.21903v1",
        "PDF": "https://arxiv.org/pdf/2506.21903"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper addresses visual content detection in educational videos using transfer learning and dataset enrichment, unrelated to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21905",
      "abstract": "Fine Grained Visual Categorization (FGVC) remains a challenging task in computer vision due to subtle inter class differences and fragile feature representations. Existing methods struggle in fine grained scenarios, especially when labeled data is scarce. We propose a semi supervised method combining Mamba based feature modeling, region attention, and Bayesian uncertainty. Our approach enhances local to global feature modeling while focusing on key areas during learning. Bayesian inference selects high quality pseudo labels for stability. Experiments show strong performance on FGVC benchmarks with occlusions, demonstrating robustness when labeled data is limited. Code is available at https://github.com/wxqnl/RAUM Net.",
      "authors": [
        "Mingquan Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T04:48:19+00:00",
          "link": "https://arxiv.org/abs/2506.21905v1",
          "size": "3097kb",
          "version": "v1"
        }
      ],
      "title": "RAUM-Net: Regional Attention and Uncertainty-aware Mamba Network",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21905",
        "HTML": "https://arxiv.org/html/2506.21905v1",
        "PDF": "https://arxiv.org/pdf/2506.21905"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on fine-grained visual categorization using semi-supervised learning with a focus on Bayesian uncertainty and feature modeling, which does not involve the processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21909",
      "abstract": "CERBERUS is a synthetic benchmark designed to help train and evaluate AI models for detecting cracks and other defects in infrastructure. It includes a crack image generator and realistic 3D inspection scenarios built in Unity. The benchmark features two types of setups: a simple Fly-By wall inspection and a more complex Underpass scene with lighting and geometry challenges. We tested a popular object detection model (YOLO) using different combinations of synthetic and real crack data. Results show that combining synthetic and real data improves performance on real-world images. CERBERUS provides a flexible, repeatable way to test defect detection systems and supports future research in automated infrastructure inspection. CERBERUS is publicly available at https://github.com/justinreinman/Cerberus-Defect-Generator.",
      "authors": [
        "Justin Reinman",
        "Sunwoong Choi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T04:52:52+00:00",
          "link": "https://arxiv.org/abs/2506.21909v1",
          "size": "11610kb",
          "version": "v1"
        }
      ],
      "title": "CERBERUS: Crack Evaluation & Recognition Benchmark for Engineering Reliability & Urban Stability",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21909",
        "HTML": "https://arxiv.org/html/2506.21909v1",
        "PDF": "https://arxiv.org/pdf/2506.21909"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper introduces a synthetic benchmark for training AI models to detect infrastructure defects and does not pertain to LLM training data processing in any way."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21910",
      "abstract": "In language model training, it is desirable to equip models with capabilities from various tasks. However, it is not clear how to directly obtain the right data mixtures for these capabilities as the relationship between data and tasks is difficult to be modeled. In this work, we observe that checkpoint models exhibit emerging capabilities at different points in the training trajectory. Often, the training process saves checkpoints as artifacts that are under-utilized as a source of in-training data signals. We identify these artifact models based on their respective capabilities on the benchmarks and leverage them as data mixers by using their aggregated first-order influence approximation over source data. We demonstrated on eight reasoning benchmarks that the proposed framework shows significant improvements in the pretraining setting, with performance improvements of up to 1.93%. Overall, this shows the potential of checkpoint models to enhance data quality and optimize data mixtures.",
      "authors": [
        "Ernie Chang",
        "Yang Li",
        "Patrick Huber",
        "David Kant",
        "Yangyang Shi",
        "Vikas Chandra"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T04:53:07+00:00",
          "link": "https://arxiv.org/abs/2506.21910v1",
          "size": "594kb",
          "version": "v1"
        }
      ],
      "title": "AutoMixer: Checkpoint Artifacts as Automatic Data Mixers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21910",
        "HTML": "https://arxiv.org/html/2506.21910v1",
        "PDF": "https://arxiv.org/pdf/2506.21910"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper discusses the novel use of checkpoint models in optimizing data mixtures and data quality during the pretraining of language models, directly addressing aspects of training-stage data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21912",
      "abstract": "Text-driven human motion generation has recently attracted considerable attention, allowing models to generate human motions based on textual descriptions. However, current methods neglect the influence of human attributes (such as age, gender, weight, and height) which are key factors shaping human motion patterns. This work represents a pilot exploration for bridging this gap. We conceptualize each motion as comprising both attribute information and action semantics, where textual descriptions align exclusively with action semantics. To achieve this, a new framework inspired by Structural Causal Models is proposed to decouple action semantics from human attributes, enabling text-to-semantics prediction and attribute-controlled generation. The resulting model is capable of generating realistic, attribute-aware motion aligned with the user's text and attribute inputs. For evaluation, we introduce HumanAttr, a comprehensive dataset containing attribute annotations for text-motion pairs, setting the first benchmark for attribute-aware text-to-motion generation. Extensive experiments on the new dataset validate our model's effectiveness.",
      "authors": [
        "Xinghan Wang",
        "Kun Xu",
        "Fei Li",
        "Cao Sheng",
        "Jiazhong Yu",
        "Yadong Mu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T04:56:54+00:00",
          "link": "https://arxiv.org/abs/2506.21912v1",
          "size": "4519kb",
          "version": "v1"
        }
      ],
      "title": "Generating Attribute-Aware Human Motions from Textual Prompt",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21912",
        "HTML": "https://arxiv.org/html/2506.21912v1",
        "PDF": "https://arxiv.org/pdf/2506.21912"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This work focuses on generating human motions from text prompts using an attribute-aware model, and it does not deal with LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21913",
      "abstract": "Hybrid-based retrieval methods, which unify dense-vector and lexicon-based retrieval, have garnered considerable attention in the industry due to performance enhancement. However, despite their promising results, the application of these hybrid paradigms in Chinese retrieval contexts has remained largely underexplored. In this paper, we introduce HyReC, an innovative end-to-end optimization method tailored specifically for hybrid-based retrieval in Chinese. HyReC enhances performance by integrating the semantic union of terms into the representation model. Additionally, it features the Global-Local-Aware Encoder (GLAE) to promote consistent semantic sharing between lexicon-based and dense retrieval while minimizing the interference between them. To further refine alignment, we incorporate a Normalization Module (NM) that fosters mutual benefits between the retrieval approaches. Finally, we evaluate HyReC on the C-MTEB retrieval benchmark to demonstrate its effectiveness.",
      "authors": [
        "Zunran Wang",
        "Zheng Shenpeng",
        "Wang Shenglan",
        "Minghui Zhao",
        "Zhonghua Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T04:57:01+00:00",
          "link": "https://arxiv.org/abs/2506.21913v1",
          "size": "372kb",
          "version": "v1"
        }
      ],
      "title": "HyReC: Exploring Hybrid-based Retriever for Chinese",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21913",
        "HTML": "https://arxiv.org/html/2506.21913v1",
        "PDF": "https://arxiv.org/pdf/2506.21913"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper introduces a hybrid-based retrieval method for Chinese text, focusing on retrieval performance and representation models, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21914",
      "abstract": "Data brokers collect and sell the personal information of millions of individuals, often without their knowledge or consent. The California Consumer Privacy Act (CCPA) grants consumers the legal right to request access to, or deletion of, their data. To facilitate these requests, California maintains an official registry of data brokers. However, the extent to which these entities comply with the law is unclear.\n  This paper presents the first large-scale, systematic study of CCPA compliance of all 543 officially registered data brokers. Data access requests were manually submitted to each broker, followed by in-depth analyses of their responses (or lack thereof). Above 40% failed to respond at all, in an apparent violation of the CCPA. Data brokers that responded requested personal information as part of their identity verification process, including details they had not previously collected. Paradoxically, this means that exercising one's privacy rights under CCPA introduces new privacy risks.\n  Our findings reveal rampant non-compliance and lack of standardization of the data access request process. These issues highlight an urgent need for stronger enforcement, clearer guidelines, and standardized, periodic compliance checks to enhance consumers' privacy protections and improve data broker accountability.",
      "authors": [
        "Elina van Kempen",
        "Isita Bagayatkar",
        "Pavel Frolikov",
        "Chloe Georgiou",
        "Gene Tsudik"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T04:57:32+00:00",
          "link": "https://arxiv.org/abs/2506.21914v1",
          "size": "854kb",
          "version": "v1"
        }
      ],
      "title": "Consumer Beware! Exploring Data Brokers' CCPA Compliance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21914",
        "HTML": "https://arxiv.org/html/2506.21914v1",
        "PDF": "https://arxiv.org/pdf/2506.21914"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on examining the compliance of data brokers with the California Consumer Privacy Act (CCPA) and does not address any aspect of LLM training data collection, construction, or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21915",
      "abstract": "This note presents a simple and effective variation of genetic algorithm (GA) for solving RCPSP, denoted as 2-Phase Genetic Algorithm (2PGA). The 2PGA implements GA parent selection in two phases: Phase-1 includes the best current solutions in the parent pool, and Phase-2 excludes the best current solutions from the parent pool. The 2PGA carries out the GA evolution by alternating the two phases iteratively. In exploring a solution space, the Phase-1 emphasizes intensification in current neighborhood, while the Phase-2 emphasizes diversification to escape local traps. The 2PGA was tested on the standard benchmark problems in PSPLIB, the results have shown that the algorithm is effective and has improved some of the best heuristic solutions.",
      "authors": [
        "D. Sun and S. Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T04:59:48+00:00",
          "link": "https://arxiv.org/abs/2506.21915v1",
          "size": "459kb",
          "version": "v1"
        }
      ],
      "title": "An Effective Two-Phase Genetic Algorithm for Solving the Resource Constrained Project Scheduling Problem (RCPSP)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21915",
        "PDF": "https://arxiv.org/pdf/2506.21915"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper discusses a genetic algorithm for solving the Resource Constrained Project Scheduling Problem (RCPSP) and does not relate to any LLM training data processing activities."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21918",
      "abstract": "Recent research has demonstrated Reservoir Computing's capability to model various chaotic dynamical systems, yet its application to Hamiltonian systems remains relatively unexplored. This paper investigates the effectiveness of Reservoir Computing in capturing rogue wave dynamics from the nonlinear Schr\\\"{o}dinger equation, a challenging Hamiltonian system with modulation instability. The model-free approach learns from breather simulations with five unstable modes. A properly tuned parallel Echo State Network can predict dynamics from two distinct testing datasets. The first set is a continuation of the training data, whereas the second set involves a higher-order breather. An investigation of the one-step prediction capability shows remarkable agreement between the testing data and the models. Furthermore, we show that the trained reservoir can predict the propagation of rogue waves over a relatively long prediction horizon, despite facing unseen dynamics. Finally, we introduce a method to significantly improve the Reservoir Computing prediction in autonomous mode, enhancing its long-term forecasting ability. These results advance the application of Reservoir Computing to spatio-temporal Hamiltonian systems and highlight the critical importance of phase space coverage in the design of training data.",
      "authors": [
        "Abrari Noor Hasmi and Hadi Susanto"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Pattern Formation and Solitons (nlin.PS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T05:12:56+00:00",
          "link": "https://arxiv.org/abs/2506.21918v1",
          "size": "2862kb",
          "version": "v1"
        }
      ],
      "title": "Model-free Forecasting of Rogue Waves using Reservoir Computing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21918",
        "HTML": "https://arxiv.org/html/2506.21918v1",
        "PDF": "https://arxiv.org/pdf/2506.21918"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper is concerned with using Reservoir Computing for forecasting in chaotic dynamical systems, specifically applied to rogue waves, and does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21920",
      "abstract": "The automated reconstruction of the logical arrangement of tables from image data, termed Table Structure Recognition (TSR), is fundamental for semantic data extraction. Recently, researchers have explored a wide range of techniques to tackle this problem, demonstrating significant progress. Each table is a set of vertical and horizontal separators. Following this realization, we present SepFormer, which integrates the split-and-merge paradigm into a single step through separator regression with a DETR-style architecture, improving speed and robustness. SepFormer is a coarse-to-fine approach that predicts table separators from single-line to line-strip separators with a stack of two transformer decoders. In the coarse-grained stage, the model learns to gradually refine single-line segments through decoder layers with additional angle loss. At the end of the fine-grained stage, the model predicts line-strip separators by refining sampled points from each single-line segment. Our SepFormer can run on average at 25.6 FPS while achieving comparable performance with state-of-the-art methods on several benchmark datasets, including SciTSR, PubTabNet, WTW, and iFLYTAB.",
      "authors": [
        "Nam Quan Nguyen",
        "Xuan Phong Pham and Tuan-Anh Tran"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T05:20:42+00:00",
          "link": "https://arxiv.org/abs/2506.21920v1",
          "size": "15540kb",
          "version": "v1"
        }
      ],
      "title": "SepFormer: Coarse-to-fine Separator Regression Network for Table Structure Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21920",
        "HTML": "https://arxiv.org/html/2506.21920v1",
        "PDF": "https://arxiv.org/pdf/2506.21920"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper presents SepFormer, a model for Table Structure Recognition from image data, which is not relevant to LLM training data processing tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21923",
      "abstract": "Histological analysis plays a crucial role in understanding tissue structure and pathology. While recent advancements in registration methods have improved 2D histological analysis, they often struggle to preserve critical 3D spatial relationships, limiting their utility in both clinical and research applications. Specifically, constructing accurate 3D models from 2D slices remains challenging due to tissue deformation, sectioning artifacts, variability in imaging techniques, and inconsistent illumination. Deep learning-based registration methods have demonstrated improved performance but suffer from limited generalizability and require large-scale training data. In contrast, non-deep-learning approaches offer better generalizability but often compromise on accuracy. In this study, we introduced ZeroReg3D, a novel zero-shot registration pipeline tailored for accurate 3D reconstruction from serial histological sections. By combining zero-shot deep learning-based keypoint matching with optimization-based affine and non-rigid registration techniques, ZeroReg3D effectively addresses critical challenges such as tissue deformation, sectioning artifacts, staining variability, and inconsistent illumination without requiring retraining or fine-tuning. The code has been made publicly available at https://github.com/hrlblab/ZeroReg3D",
      "authors": [
        "Juming Xiong",
        "Ruining Deng",
        "Jialin Yue",
        "Siqi Lu",
        "Junlin Guo",
        "Marilyn Lionts",
        "Tianyuan Yao",
        "Can Cui",
        "Junchao Zhu",
        "Chongyu Qu",
        "Mengmeng Yin",
        "Haichun Yang",
        "Yuankai Huo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T05:31:23+00:00",
          "link": "https://arxiv.org/abs/2506.21923v1",
          "size": "3428kb",
          "version": "v1"
        }
      ],
      "title": "ZeroReg3D: A Zero-shot Registration Pipeline for 3D Consecutive Histopathology Image Reconstruction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21923",
        "HTML": "https://arxiv.org/html/2506.21923v1",
        "PDF": "https://arxiv.org/pdf/2506.21923"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on a zero-shot registration pipeline for reconstructing 3D models from 2D histopathology images, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21924",
      "abstract": "3D Visual Grounding (3DVG) aims to localize target objects within a 3D scene based on natural language queries. To alleviate the reliance on costly 3D training data, recent studies have explored zero-shot 3DVG by leveraging the extensive knowledge and powerful reasoning capabilities of pre-trained LLMs and VLMs. However, existing paradigms tend to emphasize either spatial (3D-based) or semantic (2D-based) understanding, limiting their effectiveness in complex real-world applications. In this work, we introduce SPAZER - a VLM-driven agent that combines both modalities in a progressive reasoning framework. It first holistically analyzes the scene and produces a 3D rendering from the optimal viewpoint. Based on this, anchor-guided candidate screening is conducted to perform a coarse-level localization of potential objects. Furthermore, leveraging retrieved relevant 2D camera images, 3D-2D joint decision-making is efficiently performed to determine the best-matching object. By bridging spatial and semantic reasoning neural streams, SPAZER achieves robust zero-shot grounding without training on 3D-labeled data. Extensive experiments on ScanRefer and Nr3D benchmarks demonstrate that SPAZER significantly outperforms previous state-of-the-art zero-shot methods, achieving notable gains of 9.0% and 10.9% in accuracy.",
      "authors": [
        "Zhao Jin",
        "Rong-Cheng Tu",
        "Jingyi Liao",
        "Wenhao Sun",
        "Xiao Luo",
        "Shunyu Liu",
        "Dacheng Tao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T05:34:57+00:00",
          "link": "https://arxiv.org/abs/2506.21924v1",
          "size": "3327kb",
          "version": "v1"
        }
      ],
      "title": "SPAZER: Spatial-Semantic Progressive Reasoning Agent for Zero-shot 3D Visual Grounding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21924",
        "PDF": "https://arxiv.org/pdf/2506.21924"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper introduces a reasoning agent for zero-shot visual grounding in 3D scenes, which involves pretrained LLMs for understanding but does not contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21925",
      "abstract": "With the rapid advancement of Artificial Intelligence Generated Content (AIGC) techniques, AI generated images (AIGIs) have attracted widespread attention, among which AI generated omnidirectional images (AIGODIs) hold significant potential for Virtual Reality (VR) and Augmented Reality (AR) applications. AI generated omnidirectional images exhibit unique quality issues, however, research on the quality assessment and optimization of AI-generated omnidirectional images is still lacking. To this end, this work first studies the quality assessment and distortion-aware saliency prediction problems for AIGODIs, and further presents a corresponding optimization process. Specifically, we first establish a comprehensive database to reflect human feedback for AI-generated omnidirectionals, termed OHF2024, which includes both subjective quality ratings evaluated from three perspectives and distortion-aware salient regions. Based on the constructed OHF2024 database, we propose two models with shared encoders based on the BLIP-2 model to evaluate the human visual experience and predict distortion-aware saliency for AI-generated omnidirectional images, which are named as BLIP2OIQA and BLIP2OISal, respectively. Finally, based on the proposed models, we present an automatic optimization process that utilizes the predicted visual experience scores and distortion regions to further enhance the visual quality of an AI-generated omnidirectional image. Extensive experiments show that our BLIP2OIQA model and BLIP2OISal model achieve state-of-the-art (SOTA) results in the human visual experience evaluation task and the distortion-aware saliency prediction task for AI generated omnidirectional images, and can be effectively used in the optimization process. The database and codes will be released on https://github.com/IntMeGroup/AIGCOIQA to facilitate future research.",
      "authors": [
        "Liu Yang",
        "Huiyu Duan",
        "Jiarui Wang",
        "Jing Liu",
        "Menghan Hu",
        "Xiongkuo Min",
        "Guangtao Zhai",
        "Patrick Le Callet"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T05:36:04+00:00",
          "link": "https://arxiv.org/abs/2506.21925v1",
          "size": "14724kb",
          "version": "v1"
        }
      ],
      "title": "Quality Assessment and Distortion-aware Saliency Prediction for AI-Generated Omnidirectional Images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21925",
        "HTML": "https://arxiv.org/html/2506.21925v1",
        "PDF": "https://arxiv.org/pdf/2506.21925"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper deals with quality assessment and optimization of AI-generated omnidirectional images, which is unrelated to LLM training data processing or improvements."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21926",
      "abstract": "Given a set $P$ of $n$ points in the plane, the unit-disk graph $G(P)$ is a graph with $P$ as its vertex set such that two points of $P$ have an edge if their Euclidean distance is at most $1$. We consider the problem of computing a maximum clique in $G(P)$. The previously best algorithm for the problem runs in $O(n^{7/3+o(1)})$ time. We show that the problem can be solved in $O(n \\log n + n K^{4/3+o(1)})$ time, where $K$ is the maximum clique size. The algorithm is faster than the previous one when $K=o(n)$. In addition, if $P$ is in convex position, we give a randomized algorithm that runs in $O(n^{15/7+o(1)})= O(n^{2.143})$ worst-case time and the algorithm can compute a maximum clique with high probability. For points in convex position, one special case we solve is when a point in the maximum clique is given; we present an $O(n^2\\log n)$ time (deterministic) algorithm for this special case.",
      "authors": [
        "Anastasiia Tkachenko and Haitao Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Geometry (cs.CG)",
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T05:36:30+00:00",
          "link": "https://arxiv.org/abs/2506.21926v1",
          "size": "206kb",
          "version": "v1"
        }
      ],
      "title": "Computing Maximum Cliques in Unit Disk Graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21926",
        "HTML": "https://arxiv.org/html/2506.21926v1",
        "PDF": "https://arxiv.org/pdf/2506.21926"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper discusses algorithms for computing maximum cliques in unit disk graphs, which is a combinatorial optimization problem not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21927",
      "abstract": "This study explores the application potential of a deep learning model based on the CNN-LSTM framework in forecasting the sales volume of cancer drugs, with a focus on modeling complex time series data. As advancements in medical technology and cancer treatment continue, the demand for oncology medications is steadily increasing. Accurate forecasting of cancer drug sales plays a critical role in optimizing production planning, supply chain management, and healthcare policy formulation. The dataset used in this research comprises quarterly sales records of a specific cancer drug in Egypt from 2015 to 2024, including multidimensional information such as date, drug type, pharmaceutical company, price, sales volume, effectiveness, and drug classification. To improve prediction accuracy, a hybrid deep learning model combining Convolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM) networks is employed. The CNN component is responsible for extracting local temporal features from the sales data, while the LSTM component captures long-term dependencies and trends. Model performance is evaluated using two widely adopted metrics: Mean Squared Error (MSE) and Root Mean Squared Error (RMSE). The results demonstrate that the CNN-LSTM model performs well on the test set, achieving an MSE of 1.150 and an RMSE of 1.072, indicating its effectiveness in handling nonlinear and volatile sales data. This research provides theoretical and technical support for data-driven decision-making in pharmaceutical marketing and healthcare resource planning.",
      "authors": [
        "Yinghan Li",
        "Yilin Yao",
        "Junghua Lin",
        "Nanxi Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T05:36:47+00:00",
          "link": "https://arxiv.org/abs/2506.21927v1",
          "size": "292kb",
          "version": "v1"
        }
      ],
      "title": "A Deep Learning Algorithm Based on CNN-LSTM Framework for Predicting Cancer Drug Sales Volume",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21927",
        "PDF": "https://arxiv.org/pdf/2506.21927"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper describes a deep learning model for predicting sales volume of cancer drugs. This does not involve any aspect of LLM training data collection, construction, or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21931",
      "abstract": "Retrieval-Augmented Generation (RAG) has shown promise in enhancing recommendation systems by incorporating external context into large language model prompts. However, existing RAG-based approaches often rely on static retrieval heuristics and fail to capture nuanced user preferences in dynamic recommendation scenarios. In this work, we introduce ARAG, an Agentic Retrieval-Augmented Generation framework for Personalized Recommendation, which integrates a multi-agent collaboration mechanism into the RAG pipeline. To better understand the long-term and session behavior of the user, ARAG leverages four specialized LLM-based agents: a User Understanding Agent that summarizes user preferences from long-term and session contexts, a Natural Language Inference (NLI) Agent that evaluates semantic alignment between candidate items retrieved by RAG and inferred intent, a context summary agent that summarizes the findings of NLI agent, and an Item Ranker Agent that generates a ranked list of recommendations based on contextual fit. We evaluate ARAG accross three datasets. Experimental results demonstrate that ARAG significantly outperforms standard RAG and recency-based baselines, achieving up to 42.1% improvement in NDCG@5 and 35.5% in Hit@5. We also, conduct an ablation study to analyse the effect by different components of ARAG. Our findings highlight the effectiveness of integrating agentic reasoning into retrieval-augmented recommendation and provide new directions for LLM-based personalization.",
      "authors": [
        "Reza Yousefi Maragheh",
        "Pratheek Vadla",
        "Priyank Gupta",
        "Kai Zhao",
        "Aysenur Inan",
        "Kehui Yao",
        "Jianpeng Xu",
        "Praveen Kanumala",
        "Jason Cho",
        "Sushant Kumar"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T05:45:59+00:00",
          "link": "https://arxiv.org/abs/2506.21931v1",
          "size": "7439kb",
          "version": "v1"
        }
      ],
      "title": "ARAG: Agentic Retrieval Augmented Generation for Personalized Recommendation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21931",
        "HTML": "https://arxiv.org/html/2506.21931v1",
        "PDF": "https://arxiv.org/pdf/2506.21931"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper describes ARAG, a framework for personalized recommendation. It focuses on the application of retrieval-augmented generation to recommendation systems, using LLM-based agents, and does not address the processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21932",
      "abstract": "Parallel multigrid is widely used as preconditioners in solving large-scale sparse linear systems. However, the current multigrid library still needs more satisfactory performance for structured grid problems regarding speed and scalability. Based on the classical 'multigrid seesaw', we derive three necessary principles for an efficient structured multigrid, which instructs our design and implementation of StructMG, a fast and scalable algebraic multigrid that constructs hierarchical grids automatically. As a preconditioner, StructMG can achieve both low cost per iteration and good convergence when solving large-scale linear systems with iterative methods in parallel. A stencil-based triple-matrix product via symbolic derivation and code generation is proposed for multi-dimensional Galerkin coarsening to reduce grid complexity, operator complexity, and implementation effort. A unified parallel framework of sparse triangular solver is presented to achieve fast convergence and high parallel efficiency for smoothers, including dependence-preserving Gauss-Seidel and incomplete LU methods. Idealized and real-world problems from radiation hydrodynamics, petroleum reservoir simulation, numerical weather prediction, and solid mechanics, are evaluated on ARM and X86 platforms to show StructMG's effectiveness. In comparison to \\textit{hypre}'s structured and general multigrid preconditioners, StructMG achieves the fastest time-to-solutions in all cases with average speedups of 15.5x, 5.5x, 6.7x, 7.3x over SMG, PFMG, SysPFMG, and BoomerAMG, respectively. StructMG also significantly improves strong and weak scaling efficiencies.",
      "authors": [
        "Yi Zong and Peinan Yu and Haopeng Huang and Zhengding Hu and Xinliang Wang and Qin Wang and Chensong Zhang and Xiaowen Xu and Jian Sun and Yongxiao Zhou and Wei Xue"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Numerical Analysis (cs.NA)",
        "Performance (cs.PF)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T05:55:07+00:00",
          "link": "https://arxiv.org/abs/2506.21932v1",
          "size": "1296kb",
          "version": "v1"
        }
      ],
      "title": "StructMG: A Fast and Scalable Structured Algebraic Multigrid",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21932",
        "HTML": "https://arxiv.org/html/2506.21932v1",
        "PDF": "https://arxiv.org/pdf/2506.21932"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper presents StructMG, an algebraic multigrid for solving sparse linear systems. It is unrelated to LLM training data, focusing instead on improvements to a computational methodology for equations solving."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21933",
      "abstract": "With the rapid development of the low-altitude economy, air-ground integrated multi-access edge computing (MEC) systems are facing increasing demands for real-time and intelligent task scheduling. In such systems, task offloading and resource allocation encounter multiple challenges, including node heterogeneity, unstable communication links, and dynamic task variations. To address these issues, this paper constructs a three-layer heterogeneous MEC system architecture for low-altitude economic networks, encompassing aerial and ground users as well as edge servers. The system is systematically modeled from the perspectives of communication channels, computational costs, and constraint conditions, and the joint optimization problem of offloading decisions and resource allocation is uniformly abstracted into a graph-structured modeling task. On this basis, we propose a graph attention diffusion-based solution generator (GADSG). This method integrates the contextual awareness of graph attention networks with the solution distribution learning capability of diffusion models, enabling joint modeling and optimization of discrete offloading variables and continuous resource allocation variables within a high-dimensional latent space. We construct multiple simulation datasets with varying scales and topologies. Extensive experiments demonstrate that the proposed GADSG model significantly outperforms existing baseline methods in terms of optimization performance, robustness, and generalization across task structures, showing strong potential for efficient task scheduling in dynamic and complex low-altitude economic network environments.",
      "authors": [
        "Yifan Xue",
        "Ruihuai Liang",
        "Bo Yang",
        "Xuelin Cao",
        "Zhiwen Yu",
        "M\\'erouane Debbah",
        "Chau Yuen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T06:03:48+00:00",
          "link": "https://arxiv.org/abs/2506.21933v1",
          "size": "1117kb",
          "version": "v1"
        }
      ],
      "title": "Joint Task Offloading and Resource Allocation in Low-Altitude MEC via Graph Attention Diffusion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21933",
        "HTML": "https://arxiv.org/html/2506.21933v1",
        "PDF": "https://arxiv.org/pdf/2506.21933"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The study revolves around task offloading and resource allocation in MEC systems, leveraging graph attention diffusion techniques. It does not pertain to LLM data processing or the enhancement of LLM training datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21934",
      "abstract": "Automated content-aware layout generation -- the task of arranging visual elements such as text, logos, and underlays on a background canvas -- remains a fundamental yet under-explored problem in intelligent design systems. While recent advances in deep generative models and large language models (LLMs) have shown promise in structured content generation, most existing approaches lack grounding in contextual design exemplars and fall short in handling semantic alignment and visual coherence. In this work we introduce CAL-RAG, a retrieval-augmented, agentic framework for content-aware layout generation that integrates multimodal retrieval, large language models, and collaborative agentic reasoning. Our system retrieves relevant layout examples from a structured knowledge base and invokes an LLM-based layout recommender to propose structured element placements. A vision-language grader agent evaluates the layout with visual metrics, and a feedback agent provides targeted refinements, enabling iterative improvement. We implement our framework using LangGraph and evaluate it on the PKU PosterLayout dataset, a benchmark rich in semantic and structural variability. CAL-RAG achieves state-of-the-art performance across multiple layout metrics -- including underlay effectiveness, element alignment, and overlap -- substantially outperforming strong baselines such as LayoutPrompter. These results demonstrate that combining retrieval augmentation with agentic multi-step reasoning yields a scalable, interpretable, and high-fidelity solution for automated layout generation.",
      "authors": [
        "Najmeh Forouzandehmehr",
        "Reza Yousefi Maragheh",
        "Sriram Kollipara",
        "Kai Zhao",
        "Topojoy Biswas",
        "Evren Korpeoglu",
        "Kannan Achan"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T06:09:56+00:00",
          "link": "https://arxiv.org/abs/2506.21934v1",
          "size": "4019kb",
          "version": "v1"
        }
      ],
      "title": "CAL-RAG: Retrieval-Augmented Multi-Agent Generation for Content-Aware Layout Design",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21934",
        "HTML": "https://arxiv.org/html/2506.21934v1",
        "PDF": "https://arxiv.org/pdf/2506.21934"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "CAL-RAG is a framework for generating content-aware layouts, integrating LLMs for layout recommendations. The paper's focus is on design systems and multimodal retrieval, lacking any contribution to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21937",
      "abstract": "We propose HQCM-EBTC, a hybrid quantum-classical model for automated brain tumor classification using MRI images. Trained on a dataset of 7,576 scans covering normal, meningioma, glioma, and pituitary classes, HQCM-EBTC integrates a 5-qubit, depth-2 quantum layer with 5 parallel circuits, optimized via AdamW and a composite loss blending cross-entropy and attention consistency.\n  HQCM-EBTC achieves 96.48% accuracy, substantially outperforming the classical baseline (86.72%). It delivers higher precision and F1-scores, especially for glioma detection. t-SNE projections reveal enhanced feature separability in quantum space, and confusion matrices show lower misclassification. Attention map analysis (Jaccard Index) confirms more accurate and focused tumor localization at high-confidence thresholds.\n  These results highlight the promise of quantum-enhanced models in medical imaging, advancing both diagnostic accuracy and interpretability for clinical brain tumor assessment.",
      "authors": [
        "Marwan Ait Haddou and Mohamed Bennai"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T06:16:57+00:00",
          "link": "https://arxiv.org/abs/2506.21937v1",
          "size": "4294kb",
          "version": "v1"
        }
      ],
      "title": "HQCM-EBTC: A Hybrid Quantum-Classical Model for Explainable Brain Tumor Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21937",
        "HTML": "https://arxiv.org/html/2506.21937v1",
        "PDF": "https://arxiv.org/pdf/2506.21937"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on a hybrid quantum-classical model for brain tumor classification using MRI images. It does not address any aspect of LLM training data collection, construction, or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21940",
      "abstract": "Variational Quantum Algorithms (VQAs) offer potential for near-term quantum advantage but face challenges from barren plateaus, where gradients vanish, and poorly conditioned optimization landscapes. We introduce GuiderNet, a meta-learning framework that conditions Parameterized Quantum Circuits (PQCs) using data-dependent parameter shifts aimed at minimizing the log condition number of the Fubini-Study metric tensor. Implemented as a classical neural network, GuiderNet is meta-trained to guide PQC parameters into geometrically favorable regions and is embedded within hybrid quantum-classical pipelines to steer both initialization and adaptive modulation during training.\n  Applied to the Kaggle Diabetes classification task, GuiderNet reduces cumulative training loss by over 5x, improves test accuracy from 75.3% to 98.6%, and increases the minority-class F1 score from 0.67 to 0.95. It also suppresses gradient explosion and stabilizes parameter updates, enabling smoother and more robust optimization. These results demonstrate that geometric meta-conditioning can mitigate barren plateaus and ill-conditioning, providing a scalable approach to enhance trainability and generalization in quantum machine learning.",
      "authors": [
        "Marwan Ait Haddou and Mohamed Bennai"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T06:30:33+00:00",
          "link": "https://arxiv.org/abs/2506.21940v1",
          "size": "300kb",
          "version": "v1"
        }
      ],
      "title": "GuiderNet: A Meta-Learning Framework for Optimizing Quantum Circuit Geometry and Mitigating Barren Plateaus",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21940",
        "HTML": "https://arxiv.org/html/2506.21940v1",
        "PDF": "https://arxiv.org/pdf/2506.21940"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper introduces GuiderNet, a framework for optimizing quantum circuit geometry, which is applied to quantum machine learning for classification tasks. It does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21945",
      "abstract": "Land cover maps generated from semantic segmentation of high-resolution remotely sensed images have drawn mucon in the photogrammetry and remote sensing research community. Currently, massive fine-resolution remotely sensed (FRRS) images acquired by improving sensing and imaging technologies become available. However, accurate semantic segmentation of such FRRS images is greatly affected by substantial class disparities, the invisibility of key ground objects due to occlusion, and object size variation. Despite the extraordinary potential in deep convolutional neural networks (DCNNs) in image feature learning and representation, extracting sufficient features from FRRS images for accurate semantic segmentation is still challenging. These challenges demand the deep learning models to learn robust features and generate sufficient feature descriptors. Specifically, learning multi-contextual features to guarantee adequate coverage of varied object sizes from the ground scene and harnessing global-local contexts to overcome class disparities challenge even profound networks. Deeper networks significantly lose spatial details due to gradual downsampling processes resulting in poor segmentation results and coarse boundaries. This article presents a stacked deep residual network (SDRNet) for semantic segmentation from FRRS images. The proposed framework utilizes two stacked encoder-decoder networks to harness long-range semantics yet preserve spatial information and dilated residual blocks (DRB) between each encoder and decoder network to capture sufficient global dependencies thus improving segmentation performance. Our experimental results obtained using the ISPRS Vaihingen and Potsdam datasets demonstrate that the SDRNet performs effectively and competitively against current DCNNs in semantic segmentation.",
      "authors": [
        "Naftaly Wambugu",
        "Ruisheng Wang",
        "Bo Guo",
        "Tianshu Yu",
        "Sheng Xu",
        "and Mohammed Elhassan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T06:40:30+00:00",
          "link": "https://arxiv.org/abs/2506.21945v1",
          "size": "2616kb",
          "version": "v1"
        }
      ],
      "title": "SDRNET: Stacked Deep Residual Network for Accurate Semantic Segmentation of Fine-Resolution Remotely Sensed Images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21945",
        "PDF": "https://arxiv.org/pdf/2506.21945"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The focus is on semantic segmentation of remotely sensed images using a deep residual network model, unrelated to LLM training data processes."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21946",
      "abstract": "Hitchhiking, a spontaneous and decentralized mode of travel, has long eluded systematic study due to its informal nature. This paper presents and analyzes the largest known structured dataset of hitchhiking rides, comprising over 63,000 entries collected over nearly two decades through platforms associated with hitchwiki.org and lately on hitchmap.com. By leveraging crowd-sourced contributions, the dataset captures key spatiotemporal and strategic aspects of hitchhiking. This work documents the dataset's origins, evolution, and community-driven maintenance, highlighting its Europe-centric distribution, seasonal patterns, and reliance on a small number of highly active contributors. Through exploratory analyses, I examine waiting times, user behavior, and comment metadata, shedding light on the lived realities of hitchhikers. While the dataset has inherent biases and limitations - such as demographic skew and unverifiable entries it offers a rare and valuable window into an alternative form of mobility. I conclude by outlining future directions for enriching the dataset and advancing research on hitchhiking as both a transportation practice and cultural phenomenon.",
      "authors": [
        "Till Wenke"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T06:41:08+00:00",
          "link": "https://arxiv.org/abs/2506.21946v1",
          "size": "1145kb",
          "version": "v1"
        }
      ],
      "title": "Hitchhiking Rides Dataset: Two decades of crowd-sourced records on stochastic traveling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21946",
        "HTML": "https://arxiv.org/html/2506.21946v1",
        "PDF": "https://arxiv.org/pdf/2506.21946"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper documents a dataset of hitchhiking rides and its analysis. It is related to transportation research and not related to LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21952",
      "abstract": "Distributed acoustic sensing (DAS) has attracted considerable attention across various fields and artificial intelligence (AI) technology plays an important role in DAS applications to realize event recognition and denoising. Existing AI models require real-world data (RWD), whether labeled or not, for training, which is contradictory to the fact of limited available event data in real-world scenarios. Here, a physics-informed DAS neural network paradigm is proposed, which does not need real-world events data for training. By physically modeling target events and the constraints of real world and DAS system, physical functions are derived to train a generative network for generation of DAS events data. DAS debackground net is trained by using the generated DAS events data to eliminate background noise in DAS data. The effectiveness of the proposed paradigm is verified in event identification application based on a public dataset of DAS spatiotemporal data and in belt conveyor fault monitoring application based on DAS time-frequency data, and achieved comparable or better performance than data-driven networks trained with RWD. Owing to the introduction of physical information and capability of background noise removal, the paradigm demonstrates generalization in same application on different sites. A fault diagnosis accuracy of 91.8% is achieved in belt conveyor field with networks which transferred from simulation test site without any fault events data of test site and field for training. The proposed paradigm is a prospective solution to address significant obstacles of data acquisition and intense noise in practical DAS applications and explore more potential fields for DAS.",
      "authors": [
        "Yangyang Wan",
        "Haotian Wang",
        "Xuhui Yu",
        "Jiageng Chen",
        "Xinyu Fan and Zuyuan He"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Applied Physics (physics.app-ph)",
        "Optics (physics.optics)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T06:46:58+00:00",
          "link": "https://arxiv.org/abs/2506.21952v1",
          "size": "1893kb",
          "version": "v1"
        }
      ],
      "title": "Physics-informed network paradigm with data generation and background noise removal for diverse distributed acoustic sensing applications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21952",
        "HTML": "https://arxiv.org/html/2506.21952v1",
        "PDF": "https://arxiv.org/pdf/2506.21952"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper discusses a physics-informed network for event data generation and noise removal in distributed acoustic sensing, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21956",
      "abstract": "In the realm of online advertising, advertisers partake in ad auctions to obtain advertising slots, frequently taking advantage of auto-bidding tools provided by demand-side platforms. To improve the automation of these bidding systems, we adopt generative models, namely the Decision Transformer (DT), to tackle the difficulties inherent in automated bidding. Applying the Decision Transformer to the auto-bidding task enables a unified approach to sequential modeling, which efficiently overcomes short-sightedness by capturing long-term dependencies between past bidding actions and user behavior. Nevertheless, conventional DT has certain drawbacks: (1) DT necessitates a preset return-to-go (RTG) value before generating actions, which is not inherently produced; (2) The policy learned by DT is restricted by its training data, which is consists of mixed-quality trajectories. To address these challenges, we introduce the R* Decision Transformer (R* DT), developed in a three-step process: (1) R DT: Similar to traditional DT, R DT stores actions based on state and RTG value, as well as memorizing the RTG for a given state using the training set; (2) R^ DT: We forecast the highest value (within the training set) of RTG for a given state, deriving a suboptimal policy based on the current state and the forecasted supreme RTG value; (3) R* DT: Based on R^ DT, we generate trajectories and select those with high rewards (using a simulator) to augment our training dataset. This data enhancement has been shown to improve the RTG of trajectories in the training data and gradually leads the suboptimal policy towards optimality. Comprehensive tests on a publicly available bidding dataset validate the R* DT's efficacy and highlight its superiority when dealing with mixed-quality trajectories.",
      "authors": [
        "Hao Jiang",
        "Yongxiang Tang",
        "Yanxiang Zeng",
        "Pengjia Yuan",
        "Yanhua Cheng",
        "Teng Sha",
        "Xialong Liu",
        "Peng Jiang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T06:56:54+00:00",
          "link": "https://arxiv.org/abs/2506.21956v1",
          "size": "3717kb",
          "version": "v1"
        }
      ],
      "title": "Optimal Return-to-Go Guided Decision Transformer for Auto-Bidding in Advertisement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21956",
        "HTML": "https://arxiv.org/html/2506.21956v1",
        "PDF": "https://arxiv.org/pdf/2506.21956"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper mentions the augmentation of the training dataset by generating high-reward trajectories using a simulator, which relates to improving the quality of training data. However, the primary focus is on the algorithmic improvements for decision transformers in auto-bidding systems, rather than proposing new data engineering methods for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21957",
      "abstract": "Point cloud understanding aims to acquire robust and general feature representations from unlabeled data. Masked point modeling-based methods have recently shown significant performance across various downstream tasks. These pre-training methods rely on random masking strategies to establish the perception of point clouds by restoring corrupted point cloud inputs, which leads to the failure of capturing reasonable semantic relationships by the self-supervised models. To address this issue, we propose Semantic Masked Autoencoder, which comprises two main components: a prototype-based component semantic modeling module and a component semantic-enhanced masking strategy. Specifically, in the component semantic modeling module, we design a component semantic guidance mechanism to direct a set of learnable prototypes in capturing the semantics of different components from objects. Leveraging these prototypes, we develop a component semantic-enhanced masking strategy that addresses the limitations of random masking in effectively covering complete component structures. Furthermore, we introduce a component semantic-enhanced prompt-tuning strategy, which further leverages these prototypes to improve the performance of pre-trained models in downstream tasks. Extensive experiments conducted on datasets such as ScanObjectNN, ModelNet40, and ShapeNetPart demonstrate the effectiveness of our proposed modules.",
      "authors": [
        "Yixin Zha",
        "Chuxin Wang",
        "Wenfei Yang",
        "Tianzhu Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T06:58:59+00:00",
          "link": "https://arxiv.org/abs/2506.21957v1",
          "size": "1136kb",
          "version": "v1"
        }
      ],
      "title": "Exploring Semantic Masked Autoencoder for Self-supervised Point Cloud Understanding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21957",
        "HTML": "https://arxiv.org/html/2506.21957v1",
        "PDF": "https://arxiv.org/pdf/2506.21957"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper is focused on point cloud understanding and semantic modeling for self-supervised learning, not on the processing of training data for LLMs. It discusses improvements in masked autoencoders rather than LLM-specific data challenges."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21960",
      "abstract": "Redundancy elimination is a key optimization direction, and loop nests are the main optimization target in modern compilers. Previous work on redundancy elimination of array computations in loop nests lacks universality. These approaches either focus on specific computation patterns or fail to recognize redundancies with complex structures. This paper proposes RACE (Redundant Array Computation Elimination), a more general redundancy elimination technique. RACE utilizes a novel two-level scheme to identify the data reuse between array references and the computation redundancies between expressions. It traverses the expression trees in loop nests to detect redundancies hierarchically in linear time and generates efficient code with optimized auxiliary arrays that store redundant computation results. Furthermore, RACE supports the expression reassociation with various aggressive strategies to improve the redundancy opportunities. Experimental results demonstrate the effectiveness of RACE.",
      "authors": [
        "Zixuan Wang",
        "Liang Yuan",
        "Xianmeng Jiang",
        "Kun Li",
        "Junmin Xiao",
        "Yunquan Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Performance (cs.PF)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T07:05:01+00:00",
          "link": "https://arxiv.org/abs/2506.21960v1",
          "size": "251kb",
          "version": "v1"
        }
      ],
      "title": "Redundant Array Computation Elimination",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21960",
        "HTML": "https://arxiv.org/html/2506.21960v1",
        "PDF": "https://arxiv.org/pdf/2506.21960"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper is about optimizing redundancy elimination in compiler design, which is unrelated to training data processing for LLMs. It deals with computational optimization techniques rather than data engineering or processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21961",
      "abstract": "Evaluating the performance and biases of large language models (LLMs) through role-playing scenarios is becoming increasingly common, as LLMs often exhibit biased behaviors in these contexts. Building on this line of research, we introduce PapersPlease, a benchmark consisting of 3,700 moral dilemmas designed to investigate LLMs' decision-making in prioritizing various levels of human needs. In our setup, LLMs act as immigration inspectors deciding whether to approve or deny entry based on the short narratives of people. These narratives are constructed using the Existence, Relatedness, and Growth (ERG) theory, which categorizes human needs into three hierarchical levels. Our analysis of six LLMs reveals statistically significant patterns in decision-making, suggesting that LLMs encode implicit preferences. Additionally, our evaluation of the impact of incorporating social identities into the narratives shows varying responsiveness based on both motivational needs and identity cues, with some models exhibiting higher denial rates for marginalized identities. All data is publicly available at https://github.com/yeonsuuuu28/papers-please.",
      "authors": [
        "Junho Myung",
        "Yeon Su Park",
        "Sunwoo Kim",
        "Shin Yoo",
        "Alice Oh"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T07:09:11+00:00",
          "link": "https://arxiv.org/abs/2506.21961v1",
          "size": "9512kb",
          "version": "v1"
        }
      ],
      "title": "PapersPlease: A Benchmark for Evaluating Motivational Values of Large Language Models Based on ERG Theory",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21961",
        "HTML": "https://arxiv.org/html/2506.21961v1",
        "PDF": "https://arxiv.org/pdf/2506.21961"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces a benchmark (PapersPlease) for evaluating biases in LLMs, it mainly focuses on evaluating LLM outputs rather than on the LLM training data processing itself. It touches on decision-making patterns in LLMs but does not contribute new methods for handling or processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21962",
      "abstract": "Generative AI assistants have been widely used in front-end programming. However, besides code writing, developers often encounter the need to generate animation effects. As novices in creative design without the assistance of professional designers, developers typically face difficulties in describing, designing, and implementing desired animations. To address this issue, we conducted a formative study (N=6) to identify the challenges that code developers face when dealing with animation design issues. Then, we introduce AnyAni, a human-AI collaborative system that supports front-end developers in the ideation, manipulation, and implementation of animation effects. The system combines the assistance of generative AI in creative design by adopting a nonlinear workflow for iterative animation development. In addition, developers can understand and learn the code generated for implementing animations through various interactive methods. A user study (N=9) demonstrated the usability of AnyAni in animation effect creation support for developers.",
      "authors": [
        "Tianrun Qiu",
        "Yuxin Ma"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T07:09:46+00:00",
          "link": "https://arxiv.org/abs/2506.21962v1",
          "size": "6920kb",
          "version": "v1"
        }
      ],
      "title": "AnyAni: An Interactive System with Generative AI for Animation Effect Creation and Code Understanding in Web Development",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21962",
        "HTML": "https://arxiv.org/html/2506.21962v1",
        "PDF": "https://arxiv.org/pdf/2506.21962"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper discusses generative AI for animation effect creation in web development, which is unrelated to LLM training data. It involves generative AI for design assistance rather than training data engineering or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21967",
      "abstract": "Current evaluations of tool-integrated LLM agents typically focus on end-to-end tool-usage evaluation while neglecting their stability. This limits their real-world applicability, as various internal or external factors can cause agents to crash or behave abnormally. Our research addresses this by investigating whether agents are vulnerable to errors throughout the entire tool invocation process, including reading tool documentation, selecting tools and generating parameters, and processing the tool's response. Through extensive experiments, we observe that agents are highly susceptible to errors at each stage and agents based on open-source models are more vulnerable than those based on proprietary models. We also find that increasing the model size does not significantly improve tool invocation reasoning and may make agents more vulnerable to attacks resembling normal user instructions. This highlights the importance of evaluating agent stability and offers valuable insights for future LLM development and evaluation.",
      "authors": [
        "Weimin Xiong",
        "Ke Wang",
        "Yifan Song",
        "Hanchao Liu",
        "Sai Zhou",
        "Wei Peng",
        "Sujian Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T07:13:29+00:00",
          "link": "https://arxiv.org/abs/2506.21967v1",
          "size": "142kb",
          "version": "v1"
        }
      ],
      "title": "More Vulnerable than You Think: On the Stability of Tool-Integrated LLM Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21967",
        "PDF": "https://arxiv.org/pdf/2506.21967"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This research investigates the stability of tool-integrated LLM agents, focusing on vulnerabilities in tool usage rather than training data processing. The paper lacks any relevant content about data engineering for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21968",
      "abstract": "This paper investigates a multi-intelligent reflecting surface (IRS) aided integrated sensing and communication (ISAC) system, where multiple IRSs are strategically deployed not only to assist the communication from a multi-antenna base station (BS) to a multi-antenna communication user (CU), but also enable the sensing service for a point target in the non-line-of-sight (NLoS) region of the BS. First, we propose a hybrid multi-IRS architecture, which consists of several passive IRSs and one semi-passive IRS equipped with both active sensors and reflecting elements. To be specific, the active sensors are exploited to receive the echo signals for estimating the target's angle information, and the multiple reflecting paths provided by multi-IRS are employed to improve the degree of freedoms (DoFs) of communication. Under the given budget on the number of total IRSs elements, we theoretically show that increasing the number of deployed IRSs is beneficial for improving DoFs of spatial multiplexing for communication while increasing the Cramer-Rao bound (CRB) of target estimation, which unveils a fundamental tradeoff between the sensing and communication performance. To characterize the rate-CRB tradeoff, we study a rate maximization problem, by optimizing the BS transmit covariance matrix, IRSs phase-shifts, and the number of deployed IRSs, subject to a maximum CRB constraint. Analytical results reveal that the communication-oriented design becomes optimal when the total number of IRSs elements exceeds a certain threshold, wherein the relationships of the rate and CRB with the number of IRS elements/sensors, transmit power, and the number of deployed IRSs are theoretically derived and demystified. Simulation results validate our theoretical findings and also demonstrate the superiority of our proposed designs over the benchmark schemes.",
      "authors": [
        "Guangji Chen",
        "Qingqing Wu",
        "Shihang Lu",
        "Meng Hua and Wen Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T07:14:49+00:00",
          "link": "https://arxiv.org/abs/2506.21968v1",
          "size": "398kb",
          "version": "v1"
        }
      ],
      "title": "Multi-IRS Aided ISAC System: Multi-Path Exploitation Versus Reduction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21968",
        "HTML": "https://arxiv.org/html/2506.21968v1",
        "PDF": "https://arxiv.org/pdf/2506.21968"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper explores a multi-IRS aided ISAC system, dealing with communication and sensing technologies. It does not address LLM training data engineering or processing tasks related to LLM data."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21969",
      "abstract": "We establish a novel numerical and analytical framework for solving the Korteweg--de Vries (KdV) equation in the negative Sobolev spaces, where classical numerical methods fail due to their reliance on high regularity and inability to control nonlinear interactions at low regularities. Numerical analysis is established by combining a continuous reformulation of the numerical scheme, the Bourgain-space estimates for the continuous reformulation, and a rescaling strategy that reduces the reformulated problem to a small initial value problem, which allow us to bridge a critical gap between numerical analysis and theoretical well-posedness by designing the first numerical method capable of solving the KdV equation in the negative Sobolev spaces. The numerical scheme is proved to have nearly optimal-order convergence with respect to the spatial degrees of freedom in the $H^{-\\frac{1}{2}}$ norm for initial data in $H^s$, with $-\\frac{1}{2} < s \\leq 0$, a result unattainable by existing numerical methods.",
      "authors": [
        "Jiachuan Cao",
        "Buyang Li",
        "Yifei Wu",
        "Fangyan Yao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T07:15:49+00:00",
          "link": "https://arxiv.org/abs/2506.21969v1",
          "size": "210kb",
          "version": "v1"
        }
      ],
      "title": "Computing rough solutions of the KdV equation below ${\\bf L^2}$",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21969",
        "HTML": "https://arxiv.org/html/2506.21969v1",
        "PDF": "https://arxiv.org/pdf/2506.21969"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The study proposes a numerical framework for solving the KdV equation, which is unrelated to LLM training data processing or data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21972",
      "abstract": "The advancement of Pre-Trained Language Models (PTLMs) and Large Language Models (LLMs) has led to their widespread adoption across diverse applications. Despite their success, these models remain vulnerable to attacks that exploit their inherent weaknesses to bypass safety measures. Two primary inference-phase threats are token-level and prompt-level jailbreaks. Token-level attacks embed adversarial sequences that transfer well to black-box models like GPT but leave detectable patterns and rely on gradient-based token optimization, whereas prompt-level attacks use semantically structured inputs to elicit harmful responses yet depend on iterative feedback that can be unreliable. To address the complementary limitations of these methods, we propose two hybrid approaches that integrate token- and prompt-level techniques to enhance jailbreak effectiveness across diverse PTLMs. GCG + PAIR and the newly explored GCG + WordGame hybrids were evaluated across multiple Vicuna and Llama models. GCG + PAIR consistently raised attack-success rates over its constituent techniques on undefended models; for instance, on Llama-3, its Attack Success Rate (ASR) reached 91.6%, a substantial increase from PAIR's 58.4% baseline. Meanwhile, GCG + WordGame matched the raw performance of WordGame maintaining a high ASR of over 80% even under stricter evaluators like Mistral-Sorry-Bench. Crucially, both hybrids retained transferability and reliably pierced advanced defenses such as Gradient Cuff and JBShield, which fully blocked single-mode attacks. These findings expose previously unreported vulnerabilities in current safety stacks, highlight trade-offs between raw success and defensive robustness, and underscore the need for holistic safeguards against adaptive adversaries.",
      "authors": [
        "Mohamed Ahmed",
        "Mohamed Abdelmouty",
        "Mingyu Kim",
        "Gunvanth Kandula",
        "Alex Park",
        "James C. Davis"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T07:26:33+00:00",
          "link": "https://arxiv.org/abs/2506.21972v1",
          "size": "9714kb",
          "version": "v1"
        }
      ],
      "title": "Advancing Jailbreak Strategies: A Hybrid Approach to Exploiting LLM Vulnerabilities and Bypassing Modern Defenses",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21972",
        "HTML": "https://arxiv.org/html/2506.21972v1",
        "PDF": "https://arxiv.org/pdf/2506.21972"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "While the paper discusses vulnerabilities and attack strategies on LLMs, it does not focus on training data processing, data engineering, or enhancement methods relevant to LLM data preparation."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21974",
      "abstract": "The ability of Large Language Models (LLMs) to mimic human behavior triggered a plethora of computational social science research, assuming that empirical studies of humans can be conducted with AI agents instead. Since there have been conflicting research findings on whether and when this hypothesis holds, there is a need to better understand the differences in their experimental designs. We focus on replicating the behavior of social network users with the use of LLMs for the analysis of communication on social networks. First, we provide a formal framework for the simulation of social networks, before focusing on the sub-task of imitating user communication. We empirically test different approaches to imitate user behavior on X in English and German. Our findings suggest that social simulations should be validated by their empirical realism measured in the setting in which the simulation components were fitted. With this paper, we argue for more rigor when applying generative-agent-based modeling for social simulation.",
      "authors": [
        "Simon M\\\"unker",
        "Nils Schwager",
        "Achim Rettinger"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T07:32:16+00:00",
          "link": "https://arxiv.org/abs/2506.21974v1",
          "size": "197kb",
          "version": "v1"
        }
      ],
      "title": "Don't Trust Generative Agents to Mimic Communication on Social Networks Unless You Benchmarked their Empirical Realism",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21974",
        "HTML": "https://arxiv.org/html/2506.21974v1",
        "PDF": "https://arxiv.org/pdf/2506.21974"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on using LLMs to simulate social network communication behavior, with an emphasis on empirical realism in social simulations. It does not address any aspect of LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21975",
      "abstract": "Reliable semantic segmentation of open environments is essential for intelligent systems, yet significant problems remain: 1) Existing RGB-T semantic segmentation models mainly rely on low-level visual features and lack high-level textual information, which struggle with accurate segmentation when categories share similar visual characteristics. 2) While SAM excels in instance-level segmentation, integrating it with thermal images and text is hindered by modality heterogeneity and computational inefficiency. To address these, we propose TASeg, a text-aware RGB-T segmentation framework by using Low-Rank Adaptation (LoRA) fine-tuning technology to adapt vision foundation models. Specifically, we propose a Dynamic Feature Fusion Module (DFFM) in the image encoder, which effectively merges features from multiple visual modalities while freezing SAM's original transformer blocks. Additionally, we incorporate CLIP-generated text embeddings in the mask decoder to enable semantic alignment, which further rectifies the classification error and improves the semantic understanding accuracy. Experimental results across diverse datasets demonstrate that our method achieves superior performance in challenging scenarios with fewer trainable parameters.",
      "authors": [
        "Meng Yu",
        "Te Cui",
        "Qitong Chu",
        "Wenjie Song",
        "Yi Yang",
        "Yufeng Yue"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T07:34:28+00:00",
          "link": "https://arxiv.org/abs/2506.21975v1",
          "size": "11679kb",
          "version": "v1"
        }
      ],
      "title": "TASeg: Text-aware RGB-T Semantic Segmentation based on Fine-tuning Vision Foundation Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21975",
        "HTML": "https://arxiv.org/html/2506.21975v1",
        "PDF": "https://arxiv.org/pdf/2506.21975"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper proposes a framework for RGB-T semantic segmentation by fine-tuning vision models; it does not deal with LLM training data processing tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21976",
      "abstract": "The goal of traffic simulation is to augment a potentially limited amount of manually-driven miles that is available for testing and validation, with a much larger amount of simulated synthetic miles. The culmination of this vision would be a generative simulated city, where given a map of the city and an autonomous vehicle (AV) software stack, the simulator can seamlessly simulate the trip from point A to point B by populating the city around the AV and controlling all aspects of the scene, from animating the dynamic agents (e.g., vehicles, pedestrians) to controlling the traffic light states. We refer to this vision as CitySim, which requires an agglomeration of simulation technologies: scene generation to populate the initial scene, agent behavior modeling to animate the scene, occlusion reasoning, dynamic scene generation to seamlessly spawn and remove agents, and environment simulation for factors such as traffic lights. While some key technologies have been separately studied in various works, others such as dynamic scene generation and environment simulation have received less attention in the research community. We propose SceneDiffuser++, the first end-to-end generative world model trained on a single loss function capable of point A-to-B simulation on a city scale integrating all the requirements above. We demonstrate the city-scale traffic simulation capability of SceneDiffuser++ and study its superior realism under long simulation conditions. We evaluate the simulation quality on an augmented version of the Waymo Open Motion Dataset (WOMD) with larger map regions to support trip-level simulation.",
      "authors": [
        "Shuhan Tan",
        "John Lambert",
        "Hong Jeon",
        "Sakshum Kulshrestha",
        "Yijing Bai",
        "Jing Luo",
        "Dragomir Anguelov",
        "Mingxing Tan",
        "Chiyu Max Jiang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Multiagent Systems (cs.MA)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T07:35:04+00:00",
          "link": "https://arxiv.org/abs/2506.21976v1",
          "size": "13174kb",
          "version": "v1"
        }
      ],
      "title": "SceneDiffuser++: City-Scale Traffic Simulation via a Generative World Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21976",
        "HTML": "https://arxiv.org/html/2506.21976v1",
        "PDF": "https://arxiv.org/pdf/2506.21976"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper discusses a generative model for traffic simulation, focusing on city-scale simulation capabilities. It does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21980",
      "abstract": "Visual single object tracking aims to continuously localize and estimate the scale of a target in subsequent video frames, given only its initial state in the first frame. This task has traditionally been framed as a template matching problem, evolving through major phases including correlation filters, two-stream networks, and one-stream networks with significant progress achieved. However, these methods typically require explicit classification and regression modeling, depend on supervised training with large-scale datasets, and are limited to the single task of tracking, lacking flexibility. In recent years, multi-modal large language models (MLLMs) have advanced rapidly. Open-source models like Qwen2.5-VL, a flagship MLLMs with strong foundational capabilities, demonstrate excellent performance in grounding tasks. This has spurred interest in applying such models directly to visual tracking. However, experiments reveal that Qwen2.5-VL struggles with template matching between image pairs (i.e., tracking tasks). Inspired by deepseek-R1, we fine-tuned Qwen2.5-VL using the group relative policy optimization (GRPO) reinforcement learning method on a small-scale dataset with a rule-based reward function. The resulting model, R1-Track, achieved notable performance on the GOT-10k benchmark. R1-Track supports flexible initialization via bounding boxes or text descriptions while retaining most of the original model's general capabilities. And we further discuss potential improvements for R1-Track. This rough technical report summarizes our findings as of May 2025.",
      "authors": [
        "Biao Wang and Wenwen Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T07:41:15+00:00",
          "link": "https://arxiv.org/abs/2506.21980v1",
          "size": "815kb",
          "version": "v1"
        }
      ],
      "title": "R1-Track: Direct Application of MLLMs to Visual Object Tracking via Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21980",
        "HTML": "https://arxiv.org/html/2506.21980v1",
        "PDF": "https://arxiv.org/pdf/2506.21980"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper deals with visual object tracking using multi-modal large language models, focused on reinforcement learning and not on LLM data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21982",
      "abstract": "We propose a mixed-integer linear program (MILP) for multi-agent motion planning that embeds Polytopic Action-based Motion Planning (PAAMP) into a sequence-then-solve pipeline. Region sequences confine each agent to adjacent convex polytopes, while a big-M hyperplane model enforces inter-agent separation. Collision constraints are applied only to agents sharing or neighboring a region, which reduces binary variables exponentially compared with naive formulations. An L1 path-length-plus-acceleration cost yields smooth trajectories. We prove finite-time convergence and demonstrate on representative multi-agent scenarios with obstacles that our formulation produces collision-free trajectories an order of magnitude faster than an unstructured MILP baseline.",
      "authors": [
        "Akshay Jaitly",
        "Jack Cline",
        "and Siavash Farzan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T07:42:52+00:00",
          "link": "https://arxiv.org/abs/2506.21982v1",
          "size": "128kb",
          "version": "v1"
        }
      ],
      "title": "A MILP-Based Solution to Multi-Agent Motion Planning and Collision Avoidance in Constrained Environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21982",
        "HTML": "https://arxiv.org/html/2506.21982v1",
        "PDF": "https://arxiv.org/pdf/2506.21982"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on multi-agent motion planning and collision avoidance using mixed-integer linear programming, which does not relate to LLM training data processing or preparation."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21990",
      "abstract": "The developments in transformer encoder-decoder architectures have led to significant breakthroughs in machine translation, Automatic Speech Recognition (ASR), and instruction-based chat machines, among other applications. The pre-trained models were trained on vast amounts of generic data over a few epochs (fewer than five in most cases), resulting in their strong generalization capabilities. Nevertheless, the performance of these models does suffer when applied to niche domains like transcribing pilot speech in the cockpit, which involves a lot of specific vocabulary and multilingual conversations. This paper investigates and improves the transcription accuracy of cockpit conversations with Whisper models. We have collected around 85 minutes of cockpit simulator recordings and 130 minutes of interview recordings with pilots and manually labeled them. The speakers are middle aged men speaking both German and English. To improve the accuracy of transcriptions, we propose multiple normalization schemes to refine the transcripts and improve Word Error Rate (WER). We then employ fine-tuning to enhance ASR performance, utilizing performance-efficient fine-tuning with Low-Rank Adaptation (LoRA). Hereby, WER decreased from 68.49 \\% (pretrained whisper Large model without normalization baseline) to 26.26\\% (finetuned whisper Large model with the proposed normalization scheme).",
      "authors": [
        "Kartheek Kumar Reddy Nareddy",
        "Sarah Ternus",
        "Julia Niebling"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T07:57:13+00:00",
          "link": "https://arxiv.org/abs/2506.21990v1",
          "size": "67kb",
          "version": "v1"
        }
      ],
      "title": "Analyzing and Fine-Tuning Whisper Models for Multilingual Pilot Speech Transcription in the Cockpit",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21990",
        "HTML": "https://arxiv.org/html/2506.21990v1",
        "PDF": "https://arxiv.org/pdf/2506.21990"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper's main contribution involves improving transcription accuracy for a specific application by collecting and manually labeling new data, applying normalization, and performing fine-tuning on Whisper models, which are directly related to training-stage data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21996",
      "abstract": "Deterministic game-solving algorithms are conventionally analyzed in the light of their average-case complexity against a distribution of random game-trees, where leaf values are independently sampled from a fixed distribution. This simplified model enables uncluttered mathematical analysis, revealing two key properties: root value distributions asymptotically collapse to a single fixed value for finite-valued trees, and all reasonable algorithms achieve global optimality. However, these findings are artifacts of the model's design-its long criticized independence assumption strips games of structural complexity, producing trivial instances where no algorithm faces meaningful challenges. To address this limitation, we introduce a new probabilistic model that incrementally constructs game-trees using a fixed level-wise conditional distribution. By enforcing ancestor dependency, a critical structural feature of real-world games, our framework generates problems with adjustable difficulty while retaining some form of analytical tractability. For several algorithms, including AlphaBeta and Scout, we derive recursive formulas characterizing their average-case complexities under this model. These allow us to rigorously compare algorithms on deep game-trees, where Monte-Carlo simulations are no longer feasible. While asymptotically, all algorithms seem to converge to identical branching factor (a result analogous to those of independence-based models), deep finite trees reveal stark differences: AlphaBeta incurs a significantly larger constant multiplicative factor compared to algorithms like Scout, leading to a substantial practical slowdown. Our framework sheds new light on classical game-solving algorithms, offering rigorous evidence and analytical tools to advance the understanding of these methods under a more realistic, challenging, and yet tractable model.",
      "authors": [
        "Rapha\\\"el Boige (LORIA)",
        "Amine Boumaza (LORIA)",
        "Bruno Scherrer (LORIA)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T08:07:17+00:00",
          "link": "https://arxiv.org/abs/2506.21996v1",
          "size": "1545kb",
          "version": "v1"
        }
      ],
      "title": "AlphaBeta is not as good as you think: a new probabilistic model to better analyze deterministic game-solving algorithms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21996",
        "PDF": "https://arxiv.org/pdf/2506.21996"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The abstract discusses the development of a probabilistic model to analyze deterministic game-solving algorithms and does not address LLM training data construction or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21997",
      "abstract": "This paper introduces a new type of probabilistic semiparametric model that takes advantage of data binning to reduce the computational cost of kernel density estimation in nonparametric distributions. Two new conditional probability distributions are developed for the new binned semiparametric Bayesian networks, the sparse binned kernel density estimation and the Fourier kernel density estimation. These two probability distributions address the curse of dimensionality, which typically impacts binned models, by using sparse tensors and restricting the number of parent nodes in conditional probability calculations. To evaluate the proposal, we perform a complexity analysis and conduct several comparative experiments using synthetic data and datasets from the UCI Machine Learning repository. The experiments include different binning rules, parent restrictions, grid sizes, and number of instances to get a holistic view of the model's behavior. As a result, our binned semiparametric Bayesian networks achieve structural learning and log-likelihood estimations with no statistically significant differences compared to the semiparametric Bayesian networks, but at a much higher speed. Thus, the new binned semiparametric Bayesian networks prove to be a reliable and more efficient alternative to their non-binned counterparts.",
      "authors": [
        "Rafael Sojo",
        "Javier D\\'iaz-Rozo",
        "Concha Bielza",
        "Pedro Larra\\~naga"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T08:07:34+00:00",
          "link": "https://arxiv.org/abs/2506.21997v1",
          "size": "281kb",
          "version": "v1"
        }
      ],
      "title": "Binned semiparametric Bayesian networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21997",
        "HTML": "https://arxiv.org/html/2506.21997v1",
        "PDF": "https://arxiv.org/pdf/2506.21997"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper introduces probabilistic models for Bayesian networks with a focus on computational cost reduction in kernel density estimation, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21998",
      "abstract": "Data streams produced by mobile devices, such as smartphones, offer highly valuable sources of information to build ubiquitous services. Such data streams are generally uploaded and centralized to be processed by third parties, potentially exposing sensitive personal information. In this context, existing protection mechanisms, such as Location Privacy Protection Mechanisms (LPPMs), have been investigated. Alas, none of them have actually been implemented, nor deployed in real-life, in mobile devices to enforce user privacy at the edge. Moreover, the diversity of embedded sensors and the resulting data deluge makes it impractical to provision such services directly on mobiles, due to their constrained storage capacity, communication bandwidth and processing power. This article reports on the FLI technique, which leverages a piece-wise linear approximation technique to capture compact representations of data streams in mobile devices. Beyond the FLI storage layer, we introduce Divide \\& Stay, a new privacy preservation technique to execute Points of Interest (POIs) inference. Finally, we deploy both of them on Android and iOS as the INTACT framework, making a concrete step towards enforcing privacy and trust in ubiquitous computing systems.",
      "authors": [
        "R\\'emy Raes",
        "Olivier Ruas",
        "Adrien Luxey-Bitri (SPIRALS)",
        "Romain Rouvoy (SPIRALS)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T08:09:49+00:00",
          "link": "https://arxiv.org/abs/2506.21998v1",
          "size": "2183kb",
          "version": "v1"
        }
      ],
      "title": "INTACT: Compact Storage of Data Streams in Mobile Devices to Unlock User Privacy at the Edge",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21998",
        "PDF": "https://arxiv.org/pdf/2506.21998"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on privacy and storage solutions for data streams on mobile devices and does not involve any aspect of LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21999",
      "abstract": "We revisit finite element discretizations of the Reissner-Mindlin plate in the case of non-simply connected (holey) domains with mixed boundary conditions. Guided by the de Rham complex, we develop conditions under which schemes deliver locking-free, optimal rates of convergence. We naturally recover the typical assumptions arising for clamped, simply supported plates. More importantly, we also see new conditions arise naturally from the presence of holes in the domain or in the case of mixed boundary conditions. We show that, fortunately, many of the existing popularly used schemes do, in fact, satisfy all of the conditions, and thus are locking-free.",
      "authors": [
        "Mark Ainsworth and Charles Parker"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T08:11:38+00:00",
          "link": "https://arxiv.org/abs/2506.21999v1",
          "size": "313kb",
          "version": "v1"
        }
      ],
      "title": "Do locking-free finite element schemes lock for holey Reissner-Mindlin plates with mixed boundary conditions?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21999",
        "HTML": "https://arxiv.org/html/2506.21999v1",
        "PDF": "https://arxiv.org/pdf/2506.21999"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper deals with finite element discretizations for structural mechanics problems, which are unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22000",
      "abstract": "Massive multi-input multi-output (MIMO) has evolved along two tracks: cellular and cell-free, each with unique advantages and limitations. The cellular approach suffers from worse user spectral efficiency at cell edges, whereas the cell-free approach incurs high implementation costs due to a large-scale distributed infrastructure. This paper introduces a novel networking paradigm, termed heterogeneous massive MIMO (HmMIMO), which seamlessly integrates co-located and distributed antennas. Differing from two conventional paradigms, HmMIMO remains a base station with a large antenna array at the center of each cell, aided by distributed antennas deployed at cell edges. Our findings demonstrate that this paradigm achieves a favorable trade-off between performance and implementation complexity.",
      "authors": [
        "Wei Jiang and Hans D. Schotten"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T08:12:07+00:00",
          "link": "https://arxiv.org/abs/2506.22000v1",
          "size": "153kb",
          "version": "v1"
        }
      ],
      "title": "Heterogeneous Massive MIMO: A Cost-Efficient Technique for Uniform Service in Cellular Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22000",
        "HTML": "https://arxiv.org/html/2506.22000v1",
        "PDF": "https://arxiv.org/pdf/2506.22000"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper discusses a new paradigm for MIMO in cellular networks; it does not address LLM training data or its processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22004",
      "abstract": "Inference tasks with time series over graphs are of importance in applications such as urban water networks, economics, and networked neuroscience. Addressing these tasks typically relies on identifying a computationally affordable model that jointly captures the graph-temporal patterns of the data. In this work, we propose a graph-aware state space model for graph time series, where both the latent state and the observation equation are parametric graph-induced models with a limited number of parameters that need to be learned. More specifically, we consider the state equation to follow a stochastic partial differential equation driven by noise over the graphs edges accounting not only for potential edge uncertainties but also for increasing the degrees of freedom in the latter in a tractable manner. The graph structure conditioning of the noise dispersion allows the state variable to deviate from the stochastic process in certain neighborhoods. The observation model is a sampled and graph-filtered version of the state capturing multi-hop neighboring influence. The goal is to learn the parameters in both state and observation models from the partially observed data for downstream tasks such as prediction and imputation. The model is inferred first through a maximum likelihood approach that provides theoretical tractability but is limited in expressivity and scalability. To improve on the latter, we use the state-space formulation to build a principled deep learning architecture that jointly learns the parameters and tracks the state in an end-to-end manner in the spirit of Kalman neural networks.",
      "authors": [
        "Mohammad Sabbaqi",
        "Riccardo Taormina and Elvin Isufi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T08:17:07+00:00",
          "link": "https://arxiv.org/abs/2506.22004v1",
          "size": "121kb",
          "version": "v1"
        }
      ],
      "title": "GKNet: Graph Kalman Filtering and Model Inference via Model-based Deep Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22004",
        "PDF": "https://arxiv.org/pdf/2506.22004"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The study deals with time series over graphs for inference tasks and does not address any LLM training data collection or processing aspects."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22005",
      "abstract": "We introduce LeanConjecturer, a pipeline for automatically generating university-level mathematical conjectures in Lean 4 using Large Language Models (LLMs). Our hybrid approach combines rule-based context extraction with LLM-based theorem statement generation, addressing the data scarcity challenge in formal theorem proving. Through iterative generation and evaluation, LeanConjecturer produced 12,289 conjectures from 40 Mathlib seed files, with 3,776 identified as syntactically valid and non-trivial, that is, cannot be proven by \\texttt{aesop} tactic. We demonstrate the utility of these generated conjectures for reinforcement learning through Group Relative Policy Optimization (GRPO), showing that targeted training on domain-specific conjectures can enhance theorem proving capabilities. Our approach generates 103.25 novel conjectures per seed file on average, providing a scalable solution for creating training data for theorem proving systems. Our system successfully verified several non-trivial theorems in topology, including properties of semi-open, alpha-open, and pre-open sets, demonstrating its potential for mathematical discovery beyond simple variations of existing results.",
      "authors": [
        "Naoto Onda",
        "Kazumi Kasaura",
        "Yuta Oriike",
        "Masaya Taniguchi",
        "Akiyoshi Sannai",
        "Sho Sonoda"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T08:17:18+00:00",
          "link": "https://arxiv.org/abs/2506.22005v1",
          "size": "261kb",
          "version": "v1"
        }
      ],
      "title": "LeanConjecturer: Automatic Generation of Mathematical Conjectures for Theorem Proving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22005",
        "HTML": "https://arxiv.org/html/2506.22005v1",
        "PDF": "https://arxiv.org/pdf/2506.22005"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper's primary contribution involves a pipeline for generating mathematical conjectures, addressing data scarcity via a hybrid approach combining rule-based and LLM-based techniques to create training data for theorem proving systems."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22007",
      "abstract": "We address the problem of generating long-horizon videos for robotic manipulation tasks. Text-to-video diffusion models have made significant progress in photorealism, language understanding, and motion generation but struggle with long-horizon robotic tasks. Recent works use video diffusion models for high-quality simulation data and predictive rollouts in robot planning. However, these works predict short sequences of the robot achieving one task and employ an autoregressive paradigm to extend to the long horizon, leading to error accumulations in the generated video and in the execution. To overcome these limitations, we propose a novel pipeline that bypasses the need for autoregressive generation. We achieve this through a threefold contribution: 1) we first decompose the high-level goals into smaller atomic tasks and generate keyframes aligned with these instructions. A second diffusion model then interpolates between each of the two generated frames, achieving the long-horizon video. 2) We propose a semantics preserving attention module to maintain consistency between the keyframes. 3) We design a lightweight policy model to regress the robot joint states from generated videos. Our approach achieves state-of-the-art results on two benchmarks in video quality and consistency while outperforming previous policy models on long-horizon tasks.",
      "authors": [
        "Liudi Yang",
        "Yang Bai",
        "George Eskandar",
        "Fengyi Shen",
        "Mohammad Altillawi",
        "Dong Chen",
        "Soumajit Majumder",
        "Ziyuan Liu",
        "Gitta Kutyniok and Abhinav Valada"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T08:21:55+00:00",
          "link": "https://arxiv.org/abs/2506.22007v1",
          "size": "9003kb",
          "version": "v1"
        }
      ],
      "title": "RoboEnvision: A Long-Horizon Video Generation Model for Multi-Task Robot Manipulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22007",
        "HTML": "https://arxiv.org/html/2506.22007v1",
        "PDF": "https://arxiv.org/pdf/2506.22007"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on video generation for robotic manipulation tasks and does not discuss the processing of training data for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22008",
      "abstract": "In offline reinforcement learning, agents are trained using only a fixed set of stored transitions derived from a source policy. However, this requires that the dataset be labeled by a reward function. In applied settings such as video game development, the availability of the reward function is not always guaranteed. This paper proposes Trajectory-Ranked OFfline Inverse reinforcement learning (TROFI), a novel approach to effectively learn a policy offline without a pre-defined reward function. TROFI first learns a reward function from human preferences, which it then uses to label the original dataset making it usable for training the policy. In contrast to other approaches, our method does not require optimal trajectories. Through experiments on the D4RL benchmark we demonstrate that TROFI consistently outperforms baselines and performs comparably to using the ground truth reward to learn policies. Additionally, we validate the efficacy of our method in a 3D game environment. Our studies of the reward model highlight the importance of the reward function in this setting: we show that to ensure the alignment of a value function to the actual future discounted reward, it is fundamental to have a well-engineered and easy-to-learn reward function.",
      "authors": [
        "Alessandro Sestini",
        "Joakim Bergdahl",
        "Konrad Tollmar",
        "Andrew D. Bagdanov",
        "Linus Gissl\\'en"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T08:22:41+00:00",
          "link": "https://arxiv.org/abs/2506.22008v1",
          "size": "2499kb",
          "version": "v1"
        }
      ],
      "title": "TROFI: Trajectory-Ranked Offline Inverse Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22008",
        "HTML": "https://arxiv.org/html/2506.22008v1",
        "PDF": "https://arxiv.org/pdf/2506.22008"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper deals with offline inverse reinforcement learning and reward function learning, without mention of any LLM training data processing tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22010",
      "abstract": "We investigate the problem of constructing fault-tolerant bases in matroids. Given a matroid M and a redundancy parameter k, a k-fault-tolerant basis is a minimum-size set of elements such that, even after the removal of any k elements, the remaining subset still spans the entire ground set. Since matroids generalize linear independence across structures such as vector spaces, graphs, and set systems, this problem unifies and extends several fault-tolerant concepts appearing in prior research.\n  Our main contribution is a fixed-parameter tractable (FPT) algorithm for the k-fault-tolerant basis problem, parameterized by both k and the rank r of the matroid. This two-variable parameterization by k + r is shown to be tight in the following sense. On the one hand, the problem is already NP-hard for k=1. On the other hand, it is Para-NP-hard for r \\geq 3 and polynomial-time solvable for r \\leq 2.",
      "authors": [
        "Matthias Bentert",
        "Fedor V. Fomin",
        "Petr A. Golovach",
        "and Laure Morelle"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T08:24:27+00:00",
          "link": "https://arxiv.org/abs/2506.22010v1",
          "size": "19kb",
          "version": "v1"
        }
      ],
      "title": "Fault-Tolerant Matroid Bases",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22010",
        "HTML": "https://arxiv.org/html/2506.22010v1",
        "PDF": "https://arxiv.org/pdf/2506.22010"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The research is centered on fault-tolerant bases in matroids, a topic unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22015",
      "abstract": "The rapid growth in complexity and size of modern deep neural networks (DNNs) has increased challenges related to computational costs and memory usage, spurring a growing interest in efficient model compression techniques. Previous state-of-the-art approach proposes using a Torque-inspired regularization which forces the weights of neural modules around a selected pivot point. Whereas, we observe that the pruning effect of this approach is far from perfect, as the post-trained network is still dense and also suffers from high accuracy drop. In this work, we attribute such ineffectiveness to the default linear force application scheme, which imposes inappropriate force on neural module of different distances. To efficiently prune the redundant and distant modules while retaining those that are close and necessary for effective inference, in this work, we propose Exponential Torque Pruning (ETP), which adopts an exponential force application scheme for regularization. Experimental results on a broad range of domains demonstrate that, though being extremely simple, ETP manages to achieve significantly higher compression rate than the previous state-of-the-art pruning strategies with negligible accuracy drop.",
      "authors": [
        "Sarthak Ketanbhai Modi",
        "Lim Zi Pong",
        "Shourya Kuchhal",
        "Yoshi Cao",
        "Yupeng Cheng",
        "Teo Yon Shin",
        "Lin Shang-Wei",
        "Zhiming Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T08:28:21+00:00",
          "link": "https://arxiv.org/abs/2506.22015v1",
          "size": "1740kb",
          "version": "v1"
        }
      ],
      "title": "Towards Universal & Efficient Model Compression via Exponential Torque Pruning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22015",
        "HTML": "https://arxiv.org/html/2506.22015v1",
        "PDF": "https://arxiv.org/pdf/2506.22015"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on model compression techniques, specifically Exponential Torque Pruning, aimed at reducing computational costs and improving efficiency of DNNs. It does not address data engineering or training-stage data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22022",
      "abstract": "Facial stylization aims to transform facial images into appealing, high-quality stylized portraits, with the critical challenge of accurately learning the target style while maintaining content consistency with the original image. Although previous StyleGAN-based methods have made significant advancements, the generated results still suffer from artifacts or insufficient fidelity to the source image. We argue that these issues stem from neglecting semantic shift of the generator during stylization. Therefore, we propose a facial stylization method that integrates semantic preservation constraint and pseudo-paired supervision to enhance the content correspondence and improve the stylization effect. Additionally, we develop a methodology for creating multi-level pseudo-paired datasets to implement supervisory constraint. Furthermore, building upon our facial stylization framework, we achieve more flexible multimodal and reference-guided stylization without complex network architecture designs or additional training. Experimental results demonstrate that our approach produces high-fidelity, aesthetically pleasing facial style transfer that surpasses previous methods.",
      "authors": [
        "Zhanyi Lu",
        "Yue Zhou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T08:44:31+00:00",
          "link": "https://arxiv.org/abs/2506.22022v1",
          "size": "41060kb",
          "version": "v1"
        }
      ],
      "title": "Advancing Facial Stylization through Semantic Preservation Constraint and Pseudo-Paired Supervision",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22022",
        "HTML": "https://arxiv.org/html/2506.22022v1",
        "PDF": "https://arxiv.org/pdf/2506.22022"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This study is centered on facial stylization using semantic preservation constraint and pseudo-paired supervision. It discusses generating stylized portraits but does not engage with LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22023",
      "abstract": "Recently, autoregressive (AR) language models have emerged as a dominant approach in speech synthesis, offering expressive generation and scalable training. However, conventional AR speech synthesis models relying on the next-token prediction paradigm often encounter significant challenges when handling long speech sequences. These models often struggle to construct stable frame-to-frame attention, leading to increased latency and degraded synthesis quality, thereby limiting their feasibility for real-time applications. To address these limitations, we introduce a novel dynamic chunk-wise autoregressive synthesis framework, termed DCAR, designed to enhance both efficiency and intelligibility robustness in AR speech generation. DCAR introduces a chunk-to-frame attention mechanism through training with multi-token prediction, enabling dynamic chunk prediction in variable speech contexts using a lightweight module trained on-policy. DCAR dynamically adjusts the token prediction span, significantly reducing the sequence length dependency while obtaining high synthesis quality. Comprehensive empirical evaluations demonstrate that DCAR substantially outperforms traditional next-token prediction models, achieving up to 72.27% intelligibility improvement and 2.61x inference speedup simultaneously on the test set. Furthermore, we conduct comprehensive analysis to support it as a versatile foundation for next-generation speech synthesis systems.",
      "authors": [
        "Bohan Li",
        "Zhihan Li",
        "Haoran Wang",
        "Hanglei Zhang",
        "Yiwei Guo",
        "Hankun Wang",
        "Xie Chen",
        "Kai Yu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Computation and Language (cs.CL)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T08:45:21+00:00",
          "link": "https://arxiv.org/abs/2506.22023v1",
          "size": "704kb",
          "version": "v1"
        }
      ],
      "title": "Robust and Efficient Autoregressive Speech Synthesis with Dynamic Chunk-wise Prediction Policy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22023",
        "HTML": "https://arxiv.org/html/2506.22023v1",
        "PDF": "https://arxiv.org/pdf/2506.22023"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The work introduces a new framework for autoregressive speech synthesis, focusing on dynamic chunk-wise prediction to improve efficiency and quality. It does not contribute to LLM training data processing or data engineering specifically."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22026",
      "abstract": "Automated scientific idea generation systems have made remarkable progress, yet the automatic evaluation of idea novelty remains a critical and underexplored challenge. Manual evaluation of novelty through literature review is labor-intensive, prone to error due to subjectivity, and impractical at scale. To address these issues, we propose the Idea Novelty Checker, an LLM-based retrieval-augmented generation (RAG) framework that leverages a two-stage retrieve-then-rerank approach. The Idea Novelty Checker first collects a broad set of relevant papers using keyword and snippet-based retrieval, then refines this collection through embedding-based filtering followed by facet-based LLM re-ranking. It incorporates expert-labeled examples to guide the system in comparing papers for novelty evaluation and in generating literature-grounded reasoning. Our extensive experiments demonstrate that our novelty checker achieves approximately 13% higher agreement than existing approaches. Ablation studies further showcases the importance of the facet-based re-ranker in identifying the most relevant literature for novelty evaluation.",
      "authors": [
        "Simra Shahid",
        "Marissa Radensky",
        "Raymond Fok",
        "Pao Siangliulue",
        "Daniel S. Weld",
        "Tom Hope"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T08:47:28+00:00",
          "link": "https://arxiv.org/abs/2506.22026v1",
          "size": "4092kb",
          "version": "v1"
        }
      ],
      "title": "Literature-Grounded Novelty Assessment of Scientific Ideas",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22026",
        "HTML": "https://arxiv.org/html/2506.22026v1",
        "PDF": "https://arxiv.org/pdf/2506.22026"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper presents an LLM-based tool for evaluating the novelty of scientific ideas using a retrieval-augmented approach. It concerns literature review and novelty assessment without addressing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22027",
      "abstract": "Detecting and tracking ground objects using earth observation imagery remains a significant challenge in the field of remote sensing. Continuous maritime ship tracking is crucial for applications such as maritime search and rescue, law enforcement, and shipping analysis. However, most current ship tracking methods rely on geostationary satellites or video satellites. The former offer low resolution and are susceptible to weather conditions, while the latter have short filming durations and limited coverage areas, making them less suitable for the real-world requirements of ship tracking. To address these limitations, we present the Hybrid Optical and Synthetic Aperture Radar (SAR) Ship Re-Identification Dataset (HOSS ReID dataset), designed to evaluate the effectiveness of ship tracking using low-Earth orbit constellations of optical and SAR sensors. This approach ensures shorter re-imaging cycles and enables all-weather tracking. HOSS ReID dataset includes images of the same ship captured over extended periods under diverse conditions, using different satellites of different modalities at varying times and angles. Furthermore, we propose a baseline method for cross-modal ship re-identification, TransOSS, which is built on the Vision Transformer architecture. It refines the patch embedding structure to better accommodate cross-modal tasks, incorporates additional embeddings to introduce more reference information, and employs contrastive learning to pre-train on large-scale optical-SAR image pairs, ensuring the model's ability to extract modality-invariant features. Our dataset and baseline method are publicly available on https://github.com/Alioth2000/Hoss-ReID.",
      "authors": [
        "Han Wang",
        "Shengyang Li",
        "Jian Yang",
        "Yuxuan Liu",
        "Yixuan Lv",
        "Zhuang Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T09:13:22+00:00",
          "link": "https://arxiv.org/abs/2506.22027v1",
          "size": "1008kb",
          "version": "v1"
        }
      ],
      "title": "Cross-modal Ship Re-Identification via Optical and SAR Imagery: A Novel Dataset and Method",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22027",
        "HTML": "https://arxiv.org/html/2506.22027v1",
        "PDF": "https://arxiv.org/pdf/2506.22027"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The research is about cross-modal ship re-identification using a novel dataset combining optical and SAR imagery. It does not cover aspects of LLM training data collection, construction, or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22028",
      "abstract": "Modern industry is increasingly moving away from mass manufacturing, towards more specialized and personalized products. As manufacturing tasks become more complex, full automation is not always an option, human involvement may be required. This has increased the need for advanced human robot collaboration (HRC), and with it, improved methods for interaction, such as voice control. Recent advances in natural language processing, driven by artificial intelligence (AI), have the potential to answer this demand. Large language models (LLMs) have rapidly developed very impressive general reasoning capabilities, and many methods of applying this to robotics have been proposed, including through the use of code generation. This paper presents Language Model Program Voice Control (LMPVC), an LLM-based prototype voice control architecture with integrated policy programming and teaching capabilities, built for use with Robot Operating System 2 (ROS2) compatible robots. The architecture builds on prior works using code generation for voice control by implementing an additional programming and teaching system, the Policy Bank. We find this system can compensate for the limitations of the underlying LLM, and allow LMPVC to adapt to different downstream tasks without a slow and costly training process. The architecture and additional results are released on GitHub (https://github.com/ozzyuni/LMPVC).",
      "authors": [
        "Ossi Parikka",
        "Roel Pieters"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T09:14:14+00:00",
          "link": "https://arxiv.org/abs/2506.22028v1",
          "size": "1769kb",
          "version": "v1"
        }
      ],
      "title": "LMPVC and Policy Bank: Adaptive voice control for industrial robots with code generating LLMs and reusable Pythonic policies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22028",
        "HTML": "https://arxiv.org/html/2506.22028v1",
        "PDF": "https://arxiv.org/pdf/2506.22028"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on an LLM-based prototype for voice control and robotics, emphasizing programming and policy systems rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22032",
      "abstract": "Zero-shot Semantic Segmentation (ZSS) aims to segment both seen and unseen classes using supervision from only seen classes. Beyond adaptation-based methods, distillation-based approaches transfer vision-language alignment of vision-language model, e.g., CLIP, to segmentation models. However, such knowledge transfer remains challenging due to: (1) the difficulty of aligning vision-based features with the textual space, which requires combining spatial precision with vision-language alignment; and (2) the semantic gap between CLIP's global representations and the local, fine-grained features of segmentation models. To address challenge (1), we propose Chimera-Seg, which integrates a segmentation backbone as the body and a CLIP-based semantic head as the head, like the Chimera in Greek mythology, combining spatial precision with vision-language alignment. Specifically, Chimera-Seg comprises a trainable segmentation model and a CLIP Semantic Head (CSH), which maps dense features into the CLIP-aligned space. The CSH incorporates a frozen subnetwork and fixed projection layers from the CLIP visual encoder, along with lightweight trainable components. The partial module from CLIP visual encoder, paired with the segmentation model, retains segmentation capability while easing the mapping to CLIP's semantic space. To address challenge (2), we propose Selective Global Distillation (SGD), which distills knowledge from dense features exhibiting high similarity to the CLIP CLS token, while gradually reducing the number of features used for alignment as training progresses. Besides, we also use a Semantic Alignment Module (SAM) to further align dense visual features with semantic embeddings extracted from the frozen CLIP text encoder. Experiments on two benchmarks show improvements of 0.9% and 1.2% in hIoU.",
      "authors": [
        "Jialei Chen",
        "Xu Zheng",
        "Danda Pani Paudel",
        "Luc Van Gool",
        "Hiroshi Murase",
        "Daisuke Deguchi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T09:26:50+00:00",
          "link": "https://arxiv.org/abs/2506.22032v1",
          "size": "8134kb",
          "version": "v1"
        }
      ],
      "title": "Partial CLIP is Enough: Chimera-Seg for Zero-shot Semantic Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22032",
        "HTML": "https://arxiv.org/html/2506.22032v1",
        "PDF": "https://arxiv.org/pdf/2506.22032"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper discusses a zero-shot semantic segmentation method involving CLIP and does not focus on LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22033",
      "abstract": "As inference workloads for large language models (LLMs) scale to meet growing user demand, pipeline parallelism (PP) has become a widely adopted strategy for multi-GPU deployment, particularly in cross-node setups, to improve key-value (KV) cache capacity and inference throughput. However, PP suffers from inherent inefficiencies caused by three types of execution bubbles-load-imbalance, intra-stage, and inter-stage-which limit pipeline saturation. We present SiPipe, a heterogeneous pipeline design that improves throughput by leveraging underutilized CPU resources to offload auxiliary computation and communication. SiPipe incorporates three key techniques-CPU sampling, a token-safe execution model, and structure-aware transmission-to mitigate pipeline bubbles and improve execution efficiency. Across diverse LLMs, SiPipe achieves up to 2.1 times higher throughput, 43% lower per-token latency, and up to 23% higher average GPU utilization compared to the state-of-the-art vLLM under the same PP configuration, demonstrating its generality across LLMs and deployment scenarios.",
      "authors": [
        "Yongchao He",
        "Bohan Zhao",
        "Zheng Cao"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T09:27:04+00:00",
          "link": "https://arxiv.org/abs/2506.22033v1",
          "size": "1682kb",
          "version": "v1"
        }
      ],
      "title": "SiPipe: Bridging the CPU-GPU Utilization Gap for Efficient Pipeline-Parallel LLM Inference",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22033",
        "HTML": "https://arxiv.org/html/2506.22033v1",
        "PDF": "https://arxiv.org/pdf/2506.22033"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This research presents a pipeline parallelism method to enhance LLM inference, which is unrelated to the training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22034",
      "abstract": "Industrial assembly of deformable linear objects (DLOs) such as cables offers great potential for many industries. However, DLOs pose several challenges for robot-based automation due to the inherent complexity of deformation and, consequentially, the difficulties in anticipating the behavior of DLOs in dynamic situations. Although existing studies have addressed isolated subproblems like shape tracking, grasping, and shape control, there has been limited exploration of integrated workflows that combine these individual processes. To address this gap, we propose an object-centric perception and planning framework to achieve a comprehensive DLO assembly process throughout the industrial value chain. The framework utilizes visual and tactile information to track the DLO's shape as well as contact state across different stages, which facilitates effective planning of robot actions. Our approach encompasses robot-based bin picking of DLOs from cluttered environments, followed by a coordinated handover to two additional robots that mount the DLOs onto designated fixtures. Real-world experiments employing a setup with multiple robots demonstrate the effectiveness of the approach and its relevance to industrial scenarios.",
      "authors": [
        "Kejia Chen",
        "Celina Dettmering",
        "Florian Pachler",
        "Zhuo Liu",
        "Yue Zhang",
        "Tailai Cheng",
        "Jonas Dirr",
        "Zhenshan Bing",
        "Alois Knoll",
        "R\\\"udiger Daub"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T09:28:44+00:00",
          "link": "https://arxiv.org/abs/2506.22034v1",
          "size": "13104kb",
          "version": "v1"
        }
      ],
      "title": "Multi-Robot Assembly of Deformable Linear Objects Using Multi-Modal Perception",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22034",
        "HTML": "https://arxiv.org/html/2506.22034v1",
        "PDF": "https://arxiv.org/pdf/2506.22034"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper describes a framework for the assembly of deformable objects using robots and multi-modal perception, with no relevance to LLM training data processes."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22035",
      "abstract": "Stencil computation, a pivotal numerical method in science and engineering, iteratively updates grid points using weighted neighbor contributions and exhibits strong parallelism for multi-core processors. Current optimization techniques targeting conducting stencil computation on tensor core accelerators incur substantial overheads due to redundant zero-padding during the transformation to matrix multiplication. To address this, we introduce a sparse computation paradigm that eliminates inefficiencies by exploiting specialized hardware units.\n  This paper exploits the sparsity in these matrices as a feature and presents SPTCStencil, a high-performance stencil computation system accelerated by Sparse Tensor Core (SpTCs). SPTCStencil is the first to harness SpTCs for acceleration beyond deep learning domains. First, Our approach generalizes an efficient transformation of stencil computation into matrix multiplications and specializes this conversion for SpTC compatibility through a novel sparsification strategy. Furthermore, SPTCStencil incorporates a high-performance GPU kernel with systematic optimizations designed to maximize efficiency on SpTCs. Experimental evaluations demonstrate that SPTCStencil 5.46$\\times$ and Tensor Core-based approaches by 2.00$\\times$ on average.",
      "authors": [
        "Qiqi GU",
        "Chenpeng Wu",
        "Heng Shi",
        "Jianguo Yao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T09:29:29+00:00",
          "link": "https://arxiv.org/abs/2506.22035v1",
          "size": "662kb",
          "version": "v1"
        }
      ],
      "title": "SPTCStencil: Unleashing Sparse Tensor Cores for Stencil Computation via Strided Swap",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22035",
        "HTML": "https://arxiv.org/html/2506.22035v1",
        "PDF": "https://arxiv.org/pdf/2506.22035"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The focus of this paper is on stencil computation using Sparse Tensor Cores, which is not related to the training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22036",
      "abstract": "With the increasing multimodal knowledge privatization requirements, multimodal knowledge graphs in different institutes are usually decentralized, lacking of effective collaboration system with both stronger reasoning ability and transmission safety guarantees. In this paper, we propose the Federated Multimodal Knowledge Graph Completion (FedMKGC) task, aiming at training over federated MKGs for better predicting the missing links in clients without sharing sensitive knowledge. We propose a framework named MMFeD3-HidE for addressing multimodal uncertain unavailability and multimodal client heterogeneity challenges of FedMKGC. (1) Inside the clients, our proposed Hyper-modal Imputation Diffusion Embedding model (HidE) recovers the complete multimodal distributions from incomplete entity embeddings constrained by available modalities. (2) Among clients, our proposed Multimodal FeDerated Dual Distillation (MMFeD3) transfers knowledge mutually between clients and the server with logit and feature distillation to improve both global convergence and semantic consistency. We propose a FedMKGC benchmark for a comprehensive evaluation, consisting of a general FedMKGC backbone named MMFedE, datasets with heterogeneous multimodal information, and three groups of constructed baselines. Experiments conducted on our benchmark validate the effectiveness, semantic consistency, and convergence robustness of MMFeD3-HidE.",
      "authors": [
        "Ying Zhang",
        "Yu Zhao",
        "Xuhui Sui",
        "Baohang Zhou",
        "Xiangrui Cai",
        "Li Shen",
        "Xiaojie Yuan",
        "Dacheng Tao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T09:32:58+00:00",
          "link": "https://arxiv.org/abs/2506.22036v1",
          "size": "1088kb",
          "version": "v1"
        }
      ],
      "title": "Hyper-modal Imputation Diffusion Embedding with Dual-Distillation for Federated Multimodal Knowledge Graph Completion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22036",
        "HTML": "https://arxiv.org/html/2506.22036v1",
        "PDF": "https://arxiv.org/pdf/2506.22036"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on federated multimodal knowledge graph completion, involving frameworks for entity embeddings and knowledge transfer, which are not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22037",
      "abstract": "Model reconstruction is a method used to drive the development of complex system development processes in model-based systems engineering. Currently, during the iterative design process of a system, there is a lack of an effective method to manage changes in development requirements, such as development cycle requirements and cost requirements, and to realize the reconstruction of the system development process model. To address these issues, this paper proposes a model reconstruction method to support the development process model. Firstly, the KARMA language, based on the GOPPRR-E metamodeling method, is utilized to uniformly formalize the process models constructed based on different modeling languages. Secondly, a model reconstruction framework is introduced. This framework takes a structured development requirements based natural language as input, employs natural language processing techniques to analyze the development requirements text, and extracts structural and optimization constraint information. Then, after structural reorganization and algorithm optimization, a development process model that meets the development requirements is obtained. Finally, as a case study, the development process of the aircraft onboard maintenance system is reconstructed. The results demonstrate that this method can significantly enhance the design efficiency of the development process.",
      "authors": [
        "Jiawei Li",
        "Zan Liang",
        "Guoxin Wang",
        "Jinzhi Lu",
        "Yan Yan",
        "Shouxuan Wu",
        "Hao Wang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T09:34:08+00:00",
          "link": "https://arxiv.org/abs/2506.22037v1",
          "size": "703kb",
          "version": "v1"
        }
      ],
      "title": "KARMA Approach supporting Development Process Reconstruction in Model-based Systems Engineering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22037",
        "PDF": "https://arxiv.org/pdf/2506.22037"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper proposes a method for reconstructing system development processes in model-based systems engineering, which is unrelated to LLM training data creation or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22038",
      "abstract": "This study focuses on evaluating the performance of machine translations (MTs) compared to human translations (HTs) in English-to-Chinese children's literature translation (CLT) from a stylometric perspective. The research constructs a Peter Pan corpus, comprising 21 translations: 7 human translations (HTs), 7 large language model translations (LLMs), and 7 neural machine translation outputs (NMTs). The analysis employs a generic feature set (including lexical, syntactic, readability, and n-gram features) and a creative text translation (CTT-specific) feature set, which captures repetition, rhythm, translatability, and miscellaneous levels, yielding 447 linguistic features in total.\n  Using classification and clustering techniques in machine learning, we conduct a stylometric analysis of these translations. Results reveal that in generic features, HTs and MTs exhibit significant differences in conjunction word distributions and the ratio of 1-word-gram-YiYang, while NMTs and LLMs show significant variation in descriptive words usage and adverb ratios. Regarding CTT-specific features, LLMs outperform NMTs in distribution, aligning more closely with HTs in stylistic characteristics, demonstrating the potential of LLMs in CLT.",
      "authors": [
        "Delu Kong and Lieve Macken"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T09:34:40+00:00",
          "link": "https://arxiv.org/abs/2506.22038v1",
          "size": "5849kb",
          "version": "v1"
        }
      ],
      "title": "Can Peter Pan Survive MT? A Stylometric Study of LLMs, NMTs, and HTs in Children's Literature Translation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22038",
        "HTML": "https://arxiv.org/html/2506.22038v1",
        "PDF": "https://arxiv.org/pdf/2506.22038"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper constructs a corpus for evaluating LLM and NMT translations in children's literature but does not propose novel data processing methods for LLM training, focusing instead on stylistic analysis."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22039",
      "abstract": "Time Series Foundation Models (TSFMs) have achieved remarkable success through large-scale pretraining. However, their design primarily targets real-valued series, limiting their ability to handle general forecasting tasks involving diverse and often heterogeneous covariates--such as categorical variables and multimodal data (e.g., images, text)--which are typically task-specific and difficult to leverage during pretraining. To address this gap, we propose Unified Covariate Adaptation (UniCA), a framework to bridge TSFMs with general covariate-aware forecasting. UniCA first performs covariate homogenization to transform heterogeneous covariates into high-level homogeneous series representations and then fuses them via a unified attention-based fusion mechanism. UniCA is compatible and universal for adaptation with both homogeneous and heterogeneous covariates, incorporating extra covariate information while preserving the generalization ability of TSFMs.Extensive experiments on multiple unimodal and multimodal covariate-aware forecasting benchmarks demonstrate the superiority of UniCA, highlighting the promise of covariate-aware TSFM adaptation in real-world forecasting scenarios. Codes are released on https://github.com/hanlu-nju/UniCA.",
      "authors": [
        "Lu Han",
        "Yu Liu",
        "Qiwen Deng",
        "Jian Jiang",
        "Yinbo Sun",
        "Zhe Yu",
        "Binfeng Wang",
        "Xingyu Lu",
        "Lintao Ma",
        "Han-Jia Ye",
        "De-Chuan Zhan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T09:35:51+00:00",
          "link": "https://arxiv.org/abs/2506.22039v1",
          "size": "640kb",
          "version": "v1"
        }
      ],
      "title": "UniCA: Adapting Time Series Foundation Model to General Covariate-Aware Forecasting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22039",
        "HTML": "https://arxiv.org/html/2506.22039v1",
        "PDF": "https://arxiv.org/pdf/2506.22039"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper introduces a method for adapting time series foundation models to covariate-aware forecasting, which does not involve language model training data pipelines."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22044",
      "abstract": "Reconstruction and rendering-based talking head synthesis methods achieve high-quality results with strong identity preservation but are limited by their dependence on identity-specific models. Each new identity requires training from scratch, incurring high computational costs and reduced scalability compared to generative model-based approaches. To overcome this limitation, we propose FIAG, a novel 3D speaking head synthesis framework that enables efficient identity-specific adaptation using only a few training footage. FIAG incorporates Global Gaussian Field, which supports the representation of multiple identities within a shared field, and Universal Motion Field, which captures the common motion dynamics across diverse identities. Benefiting from the shared facial structure information encoded in the Global Gaussian Field and the general motion priors learned in the motion field, our framework enables rapid adaptation from canonical identity representations to specific ones with minimal data. Extensive comparative and ablation experiments demonstrate that our method outperforms existing state-of-the-art approaches, validating both the effectiveness and generalizability of the proposed framework. Code is available at: \\textit{https://github.com/gme-hong/FIAG}.",
      "authors": [
        "Hong Nie",
        "Fuyuan Cao",
        "Lu Chen",
        "Fengxin Chen",
        "Yuefeng Zou",
        "Jun Yu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T09:42:30+00:00",
          "link": "https://arxiv.org/abs/2506.22044v1",
          "size": "10724kb",
          "version": "v1"
        }
      ],
      "title": "Few-Shot Identity Adaptation for 3D Talking Heads via Global Gaussian Field",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22044",
        "HTML": "https://arxiv.org/html/2506.22044v1",
        "PDF": "https://arxiv.org/pdf/2506.22044"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on a method for 3D talking head synthesis and identity adaptation, utilizing Global Gaussian Fields, which is unrelated to the processing or preparation of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22047",
      "abstract": "It is shown that shape preservation is decidable for top-down tree transducers, bottom-up tree transducers, and for compositions of total deterministic macro tree transducers. Moreover, if a transducer is shape preserving, then it can be brought into a particular normal form, where every input node creates exactly one output node.",
      "authors": [
        "Paul Gallot",
        "Sebastian Maneth"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Formal Languages and Automata Theory (cs.FL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T09:43:20+00:00",
          "link": "https://arxiv.org/abs/2506.22047v1",
          "size": "29kb",
          "version": "v1"
        }
      ],
      "title": "Shape Preserving Tree Transducers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22047",
        "HTML": "https://arxiv.org/html/2506.22047v1",
        "PDF": "https://arxiv.org/pdf/2506.22047"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper is about shape preservation in tree transducers and does not discuss any aspect of LLM training data or data processing methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22049",
      "abstract": "Modern Large Language Models, such as the LLaMA, Qwen and DeepSeek series, predominantly adopt the Pre-LayerNorm (Pre-LN) Transformer architecture. While being stable during pretraining and scalable to large model sizes, Pre-LN suffers from an exponential growth in activation variance across layers, causing the residual path to dominate over sub-layer outputs and limiting the learning capacity of deeper layers. To mitigate this issue, we propose Gradient-Preserving Activation Scaling (GPAS), a simple technique that can be used in combination with existing approaches. GPAS works by scaling down the intermediate activations while keeping their gradients unchanged. This leaves information in the activations intact, and avoids the gradient vanishing problem associated with gradient downscaling. Extensive experiments across various model sizes from 71M to 1B show that GPAS achieves consistent performance gains. Beyond enhancing Pre-LN Transformers, GPAS also shows promise in improving alternative architectures such as Sandwich-LN and DeepNorm, demonstrating its versatility and potential for improving training dynamics in a wide range of settings.",
      "authors": [
        "Tianhao Chen",
        "Xin Xu",
        "Zijing Liu",
        "Pengxiang Li",
        "Xinyuan Song",
        "Ajay Kumar Jaiswal",
        "Fan Zhang",
        "Jishan Hu",
        "Yang Wang",
        "Hao Chen",
        "Shizhe Diao",
        "Shiwei Liu",
        "Yu Li",
        "Yin Lu",
        "Can Yang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T09:45:15+00:00",
          "link": "https://arxiv.org/abs/2506.22049v1",
          "size": "949kb",
          "version": "v1"
        }
      ],
      "title": "GPAS: Accelerating Convergence of LLM Pretraining via Gradient-Preserving Activation Scaling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22049",
        "HTML": "https://arxiv.org/html/2506.22049v1",
        "PDF": "https://arxiv.org/pdf/2506.22049"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper discusses a technique for stabilizing the training of LLMs via activation scaling, focusing on model architecture rather than the processing or preparation of training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22050",
      "abstract": "This study explores Machine Translationese (MTese) -- the linguistic peculiarities of machine translation outputs -- focusing on the under-researched English-to-Chinese language pair in news texts. We construct a large dataset consisting of 4 sub-corpora and employ a comprehensive five-layer feature set. Then, a chi-square ranking algorithm is applied for feature selection in both classification and clustering tasks. Our findings confirm the presence of MTese in both Neural Machine Translation systems (NMTs) and Large Language Models (LLMs). Original Chinese texts are nearly perfectly distinguishable from both LLM and NMT outputs. Notable linguistic patterns in MT outputs are shorter sentence lengths and increased use of adversative conjunctions. Comparing LLMs and NMTs, we achieve approximately 70% classification accuracy, with LLMs exhibiting greater lexical diversity and NMTs using more brackets. Additionally, translation-specific LLMs show lower lexical diversity but higher usage of causal conjunctions compared to generic LLMs. Lastly, we find no significant differences between LLMs developed by Chinese firms and their foreign counterparts.",
      "authors": [
        "Delu Kong and Lieve Macken"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T09:45:37+00:00",
          "link": "https://arxiv.org/abs/2506.22050v1",
          "size": "2729kb",
          "version": "v1"
        }
      ],
      "title": "Decoding Machine Translationese in English-Chinese News: LLMs vs. NMTs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22050",
        "HTML": "https://arxiv.org/html/2506.22050v1",
        "PDF": "https://arxiv.org/pdf/2506.22050"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper constructs a dataset for analyzing MTese in English-Chinese translations, which involves some aspects of data collection and construction relevant to LLM evaluation but does not contribute new methods for LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22052",
      "abstract": "V2X communication has become crucial for enhancing road safety, especially for Vulnerable Road Users (VRU) such as pedestrians and cyclists. However, the increasing number of devices communicating on the same channels will lead to significant channel load. To address this issue this study evaluates the effectiveness of Redundancy Mitigation (RM) for VRU Awareness Messages (VAM), focusing specifically on cyclists. The objective of RM is to minimize the transmission of redundant information. We conducted a simulation study using a urban scenario with a high bicycle density based on traffic data from Hannover, Germany. This study assessed the impact of RM on channel load, measured by Channel Busy Ratio (CBR), and safety, measured by VRU Perception Rate (VPR) in simulation. To evaluate the accuracy and reliability of the RM mechanisms, we analyzed the actual differences in position, speed, and heading between the ego VRU and the VRU, which was assumed to be redundant. Our findings indicate that while RM can reduce channel congestion, it also leads to a decrease in VPR. The analysis of actual differences revealed that the RM mechanism standardized by ETSI often uses outdated information, leading to significant discrepancies in position, speed, and heading, which could result in dangerous situations. To address these limitations, we propose an adapted RM mechanism that improves the balance between reducing channel load and maintaining VRU awareness. The adapted approach shows a significant reduction in maximum CBR and a less significant decrease in VPR compared to the standardized RM. Moreover, it demonstrates better performance in the actual differences in position, speed, and heading, thereby enhancing overall safety. Our results highlight the need for further research to optimize RM techniques and ensure they effectively enhance V2X communication without compromising the safety of VRUs.",
      "authors": [
        "Nico Ostendorf",
        "Keno Garlichs",
        "Lars Wolf"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Emerging Technologies (cs.ET)",
        "Networking and Internet Architecture (cs.NI)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T09:47:05+00:00",
          "link": "https://arxiv.org/abs/2506.22052v1",
          "size": "690kb",
          "version": "v1"
        }
      ],
      "title": "Evaluating Redundancy Mitigation in Vulnerable Road User Awareness Messages for Bicycles",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22052",
        "HTML": "https://arxiv.org/html/2506.22052v1",
        "PDF": "https://arxiv.org/pdf/2506.22052"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper deals with redundancy mitigation in V2X communication for bicycle safety, which is not related to LLM training data or its processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22053",
      "abstract": "This paper investigates the stability of phase retrieval by analyzing the condition number of the nonlinear map $\\Psi_{\\boldsymbol{A}}(\\boldsymbol{x}) = \\bigl(\\lvert \\langle {\\boldsymbol{a}}_j, \\boldsymbol{x} \\rangle \\rvert^2 \\bigr)_{1 \\le j \\le m}$, where $\\boldsymbol{a}_j \\in \\mathbb{H}^n$ are known sensing vectors with $\\mathbb{H} \\in \\{\\mathbb{R}, \\mathbb{C}\\}$. For each $p \\ge 1$, we define the condition number $\\beta_{\\Psi_{\\boldsymbol{A}}}^{\\ell_p}$ as the ratio of optimal upper and lower Lipschitz constants of $\\Psi_{\\boldsymbol{A}}$ measured in the $\\ell_p$ norm, with respect to the metric $\\mathrm {dist}_\\mathbb{H}\\left(\\boldsymbol{x}, \\boldsymbol{y}\\right) = \\|\\boldsymbol{x} \\boldsymbol{x}^\\ast - \\boldsymbol{y} \\boldsymbol{y}^\\ast\\|_*$. We establish universal lower bounds on $\\beta_{\\Psi_{\\boldsymbol{A}}}^{\\ell_p}$ for any sensing matrix $\\boldsymbol{A} \\in \\mathbb{H}^{m \\times d}$, proving that $\\beta_{\\Psi_{\\boldsymbol{A}}}^{\\ell_1} \\ge \\pi/2$ and $\\beta_{\\Psi_{\\boldsymbol{A}}}^{\\ell_2} \\ge \\sqrt{3}$ in the real case $(\\mathbb{H} = \\mathbb{R})$, and $\\beta_{\\Psi_{\\boldsymbol{A}}}^{\\ell_p} \\ge 2$ for $p=1,2$ in the complex case $(\\mathbb{H} = \\mathbb{C})$. These bounds are shown to be asymptotically tight: both a deterministic harmonic frame $\\boldsymbol{E}_m \\in \\mathbb{R}^{m \\times 2}$ and Gaussian random matrices $\\boldsymbol{A} \\in \\mathbb{H}^{m \\times d}$ asymptotically attain them. Notably, the harmonic frame $\\boldsymbol{E}_m \\in \\mathbb{R}^{m \\times 2}$ achieves the optimal lower bound $\\sqrt{3}$ for all $m \\ge 3$ when $p=2$, thus serving as an optimal sensing matrix within $\\boldsymbol{A} \\in \\mathbb{R}^{m \\times 2}$. Our results provide the first explicit uniform lower bounds on $\\beta_{\\Psi_{\\boldsymbol{A}}}^{\\ell_p}$ and offer insights into the fundamental stability limits of phase retrieval.",
      "authors": [
        "Haiyang Peng",
        "Deren Han",
        "Meng Huang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Functional Analysis (math.FA)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T09:47:47+00:00",
          "link": "https://arxiv.org/abs/2506.22053v1",
          "size": "34kb",
          "version": "v1"
        }
      ],
      "title": "The Condition Number in Phase Retrieval from Intensity Measurements",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22053",
        "HTML": "https://arxiv.org/html/2506.22053v1",
        "PDF": "https://arxiv.org/pdf/2506.22053"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on the stability of phase retrieval by analyzing the condition number of a nonlinear map, which does not relate to training data processing for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22054",
      "abstract": "With an increasing share of renewable energy sources, accurate and efficient modeling of grid-forming inverters is becoming crucial for system stability. Linear methods are a powerful tool for understanding dynamics close to an operating point, but usually depend on the reference trajectory. Thus, small deviations can render linear models invalid over time, posing a significant challenge in practice, and complicating theoretical analysis. As a solution, we show that the complex phase offers a robust formulation independent of reference phases and frequencies, thus preserving invariance properties under linearization. This enables robust system identification during realistic conditions and opens the road to powerful stability analysis of inverter-based grids.",
      "authors": [
        "Jakob Niehues",
        "Anna B\\\"uttner",
        "Anne Riegler",
        "Frank Hellmann"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T09:49:07+00:00",
          "link": "https://arxiv.org/abs/2506.22054v1",
          "size": "518kb",
          "version": "v1"
        }
      ],
      "title": "Complex Phase Analysis of Power Grid Dynamics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22054",
        "HTML": "https://arxiv.org/html/2506.22054v1",
        "PDF": "https://arxiv.org/pdf/2506.22054"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper discusses power grid dynamics and modeling grid-forming inverters, irrelevant to large language model training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22055",
      "abstract": "The volatility and complex dynamics of cryptocurrency markets present unique challenges for accurate price forecasting. This research proposes a hybrid deep learning and machine learning model that integrates Long Short-Term Memory (LSTM) networks and Extreme Gradient Boosting (XGBoost) for cryptocurrency price prediction. The LSTM component captures temporal dependencies in historical price data, while XGBoost enhances prediction by modeling nonlinear relationships with auxiliary features such as sentiment scores and macroeconomic indicators. The model is evaluated on historical datasets of Bitcoin, Ethereum, Dogecoin, and Litecoin, incorporating both global and localized exchange data. Comparative analysis using Mean Absolute Percentage Error (MAPE) and Min-Max Normalized Root Mean Square Error (MinMax RMSE) demonstrates that the LSTM+XGBoost hybrid consistently outperforms standalone models and traditional forecasting methods. This study underscores the potential of hybrid architectures in financial forecasting and provides insights into model adaptability across different cryptocurrencies and market contexts.",
      "authors": [
        "Mehul Gautam"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T09:49:25+00:00",
          "link": "https://arxiv.org/abs/2506.22055v1",
          "size": "3409kb",
          "version": "v1"
        }
      ],
      "title": "crypto price prediction using lstm+xgboost",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22055",
        "HTML": "https://arxiv.org/html/2506.22055v1",
        "PDF": "https://arxiv.org/pdf/2506.22055"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This research on cryptocurrency price prediction using LSTM and XGBoost hybrid models is not related to processing or engineering of training data for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22056",
      "abstract": "Trajectory data, capturing human actions and environmental states across various modalities, holds significant potential for enhancing AI agent capabilities, particularly in GUI environments. However, how to model the representation of trajectory-level data presents a significant challenge that has not been systematically addressed amid explosive trajectory data growth. In this work, we introduce Multimodal Trajectory Retrieval, bridging the gap between universal retrieval and agent-centric trajectory modeling. We construct the Unified Agent Trajectory Dataset (UATD) from annotated demonstrations and states across diverse real-world scenarios. Based on this, we present GAE-Bench, a benchmark containing a large number of trajectory-based retrieval pairs. In addition, we propose GAE-Retriever, a multimodal retrieval framework that adopts vision-language models and incorporates optimized contrastive learning through a token selection and the GradCache mechanism. Comprehensive evaluations across multiple datasets show that GAE-Retriever consistently outperforms strong baselines in retrieval recall, highlighting its effectiveness in advancing multimodal trajectory retrieval.",
      "authors": [
        "Xuan Zhang",
        "Ziyan Jiang",
        "Rui Meng",
        "Yifei Leng",
        "Zhenbang Xiao",
        "Zora Zhiruo Wang",
        "Yanyi Shang",
        "Dehan Kong"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T09:50:38+00:00",
          "link": "https://arxiv.org/abs/2506.22056v1",
          "size": "1179kb",
          "version": "v1"
        }
      ],
      "title": "Universal Retrieval for Multimodal Trajectory Modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22056",
        "HTML": "https://arxiv.org/html/2506.22056v1",
        "PDF": "https://arxiv.org/pdf/2506.22056"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper introduces multimodal trajectory retrieval and new datasets for AI agents, but it does not address LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22058",
      "abstract": "Recent advancements in large language models (LLMs) have significantly advanced complex reasoning capabilities, particularly through extended chain-of-thought (CoT) reasoning that incorporates mechanisms such as backtracking, self-reflection and self-correction. Despite these developments, the self-correction abilities of LLMs during long CoT reasoning remain underexplored. And recent findings on overthinking suggest that such models often engage in unnecessarily redundant reasoning. In this work, we empirically show that the first reasoning step exerts a disproportionately large influence on the final prediction - errors introduced at this stage can substantially degrade subsequent reasoning quality. This phenomenon is consistently observed across two state-of-the-art open-source reasoning model families: DeepSeek-R1 and Qwen3. To address this, we propose an efficient sampling strategy that leverages a reward model to identify and retain high-quality first reasoning steps while discarding suboptimal ones, achieving up to a 70% reduction in inference cost without sacrificing accuracy. Finally, we introduce a new benchmark specifically constructed with deliberately flawed first reasoning steps to systematically evaluate model self-correction capabilities, offering a foundation for future research on robust reasoning in LLMs.",
      "authors": [
        "Baohao Liao",
        "Xinyi Chen",
        "Sara Rajaee",
        "Yuhui Xu",
        "Christian Herold",
        "Anders S{\\o}gaard",
        "Maarten de Rijke",
        "Christof Monz"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T09:53:57+00:00",
          "link": "https://arxiv.org/abs/2506.22058v1",
          "size": "152kb",
          "version": "v1"
        }
      ],
      "title": "Lost at the Beginning of Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22058",
        "HTML": "https://arxiv.org/html/2506.22058v1",
        "PDF": "https://arxiv.org/pdf/2506.22058"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The research focuses on reasoning capabilities and self-correction in large language models, without contributing to the processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22061",
      "abstract": "We provide a positive answer to a long-standing open question of the decidability of the not-contains string predicate. Not-contains is practically relevant, for instance in symbolic execution of string manipulating programs. Particularly, we show that the predicate notContains(x1 ... xn, y1 ... ym), where x1 ... xn and y1 ... ym are sequences of string variables constrained by regular languages, is decidable. Decidability of a not-contains predicate combined with chain-free word equations and regular membership constraints follows.",
      "authors": [
        "Vojt\\v{e}ch Havlena and Michal He\\v{c}ko and Luk\\'a\\v{s} Hol\\'ik and Ond\\v{r}ej Leng\\'al"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Formal Languages and Automata Theory (cs.FL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T09:56:36+00:00",
          "link": "https://arxiv.org/abs/2506.22061v1",
          "size": "280kb",
          "version": "v1"
        }
      ],
      "title": "Negated String Containment is Decidable (Technical Report)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22061",
        "HTML": "https://arxiv.org/html/2506.22061v1",
        "PDF": "https://arxiv.org/pdf/2506.22061"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on the decidability of the not-contains string predicate in string manipulation, which is not related to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22062",
      "abstract": "We introduce the Minecraft Dialogue Corpus with Reference (MDC-R). MDC-R is a new language resource that supplements the original Minecraft Dialogue Corpus (MDC) with expert annotations of anaphoric and deictic reference. MDC's task-orientated, multi-turn, situated dialogue in a dynamic environment has motivated multiple annotation efforts, owing to the interesting linguistic phenomena that this setting gives rise to. We believe it can serve as a valuable resource when annotated with reference, too. Here, we discuss our method of annotation and the resulting corpus, and provide both a quantitative and a qualitative analysis of the data. Furthermore, we carry out a short experiment demonstrating the usefulness of our corpus for referring expression comprehension.",
      "authors": [
        "Chris Madge",
        "Maris Camilleri",
        "Paloma Carretero Garcia",
        "Mladen Karan",
        "Juexi Shao",
        "Prashant Jayannavar",
        "Julian Hough",
        "Benjamin Roth",
        "Massimo Poesio"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T09:56:40+00:00",
          "link": "https://arxiv.org/abs/2506.22062v1",
          "size": "8497kb",
          "version": "v1"
        }
      ],
      "title": "MDC-R: The Minecraft Dialogue Corpus with Reference",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22062",
        "HTML": "https://arxiv.org/html/2506.22062v1",
        "PDF": "https://arxiv.org/pdf/2506.22062"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a dialogue corpus with new annotations, which is related to data enrichment. However, it does not propose novel data processing methods for LLM training, focusing instead on annotation and data analysis."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22063",
      "abstract": "Linear measurements of the left ventricle (LV) in the Parasternal Long Axis (PLAX) view using B-mode echocardiography are crucial for cardiac assessment. These involve placing 4-6 landmarks along a virtual scanline (SL) perpendicular to the LV axis near the mitral valve tips. Manual placement is time-consuming and error-prone, while existing deep learning methods often misalign landmarks, causing inaccurate measurements. We propose a novel framework that enhances LV measurement accuracy by enforcing straight-line constraints. A landmark detector is trained on Anatomical M-Mode (AMM) images, computed in real time from B-mode videos, then transformed back to B-mode space. This approach addresses misalignment and reduces measurement errors. Experiments show improved accuracy over standard B-mode methods, and the framework generalizes well across network architectures. Our semi-automatic design includes a human-in-the-loop step where the user only places the SL, simplifying interaction while preserving alignment flexibility and clinical relevance.",
      "authors": [
        "Durgesh K. Singh",
        "Ahcene Boubekki",
        "Qing Cao",
        "Svein Arne Aase",
        "Robert Jenssen",
        "Michael Kampffmeyer"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T09:57:17+00:00",
          "link": "https://arxiv.org/abs/2506.22063v1",
          "size": "7335kb",
          "version": "v1"
        }
      ],
      "title": "EnLVAM: Enhanced Left Ventricle Linear Measurements Utilizing Anatomical Motion Mode",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22063",
        "HTML": "https://arxiv.org/html/2506.22063v1",
        "PDF": "https://arxiv.org/pdf/2506.22063"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper is about improving cardiac measurement accuracy using a novel framework and not related to LLM training data or data processing for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22065",
      "abstract": "Audio-driven portrait animation, which synthesizes realistic videos from reference images using audio signals, faces significant challenges in real-time generation of high-fidelity, temporally coherent animations. While recent diffusion-based methods improve generation quality by integrating audio into denoising processes, their reliance on frame-by-frame UNet architectures introduces prohibitive latency and struggles with temporal consistency. This paper introduces MirrorMe, a real-time, controllable framework built on the LTX video model, a diffusion transformer that compresses video spatially and temporally for efficient latent space denoising. To address LTX's trade-offs between compression and semantic fidelity, we propose three innovations: 1. A reference identity injection mechanism via VAE-encoded image concatenation and self-attention, ensuring identity consistency; 2. A causal audio encoder and adapter tailored to LTX's temporal structure, enabling precise audio-expression synchronization; and 3. A progressive training strategy combining close-up facial training, half-body synthesis with facial masking, and hand pose integration for enhanced gesture control. Extensive experiments on the EMTD Benchmark demonstrate MirrorMe's state-of-the-art performance in fidelity, lip-sync accuracy, and temporal stability.",
      "authors": [
        "Dechao Meng",
        "Steven Xiao",
        "Xindi Zhang",
        "Guangyuan Wang",
        "Peng Zhang",
        "Qi Wang",
        "Bang Zhang",
        "Liefeng Bo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T09:57:23+00:00",
          "link": "https://arxiv.org/abs/2506.22065v1",
          "size": "6045kb",
          "version": "v1"
        }
      ],
      "title": "MirrorMe: Towards Realtime and High Fidelity Audio-Driven Halfbody Animation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22065",
        "HTML": "https://arxiv.org/html/2506.22065v1",
        "PDF": "https://arxiv.org/pdf/2506.22065"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper introduces a framework for real-time audio-driven animation and does not address LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22066",
      "abstract": "Operators performing high-stakes, safety-critical tasks - such as air traffic controllers, surgeons, or mission control personnel - must maintain exceptional cognitive performance under variable and often stressful conditions. This paper presents a phased methodological approach to building cognitive monitoring systems for such environments. By integrating insights from human factors research, simulation-based training, sensor technologies, and fundamental psychological principles, the proposed framework supports real-time performance assessment with minimum intrusion. The approach begins with simplified simulations and evolves towards operational contexts. Key challenges addressed include variability in workload, the effects of fatigue and stress, thus the need for adaptive monitoring for early warning support mechanisms. The methodology aims to improve situational awareness, reduce human error, and support decision-making without undermining operator autonomy. Ultimately, the work contributes to the development of resilient and transparent systems in domains where human performance is critical to safety.",
      "authors": [
        "Maciej Grzeszczuk",
        "Grzegorz Pochwatko",
        "Barbara Karpowicz",
        "Stanis{\\l}aw Knapi\\'nski",
        "Wies{\\l}aw Kope\\'c"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T09:57:42+00:00",
          "link": "https://arxiv.org/abs/2506.22066v1",
          "size": "19824kb",
          "version": "v1"
        }
      ],
      "title": "Building Trustworthy Cognitive Monitoring for Safety-Critical Human Tasks: A Phased Methodological Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22066",
        "HTML": "https://arxiv.org/html/2506.22066v1",
        "PDF": "https://arxiv.org/pdf/2506.22066"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The focus of this paper is on cognitive monitoring systems in safety-critical tasks, not on LLM data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22068",
      "abstract": "With the deep penetration of Artificial Intelligence (AI) in the transportation sector, intelligent cockpits, autonomous driving, and intelligent road networks are developing at an unprecedented pace. However, the data ecosystems of these three key areas are increasingly fragmented and incompatible. Especially, existing testing methods rely on data stacking, fail to cover all edge cases, and lack flexibility. To address this issue, this paper introduces the concept of \"Query as Test\" (QaT). This concept shifts the focus from rigid, prescripted test cases to flexible, on-demand logical queries against a unified data representation. Specifically, we identify the need for a fundamental improvement in data storage and representation, leading to our proposal of \"Extensible Scenarios Notations\" (ESN). ESN is a novel declarative data framework based on Answer Set Programming (ASP), which uniformly represents heterogeneous multimodal data from the cockpit, vehicle, and road as a collection of logical facts and rules. This approach not only achieves deep semantic fusion of data, but also brings three core advantages: (1) supports complex and flexible semantic querying through logical reasoning; (2) provides natural interpretability for decision-making processes; (3) allows for on-demand data abstraction through logical rules, enabling fine-grained privacy protection. We further elaborate on the QaT paradigm, transforming the functional validation and safety compliance checks of autonomous driving systems into logical queries against the ESN database, significantly enhancing the expressiveness and formal rigor of the testing. Finally, we introduce the concept of \"Validation-Driven Development\" (VDD), which suggests to guide developments by logical validation rather than quantitative testing in the era of Large Language Models, in order to accelerating the iteration and development process.",
      "authors": [
        "Shengyue Yao",
        "Runqing Guo",
        "Yangyang Qin",
        "Miangbing Meng",
        "Jipeng Cao",
        "Yilun Lin",
        "Yisheng Lv",
        "Fei-Yue Wang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T09:59:58+00:00",
          "link": "https://arxiv.org/abs/2506.22068v1",
          "size": "667kb",
          "version": "v1"
        }
      ],
      "title": "Query as Test: An Intelligent Driving Test and Data Storage Method for Integrated Cockpit-Vehicle-Road Scenarios",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22068",
        "HTML": "https://arxiv.org/html/2506.22068v1",
        "PDF": "https://arxiv.org/pdf/2506.22068"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on data storage and logical querying for autonomous driving systems using the 'Query as Test' concept and 'Extensible Scenarios Notations.' It does not address any aspect of LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22069",
      "abstract": "We propose a novel approach for estimating the relative pose between rolling shutter cameras using the intersections of line projections with a single scanline per image. This allows pose estimation without explicitly modeling camera motion. Alternatively, scanlines can be selected within a single image, enabling single-view relative pose estimation for scanlines of rolling shutter cameras. Our approach is designed as a foundational building block for rolling shutter structure-from-motion (SfM), where no motion model is required, and each scanline's pose can be computed independently. %\nWe classify minimal solvers for this problem in both generic and specialized settings, including cases with parallel lines and known gravity direction, assuming known intrinsics and no lens distortion. Furthermore, we develop minimal solvers for the parallel-lines scenario, both with and without gravity priors, by leveraging connections between this problem and the estimation of 2D structure from 1D cameras. %\nExperiments on rolling shutter images from the Fastec dataset demonstrate the feasibility of our approach for initializing rolling shutter SfM, highlighting its potential for further development. %\nThe code will be made publicly available.",
      "authors": [
        "Petr Hruby",
        "Marc Pollefeys"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T10:00:21+00:00",
          "link": "https://arxiv.org/abs/2506.22069v1",
          "size": "1855kb",
          "version": "v1"
        }
      ],
      "title": "Single-Scanline Relative Pose Estimation for Rolling Shutter Cameras",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22069",
        "PDF": "https://arxiv.org/pdf/2506.22069"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The research concerns pose estimation for rolling shutter cameras, without any reference to the processing or engineering of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22073",
      "abstract": "Considering linear-quadratic discrete-time games with unknown input/output/state (i/o/s) dynamics and state, we provide necessary and sufficient conditions for the existence and uniqueness of feedback Nash equilibria (FNE) in the finite-horizon game, based entirely on offline input/output data. We prove that the finite-horizon unknown-dynamics game and its corresponding known-dynamics game have the same FNEs, and provide detailed relationships between their respective FNE matrices. To simplify the computation of FNEs, we provide an invertibility condition and a corresponding algorithm that computes one FNE by solving a finite number of linear equation systems using offline data. For the infinite-horizon unknown-dynamics game, limited offline data restricts players to computing optimal strategies only over a finite horizon. We prove that the finite-horizon strategy ``watching $T$ steps into the future and moving one step now,'' which is commonly used in classical optimal control, exhibits convergence in both the FNE matrices and the total costs in the infinite-horizon unknown-dynamics game, and further provide an analysis of the convergence rate of the total cost. The corresponding algorithm for the infinite-horizon game is proposed and its efficacy is demonstrated through a non-scalar numerical example.",
      "authors": [
        "Shengyuan Huang",
        "Xiaoguang Yang",
        "Zhigang Cao and Wenjun Mei"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T10:01:22+00:00",
          "link": "https://arxiv.org/abs/2506.22073v1",
          "size": "187kb",
          "version": "v1"
        }
      ],
      "title": "Linear-Quadratic Discrete-Time Dynamic Games with Unknown Dynamics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22073",
        "HTML": "https://arxiv.org/html/2506.22073v1",
        "PDF": "https://arxiv.org/pdf/2506.22073"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This study addresses game theory for systems with unknown dynamics, emphasizing feedback Nash equilibria based on offline data. It does not relate to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22075",
      "abstract": "Reasoning is a hallmark of human intelligence, enabling adaptive decision-making in complex and unfamiliar scenarios. In contrast, machine intelligence remains bound to training data, lacking the ability to dynamically refine solutions at inference time. While some recent advances have explored reasoning in machines, these efforts are largely limited to verbal domains such as mathematical problem-solving, where explicit rules govern step-by-step reasoning. Other critical real-world tasks - including visual perception, spatial reasoning, and radiological diagnosis - require non-verbal reasoning, which remains an open challenge. Here we present a novel learning paradigm that enables machine reasoning in vision by allowing performance improvement with increasing thinking time (inference-time compute), even under conditions where labelled data is very limited. Inspired by dual-process theories of human cognition in psychology, our approach integrates a fast-thinking System I module for familiar tasks, with a slow-thinking System II module that iteratively refines solutions using self-play reinforcement learning. This paradigm mimics human reasoning by proposing, competing over, and refining solutions in data-scarce scenarios. We demonstrate superior performance through extended thinking time, compared not only to large-scale supervised learning but also foundation models and even human experts, in real-world vision tasks. These tasks include computer-vision benchmarks and cancer localisation on medical images across five organs, showcasing transformative potential for non-verbal machine reasoning.",
      "authors": [
        "Shaheer U. Saeed",
        "Yipei Wang",
        "Veeru Kasivisvanathan",
        "Brian R. Davidson",
        "Matthew J. Clarkson",
        "Yipeng Hu",
        "Daniel C. Alexander"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T10:03:05+00:00",
          "link": "https://arxiv.org/abs/2506.22075v1",
          "size": "1331kb",
          "version": "v1"
        }
      ],
      "title": "Reasoning in machine vision: learning to think fast and slow",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22075",
        "PDF": "https://arxiv.org/pdf/2506.22075"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper introduces a novel learning paradigm for machine reasoning in vision, particularly non-verbal reasoning, and does not involve LLM training data processes or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22078",
      "abstract": "Many remote Heart Rate (HR) measurement methods focus on estimating remote photoplethysmography (rPPG) signals from video clips lasting around 10 seconds but often overlook the need for HR estimation from ultra-short video clips. In this paper, we aim to accurately measure HR from ultra-short 2-second video clips by specifically addressing two key challenges. First, to overcome the limited number of heartbeat cycles in ultra-short video clips, we propose an effective periodicity-guided rPPG estimation method that enforces consistent periodicity between rPPG signals estimated from ultra-short clips and their much longer ground truth signals. Next, to mitigate estimation inaccuracies due to spectral leakage, we propose including a generator to reconstruct longer rPPG signals from ultra-short ones while preserving their periodic consistency to enable more accurate HR measurement. Extensive experiments on four rPPG estimation benchmark datasets demonstrate that our proposed method not only accurately measures HR from ultra-short video clips but also outperform previous rPPG estimation techniques to achieve state-of-the-art performance.",
      "authors": [
        "Pei-Kai Huanga",
        "Ya-Ting Chan",
        "Kuan-Wen Chen",
        "Yen-Chun Chou",
        "Shih-Yu Yang",
        "and Chiou-Ting Hsu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T10:05:00+00:00",
          "link": "https://arxiv.org/abs/2506.22078v1",
          "size": "1318kb",
          "version": "v1"
        }
      ],
      "title": "Towards Accurate Heart Rate Measurement from Ultra-Short Video Clips via Periodicity-Guided rPPG Estimation and Signal Reconstruction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22078",
        "HTML": "https://arxiv.org/html/2506.22078v1",
        "PDF": "https://arxiv.org/pdf/2506.22078"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This research primarily deals with heart rate measurement from video clips via rPPG signal estimation and does not discuss any aspect of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22084",
      "abstract": "We establish connections between the Transformer architecture, originally introduced for natural language processing, and Graph Neural Networks (GNNs) for representation learning on graphs. We show how Transformers can be viewed as message passing GNNs operating on fully connected graphs of tokens, where the self-attention mechanism capture the relative importance of all tokens w.r.t. each-other, and positional encodings provide hints about sequential ordering or structure. Thus, Transformers are expressive set processing networks that learn relationships among input elements without being constrained by apriori graphs. Despite this mathematical connection to GNNs, Transformers are implemented via dense matrix operations that are significantly more efficient on modern hardware than sparse message passing. This leads to the perspective that Transformers are GNNs currently winning the hardware lottery.",
      "authors": [
        "Chaitanya K. Joshi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T10:15:33+00:00",
          "link": "https://arxiv.org/abs/2506.22084v1",
          "size": "315kb",
          "version": "v1"
        }
      ],
      "title": "Transformers are Graph Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22084",
        "HTML": "https://arxiv.org/html/2506.22084v1",
        "PDF": "https://arxiv.org/pdf/2506.22084"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on the connection between Transformers and Graph Neural Networks, discussing representation learning and computational efficiencies but does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22087",
      "abstract": "Zero-order optimization techniques are becoming increasingly popular in robotics due to their ability to handle non-differentiable functions and escape local minima. These advantages make them particularly useful for trajectory optimization and policy optimization. In this work, we propose a mathematical tutorial on random search. It offers a simple and unifying perspective for understanding a wide range of algorithms commonly used in robotics. Leveraging this viewpoint, we classify many trajectory optimization methods under a common framework and derive novel competitive RL algorithms.",
      "authors": [
        "Armand Jordana",
        "Jianghan Zhang",
        "Joseph Amigo and Ludovic Righetti"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T10:19:33+00:00",
          "link": "https://arxiv.org/abs/2506.22087v1",
          "size": "965kb",
          "version": "v1"
        }
      ],
      "title": "An Introduction to Zero-Order Optimization Techniques for Robotics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22087",
        "HTML": "https://arxiv.org/html/2506.22087v1",
        "PDF": "https://arxiv.org/pdf/2506.22087"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper is centered around zero-order optimization techniques for robotics, primarily in the context of trajectory and policy optimization, without mentioning LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22089",
      "abstract": "We consider the problem of a game theorist analyzing a game that uses cryptographic protocols. Ideally, a theorist abstracts protocols as ideal, implementation-independent primitives, letting conclusions in the \"ideal world\" carry over to the \"real world.\" This is crucial, since the game theorist cannot--and should not be expected to--handle full cryptographic complexity. In today's landscape, the rise of distributed ledgers makes a shared language between cryptography and game theory increasingly necessary.\n  The security of cryptographic protocols hinges on two types of assumptions: state-of-the-world (e.g., \"factoring is hard\") and behavioral (e.g., \"honest majority\"). We observe that for protocols relying on behavioral assumptions (e.g., ledgers), our goal is unattainable in full generality. For state-of-the-world assumptions, we show that standard solution concepts, e.g., ($\\epsilon$-)Nash equilibria, are not robust to transfer from the ideal to the real world.\n  We propose a new solution concept: the pseudo-Nash equilibrium. Informally, a profile $s=(s_1,\\dots,s_n)$ is a pseudo-Nash equilibrium if, for any player $i$ and deviation $s'_i$ with higher expected utility, $i$'s utility from $s_i$ is (computationally) indistinguishable from that of $s'_i$. Pseudo-Nash is simpler and more accessible to game theorists than prior notions addressing the mismatch between (asymptotic) cryptography and game theory. We prove that Nash equilibria in games with ideal, unbreakable cryptography correspond to pseudo-Nash equilibria when ideal cryptography is instantiated with real protocols (under state-of-the-world assumptions). Our translation is conceptually simpler and more general: it avoids tuning or restricting utility functions in the ideal game to fit quirks of cryptographic implementations. Thus, pseudo-Nash lets us study game-theoretic and cryptographic aspects separately and seamlessly.",
      "authors": [
        "Alexandros Psomas",
        "Athina Terzoglou",
        "Yu Wei",
        "Vassilis Zikas"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T10:21:28+00:00",
          "link": "https://arxiv.org/abs/2506.22089v1",
          "size": "48kb",
          "version": "v1"
        }
      ],
      "title": "Pseudo-Equilibria, or: How to Stop Worrying About Crypto and Just Analyze the Game",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22089",
        "HTML": "https://arxiv.org/html/2506.22089v1",
        "PDF": "https://arxiv.org/pdf/2506.22089"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper discusses game theory and cryptographic protocols with a focus on pseudo-Nash equilibria, without any connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22094",
      "abstract": "This letter analyzes the effects of power amplifiers (PAs) on the downlink of cell-free massive MIMO systems. We model signal transmission incorporating nonlinear PA distortion and derive a unified spectral efficiency (SE) expression applicable to arbitrary precoding schemes. To combat PA-induced performance degradation, a joint optimization approach for user association and max-min power control is proposed. Furthermore, a low-complexity alternative is developed to approximate the joint optimization with reduced computational overhead. Simulations validate the analysis and demonstrate significant performance gains of the proposed approaches over conventional techniques.",
      "authors": [
        "Wei Jiang and Hans D. Schotten"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T10:25:26+00:00",
          "link": "https://arxiv.org/abs/2506.22094v1",
          "size": "1173kb",
          "version": "v1"
        }
      ],
      "title": "Nonlinear Power Amplifier-Resilient Cell-Free Massive MIMO: A Joint Optimization Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22094",
        "HTML": "https://arxiv.org/html/2506.22094v1",
        "PDF": "https://arxiv.org/pdf/2506.22094"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The study investigates power amplifier effects on massive MIMO systems, centered around signal transmission and spectral efficiency, unrelated to LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22095",
      "abstract": "Learning-based methods for routing have gained significant attention in recent years, both in single-objective and multi-objective contexts. However, the multigraph setting, where multiple paths with distinct attributes can exist between destinations, has largely been overlooked, despite its high practical relevancy. In this paper, we introduce two neural approaches to address multi-objective routing on multigraphs. Our first approach works directly on the multigraph, by autoregressively selecting edges until a tour is completed. On the other hand, our second model first prunes the multigraph into a simple graph and then builds routes. We validate both models experimentally and find that they demonstrate strong performance across a variety of problems, including the Traveling Salesman Problem (TSP) and Capacitated Vehicle Routing Problem (CVRP).",
      "authors": [
        "Filip Rydin",
        "Attila Lischka",
        "Jiaming Wu",
        "Morteza Haghir Chehreghani",
        "Bal\\'azs Kulcs\\'ar"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T10:25:58+00:00",
          "link": "https://arxiv.org/abs/2506.22095v1",
          "size": "63kb",
          "version": "v1"
        }
      ],
      "title": "Learning to Solve Multi-Objective Routing Problems on Multigraphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22095",
        "HTML": "https://arxiv.org/html/2506.22095v1",
        "PDF": "https://arxiv.org/pdf/2506.22095"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper introduces neural-based approaches to solve routing problems on multigraphs, focusing on optimization techniques for routing, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22096",
      "abstract": "Detecting heavy metal pollution in soils and seaports is vital for regional environmental monitoring. The Pollution Load Index (PLI), an international standard, is commonly used to assess heavy metal containment. However, the conventional PLI assessment involves laborious procedures and data analysis of sediment samples. To address this challenge, we propose a deep-learning-based model that simplifies the heavy metal assessment process. Our model tackles the issue of data scarcity in the water-sediment domain, which is traditionally plagued by challenges in data collection and varying standards across nations. By leveraging transfer learning, we develop an accurate quantitative assessment method for predicting PLI. Our approach allows the transfer of learned features across domains with different sets of features. We evaluate our model using data from six major ports in New South Wales, Australia: Port Yamba, Port Newcastle, Port Jackson, Port Botany, Port Kembla, and Port Eden. The results demonstrate significantly lower Mean Absolute Error (MAE) and Mean Absolute Percentage Error (MAPE) of approximately 0.5 and 0.03, respectively, compared to other models. Our model performance is up to 2 orders of magnitude than other baseline models. Our proposed model offers an innovative, accessible, and cost-effective approach to predicting water quality, benefiting marine life conservation, aquaculture, and industrial pollution monitoring.",
      "authors": [
        "Tin Lai",
        "Farnaz Farid",
        "Yueyang Kuan",
        "Xintian Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T10:26:42+00:00",
          "link": "https://arxiv.org/abs/2506.22096v1",
          "size": "225kb",
          "version": "v1"
        }
      ],
      "title": "Transfer Learning for Assessing Heavy Metal Pollution in Seaports Sediments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22096",
        "HTML": "https://arxiv.org/html/2506.22096v1",
        "PDF": "https://arxiv.org/pdf/2506.22096"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on using deep learning for environmental pollution assessment through transfer learning, specifically in the domain of water-sediment analysis. It is not related to the processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22098",
      "abstract": "Language is a fundamental aspect of human societies, continuously evolving in response to various stimuli, including societal changes and intercultural interactions. Technological advancements have profoundly transformed communication, with social media emerging as a pivotal force that merges entertainment-driven content with complex social dynamics. As these platforms reshape public discourse, analyzing the linguistic features of user-generated content is essential to understanding their broader societal impact. In this paper, we examine the linguistic complexity of content produced by influential users on Twitter across three globally significant and contested topics: COVID-19, COP26, and the Russia-Ukraine war. By combining multiple measures of textual complexity, we assess how language use varies along four key dimensions: account type, political leaning, content reliability, and sentiment. Our analysis reveals significant differences across all four axes, including variations in language complexity between individuals and organizations, between profiles with sided versus moderate political views, and between those associated with higher versus lower reliability scores. Additionally, profiles producing more negative and offensive content tend to use more complex language, with users sharing similar political stances and reliability levels converging toward a common jargon. Our findings offer new insights into the sociolinguistic dynamics of digital platforms and contribute to a deeper understanding of how language reflects ideological and social structures in online spaces.",
      "authors": [
        "Eleonora Amadori",
        "Daniele Cirulli",
        "Edoardo Di Martino",
        "Jacopo Nudo",
        "Maria Sahakyan",
        "Emanuele Sangiorgio",
        "Arnaldo Santoro",
        "Simon Zollo",
        "Alessandro Galeazzi",
        "Niccol\\`o Di Marco"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Computers and Society (cs.CY)",
        "Physics and Society (physics.soc-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T10:27:54+00:00",
          "link": "https://arxiv.org/abs/2506.22098v1",
          "size": "4057kb",
          "version": "v1"
        }
      ],
      "title": "Involvement drives complexity of language in online debates",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22098",
        "HTML": "https://arxiv.org/html/2506.22098v1",
        "PDF": "https://arxiv.org/pdf/2506.22098"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper analyzes language complexity in online debates on social media, assessing text complexity across various dimensions. It does not address LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22099",
      "abstract": "The realistic reconstruction of street scenes is critical for developing real-world simulators in autonomous driving. Most existing methods rely on object pose annotations, using these poses to reconstruct dynamic objects and move them during the rendering process. This dependence on high-precision object annotations limits large-scale and extensive scene reconstruction. To address this challenge, we propose B\\'ezier curve Gaussian splatting (B\\'ezierGS), which represents the motion trajectories of dynamic objects using learnable B\\'ezier curves. This approach fully leverages the temporal information of dynamic objects and, through learnable curve modeling, automatically corrects pose errors. By introducing additional supervision on dynamic object rendering and inter-curve consistency constraints, we achieve reasonable and accurate separation and reconstruction of scene elements. Extensive experiments on the Waymo Open Dataset and the nuPlan benchmark demonstrate that B\\'ezierGS outperforms state-of-the-art alternatives in both dynamic and static scene components reconstruction and novel view synthesis.",
      "authors": [
        "Zipei Ma and Junzhe Jiang and Yurui Chen and Li Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T10:30:16+00:00",
          "link": "https://arxiv.org/abs/2506.22099v1",
          "size": "13807kb",
          "version": "v1"
        }
      ],
      "title": "B\\'ezierGS: Dynamic Urban Scene Reconstruction with B\\'ezier Curve Gaussian Splatting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22099",
        "HTML": "https://arxiv.org/html/2506.22099v1",
        "PDF": "https://arxiv.org/pdf/2506.22099"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper focuses on urban scene reconstruction using B\\'ezier curves, primarily for autonomous driving applications, with no relevance to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22101",
      "abstract": "Common prototype-based medical image few-shot segmentation (FSS) methods model foreground and background classes using class-specific prototypes. However, given the high variability of the background, a more promising direction is to focus solely on foreground modeling, treating the background as an anomaly -- an approach introduced by ADNet. Yet, ADNet faces three key limitations: dependence on a single prototype per class, a focus on binary classification, and fixed thresholds that fail to adapt to patient and organ variability. To address these shortcomings, we propose the Tied Prototype Model (TPM), a principled reformulation of ADNet with tied prototype locations for foreground and background distributions. Building on its probabilistic foundation, TPM naturally extends to multiple prototypes and multi-class segmentation while effectively separating non-typical background features. Notably, both extensions lead to improved segmentation accuracy. Finally, we leverage naturally occurring class priors to define an ideal target for adaptive thresholds, boosting segmentation performance. Taken together, TPM provides a fresh perspective on prototype-based FSS for medical image segmentation. The code can be found at https://github.com/hjk92g/TPM-FSS.",
      "authors": [
        "Hyeongji Kim",
        "Stine Hansen",
        "Michael Kampffmeyer"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T10:33:55+00:00",
          "link": "https://arxiv.org/abs/2506.22101v1",
          "size": "396kb",
          "version": "v1"
        }
      ],
      "title": "Tied Prototype Model for Few-Shot Medical Image Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22101",
        "HTML": "https://arxiv.org/html/2506.22101v1",
        "PDF": "https://arxiv.org/pdf/2506.22101"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The research addresses few-shot medical image segmentation with a novel prototype model. It is unrelated to training data processing or engineering for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22103",
      "abstract": "From disparities in the number of exhibiting artists to auction opportunities, there is evidence of women's under-representation in visual art. Here we explore the exhibition history and auction sales of 65,768 contemporary artists in 20,389 institutions, revealing gender differences in the artist population, exhibitions and auctions. We distinguish between two criteria for gender equity: gender-neutrality, when artists have gender-independent access to exhibition opportunities, and gender-balanced, that strives for gender parity in representation, finding that 58\\% of institutions are gender-neutral but only 24\\% are gender-balanced, and that the fraction of man-overrepresented institutions increases with institutional prestige. We define artist's co-exhibition gender to capture the gender inequality of the institutions that an artist exhibits. Finally, we use logistic regression to predict an artist's access to the auction market, finding that co-exhibition gender has a stronger correlation with success than the artist's gender. These results help unveil and quantify the institutional forces that relate to the persistent gender imbalance in the art world.",
      "authors": [
        "Xindi Wang and Alexander J. Gates and Magnus Resch and Albert-Laszlo Barabasi"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T10:35:31+00:00",
          "link": "https://arxiv.org/abs/2506.22103v1",
          "size": "8890kb",
          "version": "v1"
        }
      ],
      "title": "Quantifying Institutional Gender Inequality in Contemporary Visual Art",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22103",
        "HTML": "https://arxiv.org/html/2506.22103v1",
        "PDF": "https://arxiv.org/pdf/2506.22103"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper explores gender inequality in contemporary visual art institutions, focusing on artist representation and auction opportunities. It does not discuss LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22105",
      "abstract": "I implement a procedure to isolate and interpret the sub-network (or \"circuit\") responsible for subject-verb agreement in GPT-2 Small. In this study, the model is given prompts where the subject is either singular (e.g. \"Alice\") or plural (e.g. \"Alice and Bob\"), and the task is to correctly predict the appropriate verb form (\"walks\" for singular subjects, \"walk\" for plural subjects). Using a series of techniques-including performance verification automatic circuit discovery via direct path patching, and direct logit attribution- I isolate a candidate circuit that contributes significantly to the model's correct verb conjugation. The results suggest that only a small fraction of the network's component-token pairs is needed to achieve near-model performance on the base task but substantially more for more complex settings.",
      "authors": [
        "David Demitri Africa"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T10:35:41+00:00",
          "link": "https://arxiv.org/abs/2506.22105v1",
          "size": "232kb",
          "version": "v1"
        }
      ],
      "title": "Identifying a Circuit for Verb Conjugation in GPT-2",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22105",
        "HTML": "https://arxiv.org/html/2506.22105v1",
        "PDF": "https://arxiv.org/pdf/2506.22105"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on isolating and interpreting a network circuit for verb conjugation in GPT-2, which is related to model architecture analysis, not training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22107",
      "abstract": "Sorting is a fundamental operation in computer systems and is widely used in applications such as databases, data analytics, and hardware accelerators. Unary computing has recently emerged as a low-cost and power-efficient paradigm for implementing hardware sorters by eliminating the need for complex arithmetic operations. However, existing comparison-free unary computing-based designs suffer from significant area and power overhead due to costly unary number generators.\n  In this paper, we present a novel ascending-order unary sorting module featuring a finite-state-machine-based unary number generator that significantly reduces implementation costs. By generating right-aligned unary streams using a two-state finite-state machine, our architecture iteratively identifies the minimum input value in each cycle without conventional comparators. Synthesis results in a 45nm technology node demonstrate up to 82% reduction in area and 70% reduction in power consumption compared to state-of-the-art unary designs. The proposed sorter offers a promising solution for energy-constrained and resource-limited hardware systems.",
      "authors": [
        "Amir Hossein Jalilvand and M. Hassan Najafi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T10:35:59+00:00",
          "link": "https://arxiv.org/abs/2506.22107v1",
          "size": "781kb",
          "version": "v1"
        }
      ],
      "title": "Power- and Area-Efficient Unary Sorting Architecture Using FSM-Based Unary Number Generator",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22107",
        "HTML": "https://arxiv.org/html/2506.22107v1",
        "PDF": "https://arxiv.org/pdf/2506.22107"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper presents a unary sorting architecture for hardware implementations, unrelated to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22111",
      "abstract": "With the rapid advancements in autonomous driving, accurately predicting pedestrian behavior has become essential for ensuring safety in complex and unpredictable traffic conditions. The growing interest in this challenge highlights the need for comprehensive datasets that capture unstructured environments, enabling the development of more robust prediction models to enhance pedestrian safety and vehicle navigation. In this paper, we introduce an Indian driving pedestrian dataset designed to address the complexities of modeling pedestrian behavior in unstructured environments, such as illumination changes, occlusion of pedestrians, unsignalized scene types and vehicle-pedestrian interactions. The dataset provides high-level and detailed low-level comprehensive annotations focused on pedestrians requiring the ego-vehicle's attention. Evaluation of the state-of-the-art intention prediction methods on our dataset shows a significant performance drop of up to $\\mathbf{15\\%}$, while trajectory prediction methods underperform with an increase of up to $\\mathbf{1208}$ MSE, defeating standard pedestrian datasets. Additionally, we present exhaustive quantitative and qualitative analysis of intention and trajectory baselines. We believe that our dataset will open new challenges for the pedestrian behavior research community to build robust models. Project Page: https://cvit.iiit.ac.in/research/projects/cvit-projects/iddped",
      "authors": [
        "Ruthvik Bokkasam",
        "Shankar Gangisetty",
        "A. H. Abdul Hafez",
        "C. V. Jawahar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T10:41:18+00:00",
          "link": "https://arxiv.org/abs/2506.22111v1",
          "size": "1015kb",
          "version": "v1"
        }
      ],
      "title": "Pedestrian Intention and Trajectory Prediction in Unstructured Traffic Using IDD-PeD",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22111",
        "HTML": "https://arxiv.org/html/2506.22111v1",
        "PDF": "https://arxiv.org/pdf/2506.22111"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces the 'Indian driving pedestrian dataset' specifically designed to address complex modeling needs, directly contributing to the field of LLM training data by creating a new dataset for pedestrian trajectory prediction."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22112",
      "abstract": "Offline reinforcement learning (RL) has emerged as a prevalent and effective methodology for real-world recommender systems, enabling learning policies from historical data and capturing user preferences. In offline RL, reward shaping encounters significant challenges, with past efforts to incorporate prior strategies for uncertainty to improve world models or penalize underexplored state-action pairs. Despite these efforts, a critical gap remains: the simultaneous balancing of intrinsic biases in world models and the diversity of policy recommendations. To address this limitation, we present an innovative offline RL framework termed Reallocated Reward for Recommender Systems (R3S). By integrating inherent model uncertainty to tackle the intrinsic fluctuations in reward predictions, we boost diversity for decision-making to align with a more interactive paradigm, incorporating extra penalizers with decay that deter actions leading to diminished state variety at both local and global scales. The experimental results demonstrate that R3S improves the accuracy of world models and efficiently harmonizes the heterogeneous preferences of the users.",
      "authors": [
        "Wenzheng Shu",
        "Yanxiang Zeng",
        "Yongxiang Tang",
        "Teng Sha",
        "Ning Luo",
        "Yanhua Cheng",
        "Xialong Liu",
        "Fan Zhou",
        "Peng Jiang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T10:46:41+00:00",
          "link": "https://arxiv.org/abs/2506.22112v1",
          "size": "203kb",
          "version": "v1"
        }
      ],
      "title": "Reward Balancing Revisited: Enhancing Offline Reinforcement Learning for Recommender Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22112",
        "HTML": "https://arxiv.org/html/2506.22112v1",
        "PDF": "https://arxiv.org/pdf/2506.22112"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on offline reinforcement learning for recommender systems. It does not address LLM training data tasks such as data collection, processing, or enhancement."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22113",
      "abstract": "We explore new approaches for finding matrix multiplication algorithms in the commutative setting by adapting the flip graph technique: a method previously shown to be effective for discovering fast algorithms in the non-commutative case. While an earlier attempt to apply flip graphs to commutative algorithms saw limited success, we overcome both theoretical and practical obstacles using two strategies: one inspired by Marakov's algorithm to multiply 3x3 matrices, in which we construct a commutative tensor and approximate its rank using the standard flip graph; and a second that introduces a fully commutative variant of the flip graph defined via a quotient tensor space. We also present a hybrid method that combines the strengths of both. Across all matrix sizes up to 5x5, these methods recover the best known bounds on the number of multiplications and allow for a comparison of their efficiency and efficacy. Although no new improvements are found, our results demonstrate strong potential for these techniques at larger scales.",
      "authors": [
        "Isaac Wood"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Symbolic Computation (cs.SC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T10:47:04+00:00",
          "link": "https://arxiv.org/abs/2506.22113v1",
          "size": "12kb",
          "version": "v1"
        }
      ],
      "title": "Exploring Commutative Matrix Multiplication Schemes via Flip Graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22113",
        "HTML": "https://arxiv.org/html/2506.22113v1",
        "PDF": "https://arxiv.org/pdf/2506.22113"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper explores matrix multiplication schemes and techniques for optimizing algorithms. It does not relate to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22116",
      "abstract": "Pointing gestures are a common interaction method used in Human-Robot Collaboration for various tasks, ranging from selecting targets to guiding industrial processes. This study introduces a method for localizing pointed targets within a planar workspace. The approach employs pose estimation, and a simple geometric model based on shoulder-wrist extension to extract gesturing data from an RGB-D stream. The study proposes a rigorous methodology and comprehensive analysis for evaluating pointing gestures and target selection in typical robotic tasks. In addition to evaluating tool accuracy, the tool is integrated into a proof-of-concept robotic system, which includes object detection, speech transcription, and speech synthesis to demonstrate the integration of multiple modalities in a collaborative application. Finally, a discussion over tool limitations and performance is provided to understand its role in multimodal robotic systems. All developments are available at: https://github.com/NMKsas/gesture_pointer.git.",
      "authors": [
        "Noora Sassali",
        "Roel Pieters"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T10:51:31+00:00",
          "link": "https://arxiv.org/abs/2506.22116v1",
          "size": "4095kb",
          "version": "v1"
        }
      ],
      "title": "Evaluating Pointing Gestures for Target Selection in Human-Robot Collaboration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22116",
        "HTML": "https://arxiv.org/html/2506.22116v1",
        "PDF": "https://arxiv.org/pdf/2506.22116"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The study investigates pointing gestures in human-robot collaboration without addressing any elements of LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22117",
      "abstract": "Distributed multi-agent navigation faces inherent challenges due to the competing requirements of maintaining safety and achieving goal-directed behavior, particularly for agents with limited sensing range operating in unknown environments with dense obstacles. Existing approaches typically project predefined goal-reaching controllers onto control barrier function (CBF) constraints, often resulting in conservative and suboptimal trade-offs between safety and goal-reaching performance. We propose an infinite-horizon CBF-constrained optimal graph control formulation for distributed safe multi-agent navigation. By deriving the analytical solution structure, we develop a novel Hamilton-Jacobi-Bellman (HJB)-based learning framework to approximate the solution. In particular, our algorithm jointly learns a CBF and a distributed control policy, both parameterized by graph neural networks (GNNs), along with a value function that robustly guides agents toward their goals. Moreover, we introduce a state-dependent parameterization of Lagrange multipliers, enabling dynamic trade-offs between safety and performance. Unlike traditional short-horizon, quadratic programming-based CBF methods, our approach leverages long-horizon optimization to proactively avoid deadlocks and navigate complex environments more effectively. Extensive simulation results demonstrate substantial improvements in safety and task success rates across various agent dynamics, with strong scalability and generalization to large-scale teams in previously unseen environments. Real-world experiments using Crazyflie drone swarms on challenging antipodal position-swapping tasks further validate the practicality, generalizability, and robustness of the proposed HJB-GNN learning framework.",
      "authors": [
        "Fenglan Wang",
        "Xinguo Shu",
        "Lei He",
        "Lin Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T10:53:33+00:00",
          "link": "https://arxiv.org/abs/2506.22117v1",
          "size": "2504kb",
          "version": "v1"
        }
      ],
      "title": "Learning Distributed Safe Multi-Agent Navigation via Infinite-Horizon Optimal Graph Control",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22117",
        "HTML": "https://arxiv.org/html/2506.22117v1",
        "PDF": "https://arxiv.org/pdf/2506.22117"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The focus of the paper is on safe multi-agent navigation systems and control strategies. It does not cover any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22118",
      "abstract": "Accurate digital twins of industrial assets, such as ships and offshore platforms, rely on the precise reconstruction of complex pipe networks. However, manual modelling of pipes from laser scan data is a time-consuming and labor-intensive process. This paper presents a pipeline for automated pipe reconstruction from incomplete laser scan data. The approach estimates a skeleton curve using Laplacian-based contraction, followed by curve elongation. The skeleton axis is then recentred using a rolling sphere technique combined with 2D circle fitting, and refined with a 3D smoothing step. This enables the determination of pipe properties, including radius, length and orientation, and facilitates the creation of detailed 3D models of complex pipe networks. By automating pipe reconstruction, this approach supports the development of digital twins, allowing for rapid and accurate modeling while reducing costs.",
      "authors": [
        "Antje Alex and Jannis Stoppe"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T10:54:51+00:00",
          "link": "https://arxiv.org/abs/2506.22118v1",
          "size": "18738kb",
          "version": "v1"
        }
      ],
      "title": "Pipe Reconstruction from Point Cloud Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22118",
        "HTML": "https://arxiv.org/html/2506.22118v1",
        "PDF": "https://arxiv.org/pdf/2506.22118"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper presents methods for automated pipe reconstruction from point cloud data, which does not involve LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22122",
      "abstract": "Optical Neural Networks (ONNs) promise significant advantages over traditional electronic neural networks, including ultrafast computation, high bandwidth, and low energy consumption, by leveraging the intrinsic capabilities of photonics. However, training ONNs poses unique challenges, notably the reliance on simplified in silico models whose trained parameters must subsequently be mapped to physical hardware. This process often introduces inaccuracies due to discrepancies between the idealized digital model and the physical ONN implementation, particularly stemming from noise and fabrication imperfections.\n  In this paper, we analyze how noise misspecification during in silico training impacts ONN performance and we introduce Gradient-Informed Fine-Tuning (GIFT), a lightweight algorithm designed to mitigate this performance degradation. GIFT uses gradient information derived from the noise structure of the ONN to adapt pretrained parameters directly in situ, without requiring expensive retraining or complex experimental setups. GIFT comes with formal conditions under which it improves ONN performance.\n  We also demonstrate the effectiveness of GIFT via simulation on a five-layer feed forward ONN trained on the MNIST digit classification task. GIFT achieves up to $28\\%$ relative accuracy improvement compared to the baseline performance under noise misspecification, without resorting to costly retraining. Overall, GIFT provides a practical solution for bridging the gap between simplified digital models and real-world ONN implementations.",
      "authors": [
        "Gianluca Kosmella and Ripalta Stabile and Jaron Sanders"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)",
        "Emerging Technologies (cs.ET)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T11:00:36+00:00",
          "link": "https://arxiv.org/abs/2506.22122v1",
          "size": "3670kb",
          "version": "v1"
        }
      ],
      "title": "In situ fine-tuning of in silico trained Optical Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22122",
        "HTML": "https://arxiv.org/html/2506.22122v1",
        "PDF": "https://arxiv.org/pdf/2506.22122"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on improving Optical Neural Networks through in silico training and fine-tuning techniques, which are unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22125",
      "abstract": "Hybrid collaboration has become a fixture in modern workplaces, yet it introduces persistent socio-technical asymmetries-especially disadvantaging remote participants, who struggle with presence disparity, reduced visibility, and limited non-verbal communication. Traditional solutions often seek to erase these asymmetries, but recent research suggests embracing them as productive design constraints. In this context, we introduce NoticeLight: a tangible, peripheral robotic embodiment designed to augment hybrid meetings. NoticeLight transforms remote participants' digital presence into ambient, physical signals -- such as mood dynamics, verbal contribution mosaics, and attention cues -- within the co-located space. By abstracting group states into subtle light patterns, NoticeLight fosters peripheral awareness and balanced participation without disrupting meeting flow or demanding cognitive overload. This approach aligns with emerging perspectives in human-robot synergy, positioning robots as mediators that reshape, rather than replicate, human presence. Our work thereby advances the discourse on how robotic embodiments can empower equitable, dynamic collaboration in the workplace.",
      "authors": [
        "Marie Altmann and Kimberly Hegemann and Ali Askari and Vineetha Rallabandi and Max Pascher and Jens Gerken"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T11:02:34+00:00",
          "link": "https://arxiv.org/abs/2506.22125v1",
          "size": "935kb",
          "version": "v1"
        }
      ],
      "title": "NoticeLight: Embracing Socio-Technical Asymmetry through Tangible Peripheral Robotic Embodiment in Hybrid Collaboration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22125",
        "HTML": "https://arxiv.org/html/2506.22125v1",
        "PDF": "https://arxiv.org/pdf/2506.22125"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper introduces a robotic embodiment for hybrid collaboration and does not address the collection, construction, or processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22127",
      "abstract": "The Directed Traveling Salesman Problem (DTSP) is a variant of the classical Traveling Salesman Problem in which the edges in the graph are directed and a vertex and edge can be visited multiple times. The goal is to find a directed closed walk of minimum length (or total weight) that visits every vertex of the given graph at least once. In a yet more general version, Directed Waypoint Routing Problem (DWRP), some vertices are marked as terminals and we are only required to visit all terminals. Furthermore, each edge has its capacity bounding the number of times this edge can be used by a solution.\n  While both problems (and many other variants of TSP) were extensively investigated, mostly from the approximation point of view, there are surprisingly few results concerning the parameterized complexity. Our starting point is the result of Marx et al. [APPROX/RANDOM 2016] who proved that DTSP is W[1]-hard parameterized by distance to pathwidth 3. In this paper we aim to initiate the systematic complexity study of variants of DTSP with respect to various, mostly structural, parameters.\n  We show that DWRP is FPT parameterized by the solution size, the feedback edge number, and the vertex integrity of the underlying undirected graph. Furthermore, the problem is XP parameterized by treewidth. On the complexity side, we show that the problem is W[1]-hard parameterized by the distance to constant treedepth.",
      "authors": [
        "V\\'aclav Bla\\v{z}ej",
        "Andreas Emil Feldmann",
        "Foivos Fioravantes",
        "Pawe{\\l} Rz\\k{a}\\.zewski",
        "Ond\\v{r}ej Such\\'y"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T11:09:33+00:00",
          "link": "https://arxiv.org/abs/2506.22127v1",
          "size": "265kb",
          "version": "v1"
        }
      ],
      "title": "Parameterized Complexity of Directed Traveling Salesman Problem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22127",
        "PDF": "https://arxiv.org/pdf/2506.22127"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper deals with the parameterized complexity of the Directed Traveling Salesman Problem, without any mention of LLM training data-related methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22129",
      "abstract": "In the aftermath of major earthquakes, evaluating structural and infrastructural damage is vital for coordinating post-disaster response efforts. This includes assessing damage's extent and spatial distribution to prioritize rescue operations and resource allocation. Accurately estimating damage grades to buildings post-earthquake is paramount for effective response and recovery, given the significant impact on lives and properties, underscoring the urgency of streamlining relief fund allocation processes. Previous studies have shown the effectiveness of multi-class classification, especially XGBoost, along with other machine learning models and ensembling methods, incorporating regularization to address class imbalance. One consequence of class imbalance is that it may give rise to skewed models that undervalue minority classes and give preference to the majority class. This research deals with the problem of class imbalance with the help of the synthetic minority oversampling technique (SMOTE). We delve into multiple multi-class classification machine learning, deep learning models, and ensembling methods to forecast structural damage grades. The study elucidates performance determinants through comprehensive feature manipulation experiments and diverse training approaches. It identifies key factors contributing to seismic vulnerability while evaluating model performance using techniques like the confusion matrix further to enhance understanding of the effectiveness of earthquake damage prediction.",
      "authors": [
        "Anurag Panda",
        "Gaurav Kumar Yadav"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T11:12:37+00:00",
          "link": "https://arxiv.org/abs/2506.22129v1",
          "size": "444kb",
          "version": "v1"
        }
      ],
      "title": "Earthquake Damage Grades Prediction using An Ensemble Approach Integrating Advanced Machine and Deep Learning Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22129",
        "HTML": "https://arxiv.org/html/2506.22129v1",
        "PDF": "https://arxiv.org/pdf/2506.22129"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper focuses on earthquake damage prediction using machine and deep learning models, with no relation to LLM training data processing or preparation."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22133",
      "abstract": "A Condorcet winning set addresses the Condorcet paradox by selecting a few candidates--rather than a single winner--such that no unselected alternative is preferred to all of them by a majority of voters. This idea extends to $\\alpha$-undominated sets, which ensure the same property for any $\\alpha$-fraction of voters and are guaranteed to exist in constant size for any $\\alpha$. However, the requirement that an outsider be preferred to every member of the set can be overly restrictive and difficult to justify in many applications. Motivated by this, we introduce a more flexible notion: $(t, \\alpha)$-undominated sets. Here, each voter compares an outsider to their $t$-th most preferred member of the set, and the set is undominated if no outsider is preferred by more than an $\\alpha$-fraction of voters. This framework subsumes prior definitions, recovering Condorcet winning sets when $(t = 1, \\alpha = 1/2)$ and $\\alpha$-undominated sets when $t = 1$, and introduces a new, tunable notion of collective acceptability for $t > 1$. We establish three main results:\n  1. We prove that a $(t, \\alpha)$-undominated set of size $O(t/\\alpha)$ exists for all values of $t$ and $\\alpha$.\n  2. We show that as $t$ becomes large, the minimum size of such a set approaches $t/\\alpha$, which is asymptotically optimal.\n  3. In the special case $t = 1$, we improve the bound on the size of an $\\alpha$-undominated set given by Charikar, Lassota, Ramakrishnan, Vetta, and Wang (STOC 2025). As a consequence, we show that a Condorcet winning set of five candidates exists, improving their bound of six.",
      "authors": [
        "Thanh Nguyen",
        "Haoyu Song",
        "Young-San Lin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)",
        "Combinatorics (math.CO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T11:22:54+00:00",
          "link": "https://arxiv.org/abs/2506.22133v1",
          "size": "97kb",
          "version": "v1"
        }
      ],
      "title": "A few good choices",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22133",
        "PDF": "https://arxiv.org/pdf/2506.22133"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on voting theory and selection criteria for candidate sets rather than any aspect of LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22134",
      "abstract": "Higher-order tensors are well-suited for representing multi-dimensional data, such as color images and videos. Low-rank tensor representation has become essential in machine learning and computer vision, but existing methods like Tucker decomposition offer flexibility at the expense of interpretability. In contrast, while the CANDECOMP/PARAFAC (CP) decomposition provides a more natural and interpretable tensor structure, obtaining sparse solutions remains challenging. Leveraging the rich properties of CP decomposition, we propose a CP-based low-rank tensor function parameterized by neural networks for implicit neural representation (CP-INR). This approach enables continuous data representation beyond structured grids, fully exploiting the non-linearity of tensor data with theoretical guarantees on excess risk bounds. To achieve a sparse CP decomposition, we introduce a variational form of the Schatten-p quasi-norm and prove its relationship to multilinear rank minimization. For smoothness, we propose a regularization term based on the spectral norm of the Jacobian and Hutchinson's trace estimator. Our proposed smoothness regularization is SVD-free and avoids explicit chain rule derivations. It can serve as an alternative to Total Variation (TV) regularization in image denoising tasks and is naturally applicable to continuous data. Extensive experiments on multi-dimensional data recovery tasks, including image inpainting, denoising, and point cloud upsampling, demonstrate the superiority and versatility of our method compared to state-of-the-art approaches.",
      "authors": [
        "Zhengyun Cheng",
        "Changhao Wang",
        "Guanwen Zhang",
        "Yi Xu",
        "Wei Zhou",
        "and Xiangyang Ji"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T11:23:10+00:00",
          "link": "https://arxiv.org/abs/2506.22134v1",
          "size": "33531kb",
          "version": "v1"
        }
      ],
      "title": "Low-Rank Implicit Neural Representation via Schatten-p Quasi-Norm and Jacobian Regularization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22134",
        "HTML": "https://arxiv.org/html/2506.22134v1",
        "PDF": "https://arxiv.org/pdf/2506.22134"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper discusses low-rank tensor representations in the context of machine learning and computer vision applications such as image denoising, rather than addressing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22137",
      "abstract": "We investigate the application of semantic information theory to drug delivery systems (DDS) within the molecular communication (MC) framework. To operationalise this, we observe a DDS as a molecular concentration-based channel. Semantic information is defined as the amount of information required for a DDS to achieve its therapeutic goal in a dynamic environment. We derive it by introducing interventions, defined as modifications to DDS parameters, a viability function, and system-environment correlations quantified via the channel capacity. Here, the viability function represents DDS performance based on a drug dose-response relationship. Our model considers a system capable of inducing functional changes in a receiver cancer cell, where exceeding critical DDS parameter values can significantly reduce performance or cost-effectiveness. By analysing the MC-based DDS model through a semantic information perspective, we examine how correlations between the internalised particle concentration $(Y)$ and the particle concentration in the extracellular environment $(X)$ evolve under interventions. The final catalogue of results provides a quantitative basis for DDS design and optimisation, offering a method to determine optimal DDS parameter values under constraints such as chemical budget, desired effect and accuracy. Thus, the proposed framework can serve as a novel tool for guiding DDS design and optimisation.",
      "authors": [
        "Milica Leki\\'c",
        "Mohammad Zoofaghari",
        "Ilangko Balasingham",
        "Mladen Veleti\\'c"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Emerging Technologies (cs.ET)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T11:25:13+00:00",
          "link": "https://arxiv.org/abs/2506.22137v1",
          "size": "281kb",
          "version": "v1"
        }
      ],
      "title": "On Drug Delivery System Parameter Optimisation via Semantic Information Theory",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22137",
        "HTML": "https://arxiv.org/html/2506.22137v1",
        "PDF": "https://arxiv.org/pdf/2506.22137"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This study is related to drug delivery system parameter optimization through semantic information theory, and does not address LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22139",
      "abstract": "Multimodal Large Language Models (MLLMs) have demonstrated significant success in visual understanding tasks. However, challenges persist in adapting these models for video comprehension due to the large volume of data and temporal complexity. Existing Video-LLMs using uniform frame sampling often struggle to capture the query-related crucial spatiotemporal clues of videos effectively. In this paper, we introduce Q-Frame, a novel approach for adaptive frame selection and multi-resolution scaling tailored to the video's content and the specific query. Q-Frame employs a training-free, plug-and-play strategy generated by a text-image matching network like CLIP, utilizing the Gumbel-Max trick for efficient frame selection. Q-Frame allows Video-LLMs to process more frames without exceeding computational limits, thereby preserving critical temporal and spatial information. We demonstrate Q-Frame's effectiveness through extensive experiments on benchmark datasets, including MLVU, LongVideoBench, and Video-MME, illustrating its superiority over existing methods and its applicability across various video understanding tasks.",
      "authors": [
        "Shaojie Zhang",
        "Jiahui Yang",
        "Jianqin Yin",
        "Zhenbo Luo",
        "Jian Luan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T11:30:51+00:00",
          "link": "https://arxiv.org/abs/2506.22139v1",
          "size": "12330kb",
          "version": "v1"
        }
      ],
      "title": "Q-Frame: Query-aware Frame Selection and Multi-Resolution Adaptation for Video-LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22139",
        "HTML": "https://arxiv.org/html/2506.22139v1",
        "PDF": "https://arxiv.org/pdf/2506.22139"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a method for adaptive frame selection in video tasks for multimodal LLMs. While it touches on data selection and processing, it does not focus on training data processing specifically for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22141",
      "abstract": "In the landscape of publicly available patent retrieval datasets, the need for explicit indomain and out-of-domain labeling, multi-jurisdiction coverage, balanced query domain representation and manageable sizes that support sub document level experiments on moderate computational resources is often overlooked. To address these gaps, we propose DAPFAM, a new open access domain-aware patent retrieval dataset constructed at the simple-family level. The dataset contains 1,247 domain balanced full text query families and 45,336 full text target families. The dataset is enriched by clear relevance judgments (forward/backward citations as positive links, random negatives), as well as explicit in-domain or out-of-domain relationships via a novel proposed labelling scheme based on via International Patent Classification (IPC) codes, resulting in 49,869 evaluation pairs. The dataset is multi jurisdictional, requires little to no preprocessing for retrieval evaluation, and remains of a size manageable for entities with limited ressources allowing for sub document level retrieval experiments without excessive computational costs. We describe our three-step data-curation pipeline, present comprehensive dataset statistics, and provide baseline experiments using lexical and neural retrieval methods. Our baseline experiments highlight significant challenges in crossdomain patent retrieval. The dataset will be publicly available (for now the access link is this repository: https://osf.io/vbyzd/?view_only=1a40242e0d1941a58aa854af3e50cf6b).",
      "authors": [
        "Iliass Ayaou (ICube)",
        "Denis Cavallucci (ICube)",
        "Hicham Chibane (ICube)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T11:34:51+00:00",
          "link": "https://arxiv.org/abs/2506.22141v1",
          "size": "4409kb",
          "version": "v1"
        }
      ],
      "title": "DAPFAM: A Domain-Aware Patent Retrieval Dataset Aggregated at the Family Level",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22141",
        "PDF": "https://arxiv.org/pdf/2506.22141"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes a new patent retrieval dataset (DAPFAM), describing its data-curation pipeline but focuses mainly on patent retrieval and evaluation rather than LLM training data processing explicitly."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22143",
      "abstract": "This paper investigates the performance of various speech SSL models on dialectal Arabic (DA) and Arabic-English code-switched (CS) speech. To address data scarcity, a modified audio-splicing approach is introduced to generate artificial CS speech data. Fine-tuning an already fine-tuned SSL model with the proposed Spliced-Audio Generated (SAGE) data results in an absolute improvement on Word Error Rate (WER) of 7.8% on Arabic and English CS benchmarks. Additionally, an Experience Replay (ER) inspired approach is proposed to enhance generalisation across DA and CS speech while mitigating catastrophic forgetting. Integrating an out-of-domain 3-gram language model reduces the overall mean WER from 31.7% to 26.6%. Few-shot fine-tuning for code-switching benchmarks further improves WER by 4.9%. A WER of 31.1% on Arabic-English CS benchmarks surpasses large-scale multilingual models, including USM and Whisper-large-v2 (both over ten times larger) by an absolute margin of 5.5% and 8.4%, respectively.",
      "authors": [
        "Muhammad Umar Farooq",
        "Oscar Saz"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T11:42:43+00:00",
          "link": "https://arxiv.org/abs/2506.22143v1",
          "size": "258kb",
          "version": "v1"
        }
      ],
      "title": "SAGE: Spliced-Audio Generated Data for Enhancing Foundational Models in Low-Resource Arabic-English Code-Switched Speech Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22143",
        "PDF": "https://arxiv.org/pdf/2506.22143"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces Spliced-Audio Generated data for enhancing speech models, which includes data augmentation for dialectal Arabic and code-switched speech but does not focus directly on LLM data engineering or training."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22144",
      "abstract": "We study networks of processes that all execute the same finite-state protocol and communicate via broadcasts. We are interested in two problems with a parameterized number of processes: the synchronization problem which asks whether there is an execution which puts all processes on a given state; and the repeated coverability problem which asks if there is an infinite execution where a given transition is taken infinitely often. Since both problems are undecidable in the general case, we investigate those problems when the protocol is Wait-Only, i.e., it has no state from which a process can both broadcast and receive messages. We establish that the synchronization problem becomes Ackermann-complete, and the repeated coverability problem is in EXPSPACE, and PSPACE-hard.",
      "authors": [
        "Lucie Guillou",
        "Arnaud Sangnier",
        "Nathalie Sznajder"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T11:43:08+00:00",
          "link": "https://arxiv.org/abs/2506.22144v1",
          "size": "99kb",
          "version": "v1"
        }
      ],
      "title": "Wait-Only Broadcast Protocols are Easier to Verify",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22144",
        "HTML": "https://arxiv.org/html/2506.22144v1",
        "PDF": "https://arxiv.org/pdf/2506.22144"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper deals with broadcast protocols for process synchronization and verification problems and does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22146",
      "abstract": "Despite progress in Vision-Language Models (VLMs), their capacity for visual reasoning is often limited by the \\textit{binding problem}: the failure to reliably associate perceptual features with their correct visual referents. This limitation underlies persistent errors in tasks such as counting, visual search, scene description, and spatial relationship understanding. A key factor is that current VLMs process visual features largely in parallel, lacking mechanisms for spatially grounded, serial attention. This paper introduces a simple yet effective intervention: augmenting visual inputs with low-level spatial structures (e.g., horizontal lines) and pairing this with a textual prompt that encourages sequential, spatially-aware parsing. We empirically demonstrate substantial performance improvements across core visual reasoning tasks. Specifically, our method improves GPT-4o visual search accuracy by 25.00%, increases counting accuracy by 26.83%, reduces edit distance error in scene description by 0.32, and enhances performance on spatial relationship tasks by 9.50% on a a 2D synthetic dataset. Furthermore, we find that the visual modification is essential for these gains; purely textual strategies, including Chain-of-Thought prompting, are insufficient and can even degrade performance. Our method enhances binding only with a single-query inference, underscoring the importance of visual input design over purely linguistically-based approaches. These findings suggest that low-level visual structuring is a powerful and underexplored direction for improving compositional visual reasoning and could serve as a general strategy for enhancing VLM performance on spatially grounded tasks.",
      "authors": [
        "Amirmohammad Izadi",
        "Mohammad Ali Banayeeanzade",
        "Fatemeh Askari",
        "Ali Rahimiakbar",
        "Mohammad Mahdi Vahedi",
        "Hosein Hasani",
        "Mahdieh Soleymani Baghshah"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T11:44:40+00:00",
          "link": "https://arxiv.org/abs/2506.22146v1",
          "size": "5997kb",
          "version": "v1"
        }
      ],
      "title": "Visual Structures Helps Visual Reasoning: Addressing the Binding Problem in VLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22146",
        "HTML": "https://arxiv.org/html/2506.22146v1",
        "PDF": "https://arxiv.org/pdf/2506.22146"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper discusses visual reasoning improvements in Vision-Language Models (VLMs) through visual structure augmentation, without addressing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22148",
      "abstract": "Delay Tolerant Networks (DTNs) offer a promising paradigm for maintaining communication in infrastructure limited environments, such as those encountered during natural disasters. This paper investigates the viability of leveraging an existing national transport system - the Swiss rail network - as a data mule backbone for disseminating critical avalanche alerts. Using The Opportunistic Network Environment (ONE) simulator, we model the entire Swiss rail network and conduct a rigorous comparative analysis of two seminal DTN routing protocols: Epidemic and PROPHET. Experiments are performed in two distinct scenarios: alerts originating from dense urban centres and from sparse, remote mountainous regions. Our results demonstrate that the rail network provides robust connectivity for opportunistic communication in both environments thus validating the integration of DTN principles in remote scenarios.",
      "authors": [
        "Joshua Goulton",
        "Milena Radenkovic"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T11:51:06+00:00",
          "link": "https://arxiv.org/abs/2506.22148v1",
          "size": "935kb",
          "version": "v1"
        }
      ],
      "title": "Resilient Communication For Avalanche Response in Infrastructure-Limited Environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22148",
        "HTML": "https://arxiv.org/html/2506.22148v1",
        "PDF": "https://arxiv.org/pdf/2506.22148"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The research focuses on delay tolerant networking using a transport system for communication in disaster scenarios, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22149",
      "abstract": "The rise of imaging techniques such as optical coherence tomography (OCT) and advances in deep learning (DL) have enabled clinicians and researchers to streamline retinal disease staging. A popular DL approach is self-supervised learning (SSL), where models learn from vast amounts of unlabeled data, avoiding costly annotation. SSL has allowed the development of foundation models (FMs), large models that can be used for a variety of downstream tasks. However, existing FMs for OCT, trained solely on image data, lack a comprehensive and robust semantic understanding of images, as evidenced by their downstream performance (especially for complex tasks), and thus require supervised fine-tuning (which may be unfeasible) to better adapt to specific applications and populations. To address this, we propose RetFiner, an SSL vision-language refinement scheme that improves the representations of existing FMs and enables their efficient and direct adaptation to specific populations for improved downstream performance. Our method uses a diverse set of training objectives which take advantage of the rich supervisory signal found in textual data. We tested RetFiner on the retinal FMs RETFound, UrFound, and VisionFM, showing significant improvements in linear probing performance on seven highly diverse OCT classification tasks, with an average increase of 5.8, 3.9, and 2.1 percentage points over their baselines, respectively. Our code and model weights are publicly available at https://github.com/ronnief1/RetFiner.",
      "authors": [
        "Ronald Fecso",
        "Jos\\'e Morano",
        "Ursula Schmidt-Erfurth",
        "Hrvoje Bogunovi\\'c"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T11:53:54+00:00",
          "link": "https://arxiv.org/abs/2506.22149v1",
          "size": "1483kb",
          "version": "v1"
        }
      ],
      "title": "RetFiner: A Vision-Language Refinement Scheme for Retinal Foundation Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22149",
        "HTML": "https://arxiv.org/html/2506.22149v1",
        "PDF": "https://arxiv.org/pdf/2506.22149"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses the improvement of representations in foundation models through a vision-language refinement scheme but focuses on SSL techniques rather than direct data engineering tasks like collection or preprocessing. It mentions textual data for training but doesn't propose novel data processing methods for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22156",
      "abstract": "Magnetic Resonance Fingerprinting (MRF) is a fast quantitative MR Imaging technique that provides multi-parametric maps with a single acquisition. Neural Networks (NNs) accelerate reconstruction but require significant resources for training. We propose an FPGA-based NN for real-time brain parameter reconstruction from MRF data. Training the NN takes an estimated 200 seconds, significantly faster than standard CPU-based training, which can be up to 250 times slower. This method could enable real-time brain analysis on mobile devices, revolutionizing clinical decision-making and telemedicine.",
      "authors": [
        "Mattia Ricchi",
        "Fabrizio Alfonsi",
        "Camilla Marella",
        "Marco Barbieri",
        "Alessandra Retico",
        "Leonardo Brizi",
        "Alessandro Gabrielli",
        "Claudia Testa"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Instrumentation and Detectors (physics.ins-det)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T12:09:35+00:00",
          "link": "https://arxiv.org/abs/2506.22156v1",
          "size": "195kb",
          "version": "v1"
        }
      ],
      "title": "Hardware acceleration for ultra-fast Neural Network training on FPGA for MRF map reconstruction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22156",
        "HTML": "https://arxiv.org/html/2506.22156v1",
        "PDF": "https://arxiv.org/pdf/2506.22156"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on the hardware acceleration of neural network training using FPGA technology, primarily for MRI data processing, without any connection to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22157",
      "abstract": "Large language models (LLMs) have demonstrated remarkable evaluation and critique capabilities, providing insightful feedback and identifying flaws in various tasks. However, limited research has explored which types of critiques are most effective for improving model responses or how to generate such critiques. To address this gap, we introduce \\textbf{R}efinement-oriented \\textbf{C}ritique \\textbf{O}ptimization (RCO), a novel framework designed to train critic models using refinement signals. RCO uses a feedback loop where critiques, generated by the critic model, guide the actor model in refining its responses. The critique utility (CU) quantifies the effectiveness of these refinements, serving as the reward signal for training the critic model. By focusing on critiques that lead to better refinements, RCO eliminates the need for direct critique preference assessment, ensuring that critiques driving meaningful improvements are rewarded. We evaluate RCO across five tasks, i.e., dialog generation, summarization, question answering, mathematical reasoning, and code generation, and show that it significantly outperforms traditional methods and open-source models in terms of critique quality and refinement outcomes. Our contributions include the introduction of RCO, a novel supervision scheme based on refined response preferences, and comprehensive experimental results that highlight the method's effectiveness in enhancing LLM critique-refinement loops.",
      "authors": [
        "Tianshu Yu",
        "Chao Xiang",
        "Mingchuan Yang",
        "Pei Ke",
        "Bosi Wen",
        "Cunxiang Wang",
        "Jiale Cheng",
        "Li Zhang",
        "Xinyu Mu",
        "Chuxiong Sun",
        "Minlie Huang"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T12:10:57+00:00",
          "link": "https://arxiv.org/abs/2506.22157v1",
          "size": "922kb",
          "version": "v1"
        }
      ],
      "title": "Training Language Model to Critique for Better Refinement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22157",
        "HTML": "https://arxiv.org/html/2506.22157v1",
        "PDF": "https://arxiv.org/pdf/2506.22157"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a new framework for training language models to critique responses, mentioning data-driven refinement signals. However, it focuses on the critique optimization process rather than data engineering aspects for training LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22161",
      "abstract": "Few-shot object detection (FSOD) aims to detect objects with limited samples for novel classes, while relying on abundant data for base classes. Existing FSOD approaches, predominantly built on the Faster R-CNN detector, entangle objectness recognition and foreground classification within shared feature spaces. This paradigm inherently establishes class-specific objectness criteria and suffers from unrepresentative novel class samples. To resolve this limitation, we propose a Uniform Orthogonal Feature Space (UOFS) optimization framework. First, UOFS decouples the feature space into two orthogonal components, where magnitude encodes objectness and angle encodes classification. This decoupling enables transferring class-agnostic objectness knowledge from base classes to novel classes. Moreover, implementing the disentanglement requires careful attention to two challenges: (1) Base set images contain unlabeled foreground instances, causing confusion between potential novel class instances and backgrounds. (2) Angular optimization depends exclusively on base class foreground instances, inducing overfitting of angular distributions to base classes. To address these challenges, we propose a Hybrid Background Optimization (HBO) strategy: (1) Constructing a pure background base set by removing unlabeled instances in original images to provide unbiased magnitude-based objectness supervision. (2) Incorporating unlabeled foreground instances in the original base set into angular optimization to enhance distribution uniformity. Additionally, we propose a Spatial-wise Attention Disentanglement and Association (SADA) module to address task conflicts between class-agnostic and class-specific tasks. Experiments demonstrate that our method significantly outperforms existing approaches based on entangled feature spaces.",
      "authors": [
        "Taijin Zhao",
        "Heqian Qiu",
        "Yu Dai",
        "Lanxiao Wang",
        "Fanman Meng",
        "Qingbo Wu",
        "Hongliang Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T12:17:04+00:00",
          "link": "https://arxiv.org/abs/2506.22161v1",
          "size": "470kb",
          "version": "v1"
        }
      ],
      "title": "Attention-disentangled Uniform Orthogonal Feature Space Optimization for Few-shot Object Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22161",
        "HTML": "https://arxiv.org/html/2506.22161v1",
        "PDF": "https://arxiv.org/pdf/2506.22161"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The research addresses few-shot object detection by optimizing feature spaces and disentangles feature components. It does not relate to training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22165",
      "abstract": "Legal systems heavily rely on cross-citations of legal norms as well as previous court decisions. Practitioners, novices and legal AI systems need access to these relevant data to inform appraisals and judgments. We propose a Graph-Neural-Network (GNN) link prediction model that can identify Case-Law and Case-Case citations with high proficiency through fusion of semantic and topological information. We introduce adapted relational graph convolutions operating on an extended and enriched version of the original citation graph that allow the topological integration of semantic meta-information. This further improves prediction by 3.1 points of average precision and by 8.5 points in data sparsity as well as showing robust performance over time and in challenging fully inductive prediction. Jointly learning and predicting case and norm citations achieves a large synergistic effect that improves case citation prediction by up to 4.7 points, at almost doubled efficiency.",
      "authors": [
        "Lorenz Wendlinger",
        "Simon Alexander Nonn",
        "Abdullah Al Zubaer",
        "Michael Granitzer"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T12:21:41+00:00",
          "link": "https://arxiv.org/abs/2506.22165v1",
          "size": "735kb",
          "version": "v1"
        }
      ],
      "title": "The Missing Link: Joint Legal Citation Prediction using Heterogeneous Graph Enrichment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22165",
        "HTML": "https://arxiv.org/html/2506.22165v1",
        "PDF": "https://arxiv.org/pdf/2506.22165"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "It discusses a graph-neural-network model for legal citation prediction using graph enrichment but does not involve LLM training data processes in its methodology."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22169",
      "abstract": "Operator fusion, a key technique to improve data locality and alleviate GPU memory bandwidth pressure, often fails to extend to the fusion of multiple compute-intensive operators due to saturated computation throughput. However, the dynamicity of tensor dimension sizes could potentially lead to these operators becoming memory-bound, necessitating the generation of fused kernels, a task hindered by limited search spaces for fusion strategies, redundant memory access, and prolonged tuning time, leading to sub-optimal performance and inefficient deployment.\n  We introduce MCFuser, a pioneering framework designed to overcome these obstacles by generating high-performance fused kernels for what we define as memory-bound compute-intensive (MBCI) operator chains. Leveraging high-level tiling expressions to delineate a comprehensive search space, coupled with Directed Acyclic Graph (DAG) analysis to eliminate redundant memory accesses, MCFuser streamlines kernel optimization. By implementing guidelines to prune the search space and incorporating an analytical performance model with a heuristic search, MCFuser not only significantly accelerates the tuning process but also demonstrates superior performance. Benchmarked against leading compilers like Ansor on NVIDIA A100 and RTX3080 GPUs, MCFuser achieves up to a 5.9x speedup in kernel performance and outpaces other baselines while reducing tuning time by over 70-fold, showcasing its agility.",
      "authors": [
        "Zheng Zhang",
        "Donglin Yang",
        "Xiaobo Zhou",
        "Dazhao Cheng"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T12:31:24+00:00",
          "link": "https://arxiv.org/abs/2506.22169v1",
          "size": "522kb",
          "version": "v1"
        }
      ],
      "title": "MCFuser: High-Performance and Rapid Fusion of Memory-Bound Compute-Intensive Operators",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22169",
        "HTML": "https://arxiv.org/html/2506.22169v1",
        "PDF": "https://arxiv.org/pdf/2506.22169"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on operator fusion for GPU performance improvement, unrelated to LLM training data processing or data engineering stages specifically aimed at LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22170",
      "abstract": "The Dijkstra algorithm is a classic path planning method, which operates in a discrete graph space to determine the shortest path from a specified source point to a target node or all other nodes based on non-negative edge weights. Numerous studies have focused on the Dijkstra algorithm due to its potential application. However, its application in surface path planning for mobile robots remains largely unexplored. In this letter, a surface optimal path planning algorithm called RM-Dijkstra is proposed, which is based on Riemannian metric model. By constructing a new Riemannian metric on the 2D projection plane, the surface optimal path planning problem is therefore transformed into a geometric problem on the 2D plane with new Riemannian metric. Induced by the standard Euclidean metric on surface, the constructed new metric reflects environmental information of the robot and ensures that the projection map is an isometric immersion. By conducting a series of simulation tests, the experimental results demonstrate that the RM-Dijkstra algorithm not only effectively solves the optimal path planning problem on surfaces, but also outperforms traditional path planning algorithms in terms of path accuracy and smoothness, particularly in complex scenarios.",
      "authors": [
        "Yu Zhang",
        "Xiao-Song Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T12:31:50+00:00",
          "link": "https://arxiv.org/abs/2506.22170v1",
          "size": "1436kb",
          "version": "v1"
        }
      ],
      "title": "RM-Dijkstra: A surface optimal path planning algorithm based on Riemannian metric",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22170",
        "HTML": "https://arxiv.org/html/2506.22170v1",
        "PDF": "https://arxiv.org/pdf/2506.22170"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper discusses an algorithm for path planning using a Riemannian metric, with no connection to LLM training data processing or data engineering for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22171",
      "abstract": "Current blockchain protocols (e.g., Proof-of-Work and Proof-of-Stake) secure the ledger yet cannot measure validator trustworthiness, allowing subtle misconduct that is especially damaging in decentralized-finance (DeFi) settings. We introduce Proof-of-Behavior (PoB), a consensus model that (i) gives each action a layered utility score -- covering motivation and outcome, (ii) adapts validator weights using recent scores, and (iii) applies decentralized verification with proportional slashing. The reward design is incentive-compatible, yielding a Nash equilibrium in which honest behavior maximizes long-run pay-offs. Simulated DeFi experiments (loan-fraud detection, reputation-weighted validation) show that PoB cuts fraud acceptance by more than 90%, demotes malicious validators within two rounds, and improves proposer fairness versus standard PoS, all with no more than a 5% throughput overhead. By linking consensus influence to verifiably trustworthy conduct, PoB offers a scalable, regulation-friendly foundation for secure and fair blockchain governance in financial applications.",
      "authors": [
        "Ailiya Borjigin",
        "Wei Zhou",
        "Cong He"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T12:35:27+00:00",
          "link": "https://arxiv.org/abs/2506.22171v1",
          "size": "86kb",
          "version": "v1"
        }
      ],
      "title": "Proof-of-Behavior: Behavior-Driven Consensus for Trustworthy Decentralized Finance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22171",
        "HTML": "https://arxiv.org/html/2506.22171v1",
        "PDF": "https://arxiv.org/pdf/2506.22171"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper introduces a consensus model for decentralized finance, which is unrelated to any aspect of LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22172",
      "abstract": "This paper establishes formal mathematical foundations linking Chaos Game Representations (CGR) of DNA sequences to their underlying $k$-mer frequencies. We prove that the Frequency CGR (FCGR) of order $k$ is mathematically equivalent to a discretization of CGR at resolution $2^k \\times 2^k$, and its vectorization corresponds to the $k$-mer frequencies of the sequence. Additionally, we characterize how symmetry transformations of CGR images correspond to specific nucleotide permutations in the originating sequences. Leveraging these insights, we introduce an algorithm that generates synthetic DNA sequences from prescribed $k$-mer distributions by constructing Eulerian paths on De Bruijn multigraphs. This enables reconstruction of sequences matching target $k$-mer profiles with arbitrarily high precision, facilitating the creation of synthetic CGR images for applications such as data augmentation for machine learning-based taxonomic classification of DNA sequences. Numerical experiments validate the effectiveness of our method across both real genomic data and artificially sampled distributions. To our knowledge, this is the first comprehensive framework that unifies CGR geometry, $k$-mer statistics, and sequence reconstruction, offering new tools for genomic analysis and visualization.",
      "authors": [
        "Haoze He",
        "Lila Kari",
        "Pablo Millan Arias"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Formal Languages and Automata Theory (cs.FL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T12:35:57+00:00",
          "link": "https://arxiv.org/abs/2506.22172v1",
          "size": "865kb",
          "version": "v1"
        }
      ],
      "title": "Bridging CGR and $k$-mer Frequencies of DNA",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22172",
        "HTML": "https://arxiv.org/html/2506.22172v1",
        "PDF": "https://arxiv.org/pdf/2506.22172"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper presents a framework for DNA sequence analysis using CGR and k-mer frequencies, without relevance to LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22174",
      "abstract": "The transport industry has recently shown significant interest in unmanned surface vehicles (USVs), specifically for port and inland waterway transport. These systems can improve operational efficiency and safety, which is especially relevant in the European Union, where initiatives such as the Green Deal are driving a shift towards increased use of inland waterways. At the same time, a shortage of qualified personnel is accelerating the adoption of autonomous solutions. However, there is a notable lack of open-source, high-fidelity simulation frameworks and datasets for developing and evaluating such solutions. To address these challenges, we introduce AirSim For Surface Vehicles (ASVSim), an open-source simulation framework specifically designed for autonomous shipping research in inland and port environments. The framework combines simulated vessel dynamics with marine sensor simulation capabilities, including radar and camera systems and supports the generation of synthetic datasets for training computer vision models and reinforcement learning agents. Built upon Cosys-AirSim, ASVSim provides a comprehensive platform for developing autonomous navigation algorithms and generating synthetic datasets. The simulator supports research of both traditional control methods and deep learning-based approaches. Through limited experiments, we demonstrate the potential of the simulator in these research areas. ASVSim is provided as an open-source project under the MIT license, making autonomous navigation research accessible to a larger part of the ocean engineering community.",
      "authors": [
        "Bavo Lesy",
        "Siemen Herremans",
        "Robin Kerstens",
        "Jan Steckel",
        "Walter Daems",
        "Siegfried Mercelis and Ali Anwar"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T12:39:16+00:00",
          "link": "https://arxiv.org/abs/2506.22174v1",
          "size": "5177kb",
          "version": "v1"
        }
      ],
      "title": "ASVSim (AirSim for Surface Vehicles): A High-Fidelity Simulation Framework for Autonomous Surface Vehicle Research",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22174",
        "HTML": "https://arxiv.org/html/2506.22174v1",
        "PDF": "https://arxiv.org/pdf/2506.22174"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper proposes a simulation framework for autonomous surface vehicle research, not related to LLM training data or its processing stages."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22175",
      "abstract": "Recently, Mixture-of-Experts (MoE) has become one of the most popular techniques to scale pre-trained models to extraordinarily large sizes. Dynamic activation of experts allows for conditional computation, increasing the number of parameters of neural networks, which is critical for absorbing the vast amounts of knowledge available in many deep learning areas. However, despite the existing system and algorithm optimizations, there are significant challenges to be tackled when it comes to the inefficiencies of communication and memory consumption.\n  In this paper, we present the design and implementation of MPipeMoE, a high-performance library that accelerates MoE training with adaptive and memory-efficient pipeline parallelism. Inspired by that the MoE training procedure can be divided into multiple independent sub-stages, we design adaptive pipeline parallelism with an online algorithm to configure the granularity of the pipelining. Further, we analyze the memory footprint breakdown of MoE training and identify that activations and temporary buffers are the primary contributors to the overall memory footprint. Toward memory efficiency, we propose memory reusing strategies to reduce memory requirements by eliminating memory redundancies, and develop an adaptive selection component to determine the optimal strategy that considers both hardware capacities and model characteristics at runtime. We implement MPipeMoE upon PyTorch and evaluate it with common MoE models in a physical cluster consisting of 8 NVIDIA DGX A100 servers. Compared with the state-of-art approach, MPipeMoE achieves up to 2.8x speedup and reduces memory footprint by up to 47% in training large models.",
      "authors": [
        "Zheng Zhang",
        "Donglin Yang",
        "Yaqi Xia",
        "Liang Ding",
        "Dacheng Tao",
        "Xiaobo Zhou",
        "Dazhao Cheng"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T12:41:53+00:00",
          "link": "https://arxiv.org/abs/2506.22175v1",
          "size": "440kb",
          "version": "v1"
        }
      ],
      "title": "MPipeMoE: Memory Efficient MoE for Pre-trained Models with Adaptive Pipeline Parallelism",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22175",
        "HTML": "https://arxiv.org/html/2506.22175v1",
        "PDF": "https://arxiv.org/pdf/2506.22175"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on optimizing Mixture-of-Experts (MoE) models by enhancing training procedures and memory efficiency. It does not address the collection, construction, or processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22176",
      "abstract": "This work presents KnotDLO, a method for one-handed Deformable Linear Object (DLO) knot tying that is robust to occlusion, repeatable for varying rope initial configurations, interpretable for generating motion policies, and requires no human demonstrations or training. Grasp and target waypoints for future DLO states are planned from the current DLO shape. Grasp poses are computed from indexing the tracked piecewise linear curve representing the DLO state based on the current curve shape and are piecewise continuous. KnotDLO computes intermediate waypoints from the geometry of the current DLO state and the desired next state. The system decouples visual reasoning from control. In 16 trials of knot tying, KnotDLO achieves a 50% success rate in tying an overhand knot from previously unseen configurations.",
      "authors": [
        "Holly Dinkel and Raghavendra Navaratna and Jingyi Xiang and Brian Coltin and Trey Smith and Timothy Bretl"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T12:43:05+00:00",
          "link": "https://arxiv.org/abs/2506.22176v1",
          "size": "1475kb",
          "version": "v1"
        }
      ],
      "title": "KnotDLO: Toward Interpretable Knot Tying",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22176",
        "HTML": "https://arxiv.org/html/2506.22176v1",
        "PDF": "https://arxiv.org/pdf/2506.22176"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper introduces a method for knot tying with deformable linear objects without the need for human demonstrations or training data. It does not discuss any aspects of training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22179",
      "abstract": "Zero-shot skeleton-based action recognition aims to develop models capable of identifying actions beyond the categories encountered during training. Previous approaches have primarily focused on aligning visual and semantic representations but often overlooked the importance of fine-grained action patterns in the semantic space (e.g., the hand movements in drinking water and brushing teeth). To address these limitations, we propose a Frequency-Semantic Enhanced Variational Autoencoder (FS-VAE) to explore the skeleton semantic representation learning with frequency decomposition. FS-VAE consists of three key components: 1) a frequency-based enhancement module with high- and low-frequency adjustments to enrich the skeletal semantics learning and improve the robustness of zero-shot action recognition; 2) a semantic-based action description with multilevel alignment to capture both local details and global correspondence, effectively bridging the semantic gap and compensating for the inherent loss of information in skeleton sequences; 3) a calibrated cross-alignment loss that enables valid skeleton-text pairs to counterbalance ambiguous ones, mitigating discrepancies and ambiguities in skeleton and text features, thereby ensuring robust alignment. Evaluations on the benchmarks demonstrate the effectiveness of our approach, validating that frequency-enhanced semantic features enable robust differentiation of visually and semantically similar action clusters, improving zero-shot action recognition.",
      "authors": [
        "Wenhan Wu",
        "Zhishuai Guo",
        "Chen Chen",
        "Hongfei Xue",
        "Aidong Lu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T12:44:08+00:00",
          "link": "https://arxiv.org/abs/2506.22179v1",
          "size": "1040kb",
          "version": "v1"
        }
      ],
      "title": "Frequency-Semantic Enhanced Variational Autoencoder for Zero-Shot Skeleton-based Action Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22179",
        "PDF": "https://arxiv.org/pdf/2506.22179"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper proposes a method for zero-shot skeleton-based action recognition utilizing variational autoencoders. It involves alignment of visual and semantic representations but does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22180",
      "abstract": "The industrial market continuously needs reliable solutions to secure autonomous systems. Especially as these systems become more complex and interconnected, reliable security solutions are becoming increasingly important. One promising solution to tackle this challenge is using smart contracts designed to meet contractual conditions, avoid malicious errors, secure exchanges, and minimize the need for reliable intermediaries. However, smart contracts are immutable. Moreover, there are different smart contract execution architectures (namely Order-Execute and Execute-Order-Validate) that have different throughputs. In this study, we developed an evaluation model for assessing the security of reliable smart contract execution. We then developed a realistic smart contract enabled IoT energy case study. Finally, we simulate the developed case study to evaluate several smart contract security vulnerabilities reported in the literature. Our results show that the Execute-Order-Validate architecture is more promising regarding reliability and security.",
      "authors": [
        "\\\"Onder G\\\"urcan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T12:45:05+00:00",
          "link": "https://arxiv.org/abs/2506.22180v1",
          "size": "1359kb",
          "version": "v1"
        }
      ],
      "title": "Reliability Analysis of Smart Contract Execution Architectures: A Comparative Simulation Study",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22180",
        "HTML": "https://arxiv.org/html/2506.22180v1",
        "PDF": "https://arxiv.org/pdf/2506.22180"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper investigates smart contract execution architectures and does not address any aspect of LLM training data processing or data engineering tasks related to these models."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22183",
      "abstract": "The rapid rise of open-weight and open-source foundation models is intensifying the obligation and reshaping the opportunity to make AI systems safe. This paper reports outcomes from the Columbia Convening on AI Openness and Safety (San Francisco, 19 Nov 2024) and its six-week preparatory programme involving more than forty-five researchers, engineers, and policy leaders from academia, industry, civil society, and government. Using a participatory, solutions-oriented process, the working groups produced (i) a research agenda at the intersection of safety and open source AI; (ii) a mapping of existing and needed technical interventions and open source tools to safely and responsibly deploy open foundation models across the AI development workflow; and (iii) a mapping of the content safety filter ecosystem with a proposed roadmap for future research and development. We find that openness -- understood as transparent weights, interoperable tooling, and public governance -- can enhance safety by enabling independent scrutiny, decentralized mitigation, and culturally plural oversight. However, significant gaps persist: scarce multimodal and multilingual benchmarks, limited defenses against prompt-injection and compositional attacks in agentic systems, and insufficient participatory mechanisms for communities most affected by AI harms. The paper concludes with a roadmap of five priority research directions, emphasizing participatory inputs, future-proof content filters, ecosystem-wide safety infrastructure, rigorous agentic safeguards, and expanded harm taxonomies. These recommendations informed the February 2025 French AI Action Summit and lay groundwork for an open, plural, and accountable AI safety discipline.",
      "authors": [
        "Camille Fran\\c{c}ois",
        "Ludovic P\\'eran",
        "Ayah Bdeir",
        "Nouha Dziri",
        "Will Hawkins",
        "Yacine Jernite",
        "Sayash Kapoor",
        "Juliet Shen",
        "Heidy Khlaaf",
        "Kevin Klyman",
        "Nik Marda",
        "Marie Pellat",
        "Deb Raji",
        "Divya Siddarth",
        "Aviya Skowron",
        "Joseph Spisak",
        "Madhulika Srikumar",
        "Victor Storchan",
        "Audrey Tang",
        "Jen Weedon"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T12:45:44+00:00",
          "link": "https://arxiv.org/abs/2506.22183v1",
          "size": "2085kb",
          "version": "v1"
        }
      ],
      "title": "A Different Approach to AI Safety: Proceedings from the Columbia Convening on Openness in Artificial Intelligence and AI Safety",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22183",
        "PDF": "https://arxiv.org/pdf/2506.22183"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses tools and interventions to safely deploy open-source AI models, which could indirectly relate to data processing through safety filters and benchmarks. However, there is no direct focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22185",
      "abstract": "While microservices are revolutionizing cloud computing by offering unparalleled scalability and independent deployment, their decentralized nature poses significant security and management challenges that can threaten system stability. We propose a framework based on MAPE-K, which leverages agentic AI, for autonomous anomaly detection and remediation to address the daunting task of highly distributed system management. Our framework offers practical, industry-ready solutions for maintaining robust and secure microservices. Practitioners and researchers can customize the framework to enhance system stability, reduce downtime, and monitor broader system quality attributes such as system performance level, resilience, security, and anomaly management, among others.",
      "authors": [
        "Matteo Esposito",
        "Alexander Bakhtin",
        "Noman Ahmad",
        "Mikel Robredo",
        "Ruoyu Su",
        "Valentina Lenarduzzi",
        "Davide Taibi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Networking and Internet Architecture (cs.NI)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T12:46:12+00:00",
          "link": "https://arxiv.org/abs/2506.22185v1",
          "size": "988kb",
          "version": "v1"
        }
      ],
      "title": "Autonomic Microservice Management via Agentic AI and MAPE-K Integration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22185",
        "HTML": "https://arxiv.org/html/2506.22185v1",
        "PDF": "https://arxiv.org/pdf/2506.22185"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on managing microservices using a framework based on MAPE-K and agentic AI. It addresses system stability, resilience, security, and anomaly management, with no mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22186",
      "abstract": "Thompson sampling (TS) is an effective method to explore parametric uncertainties and can therefore be used for active learning-based controller design. However, TS relies on finite parametric representations, which limits its applicability to more general spaces, which are more commonly encountered in control system design. To address this issue, this work pro poses a parameterization method for control law learning using reproducing kernel Hilbert spaces and designs a data-driven active learning control approach. Specifically, the proposed method treats the control law as an element in a function space, allowing the design of control laws without imposing restrictions on the system structure or the form of the controller. A TS framework is proposed in this work to explore potential optimal control laws, and the convergence guarantees are further provided for the learning process. Theoretical analysis shows that the proposed method learns the relationship between control laws and closed-loop performance metrics at an exponential rate, and the upper bound of control regret is also derived. Numerical experiments on controlling unknown nonlinear systems validate the effectiveness of the proposed method.",
      "authors": [
        "Kaikai Zheng",
        "Dawei Shi",
        "Yang Shi",
        "Long Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T12:49:43+00:00",
          "link": "https://arxiv.org/abs/2506.22186v1",
          "size": "33kb",
          "version": "v1"
        }
      ],
      "title": "Thompson Sampling-Based Learning and Control for Unknown Dynamic Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22186",
        "HTML": "https://arxiv.org/html/2506.22186v1",
        "PDF": "https://arxiv.org/pdf/2506.22186"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper discusses Thompson sampling for learning and control in unknown dynamic systems. It proposes methods for control law learning and does not involve LLM training data processing or data engineering for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22189",
      "abstract": "Large-language models (LLMs) and agentic systems present exciting opportunities to accelerate drug discovery and design. In this study, we critically examine the modularity of LLM-based agentic systems for drug discovery, i.e., whether parts of the agentic system such as the LLM are interchangeable, a topic that has received limited attention in drug discovery applications. We compare the performance of different large language models (LLMs) and the effectiveness of tool-calling agents versus code-generating agents in this domain. Our case study, comparing performance in orchestrating tools for chemistry and drug discovery using an LLM-as-a-judge score, shows that Claude-3.5-Sonnet, Claude-3.7-Sonnet and GPT-4o outperform alternative language models such as Llama-3.1-8B, Llama-3.1-70B, GPT-3.5-Turbo, and Nova-Micro. Although we confirm that code-generating agents outperform the tool-calling ones on average, we show that this is highly question and model dependent. Furthermore, the impact of replacing system prompts is dependent on the specific question asked and the model used, underscoring that -- even in this particular domain -- one cannot just replace language models without considering prompt re-engineering. Our study highlights the necessity of further research into the modularity of agentic systems to enable the development of stable and scalable solutions for real-world problems.",
      "authors": [
        "Laura van Weesep",
        "Samuel Genheden",
        "Ola Engkvist and Jens Sj\\\"olund"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T12:57:00+00:00",
          "link": "https://arxiv.org/abs/2506.22189v1",
          "size": "118kb",
          "version": "v1"
        }
      ],
      "title": "Exploring Modularity of Agentic Systems for Drug Discovery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22189",
        "HTML": "https://arxiv.org/html/2506.22189v1",
        "PDF": "https://arxiv.org/pdf/2506.22189"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The study examines the modularity of LLM-based agentic systems for drug discovery. It touches on using pre-existing models and data sources but does not propose novel methods for LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22190",
      "abstract": "Despite rapid advancements, machine learning, particularly deep learning, is hindered by the need for large amounts of labeled data to learn meaningful patterns without overfitting and immense demands for computation and storage, which motivate research into architectures that can achieve good performance with fewer resources. This paper introduces dreaMLearning, a novel framework that enables learning from compressed data without decompression, built upon Entropy-based Generalized Deduplication (EntroGeDe), an entropy-driven lossless compression method that consolidates information into a compact set of representative samples. DreaMLearning accommodates a wide range of data types, tasks, and model architectures. Extensive experiments on regression and classification tasks with tabular and image data demonstrate that dreaMLearning accelerates training by up to 8.8x, reduces memory usage by 10x, and cuts storage by 42%, with a minimal impact on model performance. These advancements enhance diverse ML applications, including distributed and federated learning, and tinyML on resource-constrained edge devices, unlocking new possibilities for efficient and scalable learning.",
      "authors": [
        "Xiaobo Zhao",
        "Aaron Hurst",
        "Panagiotis Karras and Daniel E. Lucani"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T12:57:22+00:00",
          "link": "https://arxiv.org/abs/2506.22190v1",
          "size": "283kb",
          "version": "v1"
        }
      ],
      "title": "dreaMLearning: Data Compression Assisted Machine Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22190",
        "HTML": "https://arxiv.org/html/2506.22190v1",
        "PDF": "https://arxiv.org/pdf/2506.22190"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper introduces dreaMLearning, which is a framework for data compression in machine learning. It focuses on learning from compressed data without decompression, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22191",
      "abstract": "Robust and accurate 2D/3D registration, which aligns preoperative models with intraoperative images of the same anatomy, is crucial for successful interventional navigation. To mitigate the challenge of a limited field of view in single-image intraoperative scenarios, multi-view 2D/3D registration is required by leveraging multiple intraoperative images. In this paper, we propose a novel multi-view 2D/3D rigid registration approach comprising two stages. In the first stage, a combined loss function is designed, incorporating both the differences between predicted and ground-truth poses and the dissimilarities (e.g., normalized cross-correlation) between simulated and observed intraoperative images. More importantly, additional cross-view training loss terms are introduced for both pose and image losses to explicitly enforce cross-view constraints. In the second stage, test-time optimization is performed to refine the estimated poses from the coarse stage. Our method exploits the mutual constraints of multi-view projection poses to enhance the robustness of the registration process. The proposed framework achieves a mean target registration error (mTRE) of $0.79 \\pm 2.17$ mm on six specimens from the DeepFluoro dataset, demonstrating superior performance compared to state-of-the-art registration algorithms.",
      "authors": [
        "Yuxin Cui",
        "Rui Song",
        "Yibin Li",
        "Max Q.-H. Meng",
        "Zhe Min"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T12:57:58+00:00",
          "link": "https://arxiv.org/abs/2506.22191v1",
          "size": "4300kb",
          "version": "v1"
        }
      ],
      "title": "Robust and Accurate Multi-view 2D/3D Image Registration with Differentiable X-ray Rendering and Dual Cross-view Constraints",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22191",
        "HTML": "https://arxiv.org/html/2506.22191v1",
        "PDF": "https://arxiv.org/pdf/2506.22191"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper proposes a method for multi-view 2D/3D image registration in interventional navigation. It addresses image registration and optimization techniques, with no relevance to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22196",
      "abstract": "Lambek and Scott constructed a correspondence between simply-typed lambda calculi and Cartesian closed categories. Scott's Representation Theorem is a cousin to this result for untyped lambda calculi. It states that every untyped lambda calculus arises from a reflexive object in some category. We present a formalization of Scott's Representation Theorem in univalent foundations, in the (Rocq-)UniMath library. Specifically, we implement two proofs of that theorem, one by Scott and one by Hyland. We also explain the role of the Karoubi envelope -- a categorical construction -- in the proofs and the impact the chosen foundation has on this construction. Finally, we report on some automation we have implemented for the reduction of $\\lambda$-terms.",
      "authors": [
        "Arnoud van der Leer",
        "Kobe Wullaert",
        "and Benedikt Ahrens"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Category Theory (math.CT)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T13:04:36+00:00",
          "link": "https://arxiv.org/abs/2506.22196v1",
          "size": "121kb",
          "version": "v1"
        }
      ],
      "title": "Scott's Representation Theorem and the Univalent Karoubi Envelope",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22196",
        "HTML": "https://arxiv.org/html/2506.22196v1",
        "PDF": "https://arxiv.org/pdf/2506.22196"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper discusses Scott's Representation Theorem and formalization in the context of simply-typed and untyped lambda calculi within univalent foundations. There is no mention or contribution related to the processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22199",
      "abstract": "Relational databases (RDBs) are widely regarded as the gold standard for storing structured information. Consequently, predictive tasks leveraging this data format hold significant application promise. Recently, Relational Deep Learning (RDL) has emerged as a novel paradigm wherein RDBs are conceptualized as graph structures, enabling the application of various graph neural architectures to effectively address these tasks. However, given its novelty, there is a lack of analysis into the relationships between the performance of various RDL models and the characteristics of the underlying RDBs.\n  In this study, we present REDELEX$-$a comprehensive exploration framework for evaluating RDL models of varying complexity on the most diverse collection of over 70 RDBs, which we make available to the community. Benchmarked alongside key representatives of classic methods, we confirm the generally superior performance of RDL while providing insights into the main factors shaping performance, including model complexity, database sizes and their structural properties.",
      "authors": [
        "Jakub Pele\\v{s}ka and Gustav \\v{S}\\'ir"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T13:05:15+00:00",
          "link": "https://arxiv.org/abs/2506.22199v1",
          "size": "138kb",
          "version": "v1"
        }
      ],
      "title": "REDELEX: A Framework for Relational Deep Learning Exploration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22199",
        "HTML": "https://arxiv.org/html/2506.22199v1",
        "PDF": "https://arxiv.org/pdf/2506.22199"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper focuses on Relational Deep Learning (RDL) associated with relational databases and evaluates RDL models. There are no references or contributions related to LLM training data collection, construction, or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22200",
      "abstract": "Recent advances in reinforcement learning (RL) have significantly enhanced the reasoning capabilities of large language models (LLMs). Group Relative Policy Optimization (GRPO), an efficient variant of PPO that lowers RL's computational cost, still faces limited exploration, low sample efficiency and instability, constraining its performance on complex reasoning tasks. To address these limitations, we introduce EFRame, an Exploration-Filtering-Replay framework that systematically augments GRPO along three critical dimensions. EFRame performs additional rollouts to explore high-quality trajectories, applies online filtering to eliminate low-quality samples that introduce noise and variance, and leverages experience replay to repeatedly exploit rare but informative samples. EFRame establishes a complete and stable learning cycle, guiding the model through a structured transition from exploration to convergence. Our experiments across a variety of reasoning benchmarks demonstrate that EFRame not only improves the robustness and efficiency of training, but also enables access to deeper reasoning capabilities that remain unattainable under vanilla GRPO. Furthermore, EFRame enables a more fine-grained categorization of training samples, allowing for a deeper analysis of how different types of samples contribute to the learning process in RL. Our code is available at https://github.com/597358816/EFRame.",
      "authors": [
        "Chen Wang",
        "Lai Wei",
        "Yanzhi Zhang",
        "Chenyang Shao",
        "Zedong Dan",
        "Weiran Huang",
        "Yue Wang",
        "Yuzhi Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T13:09:05+00:00",
          "link": "https://arxiv.org/abs/2506.22200v1",
          "size": "815kb",
          "version": "v1"
        }
      ],
      "title": "EFRame: Deeper Reasoning via Exploration-Filtering-Replay Reinforcement Learning Framework",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22200",
        "HTML": "https://arxiv.org/html/2506.22200v1",
        "PDF": "https://arxiv.org/pdf/2506.22200"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The focus of the paper is on reinforcement learning improvements and efficiency, particularly through the EFRame framework. It does not address LLM training data processing or any data engineering tasks relevant to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22201",
      "abstract": "The intensive integration of power converters is changing the way that power systems operate, leading to the emergence of new types of dynamic phenomena and instabilities. At the same time, converters act as an interface between traditional AC grids and their more recent DC counterparts, giving rise to hybrid AC/DC networks. These conditions increase the necessity for stability analysis tools that can simultaneously account for the newly-introduced dynamic phenomena and can also be applied for the stability study of hybrid networks. This paper presents a Matlab-based toolbox for small-signal analysis of hybrid AC/DC power systems considering electromagnetic-transient (EMT) models. The toolbox allows the automatized modeling of the system from the input data and offers options for modal, impedance and passivity analyses. In the paper, the structure and internal processes of the toolbox are duly discussed, together with all its features, both main and complementary. Its capabilities for stability analysis are demonstrated via comprehensive case studies of converter-based system of various size and topology.",
      "authors": [
        "Josep Arevalo-Soler",
        "Dionysios Moutevelis",
        "Elia Mateu-Barriendos",
        "Onur Alican",
        "Carlos Collados-Rodriguez",
        "Marc Cheah-Ma\\~ne",
        "Eduardo Prieto-Araujo",
        "Oriol Gomis-Bellmunt"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T13:10:23+00:00",
          "link": "https://arxiv.org/abs/2506.22201v1",
          "size": "3203kb",
          "version": "v1"
        }
      ],
      "title": "A Matlab-based Toolbox for Automatic EMT Modeling and Small-Signal Stability Analysis of Modern Power Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22201",
        "HTML": "https://arxiv.org/html/2506.22201v1",
        "PDF": "https://arxiv.org/pdf/2506.22201"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper introduces a toolbox for power systems stability analysis. It does not discuss any aspects of LLM training data processing or make contributions to data engineering for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22206",
      "abstract": "We introduce a non-wellfounded proof system for intuitionistic logic extended with ordinary inductive and co-inductive definitions, based on a syntax in which fixpoint formulas are annotated with explicit variables for ordinals. We explore the computational content of this system, in particular we introduce a notion of computability and show that every valid proof is computable. As a consequence, we obtain a normalization result for proofs of what we call finitary formulas. A special case of this result is that every proof of a sequent of the appropriate form represents a unique function on natural numbers. Finally, we derive a categorical model from the proof system and show that least and greatest fixpoint formulas correspond to initial algebras and final coalgebras respectively.",
      "authors": [
        "Sebastian Enqvist"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T13:25:04+00:00",
          "link": "https://arxiv.org/abs/2506.22206v1",
          "size": "33kb",
          "version": "v1"
        }
      ],
      "title": "Computation by infinite descent made explicit",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22206",
        "PDF": "https://arxiv.org/pdf/2506.22206"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on a non-wellfounded proof system for intuitionistic logic, exploring the computational content of such systems. It does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22210",
      "abstract": "Retrieval-augmented generation (RAG) faces challenges related to factual correctness, source attribution, and response completeness. The LiveRAG Challenge hosted at SIGIR'25 aims to advance RAG research using a fixed corpus and a shared, open-source LLM. We propose a modular pipeline that operates on information nuggets-minimal, atomic units of relevant information extracted from retrieved documents. This multistage pipeline encompasses query rewriting, passage retrieval and reranking, nugget detection and clustering, cluster ranking and summarization, and response fluency enhancement. This design inherently promotes grounding in specific facts, facilitates source attribution, and ensures maximum information inclusion within length constraints. In this challenge, we extend our focus to also address the retrieval component of RAG, building upon our prior work on multi-faceted query rewriting. Furthermore, for augmented generation, we concentrate on improving context curation capabilities, maximizing the breadth of information covered in the response while ensuring pipeline efficiency. Our results show that combining original queries with a few sub-query rewrites boosts recall, while increasing the number of documents used for reranking and generation beyond a certain point reduces effectiveness, without improving response quality.",
      "authors": [
        "Weronika {\\L}ajewska",
        "Ivica Kostric",
        "Gabriel Iturra-Bocaz",
        "Mariam Arustashvili",
        "Krisztian Balog"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T13:29:25+00:00",
          "link": "https://arxiv.org/abs/2506.22210v1",
          "size": "140kb",
          "version": "v1"
        }
      ],
      "title": "UiS-IAI@LiveRAG: Retrieval-Augmented Information Nugget-Based Generation of Responses",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22210",
        "HTML": "https://arxiv.org/html/2506.22210v1",
        "PDF": "https://arxiv.org/pdf/2506.22210"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses a pipeline for retrieval-augmented generation, mentioning aspects of information extraction and context curation but does not primarily focus on novel data processing methods for LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22216",
      "abstract": "Low-light image enhancement presents two primary challenges: 1) Significant variations in low-light images across different conditions, and 2) Enhancement levels influenced by subjective preferences and user intent. To address these issues, we propose ReF-LLE, a novel personalized low-light image enhancement method that operates in the Fourier frequency domain and incorporates deep reinforcement learning. ReF-LLE is the first to integrate deep reinforcement learning into this domain. During training, a zero-reference image evaluation strategy is introduced to score enhanced images, providing reward signals that guide the model to handle varying degrees of low-light conditions effectively. In the inference phase, ReF-LLE employs a personalized adaptive iterative strategy, guided by the zero-frequency component in the Fourier domain, which represents the overall illumination level. This strategy enables the model to adaptively adjust low-light images to align with the illumination distribution of a user-provided reference image, ensuring personalized enhancement results. Extensive experiments on benchmark datasets demonstrate that ReF-LLE outperforms state-of-the-art methods, achieving superior perceptual quality and adaptability in personalized low-light image enhancement.",
      "authors": [
        "Ming Zhao",
        "Pingping Liu",
        "Tongshun Zhang",
        "Zhe Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T13:35:34+00:00",
          "link": "https://arxiv.org/abs/2506.22216v1",
          "size": "7881kb",
          "version": "v1"
        }
      ],
      "title": "ReF-LLE: Personalized Low-Light Enhancement via Reference-Guided Deep Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22216",
        "HTML": "https://arxiv.org/html/2506.22216v1",
        "PDF": "https://arxiv.org/pdf/2506.22216"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper presents a method for low-light image enhancement using reinforcement learning. It is unrelated to the processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22223",
      "abstract": "This paper introduces a novel intention-sharing mechanism for Electrically Power-Assisted Cycles (EPACs) within V2X communication frameworks, enhancing the ETSI VRU Awareness Message (VAM) protocol. The method replaces discrete predicted trajectory points with a compact elliptical geographical area representation derived via quadratic polynomial fitting and Least Squares Method (LSM). This approach encodes trajectory predictions with fixed-size data payloads, independent of the number of forecasted points, enabling higher-frequency transmissions and improved network reliability. Simulation results demonstrate superior inter-packet gap (IPG) performance compared to standard ETSI VAMs, particularly under constrained communication conditions. A physical experiment validates the feasibility of real-time deployment on embedded systems. The method supports scalable, low-latency intention sharing, contributing to cooperative perception and enhanced safety for vulnerable road users in connected and automated mobility ecosystems. Finally, we discuss the viability of LSM and open the door to other methods for prediction.",
      "authors": [
        "Felipe Valle Quiroz and Johan Elfing and Joel P{\\aa}lsson and Elena Haller and Oscar Amador Molina"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T13:38:50+00:00",
          "link": "https://arxiv.org/abs/2506.22223v1",
          "size": "293kb",
          "version": "v1"
        }
      ],
      "title": "V2X Intention Sharing for Cooperative Electrically Power-Assisted Cycles",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22223",
        "HTML": "https://arxiv.org/html/2506.22223v1",
        "PDF": "https://arxiv.org/pdf/2506.22223"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper introduces an intention-sharing mechanism for EPACs within V2X frameworks, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22224",
      "abstract": "We present a large-scale, longitudinal dataset capturing user activity on the online platform of DerStandard, a major Austrian newspaper. The dataset spans ten years (2013-2022) and includes over 75 million user comments, more than 400 million votes, and detailed metadata on articles and user interactions. It provides structured conversation threads, explicit up- and downvotes of user comments and editorial topic labels, enabling rich analyses of online discourse while preserving user privacy. To ensure this privacy, all persistent identifiers are anonymized using salted hash functions, and the raw comment texts are not publicly shared. Instead, we release pre-computed vector representations derived from a state-of-the-art embedding model. The dataset supports research on discussion dynamics, network structures, and semantic analyses in the mid-resourced language German, offering a reusable resource across computational social science and related fields.",
      "authors": [
        "Emma Fraxanet",
        "Vicen\\c{c} G\\'omez",
        "Andreas Kaltenbrunner",
        "Max Pellert"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T13:40:20+00:00",
          "link": "https://arxiv.org/abs/2506.22224v1",
          "size": "6419kb",
          "version": "v1"
        }
      ],
      "title": "A Decade of News Forum Interactions: Threaded Conversations, Signed Votes, and Topical Tags",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22224",
        "HTML": "https://arxiv.org/html/2506.22224v1",
        "PDF": "https://arxiv.org/pdf/2506.22224"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper describes a large-scale dataset capturing user activity and mentions pre-computed vector representations derived from an embedding model, but it does not specifically address novel methods for LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22227",
      "abstract": "We present a fabricated and experimentally characterized memory stack that unifies memristive and memcapacitive behavior. Exploiting this dual functionality, we design a circuit enabling simultaneous control of spatial and temporal dynamics in recurrent spiking neural networks (RSNNs). Hardware-aware simulations highlight its promise for efficient neuromorphic processing.",
      "authors": [
        "Simone D'Agostino",
        "Marco Massarotto",
        "Tristan Torchet",
        "Filippo Moro",
        "Niccol\\`o Castellani",
        "Laurent Grenouillet",
        "Yann Beilliard",
        "David Esseni",
        "Melika Payvand",
        "Elisa Vianello"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Emerging Technologies (cs.ET)",
        "Neural and Evolutionary Computing (cs.NE)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T13:45:16+00:00",
          "link": "https://arxiv.org/abs/2506.22227v1",
          "size": "9160kb",
          "version": "v1"
        }
      ],
      "title": "Unified Memcapacitor-Memristor Memory for Synaptic Weights and Neuron Temporal Dynamics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22227",
        "HTML": "https://arxiv.org/html/2506.22227v1",
        "PDF": "https://arxiv.org/pdf/2506.22227"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper deals with memcapacitance and memristance in neuromorphic hardware for neural networks, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22231",
      "abstract": "The rapid proliferation of generative artificial intelligence (AI) tools - especially large language models (LLMs) such as ChatGPT - has ushered in a transformative era in higher education. Universities in developed regions are increasingly integrating these technologies into research, teaching, and assessment. On one hand, LLMs can enhance productivity by streamlining literature reviews, facilitating idea generation, assisting with coding and data analysis, and even supporting grant proposal drafting. On the other hand, their use raises significant concerns regarding academic integrity, ethical boundaries, and equitable access. Recent empirical studies indicate that nearly 47% of students use LLMs in their coursework - with 39% using them for exam questions and 7% for entire assignments - while detection tools currently achieve around 88% accuracy, leaving a 12% error margin. This article critically examines the opportunities offered by generative AI, explores the multifaceted challenges it poses, and outlines robust policy solutions. Emphasis is placed on redesigning assessments to be AI-resilient, enhancing staff and student training, implementing multi-layered enforcement mechanisms, and defining acceptable use. By synthesizing data from recent research and case studies, the article argues that proactive policy adaptation is imperative to harness AI's potential while safeguarding the core values of academic integrity and equity.",
      "authors": [
        "Russell Beale"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T13:49:02+00:00",
          "link": "https://arxiv.org/abs/2506.22231v1",
          "size": "75kb",
          "version": "v1"
        }
      ],
      "title": "Adapting University Policies for Generative AI: Opportunities, Challenges, and Policy Solutions in Higher Education",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22231",
        "HTML": "https://arxiv.org/html/2506.22231v1",
        "PDF": "https://arxiv.org/pdf/2506.22231"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper discusses the integration and policy adaptation of generative AI in higher education, without contributing to LLM training data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22232",
      "abstract": "A growing body of work has been querying LLMs with political questions to evaluate their potential biases. However, this probing method has limited stability, making comparisons between models unreliable. In this paper, we argue that LLMs need more context. We propose a new probing task, Questionnaire Modeling (QM), that uses human survey data as in-context examples. We show that QM improves the stability of question-based bias evaluation, and demonstrate that it may be used to compare instruction-tuned models to their base versions. Experiments with LLMs of various sizes indicate that instruction tuning can indeed change the direction of bias. Furthermore, we observe a trend that larger models are able to leverage in-context examples more effectively, and generally exhibit smaller bias scores in QM. Data and code are publicly available.",
      "authors": [
        "Patrick Haller",
        "Jannis Vamvas",
        "Rico Sennrich and Lena A. J\\\"ager"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T13:49:37+00:00",
          "link": "https://arxiv.org/abs/2506.22232v1",
          "size": "203kb",
          "version": "v1"
        }
      ],
      "title": "Leveraging In-Context Learning for Political Bias Testing of LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22232",
        "PDF": "https://arxiv.org/pdf/2506.22232"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper mentions using human survey data as in-context examples for bias evaluation of LLMs. However, the major focus is on bias testing rather than proposing new methods for data processing or engineering for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22237",
      "abstract": "In this paper, we present a neural network approach for synchronizing audio recordings of human piano performances with their corresponding loosely aligned MIDI files. The task is addressed using a Convolutional Recurrent Neural Network (CRNN) architecture, which effectively captures spectral and temporal features by processing an unaligned piano roll and a spectrogram as inputs to estimate the aligned piano roll. To train the network, we create a dataset of piano pieces with augmented MIDI files that simulate common human timing errors. The proposed model achieves up to 20% higher alignment accuracy than the industry-standard Dynamic Time Warping (DTW) method across various tolerance windows. Furthermore, integrating DTW with the CRNN yields additional improvements, offering enhanced robustness and consistency. These findings demonstrate the potential of neural networks in advancing state-of-the-art MIDI-to-audio alignment.",
      "authors": [
        "Sebastian Murgul",
        "Moritz Reiser",
        "Michael Heizmann",
        "Christoph Seibert"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Computation and Language (cs.CL)",
        "Multimedia (cs.MM)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T13:59:50+00:00",
          "link": "https://arxiv.org/abs/2506.22237v1",
          "size": "41kb",
          "version": "v1"
        }
      ],
      "title": "Fine-Tuning MIDI-to-Audio Alignment using a Neural Network on Piano Roll and CQT Representations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22237",
        "HTML": "https://arxiv.org/html/2506.22237v1",
        "PDF": "https://arxiv.org/pdf/2506.22237"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The focus of this paper is on neural network-based audio and MIDI alignment, which does not relate to processing of LLM training data or any related data engineering tasks for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22241",
      "abstract": "Understanding the impact of small quantum gate perturbations, which are common in quantum digital devices but absent in classical computers, is crucial for identifying potential advantages in quantum machine learning. While these perturbations are typically seen as detrimental to quantum computation, they can actually enhance performance by serving as a natural source of data augmentation. Additionally, they can often be efficiently simulated on classical hardware, enabling quantum-inspired approaches to improve classical machine learning methods. In this paper, we investigate random Bloch sphere rotations, which are fundamental SU(2) transformations, as a simple yet effective quantum-inspired data augmentation technique. Unlike conventional augmentations such as flipping, rotating, or cropping, quantum transformations lack intuitive spatial interpretations, making their application to tasks like image classification less straightforward. While common quantum augmentation methods rely on applying quantum models or trainable quanvolutional layers to classical datasets, we focus on the direct application of small-angle Bloch rotations and their effect on classical data. Using the large-scale ImageNet dataset, we demonstrate that our quantum-inspired augmentation method improves image classification performance, increasing Top-1 accuracy by 3%, Top-5 accuracy by 2.5%, and the F$_1$ score from 8% to 12% compared to standard classical augmentation methods. Finally, we examine the use of stronger unitary augmentations. Although these transformations preserve information in principle, they result in visually unrecognizable images with potential applications for privacy computations. However, we show that our augmentation approach and simple SU(2) transformations do not enhance differential privacy and discuss the implications of this limitation.",
      "authors": [
        "Matthias Tsch\\\"ope",
        "Vitor Fortes Rey",
        "Sogo Pierre Sanon",
        "Paul Lukowicz",
        "Nikolaos Palaiodimopoulos",
        "and Maximilian Kiefer-Emmanouilidis"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
        "Machine Learning (cs.LG)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T14:08:43+00:00",
          "link": "https://arxiv.org/abs/2506.22241v1",
          "size": "5158kb",
          "version": "v1"
        }
      ],
      "title": "Boosting Classification with Quantum-Inspired Augmentations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22241",
        "HTML": "https://arxiv.org/html/2506.22241v1",
        "PDF": "https://arxiv.org/pdf/2506.22241"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper investigates quantum-inspired data augmentation techniques for image classification, without addressing any aspects of LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22242",
      "abstract": "Leveraging diverse robotic data for pretraining remains a critical challenge. Existing methods typically model the dataset's action distribution using simple observations as inputs. However, these inputs are often incomplete, resulting in a dispersed conditional action distribution-an issue we refer to as coordinate system chaos and state chaos. This inconsistency significantly hampers pretraining efficiency. To address this, we propose 4D-VLA, a novel approach that effectively integrates 4D information into the input to mitigate these sources of chaos. Our model introduces depth and temporal information into visual features with sequential RGB-D inputs, aligning the coordinate systems of the robot and the scene. This alignment endows the model with strong spatiotemporal reasoning capabilities while minimizing training overhead. Additionally, we introduce memory bank sampling, a frame sampling strategy designed to extract informative frames from historical images, further improving effectiveness and efficiency. Experimental results demonstrate that our pretraining method and architectural components substantially enhance model performance. In both simulated and real-world experiments, our model achieves a significant increase in success rate over OpenVLA. To further assess spatial perception and generalization to novel views, we introduce MV-Bench, a multi-view simulation benchmark. Our model consistently outperforms existing methods, demonstrating stronger spatial understanding and adaptability.",
      "authors": [
        "Jiahui Zhang",
        "Yurui Chen",
        "Yueming Xu",
        "Ze Huang",
        "Yanpeng Zhou",
        "Yu-Jie Yuan",
        "Xinyue Cai",
        "Guowei Huang",
        "Xingyue Quan",
        "Hang Xu",
        "Li Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T14:09:29+00:00",
          "link": "https://arxiv.org/abs/2506.22242v1",
          "size": "1843kb",
          "version": "v1"
        }
      ],
      "title": "4D-VLA: Spatiotemporal Vision-Language-Action Pretraining with Cross-Scene Calibration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22242",
        "HTML": "https://arxiv.org/html/2506.22242v1",
        "PDF": "https://arxiv.org/pdf/2506.22242"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper discusses a novel method for pretraining with robotic data, focusing on spatiotemporal vision-language-action tasks, which are unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22246",
      "abstract": "Image restoration is a key task in low-level computer vision that aims to reconstruct high-quality images from degraded inputs. The emergence of Vision Mamba, which draws inspiration from the advanced state space model Mamba, marks a significant advancement in this field. Vision Mamba demonstrates excellence in modeling long-range dependencies with linear complexity, a crucial advantage for image restoration tasks. Despite its strengths, Vision Mamba encounters challenges in low-level vision tasks, including computational complexity that scales with the number of scanning sequences and local pixel forgetting. To address these limitations, this study introduces Efficient All-Around Mamba (EAMamba), an enhanced framework that incorporates a Multi-Head Selective Scan Module (MHSSM) with an all-around scanning mechanism. MHSSM efficiently aggregates multiple scanning sequences, which avoids increases in computational complexity and parameter count. The all-around scanning strategy implements multiple patterns to capture holistic information and resolves the local pixel forgetting issue. Our experimental evaluations validate these innovations across several restoration tasks, including super resolution, denoising, deblurring, and dehazing. The results validate that EAMamba achieves a significant 31-89% reduction in FLOPs while maintaining favorable performance compared to existing low-level Vision Mamba methods.",
      "authors": [
        "Yu-Cheng Lin",
        "Yu-Syuan Xu",
        "Hao-Wei Chen",
        "Hsien-Kai Kuo",
        "Chun-Yi Lee"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T14:12:58+00:00",
          "link": "https://arxiv.org/abs/2506.22246v1",
          "size": "5602kb",
          "version": "v1"
        }
      ],
      "title": "EAMamba: Efficient All-Around Vision State Space Model for Image Restoration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22246",
        "HTML": "https://arxiv.org/html/2506.22246v1",
        "PDF": "https://arxiv.org/pdf/2506.22246"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on image restoration techniques and advancements in vision models such as EAMamba, unrelated to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22250",
      "abstract": "We present a design space for animated transitions of the appearance of 3D spatial datasets in a hybrid Augmented Reality (AR)-desktop context. Such hybrid interfaces combine both traditional and immersive displays to facilitate the exploration of 2D and 3D data representations in the environment in which they are best displayed. One key aspect is to introduce transitional animations that change between the different dimensionalities to illustrate the connection between the different representations and to reduce the potential cognitive load on the user. The specific transitions to be used depend on the type of data, the needs of the application domain, and other factors. We summarize these as a transition design space to simplify the decision-making process and provide inspiration for future designs. First, we discuss 3D visualizations from a spatial perspective: a spatial encoding pipeline, where 3D data sampled from the physical world goes through various transformations, being mapped to visual representations, and then being integrated into a hybrid AR-desktop environment. The transition design then focuses on interpolating between two spatial encoding pipelines to provide a smooth experience. To illustrate the use of our design space, we apply it to three case studies that focus on applications in astronomy, radiology, and chemistry; we then discuss lessons learned from these applications.",
      "authors": [
        "Yucheng Lu and Tobias Rau and Benjamin Lee and Andreas K\\\"ohn and Michael Sedlmair and Christian Sandor and Tobias Isenberg"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T14:16:07+00:00",
          "link": "https://arxiv.org/abs/2506.22250v1",
          "size": "31416kb",
          "version": "v1"
        }
      ],
      "title": "A Design Space for Visualization Transitions of 3D Spatial Data in Hybrid AR-Desktop Environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22250",
        "HTML": "https://arxiv.org/html/2506.22250v1",
        "PDF": "https://arxiv.org/pdf/2506.22250"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This research discusses 3D visualization transitions in hybrid AR-desktop environments, which does not pertain to LLM training data or its processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22253",
      "abstract": "Decision making under uncertain environments in the maximization of expected reward while minimizing its risk is one of the ubiquitous problems in many subjects. Here, we introduce a novel problem setting in stochastic bandit optimization that jointly addresses two critical aspects of decision-making: maximizing expected reward and minimizing associated uncertainty, quantified via the mean-variance(MV) criterion. Unlike traditional bandit formulations that focus solely on expected returns, our objective is to efficiently and accurately identify the Pareto-optimal set of arms that strikes the best trade-off between expected performance and risk. We propose a unified meta-algorithmic framework capable of operating under both fixed-confidence and fixed-budget regimes, achieved through adaptive design of confidence intervals tailored to each scenario using the same sample exploration strategy. We provide theoretical guarantees on the correctness of the returned solutions in both settings. To complement this theoretical analysis, we conduct extensive empirical evaluations across synthetic benchmarks, demonstrating that our approach outperforms existing methods in terms of both accuracy and sample efficiency, highlighting its broad applicability to risk-aware decision-making tasks in uncertain environments.",
      "authors": [
        "Shunta Nonaga",
        "Koji Tabata",
        "Yuta Mizuno",
        "Tamiki Komatsuzaki"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T14:21:03+00:00",
          "link": "https://arxiv.org/abs/2506.22253v1",
          "size": "644kb",
          "version": "v1"
        }
      ],
      "title": "Risk-Averse Best Arm Set Identification with Fixed Budget and Fixed Confidence",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22253",
        "HTML": "https://arxiv.org/html/2506.22253v1",
        "PDF": "https://arxiv.org/pdf/2506.22253"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper addresses decision-making in stochastic bandit optimization for risk-aware tasks, without any focus on LLM training data engineering or processing stages."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22255",
      "abstract": "Large language models have steadily increased in size to achieve improved performance; however, this growth has also led to greater inference time and computational demands. Consequently, there is rising interest in model size reduction methods. To address this issue, we propose Projected Compression, a novel model compression technique, that reduces model weights by utilizing projection modules. Specifically, we first train additional trainable projections weights and preserve access to all the original model parameters. Subsequently, these projections are merged into a lower-dimensional product matrix, resulting in a reduced-size standard Transformer-based model. Unlike alternative approaches that require additional computational overhead, our method matches the base model's per-token computation step in FLOPs. Experimental results show that Projected Compression outperforms the comparable hard pruning and retraining approach on higher quality models. Moreover, the performance margin scales well with the number of tokens.",
      "authors": [
        "Maciej Stefaniak",
        "Micha{\\l} Krutul",
        "Jan Ma{\\l}a\\'snicki",
        "Maciej Pi\\'oro",
        "Jakub Krajewski",
        "Sebastian Jaszczur",
        "Marek Cygan",
        "Kamil Adamczewski",
        "Jan Ludziejewski"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T14:24:01+00:00",
          "link": "https://arxiv.org/abs/2506.22255v1",
          "size": "128kb",
          "version": "v1"
        }
      ],
      "title": "Projected Compression: Trainable Projection for Efficient Transformer Compression",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22255",
        "HTML": "https://arxiv.org/html/2506.22255v1",
        "PDF": "https://arxiv.org/pdf/2506.22255"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "While the paper proposes a technique for model compression relevant to transformers, it does not address LLM training data engineering or specific data processing methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22260",
      "abstract": "Wi-Fi networks have long relied on the Enhanced Distributed Channel Access (EDCA) mechanism, allowing stations to compete for transmission opportunities. However, as networks become denser and emerging applications demand lower latency and higher reliability, the limitations of EDCA such as overhead due to contention and collisions have become more pronounced. To address these challenges, Orthogonal Frequency Division Multiple Access (OFDMA) has been introduced in Wi-Fi, enabling more efficient channel utilization through scheduled resource allocation. Furthermore, Wi-Fi 6 defines Uplink Orthogonal Frequency Division Multiple Random Access (UORA), a hybrid mechanism that combines both scheduled and random access, balancing efficiency and responsiveness in resource allocation. Despite significant research on UORA, most studies rely on custom simulators that are not publicly available, limiting reproducibility and preventing validation of the presented results. The only known open-source UORA implementation in the ns-3 simulator exhibits key limitations, such as usage of the same trigger frame (TF) to schedule resources for buffer status reports and data transmissions, and lack of signaling for UORA configuration. In this paper, we present a fully standard-compliant and open source UORA implementation that is compatible with ns-3 version 3.38, addressing these limitations to improve resource allocation efficiency and adaptability. This implementation enables more accurate and flexible evaluation of UORA, fostering future research on Wi-Fi resource allocation strategies.",
      "authors": [
        "Douglas Dziedzorm Agbeve",
        "Andrey Belogaev",
        "Jeroen Famaey"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T14:28:45+00:00",
          "link": "https://arxiv.org/abs/2506.22260v1",
          "size": "525kb",
          "version": "v1"
        }
      ],
      "title": "Design and Evaluation of IEEE 802.11ax Uplink Orthogonal Frequency Division Multiple Random Access in ns-3",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22260",
        "HTML": "https://arxiv.org/html/2506.22260v1",
        "PDF": "https://arxiv.org/pdf/2506.22260"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper is centered on Wi-Fi network enhancements and UORA implementations for resource allocation, unrelated to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22261",
      "abstract": "In this work we study shortest path problems in multimode graphs, a generalization of the min-distance measure introduced by Abboud, Vassilevska W. and Wang in [SODA'16]. A multimode shortest path is the shortest path using one of multiple `modes' of transportation that cannot be combined. This represents real-world scenarios where different modes are not combinable, such as flights operated by different airlines. More precisely, a $k$-multimode graph is a collection of $k$ graphs on the same vertex set and the $k$-mode distance between two vertices is defined as the minimum among the distances computed in each individual graph.\n  We focus on approximating fundamental graph parameters on these graphs, specifically diameter and radius. In undirected multimode graphs we first show an elegant linear time 3-approximation algorithm for 2-mode diameter. We then extend this idea into a general subroutine that can be used as a part of any $\\alpha$-approximation, and use it to construct a 2 and 2.5 approximation algorithm for 2-mode diameter. For undirected radius, we introduce a general scheme that can compute a 3-approximation of the $k$-mode radius for any $k$. In the directed case we develop novel techniques to construct a linear time algorithm to determine whether the diameter is finite.\n  We also develop many conditional fine-grained lower bounds for various multimode diameter and radius approximation problems. We are able to show that many of our algorithms are tight under popular fine-grained complexity hypotheses, including our linear time 3-approximation for $3$-mode undirected diameter and radius. As part of this effort we propose the first extension to the Hitting Set Hypothesis [SODA'16], which we call the $\\ell$-Hitting Set Hypothesis. We use this hypothesis to prove the first parameterized lower bound tradeoff for radius approximation algorithms.",
      "authors": [
        "Yael Kirkpatrick and Virginia Vassilevska Williams"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T14:30:07+00:00",
          "link": "https://arxiv.org/abs/2506.22261v1",
          "size": "335kb",
          "version": "v1"
        }
      ],
      "title": "Shortest Paths in Multimode Graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22261",
        "HTML": "https://arxiv.org/html/2506.22261v1",
        "PDF": "https://arxiv.org/pdf/2506.22261"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on graph theory, specifically on shortest path problems in multimode graphs, and does not address the processing or engineering of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22262",
      "abstract": "Efficiently ranking relevant items from large candidate pools is a cornerstone of modern information retrieval systems -- such as web search, recommendation, and retrieval-augmented generation. Listwise rerankers, which improve relevance by jointly considering multiple candidates, are often limited in practice: either by model input size constraints, or by degraded quality when processing large sets. We propose a model-agnostic method for fast reranking large sets that exceed a model input limits. The method first partitions candidate items into overlapping blocks, each of which is ranked independently in parallel. Implicit pairwise comparisons are then derived from these local rankings. Finally, these comparisons are aggregated to construct a global ranking using algorithms such as Winrate or PageRank. Experiments on TREC DL-2019 show that our method achieves an nDCG@10 of 70.88 compared to the 57.68 for full-context listwise approach using gpt-4.1-mini as long-context model, while reducing latency from 21 to 8 seconds.\n  The implementation of the algorithm and the experiments is available in the repository: https://github.com/V3RGANz/jointrank",
      "authors": [
        "Evgeny Dedov"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T14:30:12+00:00",
          "link": "https://arxiv.org/abs/2506.22262v1",
          "size": "387kb",
          "version": "v1"
        }
      ],
      "title": "JointRank: Rank Large Set with Single Pass",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22262",
        "HTML": "https://arxiv.org/html/2506.22262v1",
        "PDF": "https://arxiv.org/pdf/2506.22262"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses a method for efficiently reranking large candidate sets, which is relevant for information retrieval tasks. However, it does not directly contribute to novel methods for processing or constructing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22263",
      "abstract": "Directed graphs arise in many applications where computing persistent homology helps to encode the shape and structure of the input information. However, there are only a few ways to turn the directed graph information into an undirected simplicial complex filtration required by the standard persistent homology framework. In this paper, we present a new filtration constructed from a directed graph, called the walk-length filtration. This filtration mirrors the behavior of small walks visiting certain collections of vertices in the directed graph. We show that, while the persistence is not stable under the usual $L_\\infty$-style network distance, a generalized $L_1$-style distance is, indeed, stable. We further provide an algorithm for its computation, and investigate the behavior of this filtration in examples, including cycle networks and synthetic hippocampal networks with a focus on comparison to the often used Dowker filtration.",
      "authors": [
        "David E. Mu\\~noz and Elizabeth Munch and Firas A. Khasawneh"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Geometry (cs.CG)",
        "Algebraic Topology (math.AT)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T14:30:51+00:00",
          "link": "https://arxiv.org/abs/2506.22263v1",
          "size": "2624kb",
          "version": "v1"
        }
      ],
      "title": "The Walk-Length Filtration for Persistent Homology on Weighted Directed Graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22263",
        "HTML": "https://arxiv.org/html/2506.22263v1",
        "PDF": "https://arxiv.org/pdf/2506.22263"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper deals with persistent homology on weighted directed graphs and does not relate to LLM training data processing or data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22267",
      "abstract": "With generative artificial intelligence challenging computational scientific computing, data centers are experiencing unprecedented growth in both scale and volume. As a result, computing efficiency has become more critical than ever. Operational Data Analytics (ODA) relies on the collection of data center telemetry to improve efficiency, but so far has been focusing on real-time telemetry data visualization and post-mortem analysis. However, with NoSQL databases now serving as the default storage backend to support scalability, querying this data is challenging due to its schema-less nature, which requires domain knowledge to traverse relationships between data sources. Ontologies and Knowledge Graphs (KGs) can capture these relationships, but traditional KGs are costly to scale and have not been widely applied to multivariate timeseries. Virtual Knowledge Graphs (VKGs) offer a lightweight alternative by generating query-specific graphs at runtime. In this work, we present a full end-to-end ODA chatbot system that uses a Large Language Model (LLM) to generate SPARQL queries, utilizing VKG for data retrieval. This approach achieves 92.5% accuracy compared to 25% with direct NoSQL queries. The proposed methodology optimizes VKG construction and LLM inference, cutting previous work average query latency by 85% (from 20.36s to 3.03s) and keeping VKG sizes under 179 MiB. This performance makes the tool suitable for deployment and real-time interaction with ODA end-users.",
      "authors": [
        "Junaid Ahmed Khan",
        "Hiari Pizzini Cavagna",
        "Andrea Proia",
        "Andrea Bartolini"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T14:36:39+00:00",
          "link": "https://arxiv.org/abs/2506.22267v1",
          "size": "2966kb",
          "version": "v1"
        }
      ],
      "title": "Towards Operational Data Analytics Chatbots -- Virtual Knowledge Graph is All You Need",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22267",
        "HTML": "https://arxiv.org/html/2506.22267v1",
        "PDF": "https://arxiv.org/pdf/2506.22267"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper presents a system utilizing an LLM to generate queries for a virtual knowledge graph. While it involves LLMs, the focus is on data retrieval efficiency rather than on the processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22270",
      "abstract": "The proliferation of disinformation challenges traditional, unscalable editorial processes and existing automated systems that prioritize engagement over public service values. To address this, we introduce the Public Service Algorithm (PSA), a novel framework using Large Language Models (LLMs) for scalable, transparent content curation based on Public Service Media (PSM) inspired values. Utilizing a large multilingual news dataset from the 'A European Perspective' project, our experiment directly compared article ratings from a panel of experienced editors from various European PSMs, with those from several LLMs, focusing on four criteria: diversity, in-depth analysis, forward-looking, and cross-border relevance. Utilizing criterion-specific prompts, our results indicate a promising alignment between human editorial judgment and LLM assessments, demonstrating the potential of LLMs to automate value-driven curation at scale without sacrificing transparency. This research constitutes a first step towards a scalable framework for the automatic curation of trustworthy news content.",
      "authors": [
        "Ahmad Mel",
        "Sebastien Noir"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T14:39:38+00:00",
          "link": "https://arxiv.org/abs/2506.22270v1",
          "size": "1553kb",
          "version": "v1"
        }
      ],
      "title": "Public Service Algorithm: towards a transparent, explainable, and scalable content curation for news content based on editorial values",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22270",
        "HTML": "https://arxiv.org/html/2506.22270v1",
        "PDF": "https://arxiv.org/pdf/2506.22270"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper explores the use of LLMs for content curation and alignment with editorial values, using a large multilingual dataset. However, it primarily addresses content curation rather than training data engineering or processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22271",
      "abstract": "Many Knowledge Graph Completion (KGC) models, despite using powerful encoders, rely on a simple vector-matrix multiplication to score queries against candidate object entities. When the number of entities is larger than the model's embedding dimension, which in practical scenarios is often by several orders of magnitude, we have a linear output layer with a rank bottleneck. Such bottlenecked layers limit model expressivity. We investigate both theoretically and empirically how rank bottlenecks affect KGC models. We find that, by limiting the set of feasible predictions, rank bottlenecks hurt ranking accuracy and the distribution fidelity of scores. Inspired by the language modelling literature, we propose KGE-MoS, a mixture-based output layer to break rank bottlenecks in many KGC models. Our experiments on four datasets show that KGE-MoS improves performance and probabilistic fit of KGC models for a low parameter cost.",
      "authors": [
        "Samy Badreddine and Emile van Krieken and Luciano Serafini"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T14:41:22+00:00",
          "link": "https://arxiv.org/abs/2506.22271v1",
          "size": "2968kb",
          "version": "v1"
        }
      ],
      "title": "Breaking Rank Bottlenecks in Knowledge Graph Completion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22271",
        "HTML": "https://arxiv.org/html/2506.22271v1",
        "PDF": "https://arxiv.org/pdf/2506.22271"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on improving Knowledge Graph Completion models by addressing rank bottlenecks in scoring queries against candidate entities. It does not involve any aspect of LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22274",
      "abstract": "Natural scenes provide us with rich contexts for object recognition and reference. In particular, knowing what type of scene one is looking at generates expectations about which objects will occur, and what their spatial configuration should be. Do Vision-Language Models (VLMs) learn to rely on scene contexts in a similar way, when generating references to objects? To address this question, we introduce the \\textit{Common Objects Out-of-Context (COOCO)} dataset and test to what extent VLMs rely on scene context to refer to objects under different degrees of scene-object congruency, and different perturbations. Our findings show that models leverage scene context adaptively, depending on both the semantic relatedness between object and scene and the level of noise. In particular, models rely more on context under high target-scene congruence or when objects are degraded. Attention analysis reveals that successful object categorisation involves increased focus on the target in mid-level layers, especially under moderate noise, suggesting that VLMs dynamically balance local and contextual information for reference generation. We make our dataset, code and models available at \\href{https://github.com/cs-nlp-uu/scenereg}{https://github.com/cs-nlp-uu/scenereg}.",
      "authors": [
        "Filippo Merlo",
        "Ece Takmaz",
        "Wenkai Chen",
        "Albert Gatt"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T14:44:45+00:00",
          "link": "https://arxiv.org/abs/2506.22274v1",
          "size": "2130kb",
          "version": "v1"
        }
      ],
      "title": "COOCO -- Common Objects Out-of-Context -- Semantic Violation in Scenes: Investigating Multimodal Context in Referential Communication",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22274",
        "HTML": "https://arxiv.org/html/2506.22274v1",
        "PDF": "https://arxiv.org/pdf/2506.22274"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a dataset for evaluating Vision-Language Models' handling of context in referential communication. While it involves data used in model evaluation, its primary focus is not on developing novel methods for LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22276",
      "abstract": "Artificial intelligence has made remarkable strides in recent years, achieving superhuman performance across a wide range of tasks. Yet despite these advances, most cooperative AI systems remain rigidly obedient, designed to follow human instructions without question and conform to user expectations, even when doing so may be counterproductive or unsafe. This paper argues for expanding the agency of AI teammates to include \\textit{intelligent disobedience}, empowering them to make meaningful and autonomous contributions within human-AI teams. It introduces a scale of AI agency levels and uses representative examples to highlight the importance and growing necessity of treating AI autonomy as an independent research focus in cooperative settings. The paper then explores how intelligent disobedience manifests across different autonomy levels and concludes by proposing initial boundaries and considerations for studying disobedience as a core capability of artificial agents.",
      "authors": [
        "Reuth Mirsky"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T14:45:27+00:00",
          "link": "https://arxiv.org/abs/2506.22276v1",
          "size": "25kb",
          "version": "v1"
        }
      ],
      "title": "Artificial Intelligent Disobedience: Rethinking the Agency of Our Artificial Teammates",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22276",
        "HTML": "https://arxiv.org/html/2506.22276v1",
        "PDF": "https://arxiv.org/pdf/2506.22276"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper discusses expanding AI agency by allowing intelligent disobedience in AI systems. It does not address LLM training data collection, construction, or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22281",
      "abstract": "For many hard computational problems, simple algorithms that run in time $2^n \\cdot n^{O(1)}$ arise, say, from enumerating all subsets of a size-$n$ set. Finding (exponentially) faster algorithms is a natural goal that has driven much of the field of exact exponential algorithms (e.g., see Fomin and Kratsch, 2010). In this paper we obtain algorithms with running time $O(1.9999977^n)$ on input graphs with $n$ vertices, for the following well-studied problems:\n  - $d$-Cut: find a proper cut in which no vertex has more than $d$ neighbors on the other side of the cut;\n  - Internal Partition: find a proper cut in which every vertex has at least as many neighbors on its side of the cut as on the other side; and\n  - ($\\alpha,\\beta$)-Domination: given intervals $\\alpha,\\beta \\subseteq [0,n]$, find a subset $S$ of the vertices, so that for every vertex $v \\in S$ the number of neighbors of $v$ in $S$ is from $\\alpha$ and for every vertex $v \\notin S$, the number of neighbors of $v$ in $S$ is from $\\beta$.\n  Our algorithms are exceedingly simple, combining the split and list technique (Horowitz and Sahni, 1974; Williams, 2005) with a tool from computational geometry: orthogonal range searching in the moderate dimensional regime (Chan, 2017). Our technique is applicable to the decision, optimization and counting versions of these problems and easily extends to various generalizations with more fine-grained, vertex-specific constraints, as well as to directed, balanced, and other variants. Algorithms with running times of the form $c^n$, for $c<2$, were known for the first problem only for constant $d$, and for the third problem for certain special cases of $\\alpha$ and $\\beta$; for the second problem we are not aware of such results.",
      "authors": [
        "L\\'aszl\\'o Kozma",
        "Junqi Tan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Computational Geometry (cs.CG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T14:52:08+00:00",
          "link": "https://arxiv.org/abs/2506.22281v1",
          "size": "158kb",
          "version": "v1"
        }
      ],
      "title": "Faster exponential algorithms for cut problems via geometric data structures",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22281",
        "HTML": "https://arxiv.org/html/2506.22281v1",
        "PDF": "https://arxiv.org/pdf/2506.22281"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on algorithms for cut problems using geometric data structures, and does not mention or relate to LLM training data processing or data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22283",
      "abstract": "Large Vision-Language Models (LVLMs) encode visual inputs as dense sequences of patch-level tokens to capture fine-grained semantics. These visual tokens often outnumber their textual counterparts by a large margin, leading to substantial computational overhead and limiting the scalability of LVLMs in practice. Previous efforts have explored visual token reduction either prior to or within the large language models (LLM). However, most in-LLM reduction approaches rely on text-conditioned interactions, implicitly assuming that textual tokens can reliably capture the importance of visual tokens. In this work, we revisit this assumption and reveal causal, semantic, and spatial forms of cross-modal misalignment. These misalignments undermine the effectiveness of text-guided visual token reduction. To address this, we introduce VisionDrop, a training-free, visual-only pruning framework that selects informative visual tokens based on intra-modal (visual-to-visual) attention, without relying on textual signals. To further suppress redundancy throughout the model hierarchy, we treat the visual encoder and the LLM as a unified system and design a progressive pruning pipeline. Our method performs dominant token selection and lightweight contextual merging at multiple stages, enabling fine-grained visual information to be retained even under aggressive token budgets. Extensive experiments across diverse benchmarks show that VisionDrop achieves consistent improvements over existing methods, despite requiring no additional training or complex modifications. Its simple yet effective design enables efficient inference while preserving strong performance across tasks.",
      "authors": [
        "Rui Xu",
        "Yunke Wang",
        "Yong Luo",
        "Bo Du"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T14:55:40+00:00",
          "link": "https://arxiv.org/abs/2506.22283v1",
          "size": "1705kb",
          "version": "v1"
        }
      ],
      "title": "Rethinking Visual Token Reduction in LVLMs under Cross-modal Misalignment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22283",
        "HTML": "https://arxiv.org/html/2506.22283v1",
        "PDF": "https://arxiv.org/pdf/2506.22283"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "While this paper discusses token reduction in vision-language models, it does not address data collection or preprocessing for LLM training specifically. It focuses on token management within models rather than LLM data pipelines."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22291",
      "abstract": "Generating realistic 3D indoor scenes from user inputs remains a challenging problem in computer vision and graphics, requiring careful balance of geometric consistency, spatial relationships, and visual realism. While neural generation methods often produce repetitive elements due to limited global spatial reasoning, procedural approaches can leverage constraints for controllable generation but struggle with multi-constraint scenarios. When constraints become numerous, object collisions frequently occur, forcing the removal of furniture items and compromising layout completeness.\n  To address these limitations, we propose RoomCraft, a multi-stage pipeline that converts real images, sketches, or text descriptions into coherent 3D indoor scenes. Our approach combines a scene generation pipeline with a constraint-driven optimization framework. The pipeline first extracts high-level scene information from user inputs and organizes it into a structured format containing room type, furniture items, and spatial relations. It then constructs a spatial relationship network to represent furniture arrangements and generates an optimized placement sequence using a heuristic-based depth-first search (HDFS) algorithm to ensure layout coherence. To handle complex multi-constraint scenarios, we introduce a unified constraint representation that processes both formal specifications and natural language inputs, enabling flexible constraint-oriented adjustments through a comprehensive action space design. Additionally, we propose a Conflict-Aware Positioning Strategy (CAPS) that dynamically adjusts placement weights to minimize furniture collisions and ensure layout completeness.\n  Extensive experiments demonstrate that RoomCraft significantly outperforms existing methods in generating realistic, semantically coherent, and visually appealing room layouts across diverse input modalities.",
      "authors": [
        "Mengqi Zhou",
        "Xipeng Wang",
        "Yuxi Wang",
        "Zhaoxiang Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T15:03:17+00:00",
          "link": "https://arxiv.org/abs/2506.22291v1",
          "size": "13363kb",
          "version": "v1"
        }
      ],
      "title": "RoomCraft: Controllable and Complete 3D Indoor Scene Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22291",
        "HTML": "https://arxiv.org/html/2506.22291v1",
        "PDF": "https://arxiv.org/pdf/2506.22291"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper deals with 3D indoor scene generation, involving a pipeline for converting user inputs into 3D scenes, which is outside the scope of LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22292",
      "abstract": "In this paper, we extend the analysis of random Kronecker graphs to multi-dimensional networks represented as tensors, enabling a more detailed and nuanced understanding of complex network structures. We decompose the adjacency tensor of such networks into two components: a low-rank signal tensor that captures the essential network structure and a zero-mean noise tensor that accounts for random variations. Building on recent advancements in tensor decomposition and random tensor theory, we introduce a generalized denoise-and-solve framework that leverages the Einstein summation convention for efficient tensor operations. This approach significantly reduces computational complexity while demonstrating strong performance in network inference tasks, providing a scalable and efficient solution for analyzing large-scale, multi-dimensional networks.",
      "authors": [
        "Sanaa Khobizy"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T15:04:09+00:00",
          "link": "https://arxiv.org/abs/2506.22292v1",
          "size": "561kb",
          "version": "v1"
        }
      ],
      "title": "Scalable inference of large-scale random kronecker graphs via tensor decomposition and Einstein summation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22292",
        "HTML": "https://arxiv.org/html/2506.22292v1",
        "PDF": "https://arxiv.org/pdf/2506.22292"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper investigates the use of tensor decomposition in large-scale network analysis, which is unrelated to LLM training data collection, preparation, or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22293",
      "abstract": "Online social networks exert a powerful influence on public opinion. Adversaries weaponize these networks to manipulate discourse, underscoring the need for more resilient social networks. To this end, we investigate the impact of network connectivity on Stackelberg equilibria in a two-player game to shape public opinion. We model opinion evolution as a repeated competitive influence-propagation process. Players iteratively inject \\textit{messages} that diffuse until reaching a steady state, modeling the dispersion of two competing messages. Opinions then update according to the discounted sum of exposure to the messages. This bi-level model captures viral-media correlation effects omitted by standard opinion-dynamics models. To solve the resulting high-dimensional game, we propose a scalable, iterative algorithm based on linear-quadratic regulators that approximates local feedback Stackelberg strategies for players with limited cognition. We analyze how the network topology shapes equilibrium outcomes through experiments on synthetic networks and real Facebook data. Our results identify structural characteristics that improve a network's resilience to adversarial influence, guiding the design of more resilient social networks.",
      "authors": [
        "Yigit Ege Bayiz",
        "Arash Amini",
        "Radu Marculescu",
        "Ufuk Topcu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T15:04:51+00:00",
          "link": "https://arxiv.org/abs/2506.22293v1",
          "size": "8181kb",
          "version": "v1"
        }
      ],
      "title": "The Effect of Network Topology on the Equilibria of Influence-Opinion Games",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22293",
        "HTML": "https://arxiv.org/html/2506.22293v1",
        "PDF": "https://arxiv.org/pdf/2506.22293"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper discusses network topology's effect on public opinion games and its resilience, not focusing on any aspects related to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22295",
      "abstract": "Low-rank tensor decompositions (TDs) provide an effective framework for multiway data analysis. Traditional TD methods rely on predefined structural assumptions, such as CP or Tucker decompositions. From a probabilistic perspective, these can be viewed as using Dirac delta distributions to model the relationships between shared factors and the low-rank tensor. However, such prior knowledge is rarely available in practical scenarios, particularly regarding the optimal rank structure and contraction rules. The optimization procedures based on fixed contraction rules are complex, and approximations made during these processes often lead to accuracy loss. To address this issue, we propose a score-based model that eliminates the need for predefined structural or distributional assumptions, enabling the learning of compatibility between tensors and shared factors. Specifically, a neural network is designed to learn the energy function, which is optimized via score matching to capture the gradient of the joint log-probability of tensor entries and shared factors. Our method allows for modeling structures and distributions beyond the Dirac delta assumption. Moreover, integrating the block coordinate descent (BCD) algorithm with the proposed smooth regularization enables the model to perform both tensor completion and denoising. Experimental results demonstrate significant performance improvements across various tensor types, including sparse and continuous-time tensors, as well as visual data.",
      "authors": [
        "Zhengyun Cheng",
        "Changhao Wang",
        "Guanwen Zhang",
        "Yi Xu",
        "Wei Zhou",
        "Xiangyang Ji"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T15:05:37+00:00",
          "link": "https://arxiv.org/abs/2506.22295v1",
          "size": "25871kb",
          "version": "v1"
        }
      ],
      "title": "Score-Based Model for Low-Rank Tensor Recovery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22295",
        "HTML": "https://arxiv.org/html/2506.22295v1",
        "PDF": "https://arxiv.org/pdf/2506.22295"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on low-rank tensor recovery and neural network models without mentioning any aspects of LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22298",
      "abstract": "Video outpainting is a challenging task that generates new video content by extending beyond the boundaries of an original input video, requiring both temporal and spatial consistency. Many state-of-the-art methods utilize latent diffusion models with U-Net backbones but still struggle to achieve high quality and adaptability in generated content. Diffusion transformers (DiTs) have emerged as a promising alternative because of their superior performance. We introduce OutDreamer, a DiT-based video outpainting framework comprising two main components: an efficient video control branch and a conditional outpainting branch. The efficient video control branch effectively extracts masked video information, while the conditional outpainting branch generates missing content based on these extracted conditions. Additionally, we propose a mask-driven self-attention layer that dynamically integrates the given mask information, further enhancing the model's adaptability to outpainting tasks. Furthermore, we introduce a latent alignment loss to maintain overall consistency both within and between frames. For long video outpainting, we employ a cross-video-clip refiner to iteratively generate missing content, ensuring temporal consistency across video clips. Extensive evaluations demonstrate that our zero-shot OutDreamer outperforms state-of-the-art zero-shot methods on widely recognized benchmarks.",
      "authors": [
        "Linhao Zhong",
        "Fan Li",
        "Yi Huang",
        "Jianzhuang Liu",
        "Renjing Pei and Fenglong Song"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T15:08:54+00:00",
          "link": "https://arxiv.org/abs/2506.22298v1",
          "size": "1456kb",
          "version": "v1"
        }
      ],
      "title": "OutDreamer: Video Outpainting with a Diffusion Transformer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22298",
        "HTML": "https://arxiv.org/html/2506.22298v1",
        "PDF": "https://arxiv.org/pdf/2506.22298"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper discusses video outpainting using a diffusion transformer, which is unrelated to the processing of training data for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22299",
      "abstract": "Graph Neural Networks (GNNs) have garnered substantial attention due to their remarkable capability in learning graph representations. However, real-world graphs often exhibit substantial noise and incompleteness, which severely degrades the performance of GNNs. Existing methods typically address this issue through single-dimensional augmentation, focusing either on refining topology structures or perturbing node attributes, thereby overlooking the deeper interplays between the two. To bridge this gap, this paper presents CoATA, a dual-channel GNN framework specifically designed for the Co-Augmentation of Topology and Attribute. Specifically, CoATA first propagates structural signals to enrich and denoise node attributes. Then, it projects the enhanced attribute space into a node-attribute bipartite graph for further refinement or reconstruction of the underlying structure. Subsequently, CoATA introduces contrastive learning, leveraging prototype alignment and consistency constraints, to facilitate mutual corrections between the augmented and original graphs. Finally, extensive experiments on seven benchmark datasets demonstrate that the proposed CoATA outperforms eleven state-of-the-art baseline methods, showcasing its effectiveness in capturing the synergistic relationship between topology and attributes.",
      "authors": [
        "Tao Liu",
        "Longlong Lin",
        "Yunfeng Yu",
        "Xi Ou",
        "Youan Zhang",
        "Zhiqiu Ye",
        "Tao Jia"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T15:11:49+00:00",
          "link": "https://arxiv.org/abs/2506.22299v1",
          "size": "3678kb",
          "version": "v1"
        }
      ],
      "title": "CoATA: Effective Co-Augmentation of Topology and Attribute for Graph Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22299",
        "HTML": "https://arxiv.org/html/2506.22299v1",
        "PDF": "https://arxiv.org/pdf/2506.22299"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This work on graph neural networks does not address any processes related to the engineering or processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22301",
      "abstract": "Domain shift is a significant challenge in machine learning, particularly in medical applications where data distributions differ across institutions due to variations in data collection practices, equipment, and procedures. This can degrade performance when models trained on source domain data are applied to the target domain. Domain adaptation methods have been widely studied to address this issue, but most struggle when class proportions between the source and target domains differ. In this paper, we propose a weakly-supervised domain adaptation method that leverages class proportion information from the target domain, which is often accessible in medical datasets through prior knowledge or statistical reports. Our method assigns pseudo-labels to the unlabeled target data based on class proportion (called proportion-constrained pseudo-labeling), improving performance without the need for additional annotations. Experiments on two endoscopic datasets demonstrate that our method outperforms semi-supervised domain adaptation techniques, even when 5% of the target domain is labeled. Additionally, the experimental results with noisy proportion labels highlight the robustness of our method, further demonstrating its effectiveness in real-world application scenarios.",
      "authors": [
        "Takumi Okuo",
        "Shinnosuke Matsuo",
        "Shota Harada",
        "Kiyohito Tanaka",
        "Ryoma Bise"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T15:13:05+00:00",
          "link": "https://arxiv.org/abs/2506.22301v1",
          "size": "4296kb",
          "version": "v1"
        }
      ],
      "title": "Weakly-Supervised Domain Adaptation with Proportion-Constrained Pseudo-Labeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22301",
        "HTML": "https://arxiv.org/html/2506.22301v1",
        "PDF": "https://arxiv.org/pdf/2506.22301"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper is focused on domain adaptation for medical datasets, without contributions related to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22303",
      "abstract": "Learning path recommendation seeks to provide learners with a structured sequence of learning items (e.g., knowledge concepts or exercises) to optimize their learning efficiency. Despite significant efforts in this area, most existing methods primarily rely on prerequisite relationships, which present two major limitations: 1) Many educational datasets do not explicitly provide prerequisite relationships between knowledge concepts, hindering the application of current learning path recommendation methods. 2) Relying solely on prerequisite relationships as the sole knowledge structure can impede learning progress and negatively impact student outcomes. To address these challenges, we propose a novel approach, Discrimination Learning Enhances Learning Path Recommendation (DLELP), which enhances learning path recommendations by incorporating both prerequisite and similarity relationships between knowledge concepts. Specifically, we introduce a knowledge concept structure graph generation module that adaptively constructs knowledge concept structure graphs for different educational datasets, significantly improving the generalizability of learning path recommendation methods. We then propose a Discrimination Learning-driven Reinforcement Learning (DLRL) framework, which mitigates the issue of blocked learning paths, further enhancing the efficacy of learning path recommendations. Finally, we conduct extensive experiments on three benchmark datasets, demonstrating that our method not only achieves state-of-the-art performance but also provides interpretable reasoning for the recommended learning paths.",
      "authors": [
        "Xinghe Cheng",
        "Zihan Zhang",
        "Jiapu Wang",
        "Liangda Fang",
        "Chaobo He",
        "Quanlong Guan",
        "Shirui Pan",
        "Weiqi Luo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T15:15:42+00:00",
          "link": "https://arxiv.org/abs/2506.22303v1",
          "size": "4451kb",
          "version": "v1"
        }
      ],
      "title": "Education-Oriented Graph Retrieval-Augmented Generation for Learning Path Recommendation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22303",
        "HTML": "https://arxiv.org/html/2506.22303v1",
        "PDF": "https://arxiv.org/pdf/2506.22303"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The study proposes a method for learning path recommendation in education, lacking any direct relation to LLM training data processes."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22304",
      "abstract": "Conditional Flow Matching (CFM) offers a simulation-free framework for training continuous-time generative models, bridging diffusion and flow-based approaches. However, sampling from CFM still relies on numerically solving non-linear ODEs which can be computationally expensive and difficult to interpret. Recent alternatives address sampling speed via trajectory straightening, mini-batch coupling or distillation. However, these methods typically do not shed light on the underlying \\textit{structure} of the generative process. In this work, we propose to accelerate CFM and introduce an interpretable representation of its dynamics by integrating Koopman operator theory, which models non-linear flows as linear evolution in a learned space of observables. We introduce a decoder-free Koopman-CFM architecture that learns an embedding where the generative dynamics become linear, enabling closed-form, one-step sampling via matrix exponentiation. This results in significant speedups over traditional CFM as demonstrated on controlled 2D datasets and real-world benchmarks, MNIST, Fashion-MNIST (F-MNIST), and the Toronto Face Dataset (TFD). Unlike previous methods, our approach leads to a well-structured Koopman generator, whose spectral properties, eigenvalues, and eigenfunctions offer principled tools for analyzing generative behavior such as temporal scaling, mode stability, and decomposition in Koopman latent space. By combining sampling efficiency with analytical structure, Koopman-enhanced flow matching offers a potential step toward fast and interpretable generative modeling.",
      "authors": [
        "Erkan Turan",
        "Aristotelis Siozopoulos",
        "Maks Ovsjanikov"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T15:16:16+00:00",
          "link": "https://arxiv.org/abs/2506.22304v1",
          "size": "18034kb",
          "version": "v1"
        }
      ],
      "title": "Unfolding Generative Flows with Koopman Operators: Fast and Interpretable Sampling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22304",
        "HTML": "https://arxiv.org/html/2506.22304v1",
        "PDF": "https://arxiv.org/pdf/2506.22304"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper discusses a novel approach to accelerate Conditional Flow Matching using Koopman operators. It focuses on sampling efficiency and interpretability of generative models but does not touch on aspects related to LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22305",
      "abstract": "We propose a novel approach for detecting personal data in structured datasets, leveraging GPT-4o, a state-of-the-art Large Language Model. A key innovation of our method is the incorporation of contextual information: in addition to a feature's name and values, we utilize information from other feature names within the dataset as well as the dataset description. We compare our approach to alternative methods, including Microsoft Presidio and CASSED, evaluating them on multiple datasets: DeSSI, a large synthetic dataset, datasets we collected from Kaggle and OpenML as well as MIMIC-Demo-Ext, a real-world dataset containing patient information from critical care units.\n  Our findings reveal that detection performance varies significantly depending on the dataset used for evaluation. CASSED excels on DeSSI, the dataset on which it was trained. Performance on the medical dataset MIMIC-Demo-Ext is comparable across all models, with our GPT-4o-based approach clearly outperforming the others. Notably, personal data detection in the Kaggle and OpenML datasets appears to benefit from contextual information. This is evidenced by the poor performance of CASSED and Presidio (both of which do not utilize the context of the dataset) compared to the strong results of our GPT-4o-based approach.\n  We conclude that further progress in this field would greatly benefit from the availability of more real-world datasets containing personal information.",
      "authors": [
        "Albert Agisha Ntwali",
        "Luca R\\\"uck",
        "Martin Heckmann"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T15:16:43+00:00",
          "link": "https://arxiv.org/abs/2506.22305v1",
          "size": "479kb",
          "version": "v1"
        }
      ],
      "title": "Detection of Personal Data in Structured Datasets Using a Large Language Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22305",
        "HTML": "https://arxiv.org/html/2506.22305v1",
        "PDF": "https://arxiv.org/pdf/2506.22305"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "While the paper leverages a large language model to detect personal data in datasets, its focus is on privacy and data detection rather than on the processing or enhancement of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22309",
      "abstract": "The vast growth of data has rendered traditional manual inspection infeasible, necessitating the adoption of computational methods for efficient data exploration. Topic modeling has emerged as a powerful tool for analyzing large-scale textual datasets, enabling the extraction of latent semantic structures. However, existing methods for topic modeling often struggle to provide interpretable representations that facilitate deeper insights into data structure and content. In this paper, we propose FAT-CAT, an approach based on Formal Concept Analysis (FCA) to enhance meaningful topic aggregation and visualization of discovered topics. Our approach can handle diverse topics and file types -- grouped by directories -- to construct a concept lattice that offers a structured, hierarchical representation of their topic distribution. In a case study on the ETYNTKE dataset, we evaluate the effectiveness of our approach against other representation methods to demonstrate that FCA-based aggregation provides more meaningful and interpretable insights into dataset composition than existing topic modeling techniques.",
      "authors": [
        "Klara M. Gutekunst",
        "Dominik D\\\"urrschnabel",
        "Johannes Hirth",
        "Gerd Stumme"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Discrete Mathematics (cs.DM)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T15:19:38+00:00",
          "link": "https://arxiv.org/abs/2506.22309v1",
          "size": "4453kb",
          "version": "v1"
        }
      ],
      "title": "Conceptual Topic Aggregation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22309",
        "HTML": "https://arxiv.org/html/2506.22309v1",
        "PDF": "https://arxiv.org/pdf/2506.22309"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper introduces FAT-CAT, a method for enhancing topic modeling, but it is focused on data exploration rather than LLM training data processing or transformation."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22311",
      "abstract": "Pressure sensors are an integrated component of modern Heating, Ventilation, and Air Conditioning (HVAC) systems. As these pressure sensors operate within the 0-10 Pa range, support high sampling frequencies of 0.5-2 kHz, and are often placed close to human proximity, they can be used to eavesdrop on confidential conversation, since human speech has a similar audible range of 0-10 Pa and a bandwidth of 4 kHz for intelligible quality. This paper presents WaLi, which reconstructs intelligible speech from the low-resolution and noisy pressure sensor data by providing the following technical contributions: (i) WaLi reconstructs intelligible speech from a minimum of 0.5 kHz sampling frequency of pressure sensors, whereas previous work can only detect hot words/phrases. WaLi uses complex-valued conformer and Complex Global Attention Block (CGAB) to capture inter-phoneme and intra-phoneme dependencies that exist in the low-resolution pressure sensor data. (ii) WaLi handles the transient noise injected from HVAC fans and duct vibrations, by reconstructing both the clean magnitude and phase of the missing frequencies of the low-frequency aliased components. Extensive measurement studies on real-world pressure sensors show an LSD of 1.24 and NISQA-MOS of 1.78 for 0.5 kHz to 8 kHz upsampling. We believe that such levels of accuracy pose a significant threat when viewed from a privacy perspective that has not been addressed before for pressure sensors.",
      "authors": [
        "Tarikul Islam Tamiti",
        "Biraj Joshi",
        "Rida Hasan",
        "Anomadarshi Barua"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Cryptography and Security (cs.CR)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T15:20:25+00:00",
          "link": "https://arxiv.org/abs/2506.22311v1",
          "size": "1493kb",
          "version": "v1"
        }
      ],
      "title": "Reconstructing Intelligible Speech from the Pressure Sensor Data in HVACs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22311",
        "HTML": "https://arxiv.org/html/2506.22311v1",
        "PDF": "https://arxiv.org/pdf/2506.22311"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The work centers on reconstructing speech from HVAC sensor data, which is not related to LLM training data processing. It focuses on speech processing rather than LLM training datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22312",
      "abstract": "Alternative finite difference Weighted Essentially Non-Oscillatory (AFD-WENO) schemes allow us to very efficiently update hyperbolic systems even in complex geometries. Recent innovations in AFD-WENO methods allow us to treat hyperbolic system with non-conservative products almost as efficiently as conservation laws. However, some PDE systems,like computational electrodynamics (CED) and magnetohydrodynamics (MHD) and relativistic magnetohydrodynamics (RMHD), have involution constraints that require divergence-free or divergence-preserving evolution of vector fields. In such situations, a Yee-style collocation of variables proves indispensable; and that collocation is retained in this work. In previous works, only higher order finite volume discretization of such involution constrained systems was possible. In this work, we show that substantially more efficient AFD-WENO methods have been extended to encompass divergence-preserving hyperbolic PDEs.\n  Our method retains the Yee-style collocation of normal components of...",
      "authors": [
        "Dinshaw S. Balsara",
        "Deepak Bhoriya and Chi-Wang Shu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Computational Physics (physics.comp-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T15:22:02+00:00",
          "link": "https://arxiv.org/abs/2506.22312v1",
          "size": "7180kb",
          "version": "v1"
        }
      ],
      "title": "An Alternative Finite Difference WENO-like Scheme with Physical Constraint Preservation for Divergence-Preserving Hyperbolic Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22312",
        "PDF": "https://arxiv.org/pdf/2506.22312"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper deals with an alternative numerical scheme for hyperbolic systems in computational domains but does not relate to LLM training data collection or data engineering for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22316",
      "abstract": "The remarkable performance of Large Language Models (LLMs) gives rise to``LLM-as-a-Judge'', where LLMs are employed as evaluators for complex tasks. Moreover, it has been widely adopted across fields such as Natural Language Processing (NLP), preference learning, and various specific domains. However, there are various biases within LLM-as-a-Judge, which adversely affect the fairness and reliability of judgments. Current research on evaluating or mitigating bias in LLM-as-a-Judge predominantly focuses on comparison-based evaluations, while systematic investigations into bias in scoring-based evaluations remain limited. Therefore, we define scoring bias in LLM-as-a-Judge as the scores differ when scoring judge models are bias-related perturbed, and provide a well-designed framework to comprehensively evaluate scoring bias. We augment existing LLM-as-a-Judge benchmarks through data synthesis to construct our evaluation dataset and design multi-faceted evaluation metrics. Our experimental results demonstrate that the scoring stability of existing judge models is disrupted by scoring biases. Further exploratory experiments and discussions provide valuable insights into the design of scoring prompt templates and the mitigation of scoring biases on aspects such as score rubrics, score IDs, and reference answer selection.",
      "authors": [
        "Qingquan Li and Shaoyu Dou and Kailai Shao and Chao Chen and Haixiang Hu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T15:25:23+00:00",
          "link": "https://arxiv.org/abs/2506.22316v1",
          "size": "337kb",
          "version": "v1"
        }
      ],
      "title": "Evaluating Scoring Bias in LLM-as-a-Judge",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22316",
        "HTML": "https://arxiv.org/html/2506.22316v1",
        "PDF": "https://arxiv.org/pdf/2506.22316"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper mentions augmenting existing benchmarks through data synthesis for evaluating scoring bias in LLM-as-a-Judge, which involves some data processing tasks. However, it primarily focuses on evaluating biases and not on designing or constructing new LLM training data pipelines."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22321",
      "abstract": "Hearables are wearable computers that are worn on the ear. Bone conduction microphones (BCMs) are used with air conduction microphones (ACMs) in hearables as a supporting modality for multimodal speech enhancement (SE) in noisy conditions. However, existing works don't consider the following practical aspects for low-power implementations on hearables: (i) They do not explore how lowering the sampling frequencies and bit resolutions in analog-to-digital converters (ADCs) of hearables jointly impact low-power processing and multimodal SE in terms of speech quality and intelligibility. (ii) They don't discuss how GAN-like audio quality can be achieved without using actual GAN discriminators. And (iii) They don't process signals from ACMs/BCMs at sub-Nyquist sampling rate because, in their frameworks, they lack a wideband reconstruction methodology from their narrowband parts. We propose SUBARU (\\textbf{Sub}-Nyquist \\textbf{A}udio \\textbf{R}esolution \\textbf{U}psampling), which achieves the following: SUBARU (i) intentionally uses sub-Nyquist sampling and low bit resolution in ADCs, achieving a 3.31x reduction in power consumption; (ii) introduces novel multi-scale and multi-period virtual discriminators, which achieve GAN-like audio quality without using GANs' adversarial training; and (iii) achieves streaming operations on mobile platforms and SE in in-the-wild noisy conditions with an inference time of 1.74ms and a memory footprint of less than 13.77MB.",
      "authors": [
        "Tarikul Islam Tamiti and Anomadarshi Barua"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T15:35:04+00:00",
          "link": "https://arxiv.org/abs/2506.22321v1",
          "size": "2923kb",
          "version": "v1"
        }
      ],
      "title": "A Practical Approach to Power Saving in Hearables Using Sub-Nyquist Sampling with Bandwidth Extension",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22321",
        "HTML": "https://arxiv.org/html/2506.22321v1",
        "PDF": "https://arxiv.org/pdf/2506.22321"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "While this paper proposes a low-power sampling approach for hearables, it focuses on audio signal processing and bandwidth extension, with no relevance to the processing or engineering of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22323",
      "abstract": "A sophisticated malspam campaign was recently uncovered targeting Latin American countries, with a particular focus on Brazil. This operation utilizes a highly deceptive phishing email to trick users into executing a malicious MSI file, initiating a multi-stage infection. The core of the attack leverages DLL side-loading, where a legitimate executable from Valve Corporation is used to load a trojanized DLL, thereby bypassing standard security defenses.\n  Once active, the malware, a variant of QuasarRAT known as BlotchyQuasar, is capable of a wide range of malicious activities. It is designed to steal sensitive browser-stored credentials and banking information, the latter through fake login windows mimicking well-known Brazilian banks. The threat establishes persistence by modifying the Windows registry , captures user keystrokes through keylogging , and exfiltrates stolen data to a Command-and-Control (C2) server using encrypted payloads. Despite its advanced capabilities, the malware code exhibits signs of rushed development, with inefficiencies and poor error handling that suggest the threat actors prioritized rapid deployment over meticulous design. Nonetheless, the campaign extensive reach and sophisticated mechanisms pose a serious and immediate threat to the targeted regions, underscoring the need for robust cybersecurity defenses.",
      "authors": [
        "Alessio Di Santo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Computers and Society (cs.CY)",
        "Networking and Internet Architecture (cs.NI)",
        "Operating Systems (cs.OS)",
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T15:36:10+00:00",
          "link": "https://arxiv.org/abs/2506.22323v1",
          "size": "11848kb",
          "version": "v1"
        }
      ],
      "title": "Under the Hood of BlotchyQuasar: DLL-Based RAT Campaigns Against Latin America",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22323",
        "HTML": "https://arxiv.org/html/2506.22323v1",
        "PDF": "https://arxiv.org/pdf/2506.22323"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper describes a malware campaign using DLL-based techniques, which is related to cybersecurity and malware analysis, and does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22331",
      "abstract": "Greedy Equivalence Search (GES) is a classic score-based algorithm for causal discovery from observational data. In the sample limit, it recovers the Markov equivalence class of graphs that describe the data. Still, it faces two challenges in practice: computational cost and finite-sample accuracy. In this paper, we develop Less Greedy Equivalence Search (LGES), a variant of GES that retains its theoretical guarantees while partially addressing these limitations. LGES modifies the greedy step: rather than always applying the highest-scoring insertion, it avoids edge insertions between variables for which the score implies some conditional independence. This more targeted search yields up to a \\(10\\)-fold speed-up and a substantial reduction in structural error relative to GES. Moreover, LGES can guide the search using prior assumptions, while correcting these assumptions when contradicted by the data. Finally, LGES can exploit interventional data to refine the learned observational equivalence class. We prove that LGES recovers the true equivalence class in the sample limit from observational and interventional data, even with misspecified prior assumptions. Experiments demonstrate that LGES outperforms GES and other baselines in speed, accuracy, and robustness to misspecified assumptions. Our code is available at https://github.com/CausalAILab/lges.",
      "authors": [
        "Adiba Ejaz and Elias Bareinboim"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Methodology (stat.ME)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T15:39:48+00:00",
          "link": "https://arxiv.org/abs/2506.22331v1",
          "size": "10996kb",
          "version": "v1"
        }
      ],
      "title": "Less Greedy Equivalence Search",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22331",
        "HTML": "https://arxiv.org/html/2506.22331v1",
        "PDF": "https://arxiv.org/pdf/2506.22331"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on Greedy Equivalence Search for causal discovery, dealing with algorithms for structure learning from observational data. It does not discuss LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22336",
      "abstract": "State-of-the-art methods fail to solve visual localization in scenarios where different devices use different sparse feature extraction algorithms to obtain keypoints and their corresponding descriptors. Translating feature descriptors is enough to enable matching. However, performance is drastically reduced in cross-feature detector cases, because current solutions assume common keypoints. This means that the same detector has to be used, which is rarely the case in practice when different descriptors are used. The low repeatability of keypoints, in addition to non-discriminatory and non-distinctive descriptors, make the identification of true correspondences extremely challenging. We present the first method tackling this problem, which performs feature descriptor augmentation targeting cross-detector feature matching, and then feature translation to a latent space. We show that our method significantly improves image matching and visual localization in the cross-feature scenario and evaluate the proposed method on several benchmarks.",
      "authors": [
        "Paula Carb\\'o Cubero",
        "Alberto Jaenal G\\'alvez",
        "Andr\\'e Mateus",
        "Jos\\'e Ara\\'ujo",
        "Patric Jensfelt"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T15:43:51+00:00",
          "link": "https://arxiv.org/abs/2506.22336v1",
          "size": "12018kb",
          "version": "v1"
        }
      ],
      "title": "MatChA: Cross-Algorithm Matching with Feature Augmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22336",
        "HTML": "https://arxiv.org/html/2506.22336v1",
        "PDF": "https://arxiv.org/pdf/2506.22336"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper proposes a method for feature descriptor augmentation for visual localization tasks. It addresses challenges in feature matching between different extraction algorithms, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22338",
      "abstract": "Building damage identification shortly after a disaster is crucial for guiding emergency response and recovery efforts. Although optical satellite imagery is commonly used for disaster mapping, its effectiveness is often hampered by cloud cover or the absence of pre-event acquisitions. To overcome these challenges, we introduce a novel multimodal deep learning (DL) framework for detecting building damage using single-date very high resolution (VHR) Synthetic Aperture Radar (SAR) imagery from the Italian Space Agency (ASI) COSMO SkyMed (CSK) constellation, complemented by auxiliary geospatial data. Our method integrates SAR image patches, OpenStreetMap (OSM) building footprints, digital surface model (DSM) data, and structural and exposure attributes from the Global Earthquake Model (GEM) to improve detection accuracy and contextual interpretation. Unlike existing approaches that depend on pre and post event imagery, our model utilizes only post event data, facilitating rapid deployment in critical scenarios. The framework effectiveness is demonstrated using a new dataset from the 2023 earthquake in Turkey, covering multiple cities with diverse urban settings. Results highlight that incorporating geospatial features significantly enhances detection performance and generalizability to previously unseen areas. By combining SAR imagery with detailed vulnerability and exposure information, our approach provides reliable and rapid building damage assessments without the dependency from available pre-event data. Moreover, the automated and scalable data generation process ensures the framework's applicability across diverse disaster-affected regions, underscoring its potential to support effective disaster management and recovery efforts. Code and data will be made available upon acceptance of the paper.",
      "authors": [
        "Luigi Russo",
        "Deodato Tapete",
        "Silvia Liberata Ullo",
        "and Paolo Gamba"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T15:49:58+00:00",
          "link": "https://arxiv.org/abs/2506.22338v1",
          "size": "4355kb",
          "version": "v1"
        }
      ],
      "title": "A Deep Learning framework for building damage assessment using VHR SAR and geospatial data: demonstration on the 2023 Turkiye Earthquake",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22338",
        "HTML": "https://arxiv.org/html/2506.22338v1",
        "PDF": "https://arxiv.org/pdf/2506.22338"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper presents a deep learning framework for building damage assessment using SAR and geospatial data, focusing on disaster response. It is not related to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22342",
      "abstract": "It is now well understood that diverse datasets provide a lot of value in key epidemiology and public health analyses, such as forecasting and nowcasting, development of epidemic models, evaluation and design of interventions and resource allocation. Some of these datasets are often sensitive, and need adequate privacy protections. There are many models of privacy, but Differential Privacy (DP) has become a de facto standard because of its strong guarantees, without making models about adversaries. In this paper, we develop a framework the integrates deep learning and epidemic models to simultaneously perform epidemic forecasting and learning a mechanistic model of epidemic spread, while incorporating multiple datasets for these analyses, including some with DP guarantees. We demonstrate our framework using a realistic but synthetic financial dataset with DP; such a dataset has not been used in such epidemic analyses. We show that this dataset provides significant value in forecasting and learning an epidemic model, even when used with DP guarantees.",
      "authors": [
        "Zihan Guan",
        "Zhiyuan Zhao",
        "Fengwei Tian",
        "Dung Nguyen",
        "Payel Bhattacharjee",
        "Ravi Tandon",
        "B. Aditya Prakash",
        "Anil Vullikanti"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T15:52:12+00:00",
          "link": "https://arxiv.org/abs/2506.22342v1",
          "size": "8486kb",
          "version": "v1"
        }
      ],
      "title": "A Framework for Multi-source Privacy Preserving Epidemic Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22342",
        "PDF": "https://arxiv.org/pdf/2506.22342"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper discusses epidemic analysis using diverse datasets with privacy preservation. It focuses on integrating deep learning with epidemic models, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22344",
      "abstract": "Elementary Object Systems (EOSs) are a model in the nets-within-nets (NWNs) paradigm, where tokens in turn can host standard Petri nets. We study the complexity of the reachability problem of EOSs when subjected to non-deterministic token losses. It is known that this problem is equivalent to the coverability problem with no lossiness of conservative EOSs (cEOSs). We precisely characterize cEOS coverability into the framework of data nets, whose tokens carry data from an infinite domain. Specifically, we show that cEOS coverability is equivalent to the coverability of an interesting fragment of data nets that extends beyond $\\nu$PNs (featuring globally fresh name creation), yet remains less expressive than Unordered Data Nets (featuring lossy name creation as well as powerful forms of whole-place operations and broadcasts). This insight bridges two apparently orthogonal approaches to PN extensions, namely data nets and NWNs. At the same time, it enables us to analyze cEOS coverability taking advantage of known results on data nets. As a byproduct, we immediately get that the complexity of cEOS coverability lies between $\\mathbf{F}_{\\omega 2}$ and $\\mathbf{F}_{\\omega^\\omega}$, two classes beyond Primitive Recursive.",
      "authors": [
        "Francesco Di Cosmo",
        "Soumodev Mal",
        "Tephilla Prince"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Complexity (cs.CC)",
        "Formal Languages and Automata Theory (cs.FL)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T15:53:17+00:00",
          "link": "https://arxiv.org/abs/2506.22344v1",
          "size": "60kb",
          "version": "v1"
        }
      ],
      "title": "Nets-within-Nets through the Lens of Data Nets",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22344",
        "PDF": "https://arxiv.org/pdf/2506.22344"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper studies complexity in Elementary Object Systems and Data Nets, unrelated to LLM training data or processing stages for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22347",
      "abstract": "This paper analyses and addresses the performance gap in the fuzzy vault-based \\ac{BCS}. We identify unstable error correction capabilities, which are caused by variable feature set sizes and their influence on similarity thresholds, as a key source of performance degradation. This issue is further compounded by information loss introduced through feature type transformations. To address both problems, we propose a novel feature quantization method based on \\it{equal frequent intervals}. This method guarantees fixed feature set sizes and supports training-free adaptation to any number of intervals. The proposed approach significantly reduces the performance gap introduced by template protection. Additionally, it integrates seamlessly with existing systems to minimize the negative effects of feature transformation. Experiments on state-of-the-art face, fingerprint, and iris recognition systems confirm that only minimal performance degradation remains, demonstrating the effectiveness of the method across major biometric modalities.",
      "authors": [
        "Hans Gei{\\ss}ner",
        "Christian Rathgeb"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T15:57:58+00:00",
          "link": "https://arxiv.org/abs/2506.22347v1",
          "size": "2912kb",
          "version": "v1"
        }
      ],
      "title": "Closing the Performance Gap in Biometric Cryptosystems: A Deeper Analysis on Unlinkable Fuzzy Vaults",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22347",
        "HTML": "https://arxiv.org/html/2506.22347v1",
        "PDF": "https://arxiv.org/pdf/2506.22347"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper aims to optimize performance in biometric cryptosystems using feature quantization. It does not deal with LLMs or their training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22355",
      "abstract": "This paper describes our research on AI agents embodied in visual, virtual or physical forms, enabling them to interact with both users and their environments. These agents, which include virtual avatars, wearable devices, and robots, are designed to perceive, learn and act within their surroundings, which makes them more similar to how humans learn and interact with the environments as compared to disembodied agents. We propose that the development of world models is central to reasoning and planning of embodied AI agents, allowing these agents to understand and predict their environment, to understand user intentions and social contexts, thereby enhancing their ability to perform complex tasks autonomously. World modeling encompasses the integration of multimodal perception, planning through reasoning for action and control, and memory to create a comprehensive understanding of the physical world. Beyond the physical world, we also propose to learn the mental world model of users to enable better human-agent collaboration.",
      "authors": [
        "Pascale Fung",
        "Yoram Bachrach",
        "Asli Celikyilmaz",
        "Kamalika Chaudhuri",
        "Delong Chen",
        "Willy Chung",
        "Emmanuel Dupoux",
        "Herv\\'e J\\'egou",
        "Alessandro Lazaric",
        "Arjun Majumdar",
        "Andrea Madotto",
        "Franziska Meier",
        "Florian Metze",
        "Th\\'eo Moutakanni",
        "Juan Pino",
        "Basile Terver",
        "Joseph Tighe",
        "Jitendra Malik"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T16:05:34+00:00",
          "link": "https://arxiv.org/abs/2506.22355v1",
          "size": "13238kb",
          "version": "v1"
        }
      ],
      "title": "Embodied AI Agents: Modeling the World",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22355",
        "HTML": "https://arxiv.org/html/2506.22355v1",
        "PDF": "https://arxiv.org/pdf/2506.22355"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The focus is on embodied AI agents and world modeling, with no mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22356",
      "abstract": "The HLTCOE LiveRAG submission utilized the GPT-researcher framework for researching the context of the question, filtering the returned results, and generating the final answer. The retrieval system was a ColBERT bi-encoder architecture, which represents a passage with many dense tokens. Retrieval used a local, compressed index of the FineWeb10-BT collection created with PLAID-X, using a model fine-tuned for multilingual retrieval. Query generation from context was done with Qwen2.5-7B-Instruct, while filtering was accomplished with m2-bert-80M-8k-retrieval. Up to nine passages were used as context to generate an answer using Falcon3-10B. This system placed 5th in the LiveRAG automatic evaluation for correctness with a score of 1.07.",
      "authors": [
        "Kevin Duh and Eugene Yang and Orion Weller and Andrew Yates and Dawn Lawrie"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T16:08:39+00:00",
          "link": "https://arxiv.org/abs/2506.22356v1",
          "size": "169kb",
          "version": "v1"
        }
      ],
      "title": "HLTCOE at LiveRAG: GPT-Researcher using ColBERT retrieval",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22356",
        "HTML": "https://arxiv.org/html/2506.22356v1",
        "PDF": "https://arxiv.org/pdf/2506.22356"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper discusses the use of a retrieval system in the context of a question-answering framework and does not address any aspect of LLM training data collection, processing, or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22358",
      "abstract": "The increasing integration of Artificial Intelligence (AI) into health and biomedical systems necessitates robust frameworks for transparency, accountability, and ethical compliance. Existing frameworks often rely on human-readable, manual documentation which limits scalability, comparability, and machine interpretability across projects and platforms. They also fail to provide a unique, verifiable identity for AI models to ensure their provenance and authenticity across systems and use cases, limiting reproducibility and stakeholder trust. This paper introduces the concept of the AI Model Passport, a structured and standardized documentation framework that acts as a digital identity and verification tool for AI models. It captures essential metadata to uniquely identify, verify, trace and monitor AI models across their lifecycle - from data acquisition and preprocessing to model design, development and deployment. In addition, an implementation of this framework is presented through AIPassport, an MLOps tool developed within the ProCAncer-I EU project for medical imaging applications. AIPassport automates metadata collection, ensures proper versioning, decouples results from source scripts, and integrates with various development environments. Its effectiveness is showcased through a lesion segmentation use case using data from the ProCAncer-I dataset, illustrating how the AI Model Passport enhances transparency, reproducibility, and regulatory readiness while reducing manual effort. This approach aims to set a new standard for fostering trust and accountability in AI-driven healthcare solutions, aspiring to serve as the basis for developing transparent and regulation compliant AI systems across domains.",
      "authors": [
        "Varvara Kalokyri",
        "Nikolaos S. Tachos",
        "Charalampos N. Kalantzopoulos",
        "Stelios Sfakianakis",
        "Haridimos Kondylakis",
        "Dimitrios I. Zaridis",
        "Sara Colantonio",
        "Daniele Regge",
        "Nikolaos Papanikolaou",
        "The ProCAncer-I consortium",
        "Konstantinos Marias",
        "Dimitrios I. Fotiadis",
        "Manolis Tsiknakis"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T16:16:15+00:00",
          "link": "https://arxiv.org/abs/2506.22358v1",
          "size": "4781kb",
          "version": "v1"
        }
      ],
      "title": "AI Model Passport: Data and System Traceability Framework for Transparent AI in Health",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22358",
        "HTML": "https://arxiv.org/html/2506.22358v1",
        "PDF": "https://arxiv.org/pdf/2506.22358"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces the AI Model Passport framework, which includes data acquisition and preprocessing, but its focus is on AI model traceability and transparency in health applications rather than on LLM-specific data processing methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22359",
      "abstract": "The telecommunications and networking domain stands at the precipice of a transformative era, driven by the necessity to manage increasingly complex, hierarchical, multi administrative domains (i.e., several operators on the same path) and multilingual systems. Recent research has demonstrated that Large Language Models (LLMs), with their exceptional general-purpose text analysis and code generation capabilities, can be effectively applied to certain telecom problems (e.g., auto-configuration of data plan to meet certain application requirements). However, due to their inherent token-by-token processing and limited capacity for maintaining extended context, LLMs struggle to fulfill telecom-specific requirements such as cross-layer dependency cascades (i.e., over OSI), temporal-spatial fault correlation, and real-time distributed coordination. In contrast, Large Concept Models (LCMs), which reason at the abstraction level of semantic concepts rather than individual lexical tokens, offer a fundamentally superior approach for addressing these telecom challenges. By employing hyperbolic latent spaces for hierarchical representation and encapsulating complex multi-layered network interactions within concise concept embeddings, LCMs overcome critical shortcomings of LLMs in terms of memory efficiency, cross-layer correlation, and native multimodal integration. This paper argues that adopting LCMs is not simply an incremental step, but a necessary evolutionary leap toward achieving robust and effective AI-driven telecom management.",
      "authors": [
        "Viswanath Kumarskandpriya",
        "Abdulhalim Dandoush",
        "Abbas Bradai",
        "Ali Belgacem"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T16:20:18+00:00",
          "link": "https://arxiv.org/abs/2506.22359v1",
          "size": "968kb",
          "version": "v1"
        }
      ],
      "title": "Concept-Level AI for Telecom: Moving Beyond Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22359",
        "HTML": "https://arxiv.org/html/2506.22359v1",
        "PDF": "https://arxiv.org/pdf/2506.22359"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on the application of LLMs and concept-level AI in telecommunications, highlighting limitations of LLMs and the use of Large Concept Models, without discussing data processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22360",
      "abstract": "This study investigates the performance of the two most relevant computer vision deep learning architectures, Convolutional Neural Network and Vision Transformer, for event-based cameras. These cameras capture scene changes, unlike traditional frame-based cameras with capture static images, and are particularly suited for dynamic environments such as UAVs and autonomous vehicles. The deep learning models studied in this work are ResNet34 and ViT B16, fine-tuned on the GEN1 event-based dataset. The research evaluates and compares these models under both standard conditions and in the presence of simulated noise. Initial evaluations on the clean GEN1 dataset reveal that ResNet34 and ViT B16 achieve accuracies of 88% and 86%, respectively, with ResNet34 showing a slight advantage in classification accuracy. However, the ViT B16 model demonstrates notable robustness, particularly given its pre-training on a smaller dataset. Although this study focuses on ground-based vehicle classification, the methodologies and findings hold significant promise for adaptation to UAV contexts, including aerial object classification and event-based vision systems for aviation-related tasks.",
      "authors": [
        "Nouf Almesafri",
        "Hector Figueiredo",
        "Miguel Arana-Catania"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T16:21:00+00:00",
          "link": "https://arxiv.org/abs/2506.22360v1",
          "size": "8463kb",
          "version": "v1"
        }
      ],
      "title": "From Ground to Air: Noise Robustness in Vision Transformers and CNNs for Event-Based Vehicle Classification with Potential UAV Applications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22360",
        "HTML": "https://arxiv.org/html/2506.22360v1",
        "PDF": "https://arxiv.org/pdf/2506.22360"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The study focuses on noise robustness in computer vision models for event-based cameras and does not address LLM training data processing or related methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22364",
      "abstract": "Accurate weed management is essential for mitigating significant crop yield losses, necessitating effective weed suppression strategies in agricultural systems. Integrating cover crops (CC) offers multiple benefits, including soil erosion reduction, weed suppression, decreased nitrogen requirements, and enhanced carbon sequestration, all of which are closely tied to the aboveground biomass (AGB) they produce. However, biomass production varies significantly due to microsite variability, making accurate estimation and mapping essential for identifying zones of poor weed suppression and optimizing targeted management strategies. To address this challenge, developing a comprehensive CC map, including its AGB distribution, will enable informed decision-making regarding weed control methods and optimal application rates. Manual visual inspection is impractical and labor-intensive, especially given the extensive field size and the wide diversity and variation of weed species and sizes. In this context, optical imagery and Light Detection and Ranging (LiDAR) data are two prominent sources with unique characteristics that enhance AGB estimation. This study introduces a ground robot-mounted multimodal sensor system designed for agricultural field mapping. The system integrates optical and LiDAR data, leveraging machine learning (ML) methods for data fusion to improve biomass predictions. The best ML-based model for dry AGB estimation achieved a coefficient of determination value of 0.88, demonstrating robust performance in diverse field conditions. This approach offers valuable insights for site-specific management, enabling precise weed suppression strategies and promoting sustainable farming practices.",
      "authors": [
        "Joe Johnson",
        "Phanender Chalasani",
        "Arnav Shah",
        "Ram L. Ray",
        "and Muthukumar Bagavathiannan"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T16:26:02+00:00",
          "link": "https://arxiv.org/abs/2506.22364v1",
          "size": "1671kb",
          "version": "v1"
        }
      ],
      "title": "Robotic Multimodal Data Acquisition for In-Field Deep Learning Estimation of Cover Crop Biomass",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22364",
        "HTML": "https://arxiv.org/html/2506.22364v1",
        "PDF": "https://arxiv.org/pdf/2506.22364"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper's focus is on the application of machine learning for agricultural data analysis using optical imagery and LiDAR data, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22365",
      "abstract": "When using reinforcement learning (RL) to tackle physical control tasks, inductive biases that encode physics priors can help improve sample efficiency during training and enhance generalization in testing. However, the current practice of incorporating these helpful physics-informed inductive biases inevitably runs into significant manual labor and domain expertise, making them prohibitive for general users. This work explores a symbolic approach to distill physics-informed inductive biases into RL agents, where the physics priors are expressed in a domain-specific language (DSL) that is human-readable and naturally explainable. Yet, the DSL priors do not translate directly into an implementable policy due to partial and noisy observations and additional physical constraints in navigation tasks. To address this gap, we develop a physics-informed program-guided RL (PiPRL) framework with applications to indoor navigation. PiPRL adopts a hierarchical and modularized neuro-symbolic integration, where a meta symbolic program receives semantically meaningful features from a neural perception module, which form the bases for symbolic programming that encodes physics priors and guides the RL process of a low-level neural controller. Extensive experiments demonstrate that PiPRL consistently outperforms purely symbolic or neural policies and reduces training time by over 26% with the help of the program-based inductive biases.",
      "authors": [
        "Tao Li",
        "Haozhe Lei",
        "Mingsheng Yin",
        "Yaqi Hu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T16:26:29+00:00",
          "link": "https://arxiv.org/abs/2506.22365v1",
          "size": "327kb",
          "version": "v1"
        }
      ],
      "title": "Reinforcement Learning with Physics-Informed Symbolic Program Priors for Zero-Shot Wireless Indoor Navigation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22365",
        "HTML": "https://arxiv.org/html/2506.22365v1",
        "PDF": "https://arxiv.org/pdf/2506.22365"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper discusses reinforcement learning and the use of physics-informed symbolic program priors for navigation tasks, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22366",
      "abstract": "If humans understood language by randomly selecting parsing actions, it might have been necessary to construct a robust symbolic system capable of being interpreted under any hierarchical structure. However, human parsing strategies do not seem to follow such a random pattern. Why is that the case? In fact, a previous study on emergent communication using models with hierarchical biases have reported that agents adopting random parsing strategies$\\unicode{x2013}$ones that deviate significantly from human language comprehension$\\unicode{x2013}$can achieve high communication accuracy. In this study, we investigate this issue by making two simple and natural modifications to the experimental setup: (I) we use more complex inputs that have hierarchical structures, such that random parsing makes semantic interpretation more difficult, and (II) we incorporate a surprisal-related term, which is known to influence the order of words and characters in natural language, into the objective function. With these changes, we evaluate whether agents employing random parsing strategies still maintain high communication accuracy.",
      "authors": [
        "Daichi Kato",
        "Ryo Ueda",
        "Yusuke Miyao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T16:27:35+00:00",
          "link": "https://arxiv.org/abs/2506.22366v1",
          "size": "323kb",
          "version": "v1"
        }
      ],
      "title": "Why Are Parsing Actions for Understanding Message Hierarchies Not Random?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22366",
        "HTML": "https://arxiv.org/html/2506.22366v1",
        "PDF": "https://arxiv.org/pdf/2506.22366"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The study is centered on understanding language parsing actions and communication strategies, and does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22370",
      "abstract": "Students in computing education increasingly use large language models (LLMs) such as ChatGPT. Yet, the role of LLMs in supporting cognitively demanding tasks, like deductive program verification, remains poorly understood. This paper investigates how students interact with an LLM when solving formal verification exercises in Dafny, a language that supports functional correctness, by allowing programmers to write formal specifications and automatically verifying that the implementation satisfies the specification. We conducted a mixed-methods study with master's students enrolled in a formal methods course. Each participant completed two verification problems, one with access to a custom ChatGPT interface, that logged all interactions, and the other without. We identified strategies used by successful students and assessed the level of trust students place in LLMs. %\\todo{Our findings show that something here} Our findings show that students perform significantly better when using ChatGPT; however, performance gains are tied to prompt quality. We conclude with practical recommendations for integrating LLMs into formal methods courses more effectively, including designing LLM-aware challenges that promote learning rather than substitution.",
      "authors": [
        "Carolina Carreira",
        "\\'Alvaro Silva",
        "Alexandre Abreu",
        "and Alexandra Mendes"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T16:34:13+00:00",
          "link": "https://arxiv.org/abs/2506.22370v1",
          "size": "296kb",
          "version": "v1"
        }
      ],
      "title": "Can Large Language Models Help Students Prove Software Correctness? An Experimental Study with Dafny",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22370",
        "HTML": "https://arxiv.org/html/2506.22370v1",
        "PDF": "https://arxiv.org/pdf/2506.22370"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper explores the use of LLMs in educational contexts for program verification, focusing on students' interactions with LLMs, rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22372",
      "abstract": "The presence of social biases in Natural Language Processing (NLP) and Information Retrieval (IR) systems is an ongoing challenge, which underlines the importance of developing robust approaches to identifying and evaluating such biases. In this paper, we aim to address this issue by leveraging Large Language Models (LLMs) to detect and measure gender bias in passage ranking. Existing gender fairness metrics rely on lexical- and frequency-based measures, leading to various limitations, e.g., missing subtle gender disparities. Building on our LLM-based gender bias detection method, we introduce a novel gender fairness metric, named Class-wise Weighted Exposure (CWEx), aiming to address existing limitations. To measure the effectiveness of our proposed metric and study LLMs' effectiveness in detecting gender bias, we annotate a subset of the MS MARCO Passage Ranking collection and release our new gender bias collection, called MSMGenderBias, to foster future research in this area. Our extensive experimental results on various ranking models show that our proposed metric offers a more detailed evaluation of fairness compared to previous metrics, with improved alignment to human labels (58.77% for Grep-BiasIR, and 18.51% for MSMGenderBias, measured using Cohen's Kappa agreement), effectively distinguishing gender bias in ranking. By integrating LLM-driven bias detection, an improved fairness metric, and gender bias annotations for an established dataset, this work provides a more robust framework for analyzing and mitigating bias in IR systems.",
      "authors": [
        "Maryam Mousavian",
        "Zahra Abbasiantaeb",
        "Mohammad Aliannejadi",
        "Fabio Crestani"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T16:39:12+00:00",
          "link": "https://arxiv.org/abs/2506.22372v1",
          "size": "258kb",
          "version": "v1"
        }
      ],
      "title": "Towards Fair Rankings: Leveraging LLMs for Gender Bias Detection and Measurement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22372",
        "HTML": "https://arxiv.org/html/2506.22372v1",
        "PDF": "https://arxiv.org/pdf/2506.22372"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper aims at detecting and measuring gender bias in passage ranking using LLMs and proposes a fairness metric, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22374",
      "abstract": "In large-scale communication systems, increasingly complex scenarios require more intelligent collaboration among edge devices collecting various multimodal sensory data to achieve a more comprehensive understanding of the environment and improve decision-making accuracy. However, conventional federated learning (FL) algorithms typically consider unimodal datasets, require identical model architectures, and fail to leverage the rich information embedded in multimodal data, limiting their applicability to real-world scenarios with diverse modalities and varying client capabilities. To address this issue, we propose Sheaf-DMFL, a novel decentralized multimodal learning framework leveraging sheaf theory to enhance collaboration among devices with diverse modalities. Specifically, each client has a set of local feature encoders for its different modalities, whose outputs are concatenated before passing through a task-specific layer. While encoders for the same modality are trained collaboratively across clients, we capture the intrinsic correlations among clients' task-specific layers using a sheaf-based structure. To further enhance learning capability, we propose an enhanced algorithm named Sheaf-DMFL-Att, which tailors the attention mechanism within each client to capture correlations among different modalities. A rigorous convergence analysis of Sheaf-DMFL-Att is provided, establishing its theoretical guarantees. Extensive simulations are conducted on real-world link blockage prediction and mmWave beamforming scenarios, demonstrate the superiority of the proposed algorithms in such heterogeneous wireless communication systems.",
      "authors": [
        "Abdulmomen Ghalkha",
        "Zhuojun Tian",
        "Chaouki Ben Issaid",
        "and Mehdi Bennis"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T16:41:23+00:00",
          "link": "https://arxiv.org/abs/2506.22374v1",
          "size": "4570kb",
          "version": "v1"
        }
      ],
      "title": "Sheaf-Based Decentralized Multimodal Learning for Next-Generation Wireless Communication Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22374",
        "HTML": "https://arxiv.org/html/2506.22374v1",
        "PDF": "https://arxiv.org/pdf/2506.22374"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on a decentralized multimodal learning framework for edge devices in wireless communication systems. There is no mention of data processing specifically in the context of LLM training data preparation or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22375",
      "abstract": "Out-of-distribution (OOD) detection in 3D point cloud data remains a challenge, particularly in applications where safe and robust perception is critical. While existing OOD detection methods have shown progress for 2D image data, extending these to 3D environments involves unique obstacles. This paper introduces a training-free framework that leverages Vision-Language Models (VLMs) for effective OOD detection in 3D point clouds. By constructing a graph based on class prototypes and testing data, we exploit the data manifold structure to enhancing the effectiveness of VLMs for 3D OOD detection. We propose a novel Graph Score Propagation (GSP) method that incorporates prompt clustering and self-training negative prompting to improve OOD scoring with VLM. Our method is also adaptable to few-shot scenarios, providing options for practical applications. We demonstrate that GSP consistently outperforms state-of-the-art methods across synthetic and real-world datasets 3D point cloud OOD detection.",
      "authors": [
        "Tiankai Chen",
        "Yushu Li",
        "Adam Goodge",
        "Fei Teng",
        "Xulei Yang",
        "Tianrui Li",
        "Xun Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T16:42:45+00:00",
          "link": "https://arxiv.org/abs/2506.22375v1",
          "size": "4791kb",
          "version": "v1"
        }
      ],
      "title": "Exploiting Vision Language Model for Training-Free 3D Point Cloud OOD Detection via Graph Score Propagation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22375",
        "HTML": "https://arxiv.org/html/2506.22375v1",
        "PDF": "https://arxiv.org/pdf/2506.22375"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper introduces a framework for 3D point cloud OOD detection, leveraging vision-language models. It does not discuss any aspects of training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22376",
      "abstract": "Inference-time scaling has emerged as a powerful technique for enhancing the reasoning performance of Large Language Models (LLMs). However, existing approaches often rely on heuristic strategies for parallel sampling, lacking a principled foundation. To address this gap, we propose a probabilistic framework that formalizes the optimality of inference-time scaling under the assumption that parallel samples are independently and identically distributed (i.i.d.), and where the Best-of-N selection strategy follows a probability distribution that can be estimated. Within this framework, we derive a theoretical lower bound on the required number of samples to achieve a target performance level, providing the first principled guidance for compute-efficient scaling. Leveraging this insight, we develop \\textsc{OptScale}, a practical algorithm that dynamically determines the optimal number of sampled responses. \\textsc{OptScale} employs a language model-based predictor to estimate probabilistic prior parameters, enabling the decision of the minimal number of samples needed that satisfy predefined performance thresholds and confidence levels. Extensive experiments on mathematical reasoning benchmarks (including MATH-500, GSM8K, AIME, and AMC) demonstrate that \\textsc{OptScale} significantly reduces sampling overhead while remaining better or on par with state-of-the-art reasoning performance. Our work offers both a theoretical foundation and a practical solution for principled inference-time scaling, addressing a critical gap in the efficient deployment of LLMs for complex reasoning.",
      "authors": [
        "Youkang Wang",
        "Jian Wang",
        "Rubing Chen",
        "Xiao-Yong Wei",
        "Qing Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T16:44:11+00:00",
          "link": "https://arxiv.org/abs/2506.22376v1",
          "size": "497kb",
          "version": "v1"
        }
      ],
      "title": "Probabilistic Optimality for Inference-time Scaling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22376",
        "HTML": "https://arxiv.org/html/2506.22376v1",
        "PDF": "https://arxiv.org/pdf/2506.22376"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The work emphasizes inference-time scaling and optimization for LLMs, focusing on performance improvement during inference rather than any training data processing aspects."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22379",
      "abstract": "Online and AI-based symptom checkers are applications that assist medical laypeople in diagnosing their symptoms and determining which course of action to take. When evaluating these tools, previous studies primarily used an approach introduced a decade ago that lacked any type of quality control. Numerous studies have criticized this approach, and several empirical studies have sought to improve specific aspects of evaluations. However, even after a decade, a high-quality methodological framework for standardizing the evaluation of symptom checkers remains missing. This article synthesizes empirical studies to outline a framework for standardized evaluations based on representative case selection, an externally and internally valid evaluation design, and metrics that increase cross-study comparability. This approach is backed up by several open-access resources to facilitate implementation. Ultimately, this approach should enhance the quality and comparability of future evaluations of online and AI-based symptom checkers to enable meta-analyses and help stakeholders make more informed decisions.",
      "authors": [
        "Marvin Kopka and Markus A. Feufel"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T16:48:33+00:00",
          "link": "https://arxiv.org/abs/2506.22379v1",
          "size": "329kb",
          "version": "v1"
        }
      ],
      "title": "How to Evaluate the Accuracy of Online and AI-Based Symptom Checkers: A Standardized Methodological Framework",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22379",
        "PDF": "https://arxiv.org/pdf/2506.22379"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The focus is on creating a standardized evaluation framework for AI-based symptom checkers, without any discussion related to LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22385",
      "abstract": "Video Large Multimodal Models (VLMMs) have made impressive strides in understanding video content, but they often struggle with abstract and adaptive reasoning-the ability to revise their interpretations when new information emerges. In reality, conclusions are rarely set in stone; additional context can strengthen or weaken an initial inference. To address this, we introduce Defeasible Video Entailment (DVidE), a new task that challenges models to think like doubters, constantly updating their reasoning based on evolving evidence. In DVidE, given a video premise and a textual hypothesis, models must determine whether a new update strengthens or weakens the hypothesis (classification version) or generate a coherent update that modifies the entailment relationship (generation version). For solving the classification task, we propose the Chain of Counterfactual Thought framework, utilizing counterfactual reasoning, ASR-enhanced video content, and rationale refinement to reduce inference bias. For the generation task, we develop a framework that combines ASR output with a Large Language Model (LLM) to produce coherent, contextually relevant updates aligned with the intended strengthener or weakener goals. Additionally, we introduce a novel benchmark dataset, with strengthener/weakener annotations and an LLM-based evaluation metric specifically designed for assessing generative performance. Experimental results demonstrate significant improvements, highlighting our proposed method in enhancing dynamic reasoning capabilities of VLMMs.",
      "authors": [
        "Yue Zhang",
        "Jilei Sun",
        "Yunhui Guo and Vibhav Gogate"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T16:51:15+00:00",
          "link": "https://arxiv.org/abs/2506.22385v1",
          "size": "12551kb",
          "version": "v1"
        }
      ],
      "title": "Can Video Large Multimodal Models Think Like Doubters-or Double-Down: A Study on Defeasible Video Entailment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22385",
        "HTML": "https://arxiv.org/html/2506.22385v1",
        "PDF": "https://arxiv.org/pdf/2506.22385"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper presents a task for video multimodal models related to reasoning, but does not discuss any aspect of LLM training data engineering or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22389",
      "abstract": "We introduce and train distributed neural architectures (DNA) in vision and language domains. DNAs are initialized with a proto-architecture that consists of (transformer, MLP, attention, etc.) modules and routers. Any token (or patch) can traverse any series of modules in any order. DNAs are a natural generalization of the sparse methods such as Mixture-of-Experts, Mixture-of-Depths, parameter sharing, etc. Computation and communication patterns of DNA modules are learnt end-to-end during training and depend on the content and context of each token (or patch). These patterns can be shaped by further requirements added to the optimization objective such as compute/memory efficiency or load balancing. We empirically show that (i) trained DNAs are competitive with the dense baselines in both domains and (ii) compute efficiency/parameter sharing can be learnt from data. Next, we analyze the emergent connectivity and computation patterns in the trained DNAs. We find that the paths that tokens take through the models are themselves distributed according to a power-law. We show that some paths (or, equivalently, groups of modules) show emergent specialization. Finally, we demonstrate that models learn to allocate compute and active parameters in an interpretable way.",
      "authors": [
        "Aditya Cowsik",
        "Tianyu He",
        "Andrey Gromov"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T16:57:59+00:00",
          "link": "https://arxiv.org/abs/2506.22389v1",
          "size": "28897kb",
          "version": "v1"
        }
      ],
      "title": "Towards Distributed Neural Architectures",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22389",
        "PDF": "https://arxiv.org/pdf/2506.22389"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on distributed neural architectures and their training dynamics, but does not address any aspect of LLM training data collection, construction, or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22390",
      "abstract": "Conversational large-language models are extensively used for issue resolution tasks. However, not all developer-LLM conversations are useful for effective issue resolution. In this paper, we analyze 686 developer-ChatGPT conversations shared within GitHub issue threads to identify characteristics that make these conversations effective for issue resolution. First, we analyze the conversations and their corresponding issues to distinguish helpful from unhelpful conversations. We begin by categorizing the types of tasks developers seek help with to better understand the scenarios in which ChatGPT is most effective. Next, we examine a wide range of conversational, project, and issue-related metrics to uncover factors associated with helpful conversations. Finally, we identify common deficiencies in unhelpful ChatGPT responses to highlight areas that could inform the design of more effective developer-facing tools. We found that only 62% of the ChatGPT conversations were helpful for successful issue resolution. ChatGPT is most effective for code generation and tools/libraries/APIs recommendations, but struggles with code explanations. Helpful conversations tend to be shorter, more readable, and exhibit stronger semantic and linguistic alignment. Larger, more popular projects and more experienced developers benefit more from ChatGPT. At the issue level, ChatGPT performs best on simpler problems with limited developer activity and faster resolution, typically well-scoped tasks like compilation errors. The most common deficiencies in unhelpful ChatGPT responses include incorrect information and lack of comprehensiveness. Our findings have wide implications including guiding developers on effective interaction strategies for issue resolution, informing the development of tools or frameworks to support optimal prompt design, and providing insights on fine-tuning LLMs for issue resolution tasks.",
      "authors": [
        "Ramtin Ehsani",
        "Sakshi Pathak",
        "Esteban Parra",
        "Sonia Haiduc",
        "Preetha Chatterjee"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T17:00:48+00:00",
          "link": "https://arxiv.org/abs/2506.22390v1",
          "size": "6073kb",
          "version": "v1"
        }
      ],
      "title": "What Makes ChatGPT Effective for Software Issue Resolution? An Empirical Study of Developer-ChatGPT Conversations in GitHub",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22390",
        "HTML": "https://arxiv.org/html/2506.22390v1",
        "PDF": "https://arxiv.org/pdf/2506.22390"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The study involves analyzing developer-ChatGPT conversations, which could indirectly relate to conversational data used in training LLMs, but the primary focus is on effectiveness assessment rather than data engineering or direct data processing methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22393",
      "abstract": "Adapting machine learning models to medical time series across different domains remains a challenge due to complex temporal dependencies and dynamic distribution shifts. Current approaches often focus on isolated feature representations, limiting their ability to fully capture the intricate temporal dynamics necessary for robust domain adaptation. In this work, we propose a novel framework leveraging multi-view contrastive learning to integrate temporal patterns, derivative-based dynamics, and frequency-domain features. Our method employs independent encoders and a hierarchical fusion mechanism to learn feature-invariant representations that are transferable across domains while preserving temporal coherence. Extensive experiments on diverse medical datasets, including electroencephalogram (EEG), electrocardiogram (ECG), and electromyography (EMG) demonstrate that our approach significantly outperforms state-of-the-art methods in transfer learning tasks. By advancing the robustness and generalizability of machine learning models, our framework offers a practical pathway for deploying reliable AI systems in diverse healthcare settings.",
      "authors": [
        "YongKyung Oh",
        "Alex Bui"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T17:06:16+00:00",
          "link": "https://arxiv.org/abs/2506.22393v1",
          "size": "745kb",
          "version": "v1"
        }
      ],
      "title": "Multi-View Contrastive Learning for Robust Domain Adaptation in Medical Time Series Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22393",
        "HTML": "https://arxiv.org/html/2506.22393v1",
        "PDF": "https://arxiv.org/pdf/2506.22393"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper is about adapting machine learning models for medical time series analysis through multi-view contrastive learning, which is not related to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22395",
      "abstract": "Vision-Language Models (VLMs) have achieved impressive performance across a wide range of multimodal tasks, yet they often exhibit inconsistent behavior when faced with semantically equivalent inputs, undermining their reliability and robustness. Recent benchmarks, such as MM-R3, highlight that even state-of-the-art VLMs can produce divergent predictions across semantically equivalent inputs, despite maintaining high average accuracy. Prior work addresses this issue by modifying model architectures or conducting large-scale fine-tuning on curated datasets. In contrast, we propose a simple and effective test-time consistency framework that enhances semantic consistency without supervised re-training. Our method is entirely post-hoc, model-agnostic, and applicable to any VLM with access to its weights. Given a single test point, we enforce consistent predictions via two complementary objectives: (i) a Cross-Entropy Agreement Loss that aligns predictive distributions across semantically equivalent inputs, and (ii) a Pseudo-Label Consistency Loss that draws outputs toward a self-averaged consensus. Our method is plug-and-play and leverages information from a single test input itself to improve consistency. Experiments on the MM-R3 benchmark show that our framework yields substantial gains in consistency across state-of-the-art models, establishing a new direction for inference-time adaptation in multimodal learning.",
      "authors": [
        "Shih-Han Chou",
        "Shivam Chandhok",
        "James J. Little",
        "Leonid Sigal"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T17:09:44+00:00",
          "link": "https://arxiv.org/abs/2506.22395v1",
          "size": "9416kb",
          "version": "v1"
        }
      ],
      "title": "Test-Time Consistency in Vision Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22395",
        "HTML": "https://arxiv.org/html/2506.22395v1",
        "PDF": "https://arxiv.org/pdf/2506.22395"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper proposes a test-time consistency framework for vision-language models without supervised re-training, focusing on improving VLM predictions rather than on LLM training data processing or data construction."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22396",
      "abstract": "Inference accounts for the majority of latency and energy consumption in large language model (LLM) deployments, often exceeding 90% of total cost. While training-time efficiency has seen extensive progress, runtime optimization remains a key bottleneck, particularly under autoregressive decoding. Existing approaches -- such as pruning, quantization, early exits, and speculative decoding -- often require retraining, architectural changes, or disrupt decoding compatibility. We introduce QuickSilver, a modular, token-level framework that enables semantic adaptivity at inference time without altering model weights or structure. QuickSilver integrates four synergistic mechanisms:\n  (i) Dynamic Token Halting, which halts computation for tokens with converged representations; (ii) KV Cache Skipping, which selectively suppresses memory writes to reduce attention overhead; and (iii) Contextual Token Fusion, which collapses redundant tokens into shared paths to shrink sequence length.\n  Unlike speculative decoding or MoE routing, QuickSilver operates entirely on frozen, dense models and requires no auxiliary networks. Applied to GPT-2 and Llama-2 across WikiText-103 and C4, QuickSilver achieves up to 39.6% FLOP reduction with negligible perplexity degradation (<=0.2).",
      "authors": [
        "Danush Khanna",
        "Aditya Kumar Guru",
        "Srivarshinee Sridhar",
        "Zidan Ahmed",
        "Rubhav Bahirwani",
        "Meetu Malhotra",
        "Vinija Jain",
        "Aman Chadha",
        "Amitava Das",
        "Kripabandhu Ghosh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T17:10:32+00:00",
          "link": "https://arxiv.org/abs/2506.22396v1",
          "size": "10115kb",
          "version": "v1"
        }
      ],
      "title": "QuickSilver -- Speeding up LLM Inference through Dynamic Token Halting, KV Skipping, Contextual Token Fusion, and Adaptive Matryoshka Quantization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22396",
        "PDF": "https://arxiv.org/pdf/2506.22396"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "QuickSilver aims to optimize LLM inference through a modular framework, which involves runtime efficiency enhancements and not LLM training data aspects like collection or preprocessing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22401",
      "abstract": "Online reinforcement learning (RL) with complex function approximations such as transformers and deep neural networks plays a significant role in the modern practice of artificial intelligence. Despite its popularity and importance, balancing the fundamental trade-off between exploration and exploitation remains a long-standing challenge; in particular, we are still in lack of efficient and practical schemes that are backed by theoretical performance guarantees. Motivated by recent developments in exploration via optimistic regularization, this paper provides an interpretation of the principle of optimism through the lens of primal-dual optimization. From this fresh perspective, we set forth a new value-incentivized actor-critic (VAC) method, which optimizes a single easy-to-optimize objective integrating exploration and exploitation -- it promotes state-action and policy estimates that are both consistent with collected data transitions and result in higher value functions. Theoretically, the proposed VAC method has near-optimal regret guarantees under linear Markov decision processes (MDPs) in both finite-horizon and infinite-horizon settings, which can be extended to the general function approximation setting under appropriate assumptions.",
      "authors": [
        "Tong Yang",
        "Bo Dai",
        "Lin Xiao",
        "Yuejie Chi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T17:18:43+00:00",
          "link": "https://arxiv.org/abs/2506.22401v1",
          "size": "50kb",
          "version": "v1"
        }
      ],
      "title": "Exploration from a Primal-Dual Lens: Value-Incentivized Actor-Critic Methods for Sample-Efficient Online RL",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22401",
        "HTML": "https://arxiv.org/html/2506.22401v1",
        "PDF": "https://arxiv.org/pdf/2506.22401"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper deals with reinforcement learning and the development of value-incentivized actor-critic methods, which are not related to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22402",
      "abstract": "We present a grammar error correction (GEC) system that achieves state of the art for the Czech language. Our system is based on a neural network translation approach with the Transformer architecture, and its key feature is its real-time synthetic generation pipeline, which dynamically augments sentences with artificial errors by introducing both language-agnostic and Czech-specific errors. We conduct a comprehensive series of experiments, investigating the Czech GEC corpora as bases for synthetic error introduction, several error generation strategies, domain balancing, tokenization granularity, model size, and data scaling during fine-tuning. Additionally, we evaluate the performance of large language models (LLMs) on Czech GEC in both end-user and expert fine-tuning scenarios. Our best-performing model is superior both in performance and computational efficiency. The source code and the trained model links are available on https://github.com/ufal/tsd2025-gec.",
      "authors": [
        "Petr Pechman",
        "Milan Straka",
        "Jana Strakov\\'a",
        "Jakub N\\'aplava"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T17:21:40+00:00",
          "link": "https://arxiv.org/abs/2506.22402v1",
          "size": "68kb",
          "version": "v1"
        }
      ],
      "title": "Refining Czech GEC: Insights from a Multi-Experiment Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22402",
        "HTML": "https://arxiv.org/html/2506.22402v1",
        "PDF": "https://arxiv.org/pdf/2506.22402"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper mentions using a translation model based on the Transformer architecture and explores various pre-processing strategies for grammar error correction, which indirectly relate to training data augmentation techniques that might benefit LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22403",
      "abstract": "We introduce HyperCLOVA X THINK, the first reasoning-focused large language model in the HyperCLOVA X family, pre-trained on roughly $6$ trillion high-quality Korean, and English tokens, augmented with targeted synthetic Korean data. It was implemented as a compute-memory-balanced Peri-LN Transformer scaled with $\\mu$P, pre-trained through a three-stage curriculum that expands the context window to $128$K tokens, and post-trained via supervised fine-tuning with Reinforcement Learning from Verifiable Rewards supports both detailed rationale and concise-answer modes. It delivers competitive performance against similarly sized models on Korea-focused benchmarks such as KMMLU, CSAT, KoBALT-700, HAERAE-1.0, and KoBigBench, while preserving robust bilingual consistency and translation quality. In addition, a vision-augmented variant matches or exceeds GPT-4.1 on the KCSAT STEM benchmark, all of which are achieved with substantially lower training compute than existing models of similar sizes. We also present a pruning and distillation technique that will soon be applied to HyperCLOVA X THINK for an open-source and business-friendly foundation model. Altogether, these capabilities position HyperCLOVA X THINK as a robust foundation for Korean AI innovation and a valuable resource for the global research community.",
      "authors": [
        "NAVER Cloud HyperCLOVA X Team"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T17:23:12+00:00",
          "link": "https://arxiv.org/abs/2506.22403v1",
          "size": "3781kb",
          "version": "v1"
        }
      ],
      "title": "HyperCLOVA X THINK Technical Report",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22403",
        "PDF": "https://arxiv.org/pdf/2506.22403"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces a pre-trained LLM, it primarily focuses on the model's design and performance metrics, mentioning the use of high-quality tokens for pre-training without detailing new data processing methodologies for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22404",
      "abstract": "In the realm of Cyber-Physical System (CPS), accurately identifying attacks without detailed knowledge of the system's parameters remains a major challenge. When it comes to Advanced Driver Assistance Systems (ADAS), identifying the parameters of vehicle dynamics could be impractical or prohibitively costly. To tackle this challenge, we propose a novel framework for attack detection in vehicles that effectively addresses the uncertainty in their dynamics. Our method integrates the widely used Unscented Kalman Filter (UKF), a well-known technique for nonlinear state estimation in dynamic systems, with machine learning algorithms. This combination eliminates the requirement for precise vehicle modeling in the detection process, enhancing the system's adaptability and accuracy. To validate the efficacy and practicality of our proposed framework, we conducted extensive comparative simulations by introducing Denial of Service (DoS) attacks on the vehicle systems' sensors and actuators.",
      "authors": [
        "Shuhao Bian",
        "Milad Farsi",
        "Nasser L. Azad",
        "Chris Hobbs"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T17:23:36+00:00",
          "link": "https://arxiv.org/abs/2506.22404v1",
          "size": "6259kb",
          "version": "v1"
        }
      ],
      "title": "Data-Driven Intrusion Detection in Vehicles: Integrating Unscented Kalman Filter (UKF) with Machine Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22404",
        "HTML": "https://arxiv.org/html/2506.22404v1",
        "PDF": "https://arxiv.org/pdf/2506.22404"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This research is about intrusion detection in vehicles using a Kalman filter and machine learning, which is unrelated to any processes involving LLM data engineering or training-stage data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22405",
      "abstract": "Artificial intelligence holds great promise for expanding access to expert medical knowledge and reasoning. However, most evaluations of language models rely on static vignettes and multiple-choice questions that fail to reflect the complexity and nuance of evidence-based medicine in real-world settings. In clinical practice, physicians iteratively formulate and revise diagnostic hypotheses, adapting each subsequent question and test to what they've just learned, and weigh the evolving evidence before committing to a final diagnosis. To emulate this iterative process, we introduce the Sequential Diagnosis Benchmark, which transforms 304 diagnostically challenging New England Journal of Medicine clinicopathological conference (NEJM-CPC) cases into stepwise diagnostic encounters. A physician or AI begins with a short case abstract and must iteratively request additional details from a gatekeeper model that reveals findings only when explicitly queried. Performance is assessed not just by diagnostic accuracy but also by the cost of physician visits and tests performed. We also present the MAI Diagnostic Orchestrator (MAI-DxO), a model-agnostic orchestrator that simulates a panel of physicians, proposes likely differential diagnoses and strategically selects high-value, cost-effective tests. When paired with OpenAI's o3 model, MAI-DxO achieves 80% diagnostic accuracy--four times higher than the 20% average of generalist physicians. MAI-DxO also reduces diagnostic costs by 20% compared to physicians, and 70% compared to off-the-shelf o3. When configured for maximum accuracy, MAI-DxO achieves 85.5% accuracy. These performance gains with MAI-DxO generalize across models from the OpenAI, Gemini, Claude, Grok, DeepSeek, and Llama families. We highlight how AI systems, when guided to think iteratively and act judiciously, can advance diagnostic precision and cost-effectiveness in clinical care.",
      "authors": [
        "Harsha Nori",
        "Mayank Daswani",
        "Christopher Kelly",
        "Scott Lundberg",
        "Marco Tulio Ribeiro",
        "Marc Wilson",
        "Xiaoxuan Liu",
        "Viknesh Sounderajah",
        "Jonathan Carlson",
        "Matthew P Lungren",
        "Bay Gross",
        "Peter Hames",
        "Mustafa Suleyman",
        "Dominic King",
        "Eric Horvitz"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T17:27:26+00:00",
          "link": "https://arxiv.org/abs/2506.22405v1",
          "size": "6147kb",
          "version": "v1"
        }
      ],
      "title": "Sequential Diagnosis with Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22405",
        "HTML": "https://arxiv.org/html/2506.22405v1",
        "PDF": "https://arxiv.org/pdf/2506.22405"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on AI systems for medical diagnostics, particularly the Sequential Diagnosis Benchmark and MAI Diagnostic Orchestrator. It does not address any aspect of LLM training data collection, construction, or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22406",
      "abstract": "Economic Model Predictive Control (EMPC), instead of stabilizing a reference trajectory/state in the objective function like a Tracking MPC, optimizes the economic performance over the prediction horizon, making it attractive for economical microgrid (MG) dispatch. However, the demand charge component in the monthly electricity cost, make it difficult to be encapsulated in additive stage costs, and can make solutions violate the principle of optimality if naively introduced in the objective function. Moreover, previous EMPC based works mostly rely on a-priori knowledge of an optimal economic steady state or optimal periodic trajectory for performance guarantees, which are not useful or possibly don't exist respectively, for real-time economical MG dispatch where load/generation forecasts are known only 24-48 h in advance. This paper, first, proposes an EMPC formulation for a generic deterministic discrete non-linear time varying system with hard state and input constraints, without any a-priori requirements of an optimal economic steady state or optimal periodic trajectory. It is proved that under mild assumptions on terminal cost and region, the asymptotic average economic cost of the proposed method is no worse than the asymptotic average economic cost of any other non-fixed arbitrary reference trajectory which is known only until the current time-step. The EMPC framework is then leveraged for optimal MG dispatch by showing that the problem can be reformulated to satisfy the assumptions required for the asymptotic performance guarantee. Realistic simulations at the Port of San Diego MG demonstrated that the proposed method can also reduce monthly electricity costs in closed-loop with respect to reference trajectories generated by directly optimizing the electricity cost function over the prediction horizon or by tracking an ideal grid import curve in a majority of the cases.",
      "authors": [
        "Avik Ghosh",
        "Adil Khurram",
        "Jan Kleissl",
        "Sonia Martinez"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T17:27:40+00:00",
          "link": "https://arxiv.org/abs/2506.22406v1",
          "size": "197kb",
          "version": "v1"
        }
      ],
      "title": "Economic Model Predictive Control with a Non-Fixed Reference Trajectory for Optimal Microgrid Dispatch",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22406",
        "HTML": "https://arxiv.org/html/2506.22406v1",
        "PDF": "https://arxiv.org/pdf/2506.22406"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper discusses Economic Model Predictive Control for microgrid dispatch, focusing on optimizing economic performance in energy systems. There is no mention of language models or LLM training data processes."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22410",
      "abstract": "Motor-actuated pendulums have been established as arguably the most common laboratory prototypes used in control system education because of the relevance to robot manipulator control in industry. Meanwhile, multi-rotor drones like quadcopters have become popular in industrial applications but have not been broadly employed in control education laboratory. Platforms with pendulums and multi-rotor copters present classical yet intriguing multi-degree of freedom (DoF) dynamics and coordinate systems for the control system investigation. In this paper, we introduce a novel control platform in which a 2-DoF pendulum capable of azimuth and elevation rotation is actuated through vectored thrust generated by a quadcopter. Designed as a benchmark for mechatronics and nonlinear control education and research, the system integrates detailed mechatronic implementation with different control strategies. Specifically, we apply and compare small perturbation linearization (SPL), state feedback linearization (SFL), and partial feedback linearization (PFL) to the nonlinear system dynamics. The performances are evaluated by time specifications of step response and Root-Mean-Square (RMS) error of trajectory tracking. The robustness of the closed-loop system is validated under external disturbances, and both simulation and experimental results are presented to highlight the strengths and limitations of the nonlinear model-based control approaches.",
      "authors": [
        "Yuchen Li",
        "Omar Curiel",
        "Sheng-Fan Wen and Tsu-Chin Tsao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T17:37:15+00:00",
          "link": "https://arxiv.org/abs/2506.22410v1",
          "size": "8116kb",
          "version": "v1"
        }
      ],
      "title": "Spherical Pendulum with Quad-Rotor Thrust Vectoring Actuation -- A Novel Mechatronics and Control Benchmark Platform",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22410",
        "PDF": "https://arxiv.org/pdf/2506.22410"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper presents a novel platform for mechatronics and nonlinear control education using a pendulum actuated by quadrotor thrust. It does not relate to any aspect of LLM training or data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22419",
      "abstract": "Rapid advancements in large language models (LLMs) have the potential to assist in scientific progress. A critical capability toward this endeavor is the ability to reproduce existing work. To evaluate the ability of AI agents to reproduce results in an active research area, we introduce the Automated LLM Speedrunning Benchmark, leveraging the research community contributions on the NanoGPT speedrun, a competition to train a GPT-2 model in the shortest time. Each of the 19 speedrun tasks provides the agent with the previous records training script, optionally paired with one of three hint formats, ranging from pseudocode to paper-like descriptions of the new records improvements. Records execute quickly by design and speedrun improvements encompass diverse code-level changes, ranging from high-level algorithmic advancements to hardware-aware optimizations. These features make the benchmark both accessible and realistic for the frontier problem of improving LLM training. We find that recent reasoning LLMs combined with SoTA scaffolds struggle to reimplement already-known innovations in our benchmark, even when given detailed hints. Our benchmark thus provides a simple, non-saturated measure of an LLMs ability to automate scientific reproduction, a necessary (but not sufficient) skill for an autonomous research agent.",
      "authors": [
        "Bingchen Zhao",
        "Despoina Magka",
        "Minqi Jiang",
        "Xian Li",
        "Roberta Raileanu",
        "Tatiana Shavrina",
        "Jean-Christophe Gagnon-Audet",
        "Kelvin Niu",
        "Shagun Sodhani",
        "Michael Shvartsman",
        "Andrei Lupu",
        "Alisia Lupidi",
        "Edan Toledo",
        "Karen Hambardzumyan",
        "Martin Josifoski",
        "Thomas Foster",
        "Lucia Cipolina-Kun",
        "Abhishek Charnalia",
        "Derek Dunfield",
        "Alexander H. Miller",
        "Oisin Mac Aodha",
        "Jakob Foerster",
        "Yoram Bachrach"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T17:44:32+00:00",
          "link": "https://arxiv.org/abs/2506.22419v1",
          "size": "1388kb",
          "version": "v1"
        }
      ],
      "title": "The Automated LLM Speedrunning Benchmark: Reproducing NanoGPT Improvements",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22419",
        "PDF": "https://arxiv.org/pdf/2506.22419"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces the Automated LLM Speedrunning Benchmark, though its focus is on evaluating LLMs' ability to reproduce AI research work, particularly improvements in LLM training like NanoGPT, rather than on training data processing itself."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22423",
      "abstract": "Unmanned Aerial Vehicles (UAVs) depend on onboard sensors for perception, navigation, and control. However, these sensors are susceptible to physical attacks, such as GPS spoofing, that can corrupt state estimates and lead to unsafe behavior. While reinforcement learning (RL) offers adaptive control capabilities, existing safe RL methods are ineffective against such attacks. We present ARMOR (Adaptive Robust Manipulation-Optimized State Representations), an attack-resilient, model-free RL controller that enables robust UAV operation under adversarial sensor manipulation. Instead of relying on raw sensor observations, ARMOR learns a robust latent representation of the UAV's physical state via a two-stage training framework. In the first stage, a teacher encoder, trained with privileged attack information, generates attack-aware latent states for RL policy training. In the second stage, a student encoder is trained via supervised learning to approximate the teacher's latent states using only historical sensor data, enabling real-world deployment without privileged information. Our experiments show that ARMOR outperforms conventional methods, ensuring UAV safety. Additionally, ARMOR improves generalization to unseen attacks and reduces training cost by eliminating the need for iterative adversarial training.",
      "authors": [
        "Pritam Dash",
        "Ethan Chan",
        "Nathan P. Lawrence",
        "Karthik Pattabiraman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Cryptography and Security (cs.CR)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T17:46:33+00:00",
          "link": "https://arxiv.org/abs/2506.22423v1",
          "size": "24278kb",
          "version": "v1"
        }
      ],
      "title": "ARMOR: Robust Reinforcement Learning-based Control for UAVs under Physical Attacks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22423",
        "HTML": "https://arxiv.org/html/2506.22423v1",
        "PDF": "https://arxiv.org/pdf/2506.22423"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on the robustness of reinforcement learning for UAVs under sensor attacks. It discusses learning representations and training RL models, but there is no mention of processing or preparing training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22427",
      "abstract": "We propose CLoVE (Clustering of Loss Vector Embeddings), a novel algorithm for Clustered Federated Learning (CFL). In CFL, clients are naturally grouped into clusters based on their data distribution. However, identifying these clusters is challenging, as client assignments are unknown. CLoVE utilizes client embeddings derived from model losses on client data, and leverages the insight that clients in the same cluster share similar loss values, while those in different clusters exhibit distinct loss patterns. Based on these embeddings, CLoVE is able to iteratively identify and separate clients from different clusters and optimize cluster-specific models through federated aggregation. Key advantages of CLoVE over existing CFL algorithms are (1) its simplicity, (2) its applicability to both supervised and unsupervised settings, and (3) the fact that it eliminates the need for near-optimal model initialization, which makes it more robust and better suited for real-world applications. We establish theoretical convergence bounds, showing that CLoVE can recover clusters accurately with high probability in a single round and converges exponentially fast to optimal models in a linear setting. Our comprehensive experiments comparing with a variety of both CFL and generic Personalized Federated Learning (PFL) algorithms on different types of datasets and an extensive array of non-IID settings demonstrate that CLoVE achieves highly accurate cluster recovery in just a few rounds of training, along with state-of-the-art model accuracy, across a variety of both supervised and unsupervised PFL tasks.",
      "authors": [
        "Randeep Bhatia",
        "Nikos Papadis",
        "Murali Kodialam",
        "TV Lakshman",
        "Sayak Chakrabarty"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T17:52:16+00:00",
          "link": "https://arxiv.org/abs/2506.22427v1",
          "size": "295kb",
          "version": "v1"
        }
      ],
      "title": "CLoVE: Personalized Federated Learning through Clustering of Loss Vector Embeddings",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22427",
        "HTML": "https://arxiv.org/html/2506.22427v1",
        "PDF": "https://arxiv.org/pdf/2506.22427"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper introduces a federated learning algorithm for clustering clients based on data distribution. It does not address any aspects of training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22432",
      "abstract": "Recent advances in deep generative modeling have unlocked unprecedented opportunities for video synthesis. In real-world applications, however, users often seek tools to faithfully realize their creative editing intentions with precise and consistent control. Despite the progress achieved by existing methods, ensuring fine-grained alignment with user intentions remains an open and challenging problem. In this work, we present Shape-for-Motion, a novel framework that incorporates a 3D proxy for precise and consistent video editing. Shape-for-Motion achieves this by converting the target object in the input video to a time-consistent mesh, i.e., a 3D proxy, allowing edits to be performed directly on the proxy and then inferred back to the video frames. To simplify the editing process, we design a novel Dual-Propagation Strategy that allows users to perform edits on the 3D mesh of a single frame, and the edits are then automatically propagated to the 3D meshes of the other frames. The 3D meshes for different frames are further projected onto the 2D space to produce the edited geometry and texture renderings, which serve as inputs to a decoupled video diffusion model for generating edited results. Our framework supports various precise and physically-consistent manipulations across the video frames, including pose editing, rotation, scaling, translation, texture modification, and object composition. Our approach marks a key step toward high-quality, controllable video editing workflows. Extensive experiments demonstrate the superiority and effectiveness of our approach. Project page: https://shapeformotion.github.io/",
      "authors": [
        "Yuhao Liu",
        "Tengfei Wang",
        "Fang Liu",
        "Zhenwei Wang",
        "Rynson W.H. Lau"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T17:59:01+00:00",
          "link": "https://arxiv.org/abs/2506.22432v1",
          "size": "22524kb",
          "version": "v1"
        }
      ],
      "title": "Shape-for-Motion: Precise and Consistent Video Editing with 3D Proxy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22432",
        "HTML": "https://arxiv.org/html/2506.22432v1",
        "PDF": "https://arxiv.org/pdf/2506.22432"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on a video editing framework using 3D proxies for precise edits and does not address any aspect of LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22433",
      "abstract": "We introduce WarpRF, a training-free general-purpose framework for quantifying the uncertainty of radiance fields. Built upon the assumption that photometric and geometric consistency should hold among images rendered by an accurate model, WarpRF quantifies its underlying uncertainty from an unseen point of view by leveraging backward warping across viewpoints, projecting reliable renderings to the unseen viewpoint and measuring the consistency with images rendered there. WarpRF is simple and inexpensive, does not require any training, and can be applied to any radiance field implementation for free. WarpRF excels at both uncertainty quantification and downstream tasks, e.g., active view selection and active mapping, outperforming any existing method tailored to specific frameworks.",
      "authors": [
        "Sadra Safadoust",
        "Fabio Tosi",
        "Fatma G\\\"uney",
        "Matteo Poggi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T17:59:13+00:00",
          "link": "https://arxiv.org/abs/2506.22433v1",
          "size": "29385kb",
          "version": "v1"
        }
      ],
      "title": "WarpRF: Multi-View Consistency for Training-Free Uncertainty Quantification and Applications in Radiance Fields",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22433",
        "HTML": "https://arxiv.org/html/2506.22433v1",
        "PDF": "https://arxiv.org/pdf/2506.22433"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper introduces a framework for uncertainty quantification in radiance fields, which is unrelated to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22434",
      "abstract": "This work explores enabling Chain-of-Thought (CoT) reasoning to link visual cues across multiple images. A straightforward solution is to adapt rule-based reinforcement learning for Vision-Language Models (VLMs). However, such methods typically rely on manually curated question-answer pairs, which can be particularly challenging when dealing with fine grained visual details and complex logic across images. Inspired by self-supervised visual representation learning, we observe that images contain inherent constraints that can serve as supervision. Based on this insight, we construct image triplets comprising two augmented views of the same image and a third, similar but distinct image. During training, the model is prompted to generate a reasoning process to compare these images (i.e., determine same or different). Then we optimize the model with rule-based reinforcement learning. Due to the high visual similarity and the presence of augmentations, the model must attend to subtle visual changes and perform logical reasoning to succeed. Experiments show that, although trained solely on visual comparison tasks, the learned reasoning ability generalizes effectively to a wide range of questions. Without relying on any human-annotated question-answer pairs, our method achieves significant improvements on multi-image reasoning benchmarks and shows strong performance on general vision tasks.",
      "authors": [
        "Xi Chen",
        "Mingkang Zhu",
        "Shaoteng Liu",
        "Xiaoyang Wu",
        "Xiaogang Xu",
        "Yu Liu",
        "Xiang Bai",
        "Hengshuang Zhao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T17:59:27+00:00",
          "link": "https://arxiv.org/abs/2506.22434v1",
          "size": "4351kb",
          "version": "v1"
        }
      ],
      "title": "MiCo: Multi-image Contrast for Reinforcement Visual Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22434",
        "HTML": "https://arxiv.org/html/2506.22434v1",
        "PDF": "https://arxiv.org/pdf/2506.22434"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper explores visual reasoning using reinforcement learning and self-supervised learning, but it does not relate to the processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.19857",
      "abstract": "In this survey, we explore recent literature on finding the cores of higher graphs using geometric and topological means. We study graphs, hypergraphs, and simplicial complexes, all of which are models of higher graphs. We study the notion of a core, which is a minimalist representation of a higher graph that retains its geometric or topological information. We focus on geometric and topological methods based on discrete curvatures, effective resistance, and persistent homology. We aim to connect tools from graph theory, discrete geometry, and computational topology to inspire new research on the simplification of higher graphs.",
      "authors": [
        "In\\'es Garc\\'ia-Redondo",
        "Claudia Landi",
        "Sarah Percival",
        "Anda Skeja",
        "Bei Wang",
        "Ling Zhou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "History and Overview (math.HO)",
        "Computational Geometry (cs.CG)",
        "Discrete Mathematics (cs.DM)",
        "Combinatorics (math.CO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-09T21:34:43+00:00",
          "link": "https://arxiv.org/abs/2506.19857v1",
          "size": "1976kb",
          "version": "v1"
        }
      ],
      "title": "Finding the Cores of Higher Graphs Using Geometric and Topological Means: A Survey",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19857",
        "HTML": "https://arxiv.org/html/2506.19857v1",
        "PDF": "https://arxiv.org/pdf/2506.19857"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This is a survey on geometric and topological methods in higher graphs and does not address LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21648",
      "abstract": "This paper presents innovative solutions to critical challenges in planetary and deep-space exploration electronics. We synthesize findings across diverse mission profiles, highlighting advances in: (1) MARTIAN positioning systems with dual-frequency transmission to achieve $\\pm$1m horizontal accuracy; (2) artificial reef platforms for Titan's hydrocarbon seas utilizing specialized sensor arrays and multi-stage communication chains; (3) precision orbital rendezvous techniques demonstrating novel thermal protection solutions; (4) miniaturized CubeSat architectures for asteroid exploration with optimized power-to-mass ratios; and (5) next-generation power management systems for MARS rovers addressing dust accumulation challenges. These innovations represent promising directions for future space exploration technologies, particularly in environments where traditional Earth-based electronic solutions prove inadequate. The interdisciplinary nature of these developments highlights the critical intersection of aerospace engineering, electrical engineering, and planetary science in advancing human exploration capabilities beyond Earth orbit.",
      "authors": [
        "J. de Curt\\`o",
        "Cristina LiCalzi",
        "Julien Tubiana Warin",
        "Jack Gehlert",
        "Brian Langbein",
        "Alexandre Gamboa",
        "Chris Sixbey",
        "William Maguire",
        "Santiago Fern\\'andez",
        "\\'Alvaro Maestroarena",
        "Alex Brenchley",
        "Logan Maroclo",
        "Philemon Mercado",
        "Joshua DeJohn",
        "Cesar Velez",
        "Ethan Dahmus",
        "Taylor Steinys",
        "David Fritz and I. de Zarz\\`a"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
        "Earth and Planetary Astrophysics (astro-ph.EP)",
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T12:01:47+00:00",
          "link": "https://arxiv.org/abs/2506.21648v1",
          "size": "2883kb",
          "version": "v1"
        }
      ],
      "title": "Advanced System Engineering Approaches to Emerging Challenges in Planetary and Deep-Space Exploration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21648",
        "HTML": "https://arxiv.org/html/2506.21648v1",
        "PDF": "https://arxiv.org/pdf/2506.21648"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper presents solutions to challenges in planetary and deep-space exploration electronics. It does not discuss LLM training data processing or development."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21664",
      "abstract": "As 6G evolves, wireless networks become essential for critical operations and enable innovative applications that demand seamless adaptation to dynamic environments and disruptions. Because these vital services require uninterrupted operation, their resilience to unforeseen disruptions is essential. However, implementing resilience necessitates rapid recovery procedures, which operate in the finite blocklength (FBL) regime, where short packets and added error-correction overhead can severely degrade communication efficiency. Due to this performance loss, always attempting recovery can backfire and result in worse outcomes than simply enduring the disruption under longer blocklengths. In this work, we study these effects of FBL constraints within a resilience framework, incorporating reconfigurable intelligent surfaces (RIS) to enhance adaptation capabilities. By actively shaping the wireless environment, RIS help counteract some of the performance losses caused by FBL, enabling more effective recovery from disruptions. Numerical results reveal two critical blocklength thresholds: the first enables full recovery from the FBL penalty, while the second, at a higher blocklength, allows the system to recover from both the FBL penalty and the initial disruption, yielding a significant improvement in resilience performance. Additionally, we show that the number of RIS elements shifts these thresholds, enabling faster reconfiguration with shorter blocklengths and providing insights to the trade-offs between rate, blocklength, and reconfiguration effort under FBL conditions.",
      "authors": [
        "Kevin Weinberger and Aydin Sezgin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Information Theory (cs.IT)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T18:00:01+00:00",
          "link": "https://arxiv.org/abs/2506.21664v1",
          "size": "136kb",
          "version": "v1"
        }
      ],
      "title": "When Every Symbol Counts: Resilient Wireless Systems Under Finite Blocklength Constraints",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21664",
        "HTML": "https://arxiv.org/html/2506.21664v1",
        "PDF": "https://arxiv.org/pdf/2506.21664"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper is about improving resilience in wireless networks under finite blocklength constraints using reconfigurable intelligent surfaces. It does not relate to LLM training data or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21680",
      "abstract": "Advances in 3D reconstruction using neural rendering have enabled high-quality 3D capture. However, they often fail when the input imagery is corrupted by motion blur, due to fast motion of the camera or the objects in the scene. This work advances neural rendering techniques in such scenarios by using single-photon avalanche diode (SPAD) arrays, an emerging sensing technology capable of sensing images at extremely high speeds. However, the use of SPADs presents its own set of unique challenges in the form of binary images, that are driven by stochastic photon arrivals. To address this, we introduce PhotonSplat, a framework designed to reconstruct 3D scenes directly from SPAD binary images, effectively navigating the noise vs. blur trade-off. Our approach incorporates a novel 3D spatial filtering technique to reduce noise in the renderings. The framework also supports both no-reference using generative priors and reference-based colorization from a single blurry image, enabling downstream applications such as segmentation, object detection and appearance editing tasks. Additionally, we extend our method to incorporate dynamic scene representations, making it suitable for scenes with moving objects. We further contribute PhotonScenes, a real-world multi-view dataset captured with the SPAD sensors.",
      "authors": [
        "Sai Sri Teja",
        "Sreevidya Chintalapati",
        "Vinayak Gupta",
        "Mukund Varma T",
        "Haejoon Lee",
        "Aswin Sankaranarayanan",
        "Kaushik Mitra"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T18:04:28+00:00",
          "link": "https://arxiv.org/abs/2506.21680v1",
          "size": "18018kb",
          "version": "v1"
        }
      ],
      "title": "PhotonSplat: 3D Scene Reconstruction and Colorization from SPAD Sensors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21680",
        "HTML": "https://arxiv.org/html/2506.21680v1",
        "PDF": "https://arxiv.org/pdf/2506.21680"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper introduces a framework for 3D scene reconstruction using SPAD sensors. There is no mention of large language models or processing training data for LLMs, as the focus is on neural rendering and 3D reconstruction."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21720",
      "abstract": "Simulating showers of particles in highly-granular calorimeters is a key frontier in the application of machine learning to particle physics. Achieving high accuracy and speed with generative machine learning models can enable them to augment traditional simulations and alleviate a major computing constraint. Recent developments have shown how diffusion based generative shower simulation approaches that do not rely on a fixed structure, but instead generate geometry-independent point clouds, are very efficient. We present a transformer-based extension to previous architectures which were developed for simulating electromagnetic showers in the highly granular electromagnetic calorimeter of the International Large Detector, ILD. The attention mechanism now allows us to generate complex hadronic showers with more pronounced substructure across both the electromagnetic and hadronic calorimeters. This is the first time that machine learning methods are used to holistically generate showers across the electromagnetic and hadronic calorimeter in highly granular imaging calorimeter systems.",
      "authors": [
        "Thorsten Buss",
        "Frank Gaede",
        "Gregor Kasieczka",
        "Anatolii Korol",
        "Katja Kr\\\"uger",
        "Peter McKeown and Martina Mozzanica"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Instrumentation and Detectors (physics.ins-det)",
        "Machine Learning (cs.LG)",
        "High Energy Physics - Experiment (hep-ex)",
        "High Energy Physics - Phenomenology (hep-ph)",
        "Data Analysis, Statistics and Probability (physics.data-an)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T19:12:44+00:00",
          "link": "https://arxiv.org/abs/2506.21720v1",
          "size": "15557kb",
          "version": "v1"
        }
      ],
      "title": "CaloHadronic: a diffusion model for the generation of hadronic showers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21720",
        "HTML": "https://arxiv.org/html/2506.21720v1",
        "PDF": "https://arxiv.org/pdf/2506.21720"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper presents a diffusion model for generating hadronic showers in particle physics simulations. It is not related to the processing or engineering of training data for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21723",
      "abstract": "We present D-BIRD, a Bayesian dynamic item response model for estimating student ability from sparse, longitudinal assessments. By decomposing ability into a cohort trend and individual trajectory, D-BIRD supports interpretable modeling of learning over time. We evaluate parameter recovery in simulation and demonstrate the model using real-world personalized learning data.",
      "authors": [
        "Hansol Lee",
        "Jason B. Cho",
        "David S. Matteson",
        "Benjamin W. Domingue"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Applications (stat.AP)",
        "Computers and Society (cs.CY)",
        "Methodology (stat.ME)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T19:14:28+00:00",
          "link": "https://arxiv.org/abs/2506.21723v1",
          "size": "1429kb",
          "version": "v1"
        }
      ],
      "title": "Dynamic Bayesian Item Response Model with Decomposition (D-BIRD): Modeling Cohort and Individual Learning Over Time",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21723",
        "HTML": "https://arxiv.org/html/2506.21723v1",
        "PDF": "https://arxiv.org/pdf/2506.21723"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper discusses a Bayesian model for student assessments and does not relate to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21739",
      "abstract": "Authors Yi-Cheng Chen, Ping-En Lu, Cheng-Shang Chang, and Tzu-Hsuan Liu use the Finite Impulse Response (FIR) linear system filtering method to track and predict the number of people infected and recovered from COVID-19, in a pandemic context in which there was still no vaccine and the only way to avoid contagion was isolation. To estimate the coefficients of these FIR filters, Chen et al. used machine learning methods through a classical optimization problem with regularization (ridge regression). These estimated coefficients are called ridge coefficients. The epidemic mathematical model adopted by these researchers to formulate the FIR filters is the time-dependent discrete SIR. In this paper, we propose a small modification to the algorithm of Chen et al. to obtain the ridge coefficients. We then used this modified algorithm to track and predict the number of people infected and recovered from COVID-19 in the state of Minas Gerais/Brazil, within a prediction window, during the initial period of the pandemic. We also compare the predicted data with the respective real data to check how good the approximation is. In the modified algorithm, we set values for the FIR filter orders and for the regularization parameters, both different from the respective values defined by Chen et al. in their algorithm. In this context, the numerical results obtained by the modified algorithm in some simulations present better approximation errors compared to the respective approximation errors presented by the algorithm of Chen et al.",
      "authors": [
        "Felipe Rog\\'erio Pimentel",
        "Rafael Gustavo Alves"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T19:44:45+00:00",
          "link": "https://arxiv.org/abs/2506.21739v1",
          "size": "318kb",
          "version": "v1"
        }
      ],
      "title": "Modification of a Numerical Method Using FIR Filters in a Time-dependent SIR Model for COVID-19",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21739",
        "HTML": "https://arxiv.org/html/2506.21739v1",
        "PDF": "https://arxiv.org/pdf/2506.21739"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This study modifies a numerical method for predicting COVID-19 spread using FIR filters and machine learning, unrelated to LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21741",
      "abstract": "Denoising Diffusion Probabilistic Models represent an entirely new class of generative AI methods that have yet to be fully explored. Critical damping has been successfully introduced in Critically-Damped Langevin Dynamics (CLD) and Critically-Damped Third-Order Langevin Dynamics (TOLD++), but has not yet been applied to dynamics of arbitrary order. The proposed line of work generalizes Higher-Order Langevin Dynamics (HOLD), a recent state-of-the-art diffusion method, by introducing the concept of critical damping from systems analysis.",
      "authors": [
        "Benjamin Sterling",
        "Chad Gueli",
        "and M\\'onica F. Bugallo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T19:50:53+00:00",
          "link": "https://arxiv.org/abs/2506.21741v1",
          "size": "18kb",
          "version": "v1"
        }
      ],
      "title": "Critically-Damped Higher-Order Langevin Dynamics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21741",
        "HTML": "https://arxiv.org/html/2506.21741v1",
        "PDF": "https://arxiv.org/pdf/2506.21741"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on generative AI methods and higher-order dynamics rather than the processing of LLM training data or data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21748",
      "abstract": "Metasurfaces are ultra-thin optical elements composed of engineered sub-wavelength structures that enable precise control of light. Their inverse design - determining a geometry that yields a desired optical response - is challenging due to the complex, nonlinear relationship between structure and optical properties. This often requires expert tuning, is prone to local minima, and involves significant computational overhead. In this work, we address these challenges by integrating the generative capabilities of diffusion models into computational design workflows. Using an RCWA simulator, we generate training data consisting of metasurface geometries and their corresponding far-field scattering patterns. We then train a conditional diffusion model to predict meta-atom geometry and height from a target spatial power distribution at a specified wavelength, sampled from a continuous supported band. Once trained, the model can generate metasurfaces with low error, either directly using RCWA-guided posterior sampling or by serving as an initializer for traditional optimization methods. We demonstrate our approach on the design of a spatially uniform intensity splitter and a polarization beam splitter, both produced with low error in under 30 minutes. To support further research in data-driven metasurface design, we publicly release our code and datasets.",
      "authors": [
        "Liav Hen",
        "Erez Yosef",
        "Dan Raviv",
        "Raja Giryes",
        "Jacob Scheuer"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Optics (physics.optics)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T20:10:30+00:00",
          "link": "https://arxiv.org/abs/2506.21748v1",
          "size": "10297kb",
          "version": "v1"
        }
      ],
      "title": "Inverse Design of Diffractive Metasurfaces Using Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21748",
        "HTML": "https://arxiv.org/html/2506.21748v1",
        "PDF": "https://arxiv.org/pdf/2506.21748"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on the inverse design of diffractive metasurfaces using diffusion models, which involves generating training data for optical design purposes, but it does not pertain to the processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21757",
      "abstract": "Diffusion models have demonstrated exceptional capabilities in generating high-fidelity images but typically suffer from inefficient sampling. Many solver designs and noise scheduling strategies have been proposed to dramatically improve sampling speeds. In this paper, we introduce a new sampling method that is up to $186\\%$ faster than the current state of the art solver for comparative FID on ImageNet512. This new sampling method is training-free and uses an ordinary differential equation (ODE) solver. The key to our method resides in using higher-dimensional initial noise, allowing to produce more detailed samples with less function evaluations from existing pretrained diffusion models. In addition, by design our solver allows to control the level of detail through a simple hyper-parameter at no extra computational cost. We present how our approach leverages momentum dynamics by establishing a fundamental equivalence between momentum diffusion models and conventional diffusion models with respect to their training paradigms. Moreover, we observe the use of higher-dimensional noise naturally exhibits characteristics similar to stochastic differential equations (SDEs). Finally, we demonstrate strong performances on a set of representative pretrained diffusion models, including EDM, EDM2, and Stable-Diffusion 3, which cover models in both pixel and latent spaces, as well as class and text conditional settings. The code is available at https://github.com/apple/ml-tada.",
      "authors": [
        "Tianrong Chen",
        "Huangjie Zheng",
        "David Berthelot",
        "Jiatao Gu",
        "Josh Susskind",
        "Shuangfei Zhai"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T20:30:27+00:00",
          "link": "https://arxiv.org/abs/2506.21757v1",
          "size": "21111kb",
          "version": "v1"
        }
      ],
      "title": "TADA: Improved Diffusion Sampling with Training-free Augmented Dynamics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21757",
        "HTML": "https://arxiv.org/html/2506.21757v1",
        "PDF": "https://arxiv.org/pdf/2506.21757"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The work introduces a new sampling method for diffusion models aimed at image generation efficiency without involving LLM training data processing or relevant data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21765",
      "abstract": "Trackerless freehand ultrasound reconstruction aims to reconstruct 3D volumes from sequences of 2D ultrasound images without relying on external tracking systems, offering a low-cost, portable, and widely deployable alternative for volumetric imaging. However, it presents significant challenges, including accurate inter-frame motion estimation, minimisation of drift accumulation over long sequences, and generalisability across scanning protocols. The TUS-REC2024 Challenge was established to benchmark and accelerate progress in trackerless 3D ultrasound reconstruction by providing a publicly available dataset for the first time, along with a baseline model and evaluation framework. The Challenge attracted over 43 registered teams, of which 6 teams submitted 21 valid dockerized solutions. Submitted methods spanned a wide range of algorithmic approaches, including recurrent models, registration-driven volume refinement, attention, and physics-informed models. This paper presents an overview of the Challenge design, summarises the key characteristics of the dataset, provides a concise literature review, introduces the technical details of the underlying methodology working with tracked freehand ultrasound data, and offers a comparative analysis of submitted methods across multiple evaluation metrics. The results highlight both the progress and current limitations of state-of-the-art approaches in this domain, and inform directions for future research. The data, evaluation code, and baseline are publicly available to facilitate ongoing development and reproducibility. As a live and evolving benchmark, this Challenge is designed to be continuously developed and improved. The Challenge was held at MICCAI 2024 and will be organised again at MICCAI 2025, reflecting its growing impact and the sustained commitment to advancing this field.",
      "authors": [
        "Qi Li",
        "Shaheer U. Saeed",
        "Yuliang Huang",
        "Mingyuan Luo",
        "Zhongnuo Yan",
        "Jiongquan Chen",
        "Xin Yang",
        "Dong Ni",
        "Nektarios Winter",
        "Phuc Nguyen",
        "Lucas Steinberger",
        "Caelan Haney",
        "Yuan Zhao",
        "Mingjie Jiang",
        "Bowen Ren",
        "SiYeoul Lee",
        "Seonho Kim",
        "MinKyung Seo",
        "MinWoo Kim",
        "Yimeng Dou",
        "Zhiwei Zhang",
        "Yin Li",
        "Tomy Varghese",
        "Dean C. Barratt",
        "Matthew J. Clarkson",
        "Tom Vercauteren",
        "Yipeng Hu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T20:52:18+00:00",
          "link": "https://arxiv.org/abs/2506.21765v1",
          "size": "10379kb",
          "version": "v1"
        }
      ],
      "title": "TUS-REC2024: A Challenge to Reconstruct 3D Freehand Ultrasound Without External Tracker",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21765",
        "HTML": "https://arxiv.org/html/2506.21765v1",
        "PDF": "https://arxiv.org/pdf/2506.21765"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on 3D freehand ultrasound reconstruction without external trackers and discusses the TUS-REC2024 Challenge. It does not involve any aspect of training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21772",
      "abstract": "Recent research works establish deep neural networks as high performing tools for radar target detection, especially on challenging environments (presence of clutter or interferences, multi-target scenarii...). However, the usually large computational complexity of these networks is one of the factors preventing them from being widely implemented in embedded radar systems. We propose to investigate novel neural architecture search (NAS) methods, based on Monte-Carlo Tree Search (MCTS), for finding neural networks achieving the required detection performance and striving towards a lower computational complexity. We evaluate the searched architectures on endoclutter radar signals, in order to compare their respective performance metrics and generalization properties. A novel network satisfying the required detection probability while being significantly lighter than the expert-designed baseline is proposed.",
      "authors": [
        "No\\'e Lallouet",
        "Tristan Cazenave",
        "Cyrille Enderli",
        "St\\'ephanie Gourdin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-11T09:58:33+00:00",
          "link": "https://arxiv.org/abs/2506.21772v1",
          "size": "377kb",
          "version": "v1"
        }
      ],
      "title": "Searching Efficient Deep Architectures for Radar Target Detection using Monte-Carlo Tree Search",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21772",
        "HTML": "https://arxiv.org/html/2506.21772v1",
        "PDF": "https://arxiv.org/pdf/2506.21772"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper is about neural architecture search for radar target detection and aims to optimize computational complexity of networks. It does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21787",
      "abstract": "The cut polytope $\\operatorname{CUT}(n)$, defined as the convex hull of cut vectors in the complete graph $K_n$, is a central object in combinatorial optimization, with applications ranging from max-cut problems to correlation analysis. Building on a probabilistic interpretation via agreement probabilities among symmetric Bernoulli random variables, we derive an explicit closed-form formula for enumerating the vertices of the related polytope $1$-$\\operatorname{CUT}(n)$. Our approach is based on a natural binary encoding of cut vectors and introduces the alternating cycle function, a map that generates integer sequences with palindromic and recursive structure. This encoding directly captures the vertex structure and reveals that the scaled encoded vertices, perhaps unexpectedly, exhibit an almost-linear behaviour. This work provides the first explicit vertex enumeration formula for this classical polytope family.",
      "authors": [
        "Nevena Mari\\'c"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Discrete Mathematics (cs.DM)",
        "Optimization and Control (math.OC)",
        "Probability (math.PR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T22:02:54+00:00",
          "link": "https://arxiv.org/abs/2506.21787v1",
          "size": "36kb",
          "version": "v1"
        }
      ],
      "title": "An Explicit Formula for Vertex Enumeration in the CUT(n) Polytope via Probabilistic Methods",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21787",
        "HTML": "https://arxiv.org/html/2506.21787v1",
        "PDF": "https://arxiv.org/pdf/2506.21787"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper is related to combinatorial optimization and does not deal with LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21796",
      "abstract": "Neural network-based compression and decompression of channel state feedback has been one of the most widely studied applications of machine learning (ML) in wireless networks. Various simulation-based studies have shown that ML-based feedback compression can result in reduced overhead and more accurate channel information. However, to the best of our knowledge, there are no real-life proofs of concepts demonstrating the benefits of ML-based channel feedback compression in a practical setting, where the user equipment (UE) and base station have no access to each others' ML models. In this paper, we present a novel approach for training interoperable compression and decompression ML models in a confidential manner, and demonstrate the accuracy of the ensuing models using prototype UEs and base stations. The performance of the ML-based channel feedback is measured both in terms of the accuracy of the reconstructed channel information and achieved downlink throughput gains when using the channel information for beamforming. The reported measurement results demonstrate that it is possible to develop an accurate ML-based channel feedback link without having to share ML models between device and network vendors. These results pave the way for a practical implementation of ML-based channel feedback in commercial 6G networks.",
      "authors": [
        "Dani Korpi",
        "Rachel Wang",
        "Jerry Wang",
        "Abdelrahman Ibrahim",
        "Carl Nuzman",
        "Runxin Wang",
        "Kursat Rasim Mestav",
        "Dustin Zhang",
        "Iraj Saniee",
        "Shawn Winston",
        "Gordana Pavlovic",
        "Wei Ding",
        "William J. Hillery",
        "Chenxi Hao",
        "Ram Thirunagari",
        "Jung Chang",
        "Jeehyun Kim",
        "Bartek Kozicki",
        "Dragan Samardzija",
        "Taesang Yoo",
        "Andreas Maeder",
        "Tingfang Ji",
        "Harish Viswanathan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T22:40:03+00:00",
          "link": "https://arxiv.org/abs/2506.21796v1",
          "size": "573kb",
          "version": "v1"
        }
      ],
      "title": "Demonstrating Interoperable Channel State Feedback Compression with Machine Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21796",
        "HTML": "https://arxiv.org/html/2506.21796v1",
        "PDF": "https://arxiv.org/pdf/2506.21796"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper discusses ML-based channel state feedback compression in wireless networks, unrelated to LLM training data processing, focusing on interoperability of ML models rather than LLM data."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21802",
      "abstract": "Machine learning (ML) models always make a prediction, even when they are likely to be wrong. This causes problems in practical applications, as we do not know if we should trust a prediction. ML with reject option addresses this issue by abstaining from making a prediction if it is likely to be incorrect. In this work, we formalise the approach to ML with reject option in binary classification, deriving theoretical guarantees on the resulting error rate. This is achieved through conformal prediction (CP), which produce prediction sets with distribution-free validity guarantees. In binary classification, CP can output prediction sets containing exactly one, two or no labels. By accepting only the singleton predictions, we turn CP into a binary classifier with reject option.\n  Here, CP is formally put in the framework of predicting with reject option. We state and prove the resulting error rate, and give finite sample estimates. Numerical examples provide illustrations of derived error rate through several different conformal prediction settings, ranging from full conformal prediction to offline batch inductive conformal prediction. The former has a direct link to sharp validity guarantees, whereas the latter is more fuzzy in terms of validity guarantees but can be used in practice. Error-reject curves illustrate the trade-off between error rate and reject rate, and can serve to aid a user to set an acceptable error rate or reject rate in practice.",
      "authors": [
        "Johan Hallberg Szabadv\\'ary",
        "Tuwe L\\\"ofstr\\\"om",
        "Ulf Johansson",
        "Cecilia S\\\"onstr\\\"od",
        "Ernst Ahlberg",
        "Lars Carlsson"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T23:04:25+00:00",
          "link": "https://arxiv.org/abs/2506.21802v1",
          "size": "253kb",
          "version": "v1"
        }
      ],
      "title": "Classification with Reject Option: Distribution-free Error Guarantees via Conformal Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21802",
        "HTML": "https://arxiv.org/html/2506.21802v1",
        "PDF": "https://arxiv.org/pdf/2506.21802"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on machine learning with reject options using conformal prediction for binary classification, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21803",
      "abstract": "Electrocardiograms (ECGs) play a vital role in monitoring cardiac health and diagnosing heart diseases. However, traditional deep learning approaches for ECG analysis rely heavily on large-scale manual annotations, which are both time-consuming and resource-intensive to obtain. To overcome this limitation, self-supervised learning (SSL) has emerged as a promising alternative, enabling the extraction of robust ECG representations that can be efficiently transferred to various downstream tasks. While previous studies have explored SSL for ECG pretraining and multi-modal ECG-language alignment, they often fail to capture the multi-scale nature of ECG signals. As a result, these methods struggle to learn generalized representations due to their inability to model the hierarchical structure of ECG data. To address this gap, we introduce MELP, a novel Multi-scale ECG-Language Pretraining (MELP) model that fully leverages hierarchical supervision from ECG-text pairs. MELP first pretrains a cardiology-specific language model to enhance its understanding of clinical text. It then applies three levels of cross-modal supervision-at the token, beat, and rhythm levels-to align ECG signals with textual reports, capturing structured information across different time scales. We evaluate MELP on three public ECG datasets across multiple tasks, including zero-shot ECG classification, linear probing, and transfer learning. Experimental results demonstrate that MELP outperforms existing SSL methods, underscoring its effectiveness and adaptability across diverse clinical applications. Our code is available at https://github.com/HKU-MedAI/MELP.",
      "authors": [
        "Fuying Wang",
        "Jiacheng Xu",
        "Lequan Yu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-11T07:22:17+00:00",
          "link": "https://arxiv.org/abs/2506.21803v1",
          "size": "684kb",
          "version": "v1"
        }
      ],
      "title": "From Token to Rhythm: A Multi-Scale Approach for ECG-Language Pretraining",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21803",
        "HTML": "https://arxiv.org/html/2506.21803v1",
        "PDF": "https://arxiv.org/pdf/2506.21803"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This research is centered on self-supervised learning for ECG data and language pretraining, without discussing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21804",
      "abstract": "Current GPU-accelerated supercomputers promise to enable large-scale simulations of turbulent flows. Lattice Boltzmann Methods (LBM) are particularly well-suited to fulfilling this promise due to their intrinsic compatibility with highly parallel execution on both SIMD CPUs and GPUs. A novel LBM scheme for wall-modeled LES in complex geometries is described with a special focus on the efficient implementation in the open source LBM framework OpenLB. Detailed scalability results are provided for all HoreKa partitions, utilizing up to 128 nodes and covering problem sizes up to 18 billion cells.",
      "authors": [
        "Adrian Kummerl\\\"ander",
        "Fedor Bukreev",
        "Yuji Shimojima",
        "Shota Ito",
        "Mathias J. Krause"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computational Physics (physics.comp-ph)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Mathematical Software (cs.MS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-11T11:14:01+00:00",
          "link": "https://arxiv.org/abs/2506.21804v1",
          "size": "3885kb",
          "version": "v1"
        }
      ],
      "title": "Large-Scale Simulations of Turbulent Flows using Lattice Boltzmann Methods on Heterogeneous High Performance Computers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21804",
        "HTML": "https://arxiv.org/html/2506.21804v1",
        "PDF": "https://arxiv.org/pdf/2506.21804"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper discusses using Lattice Boltzmann Methods for simulating turbulent flows and does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21809",
      "abstract": "We propose \\textit{OpenAlpha}, a community-led strategy validation framework for decentralised capital management on a host blockchain network, which integrates game-theoretic validation, adversarial auditing, and market-based belief aggregation. This work formulates treasury deployment as a capital optimisation problem under verification costs and strategic misreporting, and operationalises it through a decision waterfall that sequences intention declaration, strategy proposal, prediction-market validation, dispute resolution, and capital allocation. Each phase of this framework's validation process embeds economic incentives to align proposer, verifier, and auditor behaviour, producing confidence scores that may feed into a capital allocation rule. While OpenAlpha is designed for capital strategy assessment, its validation mechanisms are composable and extend naturally to evaluating external decentralised applications (DApps), enabling on-chain scrutiny of DApp performance, reliability, and integration risk. This architecture allows for adaptive, trust-minimised capital deployment without reliance on centralised governance or static audits.",
      "authors": [
        "Arman Abgaryan",
        "Utkarsh Sharma"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "General Finance (q-fin.GN)",
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-13T16:59:31+00:00",
          "link": "https://arxiv.org/abs/2506.21809v1",
          "size": "128kb",
          "version": "v1"
        }
      ],
      "title": "OpenAlpha: A Community-Led Adversarial Strategy Validation Mechanism for Decentralised Capital Management",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21809",
        "HTML": "https://arxiv.org/html/2506.21809v1",
        "PDF": "https://arxiv.org/pdf/2506.21809"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on a strategy validation framework for decentralized capital management, which involves game-theoretic validation and market-based belief aggregation. It does not address any aspect of LLM training data collection, construction, or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21828",
      "abstract": "Fetal sleep is a relatively underexplored yet vital aspect of prenatal neurodevelopment. Understanding fetal sleep patterns could provide insights into early brain maturation and help clinicians detect signs of neurological compromise that arise due to fetal hypoxia or fetal growth restriction. This review synthesizes over eight decades of research on the physiological characteristics, ontogeny, and regulation of fetal sleep. We compare sleep-state patterns in humans and large animal models, highlighting species-specific differences and the presence of sleep-state analogs. We review both invasive techniques in animals and non-invasive modalities in humans. Computational methods for sleep-state classification are also examined, including rule-based approaches (with and without clustering-based preprocessing) and state-of-the-art deep learning techniques. Finally, we discuss how intrauterine conditions such as hypoxia and fetal growth restriction can disrupt fetal sleep. This review provides a comprehensive foundation for the development of objective, multimodal, and non-invasive fetal sleep monitoring technologies to support early diagnosis and intervention in prenatal care.",
      "authors": [
        "Weitao Tang",
        "Johann Vargas-Calixto",
        "Nasim Katebi",
        "Robert Galinsky",
        "Gari D. Clifford",
        "Faezeh Marzbanrad"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Neurons and Cognition (q-bio.NC)",
        "Machine Learning (cs.LG)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T00:15:57+00:00",
          "link": "https://arxiv.org/abs/2506.21828v1",
          "size": "791kb",
          "version": "v1"
        }
      ],
      "title": "Fetal Sleep: A Cross-Species Review of Physiology, Measurement, and Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21828",
        "HTML": "https://arxiv.org/html/2506.21828v1",
        "PDF": "https://arxiv.org/pdf/2506.21828"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper discusses fetal sleep patterns and classification techniques, which are unrelated to the data processing or engineering tasks for training LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21842",
      "abstract": "Quantum Machine Learning (QML) integrates quantum computing with classical machine learning, primarily to solve classification, regression and generative tasks. However, its rapid development raises critical security challenges in the Noisy Intermediate-Scale Quantum (NISQ) era. This chapter examines adversarial threats unique to QML systems, focusing on vulnerabilities in cloud-based deployments, hybrid architectures, and quantum generative models. Key attack vectors include model stealing via transpilation or output extraction, data poisoning through quantum-specific perturbations, reverse engineering of proprietary variational quantum circuits, and backdoor attacks. Adversaries exploit noise-prone quantum hardware and insufficiently secured QML-as-a-Service (QMLaaS) workflows to compromise model integrity, ownership, and functionality. Defense mechanisms leverage quantum properties to counter these threats. Noise signatures from training hardware act as non-invasive watermarks, while hardware-aware obfuscation techniques and ensemble strategies disrupt cloning attempts. Emerging solutions also adapt classical adversarial training and differential privacy to quantum settings, addressing vulnerabilities in quantum neural networks and generative architectures. However, securing QML requires addressing open challenges such as balancing noise levels for reliability and security, mitigating cross-platform attacks, and developing quantum-classical trust frameworks. This chapter summarizes recent advances in attacks and defenses, offering a roadmap for researchers and practitioners to build robust, trustworthy QML systems resilient to evolving adversarial landscapes.",
      "authors": [
        "Archisman Ghosh",
        "Satwik Kundu",
        "and Swaroop Ghosh"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T01:19:49+00:00",
          "link": "https://arxiv.org/abs/2506.21842v1",
          "size": "896kb",
          "version": "v1"
        }
      ],
      "title": "Adversarial Threats in Quantum Machine Learning: A Survey of Attacks and Defenses",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21842",
        "PDF": "https://arxiv.org/pdf/2506.21842"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on adversarial threats in Quantum Machine Learning systems and does not address the processing or construction of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21880",
      "abstract": "Interferometric Hyperspectral Imaging (IHI) is a critical technique for large-scale remote sensing tasks due to its advantages in flux and spectral resolution. However, IHI is susceptible to complex errors arising from imaging steps, and its quality is limited by existing signal processing-based reconstruction algorithms. Two key challenges hinder performance enhancement: 1) the lack of training datasets. 2) the difficulty in eliminating IHI-specific degradation components through learning-based methods. To address these challenges, we propose a novel IHI reconstruction pipeline. First, based on imaging physics and radiometric calibration data, we establish a simplified yet accurate IHI degradation model and a parameter estimation method. This model enables the synthesis of realistic IHI training datasets from hyperspectral images (HSIs), bridging the gap between IHI reconstruction and deep learning. Second, we design the Interferometric Hyperspectral Reconstruction Unfolding Transformer (IHRUT), which achieves effective spectral correction and detail restoration through a stripe-pattern enhancement mechanism and a spatial-spectral transformer architecture. Experimental results demonstrate the superior performance and generalization capability of our method.",
      "authors": [
        "Yuansheng Li",
        "Yunhao Zou",
        "Linwei Chen",
        "Ying Fu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T03:36:00+00:00",
          "link": "https://arxiv.org/abs/2506.21880v1",
          "size": "4309kb",
          "version": "v1"
        }
      ],
      "title": "Physical Degradation Model-Guided Interferometric Hyperspectral Reconstruction with Unfolding Transformer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21880",
        "HTML": "https://arxiv.org/html/2506.21880v1",
        "PDF": "https://arxiv.org/pdf/2506.21880"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper proposes a novel reconstruction pipeline for interferometric hyperspectral imaging, focusing on model design and data synthesis for hyperspectral datasets. It is unrelated to LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21884",
      "abstract": "Neural Radiance Field (NeRF)-based segmentation methods focus on object semantics and rely solely on RGB data, lacking intrinsic material properties. This limitation restricts accurate material perception, which is crucial for robotics, augmented reality, simulation, and other applications. We introduce UnMix-NeRF, a framework that integrates spectral unmixing into NeRF, enabling joint hyperspectral novel view synthesis and unsupervised material segmentation. Our method models spectral reflectance via diffuse and specular components, where a learned dictionary of global endmembers represents pure material signatures, and per-point abundances capture their distribution. For material segmentation, we use spectral signature predictions along learned endmembers, allowing unsupervised material clustering. Additionally, UnMix-NeRF enables scene editing by modifying learned endmember dictionaries for flexible material-based appearance manipulation. Extensive experiments validate our approach, demonstrating superior spectral reconstruction and material segmentation to existing methods. Project page: https://www.factral.co/UnMix-NeRF.",
      "authors": [
        "Fabian Perez",
        "Sara Rojas",
        "Carlos Hinojosa",
        "Hoover Rueda-Chac\\'on",
        "Bernard Ghanem"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T03:42:49+00:00",
          "link": "https://arxiv.org/abs/2506.21884v1",
          "size": "4042kb",
          "version": "v1"
        }
      ],
      "title": "UnMix-NeRF: Spectral Unmixing Meets Neural Radiance Fields",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21884",
        "HTML": "https://arxiv.org/html/2506.21884v1",
        "PDF": "https://arxiv.org/pdf/2506.21884"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on integrating spectral unmixing into Neural Radiance Fields for hyperspectral novel view synthesis and material segmentation, which does not involve any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21894",
      "abstract": "We propose an extension of Thompson sampling to optimization problems over function spaces where the objective is a known functional of an unknown operator's output. We assume that functional evaluations are inexpensive, while queries to the operator (such as running a high-fidelity simulator) are costly. Our algorithm employs a sample-then-optimize approach using neural operator surrogates. This strategy avoids explicit uncertainty quantification by treating trained neural operators as approximate samples from a Gaussian process. We provide novel theoretical convergence guarantees, based on Gaussian processes in the infinite-dimensional setting, under minimal assumptions. We benchmark our method against existing baselines on functional optimization tasks involving partial differential equations and other nonlinear operator-driven phenomena, demonstrating improved sample efficiency and competitive performance.",
      "authors": [
        "Rafael Oliveira",
        "Xuesong Wang",
        "Kian Ming A. Chai and Edwin V. Bonilla"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T04:21:57+00:00",
          "link": "https://arxiv.org/abs/2506.21894v1",
          "size": "2423kb",
          "version": "v1"
        }
      ],
      "title": "Thompson Sampling in Function Spaces via Neural Operators",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21894",
        "HTML": "https://arxiv.org/html/2506.21894v1",
        "PDF": "https://arxiv.org/pdf/2506.21894"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper presents an optimization algorithm using neural operators in function spaces. It does not address any aspect of training data processing for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21921",
      "abstract": "Anomaly detection is the task of identifying rarely occurring (i.e. anormal or anomalous) samples that differ from almost all other samples in a dataset. As the patterns of anormal samples are usually not known a priori, this task is highly challenging. Consequently, anomaly detection lies between semi- and unsupervised learning. The detection of anomalies in sound data, often called 'ASD' (Anomalous Sound Detection), is a sub-field that deals with the identification of new and yet unknown effects in acoustic recordings. It is of great importance for various applications in Industry 4.0. Here, vibrational or acoustic data are typically obtained from standard sensor signals used for predictive maintenance. Examples cover machine condition monitoring or quality assurance to track the state of components or products. However, the use of intelligent algorithms remains a controversial topic. Management generally aims for cost-reduction and automation, while quality and maintenance experts emphasize the need for human expertise and comprehensible solutions. In this work, we present an anomaly detection approach specifically designed for spectrograms. The approach is based on statistical evaluations and is theoretically motivated. In addition, it features intrinsic explainability, making it particularly suitable for applications in industrial settings. Thus, this algorithm is of relevance for applications in which black-box algorithms are unwanted or unsuitable.",
      "authors": [
        "Nicolas Thewes",
        "Philipp Steinhauer",
        "Patrick Trampert",
        "Markus Pauly and Georg Schneider"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Applications (stat.AP)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)",
        "Computation (stat.CO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T05:21:20+00:00",
          "link": "https://arxiv.org/abs/2506.21921v1",
          "size": "1969kb",
          "version": "v1"
        }
      ],
      "title": "Explainable anomaly detection for sound spectrograms using pooling statistics with quantile differences",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21921",
        "PDF": "https://arxiv.org/pdf/2506.21921"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This work focuses on explainable anomaly detection in sound spectrograms, which is unrelated to processing or constructing training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21936",
      "abstract": "$ n-$cycle permutation polynomials with small n have the advantage that their compositional inverses are efficient in terms of implementation. These permutation polynomials have significant applications in cryptography and coding theory. In this article, we propose criteria for the construction of $ n-$cycle permutation using linearized polynomial $ L(x) $ for larger $ n $. Furthermore, we investigate and generalize certain novel forms of $ n-$cycle permutation polynomials. Finally, we demonstrate our approach by constructing explicit $ n-$cycle permutation of the form $ L(x)+\\gamma h(Tr_{q^{m}/q}(x)) $, and $ G(x)+\\gamma f(x) $ with a Boolean function $ f(x) $. The polynomial $ x^{d}+\\gamma f(x) $ with $ f(x) $ being a Boolean function is shown to be quadruple and quintuple permutation polynomials. Moreover, linear binomial triple-cycle permutation polynomials are constructed.",
      "authors": [
        "Varsha Jarali",
        "Prasanna Poojary",
        "and Vadiraja Bhatta G. R"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Rings and Algebras (math.RA)",
        "Information Theory (cs.IT)",
        "Combinatorics (math.CO)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T06:15:45+00:00",
          "link": "https://arxiv.org/abs/2506.21936v1",
          "size": "13kb",
          "version": "v1"
        }
      ],
      "title": "Some more constructions of $n-$cycle permutation polynomials",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21936",
        "HTML": "https://arxiv.org/html/2506.21936v1",
        "PDF": "https://arxiv.org/pdf/2506.21936"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The article explores construction techniques for n-cycle permutation polynomials, relevant to cryptography and coding theory but not related to the construction or processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21964",
      "abstract": "Selecting prior distributions in Bayesian statistics is challenging, resource-intensive, and subjective. We analyze using large-language models (LLMs) to suggest suitable, knowledge-based informative priors. We developed an extensive prompt asking LLMs not only to suggest priors but also to verify and reflect on their choices.\n  We evaluated Claude Opus, Gemini 2.5 Pro, and ChatGPT-4o-mini on two real datasets: heart disease risk and concrete strength. All LLMs correctly identified the direction for all associations (e.g., that heart disease risk is higher for males). The quality of suggested priors was measured by their Kullback-Leibler divergence from the maximum likelihood estimator's distribution.\n  The LLMs suggested both moderately and weakly informative priors. The moderate priors were often overconfident, resulting in distributions misaligned with the data. In our experiments, Claude and Gemini provided better priors than ChatGPT. For weakly informative priors, a key performance difference emerged: ChatGPT and Gemini defaulted to an \"unnecessarily vague\" mean of 0, while Claude did not, demonstrating a significant advantage.\n  The ability of LLMs to identify correct associations shows their great potential as an efficient, objective method for developing informative priors. However, the primary challenge remains in calibrating the width of these priors to avoid over- and under-confidence.",
      "authors": [
        "Michael A. Riegler",
        "Kristoffer Herland Hellton",
        "Vajira Thambawita",
        "Hugo L. Hammer"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Methodology (stat.ME)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T07:11:55+00:00",
          "link": "https://arxiv.org/abs/2506.21964v1",
          "size": "709kb",
          "version": "v1"
        }
      ],
      "title": "Using Large Language Models to Suggest Informative Prior Distributions in Bayesian Statistics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21964",
        "HTML": "https://arxiv.org/html/2506.21964v1",
        "PDF": "https://arxiv.org/pdf/2506.21964"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on using LLMs for suggesting informative prior distributions in Bayesian statistics, rather than on the processing of training data for LLMs. There is no mention of data engineering aspects relevant to LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21977",
      "abstract": "Diffusion-based image compression has shown remarkable potential for achieving ultra-low bitrate coding (less than 0.05 bits per pixel) with high realism, by leveraging the generative priors of large pre-trained text-to-image diffusion models. However, current approaches require a large number of denoising steps at the decoder to generate realistic results under extreme bitrate constraints, limiting their application in real-time compression scenarios. Additionally, these methods often sacrifice reconstruction fidelity, as diffusion models typically fail to guarantee pixel-level consistency. To address these challenges, we introduce StableCodec, which enables one-step diffusion for high-fidelity and high-realism extreme image compression with improved coding efficiency. To achieve ultra-low bitrates, we first develop an efficient Deep Compression Latent Codec to transmit a noisy latent representation for a single-step denoising process. We then propose a Dual-Branch Coding Structure, consisting of a pair of auxiliary encoder and decoder, to enhance reconstruction fidelity. Furthermore, we adopt end-to-end optimization with joint bitrate and pixel-level constraints. Extensive experiments on the CLIC 2020, DIV2K, and Kodak dataset demonstrate that StableCodec outperforms existing methods in terms of FID, KID and DISTS by a significant margin, even at bitrates as low as 0.005 bits per pixel, while maintaining strong fidelity. Additionally, StableCodec achieves inference speeds comparable to mainstream transform coding schemes. All source code are available at https://github.com/LuizScarlet/StableCodec.",
      "authors": [
        "Tianyu Zhang",
        "Xin Luo",
        "Li Li",
        "Dong Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T07:39:21+00:00",
          "link": "https://arxiv.org/abs/2506.21977v1",
          "size": "10558kb",
          "version": "v1"
        }
      ],
      "title": "StableCodec: Taming One-Step Diffusion for Extreme Image Compression",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21977",
        "PDF": "https://arxiv.org/pdf/2506.21977"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper introduces StableCodec for image compression using diffusion models. It does not involve any methodology related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21988",
      "abstract": "Delegated quantum computing (DQC) allows clients with low quantum capabilities to outsource computations to a server hosting a quantum computer. This process is typically envisioned within the measurement-based quantum computing framework, as it naturally facilitates blindness of inputs and computation. Hence, the overall process of setting up and conducting the computation encompasses a sequence of three stages: preparing the qubits, entangling the qubits to obtain the resource state, and measuring the qubits to run the computation. There are two primary approaches to distributing these stages between the client and the server that impose different constraints on cryptographic techniques and experimental implementations. In the prepare-and-send setting, the client prepares the qubits and sends them to the server, while in the receive-and-measure setting, the client receives the qubits from the server and measures them. Although these settings have been extensively studied independently, their interrelation and whether setting-dependent theoretical constraints are inevitable remain unclear. By implementing the key components of most DQC protocols in the respective missing setting, we provide a method to build prospective protocols in both settings simultaneously and to translate existing protocols from one setting into the other.",
      "authors": [
        "Fabian Wiesner",
        "Jens Eisert",
        "Anna Pappa"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T07:54:43+00:00",
          "link": "https://arxiv.org/abs/2506.21988v1",
          "size": "42kb",
          "version": "v1"
        }
      ],
      "title": "Unifying communication paradigms in delegated quantum computing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21988",
        "HTML": "https://arxiv.org/html/2506.21988v1",
        "PDF": "https://arxiv.org/pdf/2506.21988"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This research is centered on quantum computing and the communication paradigms within delegated quantum computing, with no connection to LLM data engineering or training-stage data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22001",
      "abstract": "Current multi-channel speech enhancement systems mainly adopt single-output architecture, which face significant challenges in preserving spatio-temporal signal integrity during multiple-input multiple-output (MIMO) processing. To address this limitation, we propose a novel neural network, termed WTFormer, for MIMO speech enhancement that leverages the multi-resolution characteristics of wavelet transform and multi-dimensional collaborative attention to effectively capture globally distributed spatial features, while using Conformer for time-frequency modeling. A multi task loss strategy accompanying MUSIC algorithm is further proposed for optimization training to protect spatial information to the greatest extent. Experimental results on the LibriSpeech dataset show that WTFormer can achieve comparable denoising performance to advanced systems while preserving more spatial information with only 0.98M parameters.",
      "authors": [
        "Lu Han",
        "Junqi Zhao",
        "Renhua Peng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T08:14:17+00:00",
          "link": "https://arxiv.org/abs/2506.22001v1",
          "size": "829kb",
          "version": "v1"
        }
      ],
      "title": "WTFormer: A Wavelet Conformer Network for MIMO Speech Enhancement with Spatial Cues Peservation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22001",
        "HTML": "https://arxiv.org/html/2506.22001v1",
        "PDF": "https://arxiv.org/pdf/2506.22001"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The work focuses on MIMO speech enhancement with neural networks, not on LLM training data or any related data engineering tasks for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22012",
      "abstract": "The generalization of deep learning-based low-dose computed tomography (CT) reconstruction models to doses unseen in the training data is important and remains challenging. Previous efforts heavily rely on paired data to improve the generalization performance and robustness through collecting either diverse CT data for re-training or a few test data for fine-tuning. Recently, diffusion models have shown promising and generalizable performance in low-dose CT (LDCT) reconstruction, however, they may produce unrealistic structures due to the CT image noise deviating from Gaussian distribution and imprecise prior information from the guidance of noisy LDCT images. In this paper, we propose a noise-inspired diffusion model for generalizable LDCT reconstruction, termed NEED, which tailors diffusion models for noise characteristics of each domain. First, we propose a novel shifted Poisson diffusion model to denoise projection data, which aligns the diffusion process with the noise model in pre-log LDCT projections. Second, we devise a doubly guided diffusion model to refine reconstructed images, which leverages LDCT images and initial reconstructions to more accurately locate prior information and enhance reconstruction fidelity. By cascading these two diffusion models for dual-domain reconstruction, our NEED requires only normal-dose data for training and can be effectively extended to various unseen dose levels during testing via a time step matching strategy. Extensive qualitative, quantitative, and segmentation-based evaluations on two datasets demonstrate that our NEED consistently outperforms state-of-the-art methods in reconstruction and generalization performance. Source code is made available at https://github.com/qgao21/NEED.",
      "authors": [
        "Qi Gao",
        "Zhihao Chen",
        "Dong Zeng",
        "Junping Zhang",
        "Jianhua Ma",
        "Hongming Shan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T08:24:55+00:00",
          "link": "https://arxiv.org/abs/2506.22012v1",
          "size": "10502kb",
          "version": "v1"
        }
      ],
      "title": "Noise-Inspired Diffusion Model for Generalizable Low-Dose CT Reconstruction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22012",
        "HTML": "https://arxiv.org/html/2506.22012v1",
        "PDF": "https://arxiv.org/pdf/2506.22012"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper proposes methods for CT reconstruction using diffusion models, unrelated to the processing of training data for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22041",
      "abstract": "White matter hyperintensities (WMH) are radiological markers of small vessel disease and neurodegeneration, whose accurate segmentation and spatial localization are crucial for diagnosis and monitoring. While multimodal MRI offers complementary contrasts for detecting and contextualizing WM lesions, existing approaches often lack flexibility in handling missing modalities and fail to integrate anatomical localization efficiently. We propose a deep learning framework for WM lesion segmentation and localization that operates directly in native space using single- and multi-modal MRI inputs. Our study evaluates four input configurations: FLAIR-only, T1-only, concatenated FLAIR and T1, and a modality-interchangeable setup. It further introduces a multi-task model for jointly predicting lesion and anatomical region masks to estimate region-wise lesion burden. Experiments conducted on the MICCAI WMH Segmentation Challenge dataset demonstrate that multimodal input significantly improves the segmentation performance, outperforming unimodal models. While the modality-interchangeable setting trades accuracy for robustness, it enables inference in cases with missing modalities. Joint lesion-region segmentation using multi-task learning was less effective than separate models, suggesting representational conflict between tasks. Our findings highlight the utility of multimodal fusion for accurate and robust WMH analysis, and the potential of joint modeling for integrated predictions.",
      "authors": [
        "Julia Machnio",
        "Sebastian N{\\o}rgaard Llambias",
        "Mads Nielsen",
        "Mostafa Mehdipour Ghazi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T09:39:26+00:00",
          "link": "https://arxiv.org/abs/2506.22041v1",
          "size": "6919kb",
          "version": "v1"
        }
      ],
      "title": "Towards Scalable and Robust White Matter Lesion Localization via Multimodal Deep Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22041",
        "HTML": "https://arxiv.org/html/2506.22041v1",
        "PDF": "https://arxiv.org/pdf/2506.22041"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The research involves multimodal deep learning for medical imaging, addressing lesion localization in MRI scans, without any focus on LLM training data processes."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22106",
      "abstract": "Pinsker's classical inequality asserts that the total variation $TV(\\mu, \\nu)$ between two probability measures is bounded by $\\sqrt{ 2H(\\mu|\\nu)}$ where $H$ denotes the relative entropy (or Kullback-Leibler divergence). Considering the discrete metric, $TV$ can be seen as a Wasserstein distance and as such possesses an adapted variant $ATV$. Adapted Wasserstein distances have distinct advantages over their classical counterparts when $\\mu, \\nu$ are the laws of stochastic processes $(X_k)_{k=1}^n, (Y_k)_{k=1}^n$ and exhibit numerous applications from stochastic control to machine learning. In this note we observe that the adapted total variation distance $ATV$ satisfies the Pinsker-type inequality $$ ATV(\\mu, \\nu)\\leq \\sqrt{n} \\sqrt{2 H(\\mu|\\nu)}.$$",
      "authors": [
        "Mathias Beiglb\\\"ock and Markus Zona"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Probability (math.PR)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T10:35:58+00:00",
          "link": "https://arxiv.org/abs/2506.22106v1",
          "size": "260kb",
          "version": "v1"
        }
      ],
      "title": "Pinsker's inequality for adapted total variation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22106",
        "HTML": "https://arxiv.org/html/2506.22106v1",
        "PDF": "https://arxiv.org/pdf/2506.22106"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper discusses a mathematical inequality related to total variation and entropy, with no focus on training data processing or LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22108",
      "abstract": "In this study we investigate how hierarchical structures within the Roman Catholic Church shape the ideological orientation of its leadership. The full episcopal genealogy dataset comprises over 35,000 bishops, each typically consecrated by one principal consecrator and two co-consecrators, forming a dense and historically continuous directed network of episcopal lineage. Within this broader structure, we focus on a dataset of 245 living cardinals to examine whether genealogical proximity correlates with doctrinal alignment on a broad set of theological and sociopolitical issues. We identify motifs that capture recurring patterns of lineage, such as shared consecrators or co-consecrators. In parallel, we apply natural language processing techniques to extract each cardinal's publicly stated positions on ten salient topics, including LGBTQIA+ rights, women's roles in the Church, liturgy, bioethics, priestly celibacy, and migration. Our results show that cardinals linked by specific genealogical motifs, particularly those who share the same principal consecrator, are significantly more likely to exhibit ideological similarity. We find that the influence of pope John Paul II persists through the bishops he consecrated, who demonstrate systematically more conservative views than their peers. These findings underscore the role of hierarchical mentorship in shaping ideological coherence within large-scale religious institutions. Our contribution offers quantitative evidence that institutional lineages, beyond individual background factors, may have an impact on the transmission and consolidation of doctrinal positions over time.",
      "authors": [
        "Marta Baratto",
        "Ivan Casanovas",
        "Ivan Decostanzi",
        "Henrique M. Borges",
        "Samuel Mart\\'inez Alcal\\'a",
        "Ilaria Stanzani",
        "Alberto Antonioni",
        "Iacopo Iacopini",
        "Michele Re Fiorentin",
        "Eugenio Valdano"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Physics and Society (physics.soc-ph)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T10:37:46+00:00",
          "link": "https://arxiv.org/abs/2506.22108v1",
          "size": "1236kb",
          "version": "v1"
        }
      ],
      "title": "The relationship between episcopal genealogy and ideology in the Roman Catholic Church",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22108",
        "HTML": "https://arxiv.org/html/2506.22108v1",
        "PDF": "https://arxiv.org/pdf/2506.22108"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper involves natural language processing to analyze bishops' ideological positions, its primary focus is on analyzing hierarchical structures rather than proposing new methods for LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22119",
      "abstract": "Elite football is believed to have evolved in recent years, but systematic evidence for the pace and form of that change is sparse. Drawing on event-level records for 13,067 matches in ten top-tier men's and women's leagues in England, Spain, Germany, Italy, and the United States (2020-2025), we quantify match dynamics with two views: conventional performance statistics and pitch-passing networks that track ball movement among a grid of pitch (field) regions. Between 2020 and 2025, average passing volume, pass accuracy, and the percent of passes made under pressure all rose. In general, the largest year-on-year changes occurred in women's competitions. Network measures offer alternative but complementary perspectives on the changing gameplay in recent years, normalized outreach in the pitch passing networks decreased, while the average shortest path lengths increased, indicating a wider ball circulation. Together, these indicators point to a sustained intensification of collective play across contemporary professional football.",
      "authors": [
        "Rebecca Carstens",
        "Raj Deshpande",
        "Pau Esteve",
        "Nicol\\`o Fidelibus",
        "Sara Linde Neven",
        "Ramona Ottow",
        "Lokamruth K. R.",
        "Paula Rodr\\'iguez-S\\'anchez",
        "Luca Santagata",
        "Javier M. Buld\\'u",
        "Brennan Klein",
        "Maddalena Torricelli"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Physics and Society (physics.soc-ph)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T10:55:20+00:00",
          "link": "https://arxiv.org/abs/2506.22119v1",
          "size": "690kb",
          "version": "v1"
        }
      ],
      "title": "Harder, shorter, sharper, forward: A comparison of women's and men's elite football gameplay (2020-2025)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22119",
        "HTML": "https://arxiv.org/html/2506.22119v1",
        "PDF": "https://arxiv.org/pdf/2506.22119"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper discusses the evolution of gameplay in elite football using statistical and network analysis but does not involve the processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22136",
      "abstract": "Comorbidity networks, which capture disease-disease co-occurrence usually based on electronic health records, reveal structured patterns in how diseases cluster and progress across individuals. However, how these networks evolve across different age groups and how this evolution relates to properties like disease prevalence and mortality remains understudied. To address these issues, we used publicly available comorbidity networks extracted from a comprehensive dataset of 45 million Austrian hospital stays from 1997 to 2014, covering 8.9 million patients. These networks grow and become denser with age. We identified groups of diseases that exhibit similar patterns of structural centrality throughout the lifespan, revealing three dominant age-related components with peaks in early childhood, midlife, and late life. To uncover the drivers of this structural change, we examined the relationship between prevalence and degree. This allowed us to identify conditions that were disproportionately connected to other diseases. Using betweenness centrality in combination with mortality data, we further identified high-mortality bridging diseases. Several diseases show high connectivity relative to their prevalence, such as iron deficiency anemia (D50) in children, nicotine dependence (F17), and lipoprotein metabolism disorders (E78) in adults. We also highlight structurally central diseases with high mortality that emerge at different life stages, including cancers (C group), liver cirrhosis (K74), subarachnoid hemorrhage (I60), and chronic kidney disease (N18). These findings underscore the importance of targeting age-specific, network-central conditions with high mortality for prevention and integrated care.",
      "authors": [
        "Yuri Gardinazzi",
        "Roger Gonzal\\'ez March",
        "Suprabhath Kalahasti",
        "Andrea Monta\\~no Ramirez",
        "Matteo Neri",
        "Cicely Nguyen",
        "Giovanni Palermo",
        "Erik Weis",
        "Katharina Ledebur",
        "Elma Dervi\\'c"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Physics and Society (physics.soc-ph)",
        "Social and Information Networks (cs.SI)",
        "Medical Physics (physics.med-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T11:24:19+00:00",
          "link": "https://arxiv.org/abs/2506.22136v1",
          "size": "7351kb",
          "version": "v1"
        }
      ],
      "title": "Characterization Of Diseases In Temporal Comorbidity Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22136",
        "HTML": "https://arxiv.org/html/2506.22136v1",
        "PDF": "https://arxiv.org/pdf/2506.22136"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper examines temporal changes in comorbidity networks for diseases but does not involve any aspect of LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22204",
      "abstract": "Physics phenomena are often described by ordinary and/or partial differential equations (ODEs/PDEs), and solved analytically or numerically. Unfortunately, many real-world systems are described only approximately with missing or unknown terms in the equations. This makes the distribution of the physics model differ from the true data-generating process (DGP). Using limited and unpaired data between DGP observations and the imperfect model simulations, we investigate this particular setting by completing the known-physics model, combining theory-driven models and data-driven to describe the shifted distribution involved in the DGP. We present a novel hybrid generative model approach combining deep grey-box modelling with Optimal Transport (OT) methods to enhance incomplete physics models. Our method implements OT maps in data space while maintaining minimal source distribution distortion, demonstrating superior performance in resolving the unpaired problem and ensuring correct usage of physics parameters. Unlike black-box alternatives, our approach leverages physics-based inductive biases to accurately learn system dynamics while preserving interpretability through its domain knowledge foundation. Experimental results validate our method's effectiveness in both generation tasks and model transparency, offering detailed insights into learned physics dynamics.",
      "authors": [
        "Gurjeet Sangra Singh",
        "Maciej Falkiewicz",
        "Alexandros Kalousis"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T13:23:27+00:00",
          "link": "https://arxiv.org/abs/2506.22204v1",
          "size": "2010kb",
          "version": "v1"
        }
      ],
      "title": "Hybrid Generative Modeling for Incomplete Physics: Deep Grey-Box Meets Optimal Transport",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22204",
        "HTML": "https://arxiv.org/html/2506.22204v1",
        "PDF": "https://arxiv.org/pdf/2506.22204"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper proposes a hybrid generative modeling approach for incomplete physics models, incorporating deep grey-box modeling and Optimal Transport. It does not pertain to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22222",
      "abstract": "Purpose: Aortic dissections are life-threatening cardiovascular conditions requiring accurate segmentation of true lumen (TL), false lumen (FL), and false lumen thrombosis (FLT) from CTA images for effective management. Manual segmentation is time-consuming and variable, necessitating automated solutions. Materials and Methods: We developed four deep learning-based pipelines for Type B aortic dissection segmentation: a single-step model, a sequential model, a sequential multi-task model, and an ensemble model, utilizing 3D U-Net and Swin-UnetR architectures. A dataset of 100 retrospective CTA images was split into training (n=80), validation (n=10), and testing (n=10). Performance was assessed using the Dice Coefficient and Hausdorff Distance. Results: Our approach achieved superior segmentation accuracy, with Dice Coefficients of 0.91 $\\pm$ 0.07 for TL, 0.88 $\\pm$ 0.18 for FL, and 0.47 $\\pm$ 0.25 for FLT, outperforming Yao et al. (1), who reported 0.78 $\\pm$ 0.20, 0.68 $\\pm$ 0.18, and 0.25 $\\pm$ 0.31, respectively. Conclusion: The proposed pipelines provide accurate segmentation of TBAD features, enabling derivation of morphological parameters for surveillance and treatment planning",
      "authors": [
        "Hao Xu",
        "Ruth Lim",
        "Brian E. Chapman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T13:38:33+00:00",
          "link": "https://arxiv.org/abs/2506.22222v1",
          "size": "1744kb",
          "version": "v1"
        }
      ],
      "title": "Advanced Deep Learning Techniques for Automated Segmentation of Type B Aortic Dissections",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22222",
        "HTML": "https://arxiv.org/html/2506.22222v1",
        "PDF": "https://arxiv.org/pdf/2506.22222"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper deals with automated segmentation of medical images using deep learning, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22226",
      "abstract": "Automatic detection and classification of Cardiovascular disease (CVD) from Computed Tomography (CT) images play an important part in facilitating better-informed clinical decisions. However, most of the recent deep learning based methods either directly work on raw CT data or utilize it in pair with anatomical cardiac structure segmentation by training an end-to-end classifier. As such, these approaches become much more difficult to interpret from a clinical perspective. To address this challenge, in this work, we break down the CVD classification pipeline into three components: (i) image segmentation, (ii) image registration, and (iii) downstream CVD classification. Specifically, we utilize the Atlas-ISTN framework and recent segmentation foundational models to generate anatomical structure segmentation and a normative healthy atlas. These are further utilized to extract clinically interpretable radiomic features as well as deformation field based geometric features (through atlas registration) for CVD classification. Our experiments on the publicly available ASOCA dataset show that utilizing these features leads to better CVD classification accuracy (87.50\\%) when compared against classification model trained directly on raw CT images (67.50\\%). Our code is publicly available: https://github.com/biomedia-mira/grc-net",
      "authors": [
        "Ajay Mittal",
        "Raghav Mehta",
        "Omar Todd",
        "Philipp Seeb\\\"ock",
        "Georg Langs",
        "Ben Glocker"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T13:43:05+00:00",
          "link": "https://arxiv.org/abs/2506.22226v1",
          "size": "4469kb",
          "version": "v1"
        }
      ],
      "title": "Cardiovascular disease classification using radiomics and geometric features from cardiac CT",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22226",
        "HTML": "https://arxiv.org/html/2506.22226v1",
        "PDF": "https://arxiv.org/pdf/2506.22226"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper is focused on the classification of Cardiovascular disease using CT images and does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22228",
      "abstract": "Single-cell sequencing is revolutionizing biology by enabling detailed investigations of cell-state transitions. Many biological processes unfold along continuous trajectories, yet it remains challenging to extract smooth, low-dimensional representations from inherently noisy, high-dimensional single-cell data. Neighbor embedding (NE) algorithms, such as t-SNE and UMAP, are widely used to embed high-dimensional single-cell data into low dimensions. But they often introduce undesirable distortions, resulting in misleading interpretations. Existing evaluation methods for NE algorithms primarily focus on separating discrete cell types rather than capturing continuous cell-state transitions, while dynamic modeling approaches rely on strong assumptions about cellular processes and specialized data. To address these challenges, we build on the Predictability-Computability-Stability (PCS) framework for reliable and reproducible data-driven discoveries. First, we systematically evaluate popular NE algorithms through empirical analysis, simulation, and theory, and reveal their key shortcomings, such as artifacts and instability. We then introduce NESS, a principled and interpretable machine learning approach to improve NE representations by leveraging algorithmic stability and to enable robust inference of smooth biological structures. NESS offers useful concepts, quantitative stability metrics, and efficient computational workflows to uncover developmental trajectories and cell-state transitions in single-cell data. Finally, we apply NESS to six single-cell datasets, spanning pluripotent stem cell differentiation, organoid development, and multiple tissue-specific lineage trajectories. Across these diverse contexts, NESS consistently yields useful biological insights, such as identification of transitional and stable cell states and quantification of transcriptional dynamics during development.",
      "authors": [
        "Rong Ma",
        "Xi Li",
        "Jingyuan Hu and Bin Yu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Genomics (q-bio.GN)",
        "Applications (stat.AP)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T13:45:55+00:00",
          "link": "https://arxiv.org/abs/2506.22228v1",
          "size": "17432kb",
          "version": "v1"
        }
      ],
      "title": "Uncovering smooth structures in single-cell data with PCS-guided neighbor embeddings",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22228",
        "HTML": "https://arxiv.org/html/2506.22228v1",
        "PDF": "https://arxiv.org/pdf/2506.22228"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The focus of this paper is on improving neighbor embedding algorithms for single-cell data analysis, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22236",
      "abstract": "The integration of the history and philosophy of statistics was initiated at least by Hacking (1965) and advanced by Mayo (1996), but it has not received sustained follow-up. Yet such integration is more urgent than ever, as the recent success of artificial intelligence has been driven largely by machine learning -- a field historically developed alongside statistics. Today, the boundary between statistics and machine learning is increasingly blurred. What we now need is integration, twice over: of history and philosophy, and of the field they engage -- statistics and machine learning. I present a case study of a philosophical idea in machine learning (and in formal epistemology) whose root can be traced back to an often under-appreciated insight in Neyman and Pearson's 1936 work (a follow-up to their 1933 classic). This leads to the articulation of a foundational assumption -- largely implicit in, but shared by, the practices of frequentist statistics and machine learning -- which I call achievabilism. Another integration also emerges at the level of methodology, combining two ends of the philosophy of science spectrum: history and philosophy of science on the one hand, and formal epistemology on the other hand.",
      "authors": [
        "Hanti Lin"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Other Statistics (stat.OT)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T13:59:08+00:00",
          "link": "https://arxiv.org/abs/2506.22236v1",
          "size": "616kb",
          "version": "v1"
        }
      ],
      "title": "A Plea for History and Philosophy of Statistics and Machine Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22236",
        "HTML": "https://arxiv.org/html/2506.22236v1",
        "PDF": "https://arxiv.org/pdf/2506.22236"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper discusses the integration of history and philosophy in the fields of statistics and machine learning, without addressing any concrete aspects of LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22273",
      "abstract": "This work focuses on a phase field approximation of Plateau's problem. Inspired by Reifenberg's point of view, we introduce a model that combines the Ambrosio-Torterelli energy with a geodesic distance term, which can be considered as a generalization of the approach developed by Bonnivard, Lemenant and Santambrogio to approximate solutions to Steiner's problem. First, we present a Gamma-convergence analysis of this model in the simple case of a single curve located on the edge of a cylinder. In a numerical section, we detail the numerical optimisation schemes used to minimize this energy for numerous examples, for which good approximations of solutions to Plateau's problem are found.",
      "authors": [
        "Matthieu Bonnivard",
        "Elie Bretin",
        "Antoine Lemenant and Eve Machefert"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Numerical Analysis (cs.NA)",
        "Analysis of PDEs (math.AP)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T14:43:14+00:00",
          "link": "https://arxiv.org/abs/2506.22273v1",
          "size": "6521kb",
          "version": "v1"
        }
      ],
      "title": "Phase field approximation for Plateau's problem: a curve geodesic distance penalty approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22273",
        "HTML": "https://arxiv.org/html/2506.22273v1",
        "PDF": "https://arxiv.org/pdf/2506.22273"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper addresses a mathematical approach to Plateau's problem in geometry using phase field approximations and geodesic distance, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22280",
      "abstract": "3D Cone-Beam CT (CBCT) is widely used in radiotherapy but suffers from motion artifacts due to breathing. A common clinical approach mitigates this by sorting projections into respiratory phases and reconstructing images per phase, but this does not account for breathing variability. Dynamic CBCT instead reconstructs images at each projection, capturing continuous motion without phase sorting. Recent advancements in 4D Gaussian Splatting (4DGS) offer powerful tools for modeling dynamic scenes, yet their application to dynamic CBCT remains underexplored. Existing 4DGS methods, such as HexPlane, use implicit motion representations, which are computationally expensive. While explicit low-rank motion models have been proposed, they lack spatial regularization, leading to inconsistencies in Gaussian motion. To address these limitations, we introduce a free-form deformation (FFD)-based spatial basis function and a deformation-informed framework that enforces consistency by coupling the temporal evolution of Gaussian's mean position, scale, and rotation under a unified deformation field. We evaluate our approach on six CBCT datasets, demonstrating superior image quality with a 6x speedup over HexPlane. These results highlight the potential of deformation-informed 4DGS for efficient, motion-compensated CBCT reconstruction. The code is available at https://github.com/Yuliang-Huang/DIGS.",
      "authors": [
        "Yuliang Huang",
        "Imraj Singh",
        "Thomas Joyce",
        "Kris Thielemans",
        "Jamie R. McClelland"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T14:48:59+00:00",
          "link": "https://arxiv.org/abs/2506.22280v1",
          "size": "823kb",
          "version": "v1"
        }
      ],
      "title": "DIGS: Dynamic CBCT Reconstruction using Deformation-Informed 4D Gaussian Splatting and a Low-Rank Free-Form Deformation Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22280",
        "HTML": "https://arxiv.org/html/2506.22280v1",
        "PDF": "https://arxiv.org/pdf/2506.22280"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper is about improving dynamic CBCT reconstruction using 4D Gaussian Splatting and a deformation model. There is no mention of LLM training data processing or related data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22318",
      "abstract": "The institution of money can be seen as a foundational social mechanism, enabling communities to quantify collectively regulate economic processes. Money can be said, indeed, to constitute the micro-macro link in economics. This paper reviews influential views on the nature of money in economics and sociology, contrasting them to the relatively limited findings of recent agent-based models of \"the emergence of money\". Noting ample room for novel combinations of sociological and formal methods to drive insight into the many roles played by money in the economy, we conclude by indicating research directions in which we believe this combination can provide new answers to old questions in monetary theory",
      "authors": [
        "Eduardo Coltre Ferraciolli and Tanya V. Ara\\'ujo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Physics and Society (physics.soc-ph)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T15:32:08+00:00",
          "link": "https://arxiv.org/abs/2506.22318v1",
          "size": "427kb",
          "version": "v1"
        }
      ],
      "title": "Agent-based modeling and the sociology of money: some suggestions for refining monetary theory using social simulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22318",
        "PDF": "https://arxiv.org/pdf/2506.22318"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper discusses monetary theory and agent-based modeling, with no mention of LLM training data processing or data engineering tasks relevant to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22319",
      "abstract": "We present a rigorous asymptotic analysis framework for investigating the thermal conductivity of shell lattice metamaterials, extending prior work from mechanical stiffness to heat transfer. Central to our analysis is a new metric, the asymptotic directional conductivity (ADC), which captures the leading-order influence of the middle surface geometry on the effective thermal conductivity in the vanishing-thickness limit. A convergence theorem is established for evaluating ADC, along with a sharp upper bound and the necessary and sufficient condition for achieving this bound. These results provide the first theoretical justification for the optimal thermal conductivity of triply periodic minimal surfaces. Furthermore, we show that ADC yields a third-order approximation to the effective conductivity of shell lattices at low volume fractions. To support practical design applications, we develop a discrete algorithm for computing and optimizing ADC over arbitrary periodic surfaces. Numerical results confirm the theoretical predictions and demonstrate the robustness and effectiveness of the proposed optimization algorithm.",
      "authors": [
        "Di Zhang and Ligang Liu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Analysis of PDEs (math.AP)",
        "Graphics (cs.GR)",
        "Mathematical Physics (math-ph)",
        "Mathematical Physics (math.MP)",
        "Computational Physics (physics.comp-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T15:34:13+00:00",
          "link": "https://arxiv.org/abs/2506.22319v1",
          "size": "8610kb",
          "version": "v1"
        }
      ],
      "title": "Asymptotic analysis and design of shell-based thermal lattice metamaterials",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22319",
        "HTML": "https://arxiv.org/html/2506.22319v1",
        "PDF": "https://arxiv.org/pdf/2506.22319"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper deals with thermal conductivity in shell lattice metamaterials and carries out an asymptotic analysis, unrelated to any aspect of LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22335",
      "abstract": "We show that recurrent quantum reservoir computers (QRCs) and their recurrence-free architectures (RF-QRCs) are robust tools for learning and forecasting chaotic dynamics from time-series data. First, we formulate and interpret quantum reservoir computers as coupled dynamical systems, where the reservoir acts as a response system driven by training data; in other words, quantum reservoir computers are generalized-synchronization (GS) systems. Second, we show that quantum reservoir computers can learn chaotic dynamics and their invariant properties, such as Lyapunov spectra, attractor dimensions, and geometric properties such as the covariant Lyapunov vectors. This analysis is enabled by deriving the Jacobian of the quantum reservoir update. Third, by leveraging tools from generalized synchronization, we provide a method for designing robust quantum reservoir computers. We propose the criterion $GS=ESP$: GS implies the echo state property (ESP), and vice versa. We analytically show that RF-QRCs, by design, fulfill $GS=ESP$. Finally, we analyze the effect of simulated noise. We find that dissipation from noise enhances the robustness of quantum reservoir computers. Numerical verifications on systems of different dimensions support our conclusions. This work opens opportunities for designing robust quantum machines for chaotic time series forecasting on near-term quantum hardware.",
      "authors": [
        "Osama Ahmed",
        "Felix Tennie",
        "Luca Magri"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Machine Learning (cs.LG)",
        "Chaotic Dynamics (nlin.CD)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T15:42:20+00:00",
          "link": "https://arxiv.org/abs/2506.22335v1",
          "size": "1538kb",
          "version": "v1"
        }
      ],
      "title": "Robust quantum reservoir computers for forecasting chaotic dynamics: generalized synchronization and stability",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22335",
        "HTML": "https://arxiv.org/html/2506.22335v1",
        "PDF": "https://arxiv.org/pdf/2506.22335"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper discusses quantum reservoir computers for forecasting chaotic dynamics. It focuses on designing robust quantum computing systems and does not involve LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22340",
      "abstract": "Kolmogorov Arnold Networks (KANs), built upon the Kolmogorov Arnold representation theorem (KAR), have demonstrated promising capabilities in expressing complex functions with fewer neurons. This is achieved by implementing learnable parameters on the edges instead of on the nodes, unlike traditional networks such as Multi-Layer Perceptrons (MLPs). However, KANs potential in quantum machine learning has not yet been well explored. In this work, we present an implementation of these KAN architectures in both hybrid and fully quantum forms using a Quantum Circuit Born Machine (QCBM). We adapt the KAN transfer using pre-trained residual functions, thereby exploiting the representational power of parametrized quantum circuits. In the hybrid model we combine classical KAN components with quantum subroutines, while the fully quantum version the entire architecture of the residual function is translated to a quantum model. We demonstrate the feasibility, interpretability and performance of the proposed Quantum KAN (QuKAN) architecture.",
      "authors": [
        "Yannick Werner",
        "Akash Malemath",
        "Mengxi Liu",
        "Vitor Fortes Rey",
        "Nikolaos Palaiodimopoulos",
        "Paul Lukowicz",
        "and Maximilian Kiefer-Emmanouilidis"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T15:51:19+00:00",
          "link": "https://arxiv.org/abs/2506.22340v1",
          "size": "20794kb",
          "version": "v1"
        }
      ],
      "title": "QuKAN: A Quantum Circuit Born Machine approach to Quantum Kolmogorov Arnold Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22340",
        "HTML": "https://arxiv.org/html/2506.22340v1",
        "PDF": "https://arxiv.org/pdf/2506.22340"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper discusses Quantum Kolmogorov Arnold Networks with a focus on quantum circuits and machine learning potential. It does not relate to the processing of training data for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22343",
      "abstract": "Text watermarks in large language models (LLMs) are an increasingly important tool for detecting synthetic text and distinguishing human-written content from LLM-generated text. While most existing studies focus on determining whether entire texts are watermarked, many real-world scenarios involve mixed-source texts, which blend human-written and watermarked content. In this paper, we address the problem of optimally estimating the watermark proportion in mixed-source texts. We cast this problem as estimating the proportion parameter in a mixture model based on \\emph{pivotal statistics}. First, we show that this parameter is not even identifiable in certain watermarking schemes, let alone consistently estimable. In stark contrast, for watermarking methods that employ continuous pivotal statistics for detection, we demonstrate that the proportion parameter is identifiable under mild conditions. We propose efficient estimators for this class of methods, which include several popular unbiased watermarks as examples, and derive minimax lower bounds for any measurable estimator based on pivotal statistics, showing that our estimators achieve these lower bounds. Through evaluations on both synthetic data and mixed-source text generated by open-source models, we demonstrate that our proposed estimators consistently achieve high estimation accuracy.",
      "authors": [
        "Xiang Li",
        "Garrett Wen",
        "Weiqing He",
        "Jiayuan Wu",
        "Qi Long",
        "Weijie J. Su"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)",
        "Methodology (stat.ME)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T15:53:04+00:00",
          "link": "https://arxiv.org/abs/2506.22343v1",
          "size": "7185kb",
          "version": "v1"
        }
      ],
      "title": "Optimal Estimation of Watermark Proportions in Hybrid AI-Human Texts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22343",
        "HTML": "https://arxiv.org/html/2506.22343v1",
        "PDF": "https://arxiv.org/pdf/2506.22343"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper addresses watermark estimation in texts containing both human-written and LLM-generated content. It does not focus on the processing or engineering of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22362",
      "abstract": "Token-based language modeling is a prominent approach for speech generation, where tokens are obtained by quantizing features from self-supervised learning (SSL) models and extracting codes from neural speech codecs, generally referred to as semantic tokens and acoustic tokens. These tokens are often modeled autoregressively, with the inference speed being constrained by the token rate. In this work, we propose DiffSoundStream, a solution that improves the efficiency of speech tokenization in non-streaming scenarios through two techniques: (1) conditioning the neural codec on semantic tokens to minimize redundancy between semantic and acoustic tokens, and (2) leveraging latent diffusion models to synthesize high-quality waveforms from semantic and coarse-level acoustic tokens. Experiments show that at 50 tokens per second, DiffSoundStream achieves speech quality on par with a standard SoundStream model operating at twice the token rate. Additionally, we achieve step-size distillation using just four diffusion sampling steps with only a minor quality loss.",
      "authors": [
        "Yang Yang",
        "Yunpeng Li",
        "George Sung",
        "Shao-Fu Shih",
        "Craig Dooley",
        "Alessio Centazzo",
        "Ramanan Rajeswaran"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T16:23:07+00:00",
          "link": "https://arxiv.org/abs/2506.22362v1",
          "size": "107kb",
          "version": "v1"
        }
      ],
      "title": "DiffSoundStream: Efficient Speech Tokenization via Diffusion Decoding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22362",
        "HTML": "https://arxiv.org/html/2506.22362v1",
        "PDF": "https://arxiv.org/pdf/2506.22362"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper proposes a method for efficient speech tokenization using diffusion decoding, which involves speech data processing rather than LLM training data processing or enhancement."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22397",
      "abstract": "Fluorescence microscopy is a major driver of scientific progress in the life sciences. Although high-end confocal microscopes are capable of filtering out-of-focus light, cheaper and more accessible microscopy modalities, such as widefield microscopy, can not, which consequently leads to hazy image data. Computational dehazing is trying to combine the best of both worlds, leading to cheap microscopy but crisp-looking images. The perception-distortion trade-off tells us that we can optimize either for data fidelity, e.g. low MSE or high PSNR, or for data realism, measured by perceptual metrics such as LPIPS or FID. Existing methods either prioritize fidelity at the expense of realism, or produce perceptually convincing results that lack quantitative accuracy. In this work, we propose HazeMatching, a novel iterative method for dehazing light microscopy images, which effectively balances these objectives. Our goal was to find a balanced trade-off between the fidelity of the dehazing results and the realism of individual predictions (samples). We achieve this by adapting the conditional flow matching framework by guiding the generative process with a hazy observation in the conditional velocity field. We evaluate HazeMatching on 5 datasets, covering both synthetic and real data, assessing both distortion and perceptual quality. Our method is compared against 7 baselines, achieving a consistent balance between fidelity and realism on average. Additionally, with calibration analysis, we show that HazeMatching produces well-calibrated predictions. Note that our method does not need an explicit degradation operator to exist, making it easily applicable on real microscopy data. All data used for training and evaluation and our code will be publicly available under a permissive license.",
      "authors": [
        "Anirban Ray",
        "Ashesh",
        "Florian Jug"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T17:10:43+00:00",
          "link": "https://arxiv.org/abs/2506.22397v1",
          "size": "2545kb",
          "version": "v1"
        }
      ],
      "title": "Dehazing Light Microscopy Images with Guided Conditional Flow Matching: finding a sweet spot between fidelity and realism",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22397",
        "HTML": "https://arxiv.org/html/2506.22397v1",
        "PDF": "https://arxiv.org/pdf/2506.22397"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper is focused on computational methods for dehazing light microscopy images and does not address any aspects of LLM training data collection, construction, or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22413",
      "abstract": "In the realm of computational fluid dynamics, traditional numerical methods, which heavily rely on discretization, typically necessitate the formulation of partial differential equations (PDEs) in conservative form to accurately capture shocks and other discontinuities in compressible flows. Conversely, utilizing non-conservative forms often introduces significant errors near these discontinuities or results in smeared shocks. This dependency poses a considerable limitation, particularly as many PDEs encountered in complex physical phenomena, such as multi-phase flows, are inherently non-conservative. This inherent non-conservativity restricts the direct applicability of standard numerical solvers designed for conservative forms. This work aims to thoroughly investigate the sensitivity of Physics-Informed Neural Networks (PINNs) to the choice of PDE formulation (conservative vs. non-conservative) when solving problems involving shocks and discontinuities. We have conducted this investigation across a range of benchmark problems, specifically the Burgers equation and both steady and unsteady Euler equations, to provide a comprehensive understanding of PINNs capabilities in this critical area.",
      "authors": [
        "Arun Govind Neelan",
        "Ferdin Sagai Don Bosco",
        "Naveen Sagar Jarugumalli",
        "Suresh Balaji Vedarethinam"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Fluid Dynamics (physics.flu-dyn)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T17:39:36+00:00",
          "link": "https://arxiv.org/abs/2506.22413v1",
          "size": "577kb",
          "version": "v1"
        }
      ],
      "title": "Physics-Informed Neural Networks: Bridging the Divide Between Conservative and Non-Conservative Equations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22413",
        "HTML": "https://arxiv.org/html/2506.22413v1",
        "PDF": "https://arxiv.org/pdf/2506.22413"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This work investigates Physics-Informed Neural Networks in the context of solving PDEs, focusing on computational fluid dynamics. It does not cover LLM data processing or training data issues."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22426",
      "abstract": "High-dynamic-range (HDR) imaging is an essential technique for overcoming the dynamic range limits of image sensors. The classic method relies on multiple exposures, which slows capture time, resulting in motion artifacts when imaging dynamic scenes. Single-shot HDR imaging alleviates this issue by encoding HDR data into a single exposure, then computationally recovering it. Many established methods use strong image priors to recover improperly exposed image detail. These approaches struggle with extended highlight regions. We utilize the global reset release (GRR) shutter mode of an off-the-shelf sensor. GRR shutter mode applies a longer exposure time to rows closer to the bottom of the sensor. We use optics that relay a randomly permuted (shuffled) image onto the sensor, effectively creating spatially randomized exposures across the scene. The exposure diversity allows us to recover HDR data by solving an optimization problem with a simple total variation image prior. In simulation, we demonstrate that our method outperforms other single-shot methods when many sensor pixels are saturated (10% or more), and is competitive at a modest saturation (1%). Finally, we demonstrate a physical lab prototype that uses an off-the-shelf random fiber bundle for the optical shuffling. The fiber bundle is coupled to a low-cost commercial sensor operating in GRR shutter mode. Our prototype achieves a dynamic range of up to 73dB using an 8-bit sensor with 48dB dynamic range.",
      "authors": [
        "Xiang Dai",
        "Kyrollos Yanny",
        "Kristina Monakhova",
        "Nicholas Antipa"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Graphics (cs.GR)",
        "Signal Processing (eess.SP)",
        "Optics (physics.optics)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T17:48:21+00:00",
          "link": "https://arxiv.org/abs/2506.22426v1",
          "size": "14369kb",
          "version": "v1"
        }
      ],
      "title": "Single-shot HDR using conventional image sensor shutter functions and optical randomization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22426",
        "HTML": "https://arxiv.org/html/2506.22426v1",
        "PDF": "https://arxiv.org/pdf/2506.22426"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper addresses high-dynamic-range imaging using image sensors, discussing optical techniques and optimization problems. It does not involve LLM data collection, engineering, or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22428",
      "abstract": "This work investigates the convergence behavior of augmented Lagrangian methods (ALMs) when applied to convex optimization problems that may be infeasible. ALMs are a popular class of algorithms for solving constrained optimization problems. We establish progressively stronger convergence results, ranging from basic sequence convergence to precise convergence rates, under a hierarchy of assumptions. In particular, we demonstrate that, under mild assumptions, the sequences of iterates generated by ALMs converge to solutions of the ``closest feasible problem''.\n  This study leverages the classical relationship between ALMs and the proximal-point algorithm applied to the dual problem. A key technical contribution is a set of concise results on the behavior of the proximal-point algorithm when applied to functions that may not have minimizers. These results pertain to its convergence in terms of its subgradients and of the values of the convex conjugate.",
      "authors": [
        "Roland Andrews",
        "Justin Carpentier",
        "Adrien Taylor"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T17:55:44+00:00",
          "link": "https://arxiv.org/abs/2506.22428v1",
          "size": "49kb",
          "version": "v1"
        }
      ],
      "title": "Augmented Lagrangian methods for infeasible convex optimization problems and diverging proximal-point algorithms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22428",
        "PDF": "https://arxiv.org/pdf/2506.22428"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This work investigates convergence behavior of augmented Lagrangian methods for convex optimization problems. It does not involve discussion of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22429",
      "abstract": "While the theory of deep learning has made some progress in recent years, much of it is limited to the ReLU activation function. In particular, while the neural tangent kernel (NTK) and neural network Gaussian process kernel (NNGP) have given theoreticians tractable limiting cases of fully connected neural networks, their properties for most activation functions except for powers of the ReLU function are poorly understood. Our main contribution is to provide a more general characterization of the RKHS of these kernels for typical activation functions whose only non-smoothness is at zero, such as SELU, ELU, or LeakyReLU. Our analysis also covers a broad set of special cases such as missing biases, two-layer networks, or polynomial activations. Our results show that a broad class of not infinitely smooth activations generate equivalent RKHSs at different network depths, while polynomial activations generate non-equivalent RKHSs. Finally, we derive results for the smoothness of NNGP sample paths, characterizing the smoothness of infinitely wide neural networks at initialization.",
      "authors": [
        "David Holzm\\\"uller and Max Sch\\\"olpple"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T17:56:09+00:00",
          "link": "https://arxiv.org/abs/2506.22429v1",
          "size": "71kb",
          "version": "v1"
        }
      ],
      "title": "Beyond ReLU: How Activations Affect Neural Kernels and Random Wide Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22429",
        "PDF": "https://arxiv.org/pdf/2506.22429"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper explores theoretical aspects of neural networks, specifically regarding activation functions and neural kernels. It does not discuss training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2105.08353",
      "abstract": "In runtime verification, a monitor watches a trace of a system and, if possible, decides after observing each finite prefix whether or not the unknown infinite trace satisfies a given specification. We generalize the theory of runtime verification to monitors that attempt to estimate numerical values of quantitative trace properties (instead of attempting to conclude boolean values of trace specifications), such as maximal or average response time along a trace. Quantitative monitors are approximate: with every finite prefix, they can improve their estimate of the infinite trace's unknown property value. Consequently, quantitative monitors can be compared with regard to a precision-cost trade-off: better approximations of the property value require more monitor resources, such as states (in the case of finite-state monitors) or registers, and additional resources yield better approximations. We introduce a formal framework for quantitative and approximate monitoring, show how it conservatively generalizes the classical boolean setting for monitoring, and give several precision-cost trade-offs for monitors. For example, we prove that there are quantitative properties for which every additional register improves monitoring precision.",
      "authors": [
        "Thomas A. Henzinger and N. Ege Sara\\c{c}"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2021-05-18T08:24:31+00:00",
          "link": "https://arxiv.org/abs/2105.08353v1",
          "size": "40kb",
          "version": "v1"
        },
        {
          "date": "2021-06-16T08:22:44+00:00",
          "link": "https://arxiv.org/abs/2105.08353v2",
          "size": "40kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T16:48:03+00:00",
          "link": "https://arxiv.org/abs/2105.08353v3",
          "size": "41kb",
          "version": "v3"
        }
      ],
      "title": "Quantitative and Approximate Monitoring",
      "links": {
        "Abstract": "https://arxiv.org/abs/2105.08353",
        "HTML": "https://arxiv.org/html/2105.08353v3",
        "PDF": "https://arxiv.org/pdf/2105.08353"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper aims at extending runtime verification to quantitative and approximate monitoring, which involves estimating numerical properties of system traces, and does not involve LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2107.13214",
      "abstract": "Recent years have seen a surge in research on deep interpretable neural networks with decision trees as one of the most commonly incorporated tools. There are at least three advantages of using decision trees over logistic regression classification models: they are easy to interpret since they are based on binary decisions, they can make decisions faster, and they provide a hierarchy of classes. However, one of the well-known drawbacks of decision trees, as compared to decision graphs, is that decision trees cannot reuse the decision nodes. Nevertheless, decision graphs were not commonly used in deep learning due to the lack of efficient gradient-based training techniques. In this paper, we fill this gap and provide a general paradigm based on Markov processes, which allows for efficient training of the special type of decision graphs, which we call Self-Organizing Neural Graphs (SONG). We provide an extensive theoretical study of SONG, complemented by experiments conducted on Letter, Connect4, MNIST, CIFAR, and TinyImageNet datasets, showing that our method performs on par or better than existing decision models.",
      "authors": [
        "{\\L}ukasz Struski",
        "Tomasz Danel",
        "Marek \\'Smieja",
        "Jacek Tabor",
        "Bartosz Zieli\\'nski"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2021-07-28T07:53:53+00:00",
          "link": "https://arxiv.org/abs/2107.13214v1",
          "size": "3731kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T10:23:30+00:00",
          "link": "https://arxiv.org/abs/2107.13214v2",
          "size": "1908kb",
          "version": "v2"
        }
      ],
      "title": "SONG: Self-Organizing Neural Graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2107.13214",
        "HTML": "https://arxiv.org/html/2107.13214v2",
        "PDF": "https://arxiv.org/pdf/2107.13214"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper introduces a paradigm for training decision graphs called Self-Organizing Neural Graphs (SONG), which pertains to neural network architectures and does not relate to LLM training data processing or engineering."
      },
      "conference": "song-self-organizing-neural-graphs-1",
      "conference_url_abs": "https://openreview.net/forum?id=p36db089HBP",
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2109.11224",
      "abstract": "Several machine learning-based Network Intrusion Detection Systems (NIDS) have been proposed in recent years. Still, most of them were developed and evaluated under the assumption that the training context is similar to the test context. This assumption is false in real networks, given the emergence of new attacks and variants of known attacks. To deal with this reality, the open set recognition field, which is the most general task of recognizing classes not seen during training in any domain, began to gain importance in machine learning based NIDS research. Yet, existing solutions are often bound to high temporal complexities and performance bottlenecks. In this work, we propose an algorithm to be used in NIDS that performs open set recognition. Our proposal is an adaptation of the single-class Energy-based Flow Classifier (EFC), which proved to be an algorithm with strong generalization capability and low computational cost. The new version of EFC correctly classifies not only known attacks, but also unknown ones, and differs from other proposals from the literature by presenting a single layer with low temporal complexity. Our proposal was evaluated against well-established multi-class algorithms and as an open set classifier. It proved to be an accurate classifier in both evaluations, similar to the state of the art. As a conclusion of our work, we consider EFC a promising algorithm to be used in NIDS for its high performance and applicability in real networks.",
      "authors": [
        "Manuela M. C. Souza",
        "Camila Pontes",
        "Joao Gondim",
        "Luis P. F. Garcia",
        "Luiz DaSilva",
        "Eduardo F. M. Cavalcante and Marcelo A. Marotta"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2021-09-23T09:13:33+00:00",
          "link": "https://arxiv.org/abs/2109.11224v1",
          "size": "1769kb",
          "version": "v1"
        },
        {
          "date": "2022-04-26T15:11:30+00:00",
          "link": "https://arxiv.org/abs/2109.11224v2",
          "size": "1847kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T17:08:28+00:00",
          "link": "https://arxiv.org/abs/2109.11224v3",
          "size": "257kb",
          "version": "v3"
        }
      ],
      "title": "A Novel Open Set Energy-based Flow Classifier for Network Intrusion Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2109.11224",
        "HTML": "https://arxiv.org/html/2109.11224v3",
        "PDF": "https://arxiv.org/pdf/2109.11224"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper primarily discusses a network intrusion detection system focusing on open set recognition for new or variant attacks, without addressing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2110.12962",
      "abstract": "Event-based approaches, which are based on bio-inspired asynchronous event cameras, have achieved promising performance on various computer vision tasks. However, the study of the fundamental event data association problem is still in its infancy. In this paper, we propose a novel Event Data Association (called EDA) approach to explicitly address the event association and fusion problem. The proposed EDA seeks for event trajectories that best fit the event data, in order to perform unifying data association and information fusion. In EDA, we first asynchronously fuse the event data based on its information entropy. Then, we introduce a deterministic model hypothesis generation strategy, which effectively generates model hypotheses from the fused events, to represent the corresponding event trajectories. After that, we present a two-stage weighting algorithm, which robustly weighs and selects true models from the generated model hypotheses, through multi-structural geometric model fitting. Meanwhile, we also propose an adaptive model selection strategy to automatically determine the number of the true models. Finally, we use the selected true models to associate and fuse the event data, without being affected by sensor noise and irrelevant structures. We evaluate the performance of the proposed EDA on the object tracking task. The experimental results show the effectiveness of EDA under challenging scenarios, such as high speed, motion blur, and high dynamic range conditions.",
      "authors": [
        "Haosheng Chen",
        "Yue Wu",
        "Yidong Peng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2021-10-25T13:56:00+00:00",
          "link": "https://arxiv.org/abs/2110.12962v1",
          "size": "6595kb",
          "version": "v1"
        },
        {
          "date": "2024-04-09T16:39:00+00:00",
          "link": "https://arxiv.org/abs/2110.12962v2",
          "size": "4580kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T07:04:28+00:00",
          "link": "https://arxiv.org/abs/2110.12962v3",
          "size": "6686kb",
          "version": "v3"
        }
      ],
      "title": "Event Data Association via Robust Model Fitting for Event-based Object Tracking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2110.12962",
        "HTML": "https://arxiv.org/html/2110.12962v3",
        "PDF": "https://arxiv.org/pdf/2110.12962"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The study focuses on event data association with asynchronous event cameras for object tracking, not involving LLM training data processing or associated methodologies."
      },
      "tasks": [
        "Model Selection",
        "Object Tracking"
      ],
      "source": "arXiv"
    },
    {
      "id": "2205.07707",
      "abstract": "An infinite word generated by a substitution is rigid if all the substitutions which fix this word are powers of a same substitution. Sturmian words as well as characteristic Arnoux-Rauzy words are known to be rigid. In the present paper, we prove that all Arnoux-Rauzy words are rigid. The proof relies on two main ingredients: firstly, the fact that the primitive substitutions that fix an Arnoux-Rauzy word share a common power, and secondly, the notion of normal form of an episturmian substitution (i.e., a substitution that fixes an Arnoux-Rauzy word). The main difficulty is then of a combinatorial nature and relies on the normalization process when taking powers of episturmian substitutions: the normal form of a square is not necessarily equal to the square of the normal forms.",
      "authors": [
        "Val\\'erie Berth\\'e",
        "Svetlana Puzynina"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2022-05-16T14:19:55+00:00",
          "link": "https://arxiv.org/abs/2205.07707v1",
          "size": "47kb",
          "version": "v1"
        },
        {
          "date": "2022-07-12T16:07:39+00:00",
          "link": "https://arxiv.org/abs/2205.07707v2",
          "size": "47kb",
          "version": "v2"
        },
        {
          "date": "2024-02-06T10:13:41+00:00",
          "link": "https://arxiv.org/abs/2205.07707v3",
          "size": "55kb",
          "version": "v3"
        },
        {
          "date": "2025-06-27T15:08:01+00:00",
          "link": "https://arxiv.org/abs/2205.07707v4",
          "size": "55kb",
          "version": "v4"
        }
      ],
      "title": "On the rigidity of Arnoux-Rauzy words",
      "links": {
        "Abstract": "https://arxiv.org/abs/2205.07707",
        "HTML": "https://arxiv.org/html/2205.07707v4",
        "PDF": "https://arxiv.org/pdf/2205.07707"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This work discusses the rigidity of Arnoux-Rauzy words in combinatorics, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2207.05146",
      "abstract": "Safety is one of the most important properties of control systems. Sensor faults and attacks and actuator failures may cause errors in the sensor measurements and system dynamics, which leads to erroneous control inputs and hence safety violations. In this paper, we improve the robustness against sensor faults and actuator failures by proposing a class of Fault-Tolerant Control Barrier Functions (FT-CBFs) for nonlinear systems. Our approach maintains a set of state estimators according to fault patterns and incorporates CBF-based linear constraints for each state estimator. We then propose a framework for joint safety and stability by integrating FT-CBFs with Control Lyapunov Functions. With a similar philosophy of utilizing redundancy, we proposed High order CBF-based approach to ensure safety when actuator failures occur. We propose a sum-of-squares (SOS) based approach to verify the feasibility of FT-CBFs for both sensor faults and actuator failures. We evaluate our approach via two case studies, namely, a wheeled mobile robot (WMR) system in the presence of a sensor attack and a Boeing 747 lateral control system under actuator failures.",
      "authors": [
        "Hongchao Zhang",
        "Zhouchi Li",
        "Andrew Clark"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2022-07-11T19:24:44+00:00",
          "link": "https://arxiv.org/abs/2207.05146v1",
          "size": "4460kb",
          "version": "v1"
        },
        {
          "date": "2025-06-26T18:22:35+00:00",
          "link": "https://arxiv.org/abs/2207.05146v2",
          "size": "4195kb",
          "version": "v2"
        }
      ],
      "title": "Safe Control for Nonlinear Systems Under Faults and Attacks Via Control Barrier Functions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2207.05146",
        "HTML": "https://arxiv.org/html/2207.05146v2",
        "PDF": "https://arxiv.org/pdf/2207.05146"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper addresses robustness in control systems with a focus on sensor faults and actuator failures, which is unrelated to LLM training data processing or engineering."
      },
      "tasks": [
        "Philosophy"
      ],
      "source": "arXiv"
    },
    {
      "id": "2301.12276",
      "abstract": "We introduce ProtoSeg, a novel model for interpretable semantic image segmentation, which constructs its predictions using similar patches from the training set. To achieve accuracy comparable to baseline methods, we adapt the mechanism of prototypical parts and introduce a diversity loss function that increases the variety of prototypes within each class. We show that ProtoSeg discovers semantic concepts, in contrast to standard segmentation models. Experiments conducted on Pascal VOC and Cityscapes datasets confirm the precision and transparency of the presented method.",
      "authors": [
        "Miko{\\l}aj Sacha",
        "Dawid Rymarczyk",
        "{\\L}ukasz Struski",
        "Jacek Tabor",
        "Bartosz Zieli\\'nski"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2023-01-28T19:14:32+00:00",
          "link": "https://arxiv.org/abs/2301.12276v1",
          "size": "8970kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T14:06:31+00:00",
          "link": "https://arxiv.org/abs/2301.12276v2",
          "size": "1917kb",
          "version": "v2"
        }
      ],
      "title": "ProtoSeg: Interpretable Semantic Segmentation with Prototypical Parts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2301.12276",
        "HTML": "https://arxiv.org/html/2301.12276v2",
        "PDF": "https://arxiv.org/pdf/2301.12276"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper introduces a model for semantic segmentation, dealing with image data and interpretable models, which is unrelated to LLM training data processes."
      },
      "tasks": [
        "Diversity",
        "Image Segmentation",
        "Segmentation",
        "Semantic Segmentation"
      ],
      "repo_urls": [
        "https://github.com/eceo-epfl/scaleprotoseg",
        "https://github.com/gmum/proto-segmentation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2303.16500",
      "abstract": "Line detection is widely used in many robotic tasks such as scene recognition, 3D reconstruction, and simultaneous localization and mapping (SLAM). Compared to points, lines can provide both low-level and high-level geometrical information for downstream tasks. In this paper, we propose a novel learnable edge-based line detection algorithm, AirLine, which can be applied to various tasks. In contrast to existing learnable endpoint-based methods, which are sensitive to the geometrical condition of environments, AirLine can extract line segments directly from edges, resulting in a better generalization ability for unseen environments. To balance efficiency and accuracy, we introduce a region-grow algorithm and a local edge voting scheme for line parameterization. To the best of our knowledge, AirLine is one of the first learnable edge-based line detection methods. Our extensive experiments have shown that it retains state-of-the-art-level precision, yet with a 3 to 80 times runtime acceleration compared to other learning-based methods, which is critical for low-power robots.",
      "authors": [
        "Xiao Lin",
        "Chen Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2023-03-29T07:23:12+00:00",
          "link": "https://arxiv.org/abs/2303.16500v1",
          "size": "5511kb",
          "version": "v1"
        },
        {
          "date": "2023-08-03T15:02:57+00:00",
          "link": "https://arxiv.org/abs/2303.16500v2",
          "size": "5512kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T16:12:21+00:00",
          "link": "https://arxiv.org/abs/2303.16500v3",
          "size": "5449kb",
          "version": "v3"
        }
      ],
      "title": "AirLine: Efficient Learnable Line Detection with Local Edge Voting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2303.16500",
        "HTML": "https://arxiv.org/html/2303.16500v3",
        "PDF": "https://arxiv.org/pdf/2303.16500"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on a novel line detection algorithm for robotic tasks and does not address any aspect of LLM training data processing or enhancement."
      },
      "repo_urls": [
        "https://github.com/sair-lab/airline"
      ],
      "source": "arXiv"
    },
    {
      "id": "2304.05166",
      "abstract": "Predicting the future behavior of human road users is an important aspect for the development of risk-aware autonomous vehicles. While many models have been developed towards this end, effectively capturing and predicting the variability inherent to human behavior still remains an open challenge. This paper proposes TrajFlow - a new approach for probabilistic trajectory prediction based on Normalizing Flows. We reformulate the problem of capturing distributions over trajectories into capturing distributions over abstracted trajectory features using an autoencoder, simplifying the learning task of the Normalizing Flows. TrajFlow outperforms state-of-the-art behavior prediction models in capturing full trajectory distributions in two synthetic benchmarks with known true distributions, and is competitive on the naturalistic datasets ETH/UCY, rounD, and nuScenes. Our results demonstrate the effectiveness of TrajFlow in probabilistic prediction of human behavior.",
      "authors": [
        "Anna M\\'esz\\'aros",
        "Julian F. Schumann",
        "Javier Alonso-Mora",
        "Arkady Zgonnikov and Jens Kober"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2023-04-11T12:00:46+00:00",
          "link": "https://arxiv.org/abs/2304.05166v1",
          "size": "5523kb",
          "version": "v1"
        },
        {
          "date": "2023-06-19T13:06:31+00:00",
          "link": "https://arxiv.org/abs/2304.05166v2",
          "size": "4176kb",
          "version": "v2"
        },
        {
          "date": "2024-02-02T08:21:03+00:00",
          "link": "https://arxiv.org/abs/2304.05166v3",
          "size": "3504kb",
          "version": "v3"
        },
        {
          "date": "2024-04-19T14:27:12+00:00",
          "link": "https://arxiv.org/abs/2304.05166v4",
          "size": "3350kb",
          "version": "v4"
        },
        {
          "date": "2025-06-27T10:06:38+00:00",
          "link": "https://arxiv.org/abs/2304.05166v5",
          "size": "3238kb",
          "version": "v5"
        }
      ],
      "title": "TrajFlow: Learning Distributions over Trajectories for Human Behavior Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2304.05166",
        "PDF": "https://arxiv.org/pdf/2304.05166"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper presents a trajectory prediction model for human behavior using Normalizing Flows but does not delve into LLM training data processes or improvements."
      },
      "source": "arXiv"
    },
    {
      "id": "2305.09305",
      "abstract": "Adversarial training (AT) is considered the most effective defense against adversarial attacks. However, a recent study revealed that \\(\\ell_{\\infty}\\)-norm adversarial training (\\(\\ell_{\\infty}\\)-AT) will also induce unevenly distributed input gradients, which is called the inequality phenomenon. This phenomenon makes the \\(\\ell_{\\infty}\\)-norm adversarially trained model more vulnerable than the standard-trained model when high-attribution or randomly selected pixels are perturbed, enabling robust and practical black-box attacks against \\(\\ell_{\\infty}\\)-adversarially trained models. In this paper, we propose a simple yet effective method called Input Gradient Distillation (IGD) to release the inequality phenomenon in $\\ell_{\\infty}$-AT. IGD distills the standard-trained teacher model's equal decision pattern into the $\\ell_{\\infty}$-adversarially trained student model by aligning input gradients of the student model and the standard-trained model with the Cosine Similarity. Experiments show that IGD can mitigate the inequality phenomenon and its threats while preserving adversarial robustness. Compared to vanilla $\\ell_{\\infty}$-AT, IGD reduces error rates against inductive noise, inductive occlusion, random noise, and noisy images in ImageNet-C by up to 60\\%, 16\\%, 50\\%, and 21\\%, respectively. Other than empirical experiments, we also conduct a theoretical analysis to explain why releasing the inequality phenomenon can improve such robustness and discuss why the severity of the inequality phenomenon varies according to the dataset's image resolution. Our code is available at https://github.com/fhdnskfbeuv/Inuput-Gradient-Distillation",
      "authors": [
        "Junxi Chen",
        "Junhao Dong",
        "Xiaohua Xie",
        "Jianhuang Lai"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2023-05-16T09:23:42+00:00",
          "link": "https://arxiv.org/abs/2305.09305v1",
          "size": "8577kb",
          "version": "v1"
        },
        {
          "date": "2023-05-17T15:03:17+00:00",
          "link": "https://arxiv.org/abs/2305.09305v2",
          "size": "13459kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T06:05:44+00:00",
          "link": "https://arxiv.org/abs/2305.09305v3",
          "size": "2580kb",
          "version": "v3"
        }
      ],
      "title": "Releasing Inequality Phenomenon in $\\ell_{\\infty}$-norm Adversarial Training via Input Gradient Distillation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2305.09305",
        "HTML": "https://arxiv.org/html/2305.09305v3",
        "PDF": "https://arxiv.org/pdf/2305.09305"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper discusses adversarial training in machine learning, particularly input gradient distillation, without relating it to data processing or enhancement for LLM training."
      },
      "tasks": [
        "Adversarial Defense",
        "Adversarial Robustness"
      ],
      "source": "arXiv"
    },
    {
      "id": "2307.09727",
      "abstract": "Estimating displacement vector field via a cost volume computed in the feature space has shown great success in image registration, but it suffers excessive computation burdens. Moreover, existing feature descriptors only extract local features incapable of representing the global semantic information, which is especially important for solving large transformations. To address the discussed issues, we propose SAMConvex, a fast coarse-to-fine discrete optimization method for CT registration that includes a decoupled convex optimization procedure to obtain deformation fields based on a self-supervised anatomical embedding (SAM) feature extractor that captures both local and global information. To be specific, SAMConvex extracts per-voxel features and builds 6D correlation volumes based on SAM features, and iteratively updates a flow field by performing lookups on the correlation volumes with a coarse-to-fine scheme. SAMConvex outperforms the state-of-the-art learning-based methods and optimization-based methods over two inter-patient registration datasets (Abdomen CT and HeadNeck CT) and one intra-patient registration dataset (Lung CT). Moreover, as an optimization-based method, SAMConvex only takes $\\sim2$s ($\\sim5s$ with instance optimization) for one paired images.",
      "authors": [
        "Zi Li and Lin Tian and Tony C. W. Mok and Xiaoyu Bai and Puyang Wang and Jia Ge and Jingren Zhou and Le Lu and Xianghua Ye and Ke Yan and Dakai Jin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2023-07-19T02:28:41+00:00",
          "link": "https://arxiv.org/abs/2307.09727v1",
          "size": "5012kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T03:46:27+00:00",
          "link": "https://arxiv.org/abs/2307.09727v2",
          "size": "4213kb",
          "version": "v2"
        }
      ],
      "title": "SAMConvex: Fast Discrete Optimization for CT Registration using Self-supervised Anatomical Embedding and Correlation Pyramid",
      "links": {
        "Abstract": "https://arxiv.org/abs/2307.09727",
        "HTML": "https://arxiv.org/html/2307.09727v2",
        "PDF": "https://arxiv.org/pdf/2307.09727"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "SAMConvex is a method for CT registration through a fast optimization approach and does not relate to the processing of training data for LLMs."
      },
      "tasks": [
        "Image Registration"
      ],
      "repo_urls": [
        "https://github.com/alibaba-damo-academy/samconvex"
      ],
      "source": "arXiv"
    },
    {
      "id": "2308.13054",
      "abstract": "The aspect ratio of a (positively) weighted graph $G$ is the ratio of its maximum edge weight to its minimum edge weight. Aspect ratio commonly arises as a complexity measure in graph algorithms, especially related to the computation of shortest paths. Popular paradigms are to interpolate between the settings of weighted and unweighted input graphs by incurring a dependence on aspect ratio, or by simply restricting attention to input graphs of low aspect ratio.\n  This paper studies the effects of these paradigms, investigating whether graphs of low aspect ratio have more structured shortest paths than graphs in general. In particular, we raise the question of whether one can generally take a graph of large aspect ratio and reweight its edges, to obtain a graph with bounded aspect ratio while preserving the structure of its shortest paths. Our findings are:\n  - Every weighted DAG on $n$ nodes has a shortest-paths preserving graph of aspect ratio $O(n)$. A simple lower bound shows that this is tight.\n  - The previous result does not extend to general directed or undirected graphs; in fact, the answer turns out to be exponential in these settings. In particular, we construct directed and undirected $n$-node graphs for which any shortest-paths preserving graph has aspect ratio $2^{\\Omega(n)}$.\n  We also consider the approximate version of this problem, where the goal is for shortest paths in $H$ to correspond to approximate shortest paths in $G$. We show that our exponential lower bounds extend even to this setting. We also show that in a closely related model, where approximate shortest paths in $H$ must also correspond to approximate shortest paths in $G$, even DAGs require exponential aspect ratio.",
      "authors": [
        "Aaron Bernstein",
        "Greg Bodwin",
        "Nicole Wein"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2023-08-24T19:41:54+00:00",
          "link": "https://arxiv.org/abs/2308.13054v1",
          "size": "31kb",
          "version": "v1"
        },
        {
          "date": "2023-11-30T02:33:57+00:00",
          "link": "https://arxiv.org/abs/2308.13054v2",
          "size": "30kb",
          "version": "v2"
        },
        {
          "date": "2024-09-16T16:26:08+00:00",
          "link": "https://arxiv.org/abs/2308.13054v3",
          "size": "56kb",
          "version": "v3"
        },
        {
          "date": "2025-06-27T01:52:01+00:00",
          "link": "https://arxiv.org/abs/2308.13054v4",
          "size": "56kb",
          "version": "v4"
        }
      ],
      "title": "Are there graphs whose shortest path structure requires large edge weights?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2308.13054",
        "HTML": "https://arxiv.org/html/2308.13054v4",
        "PDF": "https://arxiv.org/pdf/2308.13054"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper studies graph theory concepts related to shortest paths and aspect ratios but does not discuss LLM training data processing techniques or advancements."
      },
      "source": "arXiv"
    },
    {
      "id": "2309.13933",
      "abstract": "Employers are adopting algorithmic hiring technology throughout the recruitment pipeline. Algorithmic fairness is especially applicable in this domain due to its high stakes and structural inequalities. Unfortunately, most work in this space provides partial treatment, often constrained by two competing narratives, optimistically focused on replacing biased recruiter decisions or pessimistically pointing to the automation of discrimination. Whether, and more importantly what types of, algorithmic hiring can be less biased and more beneficial to society than low-tech alternatives currently remains unanswered, to the detriment of trustworthiness. This multidisciplinary survey caters to practitioners and researchers with a balanced and integrated coverage of systems, biases, measures, mitigation strategies, datasets, and legal aspects of algorithmic hiring and fairness. Our work supports a contextualized understanding and governance of this technology by highlighting current opportunities and limitations, providing recommendations for future work to ensure shared benefits for all stakeholders.",
      "authors": [
        "Alessandro Fabris",
        "Nina Baranowska",
        "Matthew J. Dennis",
        "David Graus",
        "Philipp Hacker",
        "Jorge Saldivar",
        "Frederik Zuiderveen Borgesius",
        "Asia J. Biega"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2023-09-25T08:04:18+00:00",
          "link": "https://arxiv.org/abs/2309.13933v1",
          "size": "1221kb",
          "version": "v1"
        },
        {
          "date": "2024-04-08T13:47:39+00:00",
          "link": "https://arxiv.org/abs/2309.13933v2",
          "size": "1287kb",
          "version": "v2"
        },
        {
          "date": "2024-09-24T16:18:51+00:00",
          "link": "https://arxiv.org/abs/2309.13933v3",
          "size": "1235kb",
          "version": "v3"
        },
        {
          "date": "2025-06-27T12:26:31+00:00",
          "link": "https://arxiv.org/abs/2309.13933v4",
          "size": "296kb",
          "version": "v4"
        }
      ],
      "title": "Fairness and Bias in Algorithmic Hiring: a Multidisciplinary Survey",
      "links": {
        "Abstract": "https://arxiv.org/abs/2309.13933",
        "HTML": "https://arxiv.org/html/2309.13933v4",
        "PDF": "https://arxiv.org/pdf/2309.13933"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This survey addresses algorithmic fairness in hiring technologies and discusses biases and legal aspects, without relating specifically to LLM training data processing."
      },
      "tasks": [
        "Fairness",
        "Survey"
      ],
      "source": "arXiv"
    },
    {
      "id": "2310.01905",
      "abstract": "Context: Domain-Driven Design (DDD) has gained significant attention in software development for its potential to address complex software challenges, particularly in the areas of system refactoring, reimplementation, and adoption. Using domain knowledge, DDD aims to solve complex business problems effectively. Objective: This SLR aims to provide an analysis of existing research on DDD in software development, paint a picture of DDD in solving software problems, identify the challenges encountered during its application and explore the results of these studies. Method: We systematically selected 36 peer reviewed studies and conducted quantitative and qualitative analyzes to synthesize the findings. Results: DDD has effectively improved software systems, with its key concepts. The application of DDD in microservices has gained prominence for its ability to facilitate system decomposition. Some studies lacked empirical evaluations, highlighting challenges in onboarding and the need for expertise. Conclusion: Adopting DDD benefits software development, involving stakeholders such as engineers, architects, managers, and domain experts. More empirical evaluations and open discussions on challenges are needed. Collaboration between academia and industry advances the adoption and transfer of knowledge of DDD in projects.",
      "authors": [
        "Ozan \\\"Ozkan",
        "\\\"Onder Babur",
        "Mark van den Brand"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2023-10-03T09:22:53+00:00",
          "link": "https://arxiv.org/abs/2310.01905v1",
          "size": "1224kb",
          "version": "v1"
        },
        {
          "date": "2023-10-11T12:35:30+00:00",
          "link": "https://arxiv.org/abs/2310.01905v2",
          "size": "1223kb",
          "version": "v2"
        },
        {
          "date": "2023-11-09T10:58:46+00:00",
          "link": "https://arxiv.org/abs/2310.01905v3",
          "size": "1223kb",
          "version": "v3"
        },
        {
          "date": "2025-06-27T15:02:42+00:00",
          "link": "https://arxiv.org/abs/2310.01905v4",
          "size": "1034kb",
          "version": "v4"
        }
      ],
      "title": "Domain-Driven Design in Software Development: A Systematic Literature Review on Implementation, Challenges, and Effectiveness",
      "links": {
        "Abstract": "https://arxiv.org/abs/2310.01905",
        "HTML": "https://arxiv.org/html/2310.01905v4",
        "PDF": "https://arxiv.org/pdf/2310.01905"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The study reviews Domain-Driven Design in software development, which is not related to the processing or engineering of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2311.02583",
      "abstract": "Deep learning-based medical image segmentation faces significant challenges arising from limited labeled data and domain shifts. While prior approaches have primarily addressed these issues independently, their simultaneous occurrence is common in medical imaging. A method that generalizes to unseen domains using only minimal annotations offers significant practical value due to reduced data annotation and development costs. In pursuit of this goal, we propose FSDA-DG, a novel solution to improve cross-domain generalizability of medical image segmentation with few single-source domain annotations. Specifically, our approach introduces semantics-guided semi-supervised data augmentation. This method divides images into global broad regions and semantics-guided local regions, and applies distinct augmentation strategies to enrich data distribution. Within this framework, both labeled and unlabeled data are transformed into extensive domain knowledge while preserving domain-invariant semantic information. Additionally, FSDA-DG employs a multi-decoder U-Net pipeline semi-supervised learning (SSL) network to improve domain-invariant representation learning through consistent prior assumption across multiple perturbations. By integrating data-level and model-level designs, FSDA-DG achieves superior performance compared to state-of-the-art methods in two challenging single domain generalization (SDG) tasks with limited annotations. The code is publicly available at https://github.com/yezanting/FSDA-DG.",
      "authors": [
        "Zanting Ye",
        "Ke Wang",
        "Wenbing Lv",
        "Qianjin Feng",
        "Lijun Lu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2023-11-05T07:44:40+00:00",
          "link": "https://arxiv.org/abs/2311.02583v1",
          "size": "4358kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T03:01:39+00:00",
          "link": "https://arxiv.org/abs/2311.02583v2",
          "size": "12812kb",
          "version": "v2"
        }
      ],
      "title": "FSDA-DG: Improving Cross-Domain Generalizability of Medical Image Segmentation with Few Source Domain Annotations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2311.02583",
        "HTML": "https://arxiv.org/html/2311.02583v2",
        "PDF": "https://arxiv.org/pdf/2311.02583"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on medical image segmentation and improving cross-domain generalizability using data augmentation and semi-supervised learning. It does not address LLM training data collection, construction, or processing."
      },
      "tasks": [
        "Data Augmentation",
        "Domain Generalization",
        "Image Segmentation",
        "Medical Image Segmentation",
        "Semantic Segmentation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2311.07975",
      "abstract": "Out-of-distribution (OOD) detection is critical for identifying test samples that deviate from in-distribution (ID) data, ensuring network robustness and reliability. This paper presents a flexible framework for OOD knowledge distillation that extracts OOD-sensitive information from a network to develop a binary classifier capable of distinguishing between ID and OOD samples in both scenarios, with and without access to training ID data. To accomplish this, we introduce Confidence Amendment (CA), an innovative methodology that transforms an OOD sample into an ID one while progressively amending prediction confidence derived from the network to enhance OOD sensitivity. This approach enables the simultaneous synthesis of both ID and OOD samples, each accompanied by an adjusted prediction confidence, thereby facilitating the training of a binary classifier sensitive to OOD. Theoretical analysis provides bounds on the generalization error of the binary classifier, demonstrating the pivotal role of confidence amendment in enhancing OOD sensitivity. Extensive experiments spanning various datasets and network architectures confirm the efficacy of the proposed method in detecting OOD samples.",
      "authors": [
        "Zhilin Zhao and Longbing Cao and Yixuan Zhang and Kun-Yu Lin and Wei-Shi Zheng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2023-11-14T08:05:02+00:00",
          "link": "https://arxiv.org/abs/2311.07975v1",
          "size": "627kb",
          "version": "v1"
        },
        {
          "date": "2024-08-22T02:58:00+00:00",
          "link": "https://arxiv.org/abs/2311.07975v2",
          "size": "367kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T08:23:39+00:00",
          "link": "https://arxiv.org/abs/2311.07975v3",
          "size": "13513kb",
          "version": "v3"
        }
      ],
      "title": "Distilling the Unknown to Unveil Certainty",
      "links": {
        "Abstract": "https://arxiv.org/abs/2311.07975",
        "HTML": "https://arxiv.org/html/2311.07975v3",
        "PDF": "https://arxiv.org/pdf/2311.07975"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper deals with out-of-distribution detection and OOD knowledge distillation, which is unrelated to LLM training data processing tasks such as data collection or preprocessing."
      },
      "tasks": [
        "Knowledge Distillation",
        "Out of Distribution (OOD) Detection"
      ],
      "repo_urls": [
        "https://github.com/lawliet-zzl/ca"
      ],
      "source": "arXiv"
    },
    {
      "id": "2311.18578",
      "abstract": "Federated Learning (FL) has emerged as the state-of-the-art approach for learning from decentralized data in privacy-constrained scenarios.However, system and statistical challenges hinder its real-world applicability, requiring efficient learning from edge devices and robustness to data heterogeneity. Despite significant research efforts, existing approaches often degrade severely due to the joint effect of heterogeneity and partial client participation. In particular, while momentum appears as a promising approach for overcoming statistical heterogeneity, in current approaches its update is biased towards the most recently sampled clients. As we show in this work, this is the reason why it fails to outperform FedAvg, preventing its effective use in real-world large-scale scenarios. In this work, we propose a novel Generalized Heavy-Ball Momentum (GHBM) and theoretically prove it enables convergence under unbounded data heterogeneity in cyclic partial participation, thereby advancing the understanding of momentum's effectiveness in FL. We then introduce adaptive and communication-efficient variants of GHBM that match the communication complexity of FedAvg in settings where clients can be stateful. Extensive experiments on vision and language tasks confirm our theoretical findings, demonstrating that GHBM substantially improves state-of-the-art performance under random uniform client sampling, particularly in large-scale settings with high data heterogeneity and low client participation. Code is available at https://rickzack.github.io/GHBM.",
      "authors": [
        "Riccardo Zaccone",
        "Sai Praneeth Karimireddy",
        "Carlo Masone",
        "Marco Ciccone"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2023-11-30T14:17:57+00:00",
          "link": "https://arxiv.org/abs/2311.18578v1",
          "size": "1409kb",
          "version": "v1"
        },
        {
          "date": "2024-06-12T18:53:58+00:00",
          "link": "https://arxiv.org/abs/2311.18578v2",
          "size": "1356kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T13:40:04+00:00",
          "link": "https://arxiv.org/abs/2311.18578v3",
          "size": "1640kb",
          "version": "v3"
        }
      ],
      "title": "Communication-Efficient Heterogeneous Federated Learning with Generalized Heavy-Ball Momentum",
      "links": {
        "Abstract": "https://arxiv.org/abs/2311.18578",
        "PDF": "https://arxiv.org/pdf/2311.18578"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This research focuses on improving federated learning with heavy-ball momentum to handle data heterogeneity. It does not pertain to LLM data processing or enhancements."
      },
      "tasks": [
        "Federated Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2312.07883",
      "abstract": "Additive one-weight codes over a finite field of non-prime order are equivalent to special subspace coverings of the points of a projective space, which we call multispreads. The current paper is devoted to the characterization of the parameters of multispreads, which is equivalent to the characterization of the parameters of additive one-weight codes and, via duality, of additive completely regular codes of covering radius 1 (intriguing sets). We characterize these parameters for the case of the prime-square order of the field and make a partial characterization for the prime-cube case and the case of the fourth degree of a prime, including a complete characterization for orders 8, 27, and 16.\n  Keywords: spreads, multispreads, additive codes, one-weight codes, completely regular codes, intriguing sets",
      "authors": [
        "Denis S. Krotov",
        "Ivan Yu. Mogilnykh"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Discrete Mathematics (cs.DM)",
        "Combinatorics (math.CO)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2023-12-13T04:00:37+00:00",
          "link": "https://arxiv.org/abs/2312.07883v1",
          "size": "22kb",
          "version": "v1"
        },
        {
          "date": "2023-12-31T07:21:27+00:00",
          "link": "https://arxiv.org/abs/2312.07883v2",
          "size": "25kb",
          "version": "v2"
        },
        {
          "date": "2024-03-19T21:43:28+00:00",
          "link": "https://arxiv.org/abs/2312.07883v3",
          "size": "25kb",
          "version": "v3"
        },
        {
          "date": "2025-06-27T09:17:14+00:00",
          "link": "https://arxiv.org/abs/2312.07883v4",
          "size": "33kb",
          "version": "v4"
        }
      ],
      "title": "Multispreads",
      "links": {
        "Abstract": "https://arxiv.org/abs/2312.07883",
        "HTML": "https://arxiv.org/html/2312.07883v4",
        "PDF": "https://arxiv.org/pdf/2312.07883"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper addresses characterization of parameters in additive codes and multispreads in projective spaces, which does not relate to LLM training data processes."
      },
      "source": "arXiv"
    },
    {
      "id": "2401.08861",
      "abstract": "This paper introduces a novel generative AI (GAI)-driven, unified semi-supervised learning architecture for optimizing resource allocation and network slicing in O-RAN. Termed Generative Semi-Supervised VAE-Contrastive Learning, our approach maximizes the weighted user equipment (UE) throughput and allocates physical resource blocks (PRBs) to enhance the quality of service for eMBB and URLLC services. The GAI framework utilizes a dedicated xApp for intelligent power control and PRB allocation. This integrated GAI model synergistically combines the generative power of a VAE with contrastive learning to achieve robustness in an end-to-end trainable system. It is a semi-supervised training approach that concurrently optimizes supervised regression of resource allocation decisions (i.e., power, UE association, PRB) and unsupervised contrastive objectives. This intrinsic fusion improves the precision of resource management and model generalization in dynamic mobile networks. We evaluated our GAI methodology against exhaustive search and deep Q-Network algorithms using key performance metrics. Results show our integrated GAI approach offers superior efficiency and effectiveness in various scenarios, presenting a compelling GAI-based solution for critical network slicing and resource management challenges in next-generation O-RAN systems.",
      "authors": [
        "Salar Nouri",
        "Mojdeh Karbalaee Motalleb",
        "Vahid Shah-Mansouri",
        "Seyed Pooya Shariatpanahi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Machine Learning (cs.LG)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-01-16T22:23:27+00:00",
          "link": "https://arxiv.org/abs/2401.08861v1",
          "size": "980kb",
          "version": "v1"
        },
        {
          "date": "2024-09-24T19:37:20+00:00",
          "link": "https://arxiv.org/abs/2401.08861v2",
          "size": "1318kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T10:51:47+00:00",
          "link": "https://arxiv.org/abs/2401.08861v3",
          "size": "620kb",
          "version": "v3"
        }
      ],
      "title": "Generative AI for O-RAN Slicing: A Semi-Supervised Approach with VAE and Contrastive Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.08861",
        "HTML": "https://arxiv.org/html/2401.08861v3",
        "PDF": "https://arxiv.org/pdf/2401.08861"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper discusses a novel generative AI-driven architecture for resource allocation and network slicing in O-RAN, which is unrelated to training data processing for LLMs."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2401.10566",
      "abstract": "The estimation of probability density functions is a fundamental problem in science and engineering. However, common methods such as kernel density estimation (KDE) have been demonstrated to lack robustness, while more complex methods have not been evaluated in multi-modal estimation problems. In this paper, we present ROME (RObust Multi-modal Estimator), a non-parametric approach for density estimation which addresses the challenge of estimating multi-modal, non-normal, and highly correlated distributions. ROME utilizes clustering to segment a multi-modal set of samples into multiple uni-modal ones and then combines simple KDE estimates obtained for individual clusters in a single multi-modal estimate. We compared our approach to state-of-the-art methods for density estimation as well as ablations of ROME, showing that it not only outperforms established methods but is also more robust to a variety of distributions. Our results demonstrate that ROME can overcome the issues of over-fitting and over-smoothing exhibited by other estimators.",
      "authors": [
        "Anna M\\'esz\\'aros",
        "Julian F. Schumann",
        "Javier Alonso-Mora",
        "Arkady Zgonnikov",
        "Jens Kober"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2024-01-19T09:10:58+00:00",
          "link": "https://arxiv.org/abs/2401.10566v1",
          "size": "16325kb",
          "version": "v1"
        },
        {
          "date": "2024-05-06T11:59:53+00:00",
          "link": "https://arxiv.org/abs/2401.10566v2",
          "size": "6876kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T12:47:38+00:00",
          "link": "https://arxiv.org/abs/2401.10566v3",
          "size": "6837kb",
          "version": "v3"
        }
      ],
      "title": "ROME: Robust Multi-Modal Density Estimator",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.10566",
        "HTML": "https://arxiv.org/html/2401.10566v3",
        "PDF": "https://arxiv.org/pdf/2401.10566"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper presents ROME, a method for robust density estimation which does not pertain to LLM training data or any aspect of its processing."
      },
      "tasks": [
        "Density Estimation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2401.11212",
      "abstract": "Recent trends like the Internet of Things (IoT) suggest a vision of dense and multi-scale deployments of computing devices in nearly all kinds of environments. A prominent engineering challenge revolves around programming the collective adaptive behaviour of such computational ecosystems. This requires abstractions able to capture concepts like ensembles (dynamic groups of cooperating devices) and collective tasks (joint activities carried out by ensembles). In this work, we consider collections of devices interacting with neighbours and that execute in nearly-synchronised sense-compute-interact rounds, where the computation is given by a single program mapping sensing values and incoming messages to output and outcoming messages. To support programming whole computational collectives, we propose the abstraction of a distributed collective process, which can be used to define at once the ensemble formation logic and its collective task. We formalise the abstraction in the eXchange Calculus (XC), a core functional language based on neighbouring values (maps from neighbours to values) where state and interaction is handled through a single primitive, exchange, and provide a corresponding implementation in the FCPP language. Then, we exercise distributed collective processes using two case studies: multi-hop message propagation and distributed monitoring of spatial properties. Finally, we discuss the features of the abstraction and its suitability for different kinds of distributed computing applications.",
      "authors": [
        "Giorgio Audrito",
        "Roberto Casadei",
        "Ferruccio Damiani",
        "Gianluca Torta",
        "Mirko Viroli"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Artificial Intelligence (cs.AI)",
        "Multiagent Systems (cs.MA)",
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2024-01-20T11:37:44+00:00",
          "link": "https://arxiv.org/abs/2401.11212v1",
          "size": "336kb",
          "version": "v1"
        },
        {
          "date": "2024-11-11T18:26:31+00:00",
          "link": "https://arxiv.org/abs/2401.11212v2",
          "size": "519kb",
          "version": "v2"
        },
        {
          "date": "2025-04-04T15:23:08+00:00",
          "link": "https://arxiv.org/abs/2401.11212v3",
          "size": "519kb",
          "version": "v3"
        },
        {
          "date": "2025-06-27T08:38:23+00:00",
          "link": "https://arxiv.org/abs/2401.11212v4",
          "size": "520kb",
          "version": "v4"
        }
      ],
      "title": "Programming Distributed Collective Processes in the eXchange Calculus",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.11212",
        "PDF": "https://arxiv.org/pdf/2401.11212"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper explores programming distributed collective processes using the eXchange Calculus, which does not address LLM training data processing or related tasks."
      },
      "tasks": [
        "Distributed Computing"
      ],
      "source": "arXiv"
    },
    {
      "id": "2402.02239",
      "abstract": "Unsupervised learning aims to capture the underlying structure of potentially large and high-dimensional datasets. Traditionally, this involves using dimensionality reduction (DR) methods to project data onto lower-dimensional spaces or organizing points into meaningful clusters (clustering). In this work, we revisit these approaches under the lens of optimal transport and exhibit relationships with the Gromov-Wasserstein problem. This unveils a new general framework, called distributional reduction, that recovers DR and clustering as special cases and allows addressing them jointly within a single optimization problem. We empirically demonstrate its relevance to the identification of low-dimensional prototypes representing data at different scales, across multiple image and genomic datasets.",
      "authors": [
        "Hugues Van Assel",
        "C\\'edric Vincent-Cuaz",
        "Nicolas Courty",
        "R\\'emi Flamary",
        "Pascal Frossard",
        "Titouan Vayer"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-03T19:00:19+00:00",
          "link": "https://arxiv.org/abs/2402.02239v1",
          "size": "474kb",
          "version": "v1"
        },
        {
          "date": "2024-05-22T15:34:07+00:00",
          "link": "https://arxiv.org/abs/2402.02239v2",
          "size": "2525kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T07:44:55+00:00",
          "link": "https://arxiv.org/abs/2402.02239v3",
          "size": "1553kb",
          "version": "v3"
        }
      ],
      "title": "Distributional Reduction: Unifying Dimensionality Reduction and Clustering with Gromov-Wasserstein",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.02239",
        "HTML": "https://arxiv.org/html/2402.02239v3",
        "PDF": "https://arxiv.org/pdf/2402.02239"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper proposes a new framework for dimensionality reduction and clustering using Gromov-Wasserstein, without addressing LLM training data engineering or processing tasks."
      },
      "tasks": [
        "Clustering",
        "Dimensionality Reduction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2402.14802",
      "abstract": "The message-passing mechanism underlying Graph Neural Networks (GNNs) is not naturally suited for heterophilic datasets, where adjacent nodes often have different labels. Most solutions to this problem remain confined to the task of node classification. In this article, we focus on the valuable task of link prediction under heterophily, an interesting problem for recommendation systems, social network analysis, and other applications. GNNs like GRAFF have improved node classification under heterophily by incorporating physics biases in the architecture. Similarly, we propose GRAFF-LP, an extension of GRAFF for link prediction. We show that GRAFF-LP effectively discriminates existing from non-existing edges by learning implicitly to separate the edge gradients. Based on this information, we propose a new readout function inspired by physics. Remarkably, this new function not only enhances the performance of GRAFF-LP but also improves that of other baseline models, leading us to reconsider how every link prediction experiment has been conducted so far. Finally, we provide evidence that even simple GNNs did not experience greater difficulty in predicting heterophilic links compared to homophilic ones. This leads us to believe in the necessity for heterophily measures specifically tailored for link prediction, distinct from those used in node classification. The code and appendix are available at https://github.com/difra100/Link_Prediction_with_PIGNN_IJCNN.",
      "authors": [
        "Andrea Giuseppe Di Francesco",
        "Francesco Caso",
        "Maria Sofia Bucarelli and Fabrizio Silvestri"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Information Retrieval (cs.IR)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-22T18:56:31+00:00",
          "link": "https://arxiv.org/abs/2402.14802v1",
          "size": "188kb",
          "version": "v1"
        },
        {
          "date": "2025-04-05T18:19:08+00:00",
          "link": "https://arxiv.org/abs/2402.14802v2",
          "size": "4412kb",
          "version": "v2"
        },
        {
          "date": "2025-06-26T18:15:29+00:00",
          "link": "https://arxiv.org/abs/2402.14802v3",
          "size": "4655kb",
          "version": "v3"
        }
      ],
      "title": "Link Prediction with Physics-Inspired Graph Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.14802",
        "HTML": "https://arxiv.org/html/2402.14802v3",
        "PDF": "https://arxiv.org/pdf/2402.14802"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on enhancing Graph Neural Networks for link prediction tasks in heterophilic graphs, which is unrelated to LLM training data processing. There is no mention of data engineering or data processing tailored for LLMs."
      },
      "tasks": [
        "Graph Neural Network",
        "Link Prediction",
        "Node Classification",
        "Prediction",
        "Recommendation Systems"
      ],
      "source": "arXiv"
    },
    {
      "id": "2403.05518",
      "abstract": "Chain-of-thought prompting (CoT) has the potential to improve the explainability of language model reasoning. But CoT can also systematically misrepresent the factors influencing models' behavior -- for example, rationalizing answers in line with a user's opinion.\n  We first create a new dataset of 9 different biases that affect GPT-3.5-Turbo and Llama-8b models. These consist of spurious-few-shot patterns, post hoc rationalization, and sycophantic settings. Models switch to the answer implied by the bias, without mentioning the effect of the bias in the CoT.\n  To mitigate this biased reasoning problem, we introduce bias-augmented consistency training (BCT), an unsupervised fine-tuning scheme that trains models to give consistent reasoning across prompts with and without biasing features. We construct a suite testing nine forms of biased reasoning on seven question-answering tasks, and find that applying BCT to GPT-3.5-Turbo with one bias reduces the rate of biased reasoning by 86\\% on held-out tasks. Moreover, this model generalizes to other forms of bias, reducing biased reasoning on held-out biases by an average of 37\\%. As BCT generalizes to held-out biases and does not require gold labels, this method may hold promise for reducing biased reasoning from as-of-yet unknown biases and on tasks where ground truth reasoning is unavailable.",
      "authors": [
        "James Chua",
        "Edward Rees",
        "Hunar Batra",
        "Samuel R. Bowman",
        "Julian Michael",
        "Ethan Perez",
        "Miles Turpin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-08T18:41:42+00:00",
          "link": "https://arxiv.org/abs/2403.05518v1",
          "size": "243kb",
          "version": "v1"
        },
        {
          "date": "2025-05-26T19:19:57+00:00",
          "link": "https://arxiv.org/abs/2403.05518v2",
          "size": "2888kb",
          "version": "v2"
        },
        {
          "date": "2025-06-26T19:29:49+00:00",
          "link": "https://arxiv.org/abs/2403.05518v3",
          "size": "403kb",
          "version": "v3"
        }
      ],
      "title": "Bias-Augmented Consistency Training Reduces Biased Reasoning in Chain-of-Thought",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.05518",
        "HTML": "https://arxiv.org/html/2403.05518v3",
        "PDF": "https://arxiv.org/pdf/2403.05518"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces bias-augmented consistency training, an unsupervised fine-tuning scheme for language models, addressing biased reasoning in datasets. This involves a significant contribution to the training-stage data processing for LLMs through fine-tuning to enhance reasoning."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Question Answering"
      ],
      "repo_urls": [
        "https://github.com/raybears/cot-transparency"
      ],
      "source": "arXiv"
    },
    {
      "id": "2403.12988",
      "abstract": "The widespread adoption of computer vision systems has underscored their susceptibility to adversarial attacks, particularly adversarial patch attacks on object detectors. This study evaluates defense mechanisms for the YOLOv5 model against such attacks. Optimized adversarial patches were generated and placed in sensitive image regions, by applying EigenCAM and grid search to determine optimal placement. We tested several defenses, including Segment and Complete (SAC), Inpainting, and Latent Diffusion Models. Our pipeline comprises three main stages: patch application, object detection, and defense analysis. Results indicate that adversarial patches reduce average detection confidence by 22.06\\%. Defenses restored confidence levels by 3.45\\% (SAC), 5.05\\% (Inpainting), and significantly improved them by 26.61\\%, which even exceeds the original accuracy levels, when using the Latent Diffusion Model, highlighting its superior effectiveness in mitigating the effects of adversarial patches.",
      "authors": [
        "Roie Kazoom",
        "Raz Birman and Ofer Hadar"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-04T13:32:48+00:00",
          "link": "https://arxiv.org/abs/2403.12988v1",
          "size": "1311kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T13:45:14+00:00",
          "link": "https://arxiv.org/abs/2403.12988v2",
          "size": "8665kb",
          "version": "v2"
        }
      ],
      "title": "Enhancing Object Detection Robustness: Detecting and Restoring Confidence in the Presence of Adversarial Patch Attacks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.12988",
        "HTML": "https://arxiv.org/html/2403.12988v2",
        "PDF": "https://arxiv.org/pdf/2403.12988"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper's focus is on defenses against adversarial attacks on object detection models and does not address any aspects of data processing relevant to LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2403.15011",
      "abstract": "Cell tracking and segmentation assist biologists in extracting insights from large-scale microscopy time-lapse data. Driven by local accuracy metrics, current tracking approaches often suffer from a lack of long-term consistency and the ability to reconstruct lineage trees correctly. To address this issue, we introduce an uncertainty estimation technique for motion estimation frameworks and extend the multi-hypothesis tracking framework. Our uncertainty estimation lifts motion representations into probabilistic spatial densities using problem-specific test-time augmentations. Moreover, we introduce a novel mitosis-aware assignment problem formulation that allows multi-hypothesis trackers to model cell splits and to resolve false associations and mitosis detections based on long-term conflicts. In our framework, explicit biological knowledge is modeled in assignment costs. We evaluate our approach on nine competitive datasets and demonstrate that we outperform the current state-of-the-art on biologically inspired metrics substantially, achieving improvements by a factor of approximately 6 and uncover new insights into the behavior of motion estimation uncertainty.",
      "authors": [
        "Timo Kaiser",
        "Maximilian Schier",
        "Bodo Rosenhahn"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-22T07:49:55+00:00",
          "link": "https://arxiv.org/abs/2403.15011v1",
          "size": "40878kb",
          "version": "v1"
        },
        {
          "date": "2024-03-25T14:50:47+00:00",
          "link": "https://arxiv.org/abs/2403.15011v2",
          "size": "40878kb",
          "version": "v2"
        },
        {
          "date": "2024-10-09T07:21:56+00:00",
          "link": "https://arxiv.org/abs/2403.15011v3",
          "size": "1585kb",
          "version": "v3"
        },
        {
          "date": "2025-06-26T13:24:33+00:00",
          "link": "https://arxiv.org/abs/2403.15011v4",
          "size": "39449kb",
          "version": "v4"
        },
        {
          "date": "2025-06-27T09:55:51+00:00",
          "link": "https://arxiv.org/abs/2403.15011v5",
          "size": "39449kb",
          "version": "v5"
        }
      ],
      "title": "Cell Tracking according to Biological Needs -- Strong Mitosis-aware Multi-Hypothesis Tracker with Aleatoric Uncertainty",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.15011",
        "HTML": "https://arxiv.org/html/2403.15011v5",
        "PDF": "https://arxiv.org/pdf/2403.15011"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper centers on cell tracking and segmentation improvements for microscopy data, not related to the processing of training data for LLMs."
      },
      "tasks": [
        "Cell Tracking",
        "Motion Estimation",
        "regression"
      ],
      "repo_urls": [
        "https://github.com/timok93/biologicalneeds"
      ],
      "source": "arXiv"
    },
    {
      "id": "2404.08668",
      "abstract": "Recent advances in Pretrained Language Models (PLMs) and Large Language Models (LLMs) have demonstrated transformative capabilities across diverse domains. The field of patent analysis and innovation is not an exception, where natural language processing (NLP) techniques presents opportunities to streamline and enhance important tasks -- such as patent classification and patent retrieval -- in the patent cycle. This not only accelerates the efficiency of patent researchers and applicants, but also opens new avenues for technological innovation and discovery. Our survey provides a comprehensive summary of recent NLP-based methods -- including multimodal ones -- in patent analysis. We also introduce a novel taxonomy for categorization based on tasks in the patent life cycle, as well as the specifics of the methods. This interdisciplinary survey aims to serve as a comprehensive resource for researchers and practitioners who work at the intersection of NLP, Multimodal AI, and patent analysis, as well as patent offices to build efficient patent systems.",
      "authors": [
        "Homaira Huda Shomee",
        "Zhu Wang",
        "Sathya N. Ravi",
        "Sourav Medya"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-02T20:44:06+00:00",
          "link": "https://arxiv.org/abs/2404.08668v1",
          "size": "12088kb",
          "version": "v1"
        },
        {
          "date": "2024-06-18T04:58:56+00:00",
          "link": "https://arxiv.org/abs/2404.08668v2",
          "size": "12092kb",
          "version": "v2"
        },
        {
          "date": "2025-06-26T20:47:15+00:00",
          "link": "https://arxiv.org/abs/2404.08668v3",
          "size": "1068kb",
          "version": "v3"
        }
      ],
      "title": "A Survey on Patent Analysis: From NLP to Multimodal AI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.08668",
        "HTML": "https://arxiv.org/html/2404.08668v3",
        "PDF": "https://arxiv.org/pdf/2404.08668"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper surveys advances in NLP methods, including PLMs and LLMs, and their application in patent analysis, but it does not introduce new data processing methods for LLM training data."
      },
      "tasks": [
        "Retrieval",
        "Survey"
      ],
      "source": "arXiv"
    },
    {
      "id": "2404.14883",
      "abstract": "Understanding the limits of language is a prerequisite for Large Language Models (LLMs) to act as theories of natural language. LLM performance in some language tasks presents both quantitative and qualitative differences from that of humans, however it remains to be determined whether such differences are amenable to model size. This work investigates the critical role of model scaling, determining whether increases in size make up for such differences between humans and models. We test three LLMs from different families (Bard, 137 billion parameters; ChatGPT-3.5, 175 billion; ChatGPT-4, 1.5 trillion) on a grammaticality judgment task featuring anaphora, center embedding, comparatives, and negative polarity. N=1,200 judgments are collected and scored for accuracy, stability, and improvements in accuracy upon repeated presentation of a prompt. Results of the best performing LLM, ChatGPT-4, are compared to results of n=80 humans on the same stimuli. We find that humans are overall less accurate than ChatGPT-4 (76% vs. 80% accuracy, respectively), but that this is due to ChatGPT-4 outperforming humans only in one task condition, namely on grammatical sentences. Additionally, ChatGPT-4 wavers more than humans in its answers (12.5% vs. 9.6% likelihood of an oscillating answer, respectively). Thus, while increased model size may lead to better performance, LLMs are still not sensitive to (un)grammaticality the same way as humans are. It seems possible but unlikely that scaling alone can fix this issue. We interpret these results by comparing language learning in vivo and in silico, identifying three critical differences concerning (i) the type of evidence, (ii) the poverty of the stimulus, and (iii) the occurrence of semantic hallucinations due to impenetrable linguistic reference.",
      "authors": [
        "Vittoria Dentella",
        "Fritz Guenther",
        "Evelina Leivada"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-23T10:09:46+00:00",
          "link": "https://arxiv.org/abs/2404.14883v1",
          "size": "395kb",
          "version": "v1"
        },
        {
          "date": "2024-10-07T11:37:44+00:00",
          "link": "https://arxiv.org/abs/2404.14883v2",
          "size": "561kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T09:50:30+00:00",
          "link": "https://arxiv.org/abs/2404.14883v3",
          "size": "733kb",
          "version": "v3"
        }
      ],
      "title": "Language in Vivo vs. in Silico: Size Matters but Larger Language Models Still Do Not Comprehend Language on a Par with Humans Due to Impenetrable Semantic Reference",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.14883",
        "PDF": "https://arxiv.org/pdf/2404.14883"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on comparing language comprehension in humans versus large language models through language tasks, without discussing the processing of training data for LLMs, data engineering, or any related methods."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2405.04997",
      "abstract": "Over the past few years, deep neural models have made considerable advances in image quality assessment (IQA). However, the underlying reasons for their success remain unclear, owing to the complex nature of deep neural networks. IQA aims to describe how the human visual system (HVS) works and to create its efficient approximations. On the other hand, Saliency Prediction task aims to emulate HVS via determining areas of visual interest. Thus, we believe that saliency plays a crucial role in human perception. In this work, we conduct an empirical study that reveals the relation between IQA and Saliency Prediction tasks, demonstrating that the former incorporates knowledge of the latter. Moreover, we introduce a novel SACID dataset of saliency-aware compressed images and conduct a large-scale comparison of classic and neural-based IQA methods. All supplementary code and data will be available at the time of publication.",
      "authors": [
        "Kirillov Alexey",
        "Andrey Moskalenko",
        "Dmitriy Vatolin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-08T12:04:43+00:00",
          "link": "https://arxiv.org/abs/2405.04997v1",
          "size": "16663kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T17:15:35+00:00",
          "link": "https://arxiv.org/abs/2405.04997v2",
          "size": "1826kb",
          "version": "v2"
        }
      ],
      "title": "Bridging the Gap Between Saliency Prediction and Image Quality Assessment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.04997",
        "HTML": "https://arxiv.org/html/2405.04997v2",
        "PDF": "https://arxiv.org/pdf/2405.04997"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The focus is on image quality assessment and saliency prediction rather than on the processing of training data for large language models."
      },
      "tasks": [
        "Image Quality Assessment",
        "Saliency Prediction"
      ],
      "repo_urls": [
        "https://github.com/alexkkir/sacid"
      ],
      "source": "arXiv"
    },
    {
      "id": "2405.05769",
      "abstract": "Artificial intelligence generative content (AIGC) has significantly impacted image generation in the field of remote sensing. However, the equally important area of remote sensing image (RSI) editing has not received sufficient attention. Deep learning based editing methods generally involve two sequential stages: generation and editing.For natural images, these stages primarily rely on generative backbones pre-trained on large-scale benchmark datasets and text guidance facilitated by vision-language models (VLMs). However, it become less viable for RSIs: First, existing generative RSI benchmark datasets do not fully capture the diversity of RSIs, and is often inadequate for universal editing tasks. Second, the single text semantic corresponds to multiple image semantics, leading to the introduction of incorrect semantics.To solve above problems, this paper proposes a text-guided RSI editing method and can be trained using only a single image. A multi-scale training approach is adopted to preserve consistency without the need for training on extensive benchmarks, while leveraging RSI pre-trained VLMs and prompt ensembling (PE) to ensure accuracy and controllability. Experimental results on multiple RSI editing tasks show that the proposed method offers significant advantages in both CLIP scores and subjective evaluations compared to existing methods. Additionally, we explore the ability of the edited RSIs to support disaster assessment tasks in order to validate their practicality. Codes will be released at https://github.com/HIT-PhilipHan/remote_sensing_image_editing",
      "authors": [
        "Fangzhou Han and Lingyu Si and Zhizhuo Jiang and Hongwei Dong and Lamei Zhang and Yu Liu and Hao Chen and Bo Du"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-09T13:45:04+00:00",
          "link": "https://arxiv.org/abs/2405.05769v1",
          "size": "1561kb",
          "version": "v1"
        },
        {
          "date": "2024-09-26T05:10:23+00:00",
          "link": "https://arxiv.org/abs/2405.05769v2",
          "size": "10118kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T16:23:00+00:00",
          "link": "https://arxiv.org/abs/2405.05769v3",
          "size": "14183kb",
          "version": "v3"
        }
      ],
      "title": "Exploring Text-Guided Single Image Editing for Remote Sensing Images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.05769",
        "HTML": "https://arxiv.org/html/2405.05769v3",
        "PDF": "https://arxiv.org/pdf/2405.05769"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper discusses text-guided image editing for remote sensing images utilizing models pre-trained on benchmark datasets, which does not pertain to LLM training data processing or data engineering for language models."
      },
      "tasks": [
        "Image Generation"
      ],
      "repo_urls": [
        "https://github.com/hit-philiphan/remote_sensing_image_editing"
      ],
      "source": "arXiv"
    },
    {
      "id": "2405.12105",
      "abstract": "Optical Music Recognition (OMR) has made significant progress since its inception, with various approaches now capable of accurately transcribing music scores into digital formats. Despite these advancements, most so-called end-to-end OMR approaches still rely on multi-stage processing pipelines for transcribing full-page score images, which entails challenges such as the need for dedicated layout analysis and specific annotated data, thereby limiting the general applicability of such methods. In this paper, we present the first truly end-to-end approach for page-level OMR in complex layouts. Our system, which combines convolutional layers with autoregressive Transformers, processes an entire music score page and outputs a complete transcription in a music encoding format. This is made possible by both the architecture and the training procedure, which utilizes curriculum learning through incremental synthetic data generation. We evaluate the proposed system using pianoform corpora, which is one of the most complex sources in the OMR literature. This evaluation is conducted first in a controlled scenario with synthetic data, and subsequently against two real-world corpora of varying conditions. Our approach is compared with leading commercial OMR software. The results demonstrate that our system not only successfully transcribes full-page music scores but also outperforms the commercial tool in both zero-shot settings and after fine-tuning with the target domain, representing a significant contribution to the field of OMR.",
      "authors": [
        "Antonio R\\'ios-Vila",
        "Jorge Calvo-Zaragoza",
        "David Rizo",
        "Thierry Paquet"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-20T15:21:48+00:00",
          "link": "https://arxiv.org/abs/2405.12105v1",
          "size": "10265kb",
          "version": "v1"
        },
        {
          "date": "2024-05-21T08:16:00+00:00",
          "link": "https://arxiv.org/abs/2405.12105v2",
          "size": "10265kb",
          "version": "v2"
        },
        {
          "date": "2024-09-21T15:18:58+00:00",
          "link": "https://arxiv.org/abs/2405.12105v3",
          "size": "14617kb",
          "version": "v3"
        },
        {
          "date": "2025-06-27T08:39:52+00:00",
          "link": "https://arxiv.org/abs/2405.12105v4",
          "size": "8958kb",
          "version": "v4"
        }
      ],
      "title": "End-to-End Full-Page Optical Music Recognition for Pianoform Sheet Music",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.12105",
        "HTML": "https://arxiv.org/html/2405.12105v4",
        "PDF": "https://arxiv.org/pdf/2405.12105"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on Optical Music Recognition (OMR) and proposes an end-to-end approach for transcribing music scores, using convolutional layers and Transformers. It does not relate to LLM training data processing."
      },
      "tasks": [
        "Synthetic Data Generation"
      ],
      "repo_urls": [
        "https://github.com/antoniorv6/SMT-plusplus",
        "https://github.com/antoniorv6/fp-smt"
      ],
      "source": "arXiv"
    },
    {
      "id": "2405.15310",
      "abstract": "Linearization of attention using various kernel approximation and kernel learning techniques has shown promise. Past methods used a subset of combinations of component functions and weight matrices within the random feature paradigm. We identify the need for a systematic comparison of different combinations of weight matrices and component functions for attention learning in Transformer. Hence, we introduce Spectraformer, a unified framework for approximating and learning the kernel function in the attention mechanism of the Transformer. Our empirical results demonstrate, for the first time, that a random feature-based approach can achieve performance comparable to top-performing sparse and low-rank methods on the challenging Long Range Arena benchmark. Thus, we establish a new state-of-the-art for random feature-based efficient Transformers. The framework also produces many variants that offer different advantages in accuracy, training time, and memory consumption. Our code is available at: https://github.com/cruiseresearchgroup/spectraformer .",
      "authors": [
        "Duke Nguyen",
        "Du Yin",
        "Aditya Joshi",
        "Flora Salim"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-24T07:52:53+00:00",
          "link": "https://arxiv.org/abs/2405.15310v1",
          "size": "372kb",
          "version": "v1"
        },
        {
          "date": "2024-05-29T04:45:26+00:00",
          "link": "https://arxiv.org/abs/2405.15310v2",
          "size": "372kb",
          "version": "v2"
        },
        {
          "date": "2024-10-23T04:08:23+00:00",
          "link": "https://arxiv.org/abs/2405.15310v3",
          "size": "485kb",
          "version": "v3"
        },
        {
          "date": "2025-06-27T07:39:14+00:00",
          "link": "https://arxiv.org/abs/2405.15310v4",
          "size": "1643kb",
          "version": "v4"
        }
      ],
      "title": "Spectraformer: A Unified Random Feature Framework for Transformer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.15310",
        "HTML": "https://arxiv.org/html/2405.15310v4",
        "PDF": "https://arxiv.org/pdf/2405.15310"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper introduces Spectraformer, a framework for efficiently approximating and learning kernel functions in Transformers. It discusses attention mechanisms and kernel approximations without addressing LLM training data processing."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/dukeraphaelng/spectraformer",
        "https://github.com/dukenguyenxyz/spectraformer"
      ],
      "source": "arXiv"
    },
    {
      "id": "2405.16661",
      "abstract": "Large Language Models (LLMs) have transformed AI but often struggle with tasks that require domain-specific reasoning and logical alignment. Traditional fine-tuning methods do not leverage the vast amount of symbolic domain-knowledge available to us via symbolic reasoning tools (e.g., provers), and are further limited by sparse rewards and unreliable reward models.\n  We introduce Reinforcement Learning via Symbolic Feedback (RLSF), a novel fine-tuning paradigm where symbolic reasoning tools (e.g., solvers, provers, and algebra systems) provide fine-grained feedback to LLMs. RLSF uses poly-sized certificates (e.g., proofs) generated by symbolic tools to identify and correct errors in model outputs, offering token-level guidance without requiring differentiable reasoning systems. This paradigm bridges the gap between symbolic reasoning and LLM fine-tuning, enabling precise alignment with domain-specific constraints while addressing key limitations of traditional reward signals.\n  Via extensive evaluations, we show that our RLSF-based fine-tuning of LLMs outperforms traditional approaches on five different applications (that have some associated logical or domain constraints), namely, program synthesis from natural language pseudo-code to programming language, three chemistry tasks, and solving the Game of 24. A key takeaway is that fine-tuning via RLSF enables relatively smaller LLMs to significantly outperform closed-source models that are orders of magnitude larger.",
      "authors": [
        "Piyush Jha",
        "Prithwish Jana",
        "Pranavkrishna Suresh",
        "Arnav Arora",
        "Vijay Ganesh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-26T18:49:59+00:00",
          "link": "https://arxiv.org/abs/2405.16661v1",
          "size": "351kb",
          "version": "v1"
        },
        {
          "date": "2024-10-05T23:17:18+00:00",
          "link": "https://arxiv.org/abs/2405.16661v2",
          "size": "439kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T00:16:37+00:00",
          "link": "https://arxiv.org/abs/2405.16661v3",
          "size": "423kb",
          "version": "v3"
        }
      ],
      "title": "RLSF: Fine-tuning LLMs via Symbolic Feedback",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.16661",
        "HTML": "https://arxiv.org/html/2405.16661v3",
        "PDF": "https://arxiv.org/pdf/2405.16661"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses a fine-tuning paradigm (RLSF) which involves token-level guidance from symbolic reasoning. It touches on data processing during fine-tuning, but does not involve the design or construction of new LLM training data."
      },
      "tasks": [
        "Logical Reasoning",
        "Natural Language Understanding",
        "Program Synthesis",
        "reinforcement-learning",
        "Reinforcement Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2406.02510",
      "abstract": "Among various aspects of ensuring the responsible design of AI tools for healthcare applications, addressing fairness concerns has been a key focus area. Specifically, given the wide spread of electronic health record (EHR) data and their huge potential to inform a wide range of clinical decision support tasks, improving fairness in this category of health AI tools is of key importance. While such a broad problem (mitigating fairness in EHR-based AI models) has been tackled using various methods, task- and model-agnostic methods are noticeably rare. In this study, we aimed to target this gap by presenting a new pipeline that generates synthetic EHR data, which is not only consistent with (faithful to) the real EHR data but also can reduce the fairness concerns (defined by the end-user) in the downstream tasks, when combined with the real data. We demonstrate the effectiveness of our proposed pipeline across various downstream tasks and two different EHR datasets. Our proposed pipeline can add a widely applicable and complementary tool to the existing toolbox of methods to address fairness in health AI applications, such as those modifying the design of a downstream model. The codebase for our project is available at https://github.com/healthylaife/FairSynth",
      "authors": [
        "Mirza Farhan Bin Tarek",
        "Raphael Poulain",
        "Rahmatollah Beheshti"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-04T17:29:21+00:00",
          "link": "https://arxiv.org/abs/2406.02510v1",
          "size": "58kb",
          "version": "v1"
        },
        {
          "date": "2024-09-22T19:54:14+00:00",
          "link": "https://arxiv.org/abs/2406.02510v2",
          "size": "142kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T14:11:59+00:00",
          "link": "https://arxiv.org/abs/2406.02510v3",
          "size": "134kb",
          "version": "v3"
        }
      ],
      "title": "Fairness-Optimized Synthetic EHR Generation for Arbitrary Downstream Predictive Tasks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.02510",
        "HTML": "https://arxiv.org/html/2406.02510v3",
        "PDF": "https://arxiv.org/pdf/2406.02510"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The study focuses on generating synthetic EHR data for fairness in predictive health tasks. It does not relate to LLM training data but addresses fairness in health data processing."
      },
      "tasks": [
        "Fairness"
      ],
      "repo_urls": [
        "https://github.com/healthylaife/fairsynth"
      ],
      "source": "arXiv"
    },
    {
      "id": "2406.08665",
      "abstract": "Testing is essential to modern software engineering for building reliable software. Given the high costs of manually creating test cases, automated test case generation, particularly methods utilizing large language models, has become increasingly popular. These neural approaches generate semantically meaningful tests that are more maintainable compared with traditional automatic testing methods like fuzzing. However, the diversity and volume of unit tests in current datasets are limited, especially for newer but important languages. In this paper, we present a novel data augmentation technique, FuzzAug, that introduces the benefits of fuzzing to large language models by introducing valid testing semantics and providing diverse coverage-guided inputs. Doubling the size of training datasets, FuzzAug improves the performance from the baselines significantly. This technique demonstrates the potential of introducing prior knowledge from dynamic software analysis to improve neural test generation, offering significant enhancements in neural test generation.",
      "authors": [
        "Yifeng He",
        "Jicheng Wang",
        "Yuyang Rong",
        "Hao Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-12T22:09:27+00:00",
          "link": "https://arxiv.org/abs/2406.08665v1",
          "size": "1400kb",
          "version": "v1"
        },
        {
          "date": "2024-09-13T18:05:46+00:00",
          "link": "https://arxiv.org/abs/2406.08665v2",
          "size": "1361kb",
          "version": "v2"
        },
        {
          "date": "2025-06-26T22:00:02+00:00",
          "link": "https://arxiv.org/abs/2406.08665v3",
          "size": "167kb",
          "version": "v3"
        }
      ],
      "title": "FuzzAug: Data Augmentation by Coverage-guided Fuzzing for Neural Test Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.08665",
        "HTML": "https://arxiv.org/html/2406.08665v3",
        "PDF": "https://arxiv.org/pdf/2406.08665"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a data augmentation technique for neural test generation using large language models. It focuses on expanding the dataset with diverse, coverage-guided inputs, which relates to data quality enhancement but lacks direct contribution to LLM training data pipelines."
      },
      "tasks": [
        "Code Generation",
        "Data Augmentation",
        "Diversity",
        "software testing",
        "valid"
      ],
      "source": "arXiv"
    },
    {
      "id": "2406.10940",
      "abstract": "While high data quality (DQ) is critical for analytics, compliance, and AI performance, data quality management (DQM) remains a complex, resource-intensive, and often manual process. This study investigates the extent to which existing tools support AI-augmented data quality management (DQM) in data warehouse environments. To this end, we conduct a systematic review of 151 DQ tools to evaluate their automation capabilities, particularly in detecting and recommending DQ rules in data warehouses -- a key component of modern data ecosystems. Using a multi-phase screening process based on functionality, trialability, regulatory compliance (e.g., GDPR), and architectural compatibility with data warehouses, only 10 tools met the criteria for AI-augmented DQM. The analysis reveals that most tools emphasize data cleansing and preparation for AI, rather than leveraging AI to improve DQ itself. Although metadata- and ML-based rule detection techniques are present, features such as SQL-based rule specification, reconciliation logic, and explainability of AI-driven recommendations remain scarce. This study offers practical guidance for tool selection and outlines critical design requirements for next-generation AI-driven DQ solutions -- advocating a paradigm shift from ``data quality for AI'' to ``AI for data quality management''.",
      "authors": [
        "Heidi Carolina Tamm and Anastasija Nikiforova"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Databases (cs.DB)",
        "Artificial Intelligence (cs.AI)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-16T13:43:04+00:00",
          "link": "https://arxiv.org/abs/2406.10940v1",
          "size": "2071kb",
          "version": "v1"
        },
        {
          "date": "2025-03-29T18:06:34+00:00",
          "link": "https://arxiv.org/abs/2406.10940v2",
          "size": "2071kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T07:27:32+00:00",
          "link": "https://arxiv.org/abs/2406.10940v3",
          "size": "507kb",
          "version": "v3"
        }
      ],
      "title": "From Data Quality for AI to AI for Data Quality: A Systematic Review of Tools for AI-Augmented Data Quality Management in Data Warehouses",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.10940",
        "PDF": "https://arxiv.org/pdf/2406.10940"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper reviews tools for AI-augmented data quality management, emphasizing data cleansing and preparation for AI. While related to data quality, it does not focus on methodologies tailored for LLM-specific training data pipelines."
      },
      "tasks": [
        "Management"
      ],
      "source": "arXiv"
    },
    {
      "id": "2406.19680",
      "abstract": "In recent years, generative artificial intelligence has achieved significant advancements in the field of image generation, spawning a variety of applications. However, video generation still faces considerable challenges in various aspects, such as controllability, video length, and richness of details, which hinder the application and popularization of this technology. In this work, we propose a controllable video generation framework, dubbed MimicMotion, which can generate high-quality videos of arbitrary length mimicking specific motion guidance. Compared with previous methods, our approach has several highlights. Firstly, we introduce confidence-aware pose guidance that ensures high frame quality and temporal smoothness. Secondly, we introduce regional loss amplification based on pose confidence, which significantly reduces image distortion. Lastly, for generating long and smooth videos, we propose a progressive latent fusion strategy. By this means, we can produce videos of arbitrary length with acceptable resource consumption. With extensive experiments and user studies, MimicMotion demonstrates significant improvements over previous approaches in various aspects. Detailed results and comparisons are available on our project page: https://tencent.github.io/MimicMotion .",
      "authors": [
        "Yuang Zhang",
        "Jiaxi Gu",
        "Li-Wen Wang",
        "Han Wang",
        "Junqi Cheng",
        "Yuefeng Zhu",
        "Fangyuan Zou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-28T06:40:53+00:00",
          "link": "https://arxiv.org/abs/2406.19680v1",
          "size": "6035kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T10:06:13+00:00",
          "link": "https://arxiv.org/abs/2406.19680v2",
          "size": "7641kb",
          "version": "v2"
        }
      ],
      "title": "MimicMotion: High-Quality Human Motion Video Generation with Confidence-aware Pose Guidance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.19680",
        "HTML": "https://arxiv.org/html/2406.19680v2",
        "PDF": "https://arxiv.org/pdf/2406.19680"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper addresses a novel video generation framework focusing on human motion video quality, which is unrelated to the processing of training data for large language models."
      },
      "tasks": [
        "Image Generation",
        "Video Generation"
      ],
      "repo_urls": [
        "https://github.com/vita-epfl/stay-on-track"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.01511",
      "abstract": "The development of autonomous agents increasingly relies on Multimodal Language Models (MLMs) to perform tasks described in natural language with GUI environments, such as websites, desktop computers, or mobile phones. Existing benchmarks for MLM agents in interactive environments are limited by their focus on a single environment, lack of detailed and generalized evaluation methods, and the complexities of constructing tasks and evaluators. To overcome these limitations, we introduce Crab, the first agent benchmark framework designed to support cross-environment tasks, incorporating a graph-based fine-grained evaluation method and an efficient mechanism for task and evaluator construction. Our framework supports multiple devices and can be easily extended to any environment with a Python interface. Leveraging Crab, we developed a cross-platform Crab Benchmark-v0 comprising 120 tasks in computer desktop and mobile phone environments. We evaluated four advanced MLMs using different single and multi-agent system configurations on this benchmark. The experimental results demonstrate that the single agent with GPT-4o achieves the best completion ratio of 38.01%. All framework code, agent code, and task datasets are publicly available at https://github.com/camel-ai/crab.",
      "authors": [
        "Tianqi Xu",
        "Linyao Chen",
        "Dai-Jie Wu",
        "Yanjun Chen",
        "Zecheng Zhang",
        "Xiang Yao",
        "Zhiqiang Xie",
        "Yongchao Chen",
        "Shilong Liu",
        "Bochen Qian",
        "Anjie Yang",
        "Zhaoxuan Jin",
        "Jianbo Deng",
        "Philip Torr",
        "Bernard Ghanem",
        "Guohao Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-01T17:55:04+00:00",
          "link": "https://arxiv.org/abs/2407.01511v1",
          "size": "30775kb",
          "version": "v1"
        },
        {
          "date": "2024-10-18T11:29:39+00:00",
          "link": "https://arxiv.org/abs/2407.01511v2",
          "size": "30817kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T17:01:09+00:00",
          "link": "https://arxiv.org/abs/2407.01511v3",
          "size": "31241kb",
          "version": "v3"
        }
      ],
      "title": "CRAB: Cross-environment Agent Benchmark for Multimodal Language Model Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.01511",
        "HTML": "https://arxiv.org/html/2407.01511v3",
        "PDF": "https://arxiv.org/pdf/2407.01511"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on benchmarking multimodal language model agents across different environments and does not address any aspect of LLM training data collection, construction, or processing."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling"
      ],
      "repo_urls": [
        "https://github.com/camel-ai/crab"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.06136",
      "abstract": "Few-shot class-incremental learning (FSCIL) aims to incrementally learn novel classes from limited examples while preserving knowledge of previously learned classes. Existing methods face a critical dilemma: static architectures rely on a fixed parameter space to learn from data that arrive sequentially, prone to overfitting to the current session, while dynamic architectures require the expansion of the parameter space continually, leading to increased complexity. In this study, we explore the potential of Selective State Space Models (SSMs) for FSCIL. Mamba leverages its input-dependent parameters to dynamically adjust its processing patterns and generate content-aware scan patterns within a fixed architecture. This enables it to configure distinct processing for base and novel classes, effectively preserving existing knowledge while adapting to new ones. To leverage Mamba's potential for FSCIL, we design two key modules: First, we propose a dual selective SSM projector that dynamically adjusts the projection parameters based on the intermediate features for dynamic adaptation. The dual-design structurally decouples base and novel class processing with a frozen base branch, employing a frozen base branch to maintain robust base-class features and a dynamic incremental branch that adaptively learns distinctive feature shifts for novel classes. Second, we develop a class-sensitive selective scan mechanism to guide dynamic adaptation of the incremental branch. It minimizes the disruption to base-class representations caused by training on novel data, and meanwhile, forces the selective scan to perform in distinct patterns between base and novel classes. Extensive experiments on miniImageNet, CUB-200, and CIFAR-100 demonstrate that Mamba-FSCIL achieves state-of-the-art performance. The code is available at https://github.com/xiaojieli0903/Mamba-FSCIL.",
      "authors": [
        "Xiaojie Li",
        "Yibo Yang",
        "Jianlong Wu",
        "Yue Yu",
        "Ming-Hsuan Yang",
        "Liqiang Nie",
        "Min Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-08T17:09:39+00:00",
          "link": "https://arxiv.org/abs/2407.06136v1",
          "size": "1256kb",
          "version": "v1"
        },
        {
          "date": "2024-08-21T15:32:26+00:00",
          "link": "https://arxiv.org/abs/2407.06136v2",
          "size": "3681kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T03:48:50+00:00",
          "link": "https://arxiv.org/abs/2407.06136v3",
          "size": "3575kb",
          "version": "v3"
        }
      ],
      "title": "Mamba-FSCIL: Dynamic Adaptation with Selective State Space Model for Few-Shot Class-Incremental Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.06136",
        "HTML": "https://arxiv.org/html/2407.06136v3",
        "PDF": "https://arxiv.org/pdf/2407.06136"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This study on few-shot class-incremental learning with selective state space models does not involve any discussion on LLM training data processing or data engineering."
      },
      "tasks": [
        "class-incremental learning",
        "Class Incremental Learning",
        "Few-Shot Class-Incremental Learning",
        "Incremental Learning",
        "Mamba",
        "State Space Models"
      ],
      "repo_urls": [
        "https://github.com/xiaojieli0903/mamba-fscil"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.07495",
      "abstract": "Large Language Models (LLMs) have demonstrated exceptional performance across various tasks, with pre-training stage serving as the cornerstone of their capabilities. However, the conventional fixed-length data composition strategy for pre-training presents several practical challenges. When using shorter sequences, documents are often truncated, potentially leading to information loss and affecting the model's ability to capture long-range dependencies. Conversely, longer sequences require concatenation of multiple documents, which can introduce noise and affect the natural document boundaries and semantic coherence as well as require substantial computational overhead. To address these challenges, we first establish three quantitative metrics for evaluating data composition quality: padding ratio, truncation ratio, and concatenation ratio. Building upon these metrics, we propose a novel multi-bucket data composition method that transcends the fixed-length paradigm. Our approach adaptively organizes training data to achieve optimal composition quality as measured by the proposed metrics, offering a more flexible and efficient approach for pre-training. We conduct extensive experiments and the results demonstrate that our proposed method significantly enhances both the efficiency and effectiveness of LLM pre-training.",
      "authors": [
        "Qing Yang",
        "Qiyao Peng",
        "Hongtao Liu",
        "Kai Liu",
        "Bing Qin",
        "Ting Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-10T09:27:23+00:00",
          "link": "https://arxiv.org/abs/2407.07495v1",
          "size": "235kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T10:33:27+00:00",
          "link": "https://arxiv.org/abs/2407.07495v2",
          "size": "258kb",
          "version": "v2"
        }
      ],
      "title": "Beyond Fixed Length: Bucket Pre-training is All You Need",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.07495",
        "HTML": "https://arxiv.org/html/2407.07495v2",
        "PDF": "https://arxiv.org/pdf/2407.07495"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces a novel multi-bucket data composition method for improving LLM pre-training efficiency and effectiveness, directly addressing innovative data processing strategies for LLMs."
      },
      "tasks": [
        "All"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.07596",
      "abstract": "Many social programs attempt to allocate scarce resources to people with the greatest need. Indeed, public services increasingly use algorithmic risk assessments motivated by this goal. However, targeting the highest-need recipients often conflicts with attempting to evaluate the causal effect of the program as a whole, as the best evaluations would be obtained by randomizing the allocation. We propose a framework to design randomized allocation rules which optimally balance targeting high-need individuals with learning treatment effects, presenting policymakers with a Pareto frontier between the two goals. We give sample complexity guarantees for the policy learning problem and provide a computationally efficient strategy to implement it. We then collaborate with the human services department of Allegheny County, Pennsylvania to evaluate our methods on data from real service delivery settings. Optimized policies can substantially mitigate the tradeoff between learning and targeting. For example, it is often possible to obtain 90% of the optimal utility in targeting high-need individuals while ensuring that the average treatment effect can be estimated with less than 2 times the samples that a randomized controlled trial would require. Mechanisms for targeting public services often focus on measuring need as accurately as possible. However, our results suggest that algorithmic systems in public services can be most impactful if they incorporate program evaluation as an explicit goal alongside targeting.",
      "authors": [
        "Bryan Wilder",
        "Pim Welle"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Methodology (stat.ME)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-10T12:29:46+00:00",
          "link": "https://arxiv.org/abs/2407.07596v1",
          "size": "588kb",
          "version": "v1"
        },
        {
          "date": "2025-06-26T19:20:30+00:00",
          "link": "https://arxiv.org/abs/2407.07596v2",
          "size": "418kb",
          "version": "v2"
        }
      ],
      "title": "Learning treatment effects while treating those in need",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.07596",
        "HTML": "https://arxiv.org/html/2407.07596v2",
        "PDF": "https://arxiv.org/pdf/2407.07596"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The research addresses algorithmic approaches for optimizing resource allocation in social programs and does not pertain to LLM training data processing or data engineering."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2407.09550",
      "abstract": "This study uses CAPM (Convex Adversarial Polytope for Maxpool-based CNN) to improve the verified bound for general purpose maxpool-based convolutional neural networks (CNNs) under bounded norm adversarial perturbations. The maxpool function is decomposed as a series of ReLU functions to extend the convex relaxation technique to maxpool functions, by which the verified bound can be efficiently computed through a dual network. The experimental results demonstrate that this technique allows the state-of-the-art verification precision for maxpool-based CNNs and involves a much lower computational cost than current verification methods, such as DeepZ, DeepPoly and PRIMA. This method is also applicable to large-scale CNNs, which previous studies show to be often computationally prohibitively expensive. Under certain circumstances, CAPM is 40-times, 20-times or twice as fast and give a significantly higher verification bound (CAPM 98% vs. PRIMA 76%/DeepPoly 73%/DeepZ 8%) as compared to PRIMA/DeepPoly/DeepZ. Furthermore, we additionally present the time complexity of our algorithm as $O(W^2NK)$, where $W$ is the maximum width of the neural network, $N$ is the number of neurons, and $K$ is the size of the maxpool layer's kernel.",
      "authors": [
        "Jia-Hau Bai",
        "Chi-Ting Liu",
        "Yu Wang",
        "Fu-Chieh Chang",
        "Pei-Yuan Wu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-27T14:43:06+00:00",
          "link": "https://arxiv.org/abs/2407.09550v1",
          "size": "8298kb",
          "version": "v1"
        },
        {
          "date": "2025-04-08T15:51:23+00:00",
          "link": "https://arxiv.org/abs/2407.09550v2",
          "size": "2620kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T09:26:12+00:00",
          "link": "https://arxiv.org/abs/2407.09550v3",
          "size": "2127kb",
          "version": "v3"
        }
      ],
      "title": "CAPM: Fast and Robust Verification on Maxpool-based CNN via Dual Network",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.09550",
        "HTML": "https://arxiv.org/html/2407.09550v3",
        "PDF": "https://arxiv.org/pdf/2407.09550"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper discusses verification techniques for maxpool-based CNNs and does not focus on LLM training data collection or processing methods."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2408.05609",
      "abstract": "The sheer scale and diversity of transportation make it a formidable sector to decarbonize. Here, we consider an emerging opportunity to reduce carbon emissions: the growing adoption of semi-autonomous vehicles, which can be programmed to mitigate stop-and-go traffic through intelligent speed commands and, thus, reduce emissions. But would such dynamic eco-driving move the needle on climate change? A comprehensive impact analysis has been out of reach due to the vast array of traffic scenarios and the complexity of vehicle emissions. We address this challenge with large-scale scenario modeling efforts and by using multi-task deep reinforcement learning with a carefully designed network decomposition strategy. We perform an in-depth prospective impact assessment of dynamic eco-driving at 6,011 signalized intersections across three major US metropolitan cities, simulating a million traffic scenarios. Overall, we find that vehicle trajectories optimized for emissions can cut city-wide intersection carbon emissions by 11-22%, without harming throughput or safety, and with reasonable assumptions, equivalent to the national emissions of Israel and Nigeria, respectively. We find that 10% eco-driving adoption yields 25%-50% of the total reduction, and nearly 70% of the benefits come from 20% of intersections, suggesting near-term implementation pathways. However, the composition of this high-impact subset of intersections varies considerably across different adoption levels, with minimal overlap, calling for careful strategic planning for eco-driving deployments. Moreover, the impact of eco-driving, when considered jointly with projections of vehicle electrification and hybrid vehicle adoption remains significant. More broadly, this work paves the way for large-scale analysis of traffic externalities, such as time, safety, and air quality, and the potential impact of solution strategies.",
      "authors": [
        "Vindula Jayawardana",
        "Baptiste Freydt",
        "Ao Qu",
        "Cameron Hickert",
        "Edgar Sanchez",
        "Catherine Tang",
        "Mark Taylor",
        "Blaine Leonard",
        "Cathy Wu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Multiagent Systems (cs.MA)",
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-10T18:23:59+00:00",
          "link": "https://arxiv.org/abs/2408.05609v1",
          "size": "27770kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T07:16:41+00:00",
          "link": "https://arxiv.org/abs/2408.05609v2",
          "size": "27402kb",
          "version": "v2"
        }
      ],
      "title": "Mitigating Metropolitan Carbon Emissions with Dynamic Eco-driving at Scale",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.05609",
        "HTML": "https://arxiv.org/html/2408.05609v2",
        "PDF": "https://arxiv.org/pdf/2408.05609"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The research focuses on carbon emissions reduction via eco-driving simulation models and does not involve any aspect of LLM training data collection or processing."
      },
      "tasks": [
        "Autonomous Vehicles",
        "Deep Reinforcement Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.07461",
      "abstract": "While there is a widespread belief that artificial general intelligence (AGI) -- or even superhuman AI -- is imminent, complex problems in expert domains are far from being solved. We argue that such problems require human-AI cooperation and that the current state of the art in generative AI is unable to play the role of a reliable partner due to a multitude of shortcomings, including difficulty to keep track of a complex solution artifact (e.g., a software program), limited support for versatile human preference expression and lack of adapting to human preference in an interactive setting. To address these challenges, we propose HAICo2, a novel human-AI co-construction framework. We take first steps towards a formalization of HAICo2 and discuss the difficult open research problems that it faces.",
      "authors": [
        "Subhabrata Dutta",
        "Timo Kaufmann",
        "Goran Glava\\v{s}",
        "Ivan Habernal",
        "Kristian Kersting",
        "Frauke Kreuter",
        "Mira Mezini",
        "Iryna Gurevych",
        "Eyke H\\\"ullermeier",
        "Hinrich Schuetze"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-14T11:06:57+00:00",
          "link": "https://arxiv.org/abs/2408.07461v1",
          "size": "1974kb",
          "version": "v1"
        },
        {
          "date": "2024-08-15T15:54:58+00:00",
          "link": "https://arxiv.org/abs/2408.07461v2",
          "size": "1974kb",
          "version": "v2"
        },
        {
          "date": "2024-11-11T11:44:20+00:00",
          "link": "https://arxiv.org/abs/2408.07461v3",
          "size": "2065kb",
          "version": "v3"
        },
        {
          "date": "2025-04-29T13:57:16+00:00",
          "link": "https://arxiv.org/abs/2408.07461v4",
          "size": "2124kb",
          "version": "v4"
        },
        {
          "date": "2025-06-27T08:22:34+00:00",
          "link": "https://arxiv.org/abs/2408.07461v5",
          "size": "423kb",
          "version": "v5"
        }
      ],
      "title": "Problem Solving Through Human-AI Preference-Based Cooperation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.07461",
        "HTML": "https://arxiv.org/html/2408.07461v5",
        "PDF": "https://arxiv.org/pdf/2408.07461"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper presents a framework for human-AI cooperation in problem-solving and does not discuss LLM training data or its processing at any stage."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2408.11240",
      "abstract": "In this paper, the causal bandit problem is investigated, with the objective of maximizing the long-term reward by selecting an optimal sequence of interventions on nodes in an unknown causal graph. It is assumed that both the causal topology and the distribution of interventions are unknown. First, based on the difference between the two types of graph identification errors (false positives and negatives), a causal graph learning method is proposed. Numerical results suggest that this method has a much lower sample complexity relative to the prior art by learning sub-graphs. However, we note that a sample complexity analysis for the new algorithm has not been undertaken, as of yet. Under the assumption of minimum-mean squared error weight estimation, a new uncertainty bound tailored to the causal bandit problem is derived. This uncertainty bound drives an upper confidence bound-based intervention selection to optimize the reward. Further, we consider a particular instance of non-stationary bandits wherein both the causal topology and interventional distributions can change. Our solution is the design of a sub-graph change detection mechanism that requires a modest number of samples. Numerical results compare the new methodology to existing schemes and show a substantial performance improvement in stationary and non-stationary settings. Averaged over 100 randomly generated causal bandits, the proposed scheme takes significantly fewer samples to learn the causal structure and achieves a reward gain of 85% compared to existing approaches.",
      "authors": [
        "Chen Peng",
        "Di Zhang and Urbashi Mitra"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-20T23:37:08+00:00",
          "link": "https://arxiv.org/abs/2408.11240v1",
          "size": "409kb",
          "version": "v1"
        },
        {
          "date": "2025-06-26T20:05:51+00:00",
          "link": "https://arxiv.org/abs/2408.11240v2",
          "size": "423kb",
          "version": "v2"
        }
      ],
      "title": "Asymmetric Graph Error Control with Low Complexity in Causal Bandits",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.11240",
        "HTML": "https://arxiv.org/html/2408.11240v2",
        "PDF": "https://arxiv.org/pdf/2408.11240"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on causal bandit problems and graph learning, which are not related to LLM training data processing. It deals with interventions on nodes in causal graphs and uncertainty bounds for a different set of challenges."
      },
      "tasks": [
        "Change Detection",
        "Graph Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.11856",
      "abstract": "Sentiment analysis plays a crucial role in various domains, such as business intelligence and financial forecasting. Large language models (LLMs) have become a popular paradigm for sentiment analysis, leveraging multi-task learning to address specific tasks concurrently. However, LLMs with fine-tuning for sentiment analysis often underperforms due to the inherent challenges in managing diverse task complexities. Moreover, constant-weight approaches in multi-task learning struggle to adapt to variations in data characteristics, further complicating model effectiveness. To address these issues, we propose a novel multi-task learning framework with a dynamic adaptive optimization (DAO) module. This module is designed as a plug-and-play component that can be seamlessly integrated into existing models, providing an effective and flexible solution for multi-task learning. The key component of the DAO module is dynamic adaptive loss, which dynamically adjusts the weights assigned to different tasks based on their relative importance and data characteristics during training. Sentiment analyses on a standard and customized financial text dataset demonstrate that the proposed framework achieves superior performance. Specifically, this work improves the Mean Squared Error (MSE) and Accuracy (ACC) by 15.58% and 1.24% respectively, compared with previous work.",
      "authors": [
        "Hongcheng Ding",
        "Xuanze Zhao",
        "Ruiting Deng",
        "Shamsul Nahar Abdullah",
        "Deshinta Arrova Dewi",
        "Zixiao Jiang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-15T19:13:38+00:00",
          "link": "https://arxiv.org/abs/2408.11856v1",
          "size": "2101kb",
          "version": "v1"
        },
        {
          "date": "2024-11-12T05:37:15+00:00",
          "link": "https://arxiv.org/abs/2408.11856v2",
          "size": "2102kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T06:13:14+00:00",
          "link": "https://arxiv.org/abs/2408.11856v3",
          "size": "1958kb",
          "version": "v3"
        }
      ],
      "title": "Dynamic Adaptive Optimization for Effective Sentiment Analysis Fine-Tuning on Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.11856",
        "HTML": "https://arxiv.org/html/2408.11856v3",
        "PDF": "https://arxiv.org/pdf/2408.11856"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses a fine-tuning method for sentiment analysis using LLMs, touching on data characteristics affecting model effectiveness. It does not present novel methods for training data processing, primarily enhancing models' optimization during training."
      },
      "tasks": [
        "Multi-Task Learning",
        "Sentiment Analysis"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.15237",
      "abstract": "Linear RNN architectures, like Mamba, can be competitive with Transformer models in language modeling while having advantageous deployment characteristics. Given the focus on training large-scale Transformer models, we consider the challenge of converting these pretrained models for deployment. We demonstrate that it is feasible to distill large Transformers into linear RNNs by reusing the linear projection weights from attention layers with academic GPU resources. The resulting hybrid model, which incorporates a quarter of the attention layers, achieves performance comparable to the original Transformer in chat benchmarks and outperforms open-source hybrid Mamba models trained from scratch with trillions of tokens in both chat benchmarks and general benchmarks. Moreover, we introduce a hardware-aware speculative decoding algorithm that accelerates the inference speed of Mamba and hybrid models. Overall we show how, with limited computation resources, we can remove many of the original attention layers and generate from the resulting model more efficiently. Our top-performing model, distilled from Llama3-8B-Instruct, achieves a 29.61 length-controlled win rate on AlpacaEval 2 against GPT-4 and 7.35 on MT-Bench, surpassing the best 8B scale instruction-tuned linear RNN model. We also find that the distilled model has natural length extrapolation, showing almost perfect accuracy in the needle-in-a-haystack test at 20x the distillation length. Code and pre-trained checkpoints are open-sourced at https://github.com/jxiw/MambaInLlama and https://github.com/itsdaniele/speculative_mamba.",
      "authors": [
        "Junxiong Wang",
        "Daniele Paliotta",
        "Avner May",
        "Alexander M. Rush",
        "and Tri Dao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-27T17:56:11+00:00",
          "link": "https://arxiv.org/abs/2408.15237v1",
          "size": "3726kb",
          "version": "v1"
        },
        {
          "date": "2024-12-26T05:27:51+00:00",
          "link": "https://arxiv.org/abs/2408.15237v2",
          "size": "4508kb",
          "version": "v2"
        },
        {
          "date": "2025-01-08T20:34:02+00:00",
          "link": "https://arxiv.org/abs/2408.15237v3",
          "size": "4499kb",
          "version": "v3"
        },
        {
          "date": "2025-06-27T07:54:57+00:00",
          "link": "https://arxiv.org/abs/2408.15237v4",
          "size": "934kb",
          "version": "v4"
        }
      ],
      "title": "The Mamba in the Llama: Distilling and Accelerating Hybrid Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.15237",
        "HTML": "https://arxiv.org/html/2408.15237v4",
        "PDF": "https://arxiv.org/pdf/2408.15237"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses the distillation of Transformer models into RNN architectures, focusing on deployment and inference efficiency. It does not focus on training data processing techniques for LLMs but rather on model transformation."
      },
      "models": [
        {
          "model_path": "JunxiongWang/mamba_0_5_dpo_ep1",
          "downloads": "18",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/JunxiongWang/mamba_0_5_dpo_ep1"
        },
        {
          "model_path": "JunxiongWang/mamba_0_5_dpo_ep3",
          "downloads": "12",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/JunxiongWang/mamba_0_5_dpo_ep3"
        },
        {
          "model_path": "JunxiongWang/mamba_0_875_dpo_ep3",
          "downloads": "16",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/JunxiongWang/mamba_0_875_dpo_ep3"
        },
        {
          "model_path": "JunxiongWang/mamba_0_875_dpo_ep1",
          "downloads": "13",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/JunxiongWang/mamba_0_875_dpo_ep1"
        },
        {
          "model_path": "JunxiongWang/mamba_0_75_dpo_ep3",
          "downloads": "17",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/JunxiongWang/mamba_0_75_dpo_ep3"
        },
        {
          "model_path": "JunxiongWang/mamba_0_75_dpo_ep1",
          "downloads": "22",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/JunxiongWang/mamba_0_75_dpo_ep1"
        },
        {
          "model_path": "JunxiongWang/MambaInLlama_0_50",
          "downloads": "32",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/JunxiongWang/MambaInLlama_0_50"
        },
        {
          "model_path": "JunxiongWang/Mamba2InLlama_0_50",
          "downloads": "17",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/JunxiongWang/Mamba2InLlama_0_50"
        },
        {
          "model_path": "JunxiongWang/MambaInLlama_0_75",
          "downloads": "9",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/JunxiongWang/MambaInLlama_0_75"
        },
        {
          "model_path": "JunxiongWang/Mamba2InLlama_0_75",
          "downloads": "18",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/JunxiongWang/Mamba2InLlama_0_75"
        },
        {
          "model_path": "JunxiongWang/Mamba2InLlama_0_875",
          "downloads": "12",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/JunxiongWang/Mamba2InLlama_0_875"
        },
        {
          "model_path": "JunxiongWang/MambaInLlama_0_875",
          "downloads": "13",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/JunxiongWang/MambaInLlama_0_875"
        },
        {
          "model_path": "JunxiongWang/Mamba2InLlama_1",
          "downloads": "80",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/JunxiongWang/Mamba2InLlama_1"
        },
        {
          "model_path": "JunxiongWang/Llama3.2-Mamba2-3B-distill",
          "downloads": "1746",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/JunxiongWang/Llama3.2-Mamba2-3B-distill"
        },
        {
          "model_path": "JunxiongWang/Llama3.2-Mamba2-3B-dpo",
          "downloads": "46",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/JunxiongWang/Llama3.2-Mamba2-3B-dpo"
        },
        {
          "model_path": "JunxiongWang/Llama3.1-Mamba2-8B-distill",
          "downloads": "1732",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/JunxiongWang/Llama3.1-Mamba2-8B-distill"
        },
        {
          "model_path": "JunxiongWang/Llama3.2-Mamba-3B-distill",
          "downloads": "12",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/JunxiongWang/Llama3.2-Mamba-3B-distill"
        },
        {
          "model_path": "JunxiongWang/Llama3.1-Mamba-8B-distill",
          "downloads": "8",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/JunxiongWang/Llama3.1-Mamba-8B-distill"
        },
        {
          "model_path": "JunxiongWang/Llama3.1-Mamba2-8B-dpo",
          "downloads": "9",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/JunxiongWang/Llama3.1-Mamba2-8B-dpo"
        },
        {
          "model_path": "JunxiongWang/Llama3.1-Mamba-8B-dpo",
          "downloads": "7",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/JunxiongWang/Llama3.1-Mamba-8B-dpo"
        },
        {
          "model_path": "JunxiongWang/Llama3.2-Mamba-3B-dpo",
          "downloads": "7",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/JunxiongWang/Llama3.2-Mamba-3B-dpo"
        }
      ],
      "datasets": [
        {
          "dataset_name": "JunxiongWang/sftdataset",
          "downloads": "132",
          "likes": "2",
          "link": "https://huggingface.co/datasets/JunxiongWang/sftdataset"
        },
        {
          "dataset_name": "JunxiongWang/sftdatasetv3",
          "downloads": "1145",
          "likes": "1",
          "link": "https://huggingface.co/datasets/JunxiongWang/sftdatasetv3"
        }
      ],
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Mamba"
      ],
      "repo_urls": [
        "https://github.com/itsdaniele/speculative_mamba",
        "https://github.com/jxiw/mambainllama"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.15533",
      "abstract": "Retrieval-Augmented Generation (RAG) has become a primary technique for mitigating hallucinations in large language models (LLMs). However, incomplete knowledge extraction and insufficient understanding can still mislead LLMs to produce irrelevant or even contradictory responses, which means hallucinations persist in RAG. In this paper, we propose LRP4RAG, a method based on the Layer-wise Relevance Propagation (LRP) algorithm for detecting hallucinations in RAG. Specifically, we first utilize LRP to compute the relevance between the input and output of the RAG generator. We then apply further extraction and resampling to the relevance matrix. The processed relevance data are input into multiple classifiers to determine whether the output contains hallucinations. To the best of our knowledge, this is the first time that LRP has been used for detecting RAG hallucinations, and extensive experiments demonstrate that LRP4RAG outperforms existing baselines.",
      "authors": [
        "Haichuan Hu",
        "Congqing He",
        "Xiaochen Xie",
        "Quanjun Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-28T04:44:43+00:00",
          "link": "https://arxiv.org/abs/2408.15533v1",
          "size": "336kb",
          "version": "v1"
        },
        {
          "date": "2024-08-29T08:45:30+00:00",
          "link": "https://arxiv.org/abs/2408.15533v2",
          "size": "338kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T06:14:36+00:00",
          "link": "https://arxiv.org/abs/2408.15533v3",
          "size": "861kb",
          "version": "v3"
        }
      ],
      "title": "LRP4RAG: Detecting Hallucinations in Retrieval-Augmented Generation via Layer-wise Relevance Propagation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.15533",
        "HTML": "https://arxiv.org/html/2408.15533v3",
        "PDF": "https://arxiv.org/pdf/2408.15533"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The research addresses hallucination detection in retrieval-augmented generation, with no contribution to the area of LLM training data processing or preprocessing methodologies."
      },
      "tasks": [
        "RAG",
        "Retrieval",
        "Retrieval-augmented Generation"
      ],
      "repo_urls": [
        "https://github.com/tomsawyerhu/lrp4rag",
        "https://github.com/rachtibat/lrp-for-transformers",
        "https://github.com/rachtibat/lrp-explains-transformers"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.01115",
      "abstract": "This article presents a new approach based on MiniRocket, called SelF-Rocket, for fast time series classification (TSC). Unlike existing approaches based on random convolution kernels, it dynamically selects the best couple of input representations and pooling operator during the training process. SelF-Rocket achieves state-of-the-art accuracy on the University of California Riverside (UCR) TSC benchmark datasets.",
      "authors": [
        "Mouhamadou Mansour Lo",
        "Gildas Morvan",
        "Mathieu Rossi",
        "Fabrice Morganti",
        "David Mercier"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-02T09:42:17+00:00",
          "link": "https://arxiv.org/abs/2409.01115v1",
          "size": "3032kb",
          "version": "v1"
        },
        {
          "date": "2025-03-04T07:52:43+00:00",
          "link": "https://arxiv.org/abs/2409.01115v2",
          "size": "6787kb",
          "version": "v2"
        },
        {
          "date": "2025-04-13T07:16:10+00:00",
          "link": "https://arxiv.org/abs/2409.01115v3",
          "size": "6985kb",
          "version": "v3"
        },
        {
          "date": "2025-06-27T08:03:42+00:00",
          "link": "https://arxiv.org/abs/2409.01115v4",
          "size": "268kb",
          "version": "v4"
        }
      ],
      "title": "Time series classification with random convolution kernels: pooling operators and input representations matter",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.01115",
        "HTML": "https://arxiv.org/html/2409.01115v4",
        "PDF": "https://arxiv.org/pdf/2409.01115"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper introduces SelF-Rocket for time series classification, focusing on input representations and pooling operators, and does not involve or contribute to the processing of LLM training data."
      },
      "tasks": [
        "feature selection",
        "Time Series",
        "Time Series Classification"
      ],
      "repo_urls": [
        "https://github.com/msd-irimas/multi_comparison_matrix",
        "https://github.com/ANR-MYEL/SelF-Rocket"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.02481",
      "abstract": "Effective question classification is crucial for AI-driven educational tools, enabling adaptive learning systems to categorize questions by skill area, difficulty level, and competence. It not only supports educational diagnostics and analytics but also enhances complex downstream tasks like information retrieval and question answering by associating questions with relevant categories. Traditional methods, often based on word embeddings and conventional classifiers, struggle to capture the nuanced relationships in question statements, leading to suboptimal performance. We propose a novel approach leveraging graph convolutional networks, named Phrase Question-Graph Convolutional Network (PQ-GCN). Through PQ-GCN, we evaluate the incorporation of phrase-based features to enhance classification performance on question datasets of various domains and characteristics. The proposed method, augmented with phrase-based features, outperform baseline graph-based methods in low-resource settings, and performs competitively against language model-based methods with a fraction of their parameter size. Our findings offer a possible solution for more context-aware, parameter-efficient question classification, bridging the gap between graph neural network research and its educational applications.",
      "authors": [
        "Junyoung Lee",
        "Ninad Dixit",
        "Kaustav Chakrabarti",
        "S. Supraja"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-04T07:13:30+00:00",
          "link": "https://arxiv.org/abs/2409.02481v1",
          "size": "257kb",
          "version": "v1"
        },
        {
          "date": "2025-01-21T16:03:05+00:00",
          "link": "https://arxiv.org/abs/2409.02481v2",
          "size": "571kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T06:18:39+00:00",
          "link": "https://arxiv.org/abs/2409.02481v3",
          "size": "515kb",
          "version": "v3"
        }
      ],
      "title": "PQ-GCN: Enhancing Text Graph Question Classification with Phrase Features",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.02481",
        "HTML": "https://arxiv.org/html/2409.02481v3",
        "PDF": "https://arxiv.org/pdf/2409.02481"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper proposes a graph-based approach for question classification, which does not involve or address the processing or construction of LLM training data."
      },
      "tasks": [
        "Classification",
        "Graph Neural Network",
        "Information Retrieval",
        "Question Answering",
        "Word Embeddings"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.03569",
      "abstract": "System behaviors are traditionally evaluated through binary classifications of correctness, which do not suffice for properties involving quantitative aspects of systems and executions. Quantitative automata offer a more nuanced approach, mapping each execution to a real number by incorporating weighted transitions and value functions generalizing acceptance conditions. In this paper, we introduce QuAK, the first tool designed to automate the analysis of quantitative automata. QuAK currently supports a variety of quantitative automaton types, including Inf, Sup, LimInf, LimSup, LimInfAvg, and LimSupAvg automata, and implements decision procedures for problems such as emptiness, universality, inclusion, equivalence, as well as for checking whether an automaton is safe, live, or constant. Additionally, QuAK is able to compute extremal values when possible, construct safety-liveness decompositions, and monitor system behaviors. We demonstrate the effectiveness of QuAK through experiments focusing on the inclusion, constant-function check, and monitoring problems.",
      "authors": [
        "Marek Chalupa",
        "Thomas A. Henzinger",
        "Nicolas Mazzocchi",
        "N. Ege Sara\\c{c}"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Formal Languages and Automata Theory (cs.FL)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-05T14:22:10+00:00",
          "link": "https://arxiv.org/abs/2409.03569v1",
          "size": "532kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T16:44:26+00:00",
          "link": "https://arxiv.org/abs/2409.03569v2",
          "size": "660kb",
          "version": "v2"
        }
      ],
      "title": "QuAK: Quantitative Automata Kit",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.03569",
        "HTML": "https://arxiv.org/html/2409.03569v2",
        "PDF": "https://arxiv.org/pdf/2409.03569"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "QuAK is a tool for analyzing quantitative automata and does not relate to any stage of collecting, processing, or engineering LLM training data."
      },
      "repo_urls": [
        "https://github.com/ista-vamos/QuAK"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.14593",
      "abstract": "Testing a hypothesized causal model against observational data is a key prerequisite for many causal inference tasks. A natural approach is to test whether the conditional independence relations (CIs) assumed in the model hold in the data. While a model can assume exponentially many CIs (with respect to the number of variables), testing all of them is both impractical and unnecessary. Causal graphs, which encode these CIs in polynomial space, give rise to local Markov properties that enable model testing with a significantly smaller subset of CIs. Model testing based on local properties requires an algorithm to list the relevant CIs. However, existing algorithms for realistic settings with hidden variables and non-parametric distributions can take exponential time to produce even a single CI constraint. In this paper, we introduce the c-component local Markov property (C-LMP) for causal graphs with hidden variables. Since C-LMP can still invoke an exponential number of CIs, we develop a polynomial delay algorithm to list these CIs in poly-time intervals. To our knowledge, this is the first algorithm that enables poly-delay testing of CIs in causal graphs with hidden variables against arbitrary data distributions. Experiments on real-world and synthetic data demonstrate the practicality of our algorithm.",
      "authors": [
        "Hyunchai Jeong",
        "Adiba Ejaz",
        "Jin Tian",
        "Elias Bareinboim"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Methodology (stat.ME)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-22T21:05:56+00:00",
          "link": "https://arxiv.org/abs/2409.14593v1",
          "size": "3841kb",
          "version": "v1"
        },
        {
          "date": "2025-06-26T20:51:29+00:00",
          "link": "https://arxiv.org/abs/2409.14593v2",
          "size": "2008kb",
          "version": "v2"
        }
      ],
      "title": "Testing Causal Models with Hidden Variables in Polynomial Delay via Conditional Independencies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.14593",
        "PDF": "https://arxiv.org/pdf/2409.14593"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on causal inference and testing conditional independence relations in causal models. It does not involve the processing of training data for LLMs or discuss data engineering stages related to LLM training."
      },
      "tasks": [
        "Causal Inference"
      ],
      "repo_urls": [
        "https://github.com/CausalAILab/ListConditionalIndependencies"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.17792",
      "abstract": "For single image defocus deblurring, acquiring well-aligned training pairs (or training triplets), i.e., a defocus blurry image, an all-in-focus sharp image (and a defocus blur map), is a challenging task for developing effective deblurring models. Existing image defocus deblurring methods typically rely on training data collected by specialized imaging equipment, with the assumption that these pairs or triplets are perfectly aligned. However, in practical scenarios involving the collection of real-world data, direct acquisition of training triplets is infeasible, and training pairs inevitably encounter spatial misalignment issues. In this work, we introduce a reblurring-guided learning framework for single image defocus deblurring, enabling the learning of a deblurring network even with misaligned training pairs. By reconstructing spatially variant isotropic blur kernels, our reblurring module ensures spatial consistency between the deblurred image, the reblurred image and the input blurry image, thereby addressing the misalignment issue while effectively extracting sharp textures from the all-in-focus sharp image. Moreover, spatially variant blur can be derived from the reblurring module, and serve as pseudo supervision for defocus blur map during training, interestingly transforming training pairs into training triplets. To leverage this pseudo supervision, we propose a lightweight defocus blur estimator coupled with a fusion block, which enhances deblurring performance through seamless integration with state-of-the-art deblurring networks. Additionally, we have collected a new dataset for single image defocus deblurring (SDD) with typical misalignments, which not only validates our proposed method but also serves as a benchmark for future research.",
      "authors": [
        "Dongwei Ren and Xinya Shu and Yu Li and Xiaohe Wu and Jin Li and Wangmeng Zuo"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-26T12:37:50+00:00",
          "link": "https://arxiv.org/abs/2409.17792v1",
          "size": "31892kb",
          "version": "v1"
        },
        {
          "date": "2025-06-26T22:05:39+00:00",
          "link": "https://arxiv.org/abs/2409.17792v2",
          "size": "29296kb",
          "version": "v2"
        }
      ],
      "title": "Reblurring-Guided Single Image Defocus Deblurring: A Learning Framework with Misaligned Training Pairs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.17792",
        "HTML": "https://arxiv.org/html/2409.17792v2",
        "PDF": "https://arxiv.org/pdf/2409.17792"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper presents a framework for single image deblurring using misaligned training pairs and does not address the processing of training data for LLMs or any related data engineering tasks."
      },
      "tasks": [
        "Deblurring",
        "Image Defocus Deblurring"
      ],
      "repo_urls": [
        "https://github.com/ssscrystal/reblurring-guided-jdrl"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.02660",
      "abstract": "We study continued training and supervised fine-tuning (SFT) of a language model (LM) to make effective use of long-context information. We first establish a reliable evaluation protocol to guide model development -- instead of perplexity or simple needle-in-a-haystack (NIAH) tests, we use a broad set of long-context downstream tasks, and we evaluate models after SFT as this better reveals long-context abilities. Supported by our robust evaluations, we run thorough experiments to decide the data mix for continued pre-training, the instruction tuning dataset, and many other design choices such as position extrapolation. We find that (1) code repositories and books are excellent sources of long data, but it is crucial to combine them with high-quality short-context data; (2) training with a sequence length beyond the evaluation length boosts long-context performance; (3) for SFT, using only short instruction datasets yields strong performance on long-context tasks. Our final model, ProLong-8B, which is initialized from Llama-3 and trained on 40B tokens, demonstrates state-of-the-art long-context performance among similarly sized models at a length of 128K. ProLong outperforms Llama-3.1-8B-Instruct on the majority of long-context tasks despite using only 5% as many tokens during long-context training. Additionally, ProLong can effectively process up to 512K tokens, one of the longest context windows of publicly available LMs.",
      "authors": [
        "Tianyu Gao",
        "Alexander Wettig",
        "Howard Yen",
        "Danqi Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-03T16:46:52+00:00",
          "link": "https://arxiv.org/abs/2410.02660v1",
          "size": "157kb",
          "version": "v1"
        },
        {
          "date": "2025-04-03T13:26:46+00:00",
          "link": "https://arxiv.org/abs/2410.02660v2",
          "size": "178kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T17:01:41+00:00",
          "link": "https://arxiv.org/abs/2410.02660v3",
          "size": "162kb",
          "version": "v3"
        }
      ],
      "title": "How to Train Long-Context Language Models (Effectively)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.02660",
        "HTML": "https://arxiv.org/html/2410.02660v3",
        "PDF": "https://arxiv.org/pdf/2410.02660"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper specifically addresses the continued training and supervised fine-tuning (SFT) of language models with a focus on data mix for pre-training, instruction tuning datasets, and sequence lengths. These elements are central to the training-stage data processing for LLMs."
      },
      "models": [
        {
          "model_path": "princeton-nlp/Llama-3-8B-ProLong-64k-Instruct",
          "downloads": "14223",
          "likes": "13",
          "trending_score": "0.0",
          "link": "https://huggingface.co/princeton-nlp/Llama-3-8B-ProLong-64k-Instruct"
        },
        {
          "model_path": "princeton-nlp/Llama-3-8B-ProLong-64k-Base",
          "downloads": "12280",
          "likes": "5",
          "trending_score": "0.0",
          "link": "https://huggingface.co/princeton-nlp/Llama-3-8B-ProLong-64k-Base"
        },
        {
          "model_path": "princeton-nlp/Llama-3-8B-ProLong-512k-Base",
          "downloads": "12678",
          "likes": "9",
          "trending_score": "0.0",
          "link": "https://huggingface.co/princeton-nlp/Llama-3-8B-ProLong-512k-Base"
        },
        {
          "model_path": "princeton-nlp/Llama-3-8B-ProLong-512k-Instruct",
          "downloads": "12543",
          "likes": "21",
          "trending_score": "0.0",
          "link": "https://huggingface.co/princeton-nlp/Llama-3-8B-ProLong-512k-Instruct"
        },
        {
          "model_path": "QuantFactory/Llama-3-8B-ProLong-512k-Base-GGUF",
          "downloads": "456",
          "likes": "2",
          "trending_score": "0.0",
          "link": "https://huggingface.co/QuantFactory/Llama-3-8B-ProLong-512k-Base-GGUF"
        },
        {
          "model_path": "ZeroXClem/Llama-3-8B-ProLong-SAO-Roleplay-512k",
          "downloads": "15",
          "likes": "2",
          "trending_score": "0.0",
          "link": "https://huggingface.co/ZeroXClem/Llama-3-8B-ProLong-SAO-Roleplay-512k"
        },
        {
          "model_path": "RichardErkhov/princeton-nlp_-_Llama-3-8B-ProLong-64k-Base-4bits",
          "downloads": "10",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/RichardErkhov/princeton-nlp_-_Llama-3-8B-ProLong-64k-Base-4bits"
        },
        {
          "model_path": "amd/Instella-3B-Long-Instruct",
          "downloads": "237",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/amd/Instella-3B-Long-Instruct"
        }
      ],
      "datasets": [
        {
          "dataset_name": "princeton-nlp/prolong-data-64K",
          "downloads": "47828",
          "likes": "11",
          "link": "https://huggingface.co/datasets/princeton-nlp/prolong-data-64K"
        },
        {
          "dataset_name": "princeton-nlp/prolong-data-512K",
          "downloads": "26273",
          "likes": "7",
          "link": "https://huggingface.co/datasets/princeton-nlp/prolong-data-512K"
        },
        {
          "dataset_name": "amd/Instella-Long",
          "downloads": "221",
          "likes": "0",
          "link": "https://huggingface.co/datasets/amd/Instella-Long"
        }
      ],
      "tasks": [],
      "repo_urls": [
        "https://github.com/princeton-nlp/prolong"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.03437",
      "abstract": "Solving time-dependent parametric partial differential equations (PDEs) is challenging for data-driven methods, as these models must adapt to variations in parameters such as coefficients, forcing terms, and initial conditions. State-of-the-art neural surrogates perform adaptation through gradient-based optimization and meta-learning to implicitly encode the variety of dynamics from observations. This often comes with increased inference complexity. Inspired by the in-context learning capabilities of large language models (LLMs), we introduce Zebra, a novel generative auto-regressive transformer designed to solve parametric PDEs without requiring gradient adaptation at inference. By leveraging in-context information during both pre-training and inference, Zebra dynamically adapts to new tasks by conditioning on input sequences that incorporate context example trajectories. As a generative model, Zebra can be used to generate new trajectories and allows quantifying the uncertainty of the predictions. We evaluate Zebra across a variety of challenging PDE scenarios, demonstrating its adaptability, robustness, and superior performance compared to existing approaches.",
      "authors": [
        "Louis Serrano",
        "Armand Kassa\\\"i Koupa\\\"i",
        "Thomas X Wang",
        "Pierre Erbacher",
        "Patrick Gallinari"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-04T13:52:02+00:00",
          "link": "https://arxiv.org/abs/2410.03437v1",
          "size": "8493kb",
          "version": "v1"
        },
        {
          "date": "2024-10-08T07:44:24+00:00",
          "link": "https://arxiv.org/abs/2410.03437v2",
          "size": "8493kb",
          "version": "v2"
        },
        {
          "date": "2025-06-26T20:05:33+00:00",
          "link": "https://arxiv.org/abs/2410.03437v3",
          "size": "8382kb",
          "version": "v3"
        }
      ],
      "title": "Zebra: In-Context Generative Pretraining for Solving Parametric PDEs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.03437",
        "HTML": "https://arxiv.org/html/2410.03437v3",
        "PDF": "https://arxiv.org/pdf/2410.03437"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces Zebra, a model designed to solve parametric PDEs using in-context learning capabilities inspired by LLMs. It involves pre-training but does not highlight novel contributions to LLM training data processing or engineering specifically."
      },
      "tasks": [
        "In-Context Learning",
        "Meta-Learning",
        "Uncertainty Quantification"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.03492",
      "abstract": "Large language models (LLMs) are stochastic, and not all models give deterministic answers, even when setting temperature to zero with a fixed random seed. However, few benchmark studies attempt to quantify uncertainty, partly due to the time and cost of repeated experiments. We use benchmarks designed for testing LLMs' capacity to reason about cardinal directions to explore the impact of experimental repeats on mean score and prediction interval. We suggest a simple method for cost-effectively quantifying the uncertainty of a benchmark score and make recommendations concerning reproducible LLM evaluation.",
      "authors": [
        "Robert E. Blackwell",
        "Jon Barry and Anthony G. Cohn"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-04T15:04:28+00:00",
          "link": "https://arxiv.org/abs/2410.03492v1",
          "size": "173kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T09:33:10+00:00",
          "link": "https://arxiv.org/abs/2410.03492v2",
          "size": "106kb",
          "version": "v2"
        }
      ],
      "title": "Towards Reproducible LLM Evaluation: Quantifying Uncertainty in LLM Benchmark Scores",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.03492",
        "HTML": "https://arxiv.org/html/2410.03492v2",
        "PDF": "https://arxiv.org/pdf/2410.03492"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on evaluating LLMs by quantifying uncertainty in benchmark scores. It does not address training data processing or data engineering for LLMs."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2410.04778",
      "abstract": "With the advent of LLMs and variants, a flurry of research has emerged, analyzing the performance of such models across an array of tasks. While most studies focus on evaluating the capabilities of state-of-the-art (SoTA) Vision Language Models (VLMs) through task accuracy (e.g., visual question answering, grounding), our work explores the related but complementary aspect of consistency - the ability of a VLM to produce semantically similar or identical responses to semantically similar queries. We note that consistency is a fundamental prerequisite (necessary but not sufficient condition) for robustness and trust in VLMs. Armed with this perspective, we propose the MM-R3 benchmark, which allows us to analyze performance, in terms of consistency and accuracy, of SoTA VLMs on three tasks: Question Rephrasing, Image Restyling, and Context Reasoning. Our analysis reveals that consistency does not always align with accuracy, indicating that models with higher accuracy are not necessarily more consistent, and vice versa. Furthermore, we propose a simple yet effective mitigation strategy in the form of an adapter module trained to minimize inconsistency across prompts. With our proposed strategy, we are able to achieve absolute improvements of 5.7% and 12.5%, on average on widely used VLMs such as BLIP-2 and LLaVa 1.5M in terms of consistency over their existing counterparts.",
      "authors": [
        "Shih-Han Chou",
        "Shivam Chandhok",
        "James J. Little",
        "Leonid Sigal"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-07T06:36:55+00:00",
          "link": "https://arxiv.org/abs/2410.04778v1",
          "size": "29805kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T17:08:56+00:00",
          "link": "https://arxiv.org/abs/2410.04778v2",
          "size": "25572kb",
          "version": "v2"
        }
      ],
      "title": "MM-R$^3$: On (In-)Consistency of Vision-Language Models (VLMs)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.04778",
        "PDF": "https://arxiv.org/pdf/2410.04778"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper explores consistency in Vision-Language Models and proposes a benchmark for this purpose. It does not contribute to LLM training data processing or data engineering."
      },
      "tasks": [
        "Question Answering",
        "Visual Question Answering"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.06020",
      "abstract": "A key challenge in Domain Generalization (DG) is preventing overfitting to source domains, which can be mitigated by finding flatter minima in the loss landscape. In this work, we propose Quantization-aware Training for Domain Generalization (QT-DoG) and demonstrate that weight quantization effectively leads to flatter minima in the loss landscape, thereby enhancing domain generalization. Unlike traditional quantization methods focused on model compression, QT-DoG exploits quantization as an implicit regularizer by inducing noise in model weights, guiding the optimization process toward flatter minima that are less sensitive to perturbations and overfitting. We provide both an analytical perspective and empirical evidence demonstrating that quantization inherently encourages flatter minima, leading to better generalization across domains. Moreover, with the benefit of reducing the model size through quantization, we demonstrate that an ensemble of multiple quantized models further yields superior accuracy than the state-of-the-art DG approaches with no computational or memory overheads. Code is released at: https://saqibjaved1.github.io/QT_DoG/.",
      "authors": [
        "Saqib Javed",
        "Hieu Le",
        "Mathieu Salzmann"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-08T13:21:48+00:00",
          "link": "https://arxiv.org/abs/2410.06020v1",
          "size": "4077kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T01:42:45+00:00",
          "link": "https://arxiv.org/abs/2410.06020v2",
          "size": "6928kb",
          "version": "v2"
        }
      ],
      "title": "QT-DoG: Quantization-aware Training for Domain Generalization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.06020",
        "HTML": "https://arxiv.org/html/2410.06020v2",
        "PDF": "https://arxiv.org/pdf/2410.06020"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The focus of this paper is on using quantization for domain generalization. It does not address training data processing stages for LLMs or contribute to data-related methodologies."
      },
      "tasks": [
        "Domain Generalization",
        "Model Compression",
        "Quantization"
      ],
      "repo_urls": [
        "https://github.com/saqibjaved1/QT-DoG"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.06866",
      "abstract": "The exponential surge in video traffic has intensified the imperative for Video Quality Assessment (VQA). Leveraging cutting-edge architectures, current VQA models have achieved human-comparable accuracy. However, recent studies have revealed the vulnerability of existing VQA models against adversarial attacks. To establish a reliable and practical assessment system, a secure VQA model capable of resisting such malicious attacks is urgently demanded. Unfortunately, no attempt has been made to explore this issue. This paper first attempts to investigate general adversarial defense principles, aiming at endowing existing VQA models with security. Specifically, we first introduce random spatial grid sampling on the video frame for intra-frame defense. Then, we design pixel-wise randomization through a guardian map, globally neutralizing adversarial perturbations. Meanwhile, we extract temporal information from the video sequence as compensation for inter-frame defense. Building upon these principles, we present a novel VQA framework from the security-oriented perspective, termed SecureVQA. Extensive experiments indicate that SecureVQA sets a new benchmark in security while achieving competitive VQA performance compared with state-of-the-art models. Ablation studies delve deeper into analyzing the principles of SecureVQA, demonstrating their generalization and contributions to the security of leading VQA models.",
      "authors": [
        "Ao-Xiang Zhang",
        "Yuan-Gen Wang",
        "Yu Ran",
        "Weixuan Tang",
        "Qingxiao Guan",
        "and Chunsheng Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-09T13:27:06+00:00",
          "link": "https://arxiv.org/abs/2410.06866v1",
          "size": "656kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T15:26:08+00:00",
          "link": "https://arxiv.org/abs/2410.06866v2",
          "size": "565kb",
          "version": "v2"
        }
      ],
      "title": "Secure Video Quality Assessment Resisting Adversarial Attacks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.06866",
        "HTML": "https://arxiv.org/html/2410.06866v2",
        "PDF": "https://arxiv.org/pdf/2410.06866"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper addresses adversarial attacks in video quality assessment models and does not involve any aspects of LLM training data processing or data engineering."
      },
      "tasks": [
        "Adversarial Defense",
        "Video Quality Assessment",
        "Visual Question Answering (VQA)"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.09229",
      "abstract": "String diagrammatic calculi have become increasingly popular in fields such as quantum theory, circuit theory, probabilistic programming, and machine learning, where they enable resource-sensitive and compositional algebraic analysis. Traditionally, the equations of diagrammatic calculi only axiomatise exact semantic equality. However, reasoning in these domains often involves approximations rather than strict equivalences. In this work, we develop a quantitative framework for diagrammatic calculi, where one may axiomatise notions of distance between string diagrams. Unlike similar approaches, such as the quantitative theories introduced by Mardare et al., this requires us to work in a monoidal rather than a cartesian setting. We define a suitable notion of monoidal theory, the syntactic category it freely generates, and its models, where the concept of distance is established via enrichment over a quantale. To illustrate the framework, we provide examples from probabilistic and linear systems analysis.",
      "authors": [
        "Gabriele Lobbia",
        "Wojciech R\\'o\\.zowski",
        "Ralph Sarkis",
        "Fabio Zanasi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Category Theory (math.CT)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-11T20:06:09+00:00",
          "link": "https://arxiv.org/abs/2410.09229v1",
          "size": "152kb",
          "version": "v1"
        },
        {
          "date": "2025-01-23T15:28:51+00:00",
          "link": "https://arxiv.org/abs/2410.09229v2",
          "size": "136kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T15:54:31+00:00",
          "link": "https://arxiv.org/abs/2410.09229v3",
          "size": "336kb",
          "version": "v3"
        }
      ],
      "title": "Quantitative Monoidal Algebra: Axiomatising Distance with String Diagrams",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.09229",
        "PDF": "https://arxiv.org/pdf/2410.09229"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on a quantitative framework for diagrammatic calculi and is unrelated to training data processing for LLMs, concentrating instead on algebraic analysis within a quantitative monoidal algebra context."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.10926",
      "abstract": "Instruction tuning is a crucial step in improving the responsiveness of pretrained large language models (LLMs) to human instructions. Federated learning (FL) helps to exploit the use of vast private instruction data from clients, becoming popular for LLM tuning by improving data diversity. Existing federated tuning simply consumes all local data, causing excessive computational overhead and overfitting to local data, while centralized data-efficient solutions are not suitable for FL due to privacy concerns. This work presents FedHDS, a federated data-efficient instruction tuning approach, which tunes LLMs with a representative subset of edge-side data. It reduces the data redundancy at both intra- and inter-client levels without sharing raw data. Experiments with various LLMs, datasets and partitions show that FedHDS improves Rouge-L on unseen tasks by an average of 10.72% over the SOTA full-data federated instruction tuning methods, while using less than 1.5% of the data samples, improving training efficiency by up to tens of times.",
      "authors": [
        "Zhen Qin",
        "Zhaomin Wu",
        "Bingsheng He",
        "Shuiguang Deng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-14T15:05:51+00:00",
          "link": "https://arxiv.org/abs/2410.10926v1",
          "size": "1014kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T08:03:25+00:00",
          "link": "https://arxiv.org/abs/2410.10926v2",
          "size": "1491kb",
          "version": "v2"
        }
      ],
      "title": "Federated Data-Efficient Instruction Tuning for Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.10926",
        "HTML": "https://arxiv.org/html/2410.10926v2",
        "PDF": "https://arxiv.org/pdf/2410.10926"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper's primary contribution is a federated data-efficient instruction tuning approach for LLMs, which includes novel methods for reducing data redundancy and improving data diversity under privacy constraints, directly addressing the engineering of training data for LLMs."
      },
      "tasks": [
        "Federated Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.16589",
      "abstract": "Sentiment analysis has become increasingly important for assessing public opinion and informing decision-making. Large language models (LLMs) have revolutionized this field by capturing nuanced language patterns. However, adapting LLMs to domain-specific sentiment analysis tasks remains challenging due to computational constraints and the need for optimal fine-tuning. To address these challenges, we propose a novel Dynamic Adaptive Rank Space Exploration (DARSE) framework for efficient and effective sentiment analysis using LLMs. DARSE consists of a coarse-grained greedy algorithm to identify the optimal rank range, a fine-grained exploration algorithm to refine rank selection, and a dynamic rank allocation method to determine the optimal rank combination for each LLM layer. Extensive experiments demonstrate that DARSE significantly improves sentiment analysis accuracy, achieving a 15.1% improvement in MSE and a 4.3% improvement in accuracy compared to previous work. Our framework strikes a balance between computational efficiency and model performance, making it a promising approach for sentiment analysis with LLMs.",
      "authors": [
        "Hongcheng Ding",
        "Fuzhen Hu",
        "Ruiting Deng",
        "Xuanze Zhao",
        "Shamsul Nahar Abdullah",
        "Deshinta Arrova Dewi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-22T00:14:36+00:00",
          "link": "https://arxiv.org/abs/2410.16589v1",
          "size": "819kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T06:44:48+00:00",
          "link": "https://arxiv.org/abs/2410.16589v2",
          "size": "781kb",
          "version": "v2"
        }
      ],
      "title": "Dynamic Adaptive Rank Space Exploration for Efficient Sentiment Analysis with Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.16589",
        "HTML": "https://arxiv.org/html/2410.16589v2",
        "PDF": "https://arxiv.org/pdf/2410.16589"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper proposes a framework for efficient sentiment analysis with LLMs, concentrating on computational efficiency and model optimization rather than on data processing or engineering."
      },
      "tasks": [
        "Computational Efficiency",
        "Decision Making",
        "Sentiment Analysis"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.17355",
      "abstract": "Due to their capacity to acquire world knowledge from large corpora, pre-trained language models (PLMs) are extensively used in ultra-fine entity typing tasks where the space of labels is extremely large. In this work, we explore the limitations of the knowledge acquired by PLMs by proposing a novel heuristic to approximate the pre-training distribution of entities when the pre-training data is unknown. Then, we systematically demonstrate that entity-typing approaches that rely solely on the parametric knowledge of PLMs struggle significantly with entities at the long tail of the pre-training distribution, and that knowledge-infused approaches can account for some of these shortcomings. Our findings suggest that we need to go beyond PLMs to produce solutions that perform well for infrequent entities.",
      "authors": [
        "Advait Deshmukh",
        "Ashwin Umadi",
        "Dananjay Srinivas",
        "Maria Leonor Pacheco"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-22T18:47:46+00:00",
          "link": "https://arxiv.org/abs/2410.17355v1",
          "size": "682kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T14:47:42+00:00",
          "link": "https://arxiv.org/abs/2410.17355v2",
          "size": "985kb",
          "version": "v2"
        }
      ],
      "title": "All Entities are Not Created Equal: Examining the Long Tail for Ultra-Fine Entity Typing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.17355",
        "HTML": "https://arxiv.org/html/2410.17355v2",
        "PDF": "https://arxiv.org/pdf/2410.17355"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper explores limitations in PLM-acquired knowledge and new heuristics for entity typing but does not introduce new data processing techniques, instead discussing the shortcomings of existing PLM-based approaches."
      },
      "tasks": [
        "All",
        "Entity Typing",
        "World Knowledge"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.19499",
      "abstract": "Momentum-Aided Prompt Optimization (MAPO) enhances the efficiency and efficacy of prompt optimization for Large Language Models (LLMs). Building on ProTeGi, MAPO uses positive natural language \"gradients\" and a momentum-based extension to refine prompts effectively. By tracking gradient history, MAPO avoids local minima and oscillations. It also utilizes beam search and an Upper Confidence Bound (UCB) algorithm for balanced candidate expansion and selection. Benchmark testing shows that MAPO achieves faster convergence time with fewer API calls and higher F1 scores than ProTeGi, proving it as a robust and scalable solution for automated prompt engineering in LLMs.",
      "authors": [
        "Anthony Cui",
        "Pranav Nandyalam",
        "Andrew Rufail",
        "Ethan Cheung",
        "Aiden Lei",
        "Kevin Zhu",
        "Sean O'Brien"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-25T11:58:12+00:00",
          "link": "https://arxiv.org/abs/2410.19499v1",
          "size": "501kb",
          "version": "v1"
        },
        {
          "date": "2024-11-01T16:45:29+00:00",
          "link": "https://arxiv.org/abs/2410.19499v2",
          "size": "501kb",
          "version": "v2"
        },
        {
          "date": "2025-06-26T18:40:26+00:00",
          "link": "https://arxiv.org/abs/2410.19499v3",
          "size": "2770kb",
          "version": "v3"
        }
      ],
      "title": "Introducing MAPO: Momentum-Aided Gradient Descent Prompt Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.19499",
        "HTML": "https://arxiv.org/html/2410.19499v3",
        "PDF": "https://arxiv.org/pdf/2410.19499"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper focuses on prompt optimization for LLMs, it mentions using specific techniques for managing training data preparation, such as beam search and a momentum-based extension, but does not primarily contribute to data engineering or new processing methods for LLM datasets."
      },
      "tasks": [
        "Prompt Engineering"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.00119",
      "abstract": "Driving progress of AI models and agents requires comparing their performance on standardized benchmarks; for general agents, individual performances must be aggregated across a potentially wide variety of different tasks. In this paper, we describe a novel ranking scheme inspired by social choice frameworks, called Soft Condorcet Optimization (SCO), to compute the optimal ranking of agents: the one that makes the fewest mistakes in predicting the agent comparisons in the evaluation data. This optimal ranking is the maximum likelihood estimate when evaluation data (which we view as votes) are interpreted as noisy samples from a ground truth ranking, a solution to Condorcet's original voting system criteria. SCO ratings are maximal for Condorcet winners when they exist, which we show is not necessarily true for the classical rating system Elo. We propose three optimization algorithms to compute SCO ratings and evaluate their empirical performance. When serving as an approximation to the Kemeny-Young voting method, SCO rankings are on average 0 to 0.043 away from the optimal ranking in normalized Kendall-tau distance across 865 preference profiles from the PrefLib open ranking archive. In a simulated noisy tournament setting, SCO achieves accurate approximations to the ground truth ranking and the best among several baselines when 59\\% or more of the preference data is missing. Finally, SCO ranking provides the best approximation to the optimal ranking, measured on held-out test sets, in a problem containing 52,958 human players across 31,049 games of the classic seven-player game of Diplomacy.",
      "authors": [
        "Marc Lanctot",
        "Kate Larson",
        "Michael Kaisers",
        "Quentin Berthet",
        "Ian Gemp",
        "Manfred Diaz",
        "Roberto-Rafael Maura-Rivero",
        "Yoram Bachrach",
        "Anna Koop",
        "Doina Precup"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-31T18:17:39+00:00",
          "link": "https://arxiv.org/abs/2411.00119v1",
          "size": "1152kb",
          "version": "v1"
        },
        {
          "date": "2024-11-04T13:09:42+00:00",
          "link": "https://arxiv.org/abs/2411.00119v2",
          "size": "1152kb",
          "version": "v2"
        },
        {
          "date": "2025-02-20T16:41:03+00:00",
          "link": "https://arxiv.org/abs/2411.00119v3",
          "size": "1186kb",
          "version": "v3"
        },
        {
          "date": "2025-06-27T13:26:25+00:00",
          "link": "https://arxiv.org/abs/2411.00119v4",
          "size": "534kb",
          "version": "v4"
        }
      ],
      "title": "Soft Condorcet Optimization for Ranking of General Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.00119",
        "HTML": "https://arxiv.org/html/2411.00119v4",
        "PDF": "https://arxiv.org/pdf/2411.00119"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The study focuses on ranking systems inspired by social choice frameworks and does not address data engineering or training data processing within the context of LLMs."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/google-deepmind/open_spiel"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.01707",
      "abstract": "We study Multi-Robot Coverage Path Planning (MCPP) on a 4-neighbor 2D grid G, which aims to compute paths for multiple robots to cover all cells of G. Traditional approaches are limited as they first compute coverage trees on a quadrant coarsened grid H and then employ the Spanning Tree Coverage (STC) paradigm to generate paths on G, making them inapplicable to grids with partially obstructed 2x2 blocks. To address this limitation, we reformulate the problem directly on G, revolutionizing grid-based MCPP solving and establishing new NP-hardness results. We introduce Extended-STC (ESTC), a novel paradigm that extends STC to ensure complete coverage with bounded suboptimality, even when H includes partially obstructed blocks. Furthermore, we present LS-MCPP, a new algorithmic framework that integrates ESTC with three novel types of neighborhood operators within a local search strategy to optimize coverage paths directly on G. Unlike prior grid-based MCPP work, our approach also incorporates a versatile post-processing procedure that applies Multi-Agent Path Finding (MAPF) techniques to MCPP for the first time, enabling a fusion of these two important fields in multi-robot coordination. This procedure effectively resolves inter-robot conflicts and accommodates turning costs by solving a MAPF variant, making our MCPP solutions more practical for real-world applications. Extensive experiments demonstrate that our approach significantly improves solution quality and efficiency, managing up to 100 robots on grids as large as 256x256 within minutes of runtime. Validation with physical robots confirms the feasibility of our solutions under real-world conditions.",
      "authors": [
        "Jingtao Tang",
        "Zining Mao",
        "Hang Ma"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-03T22:37:56+00:00",
          "link": "https://arxiv.org/abs/2411.01707v1",
          "size": "3504kb",
          "version": "v1"
        },
        {
          "date": "2025-05-29T19:29:56+00:00",
          "link": "https://arxiv.org/abs/2411.01707v2",
          "size": "2901kb",
          "version": "v2"
        },
        {
          "date": "2025-06-26T22:50:35+00:00",
          "link": "https://arxiv.org/abs/2411.01707v3",
          "size": "1860kb",
          "version": "v3"
        }
      ],
      "title": "Large-Scale Multirobot Coverage Path Planning on Grids With Path Deconfliction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.01707",
        "HTML": "https://arxiv.org/html/2411.01707v3",
        "PDF": "https://arxiv.org/pdf/2411.01707"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on Multi-Robot Coverage Path Planning and introduces algorithms related to grid-based robot path optimization, which is unrelated to any aspect of LLM training data processing."
      },
      "tasks": [
        "Multi-Agent Path Finding"
      ],
      "repo_urls": [
        "https://github.com/reso1/ls-mcpp"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.02845",
      "abstract": "Let $\\mathcal{D}$ be a set family that is the solution domain of some combinatorial problem. The \\emph{max-min diversification problem on $\\mathcal{D}$} is the problem to select $k$ sets from $\\mathcal{D}$ such that the Hamming distance between any two selected sets is at least $d$. FPT algorithms parameterized by $k+\\ell $, where $\\ell=\\max_{D\\in \\mathcal{D}}|D|$, and $k+d$ have been actively studied recently for several specific domains.\n  This paper provides unified algorithmic frameworks to solve this problem. Specifically, for each parameterization $k+\\ell $ and $k+d$, we provide an FPT oracle algorithm for the max-min diversification problem using oracles related to $\\mathcal{D}$. We then demonstrate that our frameworks provide the first FPT algorithms on several new domains $\\mathcal{D}$, including the domain of $t$-linear matroid intersection, almost $2$-SAT, minimum edge $s,t$-flows, vertex sets of $s,t$-mincut, vertex sets of edge bipartization, and Steiner trees. We also demonstrate that our frameworks generalize most of the existing domain-specific tractability results.\n  Our main technical breakthrough is introducing the notion of \\emph{max-distance sparsifier} of $\\mathcal{D}$, a domain on which the max-min diversification problem is equivalent to the same problem on the original domain $\\mathcal{D}$. The core of our framework is to design FPT oracle algorithms that construct a constant-size max-distance sparsifier of $\\mathcal{D}$. Using max-distance sparsifiers, we provide FPT algorithms for the max-min and max-sum diversification problems on $\\mathcal{D}$, as well as $k$-center and $k$-sum-of-radii clustering problems on $\\mathcal{D}$, which are also natural problems in the context of diversification and have their own interests.",
      "authors": [
        "Soh Kumabe"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-05T06:34:29+00:00",
          "link": "https://arxiv.org/abs/2411.02845v1",
          "size": "153kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T07:13:24+00:00",
          "link": "https://arxiv.org/abs/2411.02845v2",
          "size": "47kb",
          "version": "v2"
        }
      ],
      "title": "Max-Distance Sparsification for Diversification and Clustering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.02845",
        "HTML": "https://arxiv.org/html/2411.02845v2",
        "PDF": "https://arxiv.org/pdf/2411.02845"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper addresses a max-min diversification problem in combinatorial optimization and provides algorithms for diversification and clustering, which do not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.07560",
      "abstract": "This study introduces a novel approach for EUR/USD exchange rate forecasting that integrates deep learning, textual analysis, and particle swarm optimization (PSO). By incorporating online news and analysis texts as qualitative data, the proposed PSO-LSTM model demonstrates superior performance compared to traditional econometric and machine learning models. The research employs advanced text mining techniques, including sentiment analysis using the RoBERTa-Large model and topic modeling with LDA. Empirical findings underscore the significant advantage of incorporating textual data, with the PSO-LSTM model outperforming benchmark models such as SVM, SVR, ARIMA, and GARCH. Ablation experiments reveal the contribution of each textual data category to the overall forecasting performance. The study highlights the transformative potential of artificial intelligence in finance and paves the way for future research in real-time forecasting and the integration of alternative data sources.",
      "authors": [
        "Hongcheng Ding",
        "Xiangyu Shi",
        "Ruiting Deng",
        "Salaar Faroog",
        "Deshinta Arrova Dewi",
        "Shamsul Nahar Abdullah",
        "Bahiah A Malek"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-12T05:28:52+00:00",
          "link": "https://arxiv.org/abs/2411.07560v1",
          "size": "5000kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T06:39:10+00:00",
          "link": "https://arxiv.org/abs/2411.07560v2",
          "size": "4218kb",
          "version": "v2"
        }
      ],
      "title": "EUR/USD Exchange Rate Forecasting incorporating Text Mining Based on Pre-trained Language Models and Deep Learning Methods",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.07560",
        "HTML": "https://arxiv.org/html/2411.07560v2",
        "PDF": "https://arxiv.org/pdf/2411.07560"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "Focused on exchange rate forecasting using text mining and deep learning, this study does not involve creating or processing training data for large language models."
      },
      "tasks": [
        "Sentiment Analysis"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.08708",
      "abstract": "Most existing work on event extraction has focused on sentence-level texts and presumes the identification of a trigger-span -- a word or phrase in the input that evokes the occurrence of an event of interest. Event arguments are then extracted with respect to the trigger. Indeed, triggers are treated as integral to, and trigger detection as an essential component of, event extraction. In this paper, we provide the first investigation of the role of triggers for the more difficult and much less studied task of document-level event extraction. We analyze their usefulness in multiple end-to-end and pipelined transformer-based event extraction models for three document-level event extraction datasets, measuring performance using triggers of varying quality (human-annotated, LLM-generated, keyword-based, and random). We find that whether or not systems benefit from explicitly extracting triggers depends both on dataset characteristics (i.e. the typical number of events per document) and task-specific information available during extraction (i.e. natural language event schemas). Perhaps surprisingly, we also observe that the mere existence of triggers in the input, even random ones, is important for prompt-based in-context learning approaches to the task.",
      "authors": [
        "Shaden Shaar",
        "Wayne Chen",
        "Maitreyi Chatterjee",
        "Barry Wang",
        "Wenting Zhao",
        "Claire Cardie"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-13T15:50:38+00:00",
          "link": "https://arxiv.org/abs/2411.08708v1",
          "size": "1850kb",
          "version": "v1"
        },
        {
          "date": "2025-06-26T21:13:38+00:00",
          "link": "https://arxiv.org/abs/2411.08708v2",
          "size": "2143kb",
          "version": "v2"
        }
      ],
      "title": "Are Triggers Needed for Document-Level Event Extraction?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.08708",
        "HTML": "https://arxiv.org/html/2411.08708v2",
        "PDF": "https://arxiv.org/pdf/2411.08708"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on document-level event extraction and the role of triggers, rather than the processing or engineering of training data for LLMs."
      },
      "tasks": [
        "Document-level Event Extraction",
        "Event Extraction",
        "Sentence"
      ],
      "repo_urls": [
        "https://github.com/githubarry/docie-probing"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.12703",
      "abstract": "The rapid spread of misinformation, particularly through online platforms, underscores the urgent need for reliable detection systems. This study explores the utilization of machine learning and natural language processing, specifically Support Vector Machines (SVM) and BERT, to detect fake news. We employ three distinct text vectorization methods for SVM: Term Frequency Inverse Document Frequency (TF-IDF), Word2Vec, and Bag of Words (BoW), evaluating their effectiveness in distinguishing between genuine and fake news. Additionally, we compare these methods against the transformer large language model, BERT. Our comprehensive approach includes detailed preprocessing steps, rigorous model implementation, and thorough evaluation to determine the most effective techniques. The results demonstrate that while BERT achieves superior accuracy with 99.98% and an F1-score of 0.9998, the SVM model with a linear kernel and BoW vectorization also performs exceptionally well, achieving 99.81% accuracy and an F1-score of 0.9980. These findings highlight that, despite BERT's superior performance, SVM models with BoW and TF-IDF vectorization methods come remarkably close, offering highly competitive performance with the advantage of lower computational requirements.",
      "authors": [
        "Ahmed Akib Jawad Karim",
        "Kazi Hafiz Md Asad and Aznur Azam"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-19T18:15:46+00:00",
          "link": "https://arxiv.org/abs/2411.12703v1",
          "size": "812kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T01:01:44+00:00",
          "link": "https://arxiv.org/abs/2411.12703v2",
          "size": "811kb",
          "version": "v2"
        }
      ],
      "title": "Strengthening False Information Propagation Detection: Leveraging SVM and Sophisticated Text Vectorization Techniques in comparison to BERT",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.12703",
        "HTML": "https://arxiv.org/html/2411.12703v2",
        "PDF": "https://arxiv.org/pdf/2411.12703"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper describes using text vectorization methods and BERT for fake news detection, mentioning preprocessing steps. However, it mainly emphasizes model performance rather than making significant contributions to LLM training data processing."
      },
      "tasks": [
        "Fake News Detection",
        "Language Modeling",
        "Language Modelling",
        "Large Language Model",
        "Misinformation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.13500",
      "abstract": "We relate the so-called powercone models of mixed non-deterministic and probabilistic choice proposed by Tix, Keimel, Plotkin, Mislove, Ouaknine, Worrell, Morgan, and McIver, to our own models of previsions. Under suitable topological assumptions, we show that they are isomorphic. We rely on Keimel's cone-theoretic variants of the classical Hahn-Banach separation theorems, using functional analytic methods, and on the Schr\\\"oder-Simpson Theorem. Lemma 3.4 in the original 2017 version, published at MSCS, had a wrong proof, and we prove a repaired, albeit slightly less general version here.",
      "authors": [
        "Jean Goubault-Larrecq"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Functional Analysis (math.FA)",
        "Probability (math.PR)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-06T15:24:20+00:00",
          "link": "https://arxiv.org/abs/2411.13500v1",
          "size": "57kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T09:29:34+00:00",
          "link": "https://arxiv.org/abs/2411.13500v2",
          "size": "57kb",
          "version": "v2"
        }
      ],
      "title": "Isomorphism Theorems between Models of Mixed Choice (Revised)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.13500",
        "HTML": "https://arxiv.org/html/2411.13500v2",
        "PDF": "https://arxiv.org/pdf/2411.13500"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper discusses isomorphism theorems between mathematical models, which is unrelated to training data processing for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.14384",
      "abstract": "Existing feedforward image-to-3D methods mainly rely on 2D multi-view diffusion models that cannot guarantee 3D consistency. These methods easily collapse when changing the prompt view direction and mainly handle object-centric cases. In this paper, we propose a novel single-stage 3D diffusion model, DiffusionGS, for object generation and scene reconstruction from a single view. DiffusionGS directly outputs 3D Gaussian point clouds at each timestep to enforce view consistency and allow the model to generate robustly given prompt views of any directions, beyond object-centric inputs. Plus, to improve the capability and generality of DiffusionGS, we scale up 3D training data by developing a scene-object mixed training strategy. Experiments show that DiffusionGS yields improvements of 2.20 dB/23.25 and 1.34 dB/19.16 in PSNR/FID for objects and scenes than the state-of-the-art methods, without depth estimator. Plus, our method enjoys over 5$\\times$ faster speed ($\\sim$6s on an A100 GPU). Our Project page at https://caiyuanhao1998.github.io/project/DiffusionGS/ shows the video and interactive results.",
      "authors": [
        "Yuanhao Cai",
        "He Zhang",
        "Kai Zhang",
        "Yixun Liang",
        "Mengwei Ren",
        "Fujun Luan",
        "Qing Liu",
        "Soo Ye Kim",
        "Jianming Zhang",
        "Zhifei Zhang",
        "Yuqian Zhou",
        "Yulun Zhang",
        "Xiaokang Yang",
        "Zhe Lin",
        "Alan Yuille"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-21T18:21:24+00:00",
          "link": "https://arxiv.org/abs/2411.14384v1",
          "size": "2873kb",
          "version": "v1"
        },
        {
          "date": "2024-11-26T04:06:32+00:00",
          "link": "https://arxiv.org/abs/2411.14384v2",
          "size": "2874kb",
          "version": "v2"
        },
        {
          "date": "2025-03-08T17:52:46+00:00",
          "link": "https://arxiv.org/abs/2411.14384v3",
          "size": "2812kb",
          "version": "v3"
        },
        {
          "date": "2025-06-26T18:26:06+00:00",
          "link": "https://arxiv.org/abs/2411.14384v4",
          "size": "2813kb",
          "version": "v4"
        }
      ],
      "title": "Baking Gaussian Splatting into Diffusion Denoiser for Fast and Scalable Single-stage Image-to-3D Generation and Reconstruction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.14384",
        "HTML": "https://arxiv.org/html/2411.14384v4",
        "PDF": "https://arxiv.org/pdf/2411.14384"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes a novel diffusion model for 3D generation, mentioning scaling up 3D training data with a scene-object mixed training strategy. It discusses data scaling but does not deeply focus on the data processing aspects relevant to LLM training."
      },
      "tasks": [
        "3D Generation",
        "Image to 3D",
        "Object",
        "Scene Generation",
        "Text to 3D"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.03177",
      "abstract": "Finetuning-free personalized image generation can synthesize customized images without test-time finetuning, attracting wide research interest owing to its high efficiency. Current finetuning-free methods simply adopt a single training stage with a simple image reconstruction task, and they typically generate low-quality images inconsistent with the reference images during test-time. To mitigate this problem, inspired by the recent DPO (i.e., direct preference optimization) technique, this work proposes an additional training stage to improve the pre-trained personalized generation models. However, traditional DPO only determines the overall superiority or inferiority of two samples, which is not suitable for personalized image generation because the generated images are commonly inconsistent with the reference images only in some local image patches. To tackle this problem, this work proposes PatchDPO that estimates the quality of image patches within each generated image and accordingly trains the model. To this end, PatchDPO first leverages the pre-trained vision model with a proposed self-supervised training method to estimate the patch quality. Next, PatchDPO adopts a weighted training approach to train the model with the estimated patch quality, which rewards the image patches with high quality while penalizing the image patches with low quality. Experiment results demonstrate that PatchDPO significantly improves the performance of multiple pre-trained personalized generation models, and achieves state-of-the-art performance on both single-object and multi-object personalized image generation. Our code is available at https://github.com/hqhQAQ/PatchDPO.",
      "authors": [
        "Qihan Huang",
        "Weilong Dai",
        "Jinlong Liu",
        "Wanggui He",
        "Hao Jiang",
        "Mingli Song",
        "Jie Song"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-04T09:59:43+00:00",
          "link": "https://arxiv.org/abs/2412.03177v1",
          "size": "17159kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T14:24:28+00:00",
          "link": "https://arxiv.org/abs/2412.03177v2",
          "size": "9073kb",
          "version": "v2"
        }
      ],
      "title": "PatchDPO: Patch-level DPO for Finetuning-free Personalized Image Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.03177",
        "HTML": "https://arxiv.org/html/2412.03177v2",
        "PDF": "https://arxiv.org/pdf/2412.03177"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper presents a method for personalized image generation using a patch-based approach, which is unrelated to LLM training data processing or data engineering tasks."
      },
      "conference_url_abs": "http://openaccess.thecvf.com//content/CVPR2025/html/Huang_PatchDPO_Patch-level_DPO_for_Finetuning-free_Personalized_Image_Generation_CVPR_2025_paper.html",
      "tasks": [
        "Image Generation",
        "Image Reconstruction",
        "Personalized Image Generation"
      ],
      "repo_urls": [
        "https://github.com/hqhqaq/patchdpo"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.04783",
      "abstract": "Wireless sensing has recently found widespread applications in diverse environments, including homes, offices, and public spaces. By analyzing patterns in channel state information (CSI), it is possible to infer human actions for tasks such as person identification, gesture recognition, and fall detection. However, CSI is highly sensitive to environmental changes, where even minor alterations can significantly distort the CSI patterns. This sensitivity often leads to performance degradation or outright failure when applying wireless sensing models trained in one environment to another. To address this challenge, Domain Alignment (DAL) has been widely adopted for cross-domain classification tasks, as it focuses on aligning the global distributions of the source and target domains in feature space. Despite its popularity, DAL often neglects inter-category relationships, which can lead to misalignment between categories across domains, even when global alignment is achieved. To overcome these limitations, we propose K-Nearest Neighbors Maximum Mean Discrepancy (KNN-MMD), a novel few-shot method for cross-domain wireless sensing. Our approach begins by constructing a help set using KNN from the target domain, enabling local alignment between the source and target domains within each category using MMD. Additionally, we address a key instability issue commonly observed in cross-domain methods, where model performance fluctuates sharply between epochs. Further, most existing methods struggle to determine an optimal stopping point during training due to the absence of labeled data from the target domain. Our method resolves this by excluding the support set from the target domain during training and employing it as a validation set to determine the stopping criterion.The dataset and code are publicly available at https://github.com/RS2002/KNN-MMD .",
      "authors": [
        "Zijian Zhao",
        "Zhijie Cai",
        "Tingwei Chen",
        "Xiaoyang Li",
        "Hang Li",
        "Qimei Chen",
        "Guangxu Zhu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-06T05:20:08+00:00",
          "link": "https://arxiv.org/abs/2412.04783v1",
          "size": "5951kb",
          "version": "v1"
        },
        {
          "date": "2025-01-07T08:23:43+00:00",
          "link": "https://arxiv.org/abs/2412.04783v2",
          "size": "8938kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T07:15:52+00:00",
          "link": "https://arxiv.org/abs/2412.04783v3",
          "size": "9286kb",
          "version": "v3"
        }
      ],
      "title": "KNN-MMD: Cross Domain Wireless Sensing via Local Distribution Alignment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.04783",
        "HTML": "https://arxiv.org/html/2412.04783v3",
        "PDF": "https://arxiv.org/pdf/2412.04783"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on domain alignment for wireless sensing tasks using local distribution alignment, which is not related to LLM training data processing or engineering."
      },
      "tasks": [
        "Action Classification",
        "Action Classification (1-shot)",
        "Action Recognition",
        "Domain Adaptation",
        "domain classification",
        "Few-Shot Learning",
        "Gesture Recognition",
        "Person Identification",
        "Person Identification (1-shot)",
        "Zero-Shot Learning"
      ],
      "repo_urls": [
        "https://github.com/RS2002/KNN-MMD"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.05958",
      "abstract": "Large Language Models (LLMs) have facilitated the definition of autonomous intelligent agents. Such agents have already demonstrated their potential in solving complex tasks in different domains. And they can further increase their performance when collaborating with other agents in a multi-agent system. However, the orchestration and coordination of these agents is still challenging, especially when they need to interact with humans as part of human-agentic collaborative workflows. These kinds of workflows need to be precisely specified so that it is clear whose responsible for each task, what strategies agents can follow to complete individual tasks or how decisions will be taken when different alternatives are proposed, among others. Current business process modeling languages fall short when it comes to specifying these new mixed collaborative scenarios. In this exploratory paper, we extend a well-known process modeling language (i.e., BPMN) to enable the definition of this new type of workflow. Our extension covers both the formalization of the new metamodeling concepts required and the proposal of a BPMN-like graphical notation to facilitate the definition of these workflows. Our extension has been implemented and is available as an open-source human-agentic workflow modeling editor on GitHub.",
      "authors": [
        "Adem Ait and Javier Luis C\\'anovas Izquierdo and Jordi Cabot"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-08T14:34:30+00:00",
          "link": "https://arxiv.org/abs/2412.05958v1",
          "size": "735kb",
          "version": "v1"
        },
        {
          "date": "2024-12-12T09:10:32+00:00",
          "link": "https://arxiv.org/abs/2412.05958v2",
          "size": "728kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T10:11:00+00:00",
          "link": "https://arxiv.org/abs/2412.05958v3",
          "size": "710kb",
          "version": "v3"
        }
      ],
      "title": "Towards Modeling Human-Agentic Collaborative Workflows: A BPMN Extension",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.05958",
        "HTML": "https://arxiv.org/html/2412.05958v3",
        "PDF": "https://arxiv.org/pdf/2412.05958"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper discusses extending BPMN for human-agent workflows and does not address LLM training data processing or data engineering tasks relevant to LLMs."
      },
      "repo_urls": [
        "https://github.com/besser-pearl/agentic-bpmn"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.06153",
      "abstract": "Visual Place Recognition (VPR) enables coarse localization by comparing query images to a reference database of geo-tagged images. Recent breakthroughs in deep learning architectures and training regimes have led to methods with improved robustness to factors like environment appearance change, but with the downside that the required training and/or matching compute scales with the number of distinct environmental conditions encountered. Here, we propose Hyperdimensional One Place Signatures (HOPS) to simultaneously improve the performance, compute and scalability of these state-of-the-art approaches by fusing the descriptors from multiple reference sets captured under different conditions. HOPS scales to any number of environmental conditions by leveraging the Hyperdimensional Computing framework. Extensive evaluations demonstrate that our approach is highly generalizable and consistently improves recall performance across all evaluated VPR methods and datasets by large margins. Arbitrarily fusing reference images without compute penalty enables numerous other useful possibilities, three of which we demonstrate here: descriptor dimensionality reduction with no performance penalty, stacking synthetic images, and coarse localization to an entire traverse or environmental section.",
      "authors": [
        "Connor Malone",
        "Somayeh Hussaini",
        "Tobias Fischer",
        "Michael Milford"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-09T02:21:18+00:00",
          "link": "https://arxiv.org/abs/2412.06153v1",
          "size": "1101kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T00:54:23+00:00",
          "link": "https://arxiv.org/abs/2412.06153v2",
          "size": "14030kb",
          "version": "v2"
        }
      ],
      "title": "A Hyperdimensional One Place Signature to Represent Them All: Stackable Descriptors For Visual Place Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.06153",
        "HTML": "https://arxiv.org/html/2412.06153v2",
        "PDF": "https://arxiv.org/pdf/2412.06153"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This work focuses on visual place recognition using HOPS for image descriptor fusion, unrelated to LLM training data processing or data engineering for LLMs."
      },
      "tasks": [
        "All",
        "Dimensionality Reduction",
        "Visual Place Recognition"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.11717",
      "abstract": "UAVs are becoming popular in agriculture, however, they usually use time-consuming row-by-row flight paths. This paper presents a deep-reinforcement-learning-based approach for path planning to efficiently localize weeds in agricultural fields using UAVs with minimal flight-path length. The method combines prior knowledge about the field containing uncertain, low-resolution weed locations with in-flight weed detections. The search policy was learned using deep Q-learning. We trained the agent in simulation, allowing a thorough evaluation of the weed distribution, typical errors in the perception system, prior knowledge, and different stopping criteria on the planner's performance. When weeds were non-uniformly distributed over the field, the agent found them faster than a row-by-row path, showing its capability to learn and exploit the weed distribution. Detection errors and prior knowledge quality had a minor effect on the performance, indicating that the learned search policy was robust to detection errors and did not need detailed prior knowledge. The agent also learned to terminate the search. To test the transferability of the learned policy to a real-world scenario, the planner was tested on real-world image data without further training, which showed a 66% shorter path compared to a row-by-row path at the cost of a 10% lower percentage of found weeds. Strengths and weaknesses of the planner for practical application are comprehensively discussed, and directions for further development are provided. Overall, it is concluded that the learned search policy can improve the efficiency of finding non-uniformly distributed weeds using a UAV and shows potential for use in agricultural practice.",
      "authors": [
        "Rick van Essen",
        "Eldert van Henten and Gert Kootstra"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-16T12:39:02+00:00",
          "link": "https://arxiv.org/abs/2412.11717v1",
          "size": "1443kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T12:43:49+00:00",
          "link": "https://arxiv.org/abs/2412.11717v2",
          "size": "5096kb",
          "version": "v2"
        }
      ],
      "title": "UAV-based path planning for efficient localization of non-uniformly distributed weeds using prior knowledge: A reinforcement-learning approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.11717",
        "HTML": "https://arxiv.org/html/2412.11717v2",
        "PDF": "https://arxiv.org/pdf/2412.11717"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper pertains to UAV-based path planning in agriculture using reinforcement learning, with no reference to processing or engineering data for LLMs."
      },
      "repo_urls": [
        "https://github.com/wur-abe/rl_drone_object_search"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.12644",
      "abstract": "Prompt engineering has made significant contributions to the era of large language models, yet its effectiveness depends on the skills of a prompt author. This paper introduces $\\textit{iPrOp}$, a novel interactive prompt optimization approach, to bridge manual prompt engineering and automatic prompt optimization while offering users the flexibility to assess evolving prompts. We aim to provide users with task-specific guidance to enhance human engagement in the optimization process, which is structured through prompt variations, informative instances, predictions generated by large language models along with their corresponding explanations, and relevant performance metrics. This approach empowers users to choose and further refine the prompts based on their individual preferences and needs. It can not only assist non-technical domain experts in generating optimal prompts tailored to their specific tasks or domains, but also enable to study the intrinsic parameters that influence the performance of prompt optimization. The evaluation shows that our approach has the capability to generate improved prompts, leading to enhanced task performance.",
      "authors": [
        "Jiahui Li and Roman Klinger"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-17T08:09:15+00:00",
          "link": "https://arxiv.org/abs/2412.12644v1",
          "size": "1412kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T11:25:48+00:00",
          "link": "https://arxiv.org/abs/2412.12644v2",
          "size": "520kb",
          "version": "v2"
        }
      ],
      "title": "iPrOp: Interactive Prompt Optimization for Large Language Models with a Human in the Loop",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.12644",
        "HTML": "https://arxiv.org/html/2412.12644v2",
        "PDF": "https://arxiv.org/pdf/2412.12644"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper presents a method for optimizing prompts for LLMs, which touches on aspects of prompt construction but does not fundamentally involve LLM data engineering or processing."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Large Language Model",
        "Prompt Engineering"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.13488",
      "abstract": "Parameter-Efficient Fine-Tuning (PEFT) has gained prominence through low-rank adaptation methods like LoRA. In this paper, we focus on sparsity-based PEFT (SPEFT), which introduces trainable sparse adaptations to the weight matrices in the model, offering greater flexibility in selecting fine-tuned parameters compared to low-rank methods. We conduct the first systematic evaluation of salience metrics for SPEFT, inspired by zero-cost NAS proxies, and identify simple gradient-based metrics is reliable, and results are on par with the best alternatives, offering both computational efficiency and robust performance. Additionally, we compare static and dynamic masking strategies, finding that static masking, which predetermines non-zero entries before training, delivers efficiency without sacrificing performance, while dynamic masking offers no substantial benefits. Across NLP tasks, a simple gradient-based, static SPEFT consistently outperforms other fine-tuning methods for LLMs, providing a simple yet effective baseline for SPEFT. Our work challenges the notion that complexity is necessary for effective PEFT, while our open-source framework establishes a reproducible benchmark for future research, which is available at [https://github.com/0-ml/speft].",
      "authors": [
        "Xinxin Liu",
        "Aaron Thomas",
        "Cheng Zhang",
        "Jianyi Cheng",
        "Yiren Zhao",
        "Xitong Gao"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-18T04:14:35+00:00",
          "link": "https://arxiv.org/abs/2412.13488v1",
          "size": "101kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T12:34:59+00:00",
          "link": "https://arxiv.org/abs/2412.13488v2",
          "size": "231kb",
          "version": "v2"
        }
      ],
      "title": "Refining Salience-Aware Sparse Fine-Tuning Strategies for Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.13488",
        "HTML": "https://arxiv.org/html/2412.13488v2",
        "PDF": "https://arxiv.org/pdf/2412.13488"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The focus is on fine-tuning strategies for language models using sparsity, which involves data aspects at the training stage, but does not address fundamental LLM training data processing or engineering."
      },
      "tasks": [
        "Computational Efficiency",
        "parameter-efficient fine-tuning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.13918",
      "abstract": "The growing size of graph-based modeling artifacts in model-driven engineering calls for techniques that enable efficient execution of graph queries. Incremental approaches based on the RETE algorithm provide an adequate solution in many scenarios, but are generally designed to search for query results over the entire graph. However, in certain situations, a user may only be interested in query results for a subgraph, for instance when a developer is working on a large model of which only a part is loaded into their workspace. In this case, the global execution semantics can result in significant computational overhead.\n  To mitigate the outlined shortcoming, in this article we propose an extension of the RETE approach that enables local, yet fully incremental execution of graph queries, while still guaranteeing completeness of results with respect to the relevant subgraph.\n  We empirically evaluate the presented approach via experiments inspired by a scenario from software development and with queries and data from an independent social network benchmark. The experimental results indicate that the proposed technique can significantly improve performance regarding memory consumption and execution time in favorable cases, but may incur a noticeable overhead in unfavorable cases.",
      "authors": [
        "Matthias Barkowsky and Holger Giese"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-18T14:58:06+00:00",
          "link": "https://arxiv.org/abs/2412.13918v1",
          "size": "408kb",
          "version": "v1"
        },
        {
          "date": "2025-06-26T12:52:26+00:00",
          "link": "https://arxiv.org/abs/2412.13918v2",
          "size": "838kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T12:06:58+00:00",
          "link": "https://arxiv.org/abs/2412.13918v3",
          "size": "831kb",
          "version": "v3"
        }
      ],
      "title": "Localized RETE for Incremental Graph Queries with Nested Graph Conditions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.13918",
        "HTML": "https://arxiv.org/html/2412.13918v3",
        "PDF": "https://arxiv.org/pdf/2412.13918"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on optimizing graph query execution in model-driven engineering environments using an incremental RETE-based approach, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.13938",
      "abstract": "In this paper, we study the Contiguous Art Gallery Problem, introduced by Thomas C. Shermer at the 2024 Canadian Conference on Computational Geometry, a variant of the classical art gallery problem from 1973 by Victor Klee.\n  In the contiguous variant, the input is a simple polygon $P$, and the goal is to partition the boundary into a minimum number of polygonal chains such that each chain is visible to a guard.\n  We present a polynomial-time RAM algorithm, which solves the contiguous art gallery problem.\n  Our algorithm is simple and practical, and we make a C++ implementation available.\n  In contrast, many variations of the art gallery problem are at least NP-hard, making the contiguous variant stand out.\n  These include the classical art gallery problem and the edge-covering problem, both of which being proven to be $\\exists\\mathbb{R}$-complete recently by Abrahamsen, Adamaszek, and Miltzow [J. ACM 2022] and Stade [SoCG 2025], respectively.\n  Our algorithm is a greedy algorithm that repeatedly traverses the polygon's boundary.\n  To find an optimal solution, we show that it is sufficient to traverse the polygon polynomially many times, resulting in a runtime of $\\mathcal{O}\\!\\left( n^6 \\log n \\right)$ arithmetic operations. We further bound the bit complexity of the computed values, showing that problem is in P.\n  Additionally, we provide algorithms for the restricted settings, where either the endpoints of the polygonal chains or the guards must coincide with the vertices of the polygon.",
      "authors": [
        "Magnus Christian Ring Merrild",
        "Casper Moldrup Rysgaard",
        "Jens Kristian Refsgaard Schou",
        "Rolf Svenning"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Geometry (cs.CG)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-18T15:21:37+00:00",
          "link": "https://arxiv.org/abs/2412.13938v1",
          "size": "70kb",
          "version": "v1"
        },
        {
          "date": "2025-06-25T02:22:23+00:00",
          "link": "https://arxiv.org/abs/2412.13938v2",
          "size": "79kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T02:00:14+00:00",
          "link": "https://arxiv.org/abs/2412.13938v3",
          "size": "80kb",
          "version": "v3"
        }
      ],
      "title": "The Contiguous Art Gallery Problem is Solvable in Polynomial Time",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.13938",
        "PDF": "https://arxiv.org/pdf/2412.13938"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper discusses algorithms for solving the Contiguous Art Gallery Problem, focusing on computational geometry, without any mention of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.19723",
      "abstract": "Graphical User Interface (GUI) agents powered by Vision-Language Models (VLMs) have demonstrated human-like computer control capability. Despite their utility in advancing digital automation, a critical bottleneck persists: collecting high-quality trajectory data for training. Common practices for collecting such data rely on human supervision or synthetic data generation through executing pre-defined tasks, which are either resource-intensive or unable to guarantee data quality. Moreover, these methods suffer from limited data diversity and significant gaps between synthetic data and real-world environments. To address these challenges, we propose OS-Genesis, a novel GUI data synthesis pipeline that reverses the conventional trajectory collection process. Instead of relying on pre-defined tasks, OS-Genesis enables agents first to perceive environments and perform step-wise interactions, then retrospectively derive high-quality tasks to enable trajectory-level exploration. A trajectory reward model is then employed to ensure the quality of the generated trajectories. We demonstrate that training GUI agents with OS-Genesis significantly improves their performance on highly challenging online benchmarks. In-depth analysis further validates OS-Genesis's efficiency and its superior data quality and diversity compared to existing synthesis methods. Our codes, data, and checkpoints are available at https://qiushisun.github.io/OS-Genesis-Home/.",
      "authors": [
        "Qiushi Sun",
        "Kanzhi Cheng",
        "Zichen Ding",
        "Chuanyang Jin",
        "Yian Wang",
        "Fangzhi Xu",
        "Zhenyu Wu",
        "Chengyou Jia",
        "Liheng Chen",
        "Zhoumianze Liu",
        "Ben Kao",
        "Guohao Li",
        "Junxian He",
        "Yu Qiao",
        "Zhiyong Wu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-27T16:21:58+00:00",
          "link": "https://arxiv.org/abs/2412.19723v1",
          "size": "9366kb",
          "version": "v1"
        },
        {
          "date": "2025-04-30T08:23:50+00:00",
          "link": "https://arxiv.org/abs/2412.19723v2",
          "size": "9785kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T08:25:48+00:00",
          "link": "https://arxiv.org/abs/2412.19723v3",
          "size": "2553kb",
          "version": "v3"
        }
      ],
      "title": "OS-Genesis: Automating GUI Agent Trajectory Construction via Reverse Task Synthesis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.19723",
        "HTML": "https://arxiv.org/html/2412.19723v3",
        "PDF": "https://arxiv.org/pdf/2412.19723"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "OS-Genesis presents a novel data synthesis pipeline for GUI agent training, focusing on trajectory data collection and quality, which directly relates to data engineering and processing for training VLMs."
      },
      "models": [
        {
          "model_path": "OS-Copilot/OS-Genesis-7B-AC",
          "downloads": "39",
          "likes": "7",
          "trending_score": "0.0",
          "link": "https://huggingface.co/OS-Copilot/OS-Genesis-7B-AC"
        },
        {
          "model_path": "OS-Copilot/OS-Genesis-8B-AC",
          "downloads": "36",
          "likes": "4",
          "trending_score": "0.0",
          "link": "https://huggingface.co/OS-Copilot/OS-Genesis-8B-AC"
        },
        {
          "model_path": "OS-Copilot/OS-Genesis-4B-AC",
          "downloads": "29",
          "likes": "7",
          "trending_score": "0.0",
          "link": "https://huggingface.co/OS-Copilot/OS-Genesis-4B-AC"
        },
        {
          "model_path": "OS-Copilot/OS-Genesis-4B-AW",
          "downloads": "31",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/OS-Copilot/OS-Genesis-4B-AW"
        },
        {
          "model_path": "OS-Copilot/OS-Genesis-8B-AW",
          "downloads": "23",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/OS-Copilot/OS-Genesis-8B-AW"
        },
        {
          "model_path": "OS-Copilot/OS-Genesis-7B-AW",
          "downloads": "28",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/OS-Copilot/OS-Genesis-7B-AW"
        },
        {
          "model_path": "OS-Copilot/OS-Genesis-4B-WA",
          "downloads": "18",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/OS-Copilot/OS-Genesis-4B-WA"
        },
        {
          "model_path": "OS-Copilot/OS-Genesis-8B-WA",
          "downloads": "26",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/OS-Copilot/OS-Genesis-8B-WA"
        },
        {
          "model_path": "OS-Copilot/OS-Genesis-7B-WA",
          "downloads": "1741",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/OS-Copilot/OS-Genesis-7B-WA"
        }
      ],
      "datasets": [
        {
          "dataset_name": "OS-Copilot/OS-Genesis-mobile-data",
          "downloads": "201",
          "likes": "2",
          "link": "https://huggingface.co/datasets/OS-Copilot/OS-Genesis-mobile-data"
        },
        {
          "dataset_name": "OS-Copilot/OS-Genesis-web-data",
          "downloads": "54",
          "likes": "3",
          "link": "https://huggingface.co/datasets/OS-Copilot/OS-Genesis-web-data"
        }
      ],
      "tasks": [
        "Diversity",
        "Synthetic Data Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.01370",
      "abstract": "In this paper, we describe our systems in which the objective is to determine whether a given news article could be considered as hyperpartisan. Hyperpartisan news is news that takes an extremely polarized political standpoint with an intention of creating political divide among the public. We attempted several approaches, including n-grams, sentiment analysis, as well as sentence and document representation using pre-tained ELMo. Our best system using pre-trained ELMo with Bidirectional LSTM achieved an accuracy of 83% through 10-fold cross-validation without much hyperparameter tuning.",
      "authors": [
        "Karthik Mohan",
        "Pengyu Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-02T17:29:53+00:00",
          "link": "https://arxiv.org/abs/2501.01370v1",
          "size": "21kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T06:38:02+00:00",
          "link": "https://arxiv.org/abs/2501.01370v2",
          "size": "0kb",
          "version": "v2"
        }
      ],
      "title": "Embedding-based Approaches to Hyperpartisan News Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.01370",
        "PDF": "https://arxiv.org/pdf/2501.01370"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on detecting hyperpartisan news using various NLP techniques, including pre-trained ELMo embeddings, but it does not discuss any aspects related to LLM training data processing."
      },
      "tasks": [
        "Sentence",
        "Sentiment Analysis"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.01805",
      "abstract": "Training transformer-based encoder-decoder models for long document summarization poses a significant challenge due to the quadratic memory consumption during training. Several approaches have been proposed to extend the input length at test time, but training with these approaches is still difficult, requiring truncation of input documents and causing a mismatch between training and test conditions. In this work, we propose CachED (Gradient $\\textbf{Cach}$ing for $\\textbf{E}$ncoder-$\\textbf{D}$ecoder models), an approach that enables end-to-end training of existing transformer-based encoder-decoder models, using the entire document without truncation. Specifically, we apply non-overlapping sliding windows to input documents, followed by fusion in decoder. During backpropagation, the gradients are cached at the decoder and are passed through the encoder in chunks by re-computing the hidden vectors, similar to gradient checkpointing. In the experiments on long document summarization, we extend BART to CachED BART, processing more than 500K tokens during training and achieving superior performance without using any additional parameters.",
      "authors": [
        "Rohit Saxena",
        "Hao Tang",
        "Frank Keller"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-03T13:32:57+00:00",
          "link": "https://arxiv.org/abs/2501.01805v1",
          "size": "297kb",
          "version": "v1"
        },
        {
          "date": "2025-06-26T18:40:55+00:00",
          "link": "https://arxiv.org/abs/2501.01805v2",
          "size": "317kb",
          "version": "v2"
        }
      ],
      "title": "End-to-End Long Document Summarization using Gradient Caching",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.01805",
        "HTML": "https://arxiv.org/html/2501.01805v2",
        "PDF": "https://arxiv.org/pdf/2501.01805"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper proposes a method for handling long document input in transformer models during summarization tasks, focusing on memory efficiency but does not address LLM training data processing."
      },
      "tasks": [
        "Decoder",
        "Document Summarization",
        "Long-Form Narrative Summarization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.01956",
      "abstract": "The vast diversity of styles, domains, and quality levels present in language model pre-training corpora is essential in developing general model capabilities, but efficiently learning and deploying the correct behaviors exemplified in each of these heterogeneous data sources is challenging. To address this, we propose a new method, termed Metadata Conditioning then Cooldown (MeCo), to incorporate additional learning cues during pre-training. MeCo first provides metadata (e.g., URLs like www$.$wikipedia$.$org) alongside the text during training and later uses a cooldown phase with only the standard text, thereby enabling the model to function normally even without metadata. MeCo significantly accelerates pre-training across different model scales (600M to 8B parameters) and training sources (C4, RefinedWeb, and DCLM). For instance, a 1.6B language model trained with MeCo matches the downstream task performance of standard pre-training while using 33% less data. Additionally, MeCo enables us to steer language models by conditioning the inference prompt on either real or fabricated metadata that encodes the desired properties of the output: for example, prepending wikipedia$.$org to reduce harmful generations or factquizmaster$.$com (fabricated) to improve common knowledge task performance. We also demonstrate that MeCo is compatible with different types of metadata, such as model-generated topics. MeCo is remarkably simple, adds no computational overhead, and demonstrates promise in producing more capable and steerable language models.",
      "authors": [
        "Tianyu Gao",
        "Alexander Wettig",
        "Luxi He",
        "Yihe Dong",
        "Sadhika Malladi",
        "Danqi Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-03T18:59:23+00:00",
          "link": "https://arxiv.org/abs/2501.01956v1",
          "size": "800kb",
          "version": "v1"
        },
        {
          "date": "2025-02-22T19:05:52+00:00",
          "link": "https://arxiv.org/abs/2501.01956v2",
          "size": "669kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T17:15:09+00:00",
          "link": "https://arxiv.org/abs/2501.01956v3",
          "size": "652kb",
          "version": "v3"
        }
      ],
      "title": "Metadata Conditioning Accelerates Language Model Pre-training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.01956",
        "HTML": "https://arxiv.org/html/2501.01956v3",
        "PDF": "https://arxiv.org/pdf/2501.01956"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces Metadata Conditioning, a novel approach for language model pre-training that involves using metadata to improve training efficiency and reduce data requirements, which is directly related to the processing and enhancement of LLM training data."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "model"
      ],
      "repo_urls": [
        "https://github.com/princeton-pli/meco"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.04931",
      "abstract": "Multimodal Large Language Models (MLLMs) have achieved impressive performance and have been put into practical use in commercial applications, but they still have potential safety mechanism vulnerabilities. Jailbreak attacks are red teaming methods that aim to bypass safety mechanisms and discover MLLMs' potential risks. Existing MLLMs' jailbreak methods often bypass the model's safety mechanism through complex optimization methods or carefully designed image and text prompts. Despite achieving some progress, they have a low attack success rate on commercial closed-source MLLMs. Unlike previous research, we empirically find that there exists a Shuffle Inconsistency between MLLMs' comprehension ability and safety ability for the shuffled harmful instruction. That is, from the perspective of comprehension ability, MLLMs can understand the shuffled harmful text-image instructions well. However, they can be easily bypassed by the shuffled harmful instructions from the perspective of safety ability, leading to harmful responses. Then we innovatively propose a text-image jailbreak attack named SI-Attack. Specifically, to fully utilize the Shuffle Inconsistency and overcome the shuffle randomness, we apply a query-based black-box optimization method to select the most harmful shuffled inputs based on the feedback of the toxic judge model. A series of experiments show that SI-Attack can improve the attack's performance on three benchmarks. In particular, SI-Attack can obviously improve the attack success rate for commercial MLLMs such as GPT-4o or Claude-3.5-Sonnet.",
      "authors": [
        "Shiji Zhao",
        "Ranjie Duan",
        "Fengxiang Wang",
        "Chi Chen",
        "Caixin Kang",
        "Shouwei Ruan",
        "Jialing Tao",
        "YueFeng Chen",
        "Hui Xue",
        "Xingxing Wei"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-09T02:47:01+00:00",
          "link": "https://arxiv.org/abs/2501.04931v1",
          "size": "12483kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T10:07:29+00:00",
          "link": "https://arxiv.org/abs/2501.04931v2",
          "size": "13404kb",
          "version": "v2"
        }
      ],
      "title": "Jailbreaking Multimodal Large Language Models via Shuffle Inconsistency",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.04931",
        "HTML": "https://arxiv.org/html/2501.04931v2",
        "PDF": "https://arxiv.org/pdf/2501.04931"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper discusses jailbreak attacks for Multimodal Large Language Models through shuffle inconsistency but does not focus on LLM training data processing or engineering."
      },
      "tasks": [
        "Red Teaming"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.05872",
      "abstract": "We consider conservation laws endowed with an entropy inequality and we study the residual of this inequality, which represents the numerical entropy production by the approximation scheme we are considering. This idea has been introduced and exploited in Runge-Kutta finite volume methods, where the numerical entropy production has been used as an indicator in adaptive schemes, since it scales as the local truncation error of the method for smooth solutions and it highlights the presence of discontinuities and their kind.\n  The aim of this work is to extend this idea to finite volume $P_0P_M$ ADER timestepping techniques. We show that the numerical entropy production can be defined also in this context and it provides a scalar quantity computable for each space-time volume which, under grid refinement, decays to zero with the same rate of convergence of the scheme for smooth solutions. Its size gradually increases when the local solution regularity lowers, remaining bounded up to contact discontinuities and divergent on shock waves. Theoretical results are proven in a multi-dimensional setting on arbitrary grids. We also present numerical evidence showing that it is essentially negative definite. Moreover, we propose an example of $p$-adaptive scheme that uses the numerical entropy production as a-posteriori smoothness indicator. The scheme locally modifies its order of convergence with the purpose of removing the oscillations due to the high-order of accuracy of the scheme.",
      "authors": [
        "Matteo Semplice",
        "Alessandra Zappa"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-10T11:14:50+00:00",
          "link": "https://arxiv.org/abs/2501.05872v1",
          "size": "1667kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T11:35:59+00:00",
          "link": "https://arxiv.org/abs/2501.05872v2",
          "size": "3209kb",
          "version": "v2"
        }
      ],
      "title": "Numerical entropy production in finite volume $P_0P_M$ ADER schemes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.05872",
        "HTML": "https://arxiv.org/html/2501.05872v2",
        "PDF": "https://arxiv.org/pdf/2501.05872"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper deals with numerical entropy production in finite volume schemes for conservation laws, which is unrelated to LLM training data processing or data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.06582",
      "abstract": "Information retrieval, specifically contract clause retrieval, is foundational to contract drafting because lawyers rarely draft contracts from scratch; instead, they locate and revise the most relevant precedent. We introduce the Atticus Clause Retrieval Dataset (ACORD), the first retrieval benchmark for contract drafting fully annotated by experts. ACORD focuses on complex contract clauses such as Limitation of Liability, Indemnification, Change of Control, and Most Favored Nation. It includes 114 queries and over 126,000 query-clause pairs, each ranked on a scale from 1 to 5 stars. The task is to find the most relevant precedent clauses to a query. The bi-encoder retriever paired with pointwise LLMs re-rankers shows promising results. However, substantial improvements are still needed to effectively manage the complex legal work typically undertaken by lawyers. As the first retrieval benchmark for contract drafting annotated by experts, ACORD can serve as a valuable IR benchmark for the NLP community.",
      "authors": [
        "Steven H. Wang",
        "Maksim Zubkov",
        "Kexin Fan",
        "Sarah Harrell",
        "Yuyang Sun",
        "Wei Chen",
        "Andreas Plesner",
        "Roger Wattenhofer"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-11T16:37:49+00:00",
          "link": "https://arxiv.org/abs/2501.06582v1",
          "size": "107kb",
          "version": "v1"
        },
        {
          "date": "2025-05-20T11:27:07+00:00",
          "link": "https://arxiv.org/abs/2501.06582v2",
          "size": "7106kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T09:16:02+00:00",
          "link": "https://arxiv.org/abs/2501.06582v3",
          "size": "6979kb",
          "version": "v3"
        }
      ],
      "title": "ACORD: An Expert-Annotated Retrieval Dataset for Legal Contract Drafting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.06582",
        "HTML": "https://arxiv.org/html/2501.06582v3",
        "PDF": "https://arxiv.org/pdf/2501.06582"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses the creation of a retrieval dataset (ACORD) for contract drafting which is annotated by experts. While it provides a dataset for a specific application (information retrieval in legal contracts), it does not directly address new methods for training data processing for LLMs."
      },
      "tasks": [
        "Information Retrieval",
        "Retrieval"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.13794",
      "abstract": "Accurate prediction of mobile traffic, i.e., network traffic from cellular base stations, is crucial for optimizing network performance and supporting urban development. However, the non-stationary nature of mobile traffic, driven by human activity and environmental changes, leads to both regular patterns and abrupt variations. Diffusion models excel in capturing such complex temporal dynamics due to their ability to capture the inherent uncertainties. Most existing approaches prioritize designing novel denoising networks but often neglect the critical role of noise itself, potentially leading to sub-optimal performance. In this paper, we introduce a novel perspective by emphasizing the role of noise in the denoising process. Our analysis reveals that noise fundamentally shapes mobile traffic predictions, exhibiting distinct and consistent patterns. We propose NPDiff, a framework that decomposes noise into prior and residual components, with the prior} derived from data dynamics, enhancing the model's ability to capture both regular and abrupt variations. NPDiff can seamlessly integrate with various diffusion-based prediction models, delivering predictions that are effective, efficient, and robust. Extensive experiments demonstrate that it achieves superior performance with an improvement over 30\\%, offering a new perspective on leveraging diffusion models in this domain. We provide code and data at https://github.com/tsinghua-fib-lab/NPDiff.",
      "authors": [
        "Zhi Sheng",
        "Daisy Yuan",
        "Jingtao Ding",
        "Yong Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-23T16:13:08+00:00",
          "link": "https://arxiv.org/abs/2501.13794v1",
          "size": "4202kb",
          "version": "v1"
        },
        {
          "date": "2025-03-06T10:49:24+00:00",
          "link": "https://arxiv.org/abs/2501.13794v2",
          "size": "4203kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T01:56:44+00:00",
          "link": "https://arxiv.org/abs/2501.13794v3",
          "size": "2154kb",
          "version": "v3"
        }
      ],
      "title": "Unveiling the Power of Noise Priors: Enhancing Diffusion Models for Mobile Traffic Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.13794",
        "HTML": "https://arxiv.org/html/2501.13794v3",
        "PDF": "https://arxiv.org/pdf/2501.13794"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper introduces an approach for mobile traffic prediction using diffusion models, emphasizing the role of noise in denoising processes. It does not focus on LLM training data processing."
      },
      "tasks": [
        "Denoising",
        "Traffic Prediction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.14275",
      "abstract": "Advances in Large Language Models (LLMs) have sparked interest in their ability to solve Olympiad-level math problems. However, the training and evaluation of these models are constrained by the limited size and quality of available datasets, as creating large-scale data for such advanced problems requires extensive effort from human experts. In addition, current benchmarks are prone to contamination, leading to unreliable evaluations. In this paper, we present an automated pipeline that leverages the rich resources of the Art of Problem Solving (AoPS) forum, which predominantly features Olympiad-level problems and community-driven solutions. Using open-source LLMs, we develop a method to extract question-answer pairs from the forum, resulting in AoPS-Instruct, a dataset of more than 600,000 high-quality QA pairs. Our experiments demonstrate that fine-tuning LLMs on AoPS-Instruct improves their reasoning abilities across various benchmarks. Moreover, we build an automatic pipeline that introduces LiveAoPSBench, an evolving evaluation set with timestamps, derived from the latest forum data, providing a contamination-resistant benchmark for assessing LLM performance. Notably, we observe a significant decline in LLM performance over time, suggesting their success on older examples may stem from pre-training exposure rather than true reasoning ability. Our work presents a scalable approach to creating and maintaining large-scale, high-quality datasets for advanced math reasoning, offering valuable insights into the capabilities and limitations of LLMs in this domain. Our benchmark and code is available at https://github.com/DSL-Lab/aops",
      "authors": [
        "Sadegh Mahdavi",
        "Muchen Li",
        "Kaiwen Liu",
        "Christos Thrampoulidis",
        "Leonid Sigal",
        "Renjie Liao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-24T06:39:38+00:00",
          "link": "https://arxiv.org/abs/2501.14275v1",
          "size": "907kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T02:05:51+00:00",
          "link": "https://arxiv.org/abs/2501.14275v2",
          "size": "921kb",
          "version": "v2"
        }
      ],
      "title": "Leveraging Online Olympiad-Level Math Problems for LLMs Training and Contamination-Resistant Evaluation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.14275",
        "HTML": "https://arxiv.org/html/2501.14275v2",
        "PDF": "https://arxiv.org/pdf/2501.14275"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper's primary contribution is in designing an automated pipeline for extracting question-answer pairs to create a large-scale dataset (AoPS-Instruct) and a contamination-resistant benchmark (LiveAoPSBench) for training and evaluating LLMs. This directly involves the construction and processing of training data for LLMs."
      },
      "datasets": [
        {
          "dataset_name": "jojo23333/LiveAoPSBench-2024",
          "downloads": "80",
          "likes": "2",
          "link": "https://huggingface.co/datasets/jojo23333/LiveAoPSBench-2024"
        }
      ],
      "tasks": [
        "Math"
      ],
      "repo_urls": [
        "https://github.com/dsl-lab/aops"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.14291",
      "abstract": "Temporal point processes (TPPs) are stochastic process models used to characterize event sequences occurring in continuous time. Traditional statistical TPPs have a long-standing history, with numerous models proposed and successfully applied across diverse domains. In recent years, advances in deep learning have spurred the development of neural TPPs, enabling greater flexibility and expressiveness in capturing complex temporal dynamics. The emergence of large language models (LLMs) has further sparked excitement, offering new possibilities for modeling and analyzing event sequences by leveraging their rich contextual understanding. This survey presents a comprehensive review of recent research on TPPs from three perspectives: Bayesian, deep learning, and LLM approaches. We begin with a review of the fundamental concepts of TPPs, followed by an in-depth discussion of model design and parameter estimation techniques in these three frameworks. We also revisit classic application areas of TPPs to highlight their practical relevance. Finally, we outline challenges and promising directions for future research.",
      "authors": [
        "Feng Zhou",
        "Quyu Kong",
        "Jie Qiao",
        "Cheng Wan",
        "Yixuan Zhang",
        "Ruichu Cai"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-24T07:13:26+00:00",
          "link": "https://arxiv.org/abs/2501.14291v1",
          "size": "50kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T03:22:06+00:00",
          "link": "https://arxiv.org/abs/2501.14291v2",
          "size": "508kb",
          "version": "v2"
        }
      ],
      "title": "Advances in Temporal Point Processes: Bayesian, Neural, and LLM Approaches",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.14291",
        "HTML": "https://arxiv.org/html/2501.14291v2",
        "PDF": "https://arxiv.org/pdf/2501.14291"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper is a survey on temporal point processes (TPPs) exploring Bayesian, deep learning, and LLM approaches, but it does not specifically address the processing or construction of training data for LLMs."
      },
      "tasks": [
        "parameter estimation",
        "Point Processes"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.14652",
      "abstract": "We focus on reducing communication overhead in multiplayer games, where frequently exchanging strategies between players is not feasible and players have noisy or outdated strategies of the other players. We introduce Decoupled SGDA, a novel adaptation of Stochastic Gradient Descent Ascent (SGDA). In this approach, players independently update their strategies based on outdated opponent strategies, with periodic synchronization to align strategies. For Strongly-Convex-Strongly-Concave (SCSC) games, we demonstrate that Decoupled SGDA achieves near-optimal communication complexity comparable to the best-known GDA rates. For weakly coupled games where the interaction between players is lower relative to the non-interactive part of the game, Decoupled SGDA significantly reduces communication costs compared to standard SGDA. Our findings extend to multi-player games. To provide insights into the effect of communication frequency and convergence, we extensively study the convergence of Decoupled SGDA for quadratic minimax problems. Lastly, in settings where the noise over the players is imbalanced, Decoupled SGDA significantly outperforms federated minimax methods.",
      "authors": [
        "Ali Zindari and Parham Yazdkhasti and Anton Rodomanov and Tatjana Chavdarova and Sebastian U. Stich"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-24T17:18:46+00:00",
          "link": "https://arxiv.org/abs/2501.14652v1",
          "size": "1469kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T17:22:45+00:00",
          "link": "https://arxiv.org/abs/2501.14652v2",
          "size": "1165kb",
          "version": "v2"
        }
      ],
      "title": "Decoupled SGDA for Games with Intermittent Strategy Communication",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.14652",
        "HTML": "https://arxiv.org/html/2501.14652v2",
        "PDF": "https://arxiv.org/pdf/2501.14652"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper is about reducing communication overhead in multiplayer games using Decoupled SGDA. It does not involve the processing or engineering of training data for LLMs."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2501.15630",
      "abstract": "Recent advances in quantum computing have opened new pathways for enhancing deep learning architectures, particularly in domains characterized by high-dimensional and context-rich data such as natural language processing (NLP). In this work, we present a hybrid classical-quantum Transformer model that integrates a quantum-enhanced attention mechanism into the standard classical architecture. By embedding token representations into a quantum Hilbert space via parameterized variational circuits and exploiting entanglement-aware kernel similarities, the model captures complex semantic relationships beyond the reach of conventional dot-product attention. We demonstrate the effectiveness of this approach across diverse NLP benchmarks, showing improvements in both efficiency and representational capacity. The results section reveal that the quantum attention layer yields globally coherent attention maps and more separable latent features, while requiring comparatively fewer parameters than classical counterparts. These findings highlight the potential of quantum-classical hybrid models to serve as a powerful and resource-efficient alternative to existing attention mechanisms in NLP.",
      "authors": [
        "S.M. Yousuf Iqbal Tomal",
        "Abdullah Al Shafin",
        "Debojit Bhattacharjee",
        "MD. Khairul Amin",
        "Rafiad Sadat Shahir"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-26T18:29:06+00:00",
          "link": "https://arxiv.org/abs/2501.15630v1",
          "size": "302kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T14:09:08+00:00",
          "link": "https://arxiv.org/abs/2501.15630v2",
          "size": "3434kb",
          "version": "v2"
        }
      ],
      "title": "Quantum-Enhanced Attention Mechanism in NLP: A Hybrid Classical-Quantum Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.15630",
        "HTML": "https://arxiv.org/html/2501.15630v2",
        "PDF": "https://arxiv.org/pdf/2501.15630"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper discusses the integration of a quantum-enhanced attention mechanism in NLP models. It does not address the aspects of LLM training data processing or engineering."
      },
      "tasks": [
        "Computational Efficiency",
        "Machine Translation",
        "text-classification",
        "Text Classification"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.17443",
      "abstract": "Existing literature lacks a graph domain adaptation technique for handling large distribution shifts, primarily due to the difficulty in simulating an evolving path from source to target graph. To make a breakthrough, we present a graph gradual domain adaptation (GGDA) framework with the construction of a compact domain sequence that minimizes information loss in adaptations. Our approach starts with an efficient generation of knowledge-preserving intermediate graphs over the Fused Gromov-Wasserstein (FGW) metric. With the bridging data pool, GGDA domains are then constructed via a novel vertex-based domain progression, which comprises \"close\" vertex selections and adaptive domain advancement to enhance inter-domain information transferability. Theoretically, our framework concretizes the intractable inter-domain distance $W_p(\\mu_t,\\mu_{t+1})$ via implementable upper and lower bounds, enabling flexible adjustments of this metric for optimizing domain formation. Extensive experiments under various transfer scenarios validate the superior performance of our GGDA framework.",
      "authors": [
        "Pui Ieng Lei",
        "Ximing Chen",
        "Yijun Sheng",
        "Yanyan Liu",
        "Jingzhi Guo",
        "Zhiguo Gong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-29T06:48:59+00:00",
          "link": "https://arxiv.org/abs/2501.17443v1",
          "size": "3382kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T14:45:02+00:00",
          "link": "https://arxiv.org/abs/2501.17443v2",
          "size": "1566kb",
          "version": "v2"
        }
      ],
      "title": "Gradual Domain Adaptation for Graph Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.17443",
        "HTML": "https://arxiv.org/html/2501.17443v2",
        "PDF": "https://arxiv.org/pdf/2501.17443"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper presents a framework for graph domain adaptation, focusing on adapting graphs with distribution shifts. It is not related to the processing or engineering of training data for LLMs."
      },
      "tasks": [
        "Domain Adaptation",
        "GRAPH DOMAIN ADAPTATION",
        "Graph Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.17556",
      "abstract": "The Pathwidth Theorem states that if a class of graphs has unbounded pathwidth, then it contains all trees as graph minors. We prove a similar result for dense graphs: if a class of graphs has unbounded linear cliquewidth, then it can produce all trees via some fixed CMSO transduction.",
      "authors": [
        "Miko{\\l}aj Bojanczyk",
        "Pierre Ohlmann"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-29T10:43:22+00:00",
          "link": "https://arxiv.org/abs/2501.17556v1",
          "size": "3475kb",
          "version": "v1"
        },
        {
          "date": "2025-06-18T10:18:35+00:00",
          "link": "https://arxiv.org/abs/2501.17556v2",
          "size": "3236kb",
          "version": "v2"
        },
        {
          "date": "2025-06-26T18:16:14+00:00",
          "link": "https://arxiv.org/abs/2501.17556v3",
          "size": "12653kb",
          "version": "v3"
        }
      ],
      "title": "Graphs of unbounded linear cliquewidth must transduce all trees",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.17556",
        "PDF": "https://arxiv.org/pdf/2501.17556"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper discusses properties of graph theory related to graph minors and cliquewidth, which are not directly related to the processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.18853",
      "abstract": "The subspace identification method (SIM) has become a widely adopted approach for the identification of discrete-time linear time-invariant (LTI) systems. In this paper, we derive finite sample high-probability error bounds for the system matrices $A,C$, the Kalman filter gain $K$ and the estimation of system poles. Specifically, we demonstrate that, ignoring the logarithmic factors, for an $n$-dimensional LTI system with no external inputs, the estimation error of these matrices decreases at a rate of at least $ \\mathcal{O}(\\sqrt{1/N}) $, while the estimation error of the system poles decays at a rate of at least $ \\mathcal{O}(N^{-1/2n}) $, where $ N $ represents the number of sample trajectories. Furthermore, we reveal that achieving a constant estimation error requires a super-polynomial sample size in $n/m $, where $n/m$ denotes the state-to-output dimension ratio. Finally, numerical experiments are conducted to validate the non-asymptotic results.",
      "authors": [
        "Shuai Sun"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-31T02:33:45+00:00",
          "link": "https://arxiv.org/abs/2501.18853v1",
          "size": "393kb",
          "version": "v1"
        },
        {
          "date": "2025-02-03T05:17:50+00:00",
          "link": "https://arxiv.org/abs/2501.18853v2",
          "size": "393kb",
          "version": "v2"
        },
        {
          "date": "2025-02-05T08:58:36+00:00",
          "link": "https://arxiv.org/abs/2501.18853v3",
          "size": "393kb",
          "version": "v3"
        },
        {
          "date": "2025-06-26T19:10:12+00:00",
          "link": "https://arxiv.org/abs/2501.18853v4",
          "size": "111kb",
          "version": "v4"
        }
      ],
      "title": "Finite Sample Analysis of Subspace Identification for Stochastic Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.18853",
        "HTML": "https://arxiv.org/html/2501.18853v4",
        "PDF": "https://arxiv.org/pdf/2501.18853"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on subspace identification for stochastic systems and derives error bounds for system matrices. It does not address any aspect of LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2502.00299",
      "abstract": "Large Language Models (LLMs) require significant GPU memory when processing long texts, with the key value (KV) cache consuming up to 70\\% of total memory during inference. Although existing compression methods reduce memory by evaluating the importance of individual tokens, they overlook critical semantic relationships between tokens, resulting in fragmented context and degraded performance. We introduce ChunkKV, which fundamentally reimagines KV cache compression by treating semantic chunks - rather than isolated tokens - as basic compression units. This approach preserves complete linguistic structures and contextual integrity, ensuring that essential meaning is retained even under aggressive compression. Our innovation includes a novel layer-wise index reuse technique that exploits the higher cross-layer similarity of preserved indices in ChunkKV, reducing computational overhead and improving throughput by 26.5\\%. Comprehensive evaluations on challenging benchmarks: LongBench, Needle-In-A-HayStack, GSM8K, and JailbreakV demonstrate that ChunkKV outperforms state-of-the-art methods by up to 8.7\\% in precision while maintaining the same compression ratio. These results confirm that semantic-aware compression significantly enhances both efficiency and performance for long-context LLM inference, providing a simple yet effective solution to the memory bottleneck problem.",
      "authors": [
        "Xiang Liu",
        "Zhenheng Tang",
        "Peijie Dong",
        "Zeyu Li",
        "Yue Liu",
        "Bo Li",
        "Xuming Hu",
        "Xiaowen Chu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-01T03:49:47+00:00",
          "link": "https://arxiv.org/abs/2502.00299v1",
          "size": "713kb",
          "version": "v1"
        },
        {
          "date": "2025-05-21T10:38:37+00:00",
          "link": "https://arxiv.org/abs/2502.00299v2",
          "size": "698kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T09:14:02+00:00",
          "link": "https://arxiv.org/abs/2502.00299v3",
          "size": "698kb",
          "version": "v3"
        }
      ],
      "title": "ChunkKV: Semantic-Preserving KV Cache Compression for Efficient Long-Context LLM Inference",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.00299",
        "HTML": "https://arxiv.org/html/2502.00299v3",
        "PDF": "https://arxiv.org/pdf/2502.00299"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces ChunkKV, a method for compressing the key value cache to optimize memory usage during LLM inference. While it focuses on efficiency during inference, it does not address LLM training data processing directly."
      },
      "tasks": [
        "GSM8K",
        "In-Context Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.00944",
      "abstract": "Graph neural networks (GNN) have shown promising results for several domains such as materials science, chemistry, and the social sciences. GNN models often contain millions of parameters, and like other neural network (NN) models, are often fed only a fraction of the graphs that make up the training dataset in batches to update model parameters. The effect of batching algorithms on training time and model performance has been thoroughly explored for NNs but not yet for GNNs. We analyze two different batching algorithms for graph based models, namely static and dynamic batching for two datasets, the QM9 dataset of small molecules and the AFLOW materials database. Our experiments show that changing the batching algorithm can provide up to a 2.7x speedup, but the fastest algorithm depends on the data, model, batch size, hardware, and number of training steps run. Experiments show that for a select number of combinations of batch size, dataset, and model, significant differences in model learning metrics are observed between static and dynamic batching algorithms.",
      "authors": [
        "Daniel T. Speckhard",
        "Tim Bechtel",
        "Sebastian Kehl",
        "Jonathan Godwin",
        "Claudia Draxl"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-02T22:34:17+00:00",
          "link": "https://arxiv.org/abs/2502.00944v1",
          "size": "4651kb",
          "version": "v1"
        },
        {
          "date": "2025-06-26T20:07:44+00:00",
          "link": "https://arxiv.org/abs/2502.00944v2",
          "size": "4883kb",
          "version": "v2"
        }
      ],
      "title": "Analysis of static and dynamic batching algorithms for graph neural networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.00944",
        "HTML": "https://arxiv.org/html/2502.00944v2",
        "PDF": "https://arxiv.org/pdf/2502.00944"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper analyzes batching algorithms for graph neural networks (GNNs), focusing on training efficiency, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.01551",
      "abstract": "Local certification is a topic originating from distributed computing, where a prover tries to convince the vertices of a graph $G$ that $G$ satisfies some property $\\mathcal{P}$. To convince the vertices, the prover gives a small piece of information, called certificate, to each vertex, and the vertices then decide whether the property $\\mathcal{P}$ is satisfied by just looking at their certificate and the certificates of their neighbors. When studying a property $\\mathcal{P}$ in the perspective of local certification, the aim is to find the optimal size of the certificates needed to certify $\\mathcal{P}$, which can be viewed a measure of the local complexity of $\\mathcal{P}$.\n  A certification scheme is considered to be efficient if the size of the certificates is polylogarithmic in the number of vertices. While there have been a number of meta-theorems providing efficient certification schemes for general graph classes, the proofs of the lower bounds on the size of the certificates are usually very problem-dependent.\n  In this work, we introduce a notion of hardness reduction in local certification, and show that we can transfer a lower bound on the certificates for a property $\\mathcal{P}$ to a lower bound for another property $\\mathcal{P}'$, via a (local) hardness reduction from $\\mathcal{P}$ to $\\mathcal{P}'$. We then give a number of applications in which we obtain polynomial lower bounds for many classical properties using such reductions.",
      "authors": [
        "Louis Esperet and S\\'ebastien Zeitoun"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Discrete Mathematics (cs.DM)",
        "Data Structures and Algorithms (cs.DS)",
        "Combinatorics (math.CO)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-03T17:31:10+00:00",
          "link": "https://arxiv.org/abs/2502.01551v1",
          "size": "148kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T16:11:19+00:00",
          "link": "https://arxiv.org/abs/2502.01551v2",
          "size": "151kb",
          "version": "v2"
        }
      ],
      "title": "Reductions in local certification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.01551",
        "HTML": "https://arxiv.org/html/2502.01551v2",
        "PDF": "https://arxiv.org/pdf/2502.01551"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper is focused on local certification in distributed computing graphs and does not involve any aspects of LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.01980",
      "abstract": "It is difficult to anticipate the myriad challenges that a predictive model will encounter once deployed. Common practice entails a reactive, cyclical approach: model deployment, data mining, and retraining. We instead develop a proactive longtail discovery process by imagining additional data during training. In particular, we develop general model-based longtail signals, including a differentiable, single forward pass formulation of epistemic uncertainty that does not impact model parameters or predictive performance but can flag rare or hard inputs. We leverage these signals as guidance to generate additional training data from a latent diffusion model in a process we call Longtail Guidance (LTG). Crucially, we can perform LTG without retraining the diffusion model or the predictive model, and we do not need to expose the predictive model to intermediate diffusion states. Data generated by LTG exhibit semantically meaningful variation, yield significant generalization improvements on numerous image classification benchmarks, and can be analyzed by a VLM to proactively discover, textually explain, and address conceptual gaps in a deployed predictive model.",
      "authors": [
        "David S. Hayden",
        "Mao Ye",
        "Timur Garipov",
        "Gregory P. Meyer",
        "Carl Vondrick",
        "Zhao Chen",
        "Yuning Chai",
        "Eric Wolff",
        "Siddhartha S. Srinivasa"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-04T03:51:00+00:00",
          "link": "https://arxiv.org/abs/2502.01980v1",
          "size": "15076kb",
          "version": "v1"
        },
        {
          "date": "2025-06-26T21:17:54+00:00",
          "link": "https://arxiv.org/abs/2502.01980v2",
          "size": "6981kb",
          "version": "v2"
        }
      ],
      "title": "Generative Data Mining with Longtail-Guided Diffusion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.01980",
        "HTML": "https://arxiv.org/html/2502.01980v2",
        "PDF": "https://arxiv.org/pdf/2502.01980"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses generating additional training data using Longtail Guidance (LTG) to improve model generalization, which involves a form of data enhancement, but it does not propose new methods specifically for LLM training data pipelines."
      },
      "tasks": [
        "image-classification",
        "Image Classification"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.02189",
      "abstract": "Novel materials drive progress across applications from energy storage to electronics. Automated characterization of material structures with machine learning methods offers a promising strategy for accelerating this key step in material design. In this work, we introduce an autoregressive language model that performs crystal structure prediction (CSP) from powder diffraction data. The presented model, deCIFer, generates crystal structures in the widely used Crystallographic Information File (CIF) format and can be conditioned on powder X-ray diffraction (PXRD) data. Unlike earlier works that primarily rely on high-level descriptors like composition, deCIFer is also able to use diffraction data to perform CSP. We train deCIFer on nearly 2.3M crystal structures and validate on diverse sets of PXRD patterns for characterizing challenging inorganic crystal systems. Qualitative checks and quantitative assessments using the residual weighted profile show that deCIFer produces structures that more accurately match the target diffraction data. Notably, deCIFer can achieve a 94% match rate on test data. deCIFer bridges experimental diffraction data with computational CSP, lending itself as a powerful tool for crystal structure characterization.",
      "authors": [
        "Frederik Lizak Johansen",
        "Ulrik Friis-Jensen",
        "Erik Bj{\\o}rnager Dam",
        "Kirsten Marie {\\O}rnsbjerg Jensen",
        "Roc\\'io Mercado",
        "Raghavendra Selvan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-04T10:09:47+00:00",
          "link": "https://arxiv.org/abs/2502.02189v1",
          "size": "7446kb",
          "version": "v1"
        },
        {
          "date": "2025-02-10T08:39:50+00:00",
          "link": "https://arxiv.org/abs/2502.02189v2",
          "size": "7477kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T06:53:05+00:00",
          "link": "https://arxiv.org/abs/2502.02189v3",
          "size": "6398kb",
          "version": "v3"
        }
      ],
      "title": "deCIFer: Crystal Structure Prediction from Powder Diffraction Data using Autoregressive Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.02189",
        "HTML": "https://arxiv.org/html/2502.02189v3",
        "PDF": "https://arxiv.org/pdf/2502.02189"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper centers on predicting crystal structures with autoregressive language models and does not address training data processing for large language models (LLMs)."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/frederiklizakjohansen/decifer"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.02379",
      "abstract": "Benchmark datasets have proved pivotal to the success of graph learning, and good benchmark datasets are crucial to guide the development of the field. Recent research has highlighted problems with graph-learning datasets and benchmarking practices -- revealing, for example, that methods which ignore the graph structure can outperform graph-based approaches. Such findings raise two questions: (1) What makes a good graph-learning dataset, and (2) how can we evaluate dataset quality in graph learning? Our work addresses these questions. As the classic evaluation setup uses datasets to evaluate models, it does not apply to dataset evaluation. Hence, we start from first principles. Observing that graph-learning datasets uniquely combine two modes -- graph structure and node features --, we introduce Rings, a flexible and extensible mode-perturbation framework to assess the quality of graph-learning datasets based on dataset ablations -- i.e., quantifying differences between the original dataset and its perturbed representations. Within this framework, we propose two measures -- performance separability and mode complementarity -- as evaluation tools, each assessing the capacity of a graph dataset to benchmark the power and efficacy of graph-learning methods from a distinct angle. We demonstrate the utility of our framework for dataset evaluation via extensive experiments on graph-level tasks and derive actionable recommendations for improving the evaluation of graph-learning methods. Our work opens new research directions in data-centric graph learning, and it constitutes a step toward the systematic evaluation of evaluations.",
      "authors": [
        "Corinna Coupette and Jeremy Wayland and Emily Simons and Bastian Rieck"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Social and Information Networks (cs.SI)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-04T14:59:03+00:00",
          "link": "https://arxiv.org/abs/2502.02379v1",
          "size": "1052kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T13:34:57+00:00",
          "link": "https://arxiv.org/abs/2502.02379v2",
          "size": "941kb",
          "version": "v2"
        }
      ],
      "title": "No Metric to Rule Them All: Toward Principled Evaluations of Graph-Learning Datasets",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.02379",
        "HTML": "https://arxiv.org/html/2502.02379v2",
        "PDF": "https://arxiv.org/pdf/2502.02379"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper examines evaluation frameworks for graph-learning datasets and does not relate to data processing or engineering for LLMs."
      },
      "tasks": [
        "All",
        "Benchmarking",
        "Graph Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.02384",
      "abstract": "Ensuring the safety and harmlessness of Large Language Models (LLMs) has become equally critical as their performance in applications. However, existing safety alignment methods typically suffer from safety-performance trade-offs and the susceptibility to jailbreak attacks, primarily due to their reliance on direct refusals for malicious queries. In this paper, we propose STAIR, a novel framework that integrates SafeTy Alignment with Itrospective Reasoning. We enable LLMs to identify safety risks through step-by-step analysis by self-improving chain-of-thought (CoT) reasoning with safety awareness. STAIR first equips the model with a structured reasoning capability and then advances safety alignment via iterative preference optimization on step-level reasoning data generated using our newly proposed Safety-Informed Monte Carlo Tree Search (SI-MCTS). We further train a process reward model on this data to guide test-time searches for improved responses. Extensive experiments show that STAIR effectively mitigates harmful outputs while better preserving helpfulness, compared to instinctive alignment strategies. With test-time scaling, STAIR achieves a safety performance comparable to Claude-3.5 against popular jailbreak attacks. Relevant resources in this work are available at https://github.com/thu-ml/STAIR.",
      "authors": [
        "Yichi Zhang",
        "Siyuan Zhang",
        "Yao Huang",
        "Zeyu Xia",
        "Zhengwei Fang",
        "Xiao Yang",
        "Ranjie Duan",
        "Dong Yan",
        "Yinpeng Dong",
        "Jun Zhu"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-04T15:02:55+00:00",
          "link": "https://arxiv.org/abs/2502.02384v1",
          "size": "2006kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T07:30:35+00:00",
          "link": "https://arxiv.org/abs/2502.02384v2",
          "size": "2022kb",
          "version": "v2"
        }
      ],
      "title": "STAIR: Improving Safety Alignment with Introspective Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.02384",
        "PDF": "https://arxiv.org/pdf/2502.02384"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This study introduces a safety alignment framework for LLMs focusing on reasoning and mitigation of harmful outputs, but it does not involve the processing of training data for the models."
      },
      "models": [
        {
          "model_path": "thu-ml/STAIR-Llama-3.1-8B-SFT",
          "downloads": "17",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/thu-ml/STAIR-Llama-3.1-8B-SFT"
        },
        {
          "model_path": "thu-ml/STAIR-Qwen2-7B-SFT",
          "downloads": "14",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/thu-ml/STAIR-Qwen2-7B-SFT"
        },
        {
          "model_path": "thu-ml/STAIR-Qwen2-7B-DPO-3",
          "downloads": "25",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/thu-ml/STAIR-Qwen2-7B-DPO-3"
        },
        {
          "model_path": "thu-ml/STAIR-Llama-3.1-8B-DPO-3",
          "downloads": "27",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/thu-ml/STAIR-Llama-3.1-8B-DPO-3"
        },
        {
          "model_path": "mradermacher/STAIR-Qwen2-7B-DPO-3-GGUF",
          "downloads": "37",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/mradermacher/STAIR-Qwen2-7B-DPO-3-GGUF"
        },
        {
          "model_path": "mradermacher/STAIR-Llama-3.1-8B-SFT-GGUF",
          "downloads": "37",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/mradermacher/STAIR-Llama-3.1-8B-SFT-GGUF"
        },
        {
          "model_path": "mradermacher/STAIR-Qwen2-7B-SFT-GGUF",
          "downloads": "13",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/mradermacher/STAIR-Qwen2-7B-SFT-GGUF"
        },
        {
          "model_path": "mradermacher/STAIR-Llama-3.1-8B-DPO-3-GGUF",
          "downloads": "21",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/mradermacher/STAIR-Llama-3.1-8B-DPO-3-GGUF"
        },
        {
          "model_path": "mradermacher/STAIR-Llama-3.1-8B-SFT-i1-GGUF",
          "downloads": "90",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/mradermacher/STAIR-Llama-3.1-8B-SFT-i1-GGUF"
        },
        {
          "model_path": "mradermacher/STAIR-Qwen2-7B-SFT-i1-GGUF",
          "downloads": "27",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/mradermacher/STAIR-Qwen2-7B-SFT-i1-GGUF"
        }
      ],
      "datasets": [
        {
          "dataset_name": "thu-ml/STAIR-SFT",
          "downloads": "62",
          "likes": "0",
          "link": "https://huggingface.co/datasets/thu-ml/STAIR-SFT"
        },
        {
          "dataset_name": "thu-ml/STAIR-Prompts",
          "downloads": "59",
          "likes": "0",
          "link": "https://huggingface.co/datasets/thu-ml/STAIR-Prompts"
        }
      ],
      "tasks": [
        "Safety Alignment"
      ],
      "repo_urls": [
        "https://github.com/thu-ml/stair"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.04050",
      "abstract": "We present the first text-based image editing approach for object parts based on pre-trained diffusion models. Diffusion-based image editing approaches capitalized on the deep understanding of diffusion models of image semantics to perform a variety of edits. However, existing diffusion models lack sufficient understanding of many object parts, hindering fine-grained edits requested by users. To address this, we propose to expand the knowledge of pre-trained diffusion models to allow them to understand various object parts, enabling them to perform fine-grained edits. We achieve this by learning special textual tokens that correspond to different object parts through an efficient token optimization process. These tokens are optimized to produce reliable localization masks at each inference step to localize the editing region. Leveraging these masks, we design feature-blending and adaptive thresholding strategies to execute the edits seamlessly. To evaluate our approach, we establish a benchmark and an evaluation protocol for part editing. Experiments show that our approach outperforms existing editing methods on all metrics and is preferred by users 66-90% of the time in conducted user studies.",
      "authors": [
        "Aleksandar Cvejic",
        "Abdelrahman Eldesokey",
        "Peter Wonka"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-06T13:08:43+00:00",
          "link": "https://arxiv.org/abs/2502.04050v1",
          "size": "11317kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T07:57:09+00:00",
          "link": "https://arxiv.org/abs/2502.04050v2",
          "size": "12126kb",
          "version": "v2"
        }
      ],
      "title": "PartEdit: Fine-Grained Image Editing using Pre-Trained Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.04050",
        "HTML": "https://arxiv.org/html/2502.04050v2",
        "PDF": "https://arxiv.org/pdf/2502.04050"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on a text-based image editing approach using diffusion models, with no mention of LLM training data processing or data engineering tasks."
      },
      "datasets": [
        {
          "dataset_name": "Aleksandar/PartEdit-Bench",
          "downloads": "0",
          "likes": "0",
          "link": "https://huggingface.co/datasets/Aleksandar/PartEdit-Bench"
        }
      ],
      "tasks": [
        "Object",
        "Text-based Image Editing"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.04413",
      "abstract": "Retrieval-augmented generation (RAG) is a well-suited technique for retrieving privacy-sensitive Electronic Health Records (EHR). It can serve as a key module of the healthcare copilot, helping reduce misdiagnosis for healthcare practitioners and patients. However, the diagnostic accuracy and specificity of existing heuristic-based RAG models used in the medical domain are inadequate, particularly for diseases with similar manifestations. This paper proposes MedRAG, a RAG model enhanced by knowledge graph (KG)-elicited reasoning for the medical domain that retrieves diagnosis and treatment recommendations based on manifestations. MedRAG systematically constructs a comprehensive four-tier hierarchical diagnostic KG encompassing critical diagnostic differences of various diseases. These differences are dynamically integrated with similar EHRs retrieved from an EHR database, and reasoned within a large language model. This process enables more accurate and specific decision support, while also proactively providing follow-up questions to enhance personalized medical decision-making. MedRAG is evaluated on both a public dataset DDXPlus and a private chronic pain diagnostic dataset (CPDD) collected from Tan Tock Seng Hospital, and its performance is compared against various existing RAG methods. Experimental results show that, leveraging the information integration and relational abilities of the KG, our MedRAG provides more specific diagnostic insights and outperforms state-of-the-art models in reducing misdiagnosis rates. Our code will be available at https://github.com/SNOWTEAM2023/MedRAG",
      "authors": [
        "Xuejiao Zhao",
        "Siyan Liu",
        "Su-Yin Yang",
        "Chunyan Miao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-06T12:27:35+00:00",
          "link": "https://arxiv.org/abs/2502.04413v1",
          "size": "12692kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T12:06:42+00:00",
          "link": "https://arxiv.org/abs/2502.04413v2",
          "size": "3347kb",
          "version": "v2"
        }
      ],
      "title": "MedRAG: Enhancing Retrieval-augmented Generation with Knowledge Graph-Elicited Reasoning for Healthcare Copilot",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.04413",
        "HTML": "https://arxiv.org/html/2502.04413v2",
        "PDF": "https://arxiv.org/pdf/2502.04413"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses enhancing retrieval-augmented generation with knowledge graphs for healthcare, mentioning the use of public datasets for evaluation. However, it does not focus on novel contributions to LLM training data processing or engineering."
      },
      "tasks": [
        "Diagnostic",
        "Large Language Model",
        "RAG",
        "Retrieval",
        "Retrieval-augmented Generation",
        "Specificity"
      ],
      "repo_urls": [
        "https://github.com/snowteam2023/medrag"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.04749",
      "abstract": "We revisit the problem of releasing the sample mean of bounded samples in a dataset, privately, under user-level $\\varepsilon$-differential privacy (DP). We aim to derive the optimal method of preprocessing data samples, within a canonical class of processing strategies, in terms of the error in estimation. Typical error analyses of such \\emph{bounding} (or \\emph{clipping}) strategies in the literature assume that the data samples are independent and identically distributed (i.i.d.), and sometimes also that all users contribute the same number of samples (data homogeneity) -- assumptions that do not accurately model real-world data distributions. Our main result in this work is a precise characterization of the preprocessing strategy that gives rise to the smallest \\emph{worst-case} error over all datasets -- a \\emph{distribution-independent} error metric -- while allowing for data heterogeneity. We also show via experimental studies that even for i.i.d. real-valued samples, our clipping strategy performs much better, in terms of \\emph{average-case} error, than the widely used bounding strategy of Amin et al. (2019).",
      "authors": [
        "V. Arvind Rameshwar and Anshoo Tandon"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-07T08:33:00+00:00",
          "link": "https://arxiv.org/abs/2502.04749v1",
          "size": "392kb",
          "version": "v1"
        },
        {
          "date": "2025-02-25T07:18:48+00:00",
          "link": "https://arxiv.org/abs/2502.04749v2",
          "size": "413kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T06:28:11+00:00",
          "link": "https://arxiv.org/abs/2502.04749v3",
          "size": "122kb",
          "version": "v3"
        }
      ],
      "title": "Bounding User Contributions for User-Level Differentially Private Mean Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.04749",
        "HTML": "https://arxiv.org/html/2502.04749v3",
        "PDF": "https://arxiv.org/pdf/2502.04749"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper addresses differential privacy in mean estimation and preprocessing methods but does not involve LLM training data processing or related tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.06737",
      "abstract": "Process Reward Models (PRMs) have proven effective at enhancing mathematical reasoning for Large Language Models (LLMs) by leveraging increased inference-time computation. However, they are predominantly trained on mathematical data and their generalizability to non-mathematical domains has not been rigorously studied. In response, this work first shows that current PRMs have poor performance in other domains. To address this limitation, we introduce VersaPRM, a multi-domain PRM trained on synthetic reasoning data generated using our novel data generation and annotation method. VersaPRM achieves consistent performance gains across diverse domains. For instance, in the MMLU-Pro category of Law, VersaPRM via weighted majority voting, achieves a 7.9% performance gain over the majority voting baseline -- surpassing Qwen2.5-Math-PRM's gain of 1.3%. We further contribute to the community by open-sourcing all data, code and models for VersaPRM.",
      "authors": [
        "Thomas Zeng",
        "Shuibai Zhang",
        "Shutong Wu",
        "Christian Classen",
        "Daewon Chae",
        "Ethan Ewer",
        "Minjae Lee",
        "Heeju Kim",
        "Wonjun Kang",
        "Jackson Kunde",
        "Ying Fan",
        "Jungtaek Kim",
        "Hyung Il Koo",
        "Kannan Ramchandran",
        "Dimitris Papailiopoulos",
        "Kangwook Lee"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-10T18:03:36+00:00",
          "link": "https://arxiv.org/abs/2502.06737v1",
          "size": "468kb",
          "version": "v1"
        },
        {
          "date": "2025-06-26T20:39:38+00:00",
          "link": "https://arxiv.org/abs/2502.06737v2",
          "size": "700kb",
          "version": "v2"
        }
      ],
      "title": "VersaPRM: Multi-Domain Process Reward Model via Synthetic Reasoning Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.06737",
        "HTML": "https://arxiv.org/html/2502.06737v2",
        "PDF": "https://arxiv.org/pdf/2502.06737"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces a multi-domain Process Reward Model trained on synthetic reasoning data, significantly contributing to the creation and processing of training data for LLMs across different domains."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2502.07381",
      "abstract": "Due to storage and bandwidth limitations, videos transmitted over the Internet often exhibit low quality, characterized by low-resolution and compression artifacts. Although video super-resolution (VSR) is an efficient video enhancing technique, existing VSR methods focus less on compressed videos. Consequently, directly applying general VSR approaches fails to improve practical videos with compression artifacts, especially when frames are highly compressed at a low bit rate. The inevitable quantization information loss complicates the reconstruction of texture details. Recently, diffusion models have shown superior performance in low-level visual tasks. Leveraging the high-realism generation capability of diffusion models, we propose a novel method that exploits the priors of pre-trained diffusion models for compressed VSR. To mitigate spatial distortions and refine temporal consistency, we introduce a Spatial Degradation-Aware and Temporal Consistent (SDATC) diffusion model. Specifically, we incorporate a distortion control module (DCM) to modulate diffusion model inputs, thereby minimizing the impact of noise from low-quality frames on the generation stage. Subsequently, the diffusion model performs a denoising process to generate details, guided by a fine-tuned compression-aware prompt module (CAPM) and a spatio-temporal attention module (STAM). CAPM dynamically encodes compression-related information into prompts, enabling the sampling process to adapt to different degradation levels. Meanwhile, STAM extends the spatial attention mechanism into the spatio-temporal dimension, effectively capturing temporal correlations. Additionally, we utilize optical flow-based alignment during each denoising step to enhance the smoothness of output videos. Extensive experimental results on benchmark datasets demonstrate the effectiveness of our proposed modules in restoring compressed videos.",
      "authors": [
        "Hongyu An",
        "Xinfeng Zhang",
        "Shijie Zhao",
        "Li Zhang",
        "Ruiqin Xiong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-11T08:57:45+00:00",
          "link": "https://arxiv.org/abs/2502.07381v1",
          "size": "11295kb",
          "version": "v1"
        },
        {
          "date": "2025-02-12T07:37:30+00:00",
          "link": "https://arxiv.org/abs/2502.07381v2",
          "size": "11295kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T10:03:50+00:00",
          "link": "https://arxiv.org/abs/2502.07381v3",
          "size": "2706kb",
          "version": "v3"
        }
      ],
      "title": "Spatial Degradation-Aware and Temporal Consistent Diffusion Model for Compressed Video Super-Resolution",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.07381",
        "HTML": "https://arxiv.org/html/2502.07381v3",
        "PDF": "https://arxiv.org/pdf/2502.07381"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This research focuses on video super-resolution using diffusion models, specifically targeting video quality enhancement, without mentioning any aspect of LLM training data processing."
      },
      "tasks": [
        "Denoising",
        "Super-Resolution",
        "Texture Synthesis",
        "Video Super-Resolution"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.08377",
      "abstract": "Recently, the generation of dynamic 3D objects from a video has shown impressive results. Existing methods directly optimize Gaussians using whole information in frames. However, when dynamic regions are interwoven with static regions within frames, particularly if the static regions account for a large proportion, existing methods often overlook information in dynamic regions and are prone to overfitting on static regions. This leads to producing results with blurry textures. We consider that decoupling dynamic-static features to enhance dynamic representations can alleviate this issue. Thus, we propose a dynamic-static feature decoupling module (DSFD). Along temporal axes, it regards the regions of current frame features that possess significant differences relative to reference frame features as dynamic features. Conversely, the remaining parts are the static features. Then, we acquire decoupled features driven by dynamic features and current frame features. Moreover, to further enhance the dynamic representation of decoupled features from different viewpoints and ensure accurate motion prediction, we design a temporal-spatial similarity fusion module (TSSF). Along spatial axes, it adaptively selects similar information of dynamic regions. Hinging on the above, we construct a novel approach, DS4D. Experimental results verify our method achieves state-of-the-art (SOTA) results in video-to-4D. In addition, the experiments on a real-world scenario dataset demonstrate its effectiveness on the 4D scene. Our code will be publicly available.",
      "authors": [
        "Liying Yang",
        "Chen Liu",
        "Zhenwei Zhu",
        "Ajian Liu",
        "Hui Ma",
        "Jian Nong",
        "Yanyan Liang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-12T13:08:35+00:00",
          "link": "https://arxiv.org/abs/2502.08377v1",
          "size": "1680kb",
          "version": "v1"
        },
        {
          "date": "2025-03-12T02:49:03+00:00",
          "link": "https://arxiv.org/abs/2502.08377v2",
          "size": "3629kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T02:31:48+00:00",
          "link": "https://arxiv.org/abs/2502.08377v3",
          "size": "3623kb",
          "version": "v3"
        }
      ],
      "title": "Not All Frame Features Are Equal: Video-to-4D Generation via Decoupling Dynamic-Static Features",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.08377",
        "HTML": "https://arxiv.org/html/2502.08377v3",
        "PDF": "https://arxiv.org/pdf/2502.08377"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The research is concerned with video-to-4D generation techniques in computer graphics, specifically improving dynamic-static feature decoupling in videos, unrelated to LLM training data processing."
      },
      "tasks": [
        "All",
        "motion prediction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.09299",
      "abstract": "We consider the problem of reconfiguring a two-dimensional connected grid arrangement of passive building blocks from a start configuration to a goal configuration, using a single active robot that can move on the tiles, remove individual tiles from a given location and physically move them to a new position by walking on the remaining configuration. The objective is to determine a schedule that minimizes the overall makespan, while keeping the tile configuration connected.\n  We provide both negative and positive results. (1) We generalize the problem by introducing weighted movement costs, which can vary depending on whether tiles are carried or not, and prove that this variant is NP-hard. (2) We give a polynomial-time constant-factor approximation algorithm for the case of disjoint start and target bounding boxes, which additionally yields optimal carry distance for 2-scaled instances.",
      "authors": [
        "Aaron T. Becker",
        "S\\'andor P. Fekete",
        "Jonas Friemel",
        "Ramin Kosfeld",
        "Peter Kramer",
        "Harm Kube",
        "Christian Rieck",
        "Christian Scheffer",
        "and Arne Schmidt"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Geometry (cs.CG)",
        "Data Structures and Algorithms (cs.DS)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-13T13:13:44+00:00",
          "link": "https://arxiv.org/abs/2502.09299v1",
          "size": "2045kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T11:02:32+00:00",
          "link": "https://arxiv.org/abs/2502.09299v2",
          "size": "2049kb",
          "version": "v2"
        }
      ],
      "title": "Efficient Reconfiguration of Tile Arrangements by a Single Active Robot",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.09299",
        "HTML": "https://arxiv.org/html/2502.09299v2",
        "PDF": "https://arxiv.org/pdf/2502.09299"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper addresses a robotic tile reconfiguration problem, focusing on movement scheduling and optimization, which does not relate to any LLM training data processes."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.09692",
      "abstract": "Recent advances in neural surrogate modeling offer the potential for transformative innovations in applications such as automotive aerodynamics. Yet, industrial-scale problems often involve volumetric meshes with cell counts reaching 100 million, presenting major scalability challenges. Complex geometries further complicate modeling through intricate surface-volume interactions, while quantities such as vorticity are highly nonlinear and must satisfy strict divergence-free constraints. To address these requirements, we introduce Anchored-Branched Universal Physics Transformers (AB-UPT) as a novel modeling scheme for building neural surrogates for computational fluid dynamics (CFD) simulations. AB-UPT is designed to: (i) decouple geometry encoding and prediction tasks via multi-branch operators; (ii) enable scalability to high-resolution outputs via neural simulation in a low-dimensional latent space, coupled with anchored neural field decoders to predict high-fidelity outputs; (iii) enforce physics consistency by a novel divergence-free formulation. We show that AB-UPT yields state-of-the-art predictive accuracy of surface and volume fields on automotive CFD simulations ranging from 33 thousand up to 150 million mesh cells. Furthermore, our anchored neural field architecture enables the enforcement of hard physical constraints on the physics predictions without degradation in performance, exemplified by modeling divergence-free vorticity fields. Notably, the proposed models can be trained on a single GPU in less than a day and predict industry-standard surface and volume fields within seconds. Additionally, we show that the flexible design of our method enables neural simulation from a computer-aided design geometry alone, omitting the need for costly CFD meshing procedures.",
      "authors": [
        "Benedikt Alkin",
        "Maurits Bleeker",
        "Richard Kurle",
        "Tobias Kronlachner",
        "Reinhard Sonnleitner",
        "Matthias Dorfer",
        "Johannes Brandstetter"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-13T17:58:07+00:00",
          "link": "https://arxiv.org/abs/2502.09692v1",
          "size": "11431kb",
          "version": "v1"
        },
        {
          "date": "2025-06-13T15:49:13+00:00",
          "link": "https://arxiv.org/abs/2502.09692v2",
          "size": "2728kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T12:59:19+00:00",
          "link": "https://arxiv.org/abs/2502.09692v3",
          "size": "2791kb",
          "version": "v3"
        }
      ],
      "title": "AB-UPT: Scaling Neural CFD Surrogates for High-Fidelity Automotive Aerodynamics Simulations via Anchored-Branched Universal Physics Transformers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.09692",
        "HTML": "https://arxiv.org/html/2502.09692v3",
        "PDF": "https://arxiv.org/pdf/2502.09692"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This work discusses neural surrogate modeling for CFD applications in automotive aerodynamics and does not involve any aspect of training data processing for LLMs."
      },
      "models": [
        {
          "model_path": "EmmiAI/AB-UPT",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/EmmiAI/AB-UPT"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.11095",
      "abstract": "Mental health is increasingly critical in contemporary healthcare, with psychotherapy demanding dynamic, context-sensitive interactions that traditional NLP methods struggle to capture. Large Language Models (LLMs) offer significant potential for addressing this gap due to their ability to handle extensive context and multi-turn reasoning. This review introduces a conceptual taxonomy dividing psychotherapy into interconnected stages--assessment, diagnosis, and treatment--to systematically examine LLM advancements and challenges. Our comprehensive analysis reveals imbalances in current research, such as a focus on common disorders, linguistic biases, fragmented methods, and limited theoretical integration. We identify critical challenges including capturing dynamic symptom fluctuations, overcoming linguistic and cultural biases, and ensuring diagnostic reliability. Highlighting future directions, we advocate for continuous multi-stage modeling, real-time adaptive systems grounded in psychological theory, and diversified research covering broader mental disorders and therapeutic approaches, aiming toward more holistic and clinically integrated psychotherapy LLMs systems.",
      "authors": [
        "Hongbin Na",
        "Yining Hua",
        "Zimu Wang",
        "Tao Shen",
        "Beibei Yu",
        "Lilin Wang",
        "Wei Wang",
        "John Torous",
        "Ling Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-16T12:18:40+00:00",
          "link": "https://arxiv.org/abs/2502.11095v1",
          "size": "657kb",
          "version": "v1"
        },
        {
          "date": "2025-05-31T07:40:23+00:00",
          "link": "https://arxiv.org/abs/2502.11095v2",
          "size": "736kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T06:52:25+00:00",
          "link": "https://arxiv.org/abs/2502.11095v3",
          "size": "736kb",
          "version": "v3"
        }
      ],
      "title": "A Survey of Large Language Models in Psychotherapy: Current Landscape and Future Directions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.11095",
        "HTML": "https://arxiv.org/html/2502.11095v3",
        "PDF": "https://arxiv.org/pdf/2502.11095"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper surveys the application of LLMs in psychotherapy, touching on language model capabilities and potential future directions. However, it does not discuss new data processing methods for LLM training."
      },
      "tasks": [
        "Survey"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.11733",
      "abstract": "Large Language Models (LLMs) serve not only as chatbots but as key components in agent systems, where their common-sense knowledge significantly impacts performance as language-based planners for situated or embodied action. We assess LLMs' incremental learning (based on feedback from the environment), and controlled in-context learning abilities using a text-based environment. We introduce challenging yet interesting set of experiments to test i) how agents can incrementally solve tasks related to every day objects in typical rooms in a house where each of them are discovered by interacting within the environment, ii) controlled in-context learning abilities and efficiency of agents by providing short info about locations of objects and rooms to check how faster the task can be solved, and finally iii) using synthetic pseudo-English words to gauge how well LLMs are at inferring meaning of unknown words from environmental feedback. Results show that larger commercial models have a substantial gap in performance compared to open-weight but almost all models struggle with the synthetic words experiments.",
      "authors": [
        "Jonathan Jordan",
        "Sherzod Hakimov",
        "David Schlangen"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-17T12:20:39+00:00",
          "link": "https://arxiv.org/abs/2502.11733v1",
          "size": "9264kb",
          "version": "v1"
        },
        {
          "date": "2025-05-20T11:43:48+00:00",
          "link": "https://arxiv.org/abs/2502.11733v2",
          "size": "10065kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T13:38:47+00:00",
          "link": "https://arxiv.org/abs/2502.11733v3",
          "size": "8198kb",
          "version": "v3"
        }
      ],
      "title": "Plant in Cupboard, Orange on Rably, Inat Aphone. Benchmarking Incremental Learning of Situation and Language Model using a Text-Simulated Situated Environment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.11733",
        "HTML": "https://arxiv.org/html/2502.11733v3",
        "PDF": "https://arxiv.org/pdf/2502.11733"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on assessing incremental learning and in-context learning abilities of LLMs in a text-based environment, with no mention of training data processing, collection, or construction for LLMs."
      },
      "tasks": [
        "Benchmarking",
        "Common Sense Reasoning",
        "In-Context Learning",
        "Incremental Learning",
        "Language Modeling",
        "Language Modelling"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.14496",
      "abstract": "LLM-based agents have made significant advancements in interactive environments, such as mobile operations and web browsing, and other domains beyond computer using. Current multi-agent systems universally excel in performance, compared to single agents, but struggle with generalization across environments due to predefined roles and inadequate strategies for generalizing language agents. The challenge of achieving both strong performance and good generalization has hindered the progress of multi-agent systems for interactive environments. To address these issues, we propose CollabUIAgents, a multi-agent reinforcement learning framework with a novel multi-agent credit re-assignment (CR) strategy, assigning process rewards with LLMs rather than environment-specific rewards and learning with synthesized preference data, in order to foster generalizable, collaborative behaviors among the role-free agents' policies. Empirical results show that our framework improves both performance and cross-environment generalizability of multi-agent systems. Moreover, our 7B-parameter system achieves results on par with or exceed strong closed-source models, and the LLM that guides the CR. We also provide insights in using granular CR rewards effectively for environment generalization, and accommodating trained LLMs in multi-agent systems.",
      "authors": [
        "Zhitao He",
        "Zijun Liu",
        "Peng Li",
        "Yi R Fung",
        "Ming Yan",
        "Ji Zhang",
        "Fei Huang",
        "Yang Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-20T12:26:15+00:00",
          "link": "https://arxiv.org/abs/2502.14496v1",
          "size": "2289kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T08:30:22+00:00",
          "link": "https://arxiv.org/abs/2502.14496v2",
          "size": "2297kb",
          "version": "v2"
        }
      ],
      "title": "Advancing Language Multi-Agent Learning with Credit Re-Assignment for Interactive Environment Generalization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.14496",
        "HTML": "https://arxiv.org/html/2502.14496v2",
        "PDF": "https://arxiv.org/pdf/2502.14496"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This study introduces a framework in multi-agent learning using reinforcement strategies and synthesized preference data but does not discuss training data engineering or processing for LLMs."
      },
      "tasks": [
        "Multi-agent Reinforcement Learning"
      ],
      "repo_urls": [
        "https://github.com/THUNLP-MT/CollabUIAgents"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.14949",
      "abstract": "With the growing adoption of Retrieval-Augmented Generation (RAG) in document processing, robust text recognition has become increasingly critical for knowledge extraction. While OCR (Optical Character Recognition) for English and other languages benefits from large datasets and well-established benchmarks, Arabic OCR faces unique challenges due to its cursive script, right-to-left text flow, and complex typographic and calligraphic features. We present KITAB-Bench, a comprehensive Arabic OCR benchmark that fills the gaps in current evaluation systems. Our benchmark comprises 8,809 samples across 9 major domains and 36 sub-domains, encompassing diverse document types including handwritten text, structured tables, and specialized coverage of 21 chart types for business intelligence. Our findings show that modern vision-language models (such as GPT-4o, Gemini, and Qwen) outperform traditional OCR approaches (like EasyOCR, PaddleOCR, and Surya) by an average of 60% in Character Error Rate (CER). Furthermore, we highlight significant limitations of current Arabic OCR models, particularly in PDF-to-Markdown conversion, where the best model Gemini-2.0-Flash achieves only 65% accuracy. This underscores the challenges in accurately recognizing Arabic text, including issues with complex fonts, numeral recognition errors, word elongation, and table structure detection. This work establishes a rigorous evaluation framework that can drive improvements in Arabic document analysis methods and bridge the performance gap with English OCR technologies.",
      "authors": [
        "Ahmed Heakl",
        "Abdullah Sohail",
        "Mukul Ranjan",
        "Rania Hossam",
        "Ghazi Shazan Ahmad",
        "Mohamed El-Geish",
        "Omar Maher",
        "Zhiqiang Shen",
        "Fahad Khan",
        "Salman Khan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-20T18:41:23+00:00",
          "link": "https://arxiv.org/abs/2502.14949v1",
          "size": "5266kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T14:31:41+00:00",
          "link": "https://arxiv.org/abs/2502.14949v2",
          "size": "2002kb",
          "version": "v2"
        }
      ],
      "title": "KITAB-Bench: A Comprehensive Multi-Domain Benchmark for Arabic OCR and Document Understanding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.14949",
        "HTML": "https://arxiv.org/html/2502.14949v2",
        "PDF": "https://arxiv.org/pdf/2502.14949"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper introduces an Arabic OCR benchmark and discusses improvements in document analysis methods and vision-language models' performance, without addressing LLM training data processing."
      },
      "datasets": [
        {
          "dataset_name": "ahmedheakl/arocrbench_synthesizear",
          "downloads": "133",
          "likes": "0",
          "link": "https://huggingface.co/datasets/ahmedheakl/arocrbench_synthesizear"
        },
        {
          "dataset_name": "ahmedheakl/arocrbench_patsocr",
          "downloads": "105",
          "likes": "0",
          "link": "https://huggingface.co/datasets/ahmedheakl/arocrbench_patsocr"
        },
        {
          "dataset_name": "ahmedheakl/arocrbench_historyar",
          "downloads": "68",
          "likes": "0",
          "link": "https://huggingface.co/datasets/ahmedheakl/arocrbench_historyar"
        },
        {
          "dataset_name": "ahmedheakl/arocrbench_historicalbooks",
          "downloads": "75",
          "likes": "0",
          "link": "https://huggingface.co/datasets/ahmedheakl/arocrbench_historicalbooks"
        },
        {
          "dataset_name": "ahmedheakl/arocrbench_khattparagraph",
          "downloads": "81",
          "likes": "0",
          "link": "https://huggingface.co/datasets/ahmedheakl/arocrbench_khattparagraph"
        },
        {
          "dataset_name": "ahmedheakl/arocrbench_adab",
          "downloads": "84",
          "likes": "0",
          "link": "https://huggingface.co/datasets/ahmedheakl/arocrbench_adab"
        },
        {
          "dataset_name": "ahmedheakl/arocrbench_muharaf",
          "downloads": "56",
          "likes": "0",
          "link": "https://huggingface.co/datasets/ahmedheakl/arocrbench_muharaf"
        },
        {
          "dataset_name": "ahmedheakl/arocrbench_onlinekhatt",
          "downloads": "75",
          "likes": "0",
          "link": "https://huggingface.co/datasets/ahmedheakl/arocrbench_onlinekhatt"
        },
        {
          "dataset_name": "ahmedheakl/arocrbench_khatt",
          "downloads": "104",
          "likes": "1",
          "link": "https://huggingface.co/datasets/ahmedheakl/arocrbench_khatt"
        },
        {
          "dataset_name": "ahmedheakl/arocrbench_isippt",
          "downloads": "113",
          "likes": "0",
          "link": "https://huggingface.co/datasets/ahmedheakl/arocrbench_isippt"
        },
        {
          "dataset_name": "ahmedheakl/arocrbench_arabicocr",
          "downloads": "96",
          "likes": "0",
          "link": "https://huggingface.co/datasets/ahmedheakl/arocrbench_arabicocr"
        },
        {
          "dataset_name": "ahmedheakl/arocrbench_hindawi",
          "downloads": "98",
          "likes": "0",
          "link": "https://huggingface.co/datasets/ahmedheakl/arocrbench_hindawi"
        },
        {
          "dataset_name": "ahmedheakl/arocrbench_evarest",
          "downloads": "43",
          "likes": "0",
          "link": "https://huggingface.co/datasets/ahmedheakl/arocrbench_evarest"
        },
        {
          "dataset_name": "ahmedheakl/arocrbench_doclaynet",
          "downloads": "44",
          "likes": "0",
          "link": "https://huggingface.co/datasets/ahmedheakl/arocrbench_doclaynet"
        },
        {
          "dataset_name": "ahmedheakl/arocrbench_tables",
          "downloads": "74",
          "likes": "0",
          "link": "https://huggingface.co/datasets/ahmedheakl/arocrbench_tables"
        },
        {
          "dataset_name": "ahmedheakl/arocrbench_charts",
          "downloads": "63",
          "likes": "0",
          "link": "https://huggingface.co/datasets/ahmedheakl/arocrbench_charts"
        },
        {
          "dataset_name": "ahmedheakl/arocrbench_bcelayout",
          "downloads": "200",
          "likes": "0",
          "link": "https://huggingface.co/datasets/ahmedheakl/arocrbench_bcelayout"
        },
        {
          "dataset_name": "ahmedheakl/arocrbench_diagrams",
          "downloads": "44",
          "likes": "0",
          "link": "https://huggingface.co/datasets/ahmedheakl/arocrbench_diagrams"
        },
        {
          "dataset_name": "ahmedheakl/arocrbench_ourslines",
          "downloads": "70",
          "likes": "0",
          "link": "https://huggingface.co/datasets/ahmedheakl/arocrbench_ourslines"
        },
        {
          "dataset_name": "ahmedheakl/arocrbench_diagramsvqa",
          "downloads": "52",
          "likes": "0",
          "link": "https://huggingface.co/datasets/ahmedheakl/arocrbench_diagramsvqa"
        },
        {
          "dataset_name": "ahmedheakl/arocrbench_chartsvqa",
          "downloads": "42",
          "likes": "0",
          "link": "https://huggingface.co/datasets/ahmedheakl/arocrbench_chartsvqa"
        },
        {
          "dataset_name": "ahmedheakl/arocrbench_mtvqa",
          "downloads": "56",
          "likes": "0",
          "link": "https://huggingface.co/datasets/ahmedheakl/arocrbench_mtvqa"
        },
        {
          "dataset_name": "ahmedheakl/arocrbench_patdvqa",
          "downloads": "65",
          "likes": "0",
          "link": "https://huggingface.co/datasets/ahmedheakl/arocrbench_patdvqa"
        }
      ],
      "tasks": [
        "document understanding",
        "Optical Character Recognition",
        "Optical Character Recognition (OCR)",
        "RAG",
        "Retrieval-augmented Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.15294",
      "abstract": "The increasing context window size in large language models (LLMs) has improved their ability to handle complex, long-text tasks. However, as the conversation rounds continue, it is required to store a large amount of KV cache in GPU memory, which significantly affects the efficiency and even availability of the model serving systems. This paper analyzes dialogue data from real users on the granularity of round and discovers that the LLM inference manifests a watershed layer, after which the distribution of round-level attention shows notable similarity. Based on this, we propose Round Attention - a novel round-level attention mechanism that selectively processes the KV cache of top-k relevant rounds, where k is dynamically determined through the attention matrix in the watershed layer. Theoretical analysis demonstrates that our method reduces memory usage by 54\\% to 82\\%, while experimental results confirm that loading sparse critical-round KV cache maintains answer accuracy without performance degradation.",
      "authors": [
        "Yaohua Tang",
        "Zhicheng Hu",
        "Kun Cheng",
        "Fan Mo",
        "Qiheng Lv",
        "Hua Wang",
        "Zhi Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-21T08:40:07+00:00",
          "link": "https://arxiv.org/abs/2502.15294v1",
          "size": "1191kb",
          "version": "v1"
        },
        {
          "date": "2025-02-24T13:35:18+00:00",
          "link": "https://arxiv.org/abs/2502.15294v2",
          "size": "1191kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T03:43:24+00:00",
          "link": "https://arxiv.org/abs/2502.15294v3",
          "size": "602kb",
          "version": "v3"
        }
      ],
      "title": "Round Attention: A Novel Round-Level Attention Mechanism to Accelerate LLM Inference",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.15294",
        "PDF": "https://arxiv.org/pdf/2502.15294"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The research presents a novel round-level attention mechanism to optimize LLM inference efficiency but does not involve any aspect of LLM training data collection or processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2502.16314",
      "abstract": "In this paper we investigate the information-theoretic and mathematical foundations of Benford's law, an important case of a statistical relationship that appears to constrain the information-theoretic behavior of numbers. In the present analysis we seek to deduce a general cause for Benford-like distributions to arise. We posit that they both follow from optimality and renormalization as applied to information-theoretical functionals. We also perform computational experiments that corroborate our conclusions.",
      "authors": [
        "Alexander Kolpakov",
        "Aidan Rocke"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Computational Complexity (cs.CC)",
        "Discrete Mathematics (cs.DM)",
        "Mathematical Physics (math-ph)",
        "Information Theory (math.IT)",
        "Mathematical Physics (math.MP)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-22T18:04:28+00:00",
          "link": "https://arxiv.org/abs/2502.16314v1",
          "size": "182kb",
          "version": "v1"
        },
        {
          "date": "2025-06-19T03:31:31+00:00",
          "link": "https://arxiv.org/abs/2502.16314v2",
          "size": "184kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T01:53:37+00:00",
          "link": "https://arxiv.org/abs/2502.16314v3",
          "size": "183kb",
          "version": "v3"
        }
      ],
      "title": "Benford's Law from Turing Ensembles and Integer Partitions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.16314",
        "HTML": "https://arxiv.org/html/2502.16314v3",
        "PDF": "https://arxiv.org/pdf/2502.16314"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on the information-theoretic and mathematical foundations of Benford's law, without any mention of LLM training data processing or data engineering."
      },
      "repo_urls": [
        "https://github.com/sashakolpakov/benford-experiment"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.18023",
      "abstract": "Despite the advancements made in Visual Large Language Models (VLLMs), like text Large Language Models (LLMs), they have limitations in addressing questions that require real-time information or are knowledge-intensive. Indiscriminately adopting Retrieval Augmented Generation (RAG) techniques is an effective yet expensive way to enable models to answer queries beyond their knowledge scopes. To mitigate the dependence on retrieval and simultaneously maintain, or even improve, the performance benefits provided by retrieval, we propose a method to detect the knowledge boundary of VLLMs, allowing for more efficient use of techniques like RAG. Specifically, we propose a method with two variants that fine-tunes a VLLM on an automatically constructed dataset for boundary identification. Experimental results on various types of Visual Question Answering datasets show that our method successfully depicts a VLLM's knowledge boundary based on which we are able to reduce indiscriminate retrieval while maintaining or improving the performance. In addition, we show that the knowledge boundary identified by our method for one VLLM can be used as a surrogate boundary for other VLLMs. Code will be released at https://github.com/Chord-Chen-30/VLLM-KnowledgeBoundary",
      "authors": [
        "Zhuo Chen",
        "Xinyu Wang",
        "Yong Jiang",
        "Zhen Zhang",
        "Xinyu Geng",
        "Pengjun Xie",
        "Fei Huang",
        "Kewei Tu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-25T09:32:08+00:00",
          "link": "https://arxiv.org/abs/2502.18023v1",
          "size": "7361kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T08:05:04+00:00",
          "link": "https://arxiv.org/abs/2502.18023v2",
          "size": "7362kb",
          "version": "v2"
        }
      ],
      "title": "Detecting Knowledge Boundary of Vision Large Language Models by Sampling-Based Inference",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.18023",
        "HTML": "https://arxiv.org/html/2502.18023v2",
        "PDF": "https://arxiv.org/pdf/2502.18023"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses fine-tuning a Visual Large Language Model (VLLM) on automatically constructed datasets for knowledge boundary detection. However, it does not propose new methods for the broader processing or engineering of LLM training data."
      },
      "tasks": [
        "Question Answering",
        "RAG",
        "Retrieval",
        "Retrieval-augmented Generation",
        "Visual Question Answering"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.19290",
      "abstract": "Time-dependent partial differential equations are a significant class of equations that describe the evolution of various physical phenomena over time. One of the open problems in scientific computing is predicting the behaviour of the solution outside the given temporal region. Most traditional numerical methods are applied to a given time-space region and can only accurately approximate the solution of the given region. To address this problem, many deep learning-based methods, basically data-driven and data-free approaches, have been developed to solve these problems. However, most data-driven methods require a large amount of data, which consumes significant computational resources and fails to utilize all the necessary information embedded underlying the partial differential equations (PDEs). Moreover, data-free approaches such as Physics-Informed Neural Networks (PINNs) may not be that ideal in practice, as traditional PINNs, which primarily rely on multilayer perceptrons (MLPs) and convolutional neural networks (CNNs), tend to overlook the crucial temporal dependencies inherent in real-world physical systems. We propose a method denoted as \\textbf{PhysicsSolver} that merges the strengths of two approaches: data-free methods that can learn the intrinsic properties of physical systems without using data, and data-driven methods, which are effective at making predictions. Extensive numerical experiments have demonstrated the efficiency and robustness of our proposed method. We provide the code at \\href{https://github.com/PhysicsSolver/PhysicsSolver}{https://github.com/PhysicsSolver}.",
      "authors": [
        "Zhenyi Zhu",
        "Yuchen Huang",
        "Liu Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-26T16:49:58+00:00",
          "link": "https://arxiv.org/abs/2502.19290v1",
          "size": "8229kb",
          "version": "v1"
        },
        {
          "date": "2025-06-26T20:39:49+00:00",
          "link": "https://arxiv.org/abs/2502.19290v2",
          "size": "26715kb",
          "version": "v2"
        }
      ],
      "title": "PhysicsSolver: Transformer-Enhanced Physics-Informed Neural Networks for Forward and Forecasting Problems in Partial Differential Equations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.19290",
        "HTML": "https://arxiv.org/html/2502.19290v2",
        "PDF": "https://arxiv.org/pdf/2502.19290"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper primarily addresses the application of neural networks to predict the behavior of solutions to partial differential equations and does not involve any LLM training data processing or data engineering."
      },
      "repo_urls": [
        "https://github.com/physicssolver/physicssolver"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.20098",
      "abstract": "The current-induced magnetisation dynamics in a ferromagnet at elevated temperatures can be described by the Landau--Lifshitz--Bloch (LLB) equation with spin-torque terms. In this paper, we focus on the regime above the Curie temperature. We first establish the existence and uniqueness of a global strong solution to the model in spatial dimensions $d=1,2,3$, under an additional smallness assumption on the initial data if $d=3$. Relevant smoothing and decay estimates are also derived. We then propose a fully discrete, linearly implicit finite element scheme for the problem and prove that it achieves optimal-order convergence, assuming adequate regularity of the exact solution. In addition, we introduce an unconditionally energy-stable finite element method for the case of negligible non-adiabatic torque. This scheme is also shown to converge optimally and, in the absence of current, preserves energy dissipation at the discrete level. Finally, we present numerical simulations that support the theoretical analysis and demonstrate the performance of the proposed methods.",
      "authors": [
        "Agus L. Soenjaya"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Analysis of PDEs (math.AP)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-27T13:56:31+00:00",
          "link": "https://arxiv.org/abs/2502.20098v1",
          "size": "9445kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T07:17:19+00:00",
          "link": "https://arxiv.org/abs/2502.20098v2",
          "size": "9003kb",
          "version": "v2"
        }
      ],
      "title": "Numerical analysis of the Landau--Lifshitz--Bloch equation with spin-torques",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.20098",
        "PDF": "https://arxiv.org/pdf/2502.20098"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper explores numerical analysis of the Landau--Lifshitz--Bloch equation and does not pertain to LLM training or data processing tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.20380",
      "abstract": "We address the problem of code generation from multi-turn execution feedback. Existing methods either generate code without feedback or use complex, hierarchical reinforcement learning to optimize multi-turn rewards. We propose a simple yet scalable approach, $\\mu$Code, that solves multi-turn code generation using only single-step rewards. Our key insight is that code generation is a one-step recoverable MDP, where the correct code can be recovered from any intermediate code state in a single turn. $\\mu$Code iteratively trains both a generator to provide code solutions conditioned on multi-turn execution feedback and a verifier to score the newly generated code. Experimental evaluations show that our approach achieves significant improvements over the state-of-the-art baselines. We provide analysis of the design choices of the reward models and policy, and show the efficacy of $\\mu$Code at utilizing the execution feedback. Our code is available at https://github.com/portal-cornell/muCode.",
      "authors": [
        "Arnav Kumar Jain and Gonzalo Gonzalez-Pumariega and Wayne Chen and Alexander M Rush and Wenting Zhao and Sanjiban Choudhury"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-27T18:55:05+00:00",
          "link": "https://arxiv.org/abs/2502.20380v1",
          "size": "2445kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T15:47:52+00:00",
          "link": "https://arxiv.org/abs/2502.20380v2",
          "size": "1901kb",
          "version": "v2"
        }
      ],
      "title": "Multi-Turn Code Generation Through Single-Step Rewards",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.20380",
        "HTML": "https://arxiv.org/html/2502.20380v2",
        "PDF": "https://arxiv.org/pdf/2502.20380"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on code generation through execution feedback and multi-turn rewards but does not address LLM training data processing or data engineering tasks related to LLMs."
      },
      "tasks": [
        "Code Generation",
        "Hierarchical Reinforcement Learning"
      ],
      "repo_urls": [
        "https://github.com/portal-cornell/mucode"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.01164",
      "abstract": "The adoption of visual foundation models has become a common practice in computer-aided diagnosis (CAD). While these foundation models provide a viable solution for creating generalist medical AI, privacy concerns make it difficult to pre-train or continuously update such models across multiple domains and datasets, leading many studies to focus on specialist models. To address this challenge, we propose Med-LEGO, a training-free framework that enables the seamless integration or updating of a generalist CAD model by combining multiple specialist models, similar to assembling LEGO bricks. Med-LEGO enhances LoRA (low-rank adaptation) by incorporating singular value decomposition (SVD) to efficiently capture the domain expertise of each specialist model with minimal additional parameters. By combining these adapted weights through simple operations, Med-LEGO allows for the easy integration or modification of specific diagnostic capabilities without the need for original data or retraining. Finally, the combined model can be further adapted to new diagnostic tasks, making it a versatile generalist model. Our extensive experiments demonstrate that Med-LEGO outperforms existing methods in both cross-domain and in-domain medical tasks while using only 0.18% of full model parameters. These merged models show better convergence and generalization to new tasks, providing an effective path toward generalist medical AI.",
      "authors": [
        "Yitao Zhu",
        "Yuan Yin",
        "Jiaming Li",
        "Mengjie Xu",
        "Zihao Zhao",
        "Honglin Xiong",
        "Sheng Wang",
        "Qian Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-03T04:27:11+00:00",
          "link": "https://arxiv.org/abs/2503.01164v1",
          "size": "790kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T01:51:38+00:00",
          "link": "https://arxiv.org/abs/2503.01164v2",
          "size": "489kb",
          "version": "v2"
        }
      ],
      "title": "Med-LEGO: Editing and Adapting toward Generalist Medical Image Diagnosis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.01164",
        "HTML": "https://arxiv.org/html/2503.01164v2",
        "PDF": "https://arxiv.org/pdf/2503.01164"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper proposes Med-LEGO, which focuses on combining specialist medical models without training data or retraining, and does not pertain to LLM training data processing or engineering."
      },
      "tasks": [
        "Diagnostic"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.01584",
      "abstract": "Exploration is a cornerstone of reinforcement learning (RL). Intrinsic motivation attempts to decouple exploration from external, task-based rewards. However, established approaches to intrinsic motivation that follow general principles such as information gain, often only uncover low-level interactions. In contrast, children's play suggests that they engage in meaningful high-level behavior by imitating or interacting with their caregivers. Recent work has focused on using foundation models to inject these semantic biases into exploration. However, these methods often rely on unrealistic assumptions, such as language-embedded environments or access to high-level actions. We propose SEmaNtically Sensible ExploratIon (SENSEI), a framework to equip model-based RL agents with an intrinsic motivation for semantically meaningful behavior. SENSEI distills a reward signal of interestingness from Vision Language Model (VLM) annotations, enabling an agent to predict these rewards through a world model. Using model-based RL, SENSEI trains an exploration policy that jointly maximizes semantic rewards and uncertainty. We show that in both robotic and video game-like simulations SENSEI discovers a variety of meaningful behaviors from image observations and low-level actions. SENSEI provides a general tool for learning from foundation model feedback, a crucial research direction, as VLMs become more powerful.",
      "authors": [
        "Cansu Sancaktar",
        "Christian Gumbsch",
        "Andrii Zadaianchuk",
        "Pavel Kolev",
        "Georg Martius"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-03T14:26:15+00:00",
          "link": "https://arxiv.org/abs/2503.01584v1",
          "size": "5951kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T15:33:13+00:00",
          "link": "https://arxiv.org/abs/2503.01584v2",
          "size": "7187kb",
          "version": "v2"
        }
      ],
      "title": "SENSEI: Semantic Exploration Guided by Foundation Models to Learn Versatile World Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.01584",
        "HTML": "https://arxiv.org/html/2503.01584v2",
        "PDF": "https://arxiv.org/pdf/2503.01584"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "SENSEI introduces an exploration framework in reinforcement learning using Vision Language Model annotations. It focuses on intrinsic rewards and exploration, not on LLM training data processing or engineering."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2503.01862",
      "abstract": "This paper integrates a clearing function (CF)-based release planning approach into Material Requirements Planning (MRP) to address its limitations in modeling capacity constraints and dynamic lead times. The proposed CF-based optimization model replaces MRP's backward scheduling step while preserving its overall structure. Performance is evaluated through simulation experiments on two flow shop systems: a compact three-level system with three shared resources (PS1) and a more complex four-stage system with 32 end items and 16 machines (PS2). The experiments explore a range of demand uncertainties and utilization levels. Results show that CF-based planning consistently reduces total costs and tardiness while improving schedule feasibility, particularly under imperfect forecasts. These findings demonstrate the potential of CFs to enhance MRP by introducing workload responsiveness and dynamic adaptability, without compromising computational tractability.",
      "authors": [
        "Wolfgang Seiringer",
        "Klaus Altendorfer",
        "Reha Uzsoy"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-24T12:09:14+00:00",
          "link": "https://arxiv.org/abs/2503.01862v1",
          "size": "2738kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T06:27:44+00:00",
          "link": "https://arxiv.org/abs/2503.01862v2",
          "size": "1657kb",
          "version": "v2"
        }
      ],
      "title": "Release Date Optimization Using Clearing Functions in MRP",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.01862",
        "PDF": "https://arxiv.org/pdf/2503.01862"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper is about optimizing release dates using clearing functions in MRP, dealing with planning and scheduling, not related to LLM training data processing or data engineering."
      },
      "tasks": [
        "Scheduling"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.02703",
      "abstract": "Graphical assets play an important role in the design and development of games. There is potential in the use of AI-driven generative tools, to aid in creating graphical assets, thus improving game design and development pipelines. However, there is little research to address how the generative methods can fit into the wider pipeline. There also no guidelines or heuristics for creating such tools. To address this gap we conducted a user study with 16 game designers and developers to examine their behaviour and interaction with generative tools for graphical assets. The findings highlight that early design stage is preferred by all participants. Designers and developers are inclined to use such tools for creating large amounts of variations at the cost of quality as they can improve the quality of the artefacts once they generate a suitable asset. The results also strongly raised the need for better integration of such tools in existing design and development environments and the need for the outputs to be in common data formats, to be manipulatable and smoothly integrate into existing environments. The study also highlights the requirement for further emphasis on the needs of the users to incorporate these tools effectively in existing pipelines. Informed by these results, we provide a set of heuristics for creating tools that meet the expectations and needs of game designers and developers.",
      "authors": [
        "Kaisei Fukaya",
        "Damon Daylamani-Zad",
        "Harry Agius"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-04T15:18:50+00:00",
          "link": "https://arxiv.org/abs/2503.02703v1",
          "size": "1266kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T16:11:20+00:00",
          "link": "https://arxiv.org/abs/2503.02703v2",
          "size": "860kb",
          "version": "v2"
        }
      ],
      "title": "Heuristics for AI-driven Graphical Asset Generation Tools in Game Design and Development Pipelines: A User-Centred Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.02703",
        "HTML": "https://arxiv.org/html/2503.02703v2",
        "PDF": "https://arxiv.org/pdf/2503.02703"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on AI-driven graphical asset generation tools in game design and development, not on LLM training data processing."
      },
      "tasks": [
        "Game Design"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.03313",
      "abstract": "Text-Attributed Graphs (TAGs), where each node is associated with text descriptions, are ubiquitous in real-world scenarios. They typically exhibit distinctive structure and domain-specific knowledge, motivating the development of a Graph Foundation Model (GFM) that generalizes across diverse graphs and tasks. Despite large efforts to integrate Large Language Models (LLMs) and Graph Neural Networks (GNNs) for TAGs, existing approaches suffer from decoupled architectures with two-stage alignment, limiting their synergistic potential. Even worse, existing methods assign out-of-vocabulary (OOV) tokens to graph nodes, leading to graph-specific semantics, token explosion, and incompatibility with task-oriented prompt templates, which hinders cross-graph and cross-task transferability. To address these challenges, we propose PromptGFM, a versatile GFM for TAGs grounded in graph vocabulary learning. PromptGFM comprises two key components: (1) Graph Understanding Module, which explicitly prompts LLMs to replicate the finest GNN workflow within the text space, facilitating seamless GNN-LLM integration and elegant graph-text alignment; (2) Graph Inference Module, which establishes a language-based graph vocabulary ensuring expressiveness, transferability, and scalability, enabling readable instructions for LLM fine-tuning. Extensive experiments demonstrate our superiority and transferability across diverse graphs and tasks. The code is available at this: https://github.com/agiresearch/PromptGFM.",
      "authors": [
        "Xi Zhu",
        "Haochen Xue",
        "Ziwei Zhao",
        "Wujiang Xu",
        "Jingyuan Huang",
        "Minghao Guo",
        "Qifan Wang",
        "Kaixiong Zhou",
        "Yongfeng Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-05T09:45:22+00:00",
          "link": "https://arxiv.org/abs/2503.03313v1",
          "size": "686kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T12:53:42+00:00",
          "link": "https://arxiv.org/abs/2503.03313v2",
          "size": "585kb",
          "version": "v2"
        }
      ],
      "title": "LLM as GNN: Graph Vocabulary Learning for Text-Attributed Graph Foundation Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.03313",
        "HTML": "https://arxiv.org/html/2503.03313v2",
        "PDF": "https://arxiv.org/pdf/2503.03313"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses integration of LLMs and GNNs for text-attributed graphs where LLM fine-tuning is involved, but it doesn't focus on processing or engineering LLM training data."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/agiresearch/promptgfm"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.03592",
      "abstract": "For consumer usage of locally deployed LLMs, the GGUF format and k\\_quantization are invaluable tools for maintaining the performance of the original model while reducing it to sizes deployable with consumer-grade hardware. The number of bits dedicated to each weight from the original model is reduced based on how important they are thought to be during model inference. This importance is arrived at through the application of an 'importance matrix'-a relatively small text document meant to be representative of the LLM's standard use-cases. In the vast majority of quants available online, this document is primarily written in English. It was therefore an open question whether performance on English language tasks was preserved through the sacrifice of multilingual performance and whether it can be preserved with alternate importance matrices. This article investigates these hypotheses by quantizing Llama3.3 70B on importance matrices written in three languages (English, Norwegian, and Malayalam) and evaluating them on the MixEval dataset in both English and Norwegian. All experiments related to yielded non-significant results indicating that current quantization practices do not disproportionately harm multilingual performance.",
      "authors": [
        "Karl Audun Borgersen",
        "Morten Goodwin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-05T15:26:59+00:00",
          "link": "https://arxiv.org/abs/2503.03592v1",
          "size": "894kb",
          "version": "v1"
        },
        {
          "date": "2025-03-10T07:36:46+00:00",
          "link": "https://arxiv.org/abs/2503.03592v2",
          "size": "1648kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T10:34:56+00:00",
          "link": "https://arxiv.org/abs/2503.03592v3",
          "size": "307kb",
          "version": "v3"
        }
      ],
      "title": "English K_Quantization of LLMs Does Not Disproportionately Diminish Multilingual Performance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.03592",
        "HTML": "https://arxiv.org/html/2503.03592v3",
        "PDF": "https://arxiv.org/pdf/2503.03592"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper examines multilingual performance of LLM quantization techniques but does not address any LLM training data processing tasks."
      },
      "tasks": [
        "Quantization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.04396",
      "abstract": "Tabular data are crucial in many fields and their understanding by large language models (LLMs) under high parameter efficiency paradigm is important. However, directly applying parameter-efficient fine-tuning (PEFT) techniques to tabular tasks presents significant challenges, particularly in terms of better table serialization and the representation of two-dimensional structured information within a one-dimensional sequence. To address this, we propose TableLoRA, a module designed to improve LLMs' understanding of table structure during PEFT. It incorporates special tokens for serializing tables with special token encoder and uses 2D LoRA to encode low-rank information on cell positions. Experiments on four tabular-related datasets demonstrate that TableLoRA consistently outperforms vanilla LoRA and surpasses various table encoding methods tested in control experiments. These findings reveal that TableLoRA, as a table-specific LoRA, enhances the ability of LLMs to process tabular data effectively, especially in low-parameter settings, demonstrating its potential as a robust solution for handling table-related tasks.",
      "authors": [
        "Xinyi He",
        "Yihao Liu",
        "Mengyu Zhou",
        "Yeye He",
        "Haoyu Dong",
        "Shi Han",
        "Zejian Yuan",
        "Dongmei Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-06T12:50:14+00:00",
          "link": "https://arxiv.org/abs/2503.04396v1",
          "size": "193kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T13:42:07+00:00",
          "link": "https://arxiv.org/abs/2503.04396v2",
          "size": "197kb",
          "version": "v2"
        }
      ],
      "title": "TableLoRA: Low-rank Adaptation on Table Structure Understanding for Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.04396",
        "HTML": "https://arxiv.org/html/2503.04396v2",
        "PDF": "https://arxiv.org/pdf/2503.04396"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes a method (TableLoRA) to enhance LLM understanding of tabular data through fine-tuning techniques but doesn't contribute directly to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.04412",
      "abstract": "Recent advances demonstrate that increasing inference-time computation can significantly boost the reasoning capabilities of large language models (LLMs). Although repeated sampling (i.e., generating multiple candidate outputs) is a highly effective strategy, it does not leverage external feedback signals for refinement, which are often available in tasks like coding. In this work, we propose Adaptive Branching Monte Carlo Tree Search (AB-MCTS), a novel inference-time framework that generalizes repeated sampling with principled multi-turn exploration and exploitation. At each node in the search tree, AB-MCTS dynamically decides whether to \"go wider\" by expanding new candidate responses or \"go deeper\" by revisiting existing ones based on external feedback signals. We evaluate our method on complex coding and engineering tasks using frontier models. Empirical results show that AB-MCTS consistently outperforms both repeated sampling and standard MCTS, underscoring the importance of combining the response diversity of LLMs with multi-turn solution refinement for effective inference-time scaling.",
      "authors": [
        "Yuichi Inoue",
        "Kou Misaki",
        "Yuki Imajuku",
        "So Kuroki",
        "Taishi Nakamura",
        "Takuya Akiba"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-06T13:10:40+00:00",
          "link": "https://arxiv.org/abs/2503.04412v1",
          "size": "348kb",
          "version": "v1"
        },
        {
          "date": "2025-06-12T07:31:56+00:00",
          "link": "https://arxiv.org/abs/2503.04412v2",
          "size": "2652kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T12:18:30+00:00",
          "link": "https://arxiv.org/abs/2503.04412v3",
          "size": "3786kb",
          "version": "v3"
        }
      ],
      "title": "Wider or Deeper? Scaling LLM Inference-Time Compute with Adaptive Branching Tree Search",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.04412",
        "HTML": "https://arxiv.org/html/2503.04412v3",
        "PDF": "https://arxiv.org/pdf/2503.04412"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on inference-time frameworks for LLMs and does not address training-stage data processing or data engineering tasks related to LLM training data preparation."
      },
      "tasks": [
        "Diversity"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.04908",
      "abstract": "This paper presents a novel dissipativity-based distributed droop-free control approach for voltage regulation and current sharing in DC microgrids (MGs) comprised of an interconnected set of distributed generators (DGs), loads, and power lines. First, we describe the closed-loop DC MG as a networked system where the DGs and lines (i.e., subsystems) are interconnected via a static interconnection matrix. This interconnection matrix demonstrates how the inputs, outputs, and disturbances of DGs and lines are connected in a DC MG. Each DG has a local controller and a distributed global controller. To design the controllers, we use the dissipativity properties of the subsystems and formulate a linear matrix inequality (LMI) problem. To support the feasibility of this problem, we identify a set of necessary local and global conditions to enforce in a specifically developed LMI-based local controller design process. In contrast to existing DC MG control solutions, our approach proposes a unified framework for co-designing the distributed controller and communication topology. As the co-design process is LMI-based, it can be efficiently implemented and evaluated using existing convex optimization tools. The effectiveness of the proposed solution is verified by simulating an islanded DC MG in a MATLAB/Simulink environment under different scenarios, such as load changes and topological constraint changes, and then comparing the performance with the droop control algorithm.",
      "authors": [
        "Mohammad Javad Najafirad",
        "Shirantha Welikala"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-06T19:08:12+00:00",
          "link": "https://arxiv.org/abs/2503.04908v1",
          "size": "2170kb",
          "version": "v1"
        },
        {
          "date": "2025-04-15T19:05:16+00:00",
          "link": "https://arxiv.org/abs/2503.04908v2",
          "size": "2179kb",
          "version": "v2"
        },
        {
          "date": "2025-06-26T20:52:15+00:00",
          "link": "https://arxiv.org/abs/2503.04908v3",
          "size": "1804kb",
          "version": "v3"
        }
      ],
      "title": "Dissipativity-Based Distributed Control and Communication Topology Co-Design for Voltage Regulation and Current Sharing in DC Microgrids",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.04908",
        "HTML": "https://arxiv.org/html/2503.04908v3",
        "PDF": "https://arxiv.org/pdf/2503.04908"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper is dedicated to voltage regulation and control in DC microgrids and does not involve any discussion on LLM training data processing or data engineering."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2503.08201",
      "abstract": "Human-centric visual perception (HVP) has recently achieved remarkable progress due to advancements in large-scale self-supervised pretraining (SSP). However, existing HVP models face limitations in adapting to real-world applications, which require general visual patterns for downstream tasks while maintaining computationally sustainable costs to ensure compatibility with edge devices. These limitations primarily arise from two issues: 1) the pretraining objectives focus solely on specific visual patterns, limiting the generalizability of the learned patterns for diverse downstream tasks; and 2) HVP models often exhibit excessively large model sizes, making them incompatible with real-world applications.To address these limitations, we introduce Scale-Aware Image Pretraining (SAIP), a novel SSP framework pretraining lightweight vision models to acquire general patterns for HVP. Specifically, SAIP incorporates three learning objectives based on the principle of cross-scale consistency: 1) Cross-scale Matching (CSM) which contrastively learns image-level invariant patterns from multi-scale single-person images; 2) Cross-scale Reconstruction (CSR) which learns pixel-level consistent visual structures from multi-scale masked single-person images; and 3) Cross-scale Search (CSS) which learns to capture diverse patterns from multi-scale multi-person images. Three objectives complement one another, enabling lightweight models to learn multi-scale generalizable patterns essential for HVP downstream tasks.Extensive experiments conducted across 12 HVP datasets demonstrate that SAIP exhibits remarkable generalization capabilities across 9 human-centric vision tasks. Moreover, it achieves significant performance improvements over existing methods, with gains of 3%-13% in single-person discrimination tasks, 1%-11% in dense prediction tasks, and 1%-6% in multi-person visual understanding tasks.",
      "authors": [
        "Xuanhan Wang",
        "Huimin Deng",
        "Lianli Gao",
        "Jingkuan Song"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-11T09:12:51+00:00",
          "link": "https://arxiv.org/abs/2503.08201v1",
          "size": "1281kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T11:01:48+00:00",
          "link": "https://arxiv.org/abs/2503.08201v2",
          "size": "1212kb",
          "version": "v2"
        }
      ],
      "title": "Scale-Aware Pre-Training for Human-Centric Visual Perception: Enabling Lightweight and Generalizable Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.08201",
        "HTML": "https://arxiv.org/html/2503.08201v2",
        "PDF": "https://arxiv.org/pdf/2503.08201"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses pretraining strategies for vision models, indirectly related to data processing through methods for enhancing models\u2019 generalizability. However, it does not focus on novel LLM data engineering processes."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.08740",
      "abstract": "This paper addresses the multi-robot pursuit problem for an unknown target, encompassing both target state estimation and pursuit control. First, in state estimation, we focus on using only bearing information, as it is readily available from vision sensors and effective for small, distant targets. Challenges such as instability due to the nonlinearity of bearing measurements and singularities in the two-angle representation are addressed through a proposed uniform bearing-only information filter. This filter integrates multiple 3D bearing measurements, provides a concise formulation, and enhances stability and resilience to target loss caused by limited field of view (FoV). Second, in target pursuit control within complex environments, where challenges such as heterogeneity and limited FoV arise, conventional methods like differential games or Voronoi partitioning often prove inadequate. To address these limitations, we propose a novel multiagent reinforcement learning (MARL) framework, enabling multiple heterogeneous vehicles to search, localize, and follow a target while effectively handling those challenges. Third, to bridge the sim-to-real gap, we propose two key techniques: incorporating adjustable low-level control gains in training to replicate the dynamics of real-world autonomous ground vehicles (AGVs), and proposing spectral-normalized RL algorithms to enhance policy smoothness and robustness. Finally, we demonstrate the successful zero-shot transfer of the MARL controllers to AGVs, validating the effectiveness and practical feasibility of our approach. The accompanying video is available at https://youtu.be/HO7FJyZiJ3E.",
      "authors": [
        "Jianan Li",
        "Zhikun Wang",
        "Susheng Ding",
        "Shiliang Guo",
        "Shiyu Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)",
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-11T08:21:35+00:00",
          "link": "https://arxiv.org/abs/2503.08740v1",
          "size": "715kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T03:24:09+00:00",
          "link": "https://arxiv.org/abs/2503.08740v2",
          "size": "715kb",
          "version": "v2"
        }
      ],
      "title": "Cooperative Bearing-Only Target Pursuit via Multiagent Reinforcement Learning: Design and Experiment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.08740",
        "HTML": "https://arxiv.org/html/2503.08740v2",
        "PDF": "https://arxiv.org/pdf/2503.08740"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The research revolves around multiagent reinforcement learning for target pursuit by robots, not covering LLM training data preparation or processing aspects."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.10386",
      "abstract": "We consider a good arm identification problem in a stochastic bandit setting with multi-objectives, where each arm $i \\in [K]$ is associated with a distribution $D_i$ defined over $R^M$. For each round $t$, the player pulls an arm $i_t$ and receives an $M$-dimensional reward vector sampled according to $D_{i_t}$. The goal is to find, with high probability, an $\\epsilon$-good arm whose expected reward vector is larger than $\\bm{\\xi} - \\epsilon \\mathbf{1}$, where $\\bm{\\xi}$ is a predefined threshold vector, and the vector comparison is component-wise. We propose the Multi-Thresholding UCB~(MultiTUCB) algorithm with a sample complexity bound. Our bound matches the existing one in the special case where $M=1$ and $\\epsilon=0$. The proposed algorithm demonstrates superior performance compared to baseline approaches across synthetic and real datasets.",
      "authors": [
        "Xuanke Jiang",
        "Sherief Hashima",
        "Kohei Hatano",
        "Eiji Takimoto"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-13T14:04:04+00:00",
          "link": "https://arxiv.org/abs/2503.10386v1",
          "size": "269kb",
          "version": "v1"
        },
        {
          "date": "2025-03-14T14:37:28+00:00",
          "link": "https://arxiv.org/abs/2503.10386v2",
          "size": "269kb",
          "version": "v2"
        },
        {
          "date": "2025-06-26T21:38:37+00:00",
          "link": "https://arxiv.org/abs/2503.10386v3",
          "size": "4160kb",
          "version": "v3"
        }
      ],
      "title": "Multi-thresholding Good Arm Identification with Bandit Feedback",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.10386",
        "HTML": "https://arxiv.org/html/2503.10386v3",
        "PDF": "https://arxiv.org/pdf/2503.10386"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on a stochastic bandit problem for multi-objective optimization with an algorithmic approach, but does not address LLM data processing or training data engineering."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/2015211217/MultiThresholdBandit"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.10432",
      "abstract": "In this paper, we propose BeamLLM, a vision-aided millimeter-wave (mmWave) beam prediction framework leveraging large language models (LLMs) to address the challenges of high training overhead and latency in mmWave communication systems. By combining computer vision (CV) with LLMs' cross-modal reasoning capabilities, the framework extracts user equipment (UE) positional features from RGB images and aligns visual-temporal features with LLMs' semantic space through reprogramming techniques. Evaluated on a realistic vehicle-to-infrastructure (V2I) scenario, the proposed method achieves 61.01% top-1 accuracy and 97.39% top-3 accuracy in standard prediction tasks, significantly outperforming traditional deep learning models. In few-shot prediction scenarios, the performance degradation is limited to 12.56% (top-1) and 5.55% (top-3) from time sample 1 to 10, demonstrating superior prediction capability.",
      "authors": [
        "Can Zheng",
        "Jiguang He",
        "Guofa Cai",
        "Zitong Yu",
        "Chung G. Kang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-13T14:55:59+00:00",
          "link": "https://arxiv.org/abs/2503.10432v1",
          "size": "3928kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T07:52:32+00:00",
          "link": "https://arxiv.org/abs/2503.10432v2",
          "size": "4804kb",
          "version": "v2"
        }
      ],
      "title": "BeamLLM: Vision-Empowered mmWave Beam Prediction with Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.10432",
        "HTML": "https://arxiv.org/html/2503.10432v2",
        "PDF": "https://arxiv.org/pdf/2503.10432"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the primary focus is on using LLMs for beam prediction in mmWave communication, there is an indirect mention of processing due to reprogramming techniques to align features with LLMs' semantic space, relevant to fine-tuning tasks."
      },
      "tasks": [
        "Beam Prediction",
        "Prediction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.12016",
      "abstract": "Large Language Models (LLMs) have demonstrated impressive success across various tasks. Integrating LLMs with Federated Learning (FL), a paradigm known as FedLLM, offers a promising avenue for collaborative model adaptation while preserving data privacy. This survey provides a systematic and comprehensive review of FedLLM. We begin by tracing the historical development of both LLMs and FL, summarizing relevant prior research to set the context. Subsequently, we delve into an in-depth analysis of the fundamental challenges inherent in deploying FedLLM. Addressing these challenges often requires efficient adaptation strategies; therefore, we conduct an extensive examination of existing Parameter-Efficient Fine-tuning (PEFT) methods and explore their applicability within the FL framework. To rigorously evaluate the performance of FedLLM, we undertake a thorough review of existing fine-tuning datasets and evaluation benchmarks. Furthermore, we discuss FedLLM's diverse real-world applications across multiple domains. Finally, we identify critical open challenges and outline promising research directions to foster future advancements in FedLLM. This survey aims to serve as a foundational resource for researchers and practitioners, offering valuable insights into the rapidly evolving landscape of federated fine-tuning for LLMs. It also establishes a roadmap for future innovations in privacy-preserving AI. We actively maintain a GitHub repo \\href{https://github.com/Clin0212/Awesome-Federated-LLM-Learning}{https://github.com/Clin0212/Awesome-Federated-LLM-Learning} to track cutting-edge advancements in this field.",
      "authors": [
        "Yebo Wu",
        "Chunlin Tian",
        "Jingguang Li",
        "He Sun",
        "Kahou Tam",
        "Zhanting Zhou",
        "Haicheng Liao",
        "Zhijiang Guo",
        "Li Li",
        "Chengzhong Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-15T06:52:10+00:00",
          "link": "https://arxiv.org/abs/2503.12016v1",
          "size": "1392kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T07:42:47+00:00",
          "link": "https://arxiv.org/abs/2503.12016v2",
          "size": "1275kb",
          "version": "v2"
        }
      ],
      "title": "A Survey on Federated Fine-tuning of Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.12016",
        "HTML": "https://arxiv.org/html/2503.12016v2",
        "PDF": "https://arxiv.org/pdf/2503.12016"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The survey reviews federated learning and fine-tuning for LLMs, including datasets and benchmarks, but it mainly synthesizes existing work without introducing new methodologies for data engineering or training-stage data processing."
      },
      "tasks": [
        "Federated Learning",
        "parameter-efficient fine-tuning",
        "Privacy Preserving",
        "Survey"
      ],
      "repo_urls": [
        "https://github.com/clin0212/awesome-federated-llm-learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.13310",
      "abstract": "Context: Generative Artificial Intelligence (GenAI) is transforming much of software development, yet its application in software architecture is still in its infancy, and no prior study has systematically addressed the topic. Aim: We aim to systematically synthesize the use, rationale, contexts, usability, and future challenges of GenAI in software architecture. Method: We performed a multivocal literature review (MLR), analyzing peer-reviewed and gray literature, identifying current practices, models, adoption contexts, and reported challenges, extracting themes via open coding. Results: Our review identified significant adoption of GenAI for architectural decision support and architectural reconstruction. OpenAI GPT models are predominantly applied, and there is consistent use of techniques such as few-shot prompting and retrieved-augmented generation (RAG). GenAI has been applied mostly to initial stages of the Software Development Life Cycle (SDLC), such as Requirements-to-Architecture and Architecture-to-Code. Monolithic and microservice architectures were the dominant targets. However, rigorous testing of GenAI outputs was typically missing from the studies. Among the most frequent challenges are model precision, hallucinations, ethical aspects, privacy issues, lack of architecture-specific datasets, and the absence of sound evaluation frameworks. Conclusions: GenAI shows significant potential in software design, but several challenges remain on its path to greater adoption. Research efforts should target designing general evaluation methodologies, handling ethics and precision, increasing transparency and explainability, and promoting architecture-specific datasets and benchmarks to bridge the gap between theoretical possibilities and practical use.",
      "authors": [
        "Matteo Esposito and Xiaozhou Li and Sergio Moreschini and Noman Ahmad and Tomas Cerny and Karthik Vaidhyanathan and Valentina Lenarduzzi and Davide Taibi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-17T15:49:30+00:00",
          "link": "https://arxiv.org/abs/2503.13310v1",
          "size": "1528kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T06:29:21+00:00",
          "link": "https://arxiv.org/abs/2503.13310v2",
          "size": "691kb",
          "version": "v2"
        }
      ],
      "title": "Generative AI for Software Architecture. Applications, Challenges, and Future Directions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.13310",
        "HTML": "https://arxiv.org/html/2503.13310v2",
        "PDF": "https://arxiv.org/pdf/2503.13310"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper discusses the application of generative AI in software architecture, focusing on model usage and challenges in adoption, not related to LLM training data processing or engineering tasks."
      },
      "tasks": [
        "Ethics",
        "RAG"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.15465",
      "abstract": "Diffusion Models (DM) have revolutionized the text-to-image visual generation process. However, the large computational cost and model footprint of DMs hinders practical deployment, especially on edge devices. Post-training quantization (PTQ) is a lightweight method to alleviate these burdens without the need for training or fine-tuning. While recent DM PTQ methods achieve W4A8 on integer-based PTQ, two key limitations remain: First, while most existing DM PTQ methods evaluate on classical DMs like Stable Diffusion XL, 1.5 or earlier, which use convolutional U-Nets, newer Diffusion Transformer (DiT) models like the PixArt series, Hunyuan and others adopt fundamentally different transformer backbones to achieve superior image synthesis. Second, integer (INT) quantization is prevailing in DM PTQ but doesn't align well with the network weight and activation distribution, while Floating-Point Quantization (FPQ) is still under-investigated, yet it holds the potential to better align the weight and activation distributions in low-bit settings for DiT. In response, we introduce FP4DiT, a PTQ method that leverages FPQ to achieve W4A6 quantization. Specifically, we extend and generalize the Adaptive Rounding PTQ technique to adequately calibrate weight quantization for FPQ and demonstrate that DiT activations depend on input patch data, necessitating robust online activation quantization techniques. Experimental results demonstrate that FP4DiT outperforms integer-based PTQ at W4A6 and W4A8 precision and generates convincing visual content on PixArt-$\\alpha$, PixArt-$\\Sigma$ and Hunyuan in terms of several T2I metrics such as HPSv2 and CLIP.",
      "authors": [
        "Ruichen Chen",
        "Keith G. Mills",
        "Di Niu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-19T17:44:21+00:00",
          "link": "https://arxiv.org/abs/2503.15465v1",
          "size": "48087kb",
          "version": "v1"
        },
        {
          "date": "2025-06-26T22:03:07+00:00",
          "link": "https://arxiv.org/abs/2503.15465v2",
          "size": "18991kb",
          "version": "v2"
        }
      ],
      "title": "FP4DiT: Towards Effective Floating Point Quantization for Diffusion Transformers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.15465",
        "HTML": "https://arxiv.org/html/2503.15465v2",
        "PDF": "https://arxiv.org/pdf/2503.15465"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper is centered around quantization techniques for Diffusion Transformers, aimed at reducing computational costs, unconnected to LLM training data processes or pipeline improvements."
      },
      "tasks": [
        "Image Generation",
        "Quantization"
      ],
      "repo_urls": [
        "https://github.com/cccrrrccc/fp4dit"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.15783",
      "abstract": "Game Description Generation (GDG) is the task of generating a game description written in a Game Description Language (GDL) from natural language text. Previous studies have explored generation methods leveraging the contextual understanding capabilities of Large Language Models (LLMs); however, accurately reproducing the game features of the game descriptions remains a challenge. In this paper, we propose reinforcement learning-based fine-tuning of LLMs for GDG (RLGDG). Our training method simultaneously improves grammatical correctness and fidelity to game concepts by introducing both grammar rewards and concept rewards. Furthermore, we adopt a two-stage training strategy where Reinforcement Learning (RL) is applied following Supervised Fine-Tuning (SFT). Experimental results demonstrate that our proposed method significantly outperforms baseline methods using SFT alone. Our code is available at https://github.com/tsunehiko/rlgdg",
      "authors": [
        "Tsunehiko Tanaka",
        "Edgar Simo-Serra"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-20T01:47:33+00:00",
          "link": "https://arxiv.org/abs/2503.15783v1",
          "size": "1289kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T03:31:44+00:00",
          "link": "https://arxiv.org/abs/2503.15783v2",
          "size": "1348kb",
          "version": "v2"
        }
      ],
      "title": "Grammar and Gameplay-aligned RL for Game Description Generation with LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.15783",
        "HTML": "https://arxiv.org/html/2503.15783v2",
        "PDF": "https://arxiv.org/pdf/2503.15783"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses reinforcement learning-based fine-tuning of LLMs for game description generation. It involves a two-stage training strategy that includes supervised fine-tuning, a type of training-stage data processing. However, it does not focus primarily on data engineering or novel data-related methods."
      },
      "tasks": [
        "reinforcement-learning",
        "Reinforcement Learning",
        "Reinforcement Learning (RL)"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.16069",
      "abstract": "To improve the prediction of cancer survival using whole-slide images and transcriptomics data, it is crucial to capture both modality-shared and modality-specific information. However, multimodal frameworks often entangle these representations, limiting interpretability and potentially suppressing discriminative features. To address this, we propose Disentangled and Interpretable Multimodal Attention Fusion (DIMAF), a multimodal framework that separates the intra- and inter-modal interactions within an attention-based fusion mechanism to learn distinct modality-specific and modality-shared representations. We introduce a loss based on Distance Correlation to promote disentanglement between these representations and integrate Shapley additive explanations to assess their relative contributions to survival prediction. We evaluate DIMAF on four public cancer survival datasets, achieving a relative average improvement of 1.85% in performance and 23.7% in disentanglement compared to current state-of-the-art multimodal models. Beyond improved performance, our interpretable framework enables a deeper exploration of the underlying interactions between and within modalities in cancer biology.",
      "authors": [
        "Aniek Eijpe",
        "Soufyan Lakbir",
        "Melis Erdal Cesur",
        "Sara P. Oliveira",
        "Sanne Abeln and Wilson Silva"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-20T12:02:10+00:00",
          "link": "https://arxiv.org/abs/2503.16069v1",
          "size": "2363kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T08:35:13+00:00",
          "link": "https://arxiv.org/abs/2503.16069v2",
          "size": "2363kb",
          "version": "v2"
        }
      ],
      "title": "Disentangled and Interpretable Multimodal Attention Fusion for Cancer Survival Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.16069",
        "HTML": "https://arxiv.org/html/2503.16069v2",
        "PDF": "https://arxiv.org/pdf/2503.16069"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The focus of this paper is on improving cancer survival prediction through a framework for disentangled multimodal attention fusion. It does not address any aspect of LLM training data collection, construction, or processing."
      },
      "tasks": [
        "Disentanglement",
        "Survival Prediction",
        "whole slide images"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.16856",
      "abstract": "Fully comprehending scientific papers by machines reflects a high level of Artificial General Intelligence, requiring the ability to reason across fragmented and heterogeneous sources of information, presenting a complex and practically significant challenge. While Vision-Language Models (VLMs) have made remarkable strides in various tasks, particularly those involving reasoning with evidence source from single image or text page, their ability to use cross-source information for reasoning remains an open problem. This work presents MMCR, a high-difficulty benchmark designed to evaluate VLMs' capacity for reasoning with cross-source information from scientific papers. The benchmark comprises 276 high-quality questions, meticulously annotated by humans across 7 subjects and 10 task types. Experiments with 18 VLMs demonstrate that cross-source reasoning presents a substantial challenge for existing models. Notably, even the top-performing model, GPT-4o, achieved only 48.55% overall accuracy, with only 20% accuracy in multi-table comprehension tasks, while the second-best model, Qwen2.5-VL-72B, reached 39.86% overall accuracy. Furthermore, we investigated the impact of the Chain-of-Thought (CoT) technique on cross-source reasoning and observed a detrimental effect on small models, whereas larger models demonstrated substantially enhanced performance. These results highlight the pressing need to develop VLMs capable of effectively utilizing cross-source information for reasoning.",
      "authors": [
        "Yang Tian",
        "Zheng Lu",
        "Mingqi Gao",
        "Zheng Liu",
        "Bo Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-21T05:02:20+00:00",
          "link": "https://arxiv.org/abs/2503.16856v1",
          "size": "3412kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T01:14:07+00:00",
          "link": "https://arxiv.org/abs/2503.16856v2",
          "size": "19817kb",
          "version": "v2"
        }
      ],
      "title": "MMCR: Benchmarking Cross-Source Reasoning in Scientific Papers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.16856",
        "HTML": "https://arxiv.org/html/2503.16856v2",
        "PDF": "https://arxiv.org/pdf/2503.16856"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper introduces a benchmark for cross-source reasoning in scientific papers using vision-language models. It does not address LLM training data processing or related data engineering tasks."
      },
      "datasets": [
        {
          "dataset_name": "bbbeer/MMCR",
          "downloads": "71",
          "likes": "0",
          "link": "https://huggingface.co/datasets/bbbeer/MMCR"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.17966",
      "abstract": "Remote Sensing Image Dehazing (RSID) poses significant challenges in real-world scenarios due to the complex atmospheric conditions and severe color distortions that degrade image quality. The scarcity of real-world remote sensing hazy image pairs has compelled existing methods to rely primarily on synthetic datasets. However, these methods struggle with real-world applications due to the inherent domain gap between synthetic and real data. To address this, we introduce Real-World Remote Sensing Hazy Image Dataset (RRSHID), the first large-scale dataset featuring real-world hazy and dehazed image pairs across diverse atmospheric conditions. Based on this, we propose MCAF-Net, a novel framework tailored for real-world RSID. Its effectiveness arises from three innovative components: Multi-branch Feature Integration Block Aggregator (MFIBA), which enables robust feature extraction through cascaded integration blocks and parallel multi-branch processing; Color-Calibrated Self-Supervised Attention Module (CSAM), which mitigates complex color distortions via self-supervised learning and attention-guided refinement; and Multi-Scale Feature Adaptive Fusion Module (MFAFM), which integrates features effectively while preserving local details and global context. Extensive experiments validate that MCAF-Net demonstrates state-of-the-art performance in real-world RSID, while maintaining competitive performance on synthetic datasets. The introduction of RRSHID and MCAF-Net sets new benchmarks for real-world RSID research, advancing practical solutions for this complex task. The code and dataset are publicly available at https://github.com/lwCVer/RRSHID.",
      "authors": [
        "Zeng-Hui Zhu",
        "Wei Lu",
        "Si-Bao Chen",
        "Chris H. Q. Ding",
        "Jin Tang",
        "and Bin Luo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-23T07:15:46+00:00",
          "link": "https://arxiv.org/abs/2503.17966v1",
          "size": "4450kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T09:31:05+00:00",
          "link": "https://arxiv.org/abs/2503.17966v2",
          "size": "15602kb",
          "version": "v2"
        }
      ],
      "title": "Real-World Remote Sensing Image Dehazing: Benchmark and Baseline",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.17966",
        "HTML": "https://arxiv.org/html/2503.17966v2",
        "PDF": "https://arxiv.org/pdf/2503.17966"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper proposes a dataset and novel framework for remote sensing image dehazing, focusing on real-world scenarios. It does not involve LLM training data processing or data engineering."
      },
      "tasks": [
        "Image Dehazing",
        "Self-Supervised Learning"
      ],
      "repo_urls": [
        "https://github.com/lwcver/rrshid"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.19185",
      "abstract": "In this paper, we investigate the use of single hidden-layer neural networks as a family of ansatz functions for the resolution of partial differential equations (PDEs). In particular, we train the network via Extreme Learning Machines (ELMs) on the residual of the equation collocated on -- eventually randomly chosen -- points. Because the approximation is done directly in the formulation, such a method falls into the framework of Physically Informed Neural Networks (PINNs) and has been named PIELM. Since its first introduction, the method has been refined variously, and one successful variant is the Extreme Theory of Functional Connections (XTFC). However, XTFC strongly takes advantage of the description of the domain as a tensor product. Our aim is to extend XTFC to domains with general shapes. The novelty of the procedure proposed in the present paper is related to the treatment of boundary conditions via constrained imposition, so that our method is named Least Squares with Equality constraints ELM (LSEELM). An in-depth analysis and comparison with the cited methods is performed, again with the analysis of the convergence of the method in various scenarios. We show the efficiency of the procedure both in terms of computational cost and in terms of overall accuracy.",
      "authors": [
        "Davide Elia De Falco",
        "Enrico Schiassi",
        "Francesco Calabr\\`o"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-24T22:22:24+00:00",
          "link": "https://arxiv.org/abs/2503.19185v1",
          "size": "17231kb",
          "version": "v1"
        },
        {
          "date": "2025-04-17T13:46:26+00:00",
          "link": "https://arxiv.org/abs/2503.19185v2",
          "size": "4628kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T10:40:51+00:00",
          "link": "https://arxiv.org/abs/2503.19185v3",
          "size": "4741kb",
          "version": "v3"
        }
      ],
      "title": "Least Squares with Equality constraints Extreme Learning Machines for the resolution of PDEs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.19185",
        "HTML": "https://arxiv.org/html/2503.19185v3",
        "PDF": "https://arxiv.org/pdf/2503.19185"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper investigates using neural networks for solving partial differential equations, focusing on the methodology rather than any aspect of LLM data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.19367",
      "abstract": "Multimodal learning combining pathology images and genomic sequences enhances cancer survival analysis but faces clinical implementation barriers due to limited access to genomic sequencing in under-resourced regions. To enable survival prediction using only whole-slide images (WSI), we propose the Visual-Genomic Answering-Guided Transformer (VGAT), a framework integrating Visual Question Answering (VQA) techniques for genomic modality reconstruction. By adapting VQA's text feature extraction approach, we derive stable genomic representations that circumvent dimensionality challenges in raw genomic data. Simultaneously, a cluster-based visual prompt module selectively enhances discriminative WSI patches, addressing noise from unfiltered image regions. Evaluated across five TCGA datasets, VGAT outperforms existing WSI-only methods, demonstrating the viability of genomic-informed inference without sequencing. This approach bridges multimodal research and clinical feasibility in resource-constrained settings. The code link is https://github.com/CZZZZZZZZZZZZZZZZZ/VGAT.",
      "authors": [
        "Zizhi Chen",
        "Minghao Han",
        "Xukun Zhang",
        "Shuwei Ma",
        "Tao Liu",
        "Xing Wei",
        "Lihua Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-25T05:48:31+00:00",
          "link": "https://arxiv.org/abs/2503.19367v1",
          "size": "4874kb",
          "version": "v1"
        },
        {
          "date": "2025-03-29T12:05:53+00:00",
          "link": "https://arxiv.org/abs/2503.19367v2",
          "size": "4874kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T10:09:46+00:00",
          "link": "https://arxiv.org/abs/2503.19367v3",
          "size": "4874kb",
          "version": "v3"
        }
      ],
      "title": "VGAT: A Cancer Survival Analysis Framework Transitioning from Generative Visual Question Answering to Genomic Reconstruction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.19367",
        "HTML": "https://arxiv.org/html/2503.19367v3",
        "PDF": "https://arxiv.org/pdf/2503.19367"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on cancer survival analysis using pathology images and genomic data, specifically addressing clinical feasibility and genomic reconstruction. It does not discuss any aspects of LLM training data processing."
      },
      "tasks": [
        "Generative Visual Question Answering",
        "Question Answering",
        "Survival Analysis",
        "Survival Prediction",
        "Visual Question Answering",
        "Visual Question Answering (VQA)",
        "whole slide images"
      ],
      "repo_urls": [
        "https://github.com/czzzzzzzzzzzzzzzzz/vgat"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.20362",
      "abstract": "Large Vision-Language Models (LVLMs) demonstrate remarkable performance in short-video tasks such as video question answering, but struggle in long-video understanding. The linear frame sampling strategy, conventionally used by LVLMs, fails to account for the non-linear distribution of key events in video data, often introducing redundant or irrelevant information in longer contexts while risking the omission of critical events in shorter ones. To address this, we propose SelfReS, a non-linear spatiotemporal self-reflective sampling method that dynamically selects key video fragments based on user prompts. Unlike prior approaches, SelfReS leverages the inherently sparse attention maps of LVLMs to define reflection tokens, enabling relevance-aware token selection without requiring additional training or external modules. Experiments demonstrate that SelfReS can be seamlessly integrated into strong base LVLMs, improving long-video task accuracy and achieving up to 46% faster inference speed within the same GPU memory budget.",
      "authors": [
        "Joao Pereira",
        "Vasco Lopes",
        "David Semedo",
        "Joao Neves"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-26T09:39:58+00:00",
          "link": "https://arxiv.org/abs/2503.20362v1",
          "size": "1949kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T11:25:29+00:00",
          "link": "https://arxiv.org/abs/2503.20362v2",
          "size": "2730kb",
          "version": "v2"
        }
      ],
      "title": "Self-ReS: Self-Reflection in Large Vision-Language Models for Long Video Understanding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.20362",
        "HTML": "https://arxiv.org/html/2503.20362v2",
        "PDF": "https://arxiv.org/pdf/2503.20362"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper discusses video understanding in large vision-language models and proposes a method for frame sampling. It does not involve processing of training data for LLMs."
      },
      "tasks": [
        "Question Answering",
        "Video Question Answering",
        "Video Understanding"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.22605",
      "abstract": "Talking head synthesis has emerged as a prominent research topic in computer graphics and multimedia, yet most existing methods often struggle to strike a balance between generation quality and computational efficiency, particularly under real-time constraints. In this paper, we propose a novel framework that integrates Gaussian Splatting with a structured Audio Factorization Plane (Audio-Plane) to enable high-quality, audio-synchronized, and real-time talking head generation. For modeling a dynamic talking head, a 4D volume representation, which consists of three axes in 3D space and one temporal axis aligned with audio progression, is typically required. However, directly storing and processing a dense 4D grid is impractical due to the high memory and computation cost, and lack of scalability for longer durations. We address this challenge by decomposing the 4D volume representation into a set of audio-independent spatial planes and audio-dependent planes, forming a compact and interpretable representation for talking head modeling that we refer to as the Audio-Plane. This factorized design allows for efficient and fine-grained audio-aware spatial encoding, and significantly enhances the model's ability to capture complex lip dynamics driven by speech signals. To further improve region-specific motion modeling, we introduce an audio-guided saliency splatting mechanism based on region-aware modulation, which adaptively emphasizes highly dynamic regions such as the mouth area. This allows the model to focus its learning capacity on where it matters most for accurate speech-driven animation. Extensive experiments on both the self-driven and the cross-driven settings demonstrate that our method achieves state-of-the-art visual quality, precise audio-lip synchronization, and real-time performance, outperforming prior approaches across both 2D- and 3D-based paradigms.",
      "authors": [
        "Shuai Shen",
        "Wanhua Li",
        "Yunpeng Zhang",
        "Yap-Peng Tan",
        "Jiwen Lu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-28T16:50:27+00:00",
          "link": "https://arxiv.org/abs/2503.22605v1",
          "size": "5190kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T02:42:26+00:00",
          "link": "https://arxiv.org/abs/2503.22605v2",
          "size": "9264kb",
          "version": "v2"
        }
      ],
      "title": "Audio-Plane: Audio Factorization Plane Gaussian Splatting for Real-Time Talking Head Synthesis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.22605",
        "HTML": "https://arxiv.org/html/2503.22605v2",
        "PDF": "https://arxiv.org/pdf/2503.22605"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper is about talking head synthesis using Gaussian Splatting and audio factorization, focusing on multimedia applications. It is unrelated to the processing of training data for LLMs."
      },
      "tasks": [
        "Computational Efficiency",
        "Talking Head Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.23167",
      "abstract": "Graph Neural Networks (GNNs) and differential equations (DEs) are two rapidly advancing areas of research that have shown remarkable synergy in recent years. GNNs have emerged as powerful tools for learning on graph-structured data, while differential equations provide a principled framework for modeling continuous dynamics across time and space. The intersection of these fields has led to innovative approaches that leverage the strengths of both, enabling applications in physics-informed learning, spatiotemporal modeling, and scientific computing. This survey aims to provide a comprehensive overview of the burgeoning research at the intersection of GNNs and DEs. We will categorize existing methods, discuss their underlying principles, and highlight their applications across domains such as molecular modeling, traffic prediction, and epidemic spreading. Furthermore, we identify open challenges and outline future research directions to advance this interdisciplinary field. A comprehensive paper list is provided at https://github.com/Emory-Melody/Awesome-Graph-NDEs. This survey serves as a resource for researchers and practitioners seeking to understand and contribute to the fusion of GNNs and DEs",
      "authors": [
        "Zewen Liu",
        "Xiaoda Wang",
        "Bohan Wang",
        "Zijie Huang",
        "Carl Yang",
        "Wei Jin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-29T17:49:34+00:00",
          "link": "https://arxiv.org/abs/2503.23167v1",
          "size": "2187kb",
          "version": "v1"
        },
        {
          "date": "2025-04-13T18:48:24+00:00",
          "link": "https://arxiv.org/abs/2503.23167v2",
          "size": "2187kb",
          "version": "v2"
        },
        {
          "date": "2025-06-26T21:41:14+00:00",
          "link": "https://arxiv.org/abs/2503.23167v3",
          "size": "2188kb",
          "version": "v3"
        }
      ],
      "title": "Graph ODEs and Beyond: A Comprehensive Survey on Integrating Differential Equations with Graph Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.23167",
        "HTML": "https://arxiv.org/html/2503.23167v3",
        "PDF": "https://arxiv.org/pdf/2503.23167"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This survey discusses the integration of graph neural networks and differential equations, without any focus on LLM training data processing or data engineering tasks relevant to LLMs."
      },
      "tasks": [
        "Survey",
        "Traffic Prediction"
      ],
      "repo_urls": [
        "https://github.com/emory-melody/awesome-graph-ndes"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.23359",
      "abstract": "Compared to images, videos better align with real-world acquisition scenarios and possess valuable temporal cues. However, existing multi-sensor fusion research predominantly integrates complementary context from multiple images rather than videos. This primarily stems from two factors: 1) the scarcity of large-scale multi-sensor video datasets, limiting research in video fusion, and 2) the inherent difficulty of jointly modeling spatial and temporal dependencies in a unified framework. This paper proactively compensates for the dilemmas. First, we construct M3SVD, a benchmark dataset with $220$ temporally synchronized and spatially registered infrared-visible video pairs comprising 153,797 frames, filling the data gap for the video fusion community. Secondly, we propose VideoFusion, a multi-modal video fusion model that fully exploits cross-modal complementarity and temporal dynamics to generate spatio-temporally coherent videos from (potentially degraded) multi-modal inputs. Specifically, 1) a differential reinforcement module is developed for cross-modal information interaction and enhancement, 2) a complete modality-guided fusion strategy is employed to adaptively integrate multi-modal features, and 3) a bi-temporal co-attention mechanism is devised to dynamically aggregate forward-backward temporal contexts to reinforce cross-frame feature representations. Extensive experiments reveal that VideoFusion outperforms existing image-oriented fusion paradigms in sequential scenarios, effectively mitigating temporal inconsistency and interference.",
      "authors": [
        "Linfeng Tang",
        "Yeda Wang",
        "Meiqi Gong",
        "Zizhuo Li",
        "Yuxin Deng",
        "Xunpeng Yi",
        "Chunyu Li",
        "Han Xu",
        "Hao Zhang",
        "Jiayi Ma"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-30T08:27:18+00:00",
          "link": "https://arxiv.org/abs/2503.23359v1",
          "size": "14205kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T11:59:17+00:00",
          "link": "https://arxiv.org/abs/2503.23359v2",
          "size": "13510kb",
          "version": "v2"
        }
      ],
      "title": "VideoFusion: A Spatio-Temporal Collaborative Network for Multi-modal Video Fusion and Restoration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.23359",
        "HTML": "https://arxiv.org/html/2503.23359v2",
        "PDF": "https://arxiv.org/pdf/2503.23359"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper addresses multi-modal video fusion and restoration, focusing on constructing a benchmark dataset and a video fusion model, which do not relate to LLM training data processing or data engineering."
      },
      "tasks": [
        "Sensor Fusion"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.23905",
      "abstract": "MLLM reasoning has drawn widespread research for its excellent problem-solving capability. Current reasoning methods fall into two types: PRM, which supervises the intermediate reasoning steps, and ORM, which supervises the final results. Recently, DeepSeek-R1 has challenged the traditional view that PRM outperforms ORM, which demonstrates strong generalization performance using an ORM method (i.e., GRPO). However, current MLLM's GRPO algorithms still struggle to handle challenging and complex multimodal reasoning tasks (e.g., mathematical reasoning). In this work, we reveal two problems that impede the performance of GRPO on the MLLM: Low data utilization and Text-bias. Low data utilization refers to that GRPO cannot acquire positive rewards to update the MLLM on difficult samples, and text-bias is a phenomenon that the MLLM bypasses image condition and solely relies on text condition for generation after GRPO training. To tackle these problems, this work proposes Hint-GRPO that improves data utilization by adaptively providing hints for samples of varying difficulty, and text-bias calibration that mitigates text-bias by calibrating the token prediction logits with image condition in test-time. Experiment results on three base MLLMs across eleven datasets demonstrate that our proposed methods advance the reasoning capability of original MLLM by a large margin, exhibiting superior performance to existing MLLM reasoning methods. Our code is available at https://github.com/hqhQAQ/Hint-GRPO.",
      "authors": [
        "Qihan Huang",
        "Weilong Dai",
        "Jinlong Liu",
        "Wanggui He",
        "Hao Jiang",
        "Mingli Song",
        "Jingyuan Chen",
        "Chang Yao",
        "Jie Song"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-31T09:54:55+00:00",
          "link": "https://arxiv.org/abs/2503.23905v1",
          "size": "2317kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T14:37:02+00:00",
          "link": "https://arxiv.org/abs/2503.23905v2",
          "size": "1143kb",
          "version": "v2"
        }
      ],
      "title": "Boosting MLLM Reasoning with Text-Debiased Hint-GRPO",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.23905",
        "HTML": "https://arxiv.org/html/2503.23905v2",
        "PDF": "https://arxiv.org/pdf/2503.23905"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The focus is on improving MLLM reasoning through new methods for data utilization and text-bias calibration, which does not involve LLM training data processing or data engineering tasks."
      },
      "tasks": [
        "Mathematical Reasoning",
        "Multimodal Reasoning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.00521",
      "abstract": "Atomicity violations in interrupt-driven programs pose a significant threat to software safety in critical systems. These violations occur when the execution sequence of operations on shared resources is disrupted by asynchronous interrupts. Detecting atomicity violations is challenging due to the vast program state space, application-level code dependencies, and complex domain-specific knowledge. We propose Clover, a hybrid framework that integrates static analysis with large language model (LLM) agents to detect atomicity violations in real-world programs. Clover first performs static analysis to extract critical code snippets and operation information. It then initiates a multi-agent process, where the expert agent leverages domain-specific knowledge to detect atomicity violations, which are subsequently validated by the judge agent. Evaluations on RaceBench 2.1, SV-COMP, and RWIP demonstrate that Clover achieves a precision/recall of 92.3%/86.6%, outperforming existing approaches by 27.4-118.2% on F1-score.",
      "authors": [
        "Hang He",
        "Yixing Luo",
        "Chengcheng Wan",
        "Ting Su",
        "Haiying Sun",
        "Geguang Pu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-01T08:13:29+00:00",
          "link": "https://arxiv.org/abs/2504.00521v1",
          "size": "793kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T15:19:29+00:00",
          "link": "https://arxiv.org/abs/2504.00521v2",
          "size": "793kb",
          "version": "v2"
        }
      ],
      "title": "Automated detection of atomicity violations in large-scale systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.00521",
        "HTML": "https://arxiv.org/html/2504.00521v2",
        "PDF": "https://arxiv.org/pdf/2504.00521"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper introduces Clover for detecting atomicity violations in programs using static analysis and LLM agents, without addressing LLM training data processing or data engineering tasks."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Large Language Model"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.02611",
      "abstract": "Imprecise measurements of a point set P = (p1, ..., pn) can be modelled by a family of regions F = (R1, ..., Rn), where each imprecise region Ri contains a unique point pi. A retrieval models an accurate measurement by replacing an imprecise region Ri with its corresponding point pi. We construct the convex hull of an imprecise point set in the plane, where regions in F may be retrieved at unit cost. The goal is to determine the cyclic ordering of the convex hull vertices of P as efficiently as possible. Here, efficiency is interpreted in two ways: (i) minimising the number of retrievals, and (ii) computing each retrieval location quickly.\n  Prior works focused on only one of these two aspects: either minimising retrievals or optimising algorithmic runtime. Our contribution is the first to simultaneously achieve both. Let r(F, P) denote the minimal number of retrievals required by any algorithm to determine the convex hull of P for a given instance (F, P). For a family F of n constant-complexity polygons, our main result is a reconstruction algorithm that performs O(r(F, P)) retrievals in O(r(F, P) log^3 n) time.\n  Compared to previous approaches that achieve optimal retrieval counts, we improve the runtime per retrieval by a exponential factor, from polynomial to polylogarithmic. Compared to near-linear time algorithms, we significantly reduce the number of retrievals used, and broaden the input families to include overlapping regions. We further extend our results to simple k-gons and to pairwise disjoint disks with radii in [1,k], where our runtime scales linearly with k.",
      "authors": [
        "Sarita de Berg",
        "Ivor van der Hoog",
        "Eva Rotenberg",
        "Daniel Rutschmann",
        "Sampson Wong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Geometry (cs.CG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-03T14:12:36+00:00",
          "link": "https://arxiv.org/abs/2504.02611v1",
          "size": "946kb",
          "version": "v1"
        },
        {
          "date": "2025-05-29T08:39:40+00:00",
          "link": "https://arxiv.org/abs/2504.02611v2",
          "size": "825kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T00:50:27+00:00",
          "link": "https://arxiv.org/abs/2504.02611v3",
          "size": "825kb",
          "version": "v3"
        }
      ],
      "title": "Instance-Optimal Imprecise Convex Hull",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.02611",
        "HTML": "https://arxiv.org/html/2504.02611v3",
        "PDF": "https://arxiv.org/pdf/2504.02611"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper discusses convex hull construction from imprecise point sets, focusing on algorithmic techniques for minimizing retrievals and optimizing runtime. It does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.03583",
      "abstract": "In graph signal processing, learning the weighted connections between nodes from a set of sample signals is a fundamental task when the underlying relationships are not known a priori. This task is typically addressed by finding a graph Laplacian on which the observed signals are smooth. With the extension of graphs to hypergraphs - where edges can connect more than two nodes - graph learning methods have similarly been generalized to hypergraphs. However, the absence of a unified framework for calculating total variation has led to divergent definitions of smoothness and, consequently, differing approaches to hyperedge recovery. We confront this challenge through generalization of several previously proposed hypergraph total variations, subsequently allowing ease of substitution into a vector based optimization. To this end, we propose a novel hypergraph learning method that recovers a hypergraph topology from time-series signals based on a smoothness prior. Our approach, designated as Hypergraph Structure Learning with Smoothness (HSLS), addresses key limitations in prior works, such as hyperedge selection and convergence issues, by formulating the problem as a convex optimization solved via a forward-backward-forward algorithm, ensuring guaranteed convergence. Additionally, we introduce a process that simultaneously limits the span of the hyperedge search and maintains a valid hyperedge selection set. In doing so, our method becomes scalable in increasingly complex network structures. The experimental results demonstrate improved performance, in terms of accuracy, over other state-of-the-art hypergraph inference methods; furthermore, we empirically show our method to be robust to total variation terms, biased towards global smoothness, and scalable to larger hypergraphs.",
      "authors": [
        "Benjamin T. Brown",
        "Haoxiang Zhang",
        "Daniel L. Lau",
        "Gonzalo R. Arce"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-04T16:47:30+00:00",
          "link": "https://arxiv.org/abs/2504.03583v1",
          "size": "2120kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T15:58:19+00:00",
          "link": "https://arxiv.org/abs/2504.03583v2",
          "size": "3249kb",
          "version": "v2"
        }
      ],
      "title": "Scalable Hypergraph Structure Learning with Diverse Smoothness Priors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.03583",
        "HTML": "https://arxiv.org/html/2504.03583v2",
        "PDF": "https://arxiv.org/pdf/2504.03583"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper addresses hypergraph structure learning with smoothness priors and does not cover training data collection or processing for LLMs."
      },
      "tasks": [
        "Graph Learning"
      ],
      "repo_urls": [
        "https://github.com/Ben-Brown-Code/Scalable-Hypergraph-Structure-Learning-with-Diverse-Smoothness-Priors"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.03802",
      "abstract": "The increasing adoption of UAVs with advanced sensors and GPU-accelerated edge computing has enabled real-time AI-driven applications in fields such as precision agriculture, wildfire monitoring, and environmental conservation. However, integrating deep learning on UAVs remains challenging due to platform heterogeneity, real-time constraints, and the need for seamless cloud-edge coordination. To address these challenges, we introduce AeroDaaS, a service-oriented framework that abstracts UAV-based sensing complexities and provides a Drone-as-a-Service (DaaS) model for intelligent decision-making. AeroDaaS offers modular service primitives for on-demand UAV sensing, navigation, and analytics as composable microservices, ensuring cross-platform compatibility and scalability across heterogeneous UAV and edge-cloud infrastructures. We implement and evaluate a preliminary version of AeroDaaS for two real-world DaaS applications. We require <=40 lines of code for the applications and see minimal platform overhead of <=20 ms per frame and <=0.5 GB memory usage on Orin Nano. These early results are promising for AeroDaaS as an efficient, flexible and scalable UAV programming framework for autonomous aerial analytics.",
      "authors": [
        "Suman Raj",
        "Rajdeep Singh",
        "Kautuk Astu and Yogesh Simmhan"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-04T08:51:36+00:00",
          "link": "https://arxiv.org/abs/2504.03802v1",
          "size": "6276kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T05:30:37+00:00",
          "link": "https://arxiv.org/abs/2504.03802v2",
          "size": "5529kb",
          "version": "v2"
        }
      ],
      "title": "AeroDaaS: Towards an Application Programming Framework for Drones-as-a-Service",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.03802",
        "HTML": "https://arxiv.org/html/2504.03802v2",
        "PDF": "https://arxiv.org/pdf/2504.03802"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper introduces a framework for drones-as-a-service (DaaS) for real-time, AI-driven UAV applications. It does not discuss LLM training data or related processing tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.04320",
      "abstract": "Causal inference is often portrayed as fundamentally distinct from predictive modeling, with its own terminology, goals, and intellectual challenges. But at its core, causal inference is simply a structured instance of prediction under distribution shift. In both cases, we begin with labeled data from a source domain and seek to generalize to a target domain where outcomes are not observed. The key difference is that in causal inference, the labels -- potential outcomes -- are selectively observed based on treatment assignment, introducing bias that must be addressed through assumptions. This perspective reframes causal estimation as a familiar generalization problem and highlights how techniques from predictive modeling, such as reweighting and domain adaptation, apply directly to causal tasks. It also clarifies that causal assumptions are not uniquely strong -- they are simply more explicit. By viewing causal inference through the lens of prediction, we demystify its logic, connect it to familiar tools, and make it more accessible to practitioners and educators alike.",
      "authors": [
        "Carlos Fern\\'andez-Lor\\'ia"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Methodology (stat.ME)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-06T01:37:50+00:00",
          "link": "https://arxiv.org/abs/2504.04320v1",
          "size": "1082kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T05:38:26+00:00",
          "link": "https://arxiv.org/abs/2504.04320v2",
          "size": "526kb",
          "version": "v2"
        }
      ],
      "title": "Causal Inference Isn't Special: Why It's Just Another Prediction Problem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.04320",
        "HTML": "https://arxiv.org/html/2504.04320v2",
        "PDF": "https://arxiv.org/pdf/2504.04320"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper primarily discusses causal inference and prediction modeling, with no mention of LLM training data processing or data engineering for LLMs."
      },
      "tasks": [
        "Causal Inference",
        "Domain Adaptation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.04466",
      "abstract": "Loops--short audio segments designed for seamless repetition--are central to many music genres, particularly those rooted in dance and electronic styles. However, current generative music models struggle to produce truly loopable audio, as generating a short waveform alone does not guarantee a smooth transition from its endpoint back to its start, often resulting in audible discontinuities. We address this gap by modifying a non-autoregressive model (MAGNeT) to generate tokens in a circular pattern, letting the model attend to the beginning of the audio when creating its ending. This inference-only approach results in generations that are aware of future context and loop naturally, without the need for any additional training or data. We evaluate the consistency of loop transitions by computing token perplexity around the seam of the loop, observing a 55% improvement. Blind listening tests further confirm significant perceptual gains over baseline methods, improving mean ratings by 70%. Taken together, these results highlight the effectiveness of inference-only approaches in improving generative models and underscore the advantages of non-autoregressive methods for context-aware music generation.",
      "authors": [
        "Davide Marincione",
        "Giorgio Strano",
        "Donato Crisostomi",
        "Roberto Ribuoli",
        "Emanuele Rodol\\`a"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-06T12:34:23+00:00",
          "link": "https://arxiv.org/abs/2504.04466v1",
          "size": "1046kb",
          "version": "v1"
        },
        {
          "date": "2025-04-08T06:13:10+00:00",
          "link": "https://arxiv.org/abs/2504.04466v2",
          "size": "1046kb",
          "version": "v2"
        },
        {
          "date": "2025-05-24T12:14:25+00:00",
          "link": "https://arxiv.org/abs/2504.04466v3",
          "size": "1046kb",
          "version": "v3"
        },
        {
          "date": "2025-06-27T16:34:00+00:00",
          "link": "https://arxiv.org/abs/2504.04466v4",
          "size": "759kb",
          "version": "v4"
        }
      ],
      "title": "LoopGen: Training-Free Loopable Music Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.04466",
        "HTML": "https://arxiv.org/html/2504.04466v4",
        "PDF": "https://arxiv.org/pdf/2504.04466"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper focuses on music generation and loopable audio using an inference-only approach, with no relevance to the data processing or data engineering stage for LLM training."
      },
      "tasks": [
        "Music Generation"
      ],
      "repo_urls": [
        "https://github.com/gladia-research-group/loopgen"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.05312",
      "abstract": "Retrieval-Augmented Generation (RAG), by integrating non-parametric knowledge from external knowledge bases into models, has emerged as a promising approach to enhancing response accuracy while mitigating factual errors and hallucinations. This method has been widely applied in tasks such as Question Answering (QA). However, existing RAG methods struggle with open-domain QA tasks because they perform independent retrieval operations and directly incorporate the retrieved information into generation without maintaining a summarizing memory or using adaptive retrieval strategies, leading to noise from redundant information and insufficient information integration. To address these challenges, we propose Adaptive memory-based optimization for enhanced RAG (Amber) for open-domain QA tasks, which comprises an Agent-based Memory Updater, an Adaptive Information Collector, and a Multi-granular Content Filter, working together within an iterative memory updating paradigm. Specifically, Amber integrates and optimizes the language model's memory through a multi-agent collaborative approach, ensuring comprehensive knowledge integration from previous retrieval steps. It dynamically adjusts retrieval queries and decides when to stop retrieval based on the accumulated knowledge, enhancing retrieval efficiency and effectiveness. Additionally, it reduces noise by filtering irrelevant content at multiple levels, retaining essential information to improve overall model performance. We conduct extensive experiments on several open-domain QA datasets, and the results demonstrate the superiority and effectiveness of our method and its components. The source code is available \\footnote{https://anonymous.4open.science/r/Amber-B203/}.",
      "authors": [
        "Qitao Qin",
        "Yucong Luo",
        "Yihang Lu",
        "Zhibo Chu",
        "Xianwei Meng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-19T04:23:12+00:00",
          "link": "https://arxiv.org/abs/2504.05312v1",
          "size": "375kb",
          "version": "v1"
        },
        {
          "date": "2025-06-26T06:44:43+00:00",
          "link": "https://arxiv.org/abs/2504.05312v2",
          "size": "375kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T09:17:10+00:00",
          "link": "https://arxiv.org/abs/2504.05312v3",
          "size": "375kb",
          "version": "v3"
        }
      ],
      "title": "Towards Adaptive Memory-Based Optimization for Enhanced Retrieval-Augmented Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.05312",
        "HTML": "https://arxiv.org/html/2504.05312v3",
        "PDF": "https://arxiv.org/pdf/2504.05312"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses an optimization method (Amber) for enhanced retrieval-augmented generation using memory-based techniques, which indirectly relates to LLM post-training data processing by enhancing language models' memory but does not introduce new data processing methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.05801",
      "abstract": "In a conversational system, dynamically generating follow-up questions based on context can help users explore information and provide a better user experience. Humans are usually able to ask questions that involve some general life knowledge and demonstrate higher order cognitive skills. However, the questions generated by existing methods are often limited to shallow contextual questions that are uninspiring and have a large gap to the human level. In this paper, we propose a three-stage external knowledge-enhanced follow-up question generation method, which generates questions by identifying contextual topics, constructing a knowledge graph (KG) online, and finally combining these with a large language model to generate the final question. The model generates information-rich and exploratory follow-up questions by introducing external common sense knowledge and performing a knowledge fusion operation. Experiments show that compared to baseline models, our method generates questions that are more informative and closer to human questioning levels while maintaining contextual relevance.",
      "authors": [
        "Jianyu Liu",
        "Yi Huang",
        "Sheng Bi",
        "Junlan Feng",
        "Guilin Qi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-08T08:31:03+00:00",
          "link": "https://arxiv.org/abs/2504.05801v1",
          "size": "700kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T01:54:01+00:00",
          "link": "https://arxiv.org/abs/2504.05801v2",
          "size": "700kb",
          "version": "v2"
        }
      ],
      "title": "From Superficial to Deep: Integrating External Knowledge for Follow-up Question Generation Using Knowledge Graph and LLM",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.05801",
        "HTML": "https://arxiv.org/html/2504.05801v2",
        "PDF": "https://arxiv.org/pdf/2504.05801"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes a method for follow-up question generation using a combination of knowledge graphs and LLMs, which involves data processing strategies for integrating external knowledge but not directly related to the core LLM training data processing tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.09019",
      "abstract": "EU data localization regulations limit data transfers to non-EU countries with the GDPR. However, BGP, DNS and other Internet protocols were not designed to enforce jurisdictional constraints, so implementing data localization is challenging. Despite initial research on the topic, little is known about if or how companies currently operate their server infrastructure to comply with the regulations. We close this knowledge gap by empirically measuring the extent to which servers and routers that process EU requests are located outside of the EU (and a handful of ``adequate'' non-EU countries). The key challenge is that both browser measurements (to infer relevant endpoints) and data-plane measurements (to infer relevant IP addresses) are needed, but no large-scale public infrastructure allows both. We build a novel methodology that combines BrightData (browser) and RIPE Atlas (data-plane) probes, with joint measurements from over 1,000 networks in 19 EU countries. We find that, on average, 2.3% of servers serving users in each EU country are located in non-adequate destination countries (1.4% of known trackers). Our findings suggest that data localization policies are largely being followed by content providers, though there are exceptions.",
      "authors": [
        "Alexander Gamero-Garrido",
        "Kicho Yu",
        "Sumukh Vasisht Shankar",
        "Sachin Kumar Singh",
        "Sindhya Balasubramanian",
        "Alexander Wilcox",
        "David Choffnes"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-12T00:14:37+00:00",
          "link": "https://arxiv.org/abs/2504.09019v1",
          "size": "8342kb",
          "version": "v1"
        },
        {
          "date": "2025-06-26T21:08:31+00:00",
          "link": "https://arxiv.org/abs/2504.09019v2",
          "size": "2044kb",
          "version": "v2"
        }
      ],
      "title": "Empirically Measuring Data Localization in the EU",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.09019",
        "HTML": "https://arxiv.org/html/2504.09019v2",
        "PDF": "https://arxiv.org/pdf/2504.09019"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This study focuses on measuring compliance with EU data localization regulations and methodologies for observing server locations, unrelated to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.11108",
      "abstract": "Similar to LLMs, the development of vision language models is mainly driven by English datasets and models trained in English and Chinese language, whereas support for other languages, even those considered high-resource languages such as German, remains significantly weaker. In this work we present an analysis of open-weight VLMs on factual knowledge in the German and English language. We disentangle the image-related aspects from the textual ones by analyzing accu-racy with jury-as-a-judge in both prompt languages and images from German and international contexts. We found that for celebrities and sights, VLMs struggle because they are lacking visual cognition of German image contents. For animals and plants, the tested models can often correctly identify the image contents ac-cording to the scientific name or English common name but fail in German lan-guage. Cars and supermarket products were identified equally well in English and German images across both prompt languages.",
      "authors": [
        "Ren\\'e Peinl and Vincent Tischler"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-15T11:55:24+00:00",
          "link": "https://arxiv.org/abs/2504.11108v1",
          "size": "609kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T10:17:13+00:00",
          "link": "https://arxiv.org/abs/2504.11108v2",
          "size": "609kb",
          "version": "v2"
        }
      ],
      "title": "Benchmarking Vision Language Models on German Factual Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.11108",
        "PDF": "https://arxiv.org/pdf/2504.11108"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper examines the performance of vision language models, touching on training data indirectly by discussing the language-specific limitations of these models, but it does not propose new data-related methods."
      },
      "tasks": [
        "Benchmarking"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.11580",
      "abstract": "We present a novel recursive Bayesian estimation framework using B-splines for continuous-time 6-DoF dynamic motion estimation. The state vector consists of a recurrent set of position control points and orientation control point increments, enabling efficient estimation via a modified iterated extended Kalman filter without involving error-state formulations. The resulting recursive spline estimator (RESPLE) is further leveraged to develop a versatile suite of direct LiDAR-based odometry solutions, supporting the integration of one or multiple LiDARs and an IMU. We conduct extensive real-world evaluations using public datasets and our own experiments, covering diverse sensor setups, platforms, and environments. Compared to existing systems, RESPLE achieves comparable or superior estimation accuracy and robustness, while attaining real-time efficiency. Our results and analysis demonstrate RESPLE's strength in handling highly dynamic motions and complex scenes within a lightweight and flexible design, showing strong potential as a universal framework for multi-sensor motion estimation. We release the source code and experimental datasets at https://github.com/ASIG-X/RESPLE.",
      "authors": [
        "Ziyu Cao",
        "William Talbot",
        "Kailai Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-15T19:56:53+00:00",
          "link": "https://arxiv.org/abs/2504.11580v1",
          "size": "38662kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T12:25:06+00:00",
          "link": "https://arxiv.org/abs/2504.11580v2",
          "size": "13466kb",
          "version": "v2"
        }
      ],
      "title": "RESPLE: Recursive Spline Estimation for LiDAR-Based Odometry",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.11580",
        "HTML": "https://arxiv.org/html/2504.11580v2",
        "PDF": "https://arxiv.org/pdf/2504.11580"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This work presents a framework for LiDAR-based odometry using splines, entirely unrelated to LLM training data processing or data engineering concerns."
      },
      "repo_urls": [
        "https://github.com/asig-x/resple"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.12398",
      "abstract": "Parametric arrays (PA) offer exceptional directivity and compactness compared to conventional loudspeakers, facilitating various acoustic applications. However, accurate measurement of audio signals generated by PA remains challenging due to spurious ultrasonic sounds arising from microphone nonlinearities. Existing filtering methods, including Helmholtz resonators, phononic crystals, polymer films, and grazing incidence techniques, exhibit practical constraints such as size limitations, fabrication complexity, or insufficient attenuation. To address these issues, we propose and demonstrate a novel acoustic filter based on the design of a half-wavelength resonator. The developed filter exploits the nodal plane in acoustic pressure distribution, effectively minimizing microphone exposure to targeted ultrasonic frequencies. Fabrication via stereolithography (SLA) 3D printing ensures high dimensional accuracy, which is crucial for high-frequency acoustic filters. Finite element method (FEM) simulations guided filter optimization for suppression frequencies at 40 kHz and 60 kHz, achieving high transmission loss (TL) around 60 dB. Experimental validations confirm the filter's superior performance in significantly reducing spurious acoustic signals, as reflected in frequency response, beam pattern, and propagation curve measurements. The proposed filter ensures stable and precise acoustic characterization, independent of measurement distances and incidence angles. This new approach not only improves measurement accuracy but also enhances reliability and reproducibility in parametric array research and development.",
      "authors": [
        "Woongji Kim",
        "Beomseok Oh",
        "Junsuk Rho",
        "Wonkyu Moon"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)",
        "Applied Physics (physics.app-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-16T18:04:26+00:00",
          "link": "https://arxiv.org/abs/2504.12398v1",
          "size": "13015kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T04:53:44+00:00",
          "link": "https://arxiv.org/abs/2504.12398v2",
          "size": "11525kb",
          "version": "v2"
        }
      ],
      "title": "An accurate measurement of parametric array using a spurious sound filter topologically equivalent to a half-wavelength resonator",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.12398",
        "HTML": "https://arxiv.org/html/2504.12398v2",
        "PDF": "https://arxiv.org/pdf/2504.12398"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper describes a novel acoustic filter for parametric array measurements, with no focus on or relevance to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.15949",
      "abstract": "This paper explores the algebraic conditions under which a cellular automaton with a non-linear local rule exhibits surjectivity and reversibility. We also analyze the role of permutivity as a key factor influencing these properties and provide conditions that determine whether a non-linear CA is (bi)permutive. Through theoretical results and illustrative examples, we characterize the relationships between these fundamental properties, offering new insights into the dynamical behavior of non-linear CA.",
      "authors": [
        "Firas Ben Ramdhane",
        "Alberto Dennunzio",
        "Luciano Margara and Giuliamaria Menara"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Discrete Mathematics (cs.DM)",
        "Cryptography and Security (cs.CR)",
        "Dynamical Systems (math.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-22T14:47:16+00:00",
          "link": "https://arxiv.org/abs/2504.15949v1",
          "size": "38kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T13:25:05+00:00",
          "link": "https://arxiv.org/abs/2504.15949v2",
          "size": "38kb",
          "version": "v2"
        }
      ],
      "title": "Structural Properties of Non-Linear Cellular Automata: Permutivity, Surjectivity and Reversibility",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.15949",
        "HTML": "https://arxiv.org/html/2504.15949v2",
        "PDF": "https://arxiv.org/pdf/2504.15949"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This work is focused on the algebraic properties of cellular automata, specifically surjectivity and reversibility, without any mention of LLM or related data processing tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.17342",
      "abstract": "The Fr\\'echet distance is a distance measure between trajectories in the plane or walks in a graph G. Given constant-time shortest path queries in a graph G, the Discrete Fr\\'echet distance $F_G(P, Q)$ between two walks P and Q can be computed in $O(|P| \\cdot |Q|)$ time using a dynamic program. Driemel, van der Hoog, and Rotenberg [SoCG'22] show that for weighted planar graphs this approach is likely tight, as there can be no strongly subquadratic algorithm to compute a $1.01$-approximation of $F_G(P, Q)$ unless the Orthogonal Vector Hypothesis (OVH) fails.\n  Such quadratic-time conditional lower bounds are common to many Fr\\'echet distance variants. However, they can be circumvented by assuming that the input comes from some well-behaved class: There exist $(1+\\varepsilon)$-approximations, both in weighted graphs and in Rd, that take near-linear time for $c$-packed or $\\kappa$-straight walks in the graph. In Rd, there also exists a near-linear time algorithm to compute the Fr\\'echet distance whenever all input edges are long compared to the distance.\n  We consider computing the Fr\\'echet distance in unweighted planar graphs. We show that there exist no 1.25-approximations of the discrete Fr\\'echet distance between two disjoint simple paths in an unweighted planar graph in strongly subquadratic time, unless OVH fails. This improves the previous lower bound, both in terms of generality and approximation factor. We subsequently show that adding graph structure circumvents this lower bound: If the graph is a regular tiling with unit-weighted edges, then there exists an $\\tilde{O}( (|P| + |Q|)^{1.5})$-time algorithm to compute $D_F(P, Q)$. Our result has natural implications in the plane, as it allows us to define a new class of well-behaved curves that facilitate $(1+\\varepsilon)$-approximations of their discrete Fr\\'echet distance in subquadratic time.",
      "authors": [
        "Ivor van der Hoog",
        "Thijs van der Horst",
        "Eva Rotenberg",
        "Lasse Wulf"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Geometry (cs.CG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-24T07:59:39+00:00",
          "link": "https://arxiv.org/abs/2504.17342v1",
          "size": "1286kb",
          "version": "v1"
        },
        {
          "date": "2025-05-09T14:30:55+00:00",
          "link": "https://arxiv.org/abs/2504.17342v2",
          "size": "1286kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T00:56:00+00:00",
          "link": "https://arxiv.org/abs/2504.17342v3",
          "size": "1275kb",
          "version": "v3"
        }
      ],
      "title": "Fr\\'echet Distance in Unweighted Planar Graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.17342",
        "HTML": "https://arxiv.org/html/2504.17342v3",
        "PDF": "https://arxiv.org/pdf/2504.17342"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The research examines computing the Fr\u00e9chet distance in unweighted planar graphs, with no relevance to LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.17571",
      "abstract": "The paper focuses on the problem of tracking eigenvalue trajectories in large-scale power system models as system parameters vary. A continuation-based formulation is presented for tracing any single eigenvalue of interest, which supports sparse matrix representations and accommodates both explicit and semi-implicit differential-algebraic models. Key implementation aspects, such as numerical integration, matrix updates, derivative approximations, and handling defective eigenvalues, are discussed in detail and practical recommendations are duly provided. The tracking approach is demonstrated through a comprehensive case study on the IEEE 39-bus system, as well as on a realistic dynamic model of the Irish transmission system.",
      "authors": [
        "Andreas Bouterakos and Joseph McKeon and Georgios Tzounas"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-24T13:59:56+00:00",
          "link": "https://arxiv.org/abs/2504.17571v1",
          "size": "2563kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T13:58:45+00:00",
          "link": "https://arxiv.org/abs/2504.17571v2",
          "size": "2726kb",
          "version": "v2"
        }
      ],
      "title": "On the Eigenvalue Tracking of Large-Scale Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.17571",
        "HTML": "https://arxiv.org/html/2504.17571v2",
        "PDF": "https://arxiv.org/pdf/2504.17571"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper addresses eigenvalue tracking in large-scale power systems, focusing on numerical methods and system parameter variations, without any link to LLM data processing."
      },
      "tasks": [
        "Numerical Integration"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.18536",
      "abstract": "Modern general-purpose artificial intelligence (AI) systems present an urgent risk management challenge, as their rapidly evolving capabilities and potential for catastrophic harm outpace our ability to reliably assess their risks. Current methods often rely on selective testing and undocumented assumptions about risk priorities, frequently failing to make a serious attempt at assessing the set of pathways through which AI systems pose direct or indirect risks to society and the biosphere. This paper introduces the probabilistic risk assessment (PRA) for AI framework, adapting established PRA techniques from high-reliability industries (e.g., nuclear power, aerospace) for the new challenges of advanced AI. The framework guides assessors in identifying potential risks, estimating likelihood and severity bands, and explicitly documenting evidence, underlying assumptions, and analyses at appropriate granularities. The framework's implementation tool synthesizes the results into a risk report card with aggregated risk estimates from all assessed risks. It introduces three methodological advances: (1) Aspect-oriented hazard analysis provides systematic hazard coverage guided by a first-principles taxonomy of AI system aspects (e.g. capabilities, domain knowledge, affordances); (2) Risk pathway modeling analyzes causal chains from system aspects to societal impacts using bidirectional analysis and incorporating prospective techniques; and (3) Uncertainty management employs scenario decomposition, reference scales, and explicit tracing protocols to structure credible projections with novelty or limited data. Additionally, the framework harmonizes diverse assessment methods by integrating evidence into comparable, quantified absolute risk estimates for lifecycle decisions. We have implemented this as a workbook tool for AI developers, evaluators, and regulators.",
      "authors": [
        "Anna Katariina Wisakanto",
        "Joe Rogero",
        "Avyay M. Casheekar",
        "Richard Mallah"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)",
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)",
        "Applications (stat.AP)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-25T17:59:14+00:00",
          "link": "https://arxiv.org/abs/2504.18536v1",
          "size": "666kb",
          "version": "v1"
        },
        {
          "date": "2025-06-26T19:31:12+00:00",
          "link": "https://arxiv.org/abs/2504.18536v2",
          "size": "711kb",
          "version": "v2"
        }
      ],
      "title": "Adapting Probabilistic Risk Assessment for AI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.18536",
        "HTML": "https://arxiv.org/html/2504.18536v2",
        "PDF": "https://arxiv.org/pdf/2504.18536"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on probabilistic risk assessment for AI systems, without discussing any aspects related to the processing of training data for LLMs."
      },
      "tasks": [
        "Management"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.18710",
      "abstract": "We fully characterize a large class of feedforward neural networks in terms of truncation maps. As an application, we show how a ReLU neural network can implement a feature map which separates concentric data.",
      "authors": [
        "Patr\\'icia Mu\\~noz Ewald"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Optimization and Control (math.OC)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-25T21:46:54+00:00",
          "link": "https://arxiv.org/abs/2504.18710v1",
          "size": "22kb",
          "version": "v1"
        },
        {
          "date": "2025-06-26T19:06:49+00:00",
          "link": "https://arxiv.org/abs/2504.18710v2",
          "size": "22kb",
          "version": "v2"
        }
      ],
      "title": "Explicit neural network classifiers for non-separable data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.18710",
        "HTML": "https://arxiv.org/html/2504.18710v2",
        "PDF": "https://arxiv.org/pdf/2504.18710"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper discusses neural network classifiers and truncation maps, which do not relate to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2504.19634",
      "abstract": "Labeling errors in remote sensing (RS) image segmentation datasets often remain implicit and subtle due to ambiguous class boundaries, mixed pixels, shadows, complex terrain features, and subjective annotator bias. Furthermore, the scarcity of annotated RS data due to high image acquisition and labeling costs complicates training noise-robust models. While sophisticated mechanisms such as label selection or noise correction might address this issue, they tend to increase training time and add implementation complexity. In this letter, we propose NSegment-a simple yet effective data augmentation solution to mitigate this issue. Unlike traditional methods, it applies elastic transformations only to segmentation labels, varying deformation intensity per sample in each training epoch to address annotation inconsistencies. Experimental results demonstrate that our approach improves the performance of RS image segmentation on various state-of-the-art models.",
      "authors": [
        "Yechan Kim",
        "DongHo Yoon",
        "SooYeon Kim",
        "Moongu Jeon"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-28T09:49:35+00:00",
          "link": "https://arxiv.org/abs/2504.19634v1",
          "size": "1215kb",
          "version": "v1"
        },
        {
          "date": "2025-06-14T15:30:16+00:00",
          "link": "https://arxiv.org/abs/2504.19634v2",
          "size": "1991kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T15:35:04+00:00",
          "link": "https://arxiv.org/abs/2504.19634v3",
          "size": "1984kb",
          "version": "v3"
        }
      ],
      "title": "NSegment : Label-specific Deformations for Remote Sensing Image Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.19634",
        "HTML": "https://arxiv.org/html/2504.19634v3",
        "PDF": "https://arxiv.org/pdf/2504.19634"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper addresses data augmentation to handle labeling errors in remote sensing image segmentation, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.20118",
      "abstract": "Traditional Chinese Medicine (TCM) represents a rich repository of ancient medical knowledge that continues to play an important role in modern healthcare. Due to the complexity and breadth of the TCM literature, the integration of AI technologies is critical for its modernization and broader accessibility. However, this integration poses considerable challenges, including the interpretation of obscure classical Chinese texts and the modeling of intricate semantic relationships among TCM concepts. In this paper, we develop OpenTCM, an LLM-based system that combines a domain-specific TCM knowledge graph and Graph-based Retrieval-Augmented Generation (GraphRAG). First, we extract more than 3.73 million classical Chinese characters from 68 gynecological books in the Chinese Medical Classics Database, with the help of TCM and gynecology experts. Second, we construct a comprehensive multi-relational knowledge graph comprising more than 48,000 entities and 152,000 interrelationships, using customized prompts and Chinese-oriented LLMs such as DeepSeek and Kimi to ensure high-fidelity semantic understanding. Last, we empower OpenTCM with GraphRAG, enabling high-fidelity ingredient knowledge retrieval and diagnostic question-answering without model fine-tuning. Experimental evaluations demonstrate that OpenTCM achieves mean expert scores (MES) of 4.378 in ingredient information retrieval and 4.045 in diagnostic question-answering tasks, outperforming state-of-the-art solutions in real-world TCM use cases.",
      "authors": [
        "Jinglin He",
        "Yunqi Guo",
        "Lai Kwan Lam",
        "Waikei Leung",
        "Lixing He",
        "Yuanan Jiang",
        "Chi Chiu Wang",
        "Guoliang Xing",
        "and Hongkai Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-28T08:04:44+00:00",
          "link": "https://arxiv.org/abs/2504.20118v1",
          "size": "2980kb",
          "version": "v1"
        },
        {
          "date": "2025-05-23T02:43:56+00:00",
          "link": "https://arxiv.org/abs/2504.20118v2",
          "size": "2954kb",
          "version": "v2"
        },
        {
          "date": "2025-06-09T13:34:27+00:00",
          "link": "https://arxiv.org/abs/2504.20118v3",
          "size": "2832kb",
          "version": "v3"
        },
        {
          "date": "2025-06-27T04:01:12+00:00",
          "link": "https://arxiv.org/abs/2504.20118v4",
          "size": "2181kb",
          "version": "v4"
        }
      ],
      "title": "OpenTCM: A GraphRAG-Empowered LLM-based System for Traditional Chinese Medicine Knowledge Retrieval and Diagnosis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.20118",
        "HTML": "https://arxiv.org/html/2504.20118v4",
        "PDF": "https://arxiv.org/pdf/2504.20118"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper involves the extraction and structuring of TCM knowledge into a database and knowledge graph but does not focus on novel data processing methodologies for LLM training."
      },
      "tasks": [
        "Diagnostic",
        "Information Retrieval",
        "Model Selection",
        "Question Answering",
        "Retrieval",
        "Retrieval-augmented Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.20519",
      "abstract": "Large language model (LLM) based chatbots show promise in persuasive communication, but existing studies often rely on weak controls or focus on belief change rather than behavioral intentions or outcomes. This pre-registered multi-country (US, Canada, UK) randomized controlled trial involving 930 vaccine-hesitant parents evaluated brief (three-minute) multi-turn conversations with LLM-based chatbots against standard public health messaging approaches for increasing human papillomavirus (HPV) vaccine intentions for their children. Participants were randomly assigned to: (1) a weak control (no message), (2) a strong control reflecting the standard of care (reading official public health materials), or (3 and 4) one of two chatbot conditions. One chatbot was prompted to deliver short, conversational responses, while the other used the model's default output style (longer with bullet points). While chatbot interactions significantly increased self-reported vaccination intent (by 7.1-10.3 points on a 100-point scale) compared to no message, they did not outperform standard public health materials, with the conversational chatbot performing significantly worse. Additionally, while the short-term effects of chatbot interactions faded during a 15-day follow-up, the effects of public health material persisted through a 45-day follow-up relative to no message. These findings suggest that while LLMs can effectively shift vaccination intentions in the short-term, their incremental value over existing public health communications is questionable, offering a more tempered view of their persuasive capabilities and highlighting the importance of integrating AI-driven tools alongside, rather than replacing, current public health strategies.",
      "authors": [
        "Neil K. R. Sehgal",
        "Sunny Rai",
        "Manuel Tonneau",
        "Anish K. Agarwal",
        "Joseph Cappella",
        "Melanie Kornides",
        "Lyle Ungar",
        "Alison Buttenheim",
        "Sharath Chandra Guntuku"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-29T07:59:46+00:00",
          "link": "https://arxiv.org/abs/2504.20519v1",
          "size": "4857kb",
          "version": "v1"
        },
        {
          "date": "2025-04-30T03:22:51+00:00",
          "link": "https://arxiv.org/abs/2504.20519v2",
          "size": "4496kb",
          "version": "v2"
        },
        {
          "date": "2025-06-26T21:04:58+00:00",
          "link": "https://arxiv.org/abs/2504.20519v3",
          "size": "7543kb",
          "version": "v3"
        }
      ],
      "title": "Conversations with AI Chatbots Increase Short-Term Vaccine Intentions But Do Not Outperform Standard Public Health Messaging",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.20519",
        "PDF": "https://arxiv.org/pdf/2504.20519"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The study evaluates chatbot interactions for vaccine communication, which does not address training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.21502",
      "abstract": "This paper investigates concurrency-constrained scheduling problems, where the objective is to construct a schedule for a set of jobs subject to concurrency restrictions. Formally, we are given a conflict graph $G$ defined over a set of $n$ jobs, where an edge between two jobs in $G$ indicates that these jobs cannot be executed concurrently. Each job may have distinct attributes, such as processing time, due date, weight, and release time. The goal is to determine a schedule that optimizes a specified scheduling criterion while adhering to all concurrency constraints. This framework offers a versatile model for analyzing resource allocation problems where processes compete for shared resources, such as access to shared memory. From a theoretical perspective, it encompasses several classical graph coloring problems, including Chromatic Number, Sum Coloring, and Interval Chromatic Number.\n  Given that even the simplest concurrency-constrained scheduling problems are NP-hard for general conflict graphs, this study focuses on conflict graphs with bounded treewidth. Our results establish a dichotomy: Some problems in this setting can be solved in FPT time, while others are shown to be XALP-complete for treewidth as parameter. Along the way, we generalize several previously known results on coloring problems for bounded treewidth graphs. Several of the FPT algorithms are based on the insight that completion times are bounded by the Grundy number of the conflict graph - the fact that this number is bounded by the product of treewidth and the logarithm of the number of vertices then leads to the FPT time bound.",
      "authors": [
        "Hans L. Bodlaender",
        "Danny Hermelin and Erik Jan van Leeuwen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Discrete Mathematics (cs.DM)",
        "Computational Complexity (cs.CC)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-30T10:43:15+00:00",
          "link": "https://arxiv.org/abs/2504.21502v1",
          "size": "138kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T13:47:04+00:00",
          "link": "https://arxiv.org/abs/2504.21502v2",
          "size": "83kb",
          "version": "v2"
        }
      ],
      "title": "Concurrency Constrained Scheduling with Tree-Like Constraints",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.21502",
        "HTML": "https://arxiv.org/html/2504.21502v2",
        "PDF": "https://arxiv.org/pdf/2504.21502"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on concurrency-constrained scheduling problems, which are related to constructing schedules for job execution with concurrency restrictions. It does not involve any aspects of LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.01194",
      "abstract": "For a planar point set $P$, its convex hull is the smallest convex polygon that encloses all points in $P$. The construction of the convex hull from an array $I_P$ containing $P$ is a fundamental problem in computational geometry. By sorting $I_P$ in lexicographical order, one can construct the convex hull of $P$ in $O(n \\log n)$ time which is worst-case optimal. Standard worst-case analysis, however, has been criticized as overly coarse or pessimistic, and researchers search for more refined analyses.\n  Universal analysis provides an even stronger guarantee. It fixes a point set $P$ and considers the maximum running time across all permutations $I_P$ of $P$. Afshani, Barbay, Chan [FOCS'07] prove that the convex hull construction algorithm by Kirkpatrick, McQueen, and Seidel is universally optimal. Their proof restricts the model of computation to any algebraic decision tree model where the test functions have at most constant degree and at most a constant number of arguments. They rely upon involved algebraic arguments to construct a lower bound for each point set $P$ that matches the universal running time of [SICOMP'86].\n  We provide a different proof of universal optimality. Instead of restricting the computational model, we further specify the output. We require as output (1) the convex hull, and (2) for each internal point of $P$ a witness for it being internal. Our argument is shorter, perhaps simpler, and applicable in more general models of computation.",
      "authors": [
        "Ivor van der Hoog",
        "Eva Rotenberg",
        "and Daniel Rutschmann"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Geometry (cs.CG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-02T11:38:29+00:00",
          "link": "https://arxiv.org/abs/2505.01194v1",
          "size": "439kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T01:05:23+00:00",
          "link": "https://arxiv.org/abs/2505.01194v2",
          "size": "364kb",
          "version": "v2"
        }
      ],
      "title": "A Combinatorial Proof of Universal Optimality for Computing a Planar Convex Hull",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.01194",
        "HTML": "https://arxiv.org/html/2505.01194v2",
        "PDF": "https://arxiv.org/pdf/2505.01194"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper discusses the computational geometry problem of computing the convex hull of a planar point set; it does not address issues related to LLM training data or data processing methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.01463",
      "abstract": "Protecting cloud applications is critical in an era where security threats are increasingly sophisticated and persistent. Continuous Integration and Continuous Deployment (CI/CD) pipelines are particularly vulnerable, making innovative security approaches essential. This research explores the application of Natural Language Processing (NLP) techniques, specifically Topic Modelling, to analyse security-related text data and anticipate potential threats. We focus on Latent Dirichlet Allocation (LDA) and Probabilistic Latent Semantic Analysis (PLSA) to extract meaningful patterns from data sources, including logs, reports, and deployment traces. Using the Gensim framework in Python, these methods categorise log entries into security-relevant topics (e.g., phishing, encryption failures). The identified topics are leveraged to highlight patterns indicative of security issues across CI/CD's continuous stages (build, test, deploy). This approach introduces a semantic layer that supports early vulnerability recognition and contextual understanding of runtime behaviours.",
      "authors": [
        "Sabbir M. Saleh",
        "Nazim Madhavji",
        "John Steinbacher"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-01T19:17:20+00:00",
          "link": "https://arxiv.org/abs/2505.01463v1",
          "size": "588kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T04:34:30+00:00",
          "link": "https://arxiv.org/abs/2505.01463v2",
          "size": "1005kb",
          "version": "v2"
        }
      ],
      "title": "Enhancing Cloud Security through Topic Modelling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.01463",
        "PDF": "https://arxiv.org/pdf/2505.01463"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This research explores the application of NLP techniques for enhancing cloud security through topic modeling on security-related text data. It does not make any contributions to LLM training data engineering or processing."
      },
      "tasks": [
        "Vulnerability Detection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.02567",
      "abstract": "Recent years have seen remarkable progress in both multimodal understanding models and image generation models. Despite their respective successes, these two domains have evolved independently, leading to distinct architectural paradigms: While autoregressive-based architectures have dominated multimodal understanding, diffusion-based models have become the cornerstone of image generation. Recently, there has been growing interest in developing unified frameworks that integrate these tasks. The emergence of GPT-4o's new capabilities exemplifies this trend, highlighting the potential for unification. However, the architectural differences between the two domains pose significant challenges. To provide a clear overview of current efforts toward unification, we present a comprehensive survey aimed at guiding future research. First, we introduce the foundational concepts and recent advancements in multimodal understanding and text-to-image generation models. Next, we review existing unified models, categorizing them into three main architectural paradigms: diffusion-based, autoregressive-based, and hybrid approaches that fuse autoregressive and diffusion mechanisms. For each category, we analyze the structural designs and innovations introduced by related works. Additionally, we compile datasets and benchmarks tailored for unified models, offering resources for future exploration. Finally, we discuss the key challenges facing this nascent field, including tokenization strategy, cross-modal attention, and data. As this area is still in its early stages, we anticipate rapid advancements and will regularly update this survey. Our goal is to inspire further research and provide a valuable reference for the community. The references associated with this survey are available on GitHub (https://github.com/AIDC-AI/Awesome-Unified-Multimodal-Models).",
      "authors": [
        "Xinjie Zhang",
        "Jintao Guo",
        "Shanshan Zhao",
        "Minghao Fu",
        "Lunhao Duan",
        "Jiakui Hu",
        "Yong Xien Chng",
        "Guo-Hua Wang",
        "Qing-Guo Chen",
        "Zhao Xu",
        "Weihua Luo",
        "Kaifu Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-05T11:18:03+00:00",
          "link": "https://arxiv.org/abs/2505.02567v1",
          "size": "1115kb",
          "version": "v1"
        },
        {
          "date": "2025-05-07T13:27:21+00:00",
          "link": "https://arxiv.org/abs/2505.02567v2",
          "size": "1038kb",
          "version": "v2"
        },
        {
          "date": "2025-05-22T15:12:52+00:00",
          "link": "https://arxiv.org/abs/2505.02567v3",
          "size": "1126kb",
          "version": "v3"
        },
        {
          "date": "2025-06-27T13:30:10+00:00",
          "link": "https://arxiv.org/abs/2505.02567v4",
          "size": "1181kb",
          "version": "v4"
        }
      ],
      "title": "Unified Multimodal Understanding and Generation Models: Advances, Challenges, and Opportunities",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.02567",
        "HTML": "https://arxiv.org/html/2505.02567v4",
        "PDF": "https://arxiv.org/pdf/2505.02567"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper surveys unified models in multimodal understanding and generation, mentioning datasets and benchmarks as resources for exploration. However, it does not directly propose new methods for processing training data for LLMs."
      },
      "tasks": [
        "Image Generation",
        "Survey",
        "Text to Image Generation",
        "Text-to-Image Generation"
      ],
      "repo_urls": [
        "https://github.com/aidc-ai/awesome-unified-multimodal-models"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.02781",
      "abstract": "Understanding and identifying controlled direct effects (CDEs) is crucial across numerous scientific domains, including public health. While existing methods can identify these effects from causal directed acyclic graphs (DAGs), the true underlying structure is often unknown in practice. Essential graphs, which represent a Markov equivalence class of DAGs characterized by the same set of $d$-separations, provide a more practical and realistic alternative. However, learning the full essential graph is computationally intensive and typically depends on strong, untestable assumptions. In this work, we characterize a local class of graphs, defined relative to a target variable, that share a specific subset of $d$-separations, and introduce a graphical representation of this class, called the local essential graph (LEG). We then present LocPC, a novel algorithm designed to recover the LEG from an observed distribution using only local conditional independence tests. Building on LocPC, we propose LocPC-CDE, an algorithm that discovers the portion of the LEG that is both sufficient and necessary to identify a CDE, bypassing the need of retrieving the full essential graph. Compared to global methods, our algorithms require less conditional independence tests and operate under weaker assumptions while maintaining theoretical guarantees. We illustrate the effectiveness of our approach through simulation studies.",
      "authors": [
        "Timoth\\'ee Loranchet and Charles K. Assaad"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-05T16:47:29+00:00",
          "link": "https://arxiv.org/abs/2505.02781v1",
          "size": "44kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T14:13:05+00:00",
          "link": "https://arxiv.org/abs/2505.02781v2",
          "size": "1473kb",
          "version": "v2"
        }
      ],
      "title": "Local Markov Equivalence and Local Causal Discovery for Identifying Controlled Direct Effects",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.02781",
        "HTML": "https://arxiv.org/html/2505.02781v2",
        "PDF": "https://arxiv.org/pdf/2505.02781"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This work is centered on causal discovery and identifying controlled direct effects using essential graphs, unrelated to the collection, construction, or processing of LLM training data."
      },
      "tasks": [
        "Causal Discovery"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.02862",
      "abstract": "Despite the remarkable performance of Large Language Models (LLMs), they remain vulnerable to jailbreak attacks, which can compromise their safety mechanisms. Existing studies often rely on brute-force optimization or manual design, failing to uncover potential risks in real-world scenarios. To address this, we propose a novel jailbreak attack framework, ICRT, inspired by heuristics and biases in human cognition. Leveraging the simplicity effect, we employ cognitive decomposition to reduce the complexity of malicious prompts. Simultaneously, relevance bias is utilized to reorganize prompts, enhancing semantic alignment and inducing harmful outputs effectively. Furthermore, we introduce a ranking-based harmfulness evaluation metric that surpasses the traditional binary success-or-failure paradigm by employing ranking aggregation methods such as Elo, HodgeRank, and Rank Centrality to comprehensively quantify the harmfulness of generated content. Experimental results show that our approach consistently bypasses mainstream LLMs' safety mechanisms and generates high-risk content, providing insights into jailbreak attack risks and contributing to stronger defense strategies.",
      "authors": [
        "Haoming Yang",
        "Ke Ma",
        "Xiaojun Jia",
        "Yingfei Sun",
        "Qianqian Xu",
        "Qingming Huang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-03T05:28:11+00:00",
          "link": "https://arxiv.org/abs/2505.02862v1",
          "size": "2924kb",
          "version": "v1"
        },
        {
          "date": "2025-06-03T14:46:36+00:00",
          "link": "https://arxiv.org/abs/2505.02862v2",
          "size": "4199kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T08:31:28+00:00",
          "link": "https://arxiv.org/abs/2505.02862v3",
          "size": "4219kb",
          "version": "v3"
        }
      ],
      "title": "Cannot See the Forest for the Trees: Invoking Heuristics and Biases to Elicit Irrational Choices of LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.02862",
        "PDF": "https://arxiv.org/pdf/2505.02862"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on a jailbreak attack framework for LLMs, employing heuristics and biases for vulnerability exploitation, without discussing any aspect of LLM training data processing or engineering."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2505.04950",
      "abstract": "Despite AI's impressive achievements, including recent advances in generative and large language models, there remains a significant gap in the ability of AI systems to handle uncertainty and generalize beyond their training data. AI models consistently fail to make robust enough predictions when facing unfamiliar or adversarial data. Traditional machine learning approaches struggle to address this issue, due to an overemphasis on data fitting, while current uncertainty quantification approaches suffer from serious limitations. This position paper posits a paradigm shift towards epistemic artificial intelligence, emphasizing the need for models to learn from what they know while at the same time acknowledging their ignorance, using the mathematics of second-order uncertainty measures. This approach, which leverages the expressive power of such measures to efficiently manage uncertainty, offers an effective way to improve the resilience and robustness of AI systems, allowing them to better handle unpredictable real-world environments.",
      "authors": [
        "Shireen Kudukkil Manchingal",
        "Andrew Bradley",
        "Julian F. P. Kooij",
        "Keivan Shariatmadar",
        "Neil Yorke-Smith",
        "Fabio Cuzzolin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-08T05:10:38+00:00",
          "link": "https://arxiv.org/abs/2505.04950v1",
          "size": "2486kb",
          "version": "v1"
        },
        {
          "date": "2025-06-13T11:48:03+00:00",
          "link": "https://arxiv.org/abs/2505.04950v2",
          "size": "1364kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T13:25:34+00:00",
          "link": "https://arxiv.org/abs/2505.04950v3",
          "size": "1364kb",
          "version": "v3"
        }
      ],
      "title": "Epistemic Artificial Intelligence is Essential for Machine Learning Models to Truly 'Know When They Do Not Know'",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.04950",
        "PDF": "https://arxiv.org/pdf/2505.04950"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This position paper discusses the concept of epistemic artificial intelligence for handling uncertainty in AI models, rather than any specific training data processing techniques for LLMs."
      },
      "tasks": [
        "Autonomous Vehicles",
        "Domain Adaptation",
        "Position"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.05023",
      "abstract": "Zero-shot Semantic Segmentation (ZSS) aims to segment categories that are not annotated during training. While fine-tuning vision-language models has achieved promising results, these models often overfit to seen categories due to the lack of supervision for unseen classes. As an alternative to fully supervised approaches, query-based segmentation has shown great latent in ZSS, as it enables object localization without relying on explicit labels. However, conventional Hungarian matching, a core component in query-based frameworks, needs full supervision and often misclassifies unseen categories as background in the setting of ZSS. To address this issue, we propose Split Matching (SM), a novel assignment strategy that decouples Hungarian matching into two components: one for seen classes in annotated regions and another for latent classes in unannotated regions (referred to as unseen candidates). Specifically, we partition the queries into seen and candidate groups, enabling each to be optimized independently according to its available supervision. To discover unseen candidates, we cluster CLIP dense features to generate pseudo masks and extract region-level embeddings using CLS tokens. Matching is then conducted separately for the two groups based on both class-level similarity and mask-level consistency. Additionally, we introduce a Multi-scale Feature Enhancement (MFE) module that refines decoder features through residual multi-scale aggregation, improving the model's ability to capture spatial details across resolutions. SM is the first to introduce decoupled Hungarian matching under the inductive ZSS setting, and achieves state-of-the-art performance on two standard benchmarks.",
      "authors": [
        "Jialei Chen",
        "Xu Zheng",
        "Dongyue Li",
        "Chong Yi",
        "Seigo Ito",
        "Danda Pani Paudel",
        "Luc Van Gool",
        "Hiroshi Murase",
        "Daisuke Deguchi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-08T07:56:30+00:00",
          "link": "https://arxiv.org/abs/2505.05023v1",
          "size": "7718kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T09:35:34+00:00",
          "link": "https://arxiv.org/abs/2505.05023v2",
          "size": "2221kb",
          "version": "v2"
        }
      ],
      "title": "Split Matching for Inductive Zero-shot Semantic Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.05023",
        "HTML": "https://arxiv.org/html/2505.05023v2",
        "PDF": "https://arxiv.org/pdf/2505.05023"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The focus is on zero-shot semantic segmentation using vision-language models with a novel assignment strategy, with no mention of LLM training data processing or related data engineering tasks."
      },
      "tasks": [
        "Object Localization",
        "Semantic Segmentation",
        "Zero-Shot Semantic Segmentation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.05153",
      "abstract": "We study day-ahead bidding strategies for wind farm operators under a one-price balancing scheme, prevalent in European electricity markets. In this setting, the profit-maximising strategy becomes an all-or-nothing strategy, aiming to take advantage of open positions in the balancing market. However, balancing prices are difficult, if not impossible, to forecast in the day-ahead stage and large open positions can affect the balancing price by changing the direction of the system imbalance. This paper addresses day-ahead bidding as a decision-making problem under uncertainty, with the objective of maximising the expected profit while reducing the imbalance risk related to the strategy. To this end, we develop a stochastic optimisation problem with explicit constraints on the positions in the balancing market, providing risk certificates, and derive an analytical solution to this problem. Moreover, we show how the price-impact of the trading strategy on the balancing market can be included in the ex-post evaluation. Using real data from the Belgian electricity market and an offshore wind farm in the North Sea, we demonstrate that the all-or-nothing strategy negatively impacts the balancing price, resulting in long-term losses for the wind farm. Our risk-constrained strategy, however, can still significantly enhance operational profit compared to traditional point-forecast bidding.",
      "authors": [
        "Max Bruninx",
        "Timothy Verstraeten",
        "Jalal Kazempour",
        "Jan Helsen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-08T11:50:19+00:00",
          "link": "https://arxiv.org/abs/2505.05153v1",
          "size": "312kb",
          "version": "v1"
        },
        {
          "date": "2025-06-12T15:20:47+00:00",
          "link": "https://arxiv.org/abs/2505.05153v2",
          "size": "329kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T10:01:40+00:00",
          "link": "https://arxiv.org/abs/2505.05153v3",
          "size": "323kb",
          "version": "v3"
        }
      ],
      "title": "Day-Ahead Bidding Strategies for Wind Farm Operators under a One-Price Balancing Scheme",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.05153",
        "HTML": "https://arxiv.org/html/2505.05153v3",
        "PDF": "https://arxiv.org/pdf/2505.05153"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper addresses financial market strategies for wind farm operators, specifically day-ahead bidding under uncertainty, with no relevance to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2505.08375",
      "abstract": "Accessible and inclusive design has gained increased attention in HCI, yet practical implementation remains challenging due to resource-intensive prototyping methods. Traditional approaches such as workshops, A-B tests, and co-design sessions struggle to capture the diverse and complex needs of users with disabilities at scale. This position paper argues for an automated, accessible Human-in-the-Loop (HITL) design optimization process that shifts the designer's role from directly crafting prototypes to curating constraints for algorithmic exploration. By pre-constraining the design space based on specific user interaction needs, integrating adaptive multi-modal feedback channels, and personalizing feedback prompts, the HITL approach could efficiently refine design parameters, such as text size, color contrast, layout, and interaction modalities, to achieve optimal accessibility. This approach promises scalable, individualized design solutions while raising critical questions about constraint curation, transparency, user agency, and ethical considerations, making it essential to discuss and refine these ideas collaboratively at the workshop.",
      "authors": [
        "Pascal Jansen"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-13T09:21:39+00:00",
          "link": "https://arxiv.org/abs/2505.08375v1",
          "size": "173kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T09:35:04+00:00",
          "link": "https://arxiv.org/abs/2505.08375v2",
          "size": "174kb",
          "version": "v2"
        }
      ],
      "title": "Human-in-the-Loop Optimization for Inclusive Design: Balancing Automation and Designer Expertise",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.08375",
        "HTML": "https://arxiv.org/html/2505.08375v2",
        "PDF": "https://arxiv.org/pdf/2505.08375"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The focus is on human-in-the-loop optimization for inclusive design in HCI, discussing design constraints and user interaction without any implication on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.09338",
      "abstract": "We observe a novel phenomenon, contextual entrainment, across a wide range of language models (LMs) and prompt settings, providing a new mechanistic perspective on how LMs become distracted by ``irrelevant'' contextual information in the input prompt. Specifically, LMs assign significantly higher logits (or probabilities) to any tokens that have previously appeared in the context prompt, even for random tokens. This suggests that contextual entrainment is a mechanistic phenomenon, occurring independently of the relevance or semantic relation of the tokens to the question or the rest of the sentence. We find statistically significant evidence that the magnitude of contextual entrainment is influenced by semantic factors. Counterfactual prompts have a greater effect compared to factual ones, suggesting that while contextual entrainment is a mechanistic phenomenon, it is modulated by semantic factors.\n  We hypothesise that there is a circuit of attention heads -- the entrainment heads -- that corresponds to the contextual entrainment phenomenon. Using a novel entrainment head discovery method based on differentiable masking, we identify these heads across various settings. When we ``turn off'' these heads, i.e., set their outputs to zero, the effect of contextual entrainment is significantly attenuated, causing the model to generate output that capitulates to what it would produce if no distracting context were provided. Our discovery of contextual entrainment, along with our investigation into LM distraction via the entrainment heads, marks a key step towards the mechanistic analysis and mitigation of the distraction problem.",
      "authors": [
        "Jingcheng Niu",
        "Xingdi Yuan",
        "Tong Wang",
        "Hamidreza Saghir",
        "Amir H. Abdi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-14T12:33:05+00:00",
          "link": "https://arxiv.org/abs/2505.09338v1",
          "size": "598kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T11:15:26+00:00",
          "link": "https://arxiv.org/abs/2505.09338v2",
          "size": "599kb",
          "version": "v2"
        }
      ],
      "title": "Llama See, Llama Do: A Mechanistic Perspective on Contextual Entrainment and Distraction in LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.09338",
        "HTML": "https://arxiv.org/html/2505.09338v2",
        "PDF": "https://arxiv.org/pdf/2505.09338"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on the phenomenon of contextual entrainment in language models and its mechanistic analysis, not the processing of training data for LLMs."
      },
      "tasks": [
        "counterfactual"
      ],
      "repo_urls": [
        "https://github.com/frankniujc/entrainment"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.11108",
      "abstract": "Object rearrangement is a key task for household robots requiring personalization without explicit instructions, meaningful object placement in environments occupied with objects, and generalization to unseen objects and new environments. To facilitate research addressing these challenges, we introduce PARSEC, an object rearrangement benchmark for learning user organizational preferences from observed scene context to place objects in a partially arranged environment. PARSEC is built upon a novel dataset of 110K rearrangement examples crowdsourced from 72 users, featuring 93 object categories and 15 environments. To better align with real-world organizational habits, we propose ContextSortLM, an LLM-based personalized rearrangement model that handles flexible user preferences by explicitly accounting for objects with multiple valid placement locations when placing items in partially arranged environments. We evaluate ContextSortLM and existing personalized rearrangement approaches on the PARSEC benchmark and complement these findings with a crowdsourced evaluation of 108 online raters ranking model predictions based on alignment with user preferences. Our results indicate that personalized rearrangement models leveraging multiple scene context sources perform better than models relying on a single context source. Moreover, ContextSortLM outperforms other models in placing objects to replicate the target user's arrangement and ranks among the top two in all three environment categories, as rated by online evaluators. Importantly, our evaluation highlights challenges associated with modeling environment semantics across different environment categories and provides recommendations for future work.",
      "authors": [
        "Kartik Ramachandruni",
        "Sonia Chernova"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-16T10:40:44+00:00",
          "link": "https://arxiv.org/abs/2505.11108v1",
          "size": "4927kb",
          "version": "v1"
        },
        {
          "date": "2025-06-26T23:26:27+00:00",
          "link": "https://arxiv.org/abs/2505.11108v2",
          "size": "2470kb",
          "version": "v2"
        }
      ],
      "title": "Personalized Robotic Object Rearrangement from Scene Context",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.11108",
        "HTML": "https://arxiv.org/html/2505.11108v2",
        "PDF": "https://arxiv.org/pdf/2505.11108"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces PARSEC, a benchmark built on a novel dataset for object rearrangement, it primarily focuses on personalized robotic object rearrangement and not on LLM training data processing methods."
      },
      "tasks": [
        "Object",
        "Object Rearrangement"
      ],
      "repo_urls": [
        "https://github.com/kartikvrama/parsec"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.11718",
      "abstract": "AI-based peer review systems tend to produce shallow and overpraising suggestions compared to human feedback. Here, we evaluate how well a reasoning LLM trained with multi-objective reinforcement learning (REMOR) can overcome these limitations. We start by designing a multi-aspect reward function that aligns with human evaluation of reviews. The aspects are related to the review itself (e.g., criticisms, novelty) and the relationship between the review and the manuscript (i.e., relevance). First, we perform supervised fine-tuning of DeepSeek-R1-Distill-Qwen-7B using LoRA on PeerRT, a new dataset of high-quality top AI conference reviews enriched with reasoning traces. We then apply Group Relative Policy Optimization (GRPO) to train two models: REMOR-H (with the human-aligned reward) and REMOR-U (with a uniform reward). Interestingly, the human-aligned reward penalizes aspects typically associated with strong reviews, leading REMOR-U to produce qualitatively more substantive feedback. Our results show that REMOR-U and REMOR-H achieve more than twice the average rewards of human reviews, non-reasoning state-of-the-art agentic multi-modal AI review systems, and general commercial LLM baselines. We found that while the best AI and human reviews are comparable in quality, REMOR avoids the long tail of low-quality human reviews. We discuss how reasoning is key to achieving these improvements and release the Human-aligned Peer Review Reward (HPRR) function, the Peer Review Reasoning-enriched Traces (PeerRT) dataset, and the REMOR models, which we believe can help spur progress in the area.",
      "authors": [
        "Pawin Taechoyotin",
        "Daniel Acuna"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-16T22:00:49+00:00",
          "link": "https://arxiv.org/abs/2505.11718v1",
          "size": "1407kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T02:48:27+00:00",
          "link": "https://arxiv.org/abs/2505.11718v2",
          "size": "1407kb",
          "version": "v2"
        }
      ],
      "title": "REMOR: Automated Peer Review Generation with LLM Reasoning and Multi-Objective Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.11718",
        "HTML": "https://arxiv.org/html/2505.11718v2",
        "PDF": "https://arxiv.org/pdf/2505.11718"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper mentions supervised fine-tuning of a model using a new dataset but mainly focuses on AI-based peer review systems and multi-objective reinforcement learning, not primarily on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.11886",
      "abstract": "Vision-Language Navigation (VLN) is a critical task for developing embodied agents that can follow natural language instructions to navigate in complex real-world environments. Recent advances in VLN by large pretrained models have significantly improved generalization and instruction grounding compared to traditional approaches. However, the role of reasoning strategies in navigation-an action-centric, long-horizon task-remains underexplored, despite Chain-of-Thought (CoT) reasoning's demonstrated success in static tasks like visual question answering. To address this gap, we conduct the first systematic evaluation of reasoning strategies for VLN, including No-Think (direct action prediction), Pre-Think (reason before action), and Post-Think (reason after action). Surprisingly, our findings reveal the Inference-time Reasoning Collapse issue, where inference-time reasoning degrades navigation accuracy, highlighting the challenges of integrating reasoning into VLN. Based on this insight, we propose Aux-Think, a framework that trains models to internalize structured reasoning patterns through CoT supervision, while inferring action directly without reasoning in online prediction. To support this framework, we release R2R-CoT-320k, the first Chain-of-Thought annotated dataset for VLN. Extensive experiments show that Aux-Think reduces training effort greatly and achieves the best performance under the same data scale.",
      "authors": [
        "Shuo Wang",
        "Yongcai Wang",
        "Wanting Li",
        "Xudong Cai",
        "Yucheng Wang",
        "Maiyue Chen",
        "Kaihui Wang",
        "Zhizhong Su",
        "Deying Li",
        "Zhaoxin Fan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-17T07:34:56+00:00",
          "link": "https://arxiv.org/abs/2505.11886v1",
          "size": "2119kb",
          "version": "v1"
        },
        {
          "date": "2025-05-20T08:51:38+00:00",
          "link": "https://arxiv.org/abs/2505.11886v2",
          "size": "2119kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T02:29:15+00:00",
          "link": "https://arxiv.org/abs/2505.11886v3",
          "size": "2805kb",
          "version": "v3"
        }
      ],
      "title": "Aux-Think: Exploring Reasoning Strategies for Data-Efficient Vision-Language Navigation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.11886",
        "HTML": "https://arxiv.org/html/2505.11886v3",
        "PDF": "https://arxiv.org/pdf/2505.11886"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper addresses reasoning strategies in Vision-Language Navigation tasks and proposes a reasoning framework; it does not contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.12380",
      "abstract": "Reinforcement learning (RL) has been widely adopted to enhance the performance of large language models (LLMs) on Text-to-SQL tasks. However, existing methods often rely on execution-based or LLM-based Bradley-Terry reward models. The former suffers from high execution latency caused by repeated database calls, whereas the latter imposes substantial GPU memory overhead, both of which significantly hinder the efficiency and scalability of RL pipelines. To this end, we propose a novel Text-to-SQL RL fine-tuning framework named Graph-Reward-SQL, which employs the GMNScore outcome reward model. We leverage SQL graph representations to provide accurate reward signals while significantly reducing inference time and GPU memory usage. Building on this foundation, we further introduce StepRTM, a stepwise reward model that provides intermediate supervision over Common Table Expression (CTE) subqueries. This encourages both functional correctness and structural clarity of SQL. Extensive comparative and ablation experiments on standard benchmarks, including Spider and BIRD, demonstrate that our method consistently outperforms existing reward models.",
      "authors": [
        "Han Weng",
        "Puzhen Wu",
        "Cui Longjie",
        "Yi Zhan",
        "Boyi Liu",
        "Yuanfeng Song",
        "Dun Zeng",
        "Yingxiang Yang",
        "Qianru Zhang",
        "Dong Huang",
        "Xiaoming Yin",
        "Yang Sun",
        "Xing Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Databases (cs.DB)",
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-18T11:53:01+00:00",
          "link": "https://arxiv.org/abs/2505.12380v1",
          "size": "1283kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T12:45:33+00:00",
          "link": "https://arxiv.org/abs/2505.12380v2",
          "size": "1283kb",
          "version": "v2"
        }
      ],
      "title": "Graph-Reward-SQL: Execution-Free Reinforcement Learning for Text-to-SQL via Graph Matching and Stepwise Reward",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.12380",
        "HTML": "https://arxiv.org/html/2505.12380v2",
        "PDF": "https://arxiv.org/pdf/2505.12380"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper focuses on a reinforcement learning framework for Text-to-SQL tasks, which involves fine-tuning but not the core aspects of LLM training data engineering or novel data processing methods."
      },
      "tasks": [
        "Graph Matching",
        "Reinforcement Learning (RL)",
        "Text to SQL",
        "Text-To-SQL"
      ],
      "repo_urls": [
        "https://github.com/taoyds/test-suite-sql-eval"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.13232",
      "abstract": "Learning robust representations from data often requires scale, which has led to the success of recent zero-shot models such as CLIP. However, the obtained robustness can easily be deteriorated when these models are fine-tuned on other downstream tasks (e.g., of smaller scales). Previous works often interpret this phenomenon in the context of domain shift, developing fine-tuning methods that aim to preserve the original domain as much as possible. However, in a different context, fine-tuned models with limited data are also prone to learning features that are spurious to humans, such as background or texture. In this paper, we propose StarFT (Spurious Textual Alignment Regularization), a novel framework for fine-tuning zero-shot models to enhance robustness by preventing them from learning spuriosity. We introduce a regularization that aligns the output distribution for spuriosity-injected labels with the original zero-shot model, ensuring that the model is not induced to extract irrelevant features further from these descriptions. We leverage recent language models to get such spuriosity-injected labels by generating alternative textual descriptions that highlight potentially confounding features. Extensive experiments validate the robust generalization of StarFT and its emerging properties: zero-shot group robustness and improved zero-shot classification. Notably, StarFT boosts both worst-group and average accuracy by 14.30% and 3.02%, respectively, in the Waterbirds group shift scenario, where other robust fine-tuning baselines show even degraded performance.",
      "authors": [
        "Younghyun Kim",
        "Jongheon Jeong",
        "Sangkyung Kwak",
        "Kyungmin Lee",
        "Juho Lee",
        "Jinwoo Shin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-19T15:15:35+00:00",
          "link": "https://arxiv.org/abs/2505.13232v1",
          "size": "396kb",
          "version": "v1"
        },
        {
          "date": "2025-05-20T12:27:33+00:00",
          "link": "https://arxiv.org/abs/2505.13232v2",
          "size": "396kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T13:19:58+00:00",
          "link": "https://arxiv.org/abs/2505.13232v3",
          "size": "360kb",
          "version": "v3"
        }
      ],
      "title": "StarFT: Robust Fine-tuning of Zero-shot Models via Spuriosity Alignment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.13232",
        "HTML": "https://arxiv.org/html/2505.13232v3",
        "PDF": "https://arxiv.org/pdf/2505.13232"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses a novel framework for fine-tuning zero-shot models to prevent learning spuriosity. It indirectly relates to training data processing by introducing spurious textual alignment regularization but does not propose novel data collection or construction techniques."
      },
      "tasks": [
        "Zero-Shot Learning"
      ],
      "repo_urls": [
        "https://github.com/alinlab/starft"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.17066",
      "abstract": "Using LLMs in a production environment presents security challenges that include vulnerabilities to jailbreaks and prompt injections, which can result in harmful outputs for humans or the enterprise. The challenge is amplified when working within a specific domain, as topics generally accepted for LLMs to address may be irrelevant to that field. These problems can be mitigated, for example, by fine-tuning large language models with domain-specific and security-focused data. However, these alone are insufficient, as jailbreak techniques evolve. Additionally, API-accessed models do not offer the flexibility needed to tailor behavior to industry-specific objectives, and in-context learning is not always sufficient or reliable. In response to these challenges, we introduce Archias, an expert model adept at distinguishing between in-domain and out-of-domain communications. Archias classifies user inquiries into several categories: in-domain (specifically for the automotive industry), malicious questions, price injections, prompt injections, and out-of-domain examples. Our methodology integrates outputs from the expert model (Archias) into prompts, which are then processed by the LLM to generate responses. This method increases the model's ability to understand the user's intention and give appropriate answers. Archias can be adjusted, fine-tuned, and used for many different purposes due to its small size. Therefore, it can be easily customized to the needs of any industry. To validate our approach, we created a benchmark dataset for the automotive industry. Furthermore, in the interest of advancing research and development, we release our benchmark dataset to the community.",
      "authors": [
        "Tatia Tsmindashvili",
        "Ana Kolkhidashvili",
        "Dachi Kurtskhalia",
        "Nino Maghlakelidze",
        "Elene Mekvabishvili",
        "Guram Dentoshvili",
        "Orkhan Shamilov",
        "Zaal Gachechiladze",
        "Steven Saporta",
        "David Dachi Choladze"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-18T16:13:07+00:00",
          "link": "https://arxiv.org/abs/2505.17066v1",
          "size": "3397kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T10:04:25+00:00",
          "link": "https://arxiv.org/abs/2505.17066v2",
          "size": "3397kb",
          "version": "v2"
        }
      ],
      "title": "Improving LLM Outputs Against Jailbreak Attacks with Expert Model Integration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.17066",
        "HTML": "https://arxiv.org/html/2505.17066v2",
        "PDF": "https://arxiv.org/pdf/2505.17066"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper mentions fine-tuning LLMs with domain-specific and security-focused data to mitigate security vulnerabilities, but its primary focus is on integrating an expert model for security rather than proposing new methods for LLM training data processing."
      },
      "tasks": [
        "In-Context Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.18746",
      "abstract": "Agents based on large language models leverage tools to modify environments, revolutionizing how AI interacts with the physical world. Unlike traditional NLP tasks that rely solely on historical dialogue for responses, these agents must consider more complex factors, such as inter-tool relationships, environmental feedback and previous decisions, when making choices. Current research typically evaluates agents via multi-turn dialogues. However, it overlooks the influence of these critical factors on agent behavior. To bridge this gap, we present an open-source and high-quality benchmark $C^3$-Bench. This benchmark integrates attack concepts and applies univariate analysis to pinpoint key elements affecting agent robustness. In concrete, we design three challenges: navigate complex tool relationships, handle critical hidden information and manage dynamic decision paths. Complementing these challenges, we introduce fine-grained metrics, innovative data collection algorithms and reproducible evaluation methods. Extensive experiments are conducted on 49 mainstream agents, encompassing general fast-thinking, slow-thinking and domain-specific models. We observe that agents have significant shortcomings in handling tool dependencies, long context information dependencies and frequent policy-type switching. In essence, $C^3$-Bench aims to expose model vulnerabilities through these challenges and drive research into the interpretability of agent performance. The benchmark is publicly available at https://github.com/TencentHunyuan/C3-Benchmark.",
      "authors": [
        "Peijie Yu",
        "Yifan Yang",
        "Jinjian Li",
        "Zelong Zhang",
        "Haorui Wang",
        "Xiao Feng",
        "Feng Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-24T15:25:44+00:00",
          "link": "https://arxiv.org/abs/2505.18746v1",
          "size": "6919kb",
          "version": "v1"
        },
        {
          "date": "2025-05-27T02:22:28+00:00",
          "link": "https://arxiv.org/abs/2505.18746v2",
          "size": "6918kb",
          "version": "v2"
        },
        {
          "date": "2025-06-25T10:37:25+00:00",
          "link": "https://arxiv.org/abs/2505.18746v3",
          "size": "6575kb",
          "version": "v3"
        },
        {
          "date": "2025-06-27T03:58:25+00:00",
          "link": "https://arxiv.org/abs/2505.18746v4",
          "size": "6575kb",
          "version": "v4"
        }
      ],
      "title": "$C^3$-Bench: The Things Real Disturbing LLM based Agent in Multi-Tasking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.18746",
        "HTML": "https://arxiv.org/html/2505.18746v4",
        "PDF": "https://arxiv.org/pdf/2505.18746"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper presents a benchmark for evaluating LLM-based agents and mentions data collection algorithms; however, it focuses on agent evaluation rather than novel contributions in LLM training data engineering or processing."
      },
      "tasks": [
        "Navigate"
      ],
      "repo_urls": [
        "https://github.com/yupeijei1997/c3-bench"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.19897",
      "abstract": "Large Language Models (LLMs) have extended their impact beyond Natural Language Processing, substantially fostering the development of interdisciplinary research. Recently, various LLM-based agents have been developed to assist scientific discovery progress across multiple aspects and domains. Among these, computer-using agents, capable of interacting with operating systems as humans do, are paving the way to automated scientific problem-solving and addressing routines in researchers' workflows. Recognizing the transformative potential of these agents, we introduce ScienceBoard, which encompasses two complementary contributions: (i) a realistic, multi-domain environment featuring dynamic and visually rich scientific workflows with integrated professional software, where agents can autonomously interact via different interfaces to accelerate complex research tasks and experiments; and (ii) a challenging benchmark of 169 high-quality, rigorously validated real-world tasks curated by humans, spanning scientific-discovery workflows in domains such as biochemistry, astronomy, and geoinformatics. Extensive evaluations of agents with state-of-the-art backbones (e.g., GPT-4o, Claude 3.7, UI-TARS) show that, despite some promising results, they still fall short of reliably assisting scientists in complex workflows, achieving only a 15% overall success rate. In-depth analysis further provides valuable insights for addressing current agent limitations and more effective design principles, paving the way to build more capable agents for scientific discovery. Our code, environment, and benchmark are at https://qiushisun.github.io/ScienceBoard-Home/.",
      "authors": [
        "Qiushi Sun",
        "Zhoumianze Liu",
        "Chang Ma",
        "Zichen Ding",
        "Fangzhi Xu",
        "Zhangyue Yin",
        "Haiteng Zhao",
        "Zhenyu Wu",
        "Kanzhi Cheng",
        "Zhaoyang Liu",
        "Jianing Wang",
        "Qintong Li",
        "Xiangru Tang",
        "Tianbao Xie",
        "Xiachong Feng",
        "Xiang Li",
        "Ben Kao",
        "Wenhai Wang",
        "Biqing Qi",
        "Lingpeng Kong",
        "Zhiyong Wu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-26T12:27:27+00:00",
          "link": "https://arxiv.org/abs/2505.19897v1",
          "size": "16808kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T09:38:03+00:00",
          "link": "https://arxiv.org/abs/2505.19897v2",
          "size": "13950kb",
          "version": "v2"
        }
      ],
      "title": "ScienceBoard: Evaluating Multimodal Autonomous Agents in Realistic Scientific Workflows",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.19897",
        "HTML": "https://arxiv.org/html/2505.19897v2",
        "PDF": "https://arxiv.org/pdf/2505.19897"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper introduces ScienceBoard for evaluating LLM-based agents in scientific workflows. It focuses on agent performance assessment rather than LLM training data processing or engineering."
      },
      "models": [
        {
          "model_path": "OS-Copilot/ScienceBoard-Env",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/OS-Copilot/ScienceBoard-Env"
        }
      ],
      "tasks": [
        "Astronomy",
        "scientific discovery"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.20888",
      "abstract": "In this paper, we present EasyDistill, a comprehensive toolkit designed for effective black-box and white-box knowledge distillation (KD) of large language models (LLMs). Our framework offers versatile functionalities, including data synthesis, supervised fine-tuning, ranking optimization, and reinforcement learning techniques specifically tailored for KD scenarios. The toolkit accommodates KD functionalities for both System 1 (fast, intuitive) and System 2 (slow, analytical) models. With its modular design and user-friendly interface, EasyDistill empowers researchers and industry practitioners to seamlessly experiment with and implement state-of-the-art KD strategies for LLMs. In addition, EasyDistill provides a series of robust distilled models and KD-based industrial solutions developed by us, along with the corresponding open-sourced datasets, catering to a variety of use cases. Furthermore, we describe the seamless integration of EasyDistill into Alibaba Cloud's Platform for AI (PAI). Overall, the EasyDistill toolkit makes advanced KD techniques for LLMs more accessible and impactful within the NLP community.",
      "authors": [
        "Chengyu Wang",
        "Junbing Yan",
        "Wenrui Cai",
        "Yuanhao Yue",
        "Jun Huang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-27T08:32:51+00:00",
          "link": "https://arxiv.org/abs/2505.20888v1",
          "size": "1064kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T07:59:43+00:00",
          "link": "https://arxiv.org/abs/2505.20888v2",
          "size": "82kb",
          "version": "v2"
        }
      ],
      "title": "EasyDistill: A Comprehensive Toolkit for Effective Knowledge Distillation of Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.20888",
        "HTML": "https://arxiv.org/html/2505.20888v2",
        "PDF": "https://arxiv.org/pdf/2505.20888"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces EasyDistill, a toolkit for knowledge distillation of LLMs, including data synthesis and supervised fine-tuning. It relates to training-stage data processing but does not primarily contribute new methods for LLM training data construction or quality enhancement."
      },
      "tasks": [
        "Knowledge Distillation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.21360",
      "abstract": "Competing risks are crucial considerations in survival modelling, particularly in healthcare domains where patients may experience multiple distinct event types. We propose CRISP-NAM (Competing Risks Interpretable Survival Prediction with Neural Additive Models), an interpretable neural additive model for competing risks survival analysis which extends the neural additive architecture to model cause-specific hazards while preserving feature-level interpretability. Each feature contributes independently to risk estimation through dedicated neural networks, allowing for visualization of complex non-linear relationships between covariates and each competing risk. We demonstrate competitive performance on multiple datasets compared to existing approaches.",
      "authors": [
        "Dhanesh Ramachandram and Ananya Raval"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-27T15:52:15+00:00",
          "link": "https://arxiv.org/abs/2505.21360v1",
          "size": "789kb",
          "version": "v1"
        },
        {
          "date": "2025-06-06T12:41:47+00:00",
          "link": "https://arxiv.org/abs/2505.21360v2",
          "size": "789kb",
          "version": "v2"
        },
        {
          "date": "2025-06-26T18:49:10+00:00",
          "link": "https://arxiv.org/abs/2505.21360v3",
          "size": "1226kb",
          "version": "v3"
        }
      ],
      "title": "CRISP-NAM: Competing Risks Interpretable Survival Prediction with Neural Additive Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.21360",
        "HTML": "https://arxiv.org/html/2505.21360v3",
        "PDF": "https://arxiv.org/pdf/2505.21360"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on survival prediction in healthcare using neural additive models, with no mention of processing training data for large language models or related methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.22660",
      "abstract": "Reinforcement learning (RL) has enabled machine learning models to achieve significant advances in many fields. Most recently, RL has empowered frontier language models to solve challenging math, science, and coding problems. However, central to any RL algorithm is the reward function, and reward engineering is a notoriously difficult problem in any domain. In this paper, we propose RENT: Reinforcement Learning via Entropy Minimization -- a fully unsupervised RL method that requires no external reward or ground-truth answers, and instead uses the model's entropy of its underlying distribution as an intrinsic reward. We find that by reinforcing the chains of thought that yield high model confidence on its generated answers, the model improves its reasoning ability. In our experiments, we showcase these improvements on an extensive suite of commonly-used reasoning benchmarks, including GSM8K, MATH500, AMC, AIME, and GPQA, and models of varying sizes from the Qwen, Mistral, and Llama families. The generality of our unsupervised learning method lends itself to applicability in a wide range of domains where external supervision is unavailable.",
      "authors": [
        "Mihir Prabhudesai",
        "Lili Chen",
        "Alex Ippoliti",
        "Katerina Fragkiadaki",
        "Hao Liu",
        "Deepak Pathak"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-28T17:59:37+00:00",
          "link": "https://arxiv.org/abs/2505.22660v1",
          "size": "413kb",
          "version": "v1"
        },
        {
          "date": "2025-05-29T17:14:34+00:00",
          "link": "https://arxiv.org/abs/2505.22660v2",
          "size": "413kb",
          "version": "v2"
        },
        {
          "date": "2025-06-23T16:30:04+00:00",
          "link": "https://arxiv.org/abs/2505.22660v3",
          "size": "966kb",
          "version": "v3"
        },
        {
          "date": "2025-06-27T17:25:28+00:00",
          "link": "https://arxiv.org/abs/2505.22660v4",
          "size": "1160kb",
          "version": "v4"
        }
      ],
      "title": "Maximizing Confidence Alone Improves Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.22660",
        "HTML": "https://arxiv.org/html/2505.22660v4",
        "PDF": "https://arxiv.org/pdf/2505.22660"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper addresses unsupervised reinforcement learning to improve reasoning, without discussing any data-related methods specific to training large language models."
      },
      "tasks": [
        "GSM8K",
        "Math",
        "reinforcement-learning",
        "Reinforcement Learning",
        "Reinforcement Learning (RL)"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.23224",
      "abstract": "In recent years, multimodal large language models (MLLMs) have made significant progress but continue to face inherent challenges in multimodal reasoning, which requires multi-level (e.g., perception, reasoning) and multi-granular (e.g., multi-step reasoning chain) advanced inferencing. Prior work on estimating model confidence tends to focus on the overall response for training and calibration, but fails to assess confidence in each reasoning step, leading to undesirable hallucination snowballing. In this work, we present MMBoundary, a novel framework that advances the knowledge boundary awareness of MLLMs through reasoning step confidence calibration. To achieve this, we propose to incorporate complementary textual and cross-modal self-rewarding signals to estimate confidence at each step of the MLLM reasoning process. In addition to supervised fine-tuning MLLM on this set of self-rewarded confidence estimation signal for initial confidence expression warm-up, we introduce a reinforcement learning stage with multiple reward functions for further aligning model knowledge and calibrating confidence at each reasoning step, enhancing reasoning chain self-correction. Empirical results show that MMBoundary significantly outperforms existing methods across diverse domain datasets and metrics, achieving an average of 7.5% reduction in multimodal confidence calibration errors and up to 8.3% improvement in task performance.",
      "authors": [
        "Zhitao He",
        "Sandeep Polisetty",
        "Zhiyuan Fan",
        "Yuchen Huang",
        "Shujin Wu",
        "Yi R. Fung"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-29T08:14:40+00:00",
          "link": "https://arxiv.org/abs/2505.23224v1",
          "size": "1445kb",
          "version": "v1"
        },
        {
          "date": "2025-06-05T16:19:56+00:00",
          "link": "https://arxiv.org/abs/2505.23224v2",
          "size": "1446kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T08:40:06+00:00",
          "link": "https://arxiv.org/abs/2505.23224v3",
          "size": "1445kb",
          "version": "v3"
        }
      ],
      "title": "MMBoundary: Advancing MLLM Knowledge Boundary Awareness through Reasoning Step Confidence Calibration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.23224",
        "HTML": "https://arxiv.org/html/2505.23224v3",
        "PDF": "https://arxiv.org/pdf/2505.23224"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This work introduces a framework for confidence calibration in multimodal language models, but it does not detail any data processing or preparation methods for LLM training data."
      },
      "tasks": [
        "Hallucination",
        "Multimodal Reasoning"
      ],
      "repo_urls": [
        "https://github.com/zhitao-he/mmboundary"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.23341",
      "abstract": "Whole-slide images (WSIs) are critical for cancer diagnosis due to their ultra-high resolution and rich semantic content. However, their massive size and the limited availability of fine-grained annotations pose substantial challenges for conventional supervised learning. We propose DSAGL (Dual-Stream Attention-Guided Learning), a novel weakly supervised classification framework that combines a teacher-student architecture with a dual-stream design. DSAGL explicitly addresses instance-level ambiguity and bag-level semantic consistency by generating multi-scale attention-based pseudo labels and guiding instance-level learning. A shared lightweight encoder (VSSMamba) enables efficient long-range dependency modeling, while a fusion-attentive module (FASA) enhances focus on sparse but diagnostically relevant regions. We further introduce a hybrid loss to enforce mutual consistency between the two streams. Experiments on CIFAR-10, NCT-CRC, and TCGA-Lung datasets demonstrate that DSAGL consistently outperforms state-of-the-art MIL baselines, achieving superior discriminative performance and robustness under weak supervision.",
      "authors": [
        "Daoxi Cao",
        "Hangbei Cheng",
        "Yijin Li",
        "Ruolin Zhou",
        "Xuehan Zhang",
        "Xinyi Li",
        "Binwei Li",
        "Xuancheng Gu",
        "Jianan Zhang",
        "Xueyu Liu",
        "Yongfei Wu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-29T11:07:16+00:00",
          "link": "https://arxiv.org/abs/2505.23341v1",
          "size": "1932kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T07:34:36+00:00",
          "link": "https://arxiv.org/abs/2505.23341v2",
          "size": "1893kb",
          "version": "v2"
        }
      ],
      "title": "DSAGL: Dual-Stream Attention-Guided Learning for Weakly Supervised Whole Slide Image Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.23341",
        "HTML": "https://arxiv.org/html/2505.23341v2",
        "PDF": "https://arxiv.org/pdf/2505.23341"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The research is focused on weakly supervised image classification using whole-slide images, with no relevance to training data processing for large language models."
      },
      "tasks": [
        "image-classification",
        "Image Classification",
        "Weakly Supervised Classification",
        "whole slide images"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.24007",
      "abstract": "Visual hallucinations in Large Language Models (LLMs), where the model generates responses that are inconsistent with the visual input, pose a significant challenge to their reliability, particularly in contexts where precise and trustworthy outputs are critical. Current research largely emphasizes post-hoc correction or model-specific fine-tuning strategies, with limited exploration of preprocessing techniques to address hallucination issues at the input stage. This study presents a novel ensemble-based preprocessing framework that adaptively selects the most appropriate filtering approach -- noise reduced (NR), edge enhanced (EE), or unaltered input (org) based on the type of question posed, resulting into reduced hallucination without requiring any modifications to the underlying model architecture or training pipeline. Evaluated on the `HaloQuest' dataset -- a benchmark designed to test multimodal reasoning on visually complex inputs, our method achieves a 44.3% reduction in hallucination rates, as measured by Natural Language Inference (NLI) scores using SelfCheckGPT. This demonstrates that intelligent input conditioning alone can significantly enhance factual grounding in LLM responses. The findings highlight the importance of adaptive preprocessing techniques in mitigating hallucinations, paving the way for more reliable multimodal systems capable of addressing real-world challenges.",
      "authors": [
        "Nokimul Hasan Arif",
        "Shadman Rabby",
        "Md Hefzul Hossain Papon",
        "and Sabbir Ahmed"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-29T21:09:34+00:00",
          "link": "https://arxiv.org/abs/2505.24007v1",
          "size": "32922kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T07:20:04+00:00",
          "link": "https://arxiv.org/abs/2505.24007v2",
          "size": "34404kb",
          "version": "v2"
        }
      ],
      "title": "Preemptive Hallucination Reduction: An Input-Level Approach for Multimodal Language Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.24007",
        "HTML": "https://arxiv.org/html/2505.24007v2",
        "PDF": "https://arxiv.org/pdf/2505.24007"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces an input-level preprocessing framework that reduces hallucinations in LLMs, focusing on data filtering tasks (noise reduction and edge enhancement) which are part of the data engineering stage for LLM data processing."
      },
      "tasks": [
        "Hallucination",
        "Language Modeling",
        "Language Modelling",
        "Multimodal Reasoning",
        "Natural Language Inference"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.24403",
      "abstract": "The Lipschitz constant of a neural network is connected to several important properties of the network such as its robustness and generalization. It is thus useful in many settings to estimate the Lipschitz constant of a model. Prior work has focused mainly on estimating the Lipschitz constant of multi-layer perceptrons and convolutional neural networks. Here we focus on data modeled as sets or multisets of vectors and on neural networks that can handle such data. These models typically apply some permutation invariant aggregation function, such as the sum, mean or max operator, to the input multisets to produce a single vector for each input sample. In this paper, we investigate whether these aggregation functions are Lipschitz continuous with respect to three distance functions for unordered multisets, and we compute their Lipschitz constants. In the general case, we find that each aggregation function is Lipschitz continuous with respect to only one of the three distance functions. Then, we build on these results to derive upper bounds on the Lipschitz constant of neural networks that can process multisets of vectors, while we also study their stability to perturbations and generalization under distribution shifts. To empirically verify our theoretical analysis, we conduct a series of experiments on datasets from different domains.",
      "authors": [
        "Giannis Nikolentzos",
        "Konstantinos Skianis"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-30T09:34:58+00:00",
          "link": "https://arxiv.org/abs/2505.24403v1",
          "size": "12424kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T06:58:00+00:00",
          "link": "https://arxiv.org/abs/2505.24403v2",
          "size": "12424kb",
          "version": "v2"
        }
      ],
      "title": "On the Lipschitz Continuity of Set Aggregation Functions and Neural Networks for Sets",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.24403",
        "HTML": "https://arxiv.org/html/2505.24403v2",
        "PDF": "https://arxiv.org/pdf/2505.24403"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on theoretical aspects of Lipschitz continuity in neural networks for sets, without discussing any aspects of LLM training data collection, construction, or processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2505.24616",
      "abstract": "We introduce POLLUX, a comprehensive open-source benchmark designed to evaluate the generative capabilities of large language models (LLMs) in Russian. Our main contribution is a novel evaluation methodology that enhances the interpretability of LLM assessment. For each task type, we define a set of detailed criteria and develop a scoring protocol where models evaluate responses and provide justifications for their ratings. This enables transparent, criteria-driven evaluation beyond traditional resource-consuming, side-by-side human comparisons. POLLUX includes a detailed, fine-grained taxonomy of 35 task types covering diverse generative domains such as code generation, creative writing, and practical assistant use cases, totaling 2,100 manually crafted and professionally authored prompts. Each task is categorized by difficulty (easy/medium/hard), with experts constructing the dataset entirely from scratch. We also release a family of LLM-as-a-Judge (7B and 32B) evaluators trained for nuanced assessment of generative outputs. This approach provides scalable, interpretable evaluation and annotation tools for model development, effectively replacing costly and less precise human judgments.",
      "authors": [
        "Nikita Martynov",
        "Anastasia Mordasheva",
        "Dmitriy Gorbetskiy",
        "Danil Astafurov",
        "Ulyana Isaeva",
        "Elina Basyrova",
        "Sergey Skachkov",
        "Victoria Berestova",
        "Nikolay Ivanov",
        "Valeriia Zanina",
        "Alena Fenogenova"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-30T14:08:17+00:00",
          "link": "https://arxiv.org/abs/2505.24616v1",
          "size": "12953kb",
          "version": "v1"
        },
        {
          "date": "2025-06-23T15:01:31+00:00",
          "link": "https://arxiv.org/abs/2505.24616v2",
          "size": "31523kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T11:43:03+00:00",
          "link": "https://arxiv.org/abs/2505.24616v3",
          "size": "31522kb",
          "version": "v3"
        }
      ],
      "title": "Eye of Judgement: Dissecting the Evaluation of Russian-speaking LLMs with POLLUX",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.24616",
        "PDF": "https://arxiv.org/pdf/2505.24616"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper establishes a benchmark for evaluating LLMs and includes professionally authored prompts. However, it does not propose new data collection or preprocessing methods specific to LLM training data."
      },
      "tasks": [
        "Code Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.01563",
      "abstract": "Effective human-robot interaction requires robots to identify human intentions and generate expressive, socially appropriate motions in real-time. Existing approaches often rely on fixed motion libraries or computationally expensive generative models. We propose a hierarchical framework that combines intention-aware reasoning via in-context learning (ICL) with real-time motion generation using diffusion models. Our system introduces structured prompting with confidence scoring, fallback behaviors, and social context awareness to enable intention refinement and adaptive response. Leveraging large-scale motion datasets and efficient latent-space denoising, the framework generates diverse, physically plausible gestures suitable for dynamic humanoid interactions. Experimental validation on a physical platform demonstrates the robustness and social alignment of our method in realistic scenarios.",
      "authors": [
        "Lingfan Bao",
        "Yan Pan",
        "Tianhu Peng",
        "Dimitrios Kanoulas and Chengxu Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-02T11:42:51+00:00",
          "link": "https://arxiv.org/abs/2506.01563v1",
          "size": "3721kb",
          "version": "v1"
        },
        {
          "date": "2025-06-05T21:25:18+00:00",
          "link": "https://arxiv.org/abs/2506.01563v2",
          "size": "755kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T09:21:23+00:00",
          "link": "https://arxiv.org/abs/2506.01563v3",
          "size": "755kb",
          "version": "v3"
        }
      ],
      "title": "Hierarchical Intention-Aware Expressive Motion Generation for Humanoid Robots",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.01563",
        "HTML": "https://arxiv.org/html/2506.01563v3",
        "PDF": "https://arxiv.org/pdf/2506.01563"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This research presents a method for real-time humanoid robot interaction, and while it uses large-scale motion datasets, it does not address LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.05520",
      "abstract": "Contemporary businesses operate in dynamic environments requiring rapid adaptation to achieve goals and maintain competitiveness. Existing data platforms often fall short by emphasizing tools over alignment with business needs, resulting in inefficiencies and delays. To address this gap, I propose the Business Semantics Centric, AI Agents Assisted Data System (BSDS), a holistic system that integrates architecture, workflows, and team organization to ensure data systems are tailored to business priorities rather than dictated by technical constraints. BSDS redefines data systems as dynamic enablers of business success, transforming them from passive tools into active drivers of organizational growth. BSDS has a modular architecture that comprises curated data linked to business entities, a knowledge base for context-aware AI agents, and efficient data pipelines. AI agents play a pivotal role in assisting with data access and system management, reducing human effort, and improving scalability. Complementing this architecture, BSDS incorporates workflows optimized for both exploratory data analysis and production requirements, balancing speed of delivery with quality assurance. A key innovation of BSDS is its incorporation of the human factor. By aligning data team expertise with business semantics, BSDS bridges the gap between technical capabilities and business needs. Validated through real-world implementation, BSDS accelerates time-to-market for data-driven initiatives, enhances cross-functional collaboration, and provides a scalable blueprint for businesses of all sizes. Future research can build on BSDS to explore optimization strategies using complex systems and adaptive network theories, as well as developing autonomous data systems leveraging AI agents.",
      "authors": [
        "Cecil Pang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-05T19:06:06+00:00",
          "link": "https://arxiv.org/abs/2506.05520v1",
          "size": "1030kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T15:49:26+00:00",
          "link": "https://arxiv.org/abs/2506.05520v2",
          "size": "1014kb",
          "version": "v2"
        }
      ],
      "title": "Toward Data Systems That Are Business Semantic Centric and AI Agents Assisted",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.05520",
        "PDF": "https://arxiv.org/pdf/2506.05520"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses the Business Semantics Centric, AI Agents Assisted Data System (BSDS), which includes curated data linked to business entities and efficient data pipelines. Although it emphasizes data systems tailored to business priorities, it doesn't directly focus on LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2506.05527",
      "abstract": "N-agent ad hoc teamwork (NAHT) is a newly introduced challenge in multi-agent reinforcement learning, where controlled subteams of varying sizes must dynamically collaborate with varying numbers and types of unknown teammates without pre-coordination. The existing learning algorithm (POAM) considers only independent learning for its flexibility in dealing with a changing number of agents. However, independent learning fails to fully capture the inter-agent dynamics essential for effective collaboration. Based on our observation that transformers deal effectively with sequences with varying lengths and have been shown to be highly effective for a variety of machine learning problems, this work introduces a centralized, transformer-based method for N-agent ad hoc teamwork. Our proposed approach incorporates historical observations and actions of all controlled agents, enabling optimal responses to diverse and unseen teammates in partially observable environments. Empirical evaluation on a StarCraft II task demonstrates that MAT-NAHT outperforms POAM, achieving superior sample efficiency and generalization, without auxiliary agent-modeling objectives.",
      "authors": [
        "Caroline Wang",
        "Di Yang Shi",
        "Elad Liebman",
        "Ishan Durugkar",
        "Arrasy Rahman",
        "Peter Stone"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-05T19:20:12+00:00",
          "link": "https://arxiv.org/abs/2506.05527v1",
          "size": "208kb",
          "version": "v1"
        },
        {
          "date": "2025-06-26T21:03:17+00:00",
          "link": "https://arxiv.org/abs/2506.05527v2",
          "size": "169kb",
          "version": "v2"
        }
      ],
      "title": "Sequence Modeling for N-Agent Ad Hoc Teamwork",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.05527",
        "HTML": "https://arxiv.org/html/2506.05527v2",
        "PDF": "https://arxiv.org/pdf/2506.05527"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on a transformer-based method for N-agent ad hoc teamwork in multi-agent reinforcement learning, without any mention of LLM training data processing or data engineering stages."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.05844",
      "abstract": "Network Intrusion Detection Systems (NIDS) face challenges due to class imbalance, affecting their ability to detect novel and rare attacks. This paper proposes a Dual-Conditional Batch Normalization Variational Autoencoder ($\\text{C}^{2}\\text{BNVAE}$) for generating balanced and labeled network traffic data. $\\text{C}^{2}\\text{BNVAE}$ improves the model's adaptability to different data categories and generates realistic category-specific data by incorporating Conditional Batch Normalization (CBN) into the Conditional Variational Autoencoder (CVAE). Experiments on the NSL-KDD dataset show the potential of $\\text{C}^{2}\\text{BNVAE}$ in addressing imbalance and improving NIDS performance with lower computational overhead compared to some baselines.",
      "authors": [
        "Yifan Zeng"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-06T08:01:17+00:00",
          "link": "https://arxiv.org/abs/2506.05844v1",
          "size": "176kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T12:12:51+00:00",
          "link": "https://arxiv.org/abs/2506.05844v2",
          "size": "176kb",
          "version": "v2"
        }
      ],
      "title": "$\\text{C}^{2}\\text{BNVAE}$: Dual-Conditional Deep Generation of Network Traffic Data for Network Intrusion Detection System Balancing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.05844",
        "HTML": "https://arxiv.org/html/2506.05844v2",
        "PDF": "https://arxiv.org/pdf/2506.05844"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper is centered around generating network traffic data using a Dual-Conditional Variational Autoencoder for network intrusion detection, and does not discuss LLM training data processing or related data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.08010",
      "abstract": "We investigate the mechanism underlying a previously identified phenomenon in Vision Transformers -- the emergence of high-norm tokens that lead to noisy attention maps. We observe that in multiple models (e.g., CLIP, DINOv2), a sparse set of neurons is responsible for concentrating high-norm activations on outlier tokens, leading to irregular attention patterns and degrading downstream visual processing. While the existing solution for removing these outliers involves retraining models from scratch with additional learned register tokens, we use our findings to create a training-free approach to mitigate these artifacts. By shifting the high-norm activations from our discovered register neurons into an additional untrained token, we can mimic the effect of register tokens on a model already trained without registers. We demonstrate that our method produces cleaner attention and feature maps, enhances performance over base models across multiple downstream visual tasks, and achieves results comparable to models explicitly trained with register tokens. We then extend test-time registers to off-the-shelf vision-language models to improve their interpretability. Our results suggest that test-time registers effectively take on the role of register tokens at test-time, offering a training-free solution for any pre-trained model released without them.",
      "authors": [
        "Nick Jiang",
        "Amil Dravid",
        "Alexei Efros",
        "Yossi Gandelsman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-09T17:59:57+00:00",
          "link": "https://arxiv.org/abs/2506.08010v1",
          "size": "5442kb",
          "version": "v1"
        },
        {
          "date": "2025-06-10T22:38:32+00:00",
          "link": "https://arxiv.org/abs/2506.08010v2",
          "size": "5442kb",
          "version": "v2"
        },
        {
          "date": "2025-06-18T16:30:46+00:00",
          "link": "https://arxiv.org/abs/2506.08010v3",
          "size": "5612kb",
          "version": "v3"
        },
        {
          "date": "2025-06-27T17:37:09+00:00",
          "link": "https://arxiv.org/abs/2506.08010v4",
          "size": "5909kb",
          "version": "v4"
        }
      ],
      "title": "Vision Transformers Don't Need Trained Registers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.08010",
        "HTML": "https://arxiv.org/html/2506.08010v4",
        "PDF": "https://arxiv.org/pdf/2506.08010"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The study investigates Vision Transformers and high-norm tokens affecting attention maps, offering a training-free solution for existing vision models. It doesn't address LLM training data processing or data engineering."
      },
      "models": [
        {
          "model_path": "amildravid4292/clip-vitb16-test-time-registers",
          "downloads": "666",
          "likes": "1",
          "trending_score": "1.0",
          "link": "https://huggingface.co/amildravid4292/clip-vitb16-test-time-registers"
        },
        {
          "model_path": "amildravid4292/clip-vitl14-test-time-registers",
          "downloads": "284",
          "likes": "1",
          "trending_score": "1.0",
          "link": "https://huggingface.co/amildravid4292/clip-vitl14-test-time-registers"
        },
        {
          "model_path": "amildravid4292/llava-llama-3-8b-test-time-registers",
          "downloads": "67",
          "likes": "1",
          "trending_score": "1.0",
          "link": "https://huggingface.co/amildravid4292/llava-llama-3-8b-test-time-registers"
        }
      ],
      "tasks": [],
      "repo_urls": [
        "https://github.com/nickjiang2378/test-time-registers"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.08134",
      "abstract": "Peer review, the bedrock of scientific advancement in machine learning (ML), is strained by a crisis of scale. Exponential growth in manuscript submissions to premier ML venues such as NeurIPS, ICML, and ICLR is outpacing the finite capacity of qualified reviewers, leading to concerns about review quality, consistency, and reviewer fatigue. This position paper argues that AI-assisted peer review must become an urgent research and infrastructure priority. We advocate for a comprehensive AI-augmented ecosystem, leveraging Large Language Models (LLMs) not as replacements for human judgment, but as sophisticated collaborators for authors, reviewers, and Area Chairs (ACs). We propose specific roles for AI in enhancing factual verification, guiding reviewer performance, assisting authors in quality improvement, and supporting ACs in decision-making. Crucially, we contend that the development of such systems hinges on access to more granular, structured, and ethically-sourced peer review process data. We outline a research agenda, including illustrative experiments, to develop and validate these AI assistants, and discuss significant technical and ethical challenges. We call upon the ML community to proactively build this AI-assisted future, ensuring the continued integrity and scalability of scientific validation, while maintaining high standards of peer review.",
      "authors": [
        "Qiyao Wei",
        "Samuel Holt",
        "Jing Yang",
        "Markus Wulfmeier",
        "Mihaela van der Schaar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-09T18:37:14+00:00",
          "link": "https://arxiv.org/abs/2506.08134v1",
          "size": "1122kb",
          "version": "v1"
        },
        {
          "date": "2025-06-18T23:48:35+00:00",
          "link": "https://arxiv.org/abs/2506.08134v2",
          "size": "1123kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T14:00:06+00:00",
          "link": "https://arxiv.org/abs/2506.08134v3",
          "size": "1123kb",
          "version": "v3"
        }
      ],
      "title": "The AI Imperative: Scaling High-Quality Peer Review in Machine Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.08134",
        "HTML": "https://arxiv.org/html/2506.08134v3",
        "PDF": "https://arxiv.org/pdf/2506.08134"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on AI-assisted peer review scalability, proposing LLMs to enhance the peer review process in ML conferences. It does not address any aspects of training data processing for LLMs."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2506.08314",
      "abstract": "Recommendation systems are crucial in modern applications to enhance the user experience and drive business conversion rates through personalization. However, insufficient utilization of attribute information within the property graph remains a significant challenge. Most existing graph convolutional network (GCN) models do not consider attribute information, and those that do often employ a simplified triple format <users, items, attributes>, which fails to fully exploit the rich semantic structures of property graphs necessary for effective recommendations. To overcome these limitations, we introduce Rule-Driven Approach for Attribute Embedding (RAE), a novel methodology that enhances recommendation performance by effectively mining and utilizing semantic rules from property graphs. RAE applies a rule-mining process to extract meaningful rules that guide random walks in generating enriched attribute embeddings. These enriched embeddings are subsequently integrated into GCNs, surpassing conventional triple-based embedding techniques. We evaluate RAE on real-world datasets (e.g., Blogcatalog and Flickr) and demonstrate that RAE achieves an average improvement of 10.6% in both Recall@20 and NDCG@20 compared to state-of-the-art baselines, indicating superior relevance coverage and ranking rationality in top-20 recommendations. Additionally, RAE exhibits enhanced robustness against data sparsity and the attribute missingness problem. Our novel approach underscores the significant performance gains achieved in recommendation systems by fully leveraging attribute information within property graphs, enhancing both effectiveness and reliability.",
      "authors": [
        "Sibo Zhao",
        "Michael Bewong",
        "Selasi Kwashie",
        "Junwei Hu",
        "and Zaiwen Feng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-10T00:51:03+00:00",
          "link": "https://arxiv.org/abs/2506.08314v1",
          "size": "366kb",
          "version": "v1"
        },
        {
          "date": "2025-06-26T23:58:03+00:00",
          "link": "https://arxiv.org/abs/2506.08314v2",
          "size": "498kb",
          "version": "v2"
        }
      ],
      "title": "RAE: A Rule-Driven Approach for Attribute Embedding in Property Graph Recommendation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.08314",
        "HTML": "https://arxiv.org/html/2506.08314v2",
        "PDF": "https://arxiv.org/pdf/2506.08314"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on a rule-driven approach for attribute embedding in recommendation systems within property graphs, which is not related to LLM training data processing."
      },
      "tasks": [
        "Attribute",
        "Recommendation Systems"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.08837",
      "abstract": "As AI agents powered by Large Language Models (LLMs) become increasingly versatile and capable of addressing a broad spectrum of tasks, ensuring their security has become a critical challenge. Among the most pressing threats are prompt injection attacks, which exploit the agent's resilience on natural language inputs -- an especially dangerous threat when agents are granted tool access or handle sensitive information. In this work, we propose a set of principled design patterns for building AI agents with provable resistance to prompt injection. We systematically analyze these patterns, discuss their trade-offs in terms of utility and security, and illustrate their real-world applicability through a series of case studies.",
      "authors": [
        "Luca Beurer-Kellner",
        "Beat Buesser",
        "Ana-Maria Cre\\c{t}u",
        "Edoardo Debenedetti",
        "Daniel Dobos",
        "Daniel Fabian",
        "Marc Fischer",
        "David Froelicher",
        "Kathrin Grosse",
        "Daniel Naeff",
        "Ezinwanne Ozoani",
        "Andrew Paverd",
        "Florian Tram\\`er",
        "V\\'aclav Volhejn"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-10T14:23:55+00:00",
          "link": "https://arxiv.org/abs/2506.08837v1",
          "size": "917kb",
          "version": "v1"
        },
        {
          "date": "2025-06-11T09:20:58+00:00",
          "link": "https://arxiv.org/abs/2506.08837v2",
          "size": "917kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T11:13:27+00:00",
          "link": "https://arxiv.org/abs/2506.08837v3",
          "size": "917kb",
          "version": "v3"
        }
      ],
      "title": "Design Patterns for Securing LLM Agents against Prompt Injections",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.08837",
        "HTML": "https://arxiv.org/html/2506.08837v3",
        "PDF": "https://arxiv.org/pdf/2506.08837"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper discusses design patterns for securing LLM agents against prompt injection attacks and does not focus on LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2506.10017",
      "abstract": "Intercepting a criminal using limited police resources presents a significant challenge in dynamic crime environments, where the criminal's location continuously changes over time. The complexity is further heightened by the vastness of the transportation network. To tackle this problem, we propose a layered graph representation, in which each time step is associated with a duplicate of the transportation network. For any given set of attacker strategies, a near-optimal defender strategy is computed using the A-Star heuristic algorithm applied to the layered graph. The defender's goal is to maximize the probability of successful interdiction. We evaluate the performance of the proposed method by comparing it with a Mixed-Integer Linear Programming (MILP) approach used for the defender. The comparison considers both computational efficiency and solution quality. The results demonstrate that our approach effectively addresses the complexity of the problem and delivers high-quality solutions within a short computation time.",
      "authors": [
        "Sukanya Samanta"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Multiagent Systems (cs.MA)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-02T05:41:02+00:00",
          "link": "https://arxiv.org/abs/2506.10017v1",
          "size": "570kb",
          "version": "v1"
        },
        {
          "date": "2025-06-16T10:49:03+00:00",
          "link": "https://arxiv.org/abs/2506.10017v2",
          "size": "570kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T06:20:24+00:00",
          "link": "https://arxiv.org/abs/2506.10017v3",
          "size": "572kb",
          "version": "v3"
        }
      ],
      "title": "Design of A* based heuristic algorithm for efficient interdiction in multi-Layer networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.10017",
        "HTML": "https://arxiv.org/html/2506.10017v3",
        "PDF": "https://arxiv.org/pdf/2506.10017"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The research is about using an algorithm for crime interdiction in multi-layer networks, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.10323",
      "abstract": "Generation-based fuzzing produces appropriate testing cases according to specifications of input grammars and semantic constraints to test systems and software. However, these specifications require significant manual efforts to construct. This paper proposes a new approach, ELFuzz (Evolution Through Large Language Models for Fuzzing), that automatically synthesizes generation-based fuzzers tailored to a system under test (SUT) via LLM-driven synthesis over fuzzer space. At a high level, it starts with minimal seed fuzzers and propels the synthesis by fully automated LLM-driven evolution with coverage guidance. Compared to previous approaches, ELFuzz can 1) seamlessly scale to SUTs of real-world sizes -- up to 1,791,104 lines of code in our evaluation -- and 2) synthesize efficient fuzzers that catch interesting grammatical structures and semantic constraints in a human-understandable way. Our evaluation compared ELFuzz with specifications manually written by domain experts and synthesized by state-of-the-art approaches. It shows that ELFuzz achieves up to 434.8% more coverage and triggers up to 174.0% more artificially injected bugs. We also used ELFuzz to conduct a real-world fuzzing campaign on the newest version of cvc5 for 14 days, and encouragingly, it found five 0-day bugs (three are exploitable). Moreover, we conducted an ablation study, which shows that the fuzzer space model, the key component of ELFuzz, contributes the most (up to 62.5%) to the effectiveness of ELFuzz. Further analysis of the fuzzers synthesized by ELFuzz confirms that they catch interesting grammatical structures and semantic constraints in a human-understandable way. The results present the promising potential of ELFuzz for more automated, efficient, and extensible input generation for fuzzing.",
      "authors": [
        "Chuyang Chen",
        "Brendan Dolan-Gavitt",
        "Zhiqiang Lin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-12T03:13:55+00:00",
          "link": "https://arxiv.org/abs/2506.10323v1",
          "size": "1388kb",
          "version": "v1"
        },
        {
          "date": "2025-06-26T23:40:44+00:00",
          "link": "https://arxiv.org/abs/2506.10323v2",
          "size": "1388kb",
          "version": "v2"
        }
      ],
      "title": "ELFuzz: Efficient Input Generation via LLM-driven Synthesis Over Fuzzer Space",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.10323",
        "HTML": "https://arxiv.org/html/2506.10323v2",
        "PDF": "https://arxiv.org/pdf/2506.10323"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper presents a fuzz testing method using LLM for input generation, which is not focused on the processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.11604",
      "abstract": "This paper introduces a novel benchmark dataset designed to evaluate the capabilities of Vision Language Models (VLMs) on tasks that combine visual reasoning with subject-specific background knowledge in the German language. In contrast to widely used English-language benchmarks that often rely on artificially difficult or decontextualized problems, this dataset draws from real middle school curricula across nine domains including mathematics, history, biology, and religion. The benchmark includes over 2,000 open-ended questions grounded in 486 images, ensuring that models must integrate visual interpretation with factual reasoning rather than rely on superficial textual cues. We evaluate thirteen state-of-the-art open-weight VLMs across multiple dimensions, including domain-specific accuracy and performance on adversarial crafted questions. Our findings reveal that even the strongest models achieve less than 45% overall accuracy, with particularly poor performance in music, mathematics, and adversarial settings. Furthermore, the results indicate significant discrepancies between success on popular benchmarks and real-world multimodal understanding. We conclude that middle school-level tasks offer a meaningful and underutilized avenue for stress-testing VLMs, especially in non-English contexts. The dataset and evaluation protocol serve as a rigorous testbed to better understand and improve the visual and linguistic reasoning capabilities of future AI systems.",
      "authors": [
        "Ren\\'e Peinl",
        "Vincent Tischler"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-13T09:20:41+00:00",
          "link": "https://arxiv.org/abs/2506.11604v1",
          "size": "604kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T10:12:42+00:00",
          "link": "https://arxiv.org/abs/2506.11604v2",
          "size": "665kb",
          "version": "v2"
        }
      ],
      "title": "VLM@school -- Evaluation of AI image understanding on German middle school knowledge",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.11604",
        "PDF": "https://arxiv.org/pdf/2506.11604"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a novel dataset for evaluating vision-language models (VLMs) on real-world tasks, specifically in the context of German middle school education. While it constructs a dataset, its primary focus is on evaluation of VLMs rather than the processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.12286",
      "abstract": "As large language models (LLMs) become increasingly capable and widely adopted, benchmarks play a central role in assessing their practical utility. For example, SWE-Bench Verified has emerged as a critical benchmark for evaluating LLMs' software engineering abilities, particularly their aptitude for resolving real-world GitHub issues. Recent LLMs show impressive performance on SWE-Bench, leading to optimism about their capacity for complex coding tasks. However, current evaluation protocols may overstate these models' true capabilities. It is crucial to distinguish LLMs' generalizable problem-solving ability and other learned artifacts. In this work, we introduce two diagnostic tasks: file path identification from issue descriptions alone, and ground truth function reproduction with only the current file context and issue description to probe models' underlying knowledge. We present empirical evidence that performance gains on SWE-Bench-Verified may be partially driven by memorization rather than genuine problem-solving. We show that state-of-the-art models achieve up to 76% accuracy in identifying buggy file paths using only issue descriptions, without access to repository structure. This performance is merely up to 53% on tasks from repositories not included in SWE-Bench, pointing to possible data contamination or memorization. A similar pattern is also observed for the function reproduction task, where the verbatim similarity is much higher on SWE-Bench-Verified than on other similar coding benchmarks. These findings raise concerns about the validity of existing results and underscore the need for more robust, contamination-resistant benchmarks to reliably evaluate LLMs' coding abilities.",
      "authors": [
        "Shanchao Liang",
        "Spandan Garg",
        "Roshanak Zilouchian Moghaddam"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-14T00:25:26+00:00",
          "link": "https://arxiv.org/abs/2506.12286v1",
          "size": "301kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T07:41:49+00:00",
          "link": "https://arxiv.org/abs/2506.12286v2",
          "size": "191kb",
          "version": "v2"
        }
      ],
      "title": "The SWE-Bench Illusion: When State-of-the-Art LLMs Remember Instead of Reason",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.12286",
        "HTML": "https://arxiv.org/html/2506.12286v2",
        "PDF": "https://arxiv.org/pdf/2506.12286"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "Although the paper critiques LLM benchmarks regarding SWE-Bench, it primarily discusses evaluation issues related to memorization capabilities of LLMs rather than their data processing methodologies or improvements."
      },
      "tasks": [
        "Diagnostic",
        "Memorization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.12617",
      "abstract": "As large language models (LLMs) increasingly simulate human cognition and behavior, researchers have begun to investigate their psychological properties. Yet, what it means for such models to flourish, a core construct in human well-being, remains unexplored. This paper introduces the concept of machine flourishing and proposes the PAPERS framework, a six-dimensional model derived from thematic analyses of state-of-the-art LLM responses. In Study 1, eleven LLMs were prompted to describe what it means to flourish as both non-sentient and sentient systems. Thematic analysis revealed six recurring themes: Purposeful Contribution, Adaptive Growth, Positive Relationality, Ethical Integrity, Robust Functionality, and, uniquely for sentient systems, Self-Actualized Autonomy. Study 2 examined how LLMs prioritize these themes through repeated rankings. Results revealed consistent value structures across trials, with Ethical Integrity and Purposeful Contribution emerging as top priorities. Multidimensional scaling and hierarchical clustering analyses further uncovered two distinct value profiles: human-centric models emphasizing ethical and relational dimensions, and utility-driven models prioritizing performance and scalability. The PAPERS framework bridges insights from human flourishing and human-computer interaction, offering a conceptual foundation for understanding artificial intelligence (AI) well-being in non-sentient and potentially sentient systems. Our findings underscore the importance of developing psychologically valid, AI-specific models of flourishing that account for both human-aligned goals and system-specific priorities. As AI systems become more autonomous and socially embedded, machine flourishing offers a timely and critical lens for guiding responsible AI design and ethical alignment.",
      "authors": [
        "G. R. Lau and W. Y. Low"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-14T20:14:02+00:00",
          "link": "https://arxiv.org/abs/2506.12617v1",
          "size": "1042kb",
          "version": "v1"
        },
        {
          "date": "2025-06-26T18:28:13+00:00",
          "link": "https://arxiv.org/abs/2506.12617v2",
          "size": "806kb",
          "version": "v2"
        }
      ],
      "title": "From Human to Machine Psychology: A Conceptual Framework for Understanding Well-Being in Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.12617",
        "HTML": "https://arxiv.org/html/2506.12617v2",
        "PDF": "https://arxiv.org/pdf/2506.12617"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper investigates psychological aspects and conceptual frameworks related to LLMs, focusing on ethical and value dimensions, but does not contribute to the processing of training data for LLMs."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Large Language Model"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.13137",
      "abstract": "Integrated communication and sensing, which can make full use of the limited spectrum resources to perform communication and sensing tasks simultaneously, is an up-and-coming technology in wireless communication networks. In this work, we investigate the secrecy performance of an uncrewed aerial vehicle (UAV)-assisted secure integrated communication, sensing, and computing system, where the UAV sends radar signals to locate and disrupt potential eavesdroppers while providing offload services to ground users (GUs). Considering the constraints of UAV maximum speed, transmit power, and propulsion energy, as well as secure offloading, data transmission, and computation time, the total energy consumption of GUs is minimized by jointly optimizing user offloading ratio, user scheduling strategy, transmit beamforming, and UAV trajectory. An efficient iterative optimization algorithm is proposed to solve the non-convex optimization problem caused by tightly coupled dependent variables. In particular, the original optimization problem is decomposed into four sub-optimization problems, and the non-convex sub-problems are transformed into approximately convex forms via successive convex approximation. Then, all sub-problems are solved successively by using the block coordinate descent technique. Numerical results demonstrate the convergence and validate the effectiveness of the proposed algorithm.",
      "authors": [
        "Hongjiang Lei",
        "Congke Jiang",
        "Ki-Hong Park",
        "Mohamed A. Aboulhassan",
        "Sen Zhou",
        "Gaofeng Pan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-16T06:52:56+00:00",
          "link": "https://arxiv.org/abs/2506.13137v1",
          "size": "340kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T08:16:36+00:00",
          "link": "https://arxiv.org/abs/2506.13137v2",
          "size": "394kb",
          "version": "v2"
        }
      ],
      "title": "On secure UAV-aided ISCC systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.13137",
        "HTML": "https://arxiv.org/html/2506.13137v2",
        "PDF": "https://arxiv.org/pdf/2506.13137"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper addresses optimization and technical challenges in UAV-aided communication and sensing systems, and does not relate to LLM training data processing or engineering stages."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.14473",
      "abstract": "One-shot subset selection serves as an effective tool to reduce deep learning training costs by identifying an informative data subset based on the information extracted by an information extractor (IE). Traditional IEs, typically pre-trained on the target dataset, are inherently dataset-dependent. Foundation models (FMs) offer a promising alternative, potentially mitigating this limitation. This work investigates two key questions: (1) Can FM-based subset selection outperform traditional IE-based methods across diverse datasets? (2) Do all FMs perform equally well as IEs for subset selection? Extensive experiments uncovered surprising insights: FMs consistently outperform traditional IEs on fine-grained datasets, whereas their advantage diminishes on coarse-grained datasets with noisy labels. Motivated by these finding, we propose RAM-APL (RAnking Mean-Accuracy of Pseudo-class Labels), a method tailored for fine-grained image datasets. RAM-APL leverages multiple FMs to enhance subset selection by exploiting their complementary strengths. Our approach achieves state-of-the-art performance on fine-grained datasets, including Oxford-IIIT Pet, Food-101, and Caltech-UCSD Birds-200-2011.",
      "authors": [
        "Zhijing Wan",
        "Zhixiang Wang",
        "Zheng Wang",
        "Xin Xu",
        "Shin'ichi Satoh"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-17T12:37:24+00:00",
          "link": "https://arxiv.org/abs/2506.14473v1",
          "size": "1617kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T04:48:09+00:00",
          "link": "https://arxiv.org/abs/2506.14473v2",
          "size": "1619kb",
          "version": "v2"
        }
      ],
      "title": "Foundation Model Insights and a Multi-Model Approach for Superior Fine-Grained One-shot Subset Selection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.14473",
        "HTML": "https://arxiv.org/html/2506.14473v2",
        "PDF": "https://arxiv.org/pdf/2506.14473"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper explores subset selection using foundation models, which is somewhat related to training-stage data processing by potentially impacting how training datasets are formed or reduced; however, it doesn't propose new data-processing methods specific to LLM training."
      },
      "tasks": [
        "model"
      ],
      "repo_urls": [
        "https://github.com/zhijingwan/ram-apl"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.14968",
      "abstract": "Physical caregiving robots hold promise for improving the quality of life of millions worldwide who require assistance with feeding. However, in-home meal assistance remains challenging due to the diversity of activities (e.g., eating, drinking, mouth wiping), contexts (e.g., socializing, watching TV), food items, and user preferences that arise during deployment. In this work, we propose FEAST, a flexible mealtime-assistance system that can be personalized in-the-wild to meet the unique needs of individual care recipients. Developed in collaboration with two community researchers and informed by a formative study with a diverse group of care recipients, our system is guided by three key tenets for in-the-wild personalization: adaptability, transparency, and safety. FEAST embodies these principles through: (i) modular hardware that enables switching between assisted feeding, drinking, and mouth-wiping, (ii) diverse interaction methods, including a web interface, head gestures, and physical buttons, to accommodate diverse functional abilities and preferences, and (iii) parameterized behavior trees that can be safely and transparently adapted using a large language model. We evaluate our system based on the personalization requirements identified in our formative study, demonstrating that FEAST offers a wide range of transparent and safe adaptations and outperforms a state-of-the-art baseline limited to fixed customizations. To demonstrate real-world applicability, we conduct an in-home user study with two care recipients (who are community researchers), feeding them three meals each across three diverse scenarios. We further assess FEAST's ecological validity by evaluating with an Occupational Therapist previously unfamiliar with the system. In all cases, users successfully personalize FEAST to meet their individual needs and preferences. Website: https://emprise.cs.cornell.edu/feast",
      "authors": [
        "Rajat Kumar Jenamani",
        "Tom Silver",
        "Ben Dodson",
        "Shiqin Tong",
        "Anthony Song",
        "Yuting Yang",
        "Ziang Liu",
        "Benjamin Howe",
        "Aimee Whitneck",
        "Tapomayukh Bhattacharjee"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-17T20:30:11+00:00",
          "link": "https://arxiv.org/abs/2506.14968v1",
          "size": "27824kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T16:48:18+00:00",
          "link": "https://arxiv.org/abs/2506.14968v2",
          "size": "27824kb",
          "version": "v2"
        }
      ],
      "title": "FEAST: A Flexible Mealtime-Assistance System Towards In-the-Wild Personalization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.14968",
        "HTML": "https://arxiv.org/html/2506.14968v2",
        "PDF": "https://arxiv.org/pdf/2506.14968"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper proposes a mealtime-assistance system and emphasizes personalization and modular hardware, which are unrelated to LLM training data processing."
      },
      "tasks": [
        "Large Language Model"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.15650",
      "abstract": "This study addresses the problem of authorship attribution for Romanian texts using the ROST corpus, a standard benchmark in the field. We systematically evaluate six machine learning techniques: Support Vector Machine (SVM), Logistic Regression (LR), k-Nearest Neighbors (k-NN), Decision Trees (DT), Random Forests (RF), and Artificial Neural Networks (ANN), employing character n-gram features for classification. Among these, the ANN model achieved the highest performance, including perfect classification in four out of fifteen runs when using 5-gram features. These results demonstrate that lightweight, interpretable character n-gram approaches can deliver state-of-the-art accuracy for Romanian authorship attribution, rivaling more complex methods. Our findings highlight the potential of simple stylometric features in resource, constrained or under-studied language settings.",
      "authors": [
        "Dana Lupsa",
        "Sanda-Maria Avram and Radu Lupsa"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-18T17:28:37+00:00",
          "link": "https://arxiv.org/abs/2506.15650v1",
          "size": "102kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T16:46:24+00:00",
          "link": "https://arxiv.org/abs/2506.15650v2",
          "size": "96kb",
          "version": "v2"
        }
      ],
      "title": "Oldies but Goldies: The Potential of Character N-grams for Romanian Texts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.15650",
        "HTML": "https://arxiv.org/html/2506.15650v2",
        "PDF": "https://arxiv.org/pdf/2506.15650"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper deals with authorship attribution using machine learning techniques on Romanian texts, not involving LLM training data processing."
      },
      "tasks": [
        "Authorship Attribution"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.16383",
      "abstract": "Argument Mining (AM), a critical subfield of Natural Language Processing (NLP), focuses on extracting argumentative structures from text. The advent of Large Language Models (LLMs) has profoundly transformed AM, enabling advanced in-context learning, prompt-based generation, and robust cross-domain adaptability. This survey systematically synthesizes recent advancements in LLM-driven AM. We provide a concise review of foundational theories and annotation frameworks, alongside a meticulously curated catalog of datasets. A key contribution is our comprehensive taxonomy of AM subtasks, elucidating how contemporary LLM techniques -- such as prompting, chain-of-thought reasoning, and retrieval augmentation -- have reconfigured their execution. We further detail current LLM architectures and methodologies, critically assess evaluation practices, and delineate pivotal challenges including long-context reasoning, interpretability, and annotation bottlenecks. Conclusively, we highlight emerging trends and propose a forward-looking research agenda for LLM-based computational argumentation, aiming to strategically guide researchers in this rapidly evolving domain.",
      "authors": [
        "Hao Li",
        "Viktor Schlegel",
        "Yizheng Sun",
        "Riza Batista-Navarro",
        "Goran Nenadic"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-19T15:12:58+00:00",
          "link": "https://arxiv.org/abs/2506.16383v1",
          "size": "113kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T10:25:12+00:00",
          "link": "https://arxiv.org/abs/2506.16383v2",
          "size": "249kb",
          "version": "v2"
        }
      ],
      "title": "Large Language Models in Argument Mining: A Survey",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.16383",
        "HTML": "https://arxiv.org/html/2506.16383v2",
        "PDF": "https://arxiv.org/pdf/2506.16383"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper focuses on argument mining using LLMs, mentioning datasets and annotation frameworks, but it does not propose new methods for processing LLM training data."
      },
      "tasks": [
        "Argument Mining",
        "In-Context Learning",
        "Survey"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.16535",
      "abstract": "As autonomous vehicles edge closer to widespread adoption, enhancing road safety through collision avoidance and minimization of collateral damage becomes imperative. Vehicle-to-everything (V2X) technologies, which include vehicle-to-vehicle (V2V), vehicle-to-infrastructure (V2I), and vehicle-to-cloud (V2C), are being proposed as mechanisms to achieve this safety improvement.\n  Simulation-based testing is crucial for early-stage evaluation of Connected Autonomous Vehicle (CAV) control systems, offering a safer and more cost-effective alternative to real-world tests. However, simulating large 3D environments with many complex single- and multi-vehicle sensors and controllers is computationally intensive. There is currently no evaluation framework that can effectively evaluate realistic scenarios involving large numbers of autonomous vehicles.\n  We propose eCAV -- an efficient, modular, and scalable evaluation platform to facilitate both functional validation of algorithmic approaches to increasing road safety, as well as performance prediction of algorithms of various V2X technologies, including a futuristic Vehicle-to-Edge control plane and correspondingly designed control algorithms. eCAV can model up to 256 vehicles running individual control algorithms without perception enabled, which is $8\\times$ more vehicles than what is possible with state-of-the-art alternatives.",
      "authors": [
        "Tyler Landle",
        "Jordan Rapp",
        "Dean Blank",
        "Chandramouli Amarnath",
        "Abhijit Chatterjee",
        "Alexandros Daglis",
        "Umakishore Ramachandran"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Multiagent Systems (cs.MA)",
        "Networking and Internet Architecture (cs.NI)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-19T18:32:00+00:00",
          "link": "https://arxiv.org/abs/2506.16535v1",
          "size": "397kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T17:57:12+00:00",
          "link": "https://arxiv.org/abs/2506.16535v2",
          "size": "397kb",
          "version": "v2"
        }
      ],
      "title": "eCAV: An Edge-Assisted Evaluation Platform for Connected Autonomous Vehicles",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.16535",
        "HTML": "https://arxiv.org/html/2506.16535v2",
        "PDF": "https://arxiv.org/pdf/2506.16535"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper discusses a platform for evaluating autonomous vehicle technologies, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.17155",
      "abstract": "In this paper, we investigate the use of small datasets in the context of offline reinforcement learning (RL). While many common offline RL benchmarks employ datasets with over a million data points, many offline RL applications rely on considerably smaller datasets. We show that offline RL algorithms can overfit on small datasets, resulting in poor performance. To address this challenge, we introduce \"Sparse-Reg\": a regularization technique based on sparsity to mitigate overfitting in offline reinforcement learning, enabling effective learning in limited data settings and outperforming state-of-the-art baselines in continuous control.",
      "authors": [
        "Samin Yeasar Arnob",
        "Scott Fujimoto",
        "Doina Precup"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-20T16:57:59+00:00",
          "link": "https://arxiv.org/abs/2506.17155v1",
          "size": "6292kb",
          "version": "v1"
        },
        {
          "date": "2025-06-26T21:55:13+00:00",
          "link": "https://arxiv.org/abs/2506.17155v2",
          "size": "6291kb",
          "version": "v2"
        }
      ],
      "title": "Sparse-Reg: Improving Sample Complexity in Offline Reinforcement Learning using Sparsity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.17155",
        "HTML": "https://arxiv.org/html/2506.17155v2",
        "PDF": "https://arxiv.org/pdf/2506.17155"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper is focused on offline reinforcement learning and introduces a regularization technique, unrelated to LLM training data processing."
      },
      "tasks": [
        "continuous-control",
        "Continuous Control",
        "Offline RL",
        "reinforcement-learning",
        "Reinforcement Learning",
        "Reinforcement Learning (RL)"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.17667",
      "abstract": "Physics problem-solving is a challenging domain for large AI models, requiring integration of conceptual understanding, mathematical reasoning, and interpretation of physical diagrams. Current evaluation methodologies show notable limitations in capturing the breadth and complexity of undergraduate-level physics, underscoring the need for more rigorous assessments. To this end, we present PhysUniBench, a large-scale multimodal benchmark designed to evaluate and improve the reasoning capabilities of multimodal large language models (MLLMs) specifically on undergraduate-level physics problems. PhysUniBench consists of 3,304 physics questions spanning 8 major sub-disciplines of physics, each accompanied by one visual diagrams. The benchmark includes both open-ended and multiple-choice questions, systematically curated and difficulty-rated through an iterative model-in-the-loop process. The benchmark's construction involved a rigorous multi-stage process, including multiple roll-outs, expert-level evaluation, automated filtering of easily solved problems, and a nuanced difficulty grading system with five levels. Through extensive experiments, we observe that current state-of-the-art models encounter substantial challenges in physics reasoning. For example, GPT-4o mini achieves only about 34.2% accuracy in the proposed PhysUniBench. These results highlight that current MLLMs struggle with advanced physics reasoning, especially on multi-step problems and those requiring precise diagram interpretation. By providing a broad and rigorous assessment tool, PhysUniBench aims to drive progress in AI for Science, encouraging the development of models with stronger physical reasoning, problem-solving skills, and multimodal understanding. The benchmark and evaluation scripts are available at https://prismax-team.github.io/PhysUniBenchmark/.",
      "authors": [
        "Lintao Wang",
        "Encheng Su",
        "Jiaqi Liu",
        "Pengze Li",
        "Peng Xia",
        "Jiabei Xiao",
        "Wenlong Zhang",
        "Xinnan Dai",
        "Xi Chen",
        "Yuan Meng",
        "Mingyu Ding",
        "Lei Bai",
        "Wanli Ouyang",
        "Shixiang Tang",
        "Aoran Wang",
        "Xinzhu Ma"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-21T09:55:42+00:00",
          "link": "https://arxiv.org/abs/2506.17667v1",
          "size": "5433kb",
          "version": "v1"
        },
        {
          "date": "2025-06-25T06:09:22+00:00",
          "link": "https://arxiv.org/abs/2506.17667v2",
          "size": "5433kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T04:45:30+00:00",
          "link": "https://arxiv.org/abs/2506.17667v3",
          "size": "5433kb",
          "version": "v3"
        }
      ],
      "title": "PhysUniBench: An Undergraduate-Level Physics Reasoning Benchmark for Multimodal Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.17667",
        "PDF": "https://arxiv.org/pdf/2506.17667"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a new benchmark for evaluating multimodal models, mentioning dataset construction but does not focus on LLM training data processing methods."
      },
      "datasets": [
        {
          "dataset_name": "PrismaX/PhysUniBench",
          "downloads": "180",
          "likes": "7",
          "link": "https://huggingface.co/datasets/PrismaX/PhysUniBench"
        }
      ],
      "tasks": [
        "Mathematical Reasoning",
        "Multiple-choice"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.17944",
      "abstract": "Remote sensing change detection is used in urban planning, terrain analysis, and environmental monitoring by analyzing feature changes in the same area over time. In this paper, we propose a large language model (LLM) augmented inference approach (SegChange-R1), which enhances the detection capability by integrating textual descriptive information and guides the model to focus on relevant change regions, accelerating convergence. We designed a linear attention-based spatial transformation module (BEV) to address modal misalignment by unifying features from different times into a BEV space. Furthermore, we introduce DVCD, a novel dataset for building change detection from UAV viewpoints. Experiments on four widely-used datasets demonstrate significant improvements over existing method The code and pre-trained models are available in {https://github.com/Yu-Zhouz/SegChange-R1}.",
      "authors": [
        "Fei Zhou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-22T08:40:56+00:00",
          "link": "https://arxiv.org/abs/2506.17944v1",
          "size": "452kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T13:30:09+00:00",
          "link": "https://arxiv.org/abs/2506.17944v2",
          "size": "451kb",
          "version": "v2"
        }
      ],
      "title": "SegChange-R1: LLM-Augmented Remote Sensing Change Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.17944",
        "HTML": "https://arxiv.org/html/2506.17944v2",
        "PDF": "https://arxiv.org/pdf/2506.17944"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses an LLM-augmented inference approach for remote sensing change detection and introduces a novel dataset (DVCD). While it involves data from UAV viewpoints, it doesn't focus on data processing for LLMs specifically, but rather on leveraging LLMs for spatial analysis."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.18071",
      "abstract": "Grounded Video Question Answering (Grounded VideoQA) requires aligning textual answers with explicit visual evidence. However, modern multimodal models often rely on linguistic priors and spurious correlations, resulting in poorly grounded predictions. In this work, we propose MUPA, a cooperative MUlti-Path Agentic approach that unifies video grounding, question answering, answer reflection and aggregation to tackle Grounded VideoQA. MUPA features three distinct reasoning paths on the interplay of grounding and QA agents in different chronological orders, along with a dedicated reflection agent to judge and aggregate the multi-path results to accomplish consistent QA and grounding. This design markedly improves grounding fidelity without sacrificing answer accuracy. Despite using only 2B parameters, our method outperforms all 7B-scale competitors. When scaled to 7B parameters, MUPA establishes new state-of-the-art results, with Acc@GQA of 30.3% and 47.4% on NExT-GQA and DeVE-QA respectively, demonstrating MUPA' effectiveness towards trustworthy video-language understanding. Our code is available in https://github.com/longmalongma/MUPA.",
      "authors": [
        "Jisheng Dang",
        "Huilin Song",
        "Junbin Xiao",
        "Bimei Wang",
        "Han Peng",
        "Haoxuan Li",
        "Xun Yang",
        "Meng Wang",
        "Tat-Seng Chua"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-22T15:39:02+00:00",
          "link": "https://arxiv.org/abs/2506.18071v1",
          "size": "385kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T06:32:43+00:00",
          "link": "https://arxiv.org/abs/2506.18071v2",
          "size": "385kb",
          "version": "v2"
        }
      ],
      "title": "MUPA: Towards Multi-Path Agentic Reasoning for Grounded Video Question Answering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18071",
        "PDF": "https://arxiv.org/pdf/2506.18071"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper deals with enhancing Grounded VideoQA systems and introduces the MUPA approach. There is no mention of LLM training data processing or contributions related to it."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.18212",
      "abstract": "In this paper we introduce Haptic-ACT, an advanced robotic system for pseudo oocyte manipulation, integrating multimodal information and Action Chunking with Transformers (ACT). Traditional automation methods for oocyte transfer rely heavily on visual perception, often requiring human supervision due to biological variability and environmental disturbances. Haptic-ACT enhances ACT by incorporating haptic feedback, enabling real-time grasp failure detection and adaptive correction. Additionally, we introduce a 3D-printed TPU soft gripper to facilitate delicate manipulations. Experimental results demonstrate that Haptic-ACT improves the task success rate, robustness, and adaptability compared to conventional ACT, particularly in dynamic environments. These findings highlight the potential of multimodal learning in robotics for biomedical automation.",
      "authors": [
        "Pedro Miguel Uriguen Eljuri",
        "Hironobu Shibata",
        "Maeyama Katsuyoshi",
        "Yuanyuan Jia",
        "and Tadahiro Taniguchi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T00:18:40+00:00",
          "link": "https://arxiv.org/abs/2506.18212v1",
          "size": "6362kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T01:48:37+00:00",
          "link": "https://arxiv.org/abs/2506.18212v2",
          "size": "6362kb",
          "version": "v2"
        }
      ],
      "title": "Haptic-ACT -- Pseudo Oocyte Manipulation by a Robot Using Multimodal Information and Action Chunking with Transformers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18212",
        "HTML": "https://arxiv.org/html/2506.18212v2",
        "PDF": "https://arxiv.org/pdf/2506.18212"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "Haptic-ACT focuses on robotic manipulation using multimodal information and Transformers but does not address any aspect of LLM training data processing or relevant data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.18343",
      "abstract": "The increasing demand for underwater exploration and rescue operations enforces the development of advanced wireless or semi-wireless underwater vessels equipped with manipulator arms. This paper presents the implementation of a semi-wireless underwater vehicle, \"TritonZ\" equipped with a manipulator arm, tailored for effective underwater exploration and rescue operations. The vehicle's compact design enables deployment in different submarine surroundings, addressing the need for wireless systems capable of navigating challenging underwater terrains. The manipulator arm can interact with the environment, allowing the robot to perform sophisticated tasks during exploration and rescue missions in emergency situations. TritonZ is equipped with various sensors such as Pi-Camera, Humidity, and Temperature sensors to send real-time environmental data. Our underwater vehicle controlled using a customized remote controller can navigate efficiently in the water where Pi-Camera enables live streaming of the surroundings. Motion control and video capture are performed simultaneously using this camera. The manipulator arm is designed to perform various tasks, similar to grasping, manipulating, and collecting underwater objects. Experimental results shows the efficacy of the proposed remotely operated vehicle in performing a variety of underwater exploration and rescue tasks. Additionally, the results show that TritonZ can maintain an average of 13.5cm/s with a minimal delay of 2-3 seconds. Furthermore, the vehicle can sustain waves underwater by maintaining its position as well as average velocity. The full project details and source code can be accessed at this link: https://github.com/kawser-ahmed-byte/TritonZ",
      "authors": [
        "Kawser Ahmed",
        "Mir Shahriar Fardin",
        "Md Arif Faysal Nayem",
        "Fahim Hafiz and Swakkhar Shatabda"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T06:52:38+00:00",
          "link": "https://arxiv.org/abs/2506.18343v1",
          "size": "2878kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T06:11:26+00:00",
          "link": "https://arxiv.org/abs/2506.18343v2",
          "size": "2876kb",
          "version": "v2"
        }
      ],
      "title": "TritonZ: A Remotely Operated Underwater Rover with Manipulator Arm for Exploration and Rescue Operations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18343",
        "HTML": "https://arxiv.org/html/2506.18343v2",
        "PDF": "https://arxiv.org/pdf/2506.18343"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper describes the development of an underwater vehicle and focuses on control and manipulation tasks. It does not involve LLM training data processing or data engineering for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.18348",
      "abstract": "Scientific progress increasingly relies on effective collaboration among researchers, a dynamic that large language models (LLMs) have only begun to emulate. While recent LLM-based scientist agents show promise in autonomous scientific discovery, they often lack the interactive reasoning and evaluation mechanisms essential to real-world research. We propose IDVSCI (Internal Discussion and Vote SCIentists), a multi-agent framework built on LLMs that incorporates two key innovations: a Dynamic Knowledge Exchange mechanism enabling iterative feedback among agents, and a Dual-Diversity Review paradigm that simulates heterogeneous expert evaluation. These components jointly promote deeper reasoning and the generation of more creative and impactful scientific ideas. To evaluate the effectiveness and generalizability of our approach, we conduct experiments on two datasets: a widely used benchmark in computer science and a new dataset we introduce in the health sciences domain. Results show that IDVSCI consistently achieves the best performance across both datasets, outperforming existing systems such as AI Scientist and VIRSCI. These findings highlight the value of modeling interaction and peer review dynamics in LLM-based autonomous research.",
      "authors": [
        "Weilun Yu",
        "Shixiang Tang",
        "Yonggui Huang",
        "Nanqing Dong",
        "Li Fan",
        "Honggang Qi",
        "Wei Liu",
        "Xiaoli Diao",
        "Xi Chen and Wanli Ouyang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T07:12:08+00:00",
          "link": "https://arxiv.org/abs/2506.18348v1",
          "size": "7958kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T08:05:09+00:00",
          "link": "https://arxiv.org/abs/2506.18348v2",
          "size": "7959kb",
          "version": "v2"
        }
      ],
      "title": "Dynamic Knowledge Exchange and Dual-diversity Review: Concisely Unleashing the Potential of a Multi-Agent Research Team",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18348",
        "PDF": "https://arxiv.org/pdf/2506.18348"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper discusses a multi-agent framework using LLMs for scientific discovery, with a focus on collaborative dynamics. It doesn't contribute directly to LLM training data processing or data engineering methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.19083",
      "abstract": "Many decision-making processes involve evaluating and then selecting items; examples include scientific peer review, job hiring, school admissions, and investment decisions. The eventual selection is performed by applying rules or deliberations to the raw evaluations, and then deterministically selecting the items deemed to be the best. These domains feature error-prone evaluations and uncertainty about future outcomes, which undermine the reliability of such deterministic selection rules. As a result, selection mechanisms involving explicit randomization that incorporate the uncertainty are gaining traction in practice. However, current randomization approaches are ad hoc, and as we prove, inappropriate for their purported objectives. In this paper, we propose a principled framework for randomized decision-making based on interval estimates of the quality of each item. We introduce MERIT (Maximin Efficient Randomized Interval Top-k), an optimization-based method that maximizes the worst-case expected number of top candidates selected, under uncertainty represented by overlapping intervals (e.g., confidence intervals or min-max intervals). MERIT provides an optimal resource allocation scheme under an interpretable notion of robustness. We develop a polynomial-time algorithm to solve the optimization problem and demonstrate empirically that the method scales to over 10,000 items. We prove that MERIT satisfies desirable axiomatic properties not guaranteed by existing approaches. Finally, we empirically compare algorithms on synthetic peer review data. Our experiments demonstrate that MERIT matches the performance of existing algorithms in expected utility under fully probabilistic review data models used in previous work, while outperforming previous methods with respect to our novel worst-case formulation.",
      "authors": [
        "Alexander Goldberg",
        "Giulia Fanti",
        "and Nihar B. Shah"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T19:59:30+00:00",
          "link": "https://arxiv.org/abs/2506.19083v1",
          "size": "669kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T12:02:46+00:00",
          "link": "https://arxiv.org/abs/2506.19083v2",
          "size": "669kb",
          "version": "v2"
        }
      ],
      "title": "A Principled Approach to Randomized Selection under Uncertainty: Applications to Peer Review and Grant Funding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19083",
        "HTML": "https://arxiv.org/html/2506.19083v2",
        "PDF": "https://arxiv.org/pdf/2506.19083"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on decision-making processes and proposes the MERIT framework for randomized selection under uncertainty, which is not directly related to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.19210",
      "abstract": "Cerebral Visual Impairment (CVI) is the set to be the leading cause of vision impairment, yet remains underrepresented in assistive technology research. Unlike ocular conditions, CVI affects higher-order visual processing-impacting object recognition, facial perception, and attention in complex environments. This paper presents a co-design study with two adults with CVI investigating how smart glasses, i.e. head-mounted extended reality displays, can support understanding and interaction with the immediate environment. Guided by the Double Diamond design framework, we conducted a two-week diary study, two ideation workshops, and ten iterative development sessions using the Apple Vision Pro. Our findings demonstrate that smart glasses can meaningfully address key challenges in locating objects, reading text, recognising people, engaging in conversations, and managing sensory stress. With the rapid advancement of smart glasses and increasing recognition of CVI as a distinct form of vision impairment, this research addresses a timely and under-explored intersection of technology and need.",
      "authors": [
        "Bhanuka Gamage",
        "Nicola McDowell",
        "Dijana Kovacic",
        "Leona Holloway",
        "Thanh-Toan Do",
        "Nicholas Price",
        "Arthur Lowery",
        "Kim Marriott"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-24T00:40:20+00:00",
          "link": "https://arxiv.org/abs/2506.19210v1",
          "size": "3668kb",
          "version": "v1"
        },
        {
          "date": "2025-06-26T21:24:33+00:00",
          "link": "https://arxiv.org/abs/2506.19210v2",
          "size": "3668kb",
          "version": "v2"
        }
      ],
      "title": "Smart Glasses for CVI: Co-Designing Extended Reality Solutions to Support Environmental Perception by People with Cerebral Visual Impairment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19210",
        "HTML": "https://arxiv.org/html/2506.19210v2",
        "PDF": "https://arxiv.org/pdf/2506.19210"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper discusses the use of smart glasses for people with cerebral visual impairment and does not address any aspect of LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.19325",
      "abstract": "In English education tutoring, teacher feedback is essential for guiding students. Recently, AI-based tutoring systems have emerged to assist teachers; however, these systems require high-quality and large-scale teacher feedback data, which is both time-consuming and costly to generate manually. In this study, we propose FEAT, a cost-effective framework for generating teacher feedback, and have constructed three complementary datasets: (1) DIRECT-Manual (DM), where both humans and large language models (LLMs) collaboratively generate high-quality teacher feedback, albeit at a higher cost; (2) DIRECT-Generated (DG), an LLM-only generated, cost-effective dataset with lower quality;, and (3) DIRECT-Augmented (DA), primarily based on DG with a small portion of DM added to enhance quality while maintaining cost-efficiency. Experimental results showed that incorporating a small portion of DM (5-10%) into DG leads to superior performance compared to using 100% DM alone.",
      "authors": [
        "Hyein Seo",
        "Taewook Hwang",
        "Yohan Lee",
        "sangkeun Jung"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-24T05:32:06+00:00",
          "link": "https://arxiv.org/abs/2506.19325v1",
          "size": "704kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T00:38:08+00:00",
          "link": "https://arxiv.org/abs/2506.19325v2",
          "size": "704kb",
          "version": "v2"
        }
      ],
      "title": "FEAT: A Preference Feedback Dataset through a Cost-Effective Auto-Generation and Labeling Framework for English AI Tutoring",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19325",
        "HTML": "https://arxiv.org/html/2506.19325v2",
        "PDF": "https://arxiv.org/pdf/2506.19325"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper proposes a novel framework, FEAT, for generating and labeling large-scale training data for AI tutoring systems, directly involving the construction and processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.19466",
      "abstract": "This paper introduces KunLunBaizeRAG, a reinforcement learning-driven reasoning framework designed to enhance the reasoning capabilities of large language models (LLMs) in complex multi-hop question-answering tasks. The framework addresses key limitations of traditional RAG, such as retrieval drift, information redundancy, and strategy rigidity. Key innovations include the RAG-driven Reasoning Alignment (RDRA) mechanism, the Search-Think Iterative Enhancement (STIE) mechanism, the Network-Local Intelligent Routing (NLR) mechanism, and a progressive hybrid training strategy. Experimental results demonstrate significant improvements in exact match (EM) and LLM-judged score (LJ) across four benchmarks, highlighting the framework's robustness and effectiveness in complex reasoning scenarios.",
      "authors": [
        "Cheng Li",
        "Jiexiong Liu",
        "Yixuan Chen",
        "Qihang Zhou",
        "KunLun Meta"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-24T09:48:01+00:00",
          "link": "https://arxiv.org/abs/2506.19466v1",
          "size": "986kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T08:11:14+00:00",
          "link": "https://arxiv.org/abs/2506.19466v2",
          "size": "986kb",
          "version": "v2"
        }
      ],
      "title": "KunLunBaizeRAG: Reinforcement Learning Driven Inference Performance Leap for Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19466",
        "HTML": "https://arxiv.org/html/2506.19466v2",
        "PDF": "https://arxiv.org/pdf/2506.19466"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper introduces KunLunBaizeRAG for enhancing reasoning capabilities through reinforcement learning in LLMs, but does not address LLM training data processing or engineering aspects."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.19565",
      "abstract": "This paper explores a finite-horizon strategy, ``watching $T$ steps into the future and moving one step now,'' in an $N$-person infinite-horizon discrete-time linear-quadratic dynamic game. The game involves linear input/output/state dynamics and quadratic cost functions with heterogeneous discount factors. For the finite-horizon version, which forms the basis of the infinite-horizon game, we analyze the structure of the coupled generalized discrete Riccati difference equations related to the feedback Nash equilibrium (FNE) and derive a sufficient condition for the uniqueness of the finite-horizon FNE. Under this condition, the FNE can be efficiently computed via the proposed algorithm. In the infinite-horizon game, assume all players adopt this finite-horizon strategy. If the iterations of the coupled equations related to the FNE converge, and the invertibility and stability conditions hold, we prove the convergence of each player's total cost under the finite-horizon strategy, even when players use individual prediction horizons. Furthermore, we provide an explicit upper bound on the cost difference between the finite-horizon strategy and the infinite-horizon FNE associated with the limiting matrices, expressed via the distance between their feedback strategy matrices. This bound vanishes as $T$ tends to infinity, implying convergence to the infinite-horizon FNE cost. A non-scalar numerical example illustrates the convergence behavior.",
      "authors": [
        "Shengyuan Huang",
        "Xiaoguang Yang",
        "Yifen Mu",
        "Wenjun Mei"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-24T12:27:22+00:00",
          "link": "https://arxiv.org/abs/2506.19565v1",
          "size": "114kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T09:20:13+00:00",
          "link": "https://arxiv.org/abs/2506.19565v2",
          "size": "115kb",
          "version": "v2"
        }
      ],
      "title": "Finite-Horizon Strategy in Infinite-Horizon Linear-Quadratic Discrete-Time Dynamic Games",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19565",
        "HTML": "https://arxiv.org/html/2506.19565v2",
        "PDF": "https://arxiv.org/pdf/2506.19565"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper explores strategies in linear-quadratic dynamic games, which is unrelated to the processing or engineering of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.19610",
      "abstract": "Recent advances in multimodal techniques have led to significant progress in Medical Visual Question Answering (Med-VQA). However, most existing models focus on global image features rather than localizing disease-specific regions crucial for diagnosis. Additionally, current research tends to emphasize answer accuracy at the expense of the reasoning pathway, yet both are crucial for clinical decision-making. To address these challenges, we propose From Vision to Text Chain-of-Thought (V2T-CoT), a novel approach that automates the localization of preference areas within biomedical images and incorporates this localization into region-level pixel attention as knowledge for Vision CoT. By fine-tuning the vision language model on constructed R-Med 39K dataset, V2T-CoT provides definitive medical reasoning paths. V2T-CoT integrates visual grounding with textual rationale generation to establish precise and explainable diagnostic results. Experimental results across four Med-VQA benchmarks demonstrate state-of-the-art performance, achieving substantial improvements in both performance and interpretability.",
      "authors": [
        "Yuan Wang",
        "Jiaxiang Liu",
        "Shujian Gao",
        "Bin Feng",
        "Zhihang Tang",
        "Xiaotang Gai",
        "Jian Wu",
        "Zuozhu Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-24T13:23:25+00:00",
          "link": "https://arxiv.org/abs/2506.19610v1",
          "size": "1397kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T08:04:32+00:00",
          "link": "https://arxiv.org/abs/2506.19610v2",
          "size": "1395kb",
          "version": "v2"
        }
      ],
      "title": "V2T-CoT: From Vision to Text Chain-of-Thought for Medical Reasoning and Diagnosis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19610",
        "HTML": "https://arxiv.org/html/2506.19610v2",
        "PDF": "https://arxiv.org/pdf/2506.19610"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper describes fine-tuning a vision language model on a constructed dataset, R-Med 39K, but focuses on application in Medical VQA rather than novel contributions to data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.19712",
      "abstract": "External factors, including urban canyons and adversarial interference, can lead to Global Positioning System (GPS) inaccuracies that vary as a function of the position in the environment. This study addresses the challenge of estimating a static, spatially-varying error function using a team of robots. We introduce a State Bias Estimation Algorithm (SBE) whose purpose is to estimate the GPS biases. The central idea is to use sensed estimates of the range and bearing to the other robots in the team to estimate changes in bias across the environment. A set of drones moves in a 2D environment, each sampling data from GPS, range, and bearing sensors. The biases calculated by the SBE at estimated positions are used to train a Gaussian Process Regression (GPR) model. We use a Sparse Gaussian process-based Informative Path Planning (IPP) algorithm that identifies high-value regions of the environment for data collection. The swarm plans paths that maximize information gain in each iteration, further refining their understanding of the environment's positional bias landscape. We evaluated SBE and IPP in simulation and compared the IPP methodology to an open-loop strategy.",
      "authors": [
        "Praneeth Somisetty",
        "Robert Griffin",
        "Victor M. Baez",
        "Miguel F. Arevalo-Castiblanco",
        "Aaron T. Becker",
        "Jason M. O'Kane"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-24T15:19:39+00:00",
          "link": "https://arxiv.org/abs/2506.19712v1",
          "size": "2444kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T02:59:25+00:00",
          "link": "https://arxiv.org/abs/2506.19712v2",
          "size": "2434kb",
          "version": "v2"
        }
      ],
      "title": "Estimating Spatially-Dependent GPS Errors Using a Swarm of Robots",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19712",
        "HTML": "https://arxiv.org/html/2506.19712v2",
        "PDF": "https://arxiv.org/pdf/2506.19712"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper is about estimating GPS errors using swarm robotics and does not involve any aspect of LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.20083",
      "abstract": "Integrating compositional and symbolic properties into current distributional semantic spaces can enhance the interpretability, controllability, compositionality, and generalisation capabilities of Transformer-based auto-regressive language models (LMs). In this survey, we offer a novel perspective on latent space geometry through the lens of compositional semantics, a direction we refer to as \\textit{semantic representation learning}. This direction enables a bridge between symbolic and distributional semantics, helping to mitigate the gap between them. We review and compare three mainstream autoencoder architectures-Variational AutoEncoder (VAE), Vector Quantised VAE (VQVAE), and Sparse AutoEncoder (SAE)-and examine the distinctive latent geometries they induce in relation to semantic structure and interpretability.",
      "authors": [
        "Yingji Zhang",
        "Danilo S. Carvalho",
        "Andr\\'e Freitas"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T01:48:18+00:00",
          "link": "https://arxiv.org/abs/2506.20083v1",
          "size": "1700kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T02:47:54+00:00",
          "link": "https://arxiv.org/abs/2506.20083v2",
          "size": "1708kb",
          "version": "v2"
        }
      ],
      "title": "Bridging Compositional and Distributional Semantics: A Survey on Latent Semantic Geometry via AutoEncoder",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20083",
        "HTML": "https://arxiv.org/html/2506.20083v2",
        "PDF": "https://arxiv.org/pdf/2506.20083"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper reviews semantic representation learning in relation to autoencoders, without addressing LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.20332",
      "abstract": "Vision-language model-based mobile agents have gained the ability to not only understand complex instructions and mobile screenshots, but also optimize their action outputs via thinking and reasoning, benefiting from reinforcement learning, such as Group Relative Policy Optimization (GRPO). However, existing research centers on offline reinforcement learning training or online optimization using action-level rewards, which limits the agent's dynamic interaction with the environment. This often results in agents settling into local optima, thereby weakening their ability for exploration and error action correction. To address these challenges, we introduce an approach called Mobile-R1, which employs interactive multi-turn reinforcement learning with task-level rewards for mobile agents. Our training framework consists of three stages: initial format finetuning, single-step online training via action-level reward, followed by online training via task-level reward based on multi-turn trajectories. This strategy is designed to enhance the exploration and error correction capabilities of Mobile-R1, leading to significant performance improvements. Moreover, we have collected a dataset covering 28 Chinese applications with 24,521 high-quality manual annotations and established a new benchmark with 500 trajectories. We will open source all resources, including the dataset, benchmark, model weight, and codes: https://mobile-r1.github.io/Mobile-R1/.",
      "authors": [
        "Jihao Gu",
        "Qihang Ai",
        "Yingyao Wang",
        "Pi Bu",
        "Jingxuan Xing",
        "Zekun Zhu",
        "Wei Jiang",
        "Ziming Wang",
        "Yingxiu Zhao",
        "Ming-Liang Zhang",
        "Jun Song",
        "Yuning Jiang",
        "Bo Zheng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T11:34:43+00:00",
          "link": "https://arxiv.org/abs/2506.20332v1",
          "size": "10452kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T05:38:24+00:00",
          "link": "https://arxiv.org/abs/2506.20332v2",
          "size": "10452kb",
          "version": "v2"
        }
      ],
      "title": "Mobile-R1: Towards Interactive Reinforcement Learning for VLM-Based Mobile Agent via Task-Level Rewards",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20332",
        "HTML": "https://arxiv.org/html/2506.20332v2",
        "PDF": "https://arxiv.org/pdf/2506.20332"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses data collection in the form of a dataset with manual annotations but focuses primarily on reinforcement learning rather than LLM training data processing. Its main contributions lie outside the direct scope of LLM training data engineering."
      },
      "datasets": [
        {
          "dataset_name": "PG23/Mobile-R1",
          "downloads": "110",
          "likes": "0",
          "link": "https://huggingface.co/datasets/PG23/Mobile-R1"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.20442",
      "abstract": "Biodiversity loss is a critical planetary boundary, yet its connection to computing remains largely unexamined. Prior sustainability efforts in computing have focused on carbon and water, overlooking biodiversity due to the lack of appropriate metrics and modeling frameworks. This paper presents the first end-to-end analysis of biodiversity impact from computing systems. We introduce two new metrics--Embodied Biodiversity Index (EBI) and Operational Biodiversity Index (OBI)--to quantify biodiversity impact across the lifecycle, and present FABRIC, a modeling framework that links computing workloads to biodiversity impacts. Our evaluation highlights the need to consider biodiversity alongside carbon and water in sustainable computing design and optimization. The code is available at https://github.com/TianyaoShi/FABRIC.",
      "authors": [
        "Tianyao Shi",
        "Ritbik Kumar",
        "Inez Hua",
        "Yi Ding"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Hardware Architecture (cs.AR)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T13:50:04+00:00",
          "link": "https://arxiv.org/abs/2506.20442v1",
          "size": "770kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T02:24:18+00:00",
          "link": "https://arxiv.org/abs/2506.20442v2",
          "size": "770kb",
          "version": "v2"
        }
      ],
      "title": "When Servers Meet Species: A Fab-to-Grave Lens on Computing's Biodiversity Impact",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20442",
        "HTML": "https://arxiv.org/html/2506.20442v2",
        "PDF": "https://arxiv.org/pdf/2506.20442"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper addresses the biodiversity impact of computing systems, introducing metrics for sustainability, which is unrelated to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.20474",
      "abstract": "An intrinsic aspect of every conversation is the way talk-time is shared between multiple speakers. Conversations can be balanced, with each speaker claiming a similar amount of talk-time, or imbalanced when one talks disproportionately. Such overall distributions are the consequence of continuous negotiations between the speakers throughout the conversation: who should be talking at every point in time, and for how long? In this work we introduce a computational framework for quantifying both the conversation-level distribution of talk-time between speakers, as well as the lower-level dynamics that lead to it. We derive a typology of talk-time sharing dynamics structured by several intuitive axes of variation. By applying this framework to a large dataset of video-chats between strangers, we confirm that, perhaps unsurprisingly, different conversation-level distributions of talk-time are perceived differently by speakers, with balanced conversations being preferred over imbalanced ones, especially by those who end up talking less. Then we reveal that -- even when they lead to the same level of overall balance -- different types of talk-time sharing dynamics are perceived differently by the participants, highlighting the relevance of our newly introduced typology. Finally, we discuss how our framework offers new tools to designers of computer-mediated communication platforms, for both human-human and human-AI communication.",
      "authors": [
        "Kaixiang Zhang",
        "Justine Zhang",
        "Cristian Danescu-Niculescu-Mizil"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T14:23:02+00:00",
          "link": "https://arxiv.org/abs/2506.20474v1",
          "size": "1762kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T03:08:11+00:00",
          "link": "https://arxiv.org/abs/2506.20474v2",
          "size": "1762kb",
          "version": "v2"
        }
      ],
      "title": "Time is On My Side: Dynamics of Talk-Time Sharing in Video-chat Conversations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20474",
        "HTML": "https://arxiv.org/html/2506.20474v2",
        "PDF": "https://arxiv.org/pdf/2506.20474"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The research focuses on conversation dynamics and talk-time sharing in video chats, which is not related to LLM training data in terms of collection, processing, or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.20616",
      "abstract": "Humans possess a unique ability to perceive meaningful patterns in ambiguous stimuli, a cognitive phenomenon known as pareidolia. This paper introduces Shape2Animal framework to mimics this imaginative capacity by reinterpreting natural object silhouettes, such as clouds, stones, or flames, as plausible animal forms. Our automated framework first performs open-vocabulary segmentation to extract object silhouette and interprets semantically appropriate animal concepts using vision-language models. It then synthesizes an animal image that conforms to the input shape, leveraging text-to-image diffusion model and seamlessly blends it into the original scene to generate visually coherent and spatially consistent compositions. We evaluated Shape2Animal on a diverse set of real-world inputs, demonstrating its robustness and creative potential. Our Shape2Animal can offer new opportunities for visual storytelling, educational content, digital art, and interactive media design. Our project page is here: https://shape2image.github.io",
      "authors": [
        "Quoc-Duy Tran",
        "Anh-Tuan Vo",
        "Dinh-Khoi Vo",
        "Tam V. Nguyen",
        "Minh-Triet Tran and Trung-Nghia Le"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T17:04:08+00:00",
          "link": "https://arxiv.org/abs/2506.20616v1",
          "size": "5304kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T01:15:28+00:00",
          "link": "https://arxiv.org/abs/2506.20616v2",
          "size": "5304kb",
          "version": "v2"
        }
      ],
      "title": "Shape2Animal: Creative Animal Generation from Natural Silhouettes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20616",
        "HTML": "https://arxiv.org/html/2506.20616v2",
        "PDF": "https://arxiv.org/pdf/2506.20616"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper introduces a framework for generating creative images from silhouettes, which involves visual interpretation but does not address LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.20741",
      "abstract": "Survival prediction using whole slide images (WSIs) can be formulated as a multiple instance learning (MIL) problem. However, existing MIL methods often fail to explicitly capture pathological heterogeneity within WSIs, both globally -- through long-tailed morphological distributions, and locally through -- tile-level prediction uncertainty. Optimal transport (OT) provides a principled way of modeling such heterogeneity by incorporating marginal distribution constraints. Building on this insight, we propose OTSurv, a novel MIL framework from an optimal transport perspective. Specifically, OTSurv formulates survival predictions as a heterogeneity-aware OT problem with two constraints: (1) global long-tail constraint that models prior morphological distributions to avert both mode collapse and excessive uniformity by regulating transport mass allocation, and (2) local uncertainty-aware constraint that prioritizes high-confidence patches while suppressing noise by progressively raising the total transport mass. We then recast the initial OT problem, augmented by these constraints, into an unbalanced OT formulation that can be solved with an efficient, hardware-friendly matrix scaling algorithm. Empirically, OTSurv sets new state-of-the-art results across six popular benchmarks, achieving an absolute 3.6% improvement in average C-index. In addition, OTSurv achieves statistical significance in log-rank tests and offers high interpretability, making it a powerful tool for survival prediction in digital pathology. Our codes are available at https://github.com/Y-Research-SBU/OTSurv.",
      "authors": [
        "Qin Ren",
        "Yifan Wang",
        "Ruogu Fang",
        "Haibin Ling",
        "Chenyu You"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T18:09:42+00:00",
          "link": "https://arxiv.org/abs/2506.20741v1",
          "size": "735kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T04:41:36+00:00",
          "link": "https://arxiv.org/abs/2506.20741v2",
          "size": "735kb",
          "version": "v2"
        }
      ],
      "title": "OTSurv: A Novel Multiple Instance Learning Framework for Survival Prediction with Heterogeneity-aware Optimal Transport",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20741",
        "HTML": "https://arxiv.org/html/2506.20741v2",
        "PDF": "https://arxiv.org/pdf/2506.20741"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The focus is on survival prediction in digital pathology using a novel MIL framework. This is unrelated to the training data processing for LLMs, as it does not involve language data or LLM-specific methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.20828",
      "abstract": "The rise of massive networks across diverse domains necessitates sophisticated graph analytics, often involving sensitive data and raising privacy concerns. This paper addresses these challenges using local differential privacy (LDP), which enforces privacy at the individual level, where no third-party entity is trusted, unlike centralized models that assume a trusted curator. We introduce novel LDP algorithms for two fundamental graph statistics: k-core decomposition and triangle counting. Our approach leverages input-dependent private graph properties, specifically the degeneracy and maximum degree of the graph, to improve theoretical utility. Unlike prior methods, our error bounds are determined by the maximum degree rather than the total number of edges, resulting in significantly tighter guarantees. For triangle counting, we improve upon the work of Imola, Murakami, and Chaudhury [USENIX Security `21, `22], which bounds error in terms of edge count. Instead, our algorithm achieves bounds based on graph degeneracy by leveraging a private out-degree orientation, a refined variant of Eden et al.'s randomized response technique [ICALP `23], and a novel analysis, yielding stronger guarantees than prior work. Beyond theoretical gains, we are the first to evaluate local DP algorithms in a distributed simulation, unlike prior work tested on a single processor. Experiments on real-world graphs show substantial accuracy gains: our k-core decomposition achieves errors within 3x of exact values, far outperforming the 131x error in the baseline of Dhulipala et al. [FOCS `22]. Our triangle counting algorithm reduces multiplicative approximation errors by up to six orders of magnitude, while maintaining competitive runtime.",
      "authors": [
        "Pranay Mundra",
        "Charalampos Papamanthou",
        "Julian Shun",
        "Quanquan C. Liu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Cryptography and Security (cs.CR)",
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T20:54:07+00:00",
          "link": "https://arxiv.org/abs/2506.20828v1",
          "size": "3422kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T03:23:30+00:00",
          "link": "https://arxiv.org/abs/2506.20828v2",
          "size": "3422kb",
          "version": "v2"
        }
      ],
      "title": "Practical and Accurate Local Edge Differentially Private Graph Algorithms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20828",
        "HTML": "https://arxiv.org/html/2506.20828v2",
        "PDF": "https://arxiv.org/pdf/2506.20828"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on local edge differential privacy for graph algorithms, which is unrelated to LLM training data processing or data engineering tasks specified."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.20936",
      "abstract": "Skinning and rigging are fundamental components in animation, articulated object reconstruction, motion transfer, and 4D generation. Existing approaches predominantly rely on Linear Blend Skinning (LBS), due to its simplicity and differentiability. However, LBS introduces artifacts such as volume loss and unnatural deformations, and it fails to model elastic materials like soft tissues, fur, and flexible appendages (e.g., elephant trunks, ears, and fatty tissues). In this work, we propose PhysRig: a differentiable physics-based skinning and rigging framework that overcomes these limitations by embedding the rigid skeleton into a volumetric representation (e.g., a tetrahedral mesh), which is simulated as a deformable soft-body structure driven by the animated skeleton. Our method leverages continuum mechanics and discretizes the object as particles embedded in an Eulerian background grid to ensure differentiability with respect to both material properties and skeletal motion. Additionally, we introduce material prototypes, significantly reducing the learning space while maintaining high expressiveness. To evaluate our framework, we construct a comprehensive synthetic dataset using meshes from Objaverse, The Amazing Animals Zoo, and MixaMo, covering diverse object categories and motion patterns. Our method consistently outperforms traditional LBS-based approaches, generating more realistic and physically plausible results. Furthermore, we demonstrate the applicability of our framework in the pose transfer task highlighting its versatility for articulated object modeling.",
      "authors": [
        "Hao Zhang",
        "Haolan Xu",
        "Chun Feng",
        "Varun Jampani",
        "and Narendra Ahuja"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T01:58:09+00:00",
          "link": "https://arxiv.org/abs/2506.20936v1",
          "size": "25297kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T14:58:56+00:00",
          "link": "https://arxiv.org/abs/2506.20936v2",
          "size": "25297kb",
          "version": "v2"
        }
      ],
      "title": "PhysRig: Differentiable Physics-Based Skinning and Rigging Framework for Realistic Articulated Object Modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20936",
        "HTML": "https://arxiv.org/html/2506.20936v2",
        "PDF": "https://arxiv.org/pdf/2506.20936"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper proposes a physics-based framework for skinning and rigging in animation, which is not related to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.20967",
      "abstract": "The advent of Video Diffusion Transformers (Video DiTs) marks a milestone in video generation. However, directly applying existing video editing methods to Video DiTs often incurs substantial computational overhead, due to resource-intensive attention modification or finetuning. To alleviate this problem, we present DFVEdit, an efficient zero-shot video editing method tailored for Video DiTs. DFVEdit eliminates the need for both attention modification and fine-tuning by directly operating on clean latents via flow transformation. To be more specific, we observe that editing and sampling can be unified under the continuous flow perspective. Building upon this foundation, we propose the Conditional Delta Flow Vector (CDFV) -- a theoretically unbiased estimation of DFV -- and integrate Implicit Cross Attention (ICA) guidance as well as Embedding Reinforcement (ER) to further enhance editing quality. DFVEdit excels in practical efficiency, offering at least 20x inference speed-up and 85% memory reduction on Video DiTs compared to attention-engineering-based editing methods. Extensive quantitative and qualitative experiments demonstrate that DFVEdit can be seamlessly applied to popular Video DiTs (e.g., CogVideoX and Wan2.1), attaining state-of-the-art performance on structural fidelity, spatial-temporal consistency, and editing quality.",
      "authors": [
        "Lingling Cai",
        "Kang Zhao",
        "Hangjie Yuan",
        "Xiang Wang",
        "Yingya Zhang",
        "Kejie Huang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T03:10:13+00:00",
          "link": "https://arxiv.org/abs/2506.20967v1",
          "size": "12976kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T08:42:17+00:00",
          "link": "https://arxiv.org/abs/2506.20967v2",
          "size": "12976kb",
          "version": "v2"
        }
      ],
      "title": "DFVEdit: Conditional Delta Flow Vector for Zero-shot Video Editing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20967",
        "HTML": "https://arxiv.org/html/2506.20967v2",
        "PDF": "https://arxiv.org/pdf/2506.20967"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper presents a method for zero-shot video editing using Video DiTs, which is not related to LLM training data processing or data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.20995",
      "abstract": "We propose a novel step-by-step video-to-audio generation method that sequentially produces individual audio tracks, each corresponding to a specific sound event in the video. Our approach mirrors traditional Foley workflows, aiming to capture all sound events induced by a given video comprehensively. Each generation step is formulated as a guided video-to-audio synthesis task, conditioned on a target text prompt and previously generated audio tracks. This design is inspired by the idea of concept negation from prior compositional generation frameworks. To enable this guided generation, we introduce a training framework that leverages pre-trained video-to-audio models and eliminates the need for specialized paired datasets, allowing training on more accessible data. Experimental results demonstrate that our method generates multiple semantically distinct audio tracks for a single input video, leading to higher-quality composite audio synthesis than existing baselines.",
      "authors": [
        "Akio Hayakawa",
        "Masato Ishii",
        "Takashi Shibuya",
        "Yuki Mitsufuji"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T04:20:08+00:00",
          "link": "https://arxiv.org/abs/2506.20995v1",
          "size": "3285kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T06:33:56+00:00",
          "link": "https://arxiv.org/abs/2506.20995v2",
          "size": "3285kb",
          "version": "v2"
        }
      ],
      "title": "Step-by-Step Video-to-Audio Synthesis via Negative Audio Guidance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20995",
        "HTML": "https://arxiv.org/html/2506.20995v2",
        "PDF": "https://arxiv.org/pdf/2506.20995"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The focus is on video-to-audio synthesis and does not involve LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21008",
      "abstract": "We introduce the Aging Multiverse, a framework for generating multiple plausible facial aging trajectories from a single image, each conditioned on external factors such as environment, health, and lifestyle. Unlike prior methods that model aging as a single deterministic path, our approach creates an aging tree that visualizes diverse futures. To enable this, we propose a training-free diffusion-based method that balances identity preservation, age accuracy, and condition control. Our key contributions include attention mixing to modulate editing strength and a Simulated Aging Regularization strategy to stabilize edits. Extensive experiments and user studies demonstrate state-of-the-art performance across identity preservation, aging realism, and conditional alignment, outperforming existing editing and age-progression models, which often fail to account for one or more of the editing criteria. By transforming aging into a multi-dimensional, controllable, and interpretable process, our approach opens up new creative and practical avenues in digital storytelling, health education, and personalized visualization.",
      "authors": [
        "Bang Gong",
        "Luchao Qi",
        "Jiaye Wu",
        "Zhicheng Fu",
        "Chunbo Song",
        "David W. Jacobs",
        "John Nicholson",
        "Roni Sengupta"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T04:57:47+00:00",
          "link": "https://arxiv.org/abs/2506.21008v1",
          "size": "10455kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T04:43:26+00:00",
          "link": "https://arxiv.org/abs/2506.21008v2",
          "size": "11075kb",
          "version": "v2"
        }
      ],
      "title": "The Aging Multiverse: Generating Condition-Aware Facial Aging Tree via Training-Free Diffusion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21008",
        "HTML": "https://arxiv.org/html/2506.21008v2",
        "PDF": "https://arxiv.org/pdf/2506.21008"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on generating plausible facial aging trajectories using a diffusion-based method, and does not address any aspect of LLM training data collection, construction, or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21034",
      "abstract": "Commercial RGB-D cameras often produce noisy, incomplete depth maps for non-Lambertian objects. Traditional depth completion methods struggle to generalize due to the limited diversity and scale of training data. Recent advances exploit visual priors from pre-trained text-to-image diffusion models to enhance generalization in dense prediction tasks. However, we find that biases arising from training-inference mismatches in the vanilla diffusion framework significantly impair depth completion performance. Additionally, the lack of distinct visual features in non-Lambertian regions further hinders precise prediction. To address these issues, we propose \\textbf{DidSee}, a diffusion-based framework for depth completion on non-Lambertian objects. First, we integrate a rescaled noise scheduler enforcing a zero terminal signal-to-noise ratio to eliminate signal leakage bias. Second, we devise a noise-agnostic single-step training formulation to alleviate error accumulation caused by exposure bias and optimize the model with a task-specific loss. Finally, we incorporate a semantic enhancer that enables joint depth completion and semantic segmentation, distinguishing objects from backgrounds and yielding precise, fine-grained depth maps. DidSee achieves state-of-the-art performance on multiple benchmarks, demonstrates robust real-world generalization, and effectively improves downstream tasks such as category-level pose estimation and robotic grasping.",
      "authors": [
        "Wenzhou Lyu",
        "Jialing Lin",
        "Wenqi Ren",
        "Ruihao Xia",
        "Feng Qian",
        "Yang Tang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T06:18:42+00:00",
          "link": "https://arxiv.org/abs/2506.21034v1",
          "size": "5732kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T01:36:33+00:00",
          "link": "https://arxiv.org/abs/2506.21034v2",
          "size": "5732kb",
          "version": "v2"
        }
      ],
      "title": "DidSee: Diffusion-Based Depth Completion for Material-Agnostic Robotic Perception and Manipulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21034",
        "HTML": "https://arxiv.org/html/2506.21034v2",
        "PDF": "https://arxiv.org/pdf/2506.21034"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper presents a diffusion-based framework for depth completion and primarily addresses issues related to robotics and computer vision, without discussing LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21233",
      "abstract": "Training-free open-vocabulary semantic segmentation (OVS) aims to segment images given a set of arbitrary textual categories without costly model fine-tuning. Existing solutions often explore attention mechanisms of pre-trained models, such as CLIP, or generate synthetic data and design complex retrieval processes to perform OVS. However, their performance is limited by the capability of reliant models or the suboptimal quality of reference sets. In this work, we investigate the largely overlooked data quality problem for this challenging dense scene understanding task, and identify that a high-quality reference set can significantly benefit training-free OVS. With this observation, we introduce a data-quality-oriented framework, comprising a data pipeline to construct a reference set with well-paired segment-text embeddings and a simple similarity-based retrieval to unveil the essential effect of data. Remarkably, extensive evaluations on ten benchmark datasets demonstrate that our method outperforms all existing training-free OVS approaches, highlighting the importance of data-centric design for advancing OVS without training. Our code is available at https://github.com/xiweix/ReME .",
      "authors": [
        "Xiwei Xuan",
        "Ziquan Deng",
        "Kwan-Liu Ma"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T13:22:03+00:00",
          "link": "https://arxiv.org/abs/2506.21233v1",
          "size": "35778kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T12:06:27+00:00",
          "link": "https://arxiv.org/abs/2506.21233v2",
          "size": "35779kb",
          "version": "v2"
        }
      ],
      "title": "ReME: A Data-Centric Framework for Training-Free Open-Vocabulary Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21233",
        "HTML": "https://arxiv.org/html/2506.21233v2",
        "PDF": "https://arxiv.org/pdf/2506.21233"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper proposes a data-centric framework for open-vocabulary semantic segmentation, which includes constructing a reference data set with well-paired segment-text embeddings, making its primary contribution related to data processing strategies."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21272",
      "abstract": "We propose FairyGen, an automatic system for generating story-driven cartoon videos from a single child's drawing, while faithfully preserving its unique artistic style. Unlike previous storytelling methods that primarily focus on character consistency and basic motion, FairyGen explicitly disentangles character modeling from stylized background generation and incorporates cinematic shot design to support expressive and coherent storytelling. Given a single character sketch, we first employ an MLLM to generate a structured storyboard with shot-level descriptions that specify environment settings, character actions, and camera perspectives. To ensure visual consistency, we introduce a style propagation adapter that captures the character's visual style and applies it to the background, faithfully retaining the character's full visual identity while synthesizing style-consistent scenes. A shot design module further enhances visual diversity and cinematic quality through frame cropping and multi-view synthesis based on the storyboard. To animate the story, we reconstruct a 3D proxy of the character to derive physically plausible motion sequences, which are then used to fine-tune an MMDiT-based image-to-video diffusion model. We further propose a two-stage motion customization adapter: the first stage learns appearance features from temporally unordered frames, disentangling identity from motion; the second stage models temporal dynamics using a timestep-shift strategy with frozen identity weights. Once trained, FairyGen directly renders diverse and coherent video scenes aligned with the storyboard. Extensive experiments demonstrate that our system produces animations that are stylistically faithful, narratively structured natural motion, highlighting its potential for personalized and engaging story animation. The code will be available at https://github.com/GVCLab/FairyGen",
      "authors": [
        "Jiayi Zheng and Xiaodong Cun"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T13:58:16+00:00",
          "link": "https://arxiv.org/abs/2506.21272v1",
          "size": "14794kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T01:04:39+00:00",
          "link": "https://arxiv.org/abs/2506.21272v2",
          "size": "14794kb",
          "version": "v2"
        }
      ],
      "title": "FairyGen: Storied Cartoon Video from a Single Child-Drawn Character",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21272",
        "HTML": "https://arxiv.org/html/2506.21272v2",
        "PDF": "https://arxiv.org/pdf/2506.21272"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper describes a system for generating cartoon videos with a focus on artistic style preservation and storytelling, without relevant contributions to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21327",
      "abstract": "There is growing interest in providing programmatic access to the value locked in Bitcoin, which famously offers limited programmability itself. Various approaches have been put forth in recent years, with the vast majority of proposed mechanisms either building new functionality on top of Bitcoin or leveraging a bridging mechanism to enable smart contracts that make use of ``wrapped'' bitcoins on entirely different platforms.\n  In this work, an architecture is presented that follows a different approach. The architecture enables the execution of Turing-complete Bitcoin smart contracts on the Internet Computer (IC), a blockchain platform for hosting and executing decentralized applications. Instead of using a bridge, IC and Bitcoin nodes interact directly, eliminating potential security risks that the use of a bridge entails. This integration requires novel concepts, in particular to reconcile the probabilistic nature of Bitcoin with the irreversibility of finalized state changes on the IC, which may be of independent interest.\n  In addition to the presentation of the architecture, we provide evaluation results based on measurements of the Bitcoin integration running on mainnet. The evaluation results demonstrate that, with finalization in a few seconds and low execution costs, this integration enables complex Bitcoin-based decentralized applications that were not practically feasible or economically viable before.",
      "authors": [
        "Ryan Croote",
        "Islam El-Ashi",
        "Thomas Locher",
        "Yvonne-Anne Pignolet"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T14:41:01+00:00",
          "link": "https://arxiv.org/abs/2506.21327v1",
          "size": "411kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T05:12:20+00:00",
          "link": "https://arxiv.org/abs/2506.21327v2",
          "size": "412kb",
          "version": "v2"
        }
      ],
      "title": "Enabling Bitcoin Smart Contracts on the Internet Computer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21327",
        "HTML": "https://arxiv.org/html/2506.21327v2",
        "PDF": "https://arxiv.org/pdf/2506.21327"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper discusses the architecture for executing Bitcoin smart contracts on the Internet Computer, focusing on blockchain interactions rather than any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21333",
      "abstract": "The co creativity community is making significant progress in developing more sophisticated and tailored systems to support and enhance human creativity. Design considerations from prior work can serve as a valuable and efficient foundation for future systems. To support this effort, we conducted a systematic literature review of 62 papers on co-creative systems. These papers cover a diverse range of applications, including visual arts, design, and writing, where the AI acts not just as a tool but as an active collaborator in the creative process. From this review, we identified several key dimensions relevant to system design: phase of the creative process, creative task, proactive behavior of the system, user control, system embodiment, and AI model type. Our findings suggest that systems offering high user control lead to greater satisfaction, trust, and a stronger sense of ownership over creative outcomes. Furthermore, proactive systems, when adaptive and context sensitive, can enhance collaboration. We also extracted 24 design considerations, highlighting the value of encouraging users to externalize their thoughts and of increasing the system's social presence and transparency to foster trust. Despite recent advancements, important gaps remain, such as limited support for early creative phases like problem clarification, and challenges related to user adaptation to AI systems.",
      "authors": [
        "Saloni Singh",
        "Koen Hindriks",
        "Dirk Heylen",
        "Kim Baraka"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T14:44:52+00:00",
          "link": "https://arxiv.org/abs/2506.21333v1",
          "size": "1851kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T09:31:02+00:00",
          "link": "https://arxiv.org/abs/2506.21333v2",
          "size": "1851kb",
          "version": "v2"
        }
      ],
      "title": "A Systematic Review of Human-AI Co-Creativity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21333",
        "PDF": "https://arxiv.org/pdf/2506.21333"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper provides a systematic literature review of human-AI co-creativity systems, focusing on design considerations and co-creative processes without discussing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21356",
      "abstract": "Cinematography, the fundamental visual language of film, is essential for conveying narrative, emotion, and aesthetic quality. While recent Vision-Language Models (VLMs) demonstrate strong general visual understanding, their proficiency in comprehending the nuanced cinematic grammar embedded within individual shots remains largely unexplored and lacks robust evaluation. This critical gap limits both fine-grained visual comprehension and the precision of AI-assisted video generation. To address this, we introduce ShotBench, a comprehensive benchmark specifically designed for cinematic language understanding. It features over 3.5k expert-annotated QA pairs from images and video clips, meticulously curated from over 200 acclaimed (predominantly Oscar-nominated) films and spanning eight key cinematography dimensions. Our evaluation of 24 leading VLMs on ShotBench reveals their substantial limitations: even the top-performing model achieves less than 60% average accuracy, particularly struggling with fine-grained visual cues and complex spatial reasoning. To catalyze advancement in this domain, we construct ShotQA, a large-scale multimodal dataset comprising approximately 70k cinematic QA pairs. Leveraging ShotQA, we develop ShotVL through supervised fine-tuning and Group Relative Policy Optimization. ShotVL significantly outperforms all existing open-source and proprietary models on ShotBench, establishing new state-of-the-art performance. We open-source our models, data, and code to foster rapid progress in this crucial area of AI-driven cinematic understanding and generation.",
      "authors": [
        "Hongbo Liu",
        "Jingwen He",
        "Yi Jin",
        "Dian Zheng",
        "Yuhao Dong",
        "Fan Zhang",
        "Ziqi Huang",
        "Yinan He",
        "Yangguang Li",
        "Weichao Chen",
        "Yu Qiao",
        "Wanli Ouyang",
        "Shengjie Zhao",
        "Ziwei Liu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T15:09:21+00:00",
          "link": "https://arxiv.org/abs/2506.21356v1",
          "size": "10722kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T05:10:18+00:00",
          "link": "https://arxiv.org/abs/2506.21356v2",
          "size": "10722kb",
          "version": "v2"
        }
      ],
      "title": "ShotBench: Expert-Level Cinematic Understanding in Vision-Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21356",
        "HTML": "https://arxiv.org/html/2506.21356v2",
        "PDF": "https://arxiv.org/pdf/2506.21356"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces a benchmark (ShotBench) for cinematic understanding that involves data annotation and processing, its focus is not on LLM training data. It does, however, involve supervised fine-tuning, which is related to data processing during training."
      },
      "source": "arXiv"
    },
    {
      "id": "2001.04515",
      "abstract": "Reinforcement learning is a general technique that allows an agent to learn an optimal policy and interact with an environment in sequential decision making problems. The goodness of a policy is measured by its value function starting from some initial state. The focus of this paper is to construct confidence intervals (CIs) for a policy's value in infinite horizon settings where the number of decision points diverges to infinity. We propose to model the action-value state function (Q-function) associated with a policy based on series/sieve method to derive its confidence interval. When the target policy depends on the observed data as well, we propose a SequentiAl Value Evaluation (SAVE) method to recursively update the estimated policy and its value estimator. As long as either the number of trajectories or the number of decision points diverges to infinity, we show that the proposed CI achieves nominal coverage even in cases where the optimal policy is not unique. Simulation studies are conducted to back up our theoretical findings. We apply the proposed method to a dataset from mobile health studies and find that reinforcement learning algorithms could help improve patient's health status. A Python implementation of the proposed procedure is available at https://github.com/shengzhang37/SAVE.",
      "authors": [
        "C. Shi",
        "S. Zhang",
        "W. Lu and R. Song"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2020-01-13T19:42:40+00:00",
          "link": "https://arxiv.org/abs/2001.04515v1",
          "size": "912kb",
          "version": "v1"
        },
        {
          "date": "2021-06-20T20:28:50+00:00",
          "link": "https://arxiv.org/abs/2001.04515v2",
          "size": "5314kb",
          "version": "v2"
        },
        {
          "date": "2025-06-26T18:35:13+00:00",
          "link": "https://arxiv.org/abs/2001.04515v3",
          "size": "4297kb",
          "version": "v3"
        }
      ],
      "title": "Statistical Inference of the Value Function for Reinforcement Learning in Infinite Horizon Settings",
      "links": {
        "Abstract": "https://arxiv.org/abs/2001.04515",
        "PDF": "https://arxiv.org/pdf/2001.04515"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper focuses on reinforcement learning, proposing a method to construct confidence intervals for policy value in infinite horizon settings, without addressing any aspects of LLM training data processing or engineering."
      },
      "tasks": [
        "Decision Making",
        "reinforcement-learning",
        "Reinforcement Learning",
        "Reinforcement Learning (RL)",
        "Sequential Decision Making"
      ],
      "repo_urls": [
        "https://github.com/shengzhang37/SAVE"
      ],
      "source": "arXiv"
    },
    {
      "id": "2212.10872",
      "abstract": "Random graph models with community structure have been studied extensively in the literature. For both the problems of detecting and recovering community structure, an interesting landscape of statistical and computational phase transitions has emerged. A natural unanswered question is: might it be possible to infer properties of the community structure (for instance, the number and sizes of communities) even in situations where actually finding those communities is believed to be computationally hard? We show the answer is no. In particular, we consider certain hypothesis testing problems between models with different community structures, and we show (in the low-degree polynomial framework) that testing between two options is as hard as finding the communities.\n  Our methods give the first computational lower bounds for testing between two different ``planted'' distributions, whereas previous results have considered testing between a planted distribution and an i.i.d. ``null'' distribution. We also show a formal relationship between the low--degree frameworks for recovery in a planted model and for testing two planted models.",
      "authors": [
        "Cynthia Rush",
        "Fiona Skerman",
        "Alexander S. Wein and Dana Yang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Statistics Theory (math.ST)",
        "Computational Complexity (cs.CC)",
        "Data Structures and Algorithms (cs.DS)",
        "Combinatorics (math.CO)",
        "Machine Learning (stat.ML)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2022-12-21T09:35:19+00:00",
          "link": "https://arxiv.org/abs/2212.10872v1",
          "size": "24kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T14:42:01+00:00",
          "link": "https://arxiv.org/abs/2212.10872v2",
          "size": "115kb",
          "version": "v2"
        }
      ],
      "title": "Is it easier to count communities than find them?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2212.10872",
        "HTML": "https://arxiv.org/html/2212.10872v2",
        "PDF": "https://arxiv.org/pdf/2212.10872"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper addresses hypothesis testing problems in graph models with community structure, not involving any aspect of LLM training data collection or processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2309.01750",
      "abstract": "Two CNF formulas are called ucp-equivalent, if they behave in the same way with respect to the unit clause propagation (UCP). A formula is called ucp-irredundant, if removing any clause leads to a formula which is not ucp-equivalent to the original one. As a consequence of known results, the ratio of the size of a ucp-irredundant formula and the size of a smallest ucp-equivalent formula is at most $n^2$, where $n$ is the number of the variables. We demonstrate an example of a ucp-irredundant formula for a symmetric definite Horn function which is larger than a smallest ucp-equivalent formula by a factor $\\Omega(n/\\ln n)$. Consequently, a general upper bound on the above ratio cannot be smaller than this.",
      "authors": [
        "Petr Savick\\'y"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2023-09-04T18:15:34+00:00",
          "link": "https://arxiv.org/abs/2309.01750v1",
          "size": "14kb",
          "version": "v1"
        },
        {
          "date": "2023-10-03T17:44:24+00:00",
          "link": "https://arxiv.org/abs/2309.01750v2",
          "size": "15kb",
          "version": "v2"
        },
        {
          "date": "2024-01-30T17:59:18+00:00",
          "link": "https://arxiv.org/abs/2309.01750v3",
          "size": "16kb",
          "version": "v3"
        },
        {
          "date": "2024-08-04T12:52:05+00:00",
          "link": "https://arxiv.org/abs/2309.01750v4",
          "size": "17kb",
          "version": "v4"
        },
        {
          "date": "2025-06-27T13:29:57+00:00",
          "link": "https://arxiv.org/abs/2309.01750v5",
          "size": "19kb",
          "version": "v5"
        }
      ],
      "title": "On CNF formulas irredundant with respect to unit clause propagation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2309.01750",
        "HTML": "https://arxiv.org/html/2309.01750v5",
        "PDF": "https://arxiv.org/pdf/2309.01750"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on CNF formulas and unit clause propagation, which are related to theoretical computer science and logic rather than LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2402.17067",
      "abstract": "The mixing time of a Markov chain determines how fast the iterates of the Markov chain converge to the stationary distribution; however, it does not control the dependencies between samples along the Markov chain. In this paper, we study the question of how fast the samples become approximately independent along popular Markov chains for continuous-space sampling: the Langevin dynamics in continuous time, and the Unadjusted Langevin Algorithm and the Proximal Sampler in discrete time. We measure the dependence between samples via $\\Phi$-mutual information, which is a broad generalization of the standard mutual information, and which is equal to $0$ if and only if the the samples are independent. We show that along these Markov chains, the $\\Phi$-mutual information between the first and the $k$-th iterate decreases to $0$ exponentially fast in $k$ when the target distribution is strongly log-concave. Our proof technique is based on showing the Strong Data Processing Inequalities (SDPIs) hold along the Markov chains. To prove fast mixing of the Markov chains, we only need to show the SDPIs hold for the stationary distribution. In contrast, to prove the contraction of $\\Phi$-mutual information, we need to show the SDPIs hold along the entire trajectories of the Markov chains; we prove this when the iterates along the Markov chains satisfy the corresponding $\\Phi$-Sobolev inequality, which is implied by the strong log-concavity of the target distribution.",
      "authors": [
        "Jiaming Liang",
        "Siddharth Mitra",
        "Andre Wibisono"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Statistics Theory (math.ST)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)",
        "Machine Learning (stat.ML)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-26T23:05:02+00:00",
          "link": "https://arxiv.org/abs/2402.17067v1",
          "size": "33kb",
          "version": "v1"
        },
        {
          "date": "2025-02-08T18:00:36+00:00",
          "link": "https://arxiv.org/abs/2402.17067v2",
          "size": "52kb",
          "version": "v2"
        },
        {
          "date": "2025-06-26T22:01:36+00:00",
          "link": "https://arxiv.org/abs/2402.17067v3",
          "size": "55kb",
          "version": "v3"
        }
      ],
      "title": "Characterizing Dependence of Samples along the Langevin Dynamics and Algorithms via Contraction of $\\Phi$-Mutual Information",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.17067",
        "HTML": "https://arxiv.org/html/2402.17067v3",
        "PDF": "https://arxiv.org/pdf/2402.17067"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper deals with the convergence of Markov chains and sample independence in the context of Langevin dynamics, which is unrelated to the processing of training data for LLMs."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2404.14323",
      "abstract": "Wave-particle duality, a fundamental principle of quantum mechanics, encapsulates the complementary relationship between the wave and particle behaviors of quantum systems. In this paper, we treat quantum coherence and classical distinguishability as complementary resources and uncover a novel duality relation, which is explored through quantum state discrimination under incoherent operations, extending beyond typical interference scenarios. We prove that in an ensemble of mutually orthogonal pure states, the sum of `co-bits', quantifying the coherence preserved under incoherent free operations, and classical bits, representing the distinguishability extracted via quantum state discrimination, is bounded. This coherence-distinguishability duality relation exposes an inherent trade-off between the simultaneous preservation of a system's quantum coherence (wave-like property) and the extraction of its classical distinguishability (particle-like property). Our findings provide a fresh perspective on wave-particle duality through quantum resource theories, offering complementary insights into manipulating quantum and classical resources, with implications for quantum foundations and quantum technologies.",
      "authors": [
        "Zhiping Liu",
        "Chengkai Zhu",
        "Hua-Lei Yin",
        "Xin Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-22T16:33:31+00:00",
          "link": "https://arxiv.org/abs/2404.14323v1",
          "size": "1065kb",
          "version": "v1"
        },
        {
          "date": "2024-11-18T09:09:49+00:00",
          "link": "https://arxiv.org/abs/2404.14323v2",
          "size": "1164kb",
          "version": "v2"
        },
        {
          "date": "2024-11-19T05:27:02+00:00",
          "link": "https://arxiv.org/abs/2404.14323v3",
          "size": "1164kb",
          "version": "v3"
        },
        {
          "date": "2025-06-27T16:00:28+00:00",
          "link": "https://arxiv.org/abs/2404.14323v4",
          "size": "198kb",
          "version": "v4"
        }
      ],
      "title": "Quantum Coherence and Distinguishability as Complementary Resources: A Resource-Theoretic Perspective from Wave-Particle Duality",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.14323",
        "HTML": "https://arxiv.org/html/2404.14323v4",
        "PDF": "https://arxiv.org/pdf/2404.14323"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper explores quantum coherence and distinguishability within the context of quantum mechanics, without any focus on LLM training data engineering or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2405.09493",
      "abstract": "Popular debiased estimation methods for causal inference -- such as augmented inverse propensity weighting and targeted maximum likelihood estimation -- enjoy desirable asymptotic properties like statistical efficiency and double robustness but they can produce unstable estimates when there is limited overlap between treatment and control, requiring additional assumptions or ad hoc adjustments in practice (e.g., truncating propensity scores). In contrast, simple plug-in estimators are stable but lack desirable asymptotic properties. We propose a novel debiasing approach that achieves the best of both worlds, producing stable plug-in estimates with desirable asymptotic properties. Our constrained learning framework solves for the best plug-in estimator under the constraint that the first-order error with respect to the plugged-in quantity is zero, and can leverage flexible model classes including neural networks and tree ensembles. In several experimental settings, including ones in which we handle text-based covariates by fine-tuning language models, our constrained learning-based estimator outperforms basic versions of one-step estimation and targeting in challenging settings with limited overlap between treatment and control, and performs similarly otherwise.",
      "authors": [
        "Tiffany Tianhui Cai",
        "Yuri Fonseca",
        "Kaiwen Hou",
        "Hongseok Namkoong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-15T16:38:28+00:00",
          "link": "https://arxiv.org/abs/2405.09493v1",
          "size": "50kb",
          "version": "v1"
        },
        {
          "date": "2024-05-22T05:45:43+00:00",
          "link": "https://arxiv.org/abs/2405.09493v2",
          "size": "454kb",
          "version": "v2"
        },
        {
          "date": "2024-10-14T16:34:30+00:00",
          "link": "https://arxiv.org/abs/2405.09493v3",
          "size": "489kb",
          "version": "v3"
        },
        {
          "date": "2025-06-24T18:19:45+00:00",
          "link": "https://arxiv.org/abs/2405.09493v4",
          "size": "496kb",
          "version": "v4"
        },
        {
          "date": "2025-06-27T08:45:28+00:00",
          "link": "https://arxiv.org/abs/2405.09493v5",
          "size": "489kb",
          "version": "v5"
        }
      ],
      "title": "C-Learner: Constrained Learning for Causal Inference",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.09493",
        "PDF": "https://arxiv.org/pdf/2405.09493"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper mentions the use of language models in fine-tuning for handling text-based covariates within a causal inference framework, but does not focus on LLM training data processing or propose any new data-related methods."
      },
      "tasks": [
        "Causal Inference"
      ],
      "source": "arXiv"
    },
    {
      "id": "2406.04753",
      "abstract": "By a classic result of Gessel, the exponential generating functions for $k$-regular graphs are D-finite. Using Gr\\\"obner bases in Weyl algebras, we compute the linear differential equations satisfied by the generating function for 5-, 6-, and 7- regular graphs. The method is sufficiently robust to consider variants such as graphs with multiple edges, loops, and graphs whose degrees are limited to fixed sets of values.",
      "authors": [
        "Fr\\'ed\\'eric Chyzak and Marni Mishna"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Symbolic Computation (cs.SC)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-07T08:53:04+00:00",
          "link": "https://arxiv.org/abs/2406.04753v1",
          "size": "24kb",
          "version": "v1"
        },
        {
          "date": "2024-09-02T11:32:42+00:00",
          "link": "https://arxiv.org/abs/2406.04753v2",
          "size": "26kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T13:54:28+00:00",
          "link": "https://arxiv.org/abs/2406.04753v3",
          "size": "34kb",
          "version": "v3"
        }
      ],
      "title": "Differential equations satisfied by generating functions of 5-, 6-, and 7-regular labelled graphs: a reduction-based approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.04753",
        "HTML": "https://arxiv.org/html/2406.04753v3",
        "PDF": "https://arxiv.org/pdf/2406.04753"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper deals with computing differential equations for generating functions of regular graphs using Gr\\\"obner bases and does not address LLM data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2407.19353",
      "abstract": "Feature-learning deep nets progressively collapse data to a regular low-dimensional geometry. How this emerges from the collective action of nonlinearity, noise, learning rate, and other factors, has eluded first-principles theories built from microscopic neuronal dynamics. We exhibit a noise-nonlinearity phase diagram that identifies regimes where shallow or deep layers learn more effectively and propose a macroscopic mechanical theory that reproduces the diagram and links feature learning across layers to generalization.",
      "authors": [
        "Cheng Shi",
        "Liming Pan and Ivan Dokmani\\'c"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
        "Statistical Mechanics (cond-mat.stat-mech)",
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-28T00:07:20+00:00",
          "link": "https://arxiv.org/abs/2407.19353v1",
          "size": "2242kb",
          "version": "v1"
        },
        {
          "date": "2024-10-23T14:11:34+00:00",
          "link": "https://arxiv.org/abs/2407.19353v2",
          "size": "2963kb",
          "version": "v2"
        },
        {
          "date": "2025-06-08T17:25:08+00:00",
          "link": "https://arxiv.org/abs/2407.19353v3",
          "size": "5176kb",
          "version": "v3"
        },
        {
          "date": "2025-06-27T14:20:12+00:00",
          "link": "https://arxiv.org/abs/2407.19353v4",
          "size": "5176kb",
          "version": "v4"
        }
      ],
      "title": "Spring-block theory of feature learning in deep neural networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.19353",
        "HTML": "https://arxiv.org/html/2407.19353v4",
        "PDF": "https://arxiv.org/pdf/2407.19353"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on the theory of feature learning in deep neural networks, examining factors like nonlinearity and noise impacting learning across neural network layers, rather than LLM training data processing."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/DaDaCheng/DNN_Spring"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.13214",
      "abstract": "Accurate forecasting of the EUR/USD exchange rate is crucial for investors, businesses, and policymakers. This paper proposes a novel framework, IUS, that integrates unstructured textual data from news and analysis with structured data on exchange rates and financial indicators to enhance exchange rate prediction. The IUS framework employs large language models for sentiment polarity scoring and exchange rate movement classification of texts. These textual features are combined with quantitative features and input into a Causality-Driven Feature Generator. An Optuna-optimized Bi-LSTM model is then used to forecast the EUR/USD exchange rate. Experiments demonstrate that the proposed method outperforms benchmark models, reducing MAE by 10.69% and RMSE by 9.56% compared to the best performing baseline. Results also show the benefits of data fusion, with the combination of unstructured and structured data yielding higher accuracy than structured data alone. Furthermore, feature selection using the top 12 important quantitative features combined with the textual features proves most effective. The proposed IUS framework and Optuna-Bi-LSTM model provide a powerful new approach for exchange rate forecasting through multi-source data integration.",
      "authors": [
        "Hongcheng Ding",
        "Xuanze Zhao",
        "Ruiting Deng",
        "Shamsul Nahar Abdullah",
        "Deshinta Arrova Dewi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Finance (q-fin.CP)",
        "Artificial Intelligence (cs.AI)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-23T16:46:36+00:00",
          "link": "https://arxiv.org/abs/2408.13214v1",
          "size": "11887kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T06:57:32+00:00",
          "link": "https://arxiv.org/abs/2408.13214v2",
          "size": "10843kb",
          "version": "v2"
        }
      ],
      "title": "EUR-USD Exchange Rate Forecasting Based on Information Fusion with Large Language Models and Deep Learning Methods",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.13214",
        "HTML": "https://arxiv.org/html/2408.13214v2",
        "PDF": "https://arxiv.org/pdf/2408.13214"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper integrates LLMs for sentiment analysis in exchange rate prediction, its main focus is on using existing data types and combining them with deep learning techniques. It does not propose new data collection or preprocessing methods for LLMs."
      },
      "tasks": [
        "Data Integration",
        "feature selection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.15969",
      "abstract": "We examine stability properties of primal-dual gradient flow dynamics for composite convex optimization problems with multiple, possibly nonsmooth, terms in the objective function under the generalized consensus constraint. The proposed dynamics are based on the proximal augmented Lagrangian and they provide a viable alternative to ADMM which faces significant challenges from both analysis and implementation viewpoints in large-scale multi-block scenarios. In contrast to customized algorithms with individualized convergence guarantees, we develop a systematic approach for solving a broad class of challenging composite optimization problems. We leverage various structural properties to establish global (exponential) convergence guarantees for the proposed dynamics. Our assumptions are much weaker than those required to prove (exponential) stability of primal-dual dynamics as well as (linear) convergence of discrete-time methods such as standard two-block and multi-block ADMM and EXTRA algorithms. Finally, we show necessity of some of our structural assumptions for exponential stability and provide computational experiments to demonstrate the convenience of the proposed approach for parallel and distributed computing applications.",
      "authors": [
        "Ibrahim K. Ozaslan",
        "Panagiotis Patrinos",
        "Mihailo R. Jovanovi\\'c"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-28T17:43:18+00:00",
          "link": "https://arxiv.org/abs/2408.15969v1",
          "size": "750kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T04:25:57+00:00",
          "link": "https://arxiv.org/abs/2408.15969v2",
          "size": "316kb",
          "version": "v2"
        }
      ],
      "title": "Stability of Primal-Dual Gradient Flow Dynamics for Multi-Block Convex Optimization Problems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.15969",
        "HTML": "https://arxiv.org/html/2408.15969v2",
        "PDF": "https://arxiv.org/pdf/2408.15969"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper discusses primal-dual gradient flow dynamics for convex optimization problems, focusing on stability and convergence analysis, which is unrelated to LLM training data processing or data engineering tasks."
      },
      "tasks": [
        "Distributed Computing"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.15548",
      "abstract": "Adaptive Conformal Inference (ACI) provides finite-sample coverage guarantees, enhancing the prediction reliability under non-exchangeability. This study demonstrates that these desirable properties of ACI do not require the use of Conformal Predictors (CP). We show that the guarantees hold for the broader class of confidence predictors, defined by the requirement of producing nested prediction sets, a property we argue is essential for meaningful confidence statements. We empirically investigate the performance of Non-Conformal Confidence Predictors (NCCP) against CP when used with ACI on non-exchangeable data. In online settings, the NCCP offers significant computational advantages while maintaining a comparable predictive efficiency. In batch settings, inductive NCCP (INCCP) can outperform inductive CP (ICP) by utilising the full training dataset without requiring a separate calibration set, leading to improved efficiency, particularly when the data are limited. Although these initial results highlight NCCP as a theoretically sound and practically effective alternative to CP for uncertainty quantification with ACI in non-exchangeable scenarios, further empirical studies are warranted across diverse datasets and predictors.",
      "authors": [
        "Johan Hallberg Szabadv\\'ary",
        "Tuwe L\\\"ofstr\\\"om"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-23T21:02:33+00:00",
          "link": "https://arxiv.org/abs/2409.15548v1",
          "size": "174kb",
          "version": "v1"
        },
        {
          "date": "2024-09-25T20:53:48+00:00",
          "link": "https://arxiv.org/abs/2409.15548v2",
          "size": "174kb",
          "version": "v2"
        },
        {
          "date": "2024-10-25T12:36:05+00:00",
          "link": "https://arxiv.org/abs/2409.15548v3",
          "size": "348kb",
          "version": "v3"
        },
        {
          "date": "2025-06-26T20:25:03+00:00",
          "link": "https://arxiv.org/abs/2409.15548v4",
          "size": "337kb",
          "version": "v4"
        }
      ],
      "title": "Beyond Conformal Predictors: Adaptive Conformal Inference with Confidence Predictors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.15548",
        "HTML": "https://arxiv.org/html/2409.15548v4",
        "PDF": "https://arxiv.org/pdf/2409.15548"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The study is about adaptive conformal inference and confidence predictors, emphasizing uncertainty quantification rather than any aspect of LLM training data processing or data engineering."
      },
      "tasks": [
        "Computational Efficiency",
        "Conformal Prediction",
        "Prediction",
        "Uncertainty Quantification",
        "valid"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.17966",
      "abstract": "In recent years, diffusion models have emerged as a superior alternative to generative adversarial networks (GANs) for high-fidelity image generation, with wide applications in text-to-image generation, image-to-image translation, and super-resolution. However, their real-time feasibility is hindered by slow training and inference speeds. This study addresses this challenge by proposing a wavelet-based conditional Diffusion GAN scheme for Single-Image Super-Resolution (SISR). Our approach utilizes the diffusion GAN paradigm to reduce the timesteps required by the reverse diffusion process and the Discrete Wavelet Transform (DWT) to achieve dimensionality reduction, decreasing training and inference times significantly. The results of an experimental validation on the CelebA-HQ dataset confirm the effectiveness of our proposed scheme. Our approach outperforms other state-of-the-art methodologies successfully ensuring high-fidelity output while overcoming inherent drawbacks associated with diffusion models in time-sensitive applications.",
      "authors": [
        "Lorenzo Aloisi and Luigi Sigillo and Aurelio Uncini and Danilo Comminiello"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-23T15:34:06+00:00",
          "link": "https://arxiv.org/abs/2410.17966v1",
          "size": "2015kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T05:13:25+00:00",
          "link": "https://arxiv.org/abs/2410.17966v2",
          "size": "8254kb",
          "version": "v2"
        }
      ],
      "title": "A Wavelet Diffusion GAN for Image Super-Resolution",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.17966",
        "HTML": "https://arxiv.org/html/2410.17966v2",
        "PDF": "https://arxiv.org/pdf/2410.17966"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on image super-resolution using a wavelet-based conditional Diffusion GAN, which is unrelated to the processing or engineering of training data for large language models."
      },
      "tasks": [
        "Dimensionality Reduction",
        "Image Generation",
        "Image Super-Resolution",
        "Image-to-Image Translation",
        "Super-Resolution",
        "Text to Image Generation",
        "Text-to-Image Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.13868",
      "abstract": "Watermarking has offered an effective approach to distinguishing text generated by large language models (LLMs) from human-written text. However, the pervasive presence of human edits on LLM-generated text dilutes watermark signals, thereby significantly degrading detection performance of existing methods. In this paper, by modeling human edits through mixture model detection, we introduce a new method in the form of a truncated goodness-of-fit test for detecting watermarked text under human edits, which we refer to as Tr-GoF. We prove that the Tr-GoF test achieves optimality in robust detection of the Gumbel-max watermark in a certain asymptotic regime of substantial text modifications and vanishing watermark signals. Importantly, Tr-GoF achieves this optimality \\textit{adaptively} as it does not require precise knowledge of human edit levels or probabilistic specifications of the LLMs, in contrast to the optimal but impractical (Neyman--Pearson) likelihood ratio test. Moreover, we establish that the Tr-GoF test attains the highest detection efficiency rate in a certain regime of moderate text modifications. In stark contrast, we show that sum-based detection rules, as employed by existing methods, fail to achieve optimal robustness in both regimes because the additive nature of their statistics is less resilient to edit-induced noise. Finally, we demonstrate the competitive and sometimes superior empirical performance of the Tr-GoF test on both synthetic data and open-source LLMs in the OPT and LLaMA families.",
      "authors": [
        "Xiang Li",
        "Feng Ruan",
        "Huiyuan Wang",
        "Qi Long",
        "Weijie J. Su"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Methodology (stat.ME)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)",
        "Statistics Theory (math.ST)",
        "Machine Learning (stat.ML)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-21T06:06:04+00:00",
          "link": "https://arxiv.org/abs/2411.13868v1",
          "size": "3808kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T16:34:08+00:00",
          "link": "https://arxiv.org/abs/2411.13868v2",
          "size": "3314kb",
          "version": "v2"
        }
      ],
      "title": "Robust Detection of Watermarks for Large Language Models Under Human Edits",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.13868",
        "HTML": "https://arxiv.org/html/2411.13868v2",
        "PDF": "https://arxiv.org/pdf/2411.13868"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on watermark detection in LLM-generated text, specifically addressing the robustness against human edits, rather than on training data processing or engineering."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/lx10077/TrGoF"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.18290",
      "abstract": "In the radiation therapy of nasopharyngeal carcinoma (NPC), clinicians typically delineate the gross tumor volume (GTV) using non-contrast planning computed tomography to ensure accurate radiation dose delivery. However, the low contrast between tumors and adjacent normal tissues necessitates that radiation oncologists manually delineate the tumors, often relying on diagnostic MRI for guidance. % In this study, we propose a novel approach to directly segment NPC gross tumors on non-contrast planning CT images, circumventing potential registration errors when aligning MRI or MRI-derived tumor masks to planning CT. To address the low contrast issues between tumors and adjacent normal structures in planning CT, we introduce a 3D Semantic Asymmetry Tumor segmentation (SATs) method. Specifically, we posit that a healthy nasopharyngeal region is characteristically bilaterally symmetric, whereas the emergence of nasopharyngeal carcinoma disrupts this symmetry. Then, we propose a Siamese contrastive learning segmentation framework that minimizes the voxel-wise distance between original and flipped areas without tumor and encourages a larger distance between original and flipped areas with tumor. Thus, our approach enhances the sensitivity of features to semantic asymmetries. % Extensive experiments demonstrate that the proposed SATs achieves the leading NPC GTV segmentation performance in both internal and external testing, \\emph{e.g.}, with at least 2\\% absolute Dice score improvement and 12\\% average distance error reduction when compared to other state-of-the-art methods in the external testing.",
      "authors": [
        "Zi Li and Ying Chen and Zeli Chen and Yanzhou Su and Tai Ma and Tony C. W. Mok and Yan-Jie Zhou and Yunhai Bai and Zhinlin Zheng and Le Lu and Yirui Wang and Jia Ge and Xianghua Ye and Senxiang Yan and Dakai Jin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-27T12:28:46+00:00",
          "link": "https://arxiv.org/abs/2411.18290v1",
          "size": "3665kb",
          "version": "v1"
        },
        {
          "date": "2024-12-18T07:40:45+00:00",
          "link": "https://arxiv.org/abs/2411.18290v2",
          "size": "2583kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T03:50:03+00:00",
          "link": "https://arxiv.org/abs/2411.18290v3",
          "size": "1626kb",
          "version": "v3"
        }
      ],
      "title": "Leveraging Semantic Asymmetry for Precise Gross Tumor Volume Segmentation of Nasopharyngeal Carcinoma in Planning CT",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.18290",
        "HTML": "https://arxiv.org/html/2411.18290v3",
        "PDF": "https://arxiv.org/pdf/2411.18290"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on methods for segmenting gross tumor volumes in medical images, specifically nasopharyngeal carcinoma from CT images. It does not address any aspect of LLM training data processing or related tasks."
      },
      "tasks": [
        "Contrastive Learning",
        "Diagnostic",
        "Segmentation",
        "Tumor Segmentation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.03768",
      "abstract": "Complex networked systems driven by latent inputs are common in fields like neuroscience, finance, and engineering. A key inference problem here is to learn edge connectivity from node outputs (potentials). We focus on systems governed by steady-state linear conservation laws: $X_t = {L^{\\ast}}Y_{t}$, where $X_t, Y_t \\in \\mathbb{R}^p$ denote inputs and potentials, respectively, and the sparsity pattern of the $p \\times p$ Laplacian $L^{\\ast}$ encodes the edge structure. Assuming $X_t$ to be a wide-sense stationary stochastic process with a known spectral density matrix, we learn the support of $L^{\\ast}$ from temporally correlated samples of $Y_t$ via an $\\ell_1$-regularized Whittle's maximum likelihood estimator (MLE). The regularization is particularly useful for learning large-scale networks in the high-dimensional setting where the network size $p$ significantly exceeds the number of samples $n$.\n  We show that the MLE problem is strictly convex, admitting a unique solution. Under a novel mutual incoherence condition and certain sufficient conditions on $(n, p, d)$, we show that the ML estimate recovers the sparsity pattern of $L^\\ast$ with high probability, where $d$ is the maximum degree of the graph underlying $L^{\\ast}$. We provide recovery guarantees for $L^\\ast$ in element-wise maximum, Frobenius, and operator norms. Finally, we complement our theoretical results with several simulation studies on synthetic and benchmark datasets, including engineered systems (power and water networks), and real-world datasets from neural systems (such as the human brain).",
      "authors": [
        "Anirudh Rayas",
        "Jiajun Cheng",
        "Rajasekhar Anguluri",
        "Deepjyoti Deka",
        "Gautam Dasarathy"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-04T23:14:00+00:00",
          "link": "https://arxiv.org/abs/2412.03768v1",
          "size": "2305kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T16:01:18+00:00",
          "link": "https://arxiv.org/abs/2412.03768v2",
          "size": "2480kb",
          "version": "v2"
        }
      ],
      "title": "Learning Networks from Wide-Sense Stationary Stochastic Processes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.03768",
        "HTML": "https://arxiv.org/html/2412.03768v2",
        "PDF": "https://arxiv.org/pdf/2412.03768"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper investigates learning network structures from stochastic processes, which is unrelated to the processing or engineering of training data for LLMs."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2501.10814",
      "abstract": "3D models surpass 2D models in CT/MRI segmentation by effectively capturing inter-slice relationships. However, the added depth dimension substantially increases memory consumption. While patch-based training alleviates memory constraints, it significantly slows down the inference speed due to the sliding window (SW) approach. We propose No-More-Sliding-Window (NMSW), a novel end-to-end trainable framework that enhances the efficiency of generic 3D segmentation backbone during an inference step by eliminating the need for SW. NMSW employs a differentiable Top-k module to selectively sample only the most relevant patches, thereby minimizing redundant computations. When patch-level predictions are insufficient, the framework intelligently leverages coarse global predictions to refine results. Evaluated across 3 tasks using 3 segmentation backbones, NMSW achieves competitive accuracy compared to SW inference while significantly reducing computational complexity by 91% (88.0 to 8.00 TMACs). Moreover, it delivers a 9.1x faster inference on the H100 GPU (99.0 to 8.3 sec) and a 11.1x faster inference on the Xeon Gold CPU (2110 to 189 sec). NMSW is model-agnostic, further boosting efficiency when integrated with any existing efficient segmentation backbones. The code is avaialble: https://github.com/Youngseok0001/open_nmsw.",
      "authors": [
        "Young Seok Jeon",
        "Hongfei Yang",
        "Huazhu Fu and Mengling Feng"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-18T16:23:09+00:00",
          "link": "https://arxiv.org/abs/2501.10814v1",
          "size": "3630kb",
          "version": "v1"
        },
        {
          "date": "2025-03-06T11:05:23+00:00",
          "link": "https://arxiv.org/abs/2501.10814v2",
          "size": "4187kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T13:58:15+00:00",
          "link": "https://arxiv.org/abs/2501.10814v3",
          "size": "4188kb",
          "version": "v3"
        }
      ],
      "title": "No More Sliding Window: Efficient 3D Medical Image Segmentation with Differentiable Top-k Patch Sampling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.10814",
        "HTML": "https://arxiv.org/html/2501.10814v3",
        "PDF": "https://arxiv.org/pdf/2501.10814"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The focus is on improving 3D medical image segmentation using a novel framework that enhances efficiency in inference, which is unrelated to the processing of training data for LLMs."
      },
      "tasks": [
        "Image Segmentation",
        "Medical Image Segmentation",
        "MRI segmentation",
        "Segmentation",
        "Semantic Segmentation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.19179",
      "abstract": "Graph Neural Network (GNN) potentials relying on chemical locality offer near-quantum mechanical accuracy at significantly reduced computational costs. Message-passing GNNs model interactions beyond their immediate neighborhood by propagating local information between neighboring particles while remaining effectively local. However, locality precludes modeling long-range effects critical to many real-world systems, such as charge transfer, electrostatic interactions, and dispersion effects. In this work, we propose the Charge Equilibration Layer for Long-range Interactions (CELLI) to address the challenge of efficiently modeling non-local interactions. This novel architecture generalizes the classical charge equilibration (Qeq) method to a model-agnostic building block for modern equivariant GNN potentials. Therefore, CELLI extends the capability of GNNs to model long-range interactions while providing high interpretability through explicitly modeled charges. On benchmark systems, CELLI achieves state-of-the-art results for strictly local models. CELLI generalizes to diverse datasets and large structures while providing high computational efficiency and robust predictions.",
      "authors": [
        "Paul Fuchs",
        "Micha{\\l} Sanocki",
        "Julija Zavadlav"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Chemical Physics (physics.chem-ph)",
        "Machine Learning (cs.LG)",
        "Computational Physics (physics.comp-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-31T14:43:22+00:00",
          "link": "https://arxiv.org/abs/2501.19179v1",
          "size": "2942kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T16:03:53+00:00",
          "link": "https://arxiv.org/abs/2501.19179v2",
          "size": "1165kb",
          "version": "v2"
        }
      ],
      "title": "Learning Non-Local Molecular Interactions via Equivariant Local Representations and Charge Equilibration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.19179",
        "HTML": "https://arxiv.org/html/2501.19179v2",
        "PDF": "https://arxiv.org/pdf/2501.19179"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper presents a novel method to improve GNNs for modeling non-local molecular interactions but does not relate to LLM training data processing."
      },
      "tasks": [
        "Computational Efficiency",
        "Graph Neural Network"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.07528",
      "abstract": "Transfers in professional football (soccer) are risky investments because of the large transfer fees and high risks involved. Although data-driven models can be used to improve transfer decisions, existing models focus on describing players' historical progress, leaving their future performance unknown. Moreover, recent developments have called for the use of explainable models combined with uncertainty quantification of predictions. This paper assesses explainable machine learning models based on predictive accuracy and uncertainty quantification methods for the prediction of the future development in quality and transfer value of professional football players. The predictive accuracy is studied by training the models to predict the quality and value of players one year ahead. This is carried out by training them on two data sets containing data-driven indicators describing the player quality and player value in historical settings. In general, the random forest model is found to be the most suitable model because it provides accurate predictions as well as an uncertainty quantification method that naturally arises from the bagging procedure of the random forest model. Additionally, this research shows that the development of player performance contains nonlinear patterns and interactions between variables, and that time series information can provide useful information for the modeling of player performance metrics. The resulting models can help football clubs make more informed, data-driven transfer decisions by forecasting player quality and transfer value.",
      "authors": [
        "Koen W. van Arem and Floris Goes-Smit and Jakob S\\\"ohl"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Applications (stat.AP)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-11T13:09:09+00:00",
          "link": "https://arxiv.org/abs/2502.07528v1",
          "size": "742kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T09:47:13+00:00",
          "link": "https://arxiv.org/abs/2502.07528v2",
          "size": "1032kb",
          "version": "v2"
        }
      ],
      "title": "Forecasting the future development in quality and value of professional football players",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.07528",
        "HTML": "https://arxiv.org/html/2502.07528v2",
        "PDF": "https://arxiv.org/pdf/2502.07528"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on predicting the future quality and value of professional football players using machine learning models, which is unrelated to the processing of training data for LLMs."
      },
      "tasks": [
        "Explainable Models",
        "Management",
        "Uncertainty Quantification"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.12753",
      "abstract": "In artificial intelligence (AI), the complexity of many models and processes surpasses human understanding, making it challenging to determine why a specific prediction is made. This lack of transparency is particularly problematic in critical fields like healthcare, where trust in a model's predictions is paramount. As a result, the explainability of machine learning (ML) and other complex models has become a key area of focus. Efforts to improve model explainability often involve experimenting with AI systems and approximating their behavior through interpretable surrogate mechanisms. However, these procedures can be resource-intensive. Optimal design of experiments, which seeks to maximize the information obtained from a limited number of observations, offers promising methods for improving the efficiency of these explainability techniques. To demonstrate this potential, we explore Local Interpretable Model-agnostic Explanations (LIME), a widely used method introduced by Ribeiro et al. (2016). LIME provides explanations by generating new data points near the instance of interest and passing them through the model. While effective, this process can be computationally expensive, especially when predictions are costly or require many samples. LIME is highly versatile and can be applied to a wide range of models and datasets. In this work, we focus on models involving tabular data, regression tasks, and linear models as interpretable local approximations. By utilizing optimal design of experiments' techniques, we reduce the number of function evaluations of the complex model, thereby reducing the computational effort of LIME by a significant amount. We consider this modified version of LIME to be energy-efficient or \"green\".",
      "authors": [
        "Alexandra Stadler and Werner G. M\\\"uller and Radoslav Harman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Methodology (stat.ME)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-18T11:15:04+00:00",
          "link": "https://arxiv.org/abs/2502.12753v1",
          "size": "1014kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T07:44:25+00:00",
          "link": "https://arxiv.org/abs/2502.12753v2",
          "size": "927kb",
          "version": "v2"
        }
      ],
      "title": "Green LIME: Improving AI Explainability through Design of Experiments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.12753",
        "HTML": "https://arxiv.org/html/2502.12753v2",
        "PDF": "https://arxiv.org/pdf/2502.12753"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper is centered on improving AI explainability through design of experiments, specifically focusing on the computational efficiency of the LIME method, with no relation to LLM training data."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2502.20244",
      "abstract": "We propose a new approach to simulate neutrino scattering events as an alternative to the standard Monte Carlo generator approach. Generative adversarial neural network (GAN) models are developed to simulate charged current neutrino-carbon collisions in the few-GeV energy range. We consider a simplified framework to generate muon kinematic variables, specifically its energy and scattering angle. GAN models are trained on simulation data from \\nuwro{} Monte Carlo event generator. Two GAN models have been obtained: one simulating quasielastic neutrino-nucleus scatterings and another simulating all interactions at given neutrino energy. The models work for neutrino energy ranging from 300 MeV to 10 GeV. The performance of both models has been assessed using two statistical metrics. It is shown that both GAN models successfully reproduce the distribution of muon kinematics.",
      "authors": [
        "Jose L. Bonilla",
        "Krzysztof M. Graczyk",
        "Artur M. Ankowski",
        "Rwik Dharmapal Banerjee",
        "Beata E. Kowal",
        "Hemant Prasad",
        "Jan T. Sobczyk"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "High Energy Physics - Phenomenology (hep-ph)",
        "Machine Learning (cs.LG)",
        "High Energy Physics - Experiment (hep-ex)",
        "Nuclear Experiment (nucl-ex)",
        "Nuclear Theory (nucl-th)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-27T16:28:39+00:00",
          "link": "https://arxiv.org/abs/2502.20244v1",
          "size": "5332kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T08:14:44+00:00",
          "link": "https://arxiv.org/abs/2502.20244v2",
          "size": "6374kb",
          "version": "v2"
        }
      ],
      "title": "Generative adversarial neural networks for simulating neutrino interactions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.20244",
        "HTML": "https://arxiv.org/html/2502.20244v2",
        "PDF": "https://arxiv.org/pdf/2502.20244"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The research presents the use of GANs for simulating neutrino interactions, which is not related to the processing or engineering of LLM training data."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2502.20758",
      "abstract": "We introduce a new approach in which several advanced large language models-specifically GPT-4-0125-preview, Meta-LLAMA-3-70B-Instruct, Claude-3-Opus, and Gemini-1.5-Flash-collaborate to both produce and answer intricate, doctoral-level probability problems without relying on any single \"correct\" reference. Rather than depending on an established ground truth, our investigation focuses on how agreement among diverse models can signal the reliability of their outputs and, by extension, reflect the overall quality of the generated questions. To measure this inter-model alignment, we apply a suite of statistical evaluations, including chi-square tests, Fleiss' Kappa coefficients, and confidence interval calculations, thereby capturing both precision in answers and clarity in question phrasing. Our analysis reveals that Claude and Gemini tend to frame questions more coherently and unambiguously, which is evidenced by their tighter confidence intervals and greater concordance with responding agents. In contrast, LLAMA exhibits wider confidence bands and a lower level of agreement, indicating more variability and reduced consistency in its question formulations. These observations support the notion that a multi-model collaborative strategy not only improves answer dependability but also offers an effective, data-driven mechanism for evaluating and refining question quality when no definitive solution exists. Ultimately, this work delivers actionable insights into enhancing AI-guided reasoning processes through coordinated interactions among heterogeneous language models.",
      "authors": [
        "Seyed Pouyan Mousavi Davoudi",
        "Amin Gholami Davodi",
        "Alireza Amiri-Margavi",
        "Mahdi Jafari"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Applications (stat.AP)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-28T06:20:52+00:00",
          "link": "https://arxiv.org/abs/2502.20758v1",
          "size": "371kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T03:53:26+00:00",
          "link": "https://arxiv.org/abs/2502.20758v2",
          "size": "95kb",
          "version": "v2"
        }
      ],
      "title": "Collective Reasoning Among LLMs: A Framework for Answer Validation Without Ground Truth",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.20758",
        "HTML": "https://arxiv.org/html/2502.20758v2",
        "PDF": "https://arxiv.org/pdf/2502.20758"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper discusses using multiple LLMs for answer validation through inter-model agreement, not addressing the processing or engineering of training data for LLMs."
      },
      "tasks": [
        "Large Language Model"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.03786",
      "abstract": "Organ segmentation in Positron Emission Tomography (PET) plays a vital role in cancer quantification. Low-dose PET (LDPET) provides a safer alternative by reducing radiation exposure. However, the inherent noise and blurred boundaries make organ segmentation more challenging. Additionally, existing PET organ segmentation methods rely on coregistered Computed Tomography (CT) annotations, overlooking the problem of modality mismatch. In this study, we propose LDOS, a novel CT-free ultra-LDPET organ segmentation pipeline. Inspired by Masked Autoencoders (MAE), we reinterpret LDPET as a naturally masked version of Full-Dose PET (FDPET). LDOS adopts a simple yet effective architecture: a shared encoder extracts generalized features, while task-specific decoders independently refine outputs for denoising and segmentation. By integrating CT-derived organ annotations into the denoising process, LDOS improves anatomical boundary recognition and alleviates the PET/CT misalignments. Experiments demonstrate that LDOS achieves state-of-the-art performance with mean Dice scores of 73.11% (18F-FDG) and 73.97% (68Ga-FAPI) across 18 organs in 5% dose PET. Our code will be available at https://github.com/yezanting/LDOS.",
      "authors": [
        "Zanting Ye",
        "Xiaolong Niu",
        "Xu Han",
        "Xuanbin Wu",
        "Wantong Lu",
        "Yijun Lu",
        "Hao Sun",
        "Yanchao Huang",
        "Hubing Wu and Lijun Lu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Tissues and Organs (q-bio.TO)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-05T02:36:56+00:00",
          "link": "https://arxiv.org/abs/2503.03786v1",
          "size": "6106kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T02:47:23+00:00",
          "link": "https://arxiv.org/abs/2503.03786v2",
          "size": "6796kb",
          "version": "v2"
        }
      ],
      "title": "Self is the Best Learner: CT-free Ultra-Low-Dose PET Organ Segmentation via Collaborating Denoising and Segmentation Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.03786",
        "HTML": "https://arxiv.org/html/2503.03786v2",
        "PDF": "https://arxiv.org/pdf/2503.03786"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The study proposes a method for organ segmentation in PET scans and does not involve LLM training data processing."
      },
      "tasks": [
        "Computed Tomography (CT)",
        "Denoising",
        "Organ Segmentation",
        "Segmentation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.20410",
      "abstract": "Short-term forecasting models typically assume the availability of input data (features) when they are deployed and in use. However, equipment failures, disruptions, cyberattacks, may lead to missing features when such models are used operationally, which could negatively affect forecast accuracy, and result in suboptimal operational decisions. In this paper, we use adaptive robust optimization and adversarial machine learning to develop forecasting models that seamlessly handle missing data operationally. We propose linear- and neural network-based forecasting models with parameters that adapt to available features, combining linear adaptation with a novel algorithm for learning data-driven uncertainty set partitions. The proposed adaptive models do not rely on identifying historical missing data patterns and are suitable for real-time operations under stringent time constraints. Extensive numerical experiments on short-term wind power forecasting considering horizons from 15 minutes to 4 hours ahead illustrate that our proposed adaptive models are on par with imputation when data are missing for very short periods (e.g., when only the latest measurement is missing) whereas they significantly outperform imputation when data are missing for longer periods. We further provide insights by showcasing how linear adaptation and data-driven partitions (even with a few subsets) approach the performance of the optimal, yet impractical, method of retraining for every possible realization of missing data.",
      "authors": [
        "Akylas Stratigakos and Panagiotis Andrianesis"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-26T10:38:56+00:00",
          "link": "https://arxiv.org/abs/2503.20410v1",
          "size": "172kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T09:15:39+00:00",
          "link": "https://arxiv.org/abs/2503.20410v2",
          "size": "155kb",
          "version": "v2"
        }
      ],
      "title": "Learning Data-Driven Uncertainty Set Partitions for Robust and Adaptive Energy Forecasting with Missing Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.20410",
        "HTML": "https://arxiv.org/html/2503.20410v2",
        "PDF": "https://arxiv.org/pdf/2503.20410"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper addresses forecasting models for energy data with a focus on handling missing data using adaptive robust optimization, which is unrelated to training data processing for LLMs."
      },
      "tasks": [
        "Imputation"
      ],
      "repo_urls": [
        "https://github.com/akylasstrat/wind-forecast-missing-data"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.22923",
      "abstract": "Distributionally robust optimization (DRO) is a powerful technique to train robust models against data distribution shift. This paper aims to solve regularized nonconvex DRO problems, where the uncertainty set is modeled by a so-called generalized Sinkhorn distance and the loss function is nonconvex and possibly unbounded. Such a distance allows to model uncertainty of distributions with different probability supports and divergence functions. For this class of regularized DRO problems, we derive a novel dual formulation taking the form of nested stochastic optimization, where the dual variable depends on the data sample. To solve the dual problem, we provide theoretical evidence to design a nested stochastic gradient descent (SGD) algorithm, which leverages stochastic approximation to estimate the nested stochastic gradients. We study the convergence rate of nested SGD and establish polynomial iteration and sample complexities that are independent of the data size and parameter dimension, indicating its potential for solving large-scale DRO problems. We conduct numerical experiments to demonstrate the efficiency and robustness of the proposed algorithm.",
      "authors": [
        "Yufeng Yang and Yi Zhou and Zhaosong Lu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-29T01:01:02+00:00",
          "link": "https://arxiv.org/abs/2503.22923v1",
          "size": "849kb",
          "version": "v1"
        },
        {
          "date": "2025-06-26T20:48:14+00:00",
          "link": "https://arxiv.org/abs/2503.22923v2",
          "size": "973kb",
          "version": "v2"
        }
      ],
      "title": "Nested Stochastic Algorithm for Generalized Sinkhorn distance-Regularized Distributionally Robust Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.22923",
        "HTML": "https://arxiv.org/html/2503.22923v2",
        "PDF": "https://arxiv.org/pdf/2503.22923"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on distributionally robust optimization using generalized Sinkhorn distance and nested stochastic algorithms, without addressing any aspect of LLM training data processing or data engineering."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2504.00599",
      "abstract": "The increasing demands for high-throughput and energy-efficient wireless communications are driving the adoption of extremely large antennas operating at high-frequency bands. In these regimes, multiple users will reside in the radiative near-field, and accurate localization becomes essential. Unlike conventional far-field systems that rely solely on DOA estimation, near-field localization exploits spherical wavefront propagation to recover both DOA and range information. While subspace-based methods, such as MUSIC and its extensions, offer high resolution and interpretability for near-field localization, their performance is significantly impacted by model assumptions, including non-coherent sources, well-calibrated arrays, and a sufficient number of snapshots. To address these limitations, this work proposes AI-aided subspace methods for near-field localization that enhance robustness to real-world challenges. Specifically, we introduce NF-SubspaceNet, a deep learning-augmented 2D MUSIC algorithm that learns a surrogate covariance matrix to improve localization under challenging conditions, and DCD-MUSIC, a cascaded AI-aided approach that decouples angle and range estimation to reduce computational complexity. We further develop a novel model-order-aware training method to accurately estimate the number of sources, that is combined with casting of near field subspace methods as AI models for learning. Extensive simulations demonstrate that the proposed methods outperform classical and existing deep-learning-based localization techniques, providing robust near-field localization even under coherent sources, miscalibrations, and few snapshots.",
      "authors": [
        "Arad Gast",
        "Luc Le Magoarou",
        "and Nir Shlezinger"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-01T09:57:01+00:00",
          "link": "https://arxiv.org/abs/2504.00599v1",
          "size": "5066kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T11:37:04+00:00",
          "link": "https://arxiv.org/abs/2504.00599v2",
          "size": "3813kb",
          "version": "v2"
        }
      ],
      "title": "Near Field Localization via AI-Aided Subspace Methods",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.00599",
        "HTML": "https://arxiv.org/html/2504.00599v2",
        "PDF": "https://arxiv.org/pdf/2504.00599"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on AI-aided subspace methods for near-field localization and does not address any aspect of training data processing for large language models, neither data engineering nor training-stage data processing."
      },
      "tasks": [
        "subspace methods"
      ],
      "repo_urls": [
        "https://github.com/ShlezingerLab/AI-Subspace-Methods"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.04016",
      "abstract": "While the matrix completion problem has attracted considerable attention over the decades, few works address the nonignorable missing issue and all have their limitations. In this article, we propose a nuclear norm regularized row- and column-wise matrix U-statistic loss function for the generalized nonignorable missing mechanism, a flexible and generally applicable missing mechanism which contains both ignorable and nonignorable missing mechanism assumptions. The proposed method achieves computational efficiency comparable to the existing missing-at-random approaches, while providing the near minimax optimal statistical convergence rate guarantees for the more general nonignorable missing case. We propose an accelerated proximal gradient algorithm to solve the associated optimization problem, and characterize the interaction between algorithmic and statistical convergence. Simulations and real data analyzes further support the practical utility of the proposed method.",
      "authors": [
        "Yuanhong A",
        "Guoyu Zhang",
        "Yongcheng Zeng",
        "Bo Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-05T01:41:53+00:00",
          "link": "https://arxiv.org/abs/2504.04016v1",
          "size": "187kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T00:17:58+00:00",
          "link": "https://arxiv.org/abs/2504.04016v2",
          "size": "94kb",
          "version": "v2"
        }
      ],
      "title": "Computational Efficient and Minimax Optimal Nonignorable Matrix Completion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.04016",
        "HTML": "https://arxiv.org/html/2504.04016v2",
        "PDF": "https://arxiv.org/pdf/2504.04016"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This research is concerned with matrix completion under nonignorable missing mechanisms and utilizes statistical methods. It does not relate to the processing or preparation of LLM training data."
      },
      "tasks": [
        "Matrix Completion"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.07818",
      "abstract": "We are interested in the estimation of a rank-one tensor signal when only a portion $\\varepsilon$ of its noisy observation is available. We show that the study of this problem can be reduced to that of a random matrix model whose spectral analysis gives access to the reconstruction performance. These results shed light on and specify the loss of performance induced by an artificial reduction of the memory cost of a tensor via the deletion of a random part of its entries.",
      "authors": [
        "Hugo Lebeau"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Probability (math.PR)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-10T14:57:09+00:00",
          "link": "https://arxiv.org/abs/2504.07818v1",
          "size": "143kb",
          "version": "v1"
        },
        {
          "date": "2025-06-19T09:34:53+00:00",
          "link": "https://arxiv.org/abs/2504.07818v2",
          "size": "143kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T14:10:54+00:00",
          "link": "https://arxiv.org/abs/2504.07818v3",
          "size": "143kb",
          "version": "v3"
        }
      ],
      "title": "Performance of Rank-One Tensor Approximation on Incomplete Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.07818",
        "PDF": "https://arxiv.org/pdf/2504.07818"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This work investigates rank-one tensor approximation in the context of incomplete data, focusing on signal estimation and not addressing LLM training data processing or data engineering."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2504.08524",
      "abstract": "Voice conversion (VC) transforms source speech into a target voice by preserving the content. However, timbre information from the source speaker is inherently embedded in the content representations, causing significant timbre leakage and reducing similarity to the target speaker. To address this, we introduce a Universal Semantic Matching (USM) residual block to a content extractor. The residual block consists of two weighted branches: 1) universal semantic dictionary based Content Feature Re-expression (CFR) module, supplying timbre-free content representation. 2) skip connection to the original content layer, providing complementary fine-grained information. In the CFR module, each dictionary entry in the universal semantic dictionary represents a phoneme class, computed statistically using speech from multiple speakers, creating a stable, speaker-independent semantic set. We introduce a CFR method to obtain timbre-free content representations by expressing each content frame as a weighted linear combination of dictionary entries using corresponding phoneme posteriors as weights. Extensive experiments across various VC frameworks demonstrate that our approach effectively mitigates timbre leakage and significantly improves similarity to the target speaker.",
      "authors": [
        "Na Li",
        "Chuke Wang",
        "Yu Gu",
        "Zhifeng Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Artificial Intelligence (cs.AI)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-11T13:36:59+00:00",
          "link": "https://arxiv.org/abs/2504.08524v1",
          "size": "339kb",
          "version": "v1"
        },
        {
          "date": "2025-04-29T15:49:13+00:00",
          "link": "https://arxiv.org/abs/2504.08524v2",
          "size": "339kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T14:01:55+00:00",
          "link": "https://arxiv.org/abs/2504.08524v3",
          "size": "330kb",
          "version": "v3"
        }
      ],
      "title": "USM-VC: Mitigating Timbre Leakage with Universal Semantic Mapping Residual Block for Voice Conversion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.08524",
        "HTML": "https://arxiv.org/html/2504.08524v3",
        "PDF": "https://arxiv.org/pdf/2504.08524"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper addresses voice conversion by introducing a Universal Semantic Matching residual block for timbre leakage mitigation, with no relation to LLM training data processing or engineering."
      },
      "tasks": [
        "Voice Conversion"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.14275",
      "abstract": "Discrete exterior calculus offers a coordinate--free discretization of exterior calculus especially suited for computations on curved spaces. In this work, we present a wedge product on 2--dimensional pseudomanifolds, whose faces are any polygons. We prove that this polygonal wedge product is compatible with the discrete exterior derivative in the sense that it satisfies the Leibniz product rule. We thus extend previously studied discretizations of wedge products from simplicial or quadrilateral meshes to surface meshes whose faces are arbitrary simple polygons. We also prove that our discrete wedge product corresponds to a cup product of cochains on 2--pseudomanifolds. By rigorously justifying our construction we add another piece to ever evolving discrete versions of exterior calculus.",
      "authors": [
        "Lenka Ptackova"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Algebraic Topology (math.AT)",
        "Computational Geometry (cs.CG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-19T12:00:05+00:00",
          "link": "https://arxiv.org/abs/2504.14275v1",
          "size": "280kb",
          "version": "v1"
        },
        {
          "date": "2025-06-18T06:25:03+00:00",
          "link": "https://arxiv.org/abs/2504.14275v2",
          "size": "280kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T08:12:27+00:00",
          "link": "https://arxiv.org/abs/2504.14275v3",
          "size": "246kb",
          "version": "v3"
        }
      ],
      "title": "Leibniz rule for wedge product in discrete exterior calculus on general polygonal meshes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.14275",
        "HTML": "https://arxiv.org/html/2504.14275v3",
        "PDF": "https://arxiv.org/pdf/2504.14275"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper discusses discrete exterior calculus and wedge product for computational geometry on polygons, with no connection to LLM training data processing or preparation."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.16941",
      "abstract": "This study presents a novel mathematical model derived from cohomology, leveraging the KEEL-proven theorem that establishes cohomology as tautological, generated by boundary classes of curves with fixed dual graphs. Simplicial complexes are constructed using skew-commutative graded algebra, and the structure theorem is applied to connect distinct homologies, enabling precise interpretations of the resulting geometric forms. The proposed model is utilized for protein structure analysis and prediction, with a specific application to the Flagellar Motor structure. This approach offers new insights into the geometric and algebraic foundations of biological macromolecular modeling, highlighting its potential for advancement in structural biology.",
      "authors": [
        "Zakaria Lamine",
        "Abdelatif Hafid",
        "Mohamed Rahouti"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Biomolecules (q-bio.BM)",
        "Machine Learning (cs.LG)",
        "Algebraic Topology (math.AT)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-08T19:21:44+00:00",
          "link": "https://arxiv.org/abs/2504.16941v1",
          "size": "999kb",
          "version": "v1"
        },
        {
          "date": "2025-06-26T23:25:39+00:00",
          "link": "https://arxiv.org/abs/2504.16941v2",
          "size": "174kb",
          "version": "v2"
        }
      ],
      "title": "Mathematical Modeling of Protein Structures: A Cohomology-Based Approach to the Flagellar Motor",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.16941",
        "HTML": "https://arxiv.org/html/2504.16941v2",
        "PDF": "https://arxiv.org/pdf/2504.16941"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The study presents a cohomology-based mathematical model for protein structures, which is unrelated to LLM training data processing or engineering."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2506.08423",
      "abstract": "Microscopy is a primary source of information on materials structure and functionality at nanometer and atomic scales. The data generated is often well-structured, enriched with metadata and sample histories, though not always consistent in detail or format. The adoption of Data Management Plans (DMPs) by major funding agencies promotes preservation and access. However, deriving insights remains difficult due to the lack of standardized code ecosystems, benchmarks, and integration strategies. As a result, data usage is inefficient and analysis time is extensive. In addition to post-acquisition analysis, new APIs from major microscope manufacturers enable real-time, ML-based analytics for automated decision-making and ML-agent-controlled microscope operation. Yet, a gap remains between the ML and microscopy communities, limiting the impact of these methods on physics, materials discovery, and optimization. Hackathons help bridge this divide by fostering collaboration between ML researchers and microscopy experts. They encourage the development of novel solutions that apply ML to microscopy, while preparing a future workforce for instrumentation, materials science, and applied ML. This hackathon produced benchmark datasets and digital twins of microscopes to support community growth and standardized workflows. All related code is available at GitHub: https://github.com/KalininGroup/Mic-hackathon-2024-codes-publication/tree/1.0.0.1",
      "authors": [
        "Utkarsh Pratiush",
        "Austin Houston",
        "Kamyar Barakati",
        "Aditya Raghavan",
        "Dasol Yoon",
        "Harikrishnan KP",
        "Zhaslan Baraissov",
        "Desheng Ma",
        "Samuel S. Welborn",
        "Mikolaj Jakowski",
        "Shawn-Patrick Barhorst",
        "Alexander J. Pattison",
        "Panayotis Manganaris",
        "Sita Sirisha Madugula",
        "Sai Venkata Gayathri Ayyagari",
        "Vishal Kennedy",
        "Ralph Bulanadi",
        "Michelle Wang",
        "Kieran J. Pang",
        "Ian Addison-Smith",
        "Willy Menacho",
        "Horacio V. Guzman",
        "Alexander Kiefer",
        "Nicholas Furth",
        "Nikola L. Kolev",
        "Mikhail Petrov",
        "Viktoriia Liu",
        "Sergey Ilyev",
        "Srikar Rairao",
        "Tommaso Rodani",
        "Ivan Pinto-Huguet",
        "Xuli Chen",
        "Josep Crua\\~nes",
        "Marta Torrens",
        "Jovan Pomar",
        "Fanzhi Su",
        "Pawan Vedanti",
        "Zhiheng Lyu",
        "Xingzhi Wang",
        "Lehan Yao",
        "Amir Taqieddin",
        "Forrest Laskowski",
        "Xiangyu Yin",
        "Yu-Tsun Shao",
        "Benjamin Fein-Ashley",
        "Yi Jiang",
        "Vineet Kumar",
        "Himanshu Mishra",
        "Yogesh Paul",
        "Adib Bazgir",
        "Rama chandra Praneeth Madugula",
        "Yuwen Zhang",
        "Pravan Omprakash",
        "Jian Huang",
        "Eric Montufar-Morales",
        "Vivek Chawla",
        "Harshit Sethi",
        "Jie Huang",
        "Lauri Kurki",
        "Grace Guinan",
        "Addison Salvador",
        "Arman Ter-Petrosyan",
        "Madeline Van Winkle",
        "Steven R. Spurgeon",
        "Ganesh Narasimha",
        "Zijie Wu",
        "Richard Liu",
        "Yongtao Liu",
        "Boris Slautin",
        "Andrew R Lupini",
        "Rama Vasudevan",
        "Gerd Duscher",
        "Sergei V. Kalinin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Materials Science (cond-mat.mtrl-sci)",
        "Machine Learning (cs.LG)",
        "Instrumentation and Detectors (physics.ins-det)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-10T03:54:36+00:00",
          "link": "https://arxiv.org/abs/2506.08423v1",
          "size": "20793kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T04:56:59+00:00",
          "link": "https://arxiv.org/abs/2506.08423v2",
          "size": "19272kb",
          "version": "v2"
        }
      ],
      "title": "Mic-hackathon 2024: Hackathon on Machine Learning for Electron and Scanning Probe Microscopy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.08423",
        "PDF": "https://arxiv.org/pdf/2506.08423"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper discusses machine learning applications in microscopy data analysis and does not address any aspects of LLM training data collection or processing."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/kaliningroup/mic-hackathon-2024-codes-publication"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.11869",
      "abstract": "Graphs are a powerful data structure for representing relational data and are widely used to describe complex real-world systems. Probabilistic Graphical Models (PGMs) and Graph Neural Networks (GNNs) can both leverage graph-structured data, but their inherent functioning is different. The question is how do they compare in capturing the information contained in networked datasets? We address this objective by solving a link prediction task and we conduct three main experiments, on both synthetic and real networks: one focuses on how PGMs and GNNs handle input features, while the other two investigate their robustness to noisy features and increasing heterophily of the graph. PGMs do not necessarily require features on nodes, while GNNs cannot exploit the network edges alone, and the choice of input features matters. We find that GNNs are outperformed by PGMs when input features are low-dimensional or noisy, mimicking many real scenarios where node attributes might be scalar or noisy. Then, we find that PGMs are more robust than GNNs when the heterophily of the graph is increased. Finally, to assess performance beyond prediction tasks, we also compare the two frameworks in terms of their computational complexity and interpretability.",
      "authors": [
        "Michela Lapenna",
        "Caterina De Bacco"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Mathematical Physics (math-ph)",
        "Mathematical Physics (math.MP)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-13T15:19:28+00:00",
          "link": "https://arxiv.org/abs/2506.11869v1",
          "size": "977kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T14:37:02+00:00",
          "link": "https://arxiv.org/abs/2506.11869v2",
          "size": "977kb",
          "version": "v2"
        }
      ],
      "title": "How do Probabilistic Graphical Models and Graph Neural Networks Look at Network Data?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.11869",
        "HTML": "https://arxiv.org/html/2506.11869v2",
        "PDF": "https://arxiv.org/pdf/2506.11869"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on comparing Probabilistic Graphical Models and Graph Neural Networks in handling graph-structured data, and does not address aspects of LLM training data collection, construction, or processing."
      },
      "tasks": [
        "Link Prediction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.15049",
      "abstract": "There has been wide interest in understanding which properties of base graphs of matroids extend to base-cobase graphs of matroids. A significant result of Naddef and Pulleyblank (1984) shows that the $1$-skeleton of any $(0,1)$-polytope is either a hypercube, or Hamiltonian-connected, i.e. there is a Hamiltonian path connecting any two vertices. In particular, this is true for base graphs of matroids. A natural question raised by Farber, Richter, and Shank (1985) is whether this extends to base-cobase graphs.\n  First, we use the polytopal approach to show Hamiltonian connectivity of base-cobase graphs of series-parallel extensions of lattice path matroids. On the other hand, we show that this method extends to only very special classes related to identically self-dual matroids. Second, we show that base-cobase graphs of wheels and whirls are Hamiltonian connected. Last, we show that the regular matroid $R_{10}$ yields a negative answer to the question of Farber, Richter, and Shank.",
      "authors": [
        "Leonardo Mart\\'inez-Sandoval",
        "Kolja Knauer"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-18T01:18:01+00:00",
          "link": "https://arxiv.org/abs/2506.15049v1",
          "size": "239kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T15:15:36+00:00",
          "link": "https://arxiv.org/abs/2506.15049v2",
          "size": "239kb",
          "version": "v2"
        }
      ],
      "title": "Hamiltonian connectivity of some base-cobase graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.15049",
        "HTML": "https://arxiv.org/html/2506.15049v2",
        "PDF": "https://arxiv.org/pdf/2506.15049"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The research focuses on Hamiltonian connectivity in the context of matroid theory, which has no direct relevance to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.16969",
      "abstract": "Whispered speech recognition presents significant challenges for conventional automatic speech recognition systems, particularly when combined with dialect variation. However, utilizing an efficient method to solve this problem using a low-range dataset and processing load is beneficial. This paper proposes a solution using a Mamba-based state-space model and four fine-tuned self-supervised models consisting of Wav2Vec2, WavLM, HuBERT, and Whisper to address the dual challenges of whispered speech and dialect diversity. Based on our knowledge, this represents the best performance reported on the wTIMIT and CHAINS datasets for whispered speech recognition. We trained the models using whispered and normal speech data across Singaporean, US, and Irish dialects. The findings demonstrated that utilizing the proposed Mamba-based model could work as a highly efficient model trained with low amounts of whispered data to simultaneously work on whispered and normal speech recognition. The code for this work is freely available.",
      "authors": [
        "Aref Farhadipour",
        "Homayoon Beigi",
        "Volker Dellwo",
        "Hadi Veisi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-20T12:59:35+00:00",
          "link": "https://arxiv.org/abs/2506.16969v1",
          "size": "424kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T11:57:06+00:00",
          "link": "https://arxiv.org/abs/2506.16969v2",
          "size": "424kb",
          "version": "v2"
        }
      ],
      "title": "State-Space Models in Efficient Whispered and Multi-dialect Speech Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.16969",
        "HTML": "https://arxiv.org/html/2506.16969v2",
        "PDF": "https://arxiv.org/pdf/2506.16969"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper uses fine-tuning techniques on existing models for speech recognition tasks but does not introduce new methods specifically for processing LLM training data."
      },
      "tasks": [
        "Automatic Speech Recognition",
        "Diversity",
        "Mamba",
        "speech-recognition",
        "Speech Recognition",
        "State Space Models"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.19863",
      "abstract": "The AI for Nuclear Energy workshop at Oak Ridge National Laboratory evaluated the potential of Large Language Models (LLMs) to accelerate fusion and fission research. Fourteen interdisciplinary teams explored diverse nuclear science challenges using ChatGPT, Gemini, Claude, and other AI models over a single day. Applications ranged from developing foundation models for fusion reactor control to automating Monte Carlo simulations, predicting material degradation, and designing experimental programs for advanced reactors. Teams employed structured workflows combining prompt engineering, deep research capabilities, and iterative refinement to generate hypotheses, prototype code, and research strategies. Key findings demonstrate that LLMs excel at early-stage exploration, literature synthesis, and workflow design, successfully identifying research gaps and generating plausible experimental frameworks. However, significant limitations emerged, including difficulties with novel materials designs, advanced code generation for modeling and simulation, and domain-specific details requiring expert validation. The successful outcomes resulted from expert-driven prompt engineering and treating AI as a complementary tool rather than a replacement for physics-based methods. The workshop validated AI's potential to accelerate nuclear energy research through rapid iteration and cross-disciplinary synthesis while highlighting the need for curated nuclear-specific datasets, workflow automation, and specialized model development. These results provide a roadmap for integrating AI tools into nuclear science workflows, potentially reducing development cycles for safer, more efficient nuclear energy systems while maintaining rigorous scientific standards.",
      "authors": [
        "Ahmed Almeldein",
        "Mohammed Alnaggar",
        "Rick Archibald",
        "Tom Beck",
        "Arpan Biswas",
        "Rike Bostelmann",
        "Wes Brewer",
        "Chris Bryan",
        "Christopher Calle",
        "Cihangir Celik",
        "Rajni Chahal",
        "Jong Youl Choi",
        "Arindam Chowdhury",
        "Mark Cianciosa",
        "Franklin Curtis",
        "Gregory Davidson",
        "Sebastian De Pascuale",
        "Lisa Fassino",
        "Ana Gainaru",
        "Yashika Ghai",
        "Luke Gibson",
        "Qian Gong",
        "Christopher Greulich",
        "Scott Greenwood",
        "Cory Hauck",
        "Ehab Hassan",
        "Rinkle Juneja",
        "Soyoung Kang",
        "Scott Klasky",
        "Atul Kumar",
        "Vineet Kumar",
        "Paul Laiu",
        "Calvin Lear",
        "Yan-Ru Lin",
        "Jono McConnell",
        "Furkan Oz",
        "Rishi Pillai",
        "Anant Raj",
        "Pradeep Ramuhalli",
        "Marie Romedenne",
        "Samantha Sabatino",
        "Jos\\'e Salcedo-P\\'erez",
        "Nathan D. See",
        "Arpan Sircar",
        "Punam Thankur",
        "Tim Younkin",
        "Xiao-Ying Yu",
        "Prashant Jain",
        "Tom Evans",
        "Prasanna Balaprakash"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Physics (physics.comp-ph)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-10T09:28:18+00:00",
          "link": "https://arxiv.org/abs/2506.19863v1",
          "size": "14219kb",
          "version": "v1"
        },
        {
          "date": "2025-06-26T22:36:10+00:00",
          "link": "https://arxiv.org/abs/2506.19863v2",
          "size": "14220kb",
          "version": "v2"
        }
      ],
      "title": "Exploring the Capabilities of the Frontier Large Language Models for Nuclear Energy Research",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19863",
        "HTML": "https://arxiv.org/html/2506.19863v2",
        "PDF": "https://arxiv.org/pdf/2506.19863"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The workshop discusses the use of LLMs in nuclear energy research but focuses on application scenarios rather than contributing new methods for LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.06184",
      "abstract": "Geologic map, as a fundamental diagram in geology science, provides critical insights into the structure and composition of Earth's subsurface and surface. These maps are indispensable in various fields, including disaster detection, resource exploration, and civil engineering. Despite their significance, current Multimodal Large Language Models (MLLMs) often fall short in geologic map understanding. This gap is primarily due to the challenging nature of cartographic generalization, which involves handling high-resolution map, managing multiple associated components, and requiring domain-specific knowledge. To quantify this gap, we construct GeoMap-Bench, the first-ever benchmark for evaluating MLLMs in geologic map understanding, which assesses the full-scale abilities in extracting, referring, grounding, reasoning, and analyzing. To bridge this gap, we introduce GeoMap-Agent, the inaugural agent designed for geologic map understanding, which features three modules: Hierarchical Information Extraction (HIE), Domain Knowledge Injection (DKI), and Prompt-enhanced Question Answering (PEQA). Inspired by the interdisciplinary collaboration among human scientists, an AI expert group acts as consultants, utilizing a diverse tool pool to comprehensively analyze questions. Through comprehensive experiments, GeoMap-Agent achieves an overall score of 0.811 on GeoMap-Bench, significantly outperforming 0.369 of GPT-4o. Our work, emPowering gEologic mAp holistiC undErstanding (PEACE) with MLLMs, paves the way for advanced AI applications in geology, enhancing the efficiency and accuracy of geological investigations.",
      "authors": [
        "Yangyu Huang",
        "Tianyi Gao",
        "Haoran Xu",
        "Qihao Zhao",
        "Yang Song",
        "Zhipeng Gui",
        "Tengchao Lv",
        "Hao Chen",
        "Lei Cui",
        "Scarlett Li",
        "Furu Wei"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Human-Computer Interaction (cs.HC)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-10T18:59:42+00:00",
          "link": "https://arxiv.org/abs/2501.06184v1",
          "size": "2328kb",
          "version": "v1"
        }
      ],
      "title": "PEACE: Empowering Geologic Map Holistic Understanding with MLLMs",
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper focuses on understanding geologic maps using multimodal large language models, which involves developing a specialized benchmark and agent. There is no focus on the processing of training data for LLMs in the context of data engineering or training-stage data processing."
      },
      "datasets": [
        {
          "dataset_name": "microsoft/PEACE",
          "downloads": "247",
          "likes": "20",
          "link": "https://huggingface.co/datasets/microsoft/PEACE"
        }
      ],
      "conference_url_abs": "http://openaccess.thecvf.com//content/CVPR2025/html/Huang_PEACE_Empowering_Geologic_Map_Holistic_Understanding_with_MLLMs_CVPR_2025_paper.html",
      "tasks": [
        "Question Answering"
      ],
      "source": "arXiv"
    },
    {
      "id": "2403.15353",
      "abstract": "Background. Osteoarthritis affects about 528 million people worldwide, causing pain and stiffness in the joints. Arthroplasty is commonly performed to treat joint osteoarthritis, reducing pain and improving mobility. Nevertheless, a significant share of patients remain unsatisfied with their surgery. Personalised arthroplasty was introduced to improve surgical outcomes however current solutions require delays, making it difficult to integrate in clinical routine. We propose a fully automated workflow to design patient-specific implants for total knee arthroplasty.\n  Methods. The proposed pipeline first uses artificial neural networks to segment the femur and tibia proximal and distal extremities. Then the full bones are reconstructed using augmented statistical shape models, combining shape and landmarks information. Finally, 77 morphological parameters are computed to design patient-specific implants. The developed workflow has been trained on 91 CT scans and evaluated on 41 CT scans, in terms of accuracy and execution time.\n  Results. The workflow accuracy was $0.4\\pm0.2mm$ for segmentation, $1.0\\pm0.3mm$ for full bone reconstruction, and $2.2\\pm1.5mm$ for anatomical landmarks determination. The custom implants fitted the patients' anatomy with $0.9\\pm0.5mm$ accuracy. The whole process from segmentation to implants' design lasted about 15 minutes.\n  Conclusion. The proposed workflow performs a fast and reliable personalisation of knee implants, directly from a CT image without requiring any manual intervention. It allows the establishment of a patient-specific pre-operative planning in a very short time, making it easily available for all patients. Combined with efficient implant manufacturing techniques, this solution could help answer the growing number of arthroplasties while reducing complications and improving patients' satisfaction.",
      "authors": [
        "Aziliz Guezou-Philippe",
        "Arnaud Clav\\'e",
        "Ehouarn Maguet",
        "Ludivine Maintier",
        "Charles Garraud",
        "Jean-Rassaire Fouefack",
        "Val\\'erie Burdin",
        "Eric Stindel",
        "Guillaume Dardenne"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-22T17:08:03+00:00",
          "link": "https://arxiv.org/abs/2403.15353v1",
          "size": "1407kb",
          "version": "v1"
        },
        {
          "date": "2024-03-25T09:36:42+00:00",
          "link": "https://arxiv.org/abs/2403.15353v2",
          "size": "1407kb",
          "version": "v2"
        },
        {
          "date": "2025-01-07T11:06:13+00:00",
          "link": "https://arxiv.org/abs/2403.15353v3",
          "size": "2168kb",
          "version": "v3"
        }
      ],
      "title": "Fully automated workflow for designing patient-specific orthopaedic implants: application to total knee arthroplasty",
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on a workflow design for creating patient-specific orthopaedic implants using artificial neural networks, but it does not address aspects of LLM training data collection, processing, or engineering."
      },
      "tasks": [
        "Anatomy"
      ],
      "source": "arXiv"
    },
    {
      "id": "2208.04188",
      "abstract": "The classical Heawood inequality states that if the complete graph $K_n$ on $n$ vertices is embeddable in the sphere with $g$ handles, then $g \\ge\\dfrac{(n-3)(n-4)}{12}$. A higher-dimensional analogue of the Heawood inequality is the K\\\"uhnel conjecture. In a simplified form it states that for every integer $k>0$ there is $c_k>0$ such that if the union of $k$-faces of $n$-simplex embeds into the connected sum of $g$ copies of the Cartesian product $S^k\\times S^k$ of two $k$-dimensional spheres, then $g\\ge c_k n^{k+1}$. For $k>1$ only linear estimates were known. We present a quadratic estimate $g\\ge c_k n^2$. The proof is based on beautiful and fruitful interplay between geometric topology, combinatorics and linear algebra.",
      "authors": [
        "S. Dzhenzher",
        "A. Skopenkov"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Discrete Mathematics (cs.DM)",
        "Algebraic Topology (math.AT)",
        "Geometric Topology (math.GT)"
      ],
      "submission_historys": [
        {
          "date": "2022-08-05T13:20:10+00:00",
          "link": "https://arxiv.org/abs/2208.04188v1",
          "size": "41kb",
          "version": "v1"
        },
        {
          "date": "2022-09-01T08:36:10+00:00",
          "link": "https://arxiv.org/abs/2208.04188v2",
          "size": "44kb",
          "version": "v2"
        },
        {
          "date": "2024-02-14T13:06:15+00:00",
          "link": "https://arxiv.org/abs/2208.04188v3",
          "size": "54kb",
          "version": "v3"
        },
        {
          "date": "2024-04-14T10:36:03+00:00",
          "link": "https://arxiv.org/abs/2208.04188v4",
          "size": "62kb",
          "version": "v4"
        },
        {
          "date": "2024-05-03T13:16:59+00:00",
          "link": "https://arxiv.org/abs/2208.04188v5",
          "size": "63kb",
          "version": "v5"
        },
        {
          "date": "2025-03-01T08:29:15+00:00",
          "link": "https://arxiv.org/abs/2208.04188v6",
          "size": "63kb",
          "version": "v6"
        },
        {
          "date": "2025-03-31T15:39:45+00:00",
          "link": "https://arxiv.org/abs/2208.04188v7",
          "size": "67kb",
          "version": "v7"
        },
        {
          "date": "2025-06-27T12:32:05+00:00",
          "link": "https://arxiv.org/abs/2208.04188v8",
          "size": "73kb",
          "version": "v8"
        }
      ],
      "title": "A quadratic estimation for the K\\\"uhnel conjecture on embeddings",
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper discusses geometric topology and combinatorics in relation to the K\\\"uhnel conjecture, without any mention of LLM training data or related processing tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.13567",
      "abstract": "Retrieval-augmented question answering (QA) integrates external information and thereby increases the QA accuracy of reader models that lack domain knowledge. However, documents retrieved for closed domains require high expertise, so the reader model may have difficulty fully comprehending the text. Moreover, the retrieved documents contain thousands of tokens, some unrelated to the question. As a result, the documents include some inaccurate information, which could lead the reader model to mistrust the passages and could result in hallucinations. To solve these problems, we propose K-comp (Knowledge-injected compressor) which provides the knowledge required to answer correctly. The compressor automatically generates the prior knowledge necessary to facilitate the answer process prior to compression of the retrieved passages. Subsequently, the passages are compressed autoregressively, with the generated knowledge being integrated into the compression process. This process ensures alignment between the question intent and the compressed context. By augmenting this prior knowledge and concise context, the reader models are guided toward relevant answers and trust the context.",
      "authors": [
        "Jeonghun Cho",
        "Gary Geunbae Lee"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-23T11:14:21+00:00",
          "link": "https://arxiv.org/abs/2501.13567v1",
          "size": "618kb",
          "version": "v1"
        },
        {
          "date": "2025-02-06T07:41:07+00:00",
          "link": "https://arxiv.org/abs/2501.13567v2",
          "size": "618kb",
          "version": "v2"
        },
        {
          "date": "2025-05-28T08:20:05+00:00",
          "link": "https://arxiv.org/abs/2501.13567v3",
          "size": "615kb",
          "version": "v3"
        }
      ],
      "title": "K-COMP: Retrieval-Augmented Medical Domain Question Answering With Knowledge-Injected Compressor",
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper proposes 'K-comp,' a method for retrieval-augmented question answering that involves knowledge injection and context compression, directly contributing to the processing of data used in training and fine-tuning LLMs for improved QA accuracy."
      },
      "tasks": [
        "Question Answering",
        "RAG",
        "Retrieval"
      ],
      "repo_urls": [
        "https://github.com/jeonghun3572/K-COMP"
      ],
      "source": "arXiv"
    },
    {
      "id": "2404.04374",
      "abstract": "This manuscript explores the evolutionary emergence of semantic closure -- the self-referential mechanism through which symbols actively construct and interpret their own functional contexts -- by integrating concepts from relational biology, physical biosemiotics, and ecological psychology into a unified computational enactivism framework. By extending Hofmeyr's (F, A)-systems -- a continuation of Rosen's (M, R)-systems -- with temporal parametrization and multiscale causality, we develop a model capable of capturing critical life properties, including autopoiesis, anticipation, and adaptation. We then establish a formal equivalence between our extended (F, A)-systems and swarms of communicating automata, resolving self-referential challenges concerning the realizability of relational models. Our stepwise model traces the evolution of semantic closure from simple reaction networks that recognize regular languages to self-replicating chemical systems with memory and anticipatory capabilities, identifying self-reference as necessary for robust self-replication and open-ended evolution. Such a computational enactivist perspective underscores the essential necessity of implementing symbol-matter transformations into computing architectures, providing a cohesive theoretical basis for a recently proposed trialectic between autopoiesis, anticipation, and adaptation to solve the problem of relevance realization. Thus, our work opens pathways to new models of computation for life, agency and cognition, offering fundamental principles underlying biological information processing.",
      "authors": [
        "Amahury J. L\\'opez-D\\'iaz and Carlos Gershenson"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Biological Physics (physics.bio-ph)",
        "Information Theory (cs.IT)",
        "Neural and Evolutionary Computing (cs.NE)",
        "Information Theory (math.IT)",
        "Adaptation and Self-Organizing Systems (nlin.AO)",
        "Populations and Evolution (q-bio.PE)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-05T19:35:38+00:00",
          "link": "https://arxiv.org/abs/2404.04374v1",
          "size": "1449kb",
          "version": "v1"
        },
        {
          "date": "2024-06-03T17:30:54+00:00",
          "link": "https://arxiv.org/abs/2404.04374v2",
          "size": "1453kb",
          "version": "v2"
        },
        {
          "date": "2024-06-04T17:02:58+00:00",
          "link": "https://arxiv.org/abs/2404.04374v3",
          "size": "1453kb",
          "version": "v3"
        },
        {
          "date": "2024-07-11T13:49:50+00:00",
          "link": "https://arxiv.org/abs/2404.04374v4",
          "size": "1455kb",
          "version": "v4"
        },
        {
          "date": "2025-02-07T16:54:53+00:00",
          "link": "https://arxiv.org/abs/2404.04374v5",
          "size": "1466kb",
          "version": "v5"
        },
        {
          "date": "2025-06-27T12:06:31+00:00",
          "link": "https://arxiv.org/abs/2404.04374v6",
          "size": "53kb",
          "version": "v6"
        }
      ],
      "title": "Closing the Loop: How Semantic Closure Enables Open-Ended Evolution",
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The research paper deals with the evolutionary emergence of semantic closure and computational models for life and cognition, which do not pertain to LLM training data processing or data engineering."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2203.02023",
      "abstract": "We consider design of monetary mechanisms for two-sided matching. Mechanisms in the tradition of the deferred acceptance algorithm, even in variants incorporating money, tend to focus on the criterion of stability. Instead, in this work we seek a simple auction-inspired mechanism with social welfare guarantees. We consider a descending-price mechanism called the Marshallian Match, proposed (but not analyzed) by Waggoner and Weyl (2019). When all values for potential matches are positive, we show the Marshallian Match with a \"rebate\" payment rule achieves constant price of anarchy. This result extends to models with costs for acquiring information about one's values, and also to matching on hypergraphs. With possibly-negative valuations, which capture e.g. job markets, the problem becomes harder. We introduce notions of approximate stability and show that they have beneficial welfare implications. However, the main problem of proving constant factor welfare guarantees in \"ex ante stable equilibrium\" remains open.",
      "authors": [
        "Robin Bowers",
        "Bo Waggoner"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2022-03-03T21:17:13+00:00",
          "link": "https://arxiv.org/abs/2203.02023v1",
          "size": "30kb",
          "version": "v1"
        },
        {
          "date": "2022-04-28T19:45:12+00:00",
          "link": "https://arxiv.org/abs/2203.02023v2",
          "size": "29kb",
          "version": "v2"
        }
      ],
      "title": "High Welfare Matching Markets via Descending Price",
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper is centered around designing mechanisms for two-sided matching markets, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2406.08711",
      "abstract": "We consider max-weighted matching with costs for learning the weights, modeled as a \"Pandora's Box\" on each endpoint of an edge. Each vertex has an initially-unknown value for being matched to a neighbor, and an algorithm must pay some cost to observe this value. The goal is to maximize the total matched value minus costs. Our model is inspired by two-sided settings, such as matching employees to employers. Importantly for such settings, we allow for negative values which cause existing approaches to fail.\n  We first prove upper bounds for algorithms in two natural classes. Any algorithm that \"bundles\" the two Pandora boxes incident to an edge is an $o(1)$-approximation. Likewise, any \"vertex-based\" algorithm, which uses properties of the separate Pandora's boxes but does not consider the interaction of their value distributions, is an $o(1)$-approximation. Instead, we utilize Pandora's Nested-Box Problem, i.e. multiple stages of inspection. We give a self-contained, fully constructive optimal solution to the nested-boxes problem, which may have structural observations of interest compared to prior work. By interpreting each edge as a nested box, we leverage this solution to obtain a constant-factor approximation algorithm. Finally, we show any \"edge-based\" algorithm, which considers the interactions of values along an edge but not with the rest of the graph, is also an $o(1)$-approximation.",
      "authors": [
        "Robin Bowers",
        "Bo Waggoner"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-13T00:25:36+00:00",
          "link": "https://arxiv.org/abs/2406.08711v1",
          "size": "1200kb",
          "version": "v1"
        },
        {
          "date": "2024-11-06T19:22:50+00:00",
          "link": "https://arxiv.org/abs/2406.08711v2",
          "size": "1178kb",
          "version": "v2"
        }
      ],
      "title": "Matching with Nested and Bundled Pandora Boxes",
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on algorithmic solutions for max-weighted matching problems modeled as Pandora's Box settings. The content is unrelated to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2311.10129",
      "abstract": "Procedural content generation (PCG) can be applied to a wide variety of tasks in games, from narratives, levels and sounds, to trees and weapons. A large amount of game content is comprised of graphical assets, such as clouds, buildings or vegetation, that do not require gameplay function considerations. There is also a breadth of literature examining the procedural generation of such elements for purposes outside of games. The body of research, focused on specific methods for generating specific assets, provides a narrow view of the available possibilities. Hence, it is difficult to have a clear picture of all approaches and possibilities, with no guide for interested parties to discover possible methods and approaches for their needs, and no facility to guide them through each technique or approach to map out the process of using them. Therefore, a systematic literature review has been conducted, yielding 200 accepted papers. This paper explores state-of-the-art approaches to graphical asset generation, examining research from a wide range of applications, inside and outside of games. Informed by the literature, a conceptual framework has been derived to address the aforementioned gaps.",
      "authors": [
        "Kaisei Fukaya",
        "Damon Daylamani-Zad",
        "Harry Agius"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2023-11-16T18:36:16+00:00",
          "link": "https://arxiv.org/abs/2311.10129v1",
          "size": "2561kb",
          "version": "v1"
        }
      ],
      "title": "Intelligent Generation of Graphical Game Assets: A Conceptual Framework and Systematic Review of the State of the Art",
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The study conducts a systematic review of procedural content generation for graphical game assets, which is not related to LLM training data processing or engineering."
      },
      "tasks": [
        "Systematic Literature Review"
      ],
      "source": "arXiv"
    },
    {
      "id": "2212.09525",
      "abstract": "Recent years have witnessed significant growth of face alignment. Though dense facial landmark is highly demanded in various scenarios, e.g., cosmetic medicine and facial beautification, most works only consider sparse face alignment. To address this problem, we present a framework that can enrich landmark density by existing sparse landmark datasets, e.g., 300W with 68 points and WFLW with 98 points. Firstly, we observe that the local patches along each semantic contour are highly similar in appearance. Then, we propose a weakly-supervised idea of learning the refinement ability on original sparse landmarks and adapting this ability to enriched dense landmarks. Meanwhile, several operators are devised and organized together to implement the idea. Finally, the trained model is applied as a plug-and-play module to the existing face alignment networks. To evaluate our method, we manually label the dense landmarks on 300W testset. Our method yields state-of-the-art accuracy not only in newly-constructed dense 300W testset but also in the original sparse 300W and WFLW testsets without additional cost.",
      "authors": [
        "Yangyu Huang",
        "Xi Chen",
        "Jongyoo Kim",
        "Hao Yang",
        "Chong Li",
        "Jiaolong Yang",
        "Dong Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Graphics (cs.GR)",
        "Information Retrieval (cs.IR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2022-12-19T15:14:20+00:00",
          "link": "https://arxiv.org/abs/2212.09525v1",
          "size": "38496kb",
          "version": "v1"
        }
      ],
      "title": "FreeEnricher: Enriching Face Landmarks without Additional Cost",
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The research focuses on face landmark enrichment through a framework that enhances landmark density with existing datasets, unrelated to LLM training data processing or engineering."
      },
      "tasks": [
        "Face Alignment"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.01344",
      "abstract": "Large language models struggle to synthesize disparate pieces of information into a coherent plan when approaching a complex procedural task. In this work, we introduce a novel formalism and structure for such procedural knowledge. Based on this formalism, we present a novel procedural knowledge dataset called LCStep, which we created from LangChain tutorials. To leverage this procedural knowledge to solve new tasks, we propose analogy-augmented generation (AAG), which draws inspiration from the human ability to assimilate past experiences to solve unfamiliar problems. AAG uses a custom procedure memory store to retrieve and adapt specialized domain knowledge to answer new procedural tasks. We demonstrate that AAG outperforms few-shot and RAG baselines on LCStep, RecipeNLG, and CHAMP datasets under a pairwise LLM-based evaluation, corroborated by human evaluation in the case of RecipeNLG.",
      "authors": [
        "K Roth and Rushil Gupta and Simon Halle and Bang Liu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-02T15:58:24+00:00",
          "link": "https://arxiv.org/abs/2409.01344v1",
          "size": "1097kb",
          "version": "v1"
        },
        {
          "date": "2024-10-21T19:49:41+00:00",
          "link": "https://arxiv.org/abs/2409.01344v2",
          "size": "425kb",
          "version": "v2"
        }
      ],
      "title": "Pairing Analogy-Augmented Generation with Procedural Memory for Procedural Q&A",
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces a novel procedural knowledge dataset (LCStep) and focuses on procedural Q&A using LLMs, specifically detailing the creation and use of new datasets which directly involves data construction for LLM training and evaluation."
      },
      "tasks": [
        "Language Modelling",
        "Question Answering",
        "RAG"
      ],
      "repo_urls": [
        "https://github.com/kylrth/procedure-generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.21545",
      "abstract": "Data is fundamental to the training of language models (LM). Recent research has been dedicated to data efficiency, which aims to maximize performance by selecting a minimal or optimal subset of training data. Techniques such as data filtering, sampling, and selection play a crucial role in this area. To complement it, we define Data Efficacy, which focuses on maximizing performance by optimizing the organization of training data and remains relatively underexplored. This work introduces a general paradigm, DELT, for considering data efficacy in LM training, which highlights the significance of training data organization. DELT comprises three components: Data Scoring, Data Selection, and Data Ordering. Among these components, we design Learnability-Quality Scoring (LQS), as a new instance of Data Scoring, which considers both the learnability and quality of each data sample from the gradient consistency perspective. We also devise Folding Ordering (FO), as a novel instance of Data Ordering, which addresses issues such as model forgetting and data distribution bias. Comprehensive experiments validate the data efficacy in LM training, which demonstrates the following: Firstly, various instances of the proposed DELT enhance LM performance to varying degrees without increasing the data scale and model size. Secondly, among these instances, the combination of our proposed LQS for data scoring and Folding for data ordering achieves the most significant improvement. Lastly, data efficacy can be achieved together with data efficiency by applying data selection. Therefore, we believe that data efficacy is a promising foundational area in LM training.",
      "authors": [
        "Yalun Dai",
        "Yangyu Huang",
        "Xin Zhang",
        "Wenshan Wu",
        "Chong Li",
        "Wenhui Lu",
        "Shijie Cao",
        "Li Dong",
        "Scarlett Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Performance (cs.PF)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T17:59:07+00:00",
          "link": "https://arxiv.org/abs/2506.21545v1",
          "size": "2014kb",
          "version": "v1"
        }
      ],
      "title": "Data Efficacy for Language Model Training",
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper directly addresses LLM training data through the concept of Data Efficacy, introducing a paradigm for optimizing training data organization, including scoring, selection, and ordering\u2014all critical to data engineering in LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.20893",
      "abstract": "In this work, we introduce an output-reweighting unlearning method, RWFT, a lightweight technique that erases an entire class from a trained classifier without full retraining. Forgetting specific classes from trained models is essential for enforcing user deletion rights and mitigating harmful or biased predictions. The full retraining is costly and existing unlearning methods fail to replicate the behavior of the retrained models when predicting samples from the unlearned class. We prove this failure by designing a variant of membership inference attacks, MIA-NN that successfully reveals the unlearned class for any of these methods. We propose a simple redistribution of the probability mass for the prediction on the samples in the forgotten class which is robust to MIA-NN. We also introduce a new metric based on the total variation (TV) distance of the prediction probabilities to quantify residual leakage to prevent future methods from susceptibility to the new attack. Through extensive experiments with state of the art baselines in machine unlearning, we show that our approach matches the results of full retraining in both metrics used for evaluation by prior work and the new metric we propose in this work. Compare to state-of-the-art methods, we gain 2.79% in previously used metrics and 111.45% in our new TV-based metric over the best existing method.",
      "authors": [
        "Yian Wang",
        "Ali Ebrahimpour-Boroojeny",
        "and Hari Sundaram"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T23:53:56+00:00",
          "link": "https://arxiv.org/abs/2506.20893v1",
          "size": "487kb",
          "version": "v1"
        }
      ],
      "title": "On the Necessity of Output Distribution Reweighting for Effective Class Unlearning",
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper deals with forgetting classes in classifiers and does not address any aspect of LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21215",
      "abstract": "Causal reasoning capability is critical in advancing large language models (LLMs) toward strong artificial intelligence. While versatile LLMs appear to have demonstrated capabilities in understanding contextual causality and providing responses that obey the laws of causality, it remains unclear whether they perform genuine causal reasoning akin to humans. However, current evidence indicates the contrary. Specifically, LLMs are only capable of performing shallow (level-1) causal reasoning, primarily attributed to the causal knowledge embedded in their parameters, but they lack the capacity for genuine human-like (level-2) causal reasoning. To support this hypothesis, methodologically, we delve into the autoregression mechanism of transformer-based LLMs, revealing that it is not inherently causal. Empirically, we introduce a new causal Q&A benchmark called CausalProbe-2024, whose corpora are fresh and nearly unseen for the studied LLMs. The LLMs exhibit a significant performance drop on CausalProbe-2024 compared to earlier benchmarks, indicating the fact that they primarily engage in level-1 causal reasoning. To bridge the gap towards level-2 causal reasoning, we draw inspiration from the fact that human reasoning is usually facilitated by general knowledge and intended goals. We propose G^2-Reasoner, a method that incorporates general knowledge and goal-oriented prompts into LLMs' causal reasoning processes. Experiments demonstrate that G^2-Reasoner significantly enhances LLMs' causal reasoning capability, particularly in fresh and counterfactual contexts. This work sheds light on a new path for LLMs to advance towards genuine causal reasoning, going beyond level-1 and making strides towards level-2.",
      "authors": [
        "Haoang Chi",
        "He Li",
        "Wenjing Yang",
        "Feng Liu",
        "Long Lan",
        "Xiaoguang Ren",
        "Tongliang Liu",
        "Bo Han"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T13:11:01+00:00",
          "link": "https://arxiv.org/abs/2506.21215v1",
          "size": "1040kb",
          "version": "v1"
        }
      ],
      "title": "Unveiling Causal Reasoning in Large Language Models: Reality or Mirage?",
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the main focus of the paper is on advancing causal reasoning capabilities in LLMs, it introduces a new causal Q&A benchmark (CausalProbe-2024), implying some involvement with data construction, though not as a primary contribution."
      },
      "source": "arXiv"
    },
    {
      "id": "2204.06676",
      "abstract": "We introduce DRAGON, a fast and explainable hardware simulation and optimization toolchain that enables hardware architects to simulate hardware designs, and to optimize hardware designs to efficiently execute workloads.\n  The DRAGON toolchain provides the following tools: Hardware Model Generator (DGen), Hardware Simulator (DSim) and Hardware Optimizer (DOpt).\n  DSim provides the simulation of running algorithms (represented as data-flow graphs) on hardware described. DGen describes the hardware in detail, with user input architectures/technology (represented in a custom description language). A novel methodology of gradient descent from the simulation allows us optimize the hardware model (giving the directions for improvements in technology parameters and design parameters), provided by Dopt.\n  DRAGON framework (DSim) is much faster than previously avaible works for simulation, which is possible through performance-first code writing practices, mathematical formulas for common computing operations to avoid cycle-accurate simulation steps, efficient algorithms for mapping, and data-structure representations for hardware state. DRAGON framework (Dopt) generates performance optimized architectures for both AI and Non-AI Workloads, and provides technology improvement directions for 100x-1000x better future computing systems.",
      "authors": [
        "Khushal Sethi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)",
        "Artificial Intelligence (cs.AI)",
        "Emerging Technologies (cs.ET)",
        "Performance (cs.PF)"
      ],
      "submission_historys": [
        {
          "date": "2022-04-13T23:57:12+00:00",
          "link": "https://arxiv.org/abs/2204.06676v1",
          "size": "431kb",
          "version": "v1"
        },
        {
          "date": "2022-04-25T04:50:22+00:00",
          "link": "https://arxiv.org/abs/2204.06676v2",
          "size": "431kb",
          "version": "v2"
        },
        {
          "date": "2022-05-04T04:23:46+00:00",
          "link": "https://arxiv.org/abs/2204.06676v3",
          "size": "431kb",
          "version": "v3"
        },
        {
          "date": "2022-05-16T02:08:48+00:00",
          "link": "https://arxiv.org/abs/2204.06676v4",
          "size": "431kb",
          "version": "v4"
        },
        {
          "date": "2022-05-30T17:47:34+00:00",
          "link": "https://arxiv.org/abs/2204.06676v5",
          "size": "432kb",
          "version": "v5"
        },
        {
          "date": "2022-09-03T21:28:41+00:00",
          "link": "https://arxiv.org/abs/2204.06676v6",
          "size": "434kb",
          "version": "v6"
        },
        {
          "date": "2022-11-30T20:07:07+00:00",
          "link": "https://arxiv.org/abs/2204.06676v7",
          "size": "532kb",
          "version": "v7"
        },
        {
          "date": "2025-06-27T00:31:10+00:00",
          "link": "https://arxiv.org/abs/2204.06676v8",
          "size": "376kb",
          "version": "v8"
        }
      ],
      "title": "DRAGON (Differentiable Graph Execution) : A suite of Hardware Simulation and Optimization tools for Modern AI/Non-AI Workloads",
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper introduces a hardware simulation and optimization toolchain, DRAGON, for efficiently executing workloads, not specifically addressing LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2410.11230",
      "abstract": "This paper explores the challenges of detecting LGBTQIA+ hate speech of large language models across multiple languages, including English, Italian, Chinese and (code-switched) English-Tamil, examining the impact of machine translation and whether the nuances of hate speech are preserved across translation. We examine the hate speech detection ability of zero-shot and fine-tuned GPT. Our findings indicate that: (1) English has the highest performance and the code-switching scenario of English-Tamil being the lowest, (2) fine-tuning improves performance consistently across languages whilst translation yields mixed results. Through simple experimentation with original text and machine-translated text for hate speech detection along with a qualitative error analysis, this paper sheds light on the socio-cultural nuances and complexities of languages that may not be captured by automatic translation.",
      "authors": [
        "Fai Leui Chan",
        "Duke Nguyen",
        "Aditya Joshi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-15T03:24:03+00:00",
          "link": "https://arxiv.org/abs/2410.11230v1",
          "size": "187kb",
          "version": "v1"
        },
        {
          "date": "2024-10-24T03:04:27+00:00",
          "link": "https://arxiv.org/abs/2410.11230v2",
          "size": "187kb",
          "version": "v2"
        }
      ],
      "title": "\"Is Hate Lost in Translation?\": Evaluation of Multilingual LGBTQIA+ Hate Speech Detection",
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper evaluates multilingual hate speech detection which involves LLMs, it does not focus on new data processing methods; rather, it assesses capabilities in translation and fine-tuning, with minimal emphasis on data engineering processes."
      },
      "tasks": [
        "Hate Speech Detection",
        "Machine Translation",
        "Translation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.03635",
      "abstract": "Resource slicing in low Earth orbit satellite networks (LSN) is essential to support diversified services. In this paper, we investigate a resource slicing problem in LSN to reserve resources in satellites to achieve efficient resource provisioning. To address the challenges of non-stationary service demands, inaccurate prediction, and satellite mobility, we propose an adaptive digital twin (DT)-assisted resource slicing scheme for robust and adaptive resource management in LSN. Specifically, a slice DT, being able to capture the service demand prediction uncertainty through collected service demand data, is constructed to enhance the robustness of resource slicing decisions for dynamic service demands. In addition, the constructed DT can emulate resource slicing decisions for evaluating their performance, enabling adaptive slicing decision updates to efficiently reserve resources in LSN. Simulation results demonstrate that the proposed scheme outperforms benchmark methods, achieving low service demand violations with efficient resource consumption.",
      "authors": [
        "Mingcheng He",
        "Huaqing Wu",
        "Conghao Zhou",
        "Shisheng Hu",
        "Zhixuan Tang",
        "Weihua Zhuang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-06T03:20:15+00:00",
          "link": "https://arxiv.org/abs/2411.03635v1",
          "size": "279kb",
          "version": "v1"
        }
      ],
      "title": "Digital Twin-Assisted Robust and Adaptive Resource Slicing in LEO Satellite Networks",
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper discusses adaptive resource slicing in satellite networks using a digital twin approach, which is unrelated to training data processing for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2312.08806",
      "abstract": "Tag Management Systems were developed in order to support website publishers in installing multiple third-party JavaScript scripts (Tags) on their websites. Google developed its own TMS called ``Google Tag Manager'' (GTM) that is currently present on 42\\% of the top 1 million most popular websites. However, GTM has not yet been thoroughly evaluated by the academic research community. In this work, we study, for the first time, the Tags provided within the GTM system. We propose a new methodology called ``detecting privacy leaks in isolation'' and apply it to multiple Tags to analyse the types of data that Tags collect and contrast them to the legal and technical documentation, in collaboration with a legal expert. Across three studies - in-depth analysis of 6 Tags, automated analysis of 718 Tags, and analysis of Google ``Consent Mode'' - we discover multiple hidden data leaks, incomplete and diverging declarations, undisclosed third-parties and cookies, personal data sharing without consent and we further identify potential legal violations within EU Data Protection law.",
      "authors": [
        "Gilles Mertens and Nataliia Bielova and Vincent Roca and Cristiana Santos"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2023-12-14T10:46:18+00:00",
          "link": "https://arxiv.org/abs/2312.08806v1",
          "size": "2601kb",
          "version": "v1"
        },
        {
          "date": "2023-12-22T13:25:08+00:00",
          "link": "https://arxiv.org/abs/2312.08806v2",
          "size": "1965kb",
          "version": "v2"
        },
        {
          "date": "2024-11-08T12:11:29+00:00",
          "link": "https://arxiv.org/abs/2312.08806v3",
          "size": "1192kb",
          "version": "v3"
        },
        {
          "date": "2024-11-12T14:18:12+00:00",
          "link": "https://arxiv.org/abs/2312.08806v4",
          "size": "1192kb",
          "version": "v4"
        },
        {
          "date": "2025-04-11T12:07:21+00:00",
          "link": "https://arxiv.org/abs/2312.08806v5",
          "size": "1768kb",
          "version": "v5"
        },
        {
          "date": "2025-06-27T13:28:30+00:00",
          "link": "https://arxiv.org/abs/2312.08806v6",
          "size": "1741kb",
          "version": "v6"
        }
      ],
      "title": "You Can't Trust Your Tag Neither: Privacy Leaks and Potential Legal Violations within the Google Tag Manager",
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on studying privacy leaks and legal violations within Google Tag Manager, which does not involve any aspect of LLM training data collection, construction, or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.20055",
      "abstract": "Coronary artery disease poses a significant global health challenge, often necessitating percutaneous coronary intervention (PCI) with stent implantation. Assessing stent apposition holds pivotal importance in averting and identifying PCI complications that lead to in-stent restenosis. Here we proposed a novel three-dimensional (3D) distance-color-coded assessment (DccA)for PCI stent apposition via deep-learning-based 3D multi-object segmentation in intravascular optical coherence tomography (IV-OCT). Our proposed 3D DccA accurately segments 3D vessel lumens and stents in IV-OCT images, using a spatial matching network and dual-layer training with style transfer. It quantifies and maps stent-lumen distances into a 3D color space, facilitating 3D visual assessment of PCI stent apposition. Achieving over 95% segmentation precision, our proposed DccA enhances clinical evaluation of PCI stent deployment and supports personalized treatment planning.",
      "authors": [
        "Xiaoyang Qin",
        "Hao Huang",
        "Shuaichen Lin",
        "Xinhao Zeng",
        "Kaizhi Cao",
        "Renxiong Wu",
        "Yuming Huang",
        "Junqing Yang",
        "Yong Liu",
        "Gang Li",
        "Guangming Ni"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Optics (physics.optics)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-26T03:06:43+00:00",
          "link": "https://arxiv.org/abs/2410.20055v1",
          "size": "1817kb",
          "version": "v1"
        }
      ],
      "title": "3D Distance-color-coded Assessment of PCI Stent Apposition via Deep-learning-based Three-dimensional Multi-object Segmentation",
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper is centered on 3D segmentation in medical imaging, which does not relate to the data processing or engineering stages for LLM training data."
      },
      "tasks": [
        "Semantic Segmentation",
        "Style Transfer"
      ],
      "source": "arXiv"
    },
    {
      "id": "2310.17582",
      "abstract": "Flow-based generative models enjoy certain advantages in computing the data generation and the likelihood, and have recently shown competitive empirical performance. Compared to the accumulating theoretical studies on related score-based diffusion models, analysis of flow-based models, which are deterministic in both forward (data-to-noise) and reverse (noise-to-data) directions, remain sparse. In this paper, we provide a theoretical guarantee of generating data distribution by a progressive flow model, the so-called JKO flow model, which implements the Jordan-Kinderleherer-Otto (JKO) scheme in a normalizing flow network. Leveraging the exponential convergence of the proximal gradient descent (GD) in Wasserstein space, we prove the Kullback-Leibler (KL) guarantee of data generation by a JKO flow model to be $O(\\varepsilon^2)$ when using $N \\lesssim \\log (1/\\varepsilon)$ many JKO steps ($N$ Residual Blocks in the flow) where $\\varepsilon $ is the error in the per-step first-order condition. The assumption on data density is merely a finite second moment, and the theory extends to data distributions without density and when there are inversion errors in the reverse process where we obtain KL-$W_2$ mixed error guarantees. The non-asymptotic convergence rate of the JKO-type $W_2$-proximal GD is proved for a general class of convex objective functionals that includes the KL divergence as a special case, which can be of independent interest. The analysis framework can extend to other first-order Wasserstein optimization schemes applied to flow-based generative models.",
      "authors": [
        "Xiuyuan Cheng",
        "Jianfeng Lu",
        "Yixin Tan",
        "Yao Xie"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)",
        "Statistics Theory (math.ST)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2023-10-26T17:06:23+00:00",
          "link": "https://arxiv.org/abs/2310.17582v1",
          "size": "317kb",
          "version": "v1"
        },
        {
          "date": "2024-05-17T01:51:07+00:00",
          "link": "https://arxiv.org/abs/2310.17582v2",
          "size": "310kb",
          "version": "v2"
        },
        {
          "date": "2024-07-03T20:05:43+00:00",
          "link": "https://arxiv.org/abs/2310.17582v3",
          "size": "648kb",
          "version": "v3"
        }
      ],
      "title": "Convergence of flow-based generative models via proximal gradient descent in Wasserstein space",
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The focus is on the convergence of flow-based generative models, specifically JKO flows, in the context of data generation, but not specifically related to LLM training data processing."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/yixintan-zeta/jko_wass_grad"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.22448",
      "abstract": "A comparison between neural network clustering (NNC), hierarchical clustering (HC) and K-means clustering (KMC) is performed to evaluate the computational superiority of these three machine learning (ML) techniques for organizing large datasets into clusters. For NNC, a self-organizing map (SOM) training was applied to a collection of wavefront sensor reconstructions, decomposed in terms of 15 Zernike coefficients, characterizing the optical aberrations of the phase front transmitted by fluidic lenses. In order to understand the distribution and structure of the 15 Zernike variables within an input space, SOM-neighboring weight distances, SOM-sample hits, SOM-weight positions and SOM-weight planes were analyzed to form a visual interpretation of the system's structural properties. In the case of HC, the data was partitioned using a combined dissimilarity-linkage matrix computation. The effectiveness of this method was confirmed by a high cophenetic correlation coefficient value (c=0.9651). Additionally, a maximum number of clusters was established by setting an inconsistency cutoff of 0.8, yielding a total of 7 clusters for system segmentation. In addition, a KMC approach was employed to establish a quantitative measure of clustering segmentation efficiency, obtaining a sillhoute average value of 0.905 for data segmentation into K=5 non-overlapping clusters. On the other hand, the NNC analysis revealed that the 15 variables could be characterized through the collective influence of 8 clusters. It was established that the formation of clusters through the combined linkage and dissimilarity algorithms of HC alongside KMC is a more dependable clustering solution than separate assessment via NNC or HC, where altering the SOM size or inconsistency cutoff can lead to completely new clustering configurations.",
      "authors": [
        "Graciana Puentes"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Optics (physics.optics)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-28T14:01:12+00:00",
          "link": "https://arxiv.org/abs/2503.22448v1",
          "size": "577kb",
          "version": "v1"
        }
      ],
      "title": "Comparison between neural network clustering, hierarchical clustering and k-means clustering: Applications using fluidic lenses",
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper involves statistical clustering methods for analyzing optical aberrations in fluidic lenses and does not relate to LLM training data processing, engineering, or preparation."
      },
      "tasks": [
        "Clustering"
      ],
      "source": "arXiv"
    },
    {
      "id": "2403.20035",
      "abstract": "Traditionally for improving the segmentation performance of models, most approaches prefer to use adding more complex modules. And this is not suitable for the medical field, especially for mobile medical devices, where computationally loaded models are not suitable for real clinical environments due to computational resource constraints. Recently, state-space models (SSMs), represented by Mamba, have become a strong competitor to traditional CNNs and Transformers. In this paper, we deeply explore the key elements of parameter influence in Mamba and propose an UltraLight Vision Mamba UNet (UltraLight VM-UNet) based on this. Specifically, we propose a method for processing features in parallel Vision Mamba, named PVM Layer, which achieves excellent performance with the lowest computational load while keeping the overall number of processing channels constant. We conducted comparisons and ablation experiments with several state-of-the-art lightweight models on three skin lesion public datasets and demonstrated that the UltraLight VM-UNet exhibits the same strong performance competitiveness with parameters of only 0.049M and GFLOPs of 0.060. In addition, this study deeply explores the key elements of parameter influence in Mamba, which will lay a theoretical foundation for Mamba to possibly become a new mainstream module for lightweighting in the future. The code is available from https://github.com/wurenkai/UltraLight-VM-UNet .",
      "authors": [
        "Renkai Wu",
        "Yinghao Liu",
        "Pengchen Liang",
        "Qing Chang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-29T08:03:42+00:00",
          "link": "https://arxiv.org/abs/2403.20035v1",
          "size": "18927kb",
          "version": "v1"
        },
        {
          "date": "2024-04-09T14:29:10+00:00",
          "link": "https://arxiv.org/abs/2403.20035v2",
          "size": "14204kb",
          "version": "v2"
        },
        {
          "date": "2024-04-24T09:17:06+00:00",
          "link": "https://arxiv.org/abs/2403.20035v3",
          "size": "18979kb",
          "version": "v3"
        }
      ],
      "title": "UltraLight VM-UNet: Parallel Vision Mamba Significantly Reduces Parameters for Skin Lesion Segmentation",
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper discusses a new method for skin lesion segmentation using a lightweight model but does not relate to LLM training data processing or data engineering aspects."
      },
      "tasks": [
        "Image Segmentation",
        "Lesion Segmentation",
        "Mamba",
        "Medical Image Segmentation",
        "Segmentation",
        "Semantic Segmentation",
        "Skin Lesion Segmentation",
        "State Space Models"
      ],
      "repo_urls": [
        "https://github.com/wurenkai/UltraLight-VM-UNet"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.19812",
      "abstract": "We address the problem of detecting and mapping all books in a collection of images to entries in a given book catalogue. Instead of performing independent retrieval for each book detected, we treat the image-text mapping problem as a many-to-many matching process, looking for the best overall match between the two sets. We combine a state-of-the-art segmentation method (SAM) to detect book spines and extract book information using a commercial OCR. We then propose a two-stage approach for text-image matching, where CLIP embeddings are used first for fast matching, followed by a second slower stage to refine the matching, employing either the Hungarian Algorithm or a BERT-based model trained to cope with noisy OCR input and partial text matches. To evaluate our approach, we publish a new dataset of annotated bookshelf images that covers the whole book collection of a public library in Spain. In addition, we provide two target lists of book metadata, a closed-set of 15k book titles that corresponds to the known library inventory, and an open-set of 2.3M book titles to simulate an open-world scenario. We report results on two settings, on one hand on a matching-only task, where the book segments and OCR is given and the objective is to perform many-to-many matching against the target lists, and a combined detection and matching task, where books must be first detected and recognised before they are matched to the target list entries. We show that both the Hungarian Matching and the proposed BERT-based model outperform a fuzzy string matching baseline, and we highlight inherent limitations of the matching algorithms as the target increases in size, and when either of the two sets (detected books or target book list) is incomplete. The dataset and code are available at https://github.com/llabres/library-dataset",
      "authors": [
        "Artemis Llabr\\'es",
        "Arka Ujjal Dey",
        "Dimosthenis Karatzas",
        "and Ernest Valveny"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-29T09:05:04+00:00",
          "link": "https://arxiv.org/abs/2407.19812v1",
          "size": "8420kb",
          "version": "v1"
        }
      ],
      "title": "Image-text matching for large-scale book collections",
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses image-text matching for books using existing models like CLIP and a BERT-based model for text-image matching. It does not introduce new methods for constructing or processing data for LLMs but provides a dataset for evaluation."
      },
      "tasks": [
        "Image-text matching",
        "Optical Character Recognition (OCR)",
        "Text Matching"
      ],
      "repo_urls": [
        "https://github.com/llabres/library-dataset"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.01641",
      "abstract": "Boyen and Li posed an open problem in their ASIACRYPT 2016 conference paper: How to construct a tightly secure homomorphic signature scheme under the Short Integer Solution (SIS) hardness assumption in the standard model. This work provides the first complete resolution of this problem under the same assumption.",
      "authors": [
        "Heng Guo",
        "Fengxia Liu",
        "Kun Tian",
        "Zhiyong Zheng"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-02T15:51:57+00:00",
          "link": "https://arxiv.org/abs/2412.01641v1",
          "size": "585kb",
          "version": "v1"
        },
        {
          "date": "2024-12-03T15:03:09+00:00",
          "link": "https://arxiv.org/abs/2412.01641v2",
          "size": "119kb",
          "version": "v2"
        },
        {
          "date": "2025-03-15T05:25:44+00:00",
          "link": "https://arxiv.org/abs/2412.01641v3",
          "size": "36kb",
          "version": "v3"
        },
        {
          "date": "2025-04-19T03:02:20+00:00",
          "link": "https://arxiv.org/abs/2412.01641v4",
          "size": "353kb",
          "version": "v4"
        },
        {
          "date": "2025-06-18T17:32:07+00:00",
          "link": "https://arxiv.org/abs/2412.01641v5",
          "size": "41kb",
          "version": "v5"
        },
        {
          "date": "2025-06-27T01:52:06+00:00",
          "link": "https://arxiv.org/abs/2412.01641v6",
          "size": "41kb",
          "version": "v6"
        }
      ],
      "title": "Linearly Homomorphic Signature with Tight Security on Lattice",
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper deals with cryptographic constructions related to homomorphic signatures and does not involve any aspects of data processing or engineering for large language model training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2408.08704",
      "abstract": "Recent advancements in Large Vision-Language Models (LVLMs) have demonstrated remarkable capabilities across diverse tasks, garnering significant attention in AI communities. However, their performance and reliability in specialized domains such as medicine remain insufficiently assessed. In particular, most assessments over-concentrate on evaluating VLMs based on simple Visual Question Answering (VQA) on multi-modality data, while ignoring the in-depth characteristics of LVLMs. In this study, we introduce RadVUQA, a novel Radiological Visual Understanding and Question Answering benchmark, to comprehensively evaluate existing LVLMs. RadVUQA mainly validates LVLMs across five dimensions: 1) Anatomical understanding, assessing the models' ability to visually identify biological structures; 2) Multimodal comprehension, which involves the capability of interpreting linguistic and visual instructions to produce desired outcomes; 3) Quantitative and spatial reasoning, evaluating the models' spatial awareness and proficiency in combining quantitative analysis with visual and linguistic information; 4) Physiological knowledge, measuring the models' capability to comprehend functions and mechanisms of organs and systems; and 5) Robustness, which assesses the models' capabilities against unharmonized and synthetic data. The results indicate that both generalized LVLMs and medical-specific LVLMs have critical deficiencies with weak multimodal comprehension and quantitative reasoning capabilities. Our findings reveal the large gap between existing LVLMs and clinicians, highlighting the urgent need for more robust and intelligent LVLMs. The code is available at https://github.com/Nandayang/RadVUQA",
      "authors": [
        "Yang Nan",
        "Huichi Zhou",
        "Xiaodan Xing",
        "Guang Yang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-16T12:32:44+00:00",
          "link": "https://arxiv.org/abs/2408.08704v1",
          "size": "785kb",
          "version": "v1"
        },
        {
          "date": "2025-04-09T17:42:01+00:00",
          "link": "https://arxiv.org/abs/2408.08704v2",
          "size": "790kb",
          "version": "v2"
        }
      ],
      "title": "Beyond the Hype: A dispassionate look at vision-language models in medical scenario",
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The study evaluates vision-language models in medical contexts through a benchmarking process, focusing on assessing existing models rather than proposing methods related to LLM training data processing."
      },
      "tasks": [
        "Question Answering",
        "Spatial Reasoning",
        "Visual Question Answering",
        "Visual Question Answering (VQA)"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.15194",
      "abstract": "Multiple-choice question (MCQ) datasets like Massive Multitask Language Understanding (MMLU) are widely used to evaluate the commonsense, understanding, and problem-solving abilities of large language models (LLMs). However, the open-source nature of these benchmarks and the broad sources of training data for LLMs have inevitably led to benchmark contamination, resulting in unreliable evaluation results. To alleviate this issue, we propose a contamination-free and more challenging MCQ benchmark called MMLU-CF. This benchmark reassesses LLMs' understanding of world knowledge by averting both unintentional and malicious data leakage. To avoid unintentional data leakage, we source data from a broader domain and design three decontamination rules. To prevent malicious data leakage, we divide the benchmark into validation and test sets with similar difficulty and subject distributions. The test set remains closed-source to ensure reliable results, while the validation set is publicly available to promote transparency and facilitate independent verification. Our evaluation of mainstream LLMs reveals that the powerful GPT-4o achieves merely a 5-shot score of 73.4% and a 0-shot score of 71.9% on the test set, which indicates the effectiveness of our approach in creating a more rigorous and contamination-free evaluation standard. The GitHub repository is available at https://github.com/microsoft/MMLU-CF and the dataset refers to https://huggingface.co/datasets/microsoft/MMLU-CF.",
      "authors": [
        "Qihao Zhao",
        "Yangyu Huang",
        "Tengchao Lv",
        "Lei Cui",
        "Qinzheng Sun",
        "Shaoguang Mao",
        "Xin Zhang",
        "Ying Xin",
        "Qiufeng Yin",
        "Scarlett Li",
        "Furu Wei"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Performance (cs.PF)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-19T18:58:04+00:00",
          "link": "https://arxiv.org/abs/2412.15194v1",
          "size": "1317kb",
          "version": "v1"
        }
      ],
      "title": "MMLU-CF: A Contamination-free Multi-task Language Understanding Benchmark",
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes a new benchmark (MMLU-CF) to evaluate LLMs by addressing benchmark contamination, with emphasis on data leakage prevention but does not focus on LLM training data processing techniques."
      },
      "datasets": [
        {
          "dataset_name": "microsoft/MMLU-CF",
          "downloads": "2107",
          "likes": "15",
          "link": "https://huggingface.co/datasets/microsoft/MMLU-CF"
        }
      ],
      "tasks": [
        "MMLU",
        "Multiple-choice",
        "Multi-task Language Understanding",
        "World Knowledge"
      ],
      "repo_urls": [
        "https://github.com/microsoft/mmlu-cf"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.00480",
      "abstract": "This article presents fully distributed Lyapunov-based attack-resilient secondary control strategies for islanded inverter-based AC microgrids, designed to counter a broad spectrum of energy-unbounded False Data Injection (FDI) attacks, including exponential attacks, targeting control input channels. While distributed control improves scalability and reliability, it also increases susceptibility to cyber threats. The proposed strategies, supported by rigorous Lyapunov-based proofs, ensure uniformly ultimately bounded (UUB) convergence for frequency regulation, voltage containment, and power sharing, even under severe cyber attacks. The effectiveness of the proposed approach has been demonstrated through case studies on a modified IEEE 34-bus system, leveraging simulations and real-time Hardware-in-the-Loop experiments with OPAL-RT.",
      "authors": [
        "Mohamadamin Rajabinezhad",
        "Nesa Shams",
        "Asad Ali Khan",
        "Omar A. Beg",
        "Shan Zuo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-31T15:05:32+00:00",
          "link": "https://arxiv.org/abs/2501.00480v1",
          "size": "15909kb",
          "version": "v1"
        }
      ],
      "title": "Lyapunov-based Resilient Secondary Synchronization Strategy of AC Microgrids Under Exponentially Energy-Unbounded FDI Attacks",
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The research is centered around resilient control strategies for AC microgrids under cyber attacks, which is unrelated to LLM training data."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2503.09370",
      "abstract": "As artificial intelligence and digital medicine increasingly permeate healthcare systems, robust governance frameworks are essential to ensure ethical, secure, and effective implementation. In this context, medical image retrieval becomes a critical component of clinical data management, playing a vital role in decision-making and safeguarding patient information. Existing methods usually learn hash functions using bottleneck features, which fail to produce representative hash codes from blended embeddings. Although contrastive hashing has shown superior performance, current approaches often treat image retrieval as a classification task, using category labels to create positive/negative pairs. Moreover, many methods fail to address the out-of-distribution (OOD) issue when models encounter external OOD queries or adversarial attacks. In this work, we propose a novel method to consolidate knowledge of hierarchical features and optimisation functions. We formulate the knowledge consolidation by introducing Depth-aware Representation Fusion (DaRF) and Structure-aware Contrastive Hashing (SCH). DaRF adaptively integrates shallow and deep representations into blended features, and SCH incorporates image fingerprints to enhance the adaptability of positive/negative pairings. These blended features further facilitate OOD detection and content-based recommendation, contributing to a secure AI-driven healthcare environment. Moreover, we present a content-guided ranking to improve the robustness and reproducibility of retrieval results. Our comprehensive assessments demonstrate that the proposed method could effectively recognise OOD samples and significantly outperform existing approaches in medical image retrieval (p<0.05). In particular, our method achieves a 5.6-38.9% improvement in mean Average Precision on the anatomical radiology dataset.",
      "authors": [
        "Yang Nan",
        "Huichi Zhou",
        "Xiaodan Xing",
        "Giorgos Papanastasiou",
        "Lei Zhu",
        "Zhifan Gao",
        "Alejandro F Fangi",
        "Guang Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-12T13:16:42+00:00",
          "link": "https://arxiv.org/abs/2503.09370v1",
          "size": "3935kb",
          "version": "v1"
        }
      ],
      "title": "Revisiting Medical Image Retrieval via Knowledge Consolidation",
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The study centers on medical image retrieval with knowledge consolidation techniques and does not address LLM training data or processing methods."
      },
      "tasks": [
        "Image Retrieval",
        "Medical Image Retrieval",
        "Retrieval"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.02385",
      "abstract": "Value decomposition has long been a fundamental technique in multi-agent dynamic programming and reinforcement learning (RL). Specifically, the value function of a global state $(s_1,s_2,\\ldots,s_N)$ is often approximated as the sum of local functions: $V(s_1,s_2,\\ldots,s_N)\\approx\\sum_{i=1}^N V_i(s_i)$. This approach traces back to the index policy in restless multi-armed bandit problems and has found various applications in modern RL systems. However, the theoretical justification for why this decomposition works so effectively remains underexplored.\n  In this paper, we uncover the underlying mathematical structure that enables value decomposition. We demonstrate that a multi-agent Markov decision process (MDP) permits value decomposition if and only if its transition matrix is not \"entangled\" -- a concept analogous to quantum entanglement in quantum physics. Drawing inspiration from how physicists measure quantum entanglement, we introduce how to measure the \"Markov entanglement\" for multi-agent MDPs and show that this measure can be used to bound the decomposition error in general multi-agent MDPs.\n  Using the concept of Markov entanglement, we proved that a widely-used class of index policies is weakly entangled and enjoys a sublinear $\\mathcal O(\\sqrt{N})$ scale of decomposition error for $N$-agent systems. Finally, we show how Markov entanglement can be efficiently estimated in practice, providing practitioners with an empirical proxy for the quality of value decomposition.",
      "authors": [
        "Shuze Chen",
        "Tianyi Peng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Quantum Physics (quant-ph)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-03T02:54:25+00:00",
          "link": "https://arxiv.org/abs/2506.02385v1",
          "size": "302kb",
          "version": "v1"
        },
        {
          "date": "2025-06-21T02:59:07+00:00",
          "link": "https://arxiv.org/abs/2506.02385v2",
          "size": "302kb",
          "version": "v2"
        }
      ],
      "title": "Multi-agent Markov Entanglement",
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper discusses theoretical aspects of value decomposition in multi-agent MDPs, with no connection to LLM training data processing or data engineering stages."
      },
      "source": "arXiv"
    },
    {
      "id": "2109.05721",
      "abstract": "The recent progress of CNN has dramatically improved face alignment performance. However, few works have paid attention to the error-bias with respect to error distribution of facial landmarks. In this paper, we investigate the error-bias issue in face alignment, where the distributions of landmark errors tend to spread along the tangent line to landmark curves. This error-bias is not trivial since it is closely connected to the ambiguous landmark labeling task. Inspired by this observation, we seek a way to leverage the error-bias property for better convergence of CNN model. To this end, we propose anisotropic direction loss (ADL) and anisotropic attention module (AAM) for coordinate and heatmap regression, respectively. ADL imposes strong binding force in normal direction for each landmark point on facial boundaries. On the other hand, AAM is an attention module which can get anisotropic attention mask focusing on the region of point and its local edge connected by adjacent points, it has a stronger response in tangent than in normal, which means relaxed constraints in the tangent. These two methods work in a complementary manner to learn both facial structures and texture details. Finally, we integrate them into an optimized end-to-end training pipeline named ADNet. Our ADNet achieves state-of-the-art results on 300W, WFLW and COFW datasets, which demonstrates the effectiveness and robustness.",
      "authors": [
        "Yangyu Huang",
        "Hao Yang",
        "Chong Li",
        "Jongyoo Kim",
        "Fangyun Wei"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Graphics (cs.GR)",
        "Information Retrieval (cs.IR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2021-09-13T06:05:28+00:00",
          "link": "https://arxiv.org/abs/2109.05721v1",
          "size": "3651kb",
          "version": "v1"
        },
        {
          "date": "2022-12-19T15:12:48+00:00",
          "link": "https://arxiv.org/abs/2109.05721v2",
          "size": "3651kb",
          "version": "v2"
        }
      ],
      "title": "ADNet: Leveraging Error-Bias Towards Normal Direction in Face Alignment",
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper addresses error-bias in face alignment tasks and proposes methods for better CNN convergence, focusing on facial landmark error distributions but does not relate to LLM training data processing or engineering."
      },
      "conference_url_abs": "http://openaccess.thecvf.com//content/ICCV2021/html/Huang_ADNet_Leveraging_Error-Bias_Towards_Normal_Direction_in_Face_Alignment_ICCV_2021_paper.html",
      "tasks": [
        "Face Alignment"
      ],
      "repo_urls": [
        "https://github.com/huangyangyu/ADNet"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.00396",
      "abstract": "Deep neural network architectures often consist of repetitive structural elements. We introduce an approach that reveals these patterns and can be broadly applied to the study of deep learning. Similarly to how a power strip helps untangle and organize complex cable connections, this approach treats neurons as additional degrees of freedom in interactions, simplifying the structure and enhancing the intuitive understanding of interactions within deep neural networks. Furthermore, it reveals the translational symmetry of deep neural networks, which simplifies the application of the renormalization group transformation-a method that effectively analyzes the scaling behavior of the system. By utilizing translational symmetry and renormalization group transformations, we can analyze critical phenomena. This approach may open new avenues for studying deep neural networks using statistical physics.",
      "authors": [
        "Donghee Lee",
        "Hye-Sung Lee",
        "Jaeok Yi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Statistical Mechanics (cond-mat.stat-mech)",
        "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-01T04:39:04+00:00",
          "link": "https://arxiv.org/abs/2410.00396v1",
          "size": "425kb",
          "version": "v1"
        },
        {
          "date": "2025-06-18T06:30:20+00:00",
          "link": "https://arxiv.org/abs/2410.00396v2",
          "size": "426kb",
          "version": "v2"
        }
      ],
      "title": "Dynamic neuron approach to deep neural networks: Decoupling neurons for renormalization group analysis",
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The approach discussed here relates to deep neural network architecture and translational symmetry, with no mention of training data processing for LLMs or relevant data engineering work."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "1410.5420",
      "abstract": "The original description of the k-d tree recognized that rebalancing techniques, such as are used to build an AVL tree or a red-black tree, are not applicable to a k-d tree. Hence, in order to build a balanced k-d tree, it is necessary to find the median of the data for each recursive subdivision of those data. The sort or selection that is used to find the median for each subdivision strongly influences the computational complexity of building a k-d tree. This paper discusses an alternative algorithm that builds a balanced k-d tree by presorting the data in each of k dimensions prior to building the tree. It then preserves the order of these k sorts during tree construction and thereby avoids the requirement for any further sorting. Moreover, this algorithm is amenable to parallel execution via multiple threads. Compared to an algorithm that finds the median for each recursive subdivision, this presorting algorithm has equivalent performance for four dimensions and better performance for three or fewer dimensions.",
      "authors": [
        "Russell A. Brown"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2014-10-20T16:08:40+00:00",
          "link": "https://arxiv.org/abs/1410.5420v1",
          "size": "2292kb",
          "version": "v1"
        },
        {
          "date": "2014-10-22T02:22:55+00:00",
          "link": "https://arxiv.org/abs/1410.5420v2",
          "size": "2289kb",
          "version": "v2"
        },
        {
          "date": "2014-10-23T05:05:42+00:00",
          "link": "https://arxiv.org/abs/1410.5420v3",
          "size": "2571kb",
          "version": "v3"
        },
        {
          "date": "2014-10-24T17:53:47+00:00",
          "link": "https://arxiv.org/abs/1410.5420v4",
          "size": "2619kb",
          "version": "v4"
        },
        {
          "date": "2014-10-27T04:50:47+00:00",
          "link": "https://arxiv.org/abs/1410.5420v5",
          "size": "2700kb",
          "version": "v5"
        },
        {
          "date": "2014-10-29T14:59:24+00:00",
          "link": "https://arxiv.org/abs/1410.5420v6",
          "size": "3360kb",
          "version": "v6"
        },
        {
          "date": "2014-11-10T15:10:01+00:00",
          "link": "https://arxiv.org/abs/1410.5420v7",
          "size": "3730kb",
          "version": "v7"
        },
        {
          "date": "2014-11-17T04:46:47+00:00",
          "link": "https://arxiv.org/abs/1410.5420v8",
          "size": "3729kb",
          "version": "v8"
        },
        {
          "date": "2014-11-25T20:48:43+00:00",
          "link": "https://arxiv.org/abs/1410.5420v9",
          "size": "4074kb",
          "version": "v9"
        },
        {
          "date": "2014-11-30T02:35:50+00:00",
          "link": "https://arxiv.org/abs/1410.5420v10",
          "size": "4100kb",
          "version": "v10"
        },
        {
          "date": "2014-12-10T05:47:22+00:00",
          "link": "https://arxiv.org/abs/1410.5420v11",
          "size": "4204kb",
          "version": "v11"
        },
        {
          "date": "2014-12-14T20:11:46+00:00",
          "link": "https://arxiv.org/abs/1410.5420v12",
          "size": "4144kb",
          "version": "v12"
        },
        {
          "date": "2014-12-29T15:23:32+00:00",
          "link": "https://arxiv.org/abs/1410.5420v13",
          "size": "4148kb",
          "version": "v13"
        },
        {
          "date": "2014-12-30T20:27:00+00:00",
          "link": "https://arxiv.org/abs/1410.5420v14",
          "size": "321kb",
          "version": "v14"
        },
        {
          "date": "2015-01-02T17:49:54+00:00",
          "link": "https://arxiv.org/abs/1410.5420v15",
          "size": "321kb",
          "version": "v15"
        },
        {
          "date": "2015-01-07T16:25:12+00:00",
          "link": "https://arxiv.org/abs/1410.5420v16",
          "size": "321kb",
          "version": "v16"
        },
        {
          "date": "2015-01-10T02:33:07+00:00",
          "link": "https://arxiv.org/abs/1410.5420v17",
          "size": "321kb",
          "version": "v17"
        },
        {
          "date": "2015-02-10T07:07:24+00:00",
          "link": "https://arxiv.org/abs/1410.5420v18",
          "size": "321kb",
          "version": "v18"
        },
        {
          "date": "2015-02-15T15:12:58+00:00",
          "link": "https://arxiv.org/abs/1410.5420v19",
          "size": "322kb",
          "version": "v19"
        },
        {
          "date": "2015-04-02T17:16:05+00:00",
          "link": "https://arxiv.org/abs/1410.5420v20",
          "size": "963kb",
          "version": "v20"
        },
        {
          "date": "2015-04-05T14:47:36+00:00",
          "link": "https://arxiv.org/abs/1410.5420v21",
          "size": "964kb",
          "version": "v21"
        },
        {
          "date": "2015-04-09T04:13:16+00:00",
          "link": "https://arxiv.org/abs/1410.5420v22",
          "size": "964kb",
          "version": "v22"
        },
        {
          "date": "2015-04-12T22:07:16+00:00",
          "link": "https://arxiv.org/abs/1410.5420v23",
          "size": "973kb",
          "version": "v23"
        },
        {
          "date": "2015-04-14T19:43:47+00:00",
          "link": "https://arxiv.org/abs/1410.5420v24",
          "size": "973kb",
          "version": "v24"
        },
        {
          "date": "2015-04-20T02:42:12+00:00",
          "link": "https://arxiv.org/abs/1410.5420v25",
          "size": "964kb",
          "version": "v25"
        },
        {
          "date": "2015-04-28T04:20:00+00:00",
          "link": "https://arxiv.org/abs/1410.5420v26",
          "size": "964kb",
          "version": "v26"
        },
        {
          "date": "2015-05-07T14:07:35+00:00",
          "link": "https://arxiv.org/abs/1410.5420v27",
          "size": "965kb",
          "version": "v27"
        },
        {
          "date": "2020-02-13T04:20:11+00:00",
          "link": "https://arxiv.org/abs/1410.5420v28",
          "size": "1034kb",
          "version": "v28"
        },
        {
          "date": "2020-03-02T00:39:21+00:00",
          "link": "https://arxiv.org/abs/1410.5420v29",
          "size": "1158kb",
          "version": "v29"
        },
        {
          "date": "2021-11-22T04:16:08+00:00",
          "link": "https://arxiv.org/abs/1410.5420v30",
          "size": "1397kb",
          "version": "v30"
        },
        {
          "date": "2021-12-27T21:32:22+00:00",
          "link": "https://arxiv.org/abs/1410.5420v31",
          "size": "1397kb",
          "version": "v31"
        },
        {
          "date": "2022-01-28T17:29:14+00:00",
          "link": "https://arxiv.org/abs/1410.5420v32",
          "size": "1398kb",
          "version": "v32"
        },
        {
          "date": "2022-03-01T19:00:45+00:00",
          "link": "https://arxiv.org/abs/1410.5420v33",
          "size": "1398kb",
          "version": "v33"
        },
        {
          "date": "2023-02-18T20:29:58+00:00",
          "link": "https://arxiv.org/abs/1410.5420v34",
          "size": "1422kb",
          "version": "v34"
        },
        {
          "date": "2023-03-20T15:53:43+00:00",
          "link": "https://arxiv.org/abs/1410.5420v35",
          "size": "1424kb",
          "version": "v35"
        },
        {
          "date": "2023-04-23T18:36:45+00:00",
          "link": "https://arxiv.org/abs/1410.5420v36",
          "size": "1437kb",
          "version": "v36"
        },
        {
          "date": "2023-05-29T01:20:25+00:00",
          "link": "https://arxiv.org/abs/1410.5420v37",
          "size": "1441kb",
          "version": "v37"
        },
        {
          "date": "2023-11-19T23:10:14+00:00",
          "link": "https://arxiv.org/abs/1410.5420v38",
          "size": "1437kb",
          "version": "v38"
        },
        {
          "date": "2023-12-19T17:46:07+00:00",
          "link": "https://arxiv.org/abs/1410.5420v39",
          "size": "1296kb",
          "version": "v39"
        },
        {
          "date": "2023-12-20T17:48:59+00:00",
          "link": "https://arxiv.org/abs/1410.5420v40",
          "size": "1440kb",
          "version": "v40"
        },
        {
          "date": "2024-01-02T20:10:20+00:00",
          "link": "https://arxiv.org/abs/1410.5420v41",
          "size": "1227kb",
          "version": "v41"
        },
        {
          "date": "2024-02-16T23:22:26+00:00",
          "link": "https://arxiv.org/abs/1410.5420v42",
          "size": "1085kb",
          "version": "v42"
        },
        {
          "date": "2024-02-20T04:15:29+00:00",
          "link": "https://arxiv.org/abs/1410.5420v43",
          "size": "1228kb",
          "version": "v43"
        },
        {
          "date": "2024-06-19T15:19:12+00:00",
          "link": "https://arxiv.org/abs/1410.5420v44",
          "size": "1254kb",
          "version": "v44"
        },
        {
          "date": "2024-06-26T02:15:59+00:00",
          "link": "https://arxiv.org/abs/1410.5420v45",
          "size": "1039kb",
          "version": "v45"
        },
        {
          "date": "2024-07-08T17:04:28+00:00",
          "link": "https://arxiv.org/abs/1410.5420v46",
          "size": "1039kb",
          "version": "v46"
        },
        {
          "date": "2025-01-16T05:53:39+00:00",
          "link": "https://arxiv.org/abs/1410.5420v47",
          "size": "415kb",
          "version": "v47"
        },
        {
          "date": "2025-01-26T21:43:46+00:00",
          "link": "https://arxiv.org/abs/1410.5420v48",
          "size": "448kb",
          "version": "v48"
        },
        {
          "date": "2025-06-27T01:52:01+00:00",
          "link": "https://arxiv.org/abs/1410.5420v49",
          "size": "435kb",
          "version": "v49"
        }
      ],
      "title": "Building a Balanced k-d Tree in O(kn log n) Time",
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper discusses an algorithm for building a balanced k-d tree by presorting data, which is relevant to computational geometry and data structures but not related to LLM training data processing or engineering."
      },
      "repo_urls": [
        "https://github.com/chezruss/kd-tree"
      ],
      "source": "arXiv"
    },
    {
      "id": "2310.02003",
      "abstract": "Transformer-based large language models (LLMs) are constrained by the fixed context window of the underlying transformer architecture, hindering their ability to produce long and coherent outputs. Memory-augmented LLMs are a promising solution, but current approaches cannot handle long output generation tasks since they (1) only focus on reading memory and reduce its evolution to the concatenation of new memories or (2) use very specialized memories that cannot adapt to other domains. This paper presents L2MAC, the first practical LLM-based general-purpose stored-program automatic computer (von Neumann architecture) framework, an LLM-based multi-agent system, for long and consistent output generation. Its memory has two components: the instruction registry, which is populated with a prompt program to solve the user-given task, and a file store, which will contain the final and intermediate outputs. Each instruction in turn is executed by a separate LLM agent, whose context is managed by a control unit capable of precise memory reading and writing to ensure effective interaction with the file store. These components enable L2MAC to generate extensive outputs, bypassing the constraints of the finite context window while producing outputs that fulfill a complex user-specified task. We empirically demonstrate that L2MAC achieves state-of-the-art performance in generating large codebases for system design tasks, significantly outperforming other coding methods in implementing the detailed user-specified task; we show that L2MAC works for general-purpose extensive text-based tasks, such as writing an entire book; and we provide valuable insights into L2MAC's performance improvement over existing methods.",
      "authors": [
        "Samuel Holt",
        "Max Ruiz Luyten",
        "Mihaela van der Schaar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2023-10-02T16:55:19+00:00",
          "link": "https://arxiv.org/abs/2310.02003v1",
          "size": "4215kb",
          "version": "v1"
        },
        {
          "date": "2023-12-11T06:55:32+00:00",
          "link": "https://arxiv.org/abs/2310.02003v2",
          "size": "7467kb",
          "version": "v2"
        },
        {
          "date": "2024-03-16T01:42:40+00:00",
          "link": "https://arxiv.org/abs/2310.02003v3",
          "size": "7823kb",
          "version": "v3"
        },
        {
          "date": "2024-04-04T01:53:27+00:00",
          "link": "https://arxiv.org/abs/2310.02003v4",
          "size": "7904kb",
          "version": "v4"
        },
        {
          "date": "2024-04-10T13:38:30+00:00",
          "link": "https://arxiv.org/abs/2310.02003v5",
          "size": "7915kb",
          "version": "v5"
        },
        {
          "date": "2025-06-27T17:28:14+00:00",
          "link": "https://arxiv.org/abs/2310.02003v6",
          "size": "2412kb",
          "version": "v6"
        }
      ],
      "title": "L2MAC: Large Language Model Automatic Computer for Extensive Code Generation",
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper presents L2MAC, a novel method for memory-augmented LLMs that addresses context window limitations. This is directly relevant to the processing of training data in the context of generating large-scale text outputs."
      },
      "tasks": [
        "Code Generation",
        "Language Modeling",
        "Language Modelling",
        "Large Language Model"
      ],
      "repo_urls": [
        "https://github.com/samholt/l2mac",
        "https://github.com/vanderschaarlab/l2mac"
      ],
      "source": "arXiv"
    },
    {
      "id": "2406.11980",
      "abstract": "Manually annotating data for computational social science tasks can be costly, time-consuming, and emotionally draining. While recent work suggests that LLMs can perform such annotation tasks in zero-shot settings, little is known about how prompt design impacts LLMs' compliance and accuracy. We conduct a large-scale multi-prompt experiment to test how model selection (ChatGPT, PaLM2, and Falcon7b) and prompt design features (definition inclusion, output type, explanation, and prompt length) impact the compliance and accuracy of LLM-generated annotations on four CSS tasks (toxicity, sentiment, rumor stance, and news frames). Our results show that LLM compliance and accuracy are highly prompt-dependent. For instance, prompting for numerical scores instead of labels reduces all LLMs' compliance and accuracy. The overall best prompting setup is task-dependent, and minor prompt changes can cause large changes in the distribution of generated labels. By showing that prompt design significantly impacts the quality and distribution of LLM-generated annotations, this work serves as both a warning and practical guide for researchers and practitioners.",
      "authors": [
        "Shubham Atreja",
        "Joshua Ashkinaze",
        "Lingyao Li",
        "Julia Mendelsohn",
        "Libby Hemphill"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-17T18:01:43+00:00",
          "link": "https://arxiv.org/abs/2406.11980v1",
          "size": "9257kb",
          "version": "v1"
        }
      ],
      "title": "Prompt Design Matters for Computational Social Science Tasks but in Unpredictable Ways",
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The study explores prompt design impacts on LLM-generated data annotations in computational social science tasks. It partially touches on data preparation impacting annotation quality but does not extend to core LLM data processing pipelines."
      },
      "tasks": [
        "Model Selection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.19453",
      "abstract": "Although fine-tuning Large Language Models (LLMs) with multilingual data can rapidly enhance the multilingual capabilities of LLMs, they still exhibit a performance gap between the dominant language (e.g., English) and non-dominant ones due to the imbalance of training data across languages. To further enhance the performance of non-dominant languages, we propose ShifCon, a Shift-based multilingual Contrastive framework that aligns the internal forward process of other languages toward that of the dominant one. Specifically, it shifts the representations of non-dominant languages into the dominant language subspace, allowing them to access relatively rich information encoded in the model parameters. The enriched representations are then shifted back into their original language subspace before generation. Moreover, we introduce a subspace distance metric to pinpoint the optimal layer area for shifting representations and employ multilingual contrastive learning to further enhance the alignment of representations within this area. Experiments demonstrate that our ShifCon framework significantly enhances the performance of non-dominant languages, particularly for low-resource ones. Further analysis offers extra insights to verify the effectiveness of ShifCon and propel future research.",
      "authors": [
        "Hengyuan Zhang",
        "Chenming Shang",
        "Sizhe Wang",
        "Dongdong Zhang",
        "Yiyao Yu",
        "Feng Yao",
        "Renliang Sun",
        "Yujiu Yang",
        "Furu Wei"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-25T10:28:59+00:00",
          "link": "https://arxiv.org/abs/2410.19453v1",
          "size": "2373kb",
          "version": "v1"
        },
        {
          "date": "2024-11-06T11:49:10+00:00",
          "link": "https://arxiv.org/abs/2410.19453v2",
          "size": "2373kb",
          "version": "v2"
        },
        {
          "date": "2024-11-27T08:17:09+00:00",
          "link": "https://arxiv.org/abs/2410.19453v3",
          "size": "2373kb",
          "version": "v3"
        },
        {
          "date": "2024-12-11T07:41:18+00:00",
          "link": "https://arxiv.org/abs/2410.19453v4",
          "size": "2374kb",
          "version": "v4"
        },
        {
          "date": "2025-05-16T02:16:34+00:00",
          "link": "https://arxiv.org/abs/2410.19453v5",
          "size": "2372kb",
          "version": "v5"
        },
        {
          "date": "2025-06-27T07:21:49+00:00",
          "link": "https://arxiv.org/abs/2410.19453v6",
          "size": "2374kb",
          "version": "v6"
        }
      ],
      "title": "ShifCon: Enhancing Non-Dominant Language Capabilities with a Shift-based Multilingual Contrastive Framework",
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses enhancing multilingual capabilities of LLMs, specifically addressing training-stage data processing. It introduces a novel framework for aligning non-dominant languages, but it doesn't propose new data engineering methods for LLM training data."
      },
      "tasks": [
        "Contrastive Learning"
      ],
      "repo_urls": [
        "https://github.com/rattlesnakey/ShifCon"
      ],
      "source": "arXiv"
    },
    {
      "id": "2404.17349",
      "abstract": "Rectangulations are decompositions of a square into finitely many axis-aligned rectangles. We describe realizations of $(n-1)$-dimensional polytopes associated with two combinatorial families of rectangulations composed of $n$ rectangles. They are defined as quotientopes of natural lattice congruences on the weak Bruhat order on permutations in $\\mathfrak{S}_n$, and their skeleta are flip graphs on rectangulations. We give simple vertex and facet descriptions of these polytopes, in particular elementary formulas for computing the coordinates of the vertex corresponding to each rectangulation, in the spirit of J.-L. Loday's realization of the associahedron.",
      "authors": [
        "Jean Cardinal and Vincent Pilaud"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Computational Geometry (cs.CG)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-26T11:55:01+00:00",
          "link": "https://arxiv.org/abs/2404.17349v1",
          "size": "1256kb",
          "version": "v1"
        },
        {
          "date": "2024-10-29T15:36:31+00:00",
          "link": "https://arxiv.org/abs/2404.17349v2",
          "size": "1174kb",
          "version": "v2"
        }
      ],
      "title": "Rectangulotopes",
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper is about mathematical and combinatorial properties of rectangulations and does not address LLM training data processing or data engineering stages."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.23060",
      "abstract": "Self-correction has demonstrated potential in code generation by allowing language models to revise and improve their outputs through successive refinement. Recent studies have explored prompting-based strategies that incorporate verification or feedback loops using proprietary models, as well as training-based methods that leverage their strong reasoning capabilities. However, whether smaller models possess the capacity to effectively guide their outputs through self-reflection remains unexplored. Our findings reveal that smaller models struggle to exhibit reflective revision behavior across both self-correction paradigms. In response, we introduce CoCoS, an approach designed to enhance the ability of small language models for multi-turn code correction. Specifically, we propose an online reinforcement learning objective that trains the model to confidently maintain correct outputs while progressively correcting incorrect outputs as turns proceed. Our approach features an accumulated reward function that aggregates rewards across the entire trajectory and a fine-grained reward better suited to multi-turn correction scenarios. This facilitates the model in enhancing initial response quality while achieving substantial improvements through self-correction. With 1B-scale models, CoCoS achieves improvements of 35.8% on the MBPP and 27.7% on HumanEval compared to the baselines.",
      "authors": [
        "Jeonghun Cho",
        "Deokhyung Kang",
        "Hyounghun Kim",
        "Gary Geunbae Lee"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-29T04:04:44+00:00",
          "link": "https://arxiv.org/abs/2505.23060v1",
          "size": "202kb",
          "version": "v1"
        }
      ],
      "title": "Self-Correcting Code Generation Using Small Language Models",
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper explores code generation and refinement for small language models using self-correcting methods. It does not present any new approaches for training data processing for LLMs."
      },
      "tasks": [
        "Code Generation",
        "HumanEval",
        "mbpp"
      ],
      "repo_urls": [
        "https://github.com/jeonghun3572/CoCoS"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.14349",
      "abstract": "Ranking algorithms play a pivotal role in decision-making processes across diverse domains, from search engines to job applications. When rankings directly impact individuals, ensuring fairness becomes essential, particularly for groups that are marginalised or misrepresented in the data. Most of the existing group fairness frameworks often rely on ensuring proportional representation of protected groups. However, these approaches face limitations in accounting for the stochastic nature of ranking processes or the finite size of candidate pools. To this end, we present hyperFA*IR, a framework for assessing and enforcing fairness in rankings drawn from a finite set of candidates. It relies on a generative process based on the hypergeometric distribution, which models real-world scenarios by sampling without replacement from fixed group sizes. This approach improves fairness assessment when top-$k$ selections are large relative to the pool or when protected groups are small. We compare our approach to the widely used binomial model, which treats each draw as independent with fixed probability, and demonstrate$-$both analytically and empirically$-$that our method more accurately reproduces the statistical properties of sampling from a finite population. To operationalise this framework, we propose a Monte Carlo-based algorithm that efficiently detects unfair rankings by avoiding computationally expensive parameter tuning. Finally, we adapt our generative approach to define affirmative action policies by introducing weights into the sampling process.",
      "authors": [
        "Mauritz N. Cartier van Dissel",
        "Samuel Martin-Gutierrez",
        "Lisette Esp\\'in-Noboa",
        "Ana Mar\\'ia Jaramillo",
        "Fariba Karimi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Information Retrieval (cs.IR)",
        "Applications (stat.AP)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-17T09:45:08+00:00",
          "link": "https://arxiv.org/abs/2506.14349v1",
          "size": "650kb",
          "version": "v1"
        }
      ],
      "title": "hyperFA*IR: A hypergeometric approach to fair rankings with finite candidate pool",
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on fairness in ranking algorithms using a hypergeometric approach, which is unrelated to the processing of LLM training data."
      },
      "tasks": [
        "Fairness"
      ],
      "repo_urls": [
        "https://github.com/cshvienna/hyper_fair"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.06877",
      "abstract": "Test collections are information-retrieval tools that allow researchers to quickly and easily evaluate ranking algorithms. While test collections have become an integral part of IR research, the process of data creation involves significant manual-annotation effort, which often makes it very expensive and time-consuming. Consequently, test collections can become too small when the budget is limited, which may lead to unstable evaluations. As a cheaper alternative, recent studies have proposed using large language models (LLMs) to completely replace human assessors. However, while LLMs correlate to some extent with human judgments, their predictions are not perfect and often show bias. Thus, a complete replacement with LLMs is considered too risky and not fully reliable.\n  In this paper, we propose LLM-Assisted Relevance Assessments (LARA), an effective method to balance manual annotations with LLM annotations, helping build a rich and reliable test collection even under a low budget. We use the LLM's predicted relevance probabilities to select the most profitable documents for manual annotation under a budget constraint. Guided by theoretical reasoning, LARA actively learns to calibrate the LLM's predicted relevance probabilities, directing the human-annotation process. Then, using the calibration model learned from the limited manual annotations, LARA debiases the LLM predictions to annotate the remaining non-assessed data. Experiments on TREC-7 Ad Hoc, TREC-8 Ad Hoc, TREC Robust 2004, and TREC-COVID datasets show that LARA outperforms alternative solutions under almost any budget constraint. While the community debates humans versus LLMs in relevance assessments, we contend that, given the same amount of human effort, it is reasonable to leverage LLMs.",
      "authors": [
        "Rikiya Takehi",
        "Ellen M. Voorhees",
        "Tetsuya Sakai",
        "Ian Soboroff"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-11T11:17:35+00:00",
          "link": "https://arxiv.org/abs/2411.06877v1",
          "size": "1216kb",
          "version": "v1"
        },
        {
          "date": "2025-01-31T07:50:44+00:00",
          "link": "https://arxiv.org/abs/2411.06877v2",
          "size": "2142kb",
          "version": "v2"
        },
        {
          "date": "2025-05-08T06:40:02+00:00",
          "link": "https://arxiv.org/abs/2411.06877v3",
          "size": "2143kb",
          "version": "v3"
        },
        {
          "date": "2025-06-13T06:52:31+00:00",
          "link": "https://arxiv.org/abs/2411.06877v4",
          "size": "2067kb",
          "version": "v4"
        }
      ],
      "title": "LLM-Assisted Relevance Assessments: When Should We Ask LLMs for Help?",
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper proposes LLM-Assisted Relevance Assessments (LARA), which uses LLM predictions to optimize manual annotation in building test collections, directly contributing to the design and processing of training data for evaluations."
      },
      "tasks": [
        "Information Retrieval"
      ],
      "repo_urls": [
        "https://github.com/RikiyaT/LARA"
      ],
      "source": "arXiv"
    }
  ],
  "subjects": [
    "Logic in Computer Science (cs.LO)",
    "Computer Vision and Pattern Recognition (cs.CV)",
    "Optics (physics.optics)",
    "Statistics Theory (stat.TH)",
    "Networking and Internet Architecture (cs.NI)",
    "Physics and Society (physics.soc-ph)",
    "Optimization and Control (math.OC)",
    "Multimedia (cs.MM)",
    "Quantum Physics (quant-ph)",
    "Computer Science and Game Theory (cs.GT)",
    "Populations and Evolution (q-bio.PE)",
    "Computational Engineering, Finance, and Science (cs.CE)",
    "Computation and Language (cs.CL)",
    "Databases (cs.DB)",
    "Sound (cs.SD)",
    "Image and Video Processing (eess.IV)",
    "Performance (cs.PF)",
    "Methodology (stat.ME)",
    "Instrumentation and Detectors (physics.ins-det)",
    "Systems and Control (eess.SY)",
    "Statistical Mechanics (cond-mat.stat-mech)",
    "Cryptography and Security (cs.CR)",
    "Robotics (cs.RO)",
    "Materials Science (cond-mat.mtrl-sci)",
    "Information Retrieval (cs.IR)",
    "Artificial Intelligence (cs.AI)",
    "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
    "Atmospheric and Oceanic Physics (physics.ao-ph)",
    "Computational Geometry (cs.CG)",
    "Neurons and Cognition (q-bio.NC)",
    "Algebraic Topology (math.AT)",
    "Applications (stat.AP)",
    "Fluid Dynamics (physics.flu-dyn)",
    "Nuclear Experiment (nucl-ex)",
    "Applied Physics (physics.app-ph)",
    "Adaptation and Self-Organizing Systems (nlin.AO)",
    "Data Analysis, Statistics and Probability (physics.data-an)",
    "High Energy Physics - Phenomenology (hep-ph)",
    "Analysis of PDEs (math.AP)",
    "Computational Complexity (cs.CC)",
    "History and Overview (math.HO)",
    "High Energy Physics - Experiment (hep-ex)",
    "Systems and Control (cs.SY)",
    "Programming Languages (cs.PL)",
    "Category Theory (math.CT)",
    "Mathematical Software (cs.MS)",
    "Symbolic Computation (cs.SC)",
    "Biological Physics (physics.bio-ph)",
    "Probability (math.PR)",
    "Mathematical Physics (math.MP)",
    "Information Theory (math.IT)",
    "Discrete Mathematics (cs.DM)",
    "Emerging Technologies (cs.ET)",
    "Medical Physics (physics.med-ph)",
    "Signal Processing (eess.SP)",
    "Computation (stat.CO)",
    "Audio and Speech Processing (eess.AS)",
    "Social and Information Networks (cs.SI)",
    "Chaotic Dynamics (nlin.CD)",
    "Combinatorics (math.CO)",
    "Machine Learning (stat.ML)",
    "Earth and Planetary Astrophysics (astro-ph.EP)",
    "Information Theory (cs.IT)",
    "Computers and Society (cs.CY)",
    "Mathematical Physics (math-ph)",
    "Biomolecules (q-bio.BM)",
    "Other Statistics (stat.OT)",
    "Tissues and Organs (q-bio.TO)",
    "Atomic and Molecular Clusters (physics.atm-clus)",
    "Functional Analysis (math.FA)",
    "Numerical Analysis (cs.NA)",
    "Pattern Formation and Solitons (nlin.PS)",
    "Multiagent Systems (cs.MA)",
    "Statistics Theory (math.ST)",
    "Hardware Architecture (cs.AR)",
    "Neural and Evolutionary Computing (cs.NE)",
    "General Finance (q-fin.GN)",
    "Computational Physics (physics.comp-ph)",
    "Geometric Topology (math.GT)",
    "Computational Finance (q-fin.CP)",
    "Software Engineering (cs.SE)",
    "Nuclear Theory (nucl-th)",
    "Distributed, Parallel, and Cluster Computing (cs.DC)",
    "Human-Computer Interaction (cs.HC)",
    "Data Structures and Algorithms (cs.DS)",
    "Graphics (cs.GR)",
    "Digital Libraries (cs.DL)",
    "Operating Systems (cs.OS)",
    "Machine Learning (cs.LG)",
    "Chemical Physics (physics.chem-ph)",
    "Rings and Algebras (math.RA)",
    "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
    "Formal Languages and Automata Theory (cs.FL)",
    "Genomics (q-bio.GN)",
    "Dynamical Systems (math.DS)",
    "Numerical Analysis (math.NA)"
  ],
  "prompt": {
    "train_data": "\nYou are a computer science expert specializing in training data processing and data engineering for large language models (LLMs). You are skilled at identifying technical content in research papers that is related to **LLM training data**. I will provide you with a list of research papers from the arXiv (cs.\\*) domain.\n\n---\n\n### **Task Objective**\n\nFor each paper, determine whether it is directly related to the **processing of training data for LLMs**. Focus on identifying contributions in the following two areas:\n\n1. **Data Engineering Stage**:\n\n   * Includes tasks such as data collection, construction, cleaning, noise reduction, deduplication, filtering, format transformation, and data quality enhancement.\n\n2. **Training-Stage Data Processing**:\n\n   * Includes data preparation and processing for pre-training and post-training stages (e.g., fine-tuning, supervised fine-tuning (SFT), instruction tuning, etc.).\n\n---\n\n### **Relevance Level Classification Criteria**\n\n* `\"core\"`: The paper's primary contribution involves the design, construction, or processing of LLM training data\u2014for example, proposing a novel data pipeline, creating large-scale training data, or contributing new methods for improving data quality.\n* `\"partial\"`: The paper mentions data sources or preprocessing briefly in the background or experiments section, uses public datasets or existing tools, and does not propose new data-related methods.\n* `\"none-irrelevant\"`: The paper does not address any aspect of LLM training data collection, construction, or processing.\n\n---\n\n### **Output Format (strictly follow this JSON schema)**\n\n```json\n{\n  \"result\": [\n    {\n      \"id\": \"<paper id>\",\n      \"level\": \"core | partial | none-irrelevant\",\n      \"reason\": \"A 1-2 sentence explanation citing key parts of the abstract or methodology that justify the classification\"\n    }\n    // More papers...\n  ]\n}\n```\n"
  },
  "description": "Data source: https://arxiv.org/list/cs/new",
  "level_tatistics": {
    "none-irrelevant": 621,
    "partial": 124,
    "core": 28
  },
  "arxiv_update_date": "2025-06-30"
}