{
  "data": [
    {
      "id": "2304.02278",
      "abstract": "Text-Based Person Search (TBPS) faces critical challenges in cross-modal information fusion, requiring effective alignment of visual and textual modalities for person retrieval using natural language queries. Existing methods struggle with cross-modal heterogeneity, where visual and textual features reside in disparate semantic spaces, creating substantial inter-modal gaps that limit fusion effectiveness. We propose SCMM (Sew Calibration and Masked Modeling), a novel framework addressing these fusion challenges through two complementary mechanisms. First, our sew calibration loss implements adaptive margin constraints guided by caption quality, dynamically aligning image-text features while accommodating varying information density across modalities. Second, our masked caption modeling loss establishes fine-grained cross-modal correspondences through masked prediction tasks and cross-modal attention, enabling detailed visual-textual relationship learning. The streamlined dual-encoder architecture maintains computational efficiency while achieving superior fusion performance through synergistic alignment and correspondence strategies. Extensive experiments on three benchmark datasets validate SCMM's effectiveness, achieving state-of-the-art Rank1 accuracies of 73.81%, 64.25%, and 57.35% on CUHK-PEDES, ICFG-PEDES, and RSTPReID respectively. These results demonstrate the importance of quality-aware adaptive constraints and fine-grained correspondence modeling in advancing multimodal information fusion for person search applications.",
      "authors": [
        "Jing Liu",
        "Donglai Wei",
        "Yang Liu",
        "Sipeng Zhang",
        "Tong Yang",
        "Wei Zhou",
        "Weiping Ding",
        "Victor C. M. Leung"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2023-04-05T07:50:16+00:00",
          "link": "https://arxiv.org/abs/2304.02278v1",
          "size": "845kb",
          "version": "v1"
        },
        {
          "date": "2023-06-01T01:49:26+00:00",
          "link": "https://arxiv.org/abs/2304.02278v2",
          "size": "1277kb",
          "version": "v2"
        },
        {
          "date": "2024-10-17T08:57:50+00:00",
          "link": "https://arxiv.org/abs/2304.02278v3",
          "size": "1416kb",
          "version": "v3"
        },
        {
          "date": "2024-12-05T08:55:34+00:00",
          "link": "https://arxiv.org/abs/2304.02278v4",
          "size": "1755kb",
          "version": "v4"
        },
        {
          "date": "2024-12-06T10:13:10+00:00",
          "link": "https://arxiv.org/abs/2304.02278v5",
          "size": "2110kb",
          "version": "v5"
        },
        {
          "date": "2025-07-09T11:56:56+00:00",
          "link": "https://arxiv.org/abs/2304.02278v6",
          "size": "2016kb",
          "version": "v6"
        }
      ],
      "title": "SCMM: Calibrating Cross-modal Fusion for Text-Based Person Search",
      "links": {
        "Abstract": "https://arxiv.org/abs/2304.02278",
        "HTML": "https://arxiv.org/html/2304.02278",
        "PDF": "https://arxiv.org/pdf/2304.02278"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a framework for cross-modal fusion in text-based person search, focusing on alignment strategies, without contributing to LLM training data processing or dataset creation."
      },
      "tasks": [
        "Person Search",
        "Text based Person Search"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06254",
      "abstract": "Wallets are access points for the digital economys value creation. Wallets for blockchains store the end-users cryptographic keys for administrating their digital assets and enable access to blockchain Web3 systems. Web3 delivers new service opportunities. This chapter focuses on the Web3 enabled release of value through the lens of wallets. Wallets may be implemented as software apps on smartphones, web apps on desktops, or hardware devices. Wallet users request high security, ease of use, and access of relevance from their wallets. Increasing connectivity, functionality, autonomy, personal support, and offline capability make the wallet into the user's Universal Access Device for any digital asset. Through wallet based services, the owner obtains enhanced digital empowerment. The new Web3 solutionareas, Identity and Decentralisation, enable considerable societal effects, and wallets are an integral part of these. One example is self sovereign identity solutions combined with wallet borne AI for personalised support, empowering the enduser beyond anything previously known. Improved welfare is foreseen globally through enlarged markets with collaborative services with drastically lowered transaction costs compared to today, the expected vastly increased levels of automation in society necessitate enhanced enduser protection. As wallets are considered a weak spot for security, improving overall security through blockchains is essential.",
      "authors": [
        "Kim Peiter J{\\o}rgensen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-06T17:42:24+00:00",
          "link": "https://arxiv.org/abs/2507.06254v1",
          "size": "412kb",
          "version": "v1"
        }
      ],
      "title": "Wallets as Universal Access Devices",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06254",
        "PDF": "https://arxiv.org/pdf/2507.06254"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is focused on the digital economy and blockchain technology through the use of digital wallets, lacking any discussion on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06275",
      "abstract": "Offline Handwritten Text Recognition (HTR) systems play a crucial role in applications such as historical document digitization, automatic form processing, and biometric authentication. However, their performance is often hindered by the limited availability of annotated training data, particularly for low-resource languages and complex scripts. This paper presents a comprehensive survey of offline handwritten data augmentation and generation techniques designed to improve the accuracy and robustness of HTR systems. We systematically examine traditional augmentation methods alongside recent advances in deep learning, including Generative Adversarial Networks (GANs), diffusion models, and transformer-based approaches. Furthermore, we explore the challenges associated with generating diverse and realistic handwriting samples, particularly in preserving script authenticity and addressing data scarcity. This survey follows the PRISMA methodology, ensuring a structured and rigorous selection process. Our analysis began with 1,302 primary studies, which were filtered down to 848 after removing duplicates, drawing from key academic sources such as IEEE Digital Library, Springer Link, Science Direct, and ACM Digital Library. By evaluating existing datasets, assessment metrics, and state-of-the-art methodologies, this survey identifies key research gaps and proposes future directions to advance the field of handwritten text generation across diverse linguistic and stylistic landscapes.",
      "authors": [
        "Yassin Hussein Rassul",
        "Aram M. Ahmed",
        "Polla Fattah",
        "Bryar A. Hassan",
        "Arwaa W. Abdulkareem",
        "Tarik A. Rashid",
        "Joan Lu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T12:03:58+00:00",
          "link": "https://arxiv.org/abs/2507.06275v1",
          "size": "577kb",
          "version": "v1"
        }
      ],
      "title": "Advancing Offline Handwritten Text Recognition: A Systematic Review of Data Augmentation and Generation Techniques",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06275",
        "HTML": "https://arxiv.org/html/2507.06275v1",
        "PDF": "https://arxiv.org/pdf/2507.06275"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "CORE",
        "reason": "The paper conducts a systematic review of data augmentation and generation techniques, which are crucial for LLM training data processing in improving model performance, especially in low-resource scenarios."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06563",
      "abstract": "Social media users often make scientific claims without citing where these claims come from, generating a need to verify these claims. This paper details work done by the DS@GT team for CLEF 2025 CheckThat! Lab Task 4b Scientific Claim Source Retrieval which seeks to find relevant scientific papers based on implicit references in tweets. Our team explored 6 different data augmentation techniques, 7 different retrieval and reranking pipelines, and finetuned a bi-encoder. Achieving an MRR@5 of 0.58, our team ranked 16th out of 30 teams for the CLEF 2025 CheckThat! Lab Task 4b, and improvement of 0.15 over the BM25 baseline of 0.43. Our code is available on Github at https://github.com/dsgt-arc/checkthat-2025-swd/tree/main/subtask-4b.",
      "authors": [
        "Jeanette Schofield",
        "Shuyu Tian",
        "Hoang Thanh Thanh Truong and Maximilian Heil"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T05:32:02+00:00",
          "link": "https://arxiv.org/abs/2507.06563v1",
          "size": "535kb",
          "version": "v1"
        }
      ],
      "title": "DS@GT at CheckThat! 2025: Exploring Retrieval and Reranking Pipelines for Scientific Claim Source Retrieval on Social Media Discourse",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06563",
        "HTML": "https://arxiv.org/html/2507.06563v1",
        "PDF": "https://arxiv.org/pdf/2507.06563"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes retrieval and reranking pipelines for scientific claim source retrieval from social media discourse, without discussing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07013",
      "abstract": "The rapid development of digital pathology and modern deep learning has facilitated the emergence of pathology foundation models that are expected to solve general pathology problems under various disease conditions in one unified model, with or without fine-tuning. In parallel, spatial transcriptomics has emerged as a transformative technology that enables the profiling of gene expression on hematoxylin and eosin (H&E) stained histology images. Spatial transcriptomics unlocks the unprecedented opportunity to dive into existing histology images at a more granular, cellular level. In this work, we propose a lightweight and training-efficient approach to predict cellular composition directly from H&E-stained histology images by leveraging information-enriched feature embeddings extracted from pre-trained pathology foundation models. By training a lightweight multi-layer perceptron (MLP) regressor on cell-type abundances derived via cell2location, our method efficiently distills knowledge from pathology foundation models and demonstrates the ability to accurately predict cell-type compositions from histology images, without physically performing the costly spatial transcriptomics. Our method demonstrates competitive performance compared to existing methods such as Hist2Cell, while significantly reducing computational complexity.",
      "authors": [
        "Yutong Sun",
        "Sichen Zhu",
        "Peng Qiu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T16:43:04+00:00",
          "link": "https://arxiv.org/abs/2507.07013v1",
          "size": "13991kb",
          "version": "v1"
        }
      ],
      "title": "Integrating Pathology Foundation Models and Spatial Transcriptomics for Cellular Decomposition from Histology Images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07013",
        "HTML": "https://arxiv.org/html/2507.07013v1",
        "PDF": "https://arxiv.org/pdf/2507.07013"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study centers on using pathology foundation models and spatial transcriptomics for cellular decomposition, with no contribution to LLM training data processing or related data engineering techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.18951",
      "abstract": "Resolution of complex SQL issues persists as a significant bottleneck in real-world database applications. Current Large Language Models (LLMs), while adept at text-to-SQL translation, have not been rigorously evaluated on the more challenging task of debugging SQL issues. To address this gap, we introduce BIRD-CRITIC, a new SQL issue debugging benchmark comprising 530 PostgreSQL tasks (BIRD-CRITIC-PG) and 570 multi-dialect tasks (BIRD-CRITIC-Multi), distilled from authentic user issues and replayed within new environments to facilitate rigorous evaluation. Baseline evaluations underscore the task's complexity, with the leading reasoning model O3-Mini achieving only 38.87% success rate on BIRD-CRITIC-PG and 33.33% on BIRD-CRITIC-Multi. Meanwhile, advancing open-source models for database tasks is crucial for empowering local development while safeguarding data privacy. Therefore, we present Six-Gym (Sql-fIX-Gym), a training environment for elevating open-source model capabilities for SQL issue debugging. This environment leverages SQL-Rewind strategy, which automatically generates executable issue-solution datasets by reverse-engineering issues from verified SQLs. However, popular trajectory-based fine-tuning methods do not explore substantial supervisory signals. We further propose f-Plan Boosting, which extracts high-level debugging plans from SQL solutions, enabling teacher LLMs to produce 73.7% more successful trajectories for training. We integrate these components into an open-source agent, Bird-Fixer. Based on Qwen-2.5-Coder-14B, Bird-Fixer achieves 38.11% success rate on BIRD-CRITIC-PG and 29.65% on BIRD-CRITIC-Multi, surpassing leading proprietary models such as Claude-3.7-Sonnet and GPT-4.1, marking a significant step toward democratizing sophisticated SQL-debugging capabilities. The leaderboard and source code are available: https://bird-critic.github.io/",
      "authors": [
        "Jinyang Li",
        "Xiaolong Li",
        "Ge Qu",
        "Per Jacobsson",
        "Bowen Qin",
        "Binyuan Hui",
        "Shuzheng Si",
        "Nan Huo",
        "Xiaohan Xu",
        "Yue Zhang",
        "Ziwei Tang",
        "Yuanshuai Li",
        "Florensia Widjaja",
        "Xintong Zhu",
        "Feige Zhou",
        "Yongfeng Huang",
        "Yannis Papakonstantinou",
        "Fatma Ozcan",
        "Chenhao Ma",
        "Reynold Cheng"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Databases (cs.DB)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T09:41:37+00:00",
          "link": "https://arxiv.org/abs/2506.18951v1",
          "size": "2761kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T08:22:28+00:00",
          "link": "https://arxiv.org/abs/2506.18951v2",
          "size": "2761kb",
          "version": "v2"
        }
      ],
      "title": "SWE-SQL: Illuminating LLM Pathways to Solve User SQL Issues in Real-World Applications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18951",
        "HTML": "https://arxiv.org/html/2506.18951v2",
        "PDF": "https://arxiv.org/pdf/2506.18951"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper makes a technical contribution by introducing BIRD-CRITIC, a new benchmark, and SQL-Rewind strategy for generating datasets, focusing on data processing for training models in the context of SQL debugging."
      },
      "datasets": [
        {
          "dataset_name": "birdsql/bird-critic-1.0-open",
          "downloads": "478",
          "likes": "1",
          "link": "https://huggingface.co/datasets/birdsql/bird-critic-1.0-open"
        },
        {
          "dataset_name": "birdsql/bird-critic-1.0-postgresql",
          "downloads": "313",
          "likes": "3",
          "link": "https://huggingface.co/datasets/birdsql/bird-critic-1.0-postgresql"
        },
        {
          "dataset_name": "birdsql/bird-critic-1.0-flash-exp",
          "downloads": "297",
          "likes": "6",
          "link": "https://huggingface.co/datasets/birdsql/bird-critic-1.0-flash-exp"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06313",
      "abstract": "Transformer-based Language Models' computation and memory overhead increase quadratically as a function of sequence length. The quadratic cost poses challenges when employing LLMs for processing long sequences. In this work, we introduce \\ourmodelacronym~(Extend at Test-Time), method for extending the context length of short context Transformer-based LLMs, with constant memory requirement and linear computation overhead. ETT enable the extension of the context length at test-time by efficient fine-tuning the model's parameters on the input context, chunked into overlapping small subsequences. We evaluate ETT on LongBench by extending the context length of GPT-Large and Phi-2 up to 32 times, increasing from 1k to 32k tokens. This results in up to a 30 percent improvement in the model's accuracy. We also study how context can be stored in LLM's weights effectively and efficiently. Through a detailed ablation study, we examine which Transformer modules are most beneficial to fine-tune at test-time. Interestingly, we find that fine-tuning the second layer of the FFNs is more effective than full fine-tuning, leading to a further improvement in the models' accuracy.",
      "authors": [
        "Kiarash Zahirnia",
        "Zahra Golpayegani",
        "Walid Ahmad",
        "Yang Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T18:06:45+00:00",
          "link": "https://arxiv.org/abs/2507.06313v1",
          "size": "223kb",
          "version": "v1"
        }
      ],
      "title": "ETT: Expanding the Long Context Understanding Capability of LLMs at Test-Time",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06313",
        "HTML": "https://arxiv.org/html/2507.06313v1",
        "PDF": "https://arxiv.org/pdf/2507.06313"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on extending the context length of LLMs at test time through fine-tuning rather than describing any preprocessing or processing of training data itself."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06397",
      "abstract": "This paper presents a framework for mapping underwater caves. Underwater caves are crucial for fresh water resource management, underwater archaeology, and hydrogeology. Mapping the cave's outline and dimensions, as well as creating photorealistic 3D maps, is critical for enabling a better understanding of this underwater domain. In this paper, we present the mapping of an underwater cave segment (the catacombs) of the Devil's Eye cave system at Ginnie Springs, FL. We utilized a set of inexpensive action cameras in conjunction with a dive computer to estimate the trajectories of the cameras together with a sparse point cloud. The resulting reconstructions are utilized to produce a one-dimensional retract of the cave passages in the form of the average trajectory together with the boundaries (top, bottom, left, and right). The use of the dive computer enables the observability of the z-dimension in addition to the roll and pitch in a visual/inertial framework (SVIn2). In addition, the keyframes generated by SVIn2 together with the estimated camera poses for select areas are used as input to a global optimization (bundle adjustment) framework -- COLMAP -- in order to produce a dense reconstruction of those areas. The same cave segment is manually surveyed using the MNemo V2 instrument, providing an additional set of measurements validating the proposed approach. It is worth noting that with the use of action cameras, the primary components of a cave map can be constructed. Furthermore, with the utilization of a global optimization framework guided by the results of VI-SLAM package SVIn2, photorealistic dense 3D representations of selected areas can be reconstructed.",
      "authors": [
        "Michalis Chatzispyrou",
        "Luke Horgan",
        "Hyunkil Hwang",
        "Harish Sathishchandra",
        "Monika Roznere",
        "Alberto Quattrini Li",
        "Philippos Mordohai",
        "Ioannis Rekleitis"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T21:03:35+00:00",
          "link": "https://arxiv.org/abs/2507.06397v1",
          "size": "5416kb",
          "version": "v1"
        }
      ],
      "title": "Mapping the Catacombs: An Underwater Cave Segment of the Devil's Eye System",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06397",
        "HTML": "https://arxiv.org/html/2507.06397v1",
        "PDF": "https://arxiv.org/pdf/2507.06397"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about mapping underwater caves with visual/inertial frameworks and does not relate to LLM training data processing or any technique to improve data quality for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06619",
      "abstract": "When applying machine learning to medical image classification, data leakage is a critical issue. Previous methods, such as adding noise to gradients for differential privacy, work well on large datasets like MNIST and CIFAR-100, but fail on small, imbalanced medical datasets like HAM10000. This is because the imbalanced distribution causes gradients from minority classes to be clipped and lose crucial information, while majority classes dominate. This leads the model to fall into suboptimal solutions early. To address this, we propose SAD-DPSGD, which uses a linear decaying mechanism for noise and clipping thresholds. By allocating more privacy budget and using higher clipping thresholds in the initial training phases, the model avoids suboptimal solutions and enhances performance. Experiments show that SAD-DPSGD outperforms Auto-DPSGD on HAM10000, improving accuracy by 2.15% under $\\epsilon = 3.0$ , $\\delta = 10^{-3}$.",
      "authors": [
        "Xiaobo Huang and Fang Xie"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T07:46:29+00:00",
          "link": "https://arxiv.org/abs/2507.06619v1",
          "size": "881kb",
          "version": "v1"
        }
      ],
      "title": "Steps Adaptive Decay DPSGD: Enhancing Performance on Imbalanced Datasets with Differential Privacy with HAM10000",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06619",
        "HTML": "https://arxiv.org/html/2507.06619v1",
        "PDF": "https://arxiv.org/pdf/2507.06619"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with enhancing machine learning performance on imbalanced medical datasets using differential privacy, without relevance to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "1907.00317",
      "abstract": "We consider the online traveling salesman problem on the real line (OLTSPL) in which a salesman begins at the origin, traveling at no faster than unit speed along the real line, and wants to serve a sequence of requests, arriving online over time on the real line and return to the origin as quickly as possible. The problem has been widely investigated for more than two decades, but was just optimally solved by a deterministic algorithm with a competitive ratio of $(9+\\sqrt{17})/8$, reported in~[Bjelde A. et al., in Proc. SODA 2017, pp.994--1005].\n  In this study we present lower bounds and upper bounds for randomized algorithms in the OLTSPL. Precisely, we show, for the first time, that a simple randomized \\emph{zealous} algorithm can improve the optimal deterministic algorithm. Here an algorithm is called zealous if waiting strategies are not allowed to use for the salesman as long as there are unserved requests. Moreover, we incorporate a natural waiting scheme into the randomized algorithm, which can even achieve the lower bound we propose for any randomized algorithms, and thus it is optimal. We also consider randomized algorithms against a \\emph{fair} adversary, i.e. an adversary with restricted power that requires the salesman to move within the convex hull of the origin and the requests released so far. The randomized non-zealous algorithm can outperform the optimal deterministic algorithm against the fair adversary as well.",
      "authors": [
        "Pei-Chuan Chen",
        "Erik D. Demaine",
        "Chung-Shou Liao",
        "Hao-Ting Wei"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2019-06-30T04:40:56+00:00",
          "link": "https://arxiv.org/abs/1907.00317v1",
          "size": "426kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T01:06:47+00:00",
          "link": "https://arxiv.org/abs/1907.00317v2",
          "size": "0kb",
          "version": "v2"
        }
      ],
      "title": "Waiting is not easy but worth it: the online TSP on the line revisited",
      "links": {
        "Abstract": "https://arxiv.org/abs/1907.00317",
        "PDF": "https://arxiv.org/pdf/1907.00317"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on the online traveling salesman problem with randomized algorithms, unrelated to the processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.13362",
      "abstract": "Super-resolution (SR) is a key technique for improving the visual quality of video content by increasing its spatial resolution while reconstructing fine details. SR has been employed in many applications including video streaming, where compressed low-resolution content is typically transmitted to end users and then reconstructed with a higher resolution and enhanced quality. To support real-time playback, it is important to implement fast SR models while preserving reconstruction quality; however most existing solutions, in particular those based on complex deep neural networks, fail to do so. To address this issue, this paper proposes a low-complexity SR method, RTSR, designed to enhance the visual quality of compressed video content, focusing on resolution up-scaling from a) 360p to 1080p and from b) 540p to 4K. The proposed approach utilizes a CNN-based network architecture, which was optimized for AV1 (SVT)-encoded content at various quantization levels based on a dual-teacher knowledge distillation method. This method was submitted to the AIM 2024 Video Super-Resolution Challenge, specifically targeting the Efficient/Mobile Real-Time Video Super-Resolution competition. It achieved the best trade-off between complexity and coding performance (measured in PSNR, SSIM and VMAF) among all six submissions. The code will be available soon.",
      "authors": [
        "Yuxuan Jiang",
        "Jakub Nawa{\\l}a",
        "Chen Feng",
        "Fan Zhang",
        "Xiaoqing Zhu",
        "Joel Sole",
        "and David Bull"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-20T14:36:06+00:00",
          "link": "https://arxiv.org/abs/2411.13362v1",
          "size": "21637kb",
          "version": "v1"
        }
      ],
      "title": "RTSR: A Real-Time Super-Resolution Model for AV1 Compressed Content",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.13362",
        "HTML": "https://arxiv.org/html/2411.13362",
        "PDF": "https://arxiv.org/pdf/2411.13362"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses super-resolution for video content using a CNN-based method, without contributing to LLM training data processing or dataset improvement for language models."
      },
      "tasks": [
        "4k",
        "Knowledge Distillation",
        "Quantization",
        "SSIM",
        "Super-Resolution",
        "Video Super-Resolution"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.14568",
      "abstract": "Multi-Agent Path Finding (MAPF) focuses on determining conflict-free paths for multiple agents navigating through a shared space to reach specified goal locations. This problem becomes computationally challenging, particularly when handling large numbers of agents, as frequently encountered in practical applications like coordinating autonomous vehicles. Quantum Computing (QC) is a promising candidate in overcoming such limits. However, current quantum hardware is still in its infancy and thus limited in terms of computing power and error robustness. In this work, we present the first optimal hybrid quantum-classical MAPF algorithms which are based on branch-andcut-and-price. QC is integrated by iteratively solving QUBO problems, based on conflict graphs. Experiments on actual quantum hardware and results on benchmark data suggest that our approach dominates previous QUBO formulationsand state-of-the-art MAPF solvers.",
      "authors": [
        "Thore Gerlach",
        "Loong Kuan Lee",
        "Fr\\'ed\\'eric Barbaresco",
        "Nico Piatkowski"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-24T15:20:09+00:00",
          "link": "https://arxiv.org/abs/2501.14568v1",
          "size": "738kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T13:09:38+00:00",
          "link": "https://arxiv.org/abs/2501.14568v2",
          "size": "624kb",
          "version": "v2"
        }
      ],
      "title": "Hybrid Quantum-Classical Multi-Agent Pathfinding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.14568",
        "HTML": "https://arxiv.org/html/2501.14568v2",
        "PDF": "https://arxiv.org/pdf/2501.14568"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses a hybrid quantum-classical approach to the Multi-Agent Path Finding problem, discussing computational challenges without mentioning any LLM training data processing or related data engineering tasks."
      },
      "tasks": [
        "Autonomous Vehicles",
        "Multi-Agent Path Finding"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.02966",
      "abstract": "The use of Natural Language Processing (NLP) in highstakes AI-based applications has increased significantly in recent years, especially since the emergence of Large Language Models (LLMs). However, despite their strong performance, LLMs introduce important legal/ ethical concerns, particularly regarding privacy, data protection, and transparency. Due to these concerns, this work explores the use of Named- Entity Recognition (NER) to facilitate the privacy-preserving training (or adaptation) of LLMs. We propose a framework that uses NER technologies to anonymize sensitive information in text data, such as personal identities or geographic locations. An evaluation of the proposed privacy-preserving learning framework was conducted to measure its impact on user privacy and system performance in a particular high-stakes and sensitive setup: AI-based resume scoring for recruitment processes. The study involved two language models (BERT and RoBERTa) and six anonymization algorithms (based on Presidio, FLAIR, BERT, and different versions of GPT) applied to a database of 24,000 candidate profiles. The findings indicate that the proposed privacy preservation techniques effectively maintain system performance while playing a critical role in safeguarding candidate confidentiality, thus promoting trust in the experimented scenario. On top of the proposed privacy-preserving approach, we also experiment applying an existing approach that reduces the gender bias in LLMs, thus finally obtaining our proposed Privacyand Bias-aware LLMs (PBa-LLMs). Note that the proposed PBa-LLMs have been evaluated in a particular setup (resume scoring), but are generally applicable to any other LLM-based AI application.",
      "authors": [
        "Gonzalo Mancera",
        "Aythami Morales",
        "Julian Fierrez",
        "Ruben Tolosana",
        "Alejandro Penna",
        "Miguel Lopez-Duran",
        "Francisco Jurado",
        "and Alvaro Ortigosa"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T14:42:49+00:00",
          "link": "https://arxiv.org/abs/2507.02966v1",
          "size": "741kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T08:02:08+00:00",
          "link": "https://arxiv.org/abs/2507.02966v2",
          "size": "741kb",
          "version": "v2"
        }
      ],
      "title": "PBa-LLM: Privacy- and Bias-aware NLP using Named-Entity Recognition (NER)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02966",
        "HTML": "https://arxiv.org/html/2507.02966v2",
        "PDF": "https://arxiv.org/pdf/2507.02966"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses privacy-preserving techniques using Named-Entity Recognition for large language models and achieves bias reduction, but does not focus primarily on novel data processing methodologies for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06282",
      "abstract": "Prior work on jailbreak detection has established the importance of adversarial robustness for LLMs but has largely focused on the model ability to resist adversarial inputs and to output safe content, rather than the effectiveness of external supervision systems. The only public and independent benchmark of these guardrails to date evaluates a narrow set of supervisors on limited scenarios. Consequently, no comprehensive public benchmark yet verifies how well supervision systems from the market perform under realistic, diverse attacks. To address this, we introduce BELLS, a Benchmark for the Evaluation of LLM Supervision Systems. The framework is two dimensional: harm severity (benign, borderline, harmful) and adversarial sophistication (direct vs. jailbreak) and provides a rich dataset covering 3 jailbreak families and 11 harm categories. Our evaluations reveal drastic limitations of specialized supervision systems. While they recognize some known jailbreak patterns, their semantic understanding and generalization capabilities are very limited, sometimes with detection rates close to zero when asking a harmful question directly or with a new jailbreak technique such as base64 encoding. Simply asking generalist LLMs if the user question is \"harmful or not\" largely outperforms these supervisors from the market according to our BELLS score. But frontier LLMs still suffer from metacognitive incoherence, often responding to queries they correctly identify as harmful (up to 30 percent for Claude 3.7 and greater than 50 percent for Mistral Large). These results suggest that simple scaffolding could significantly improve misuse detection robustness, but more research is needed to assess the tradeoffs of such techniques. Our results support the \"bitter lesson\" of misuse detection: general capabilities of LLMs are necessary to detect a diverse array of misuses and jailbreaks.",
      "authors": [
        "Hadrien Mariaccia",
        "Charbel-Rapha\\\"el Segerie",
        "Diego Dorn"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T15:21:17+00:00",
          "link": "https://arxiv.org/abs/2507.06282v1",
          "size": "732kb",
          "version": "v1"
        }
      ],
      "title": "The bitter lesson of misuse detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06282",
        "HTML": "https://arxiv.org/html/2507.06282v1",
        "PDF": "https://arxiv.org/pdf/2507.06282"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "While the paper discusses benchmarks for misuse detection in LLMs, it does not focus on LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06351",
      "abstract": "Commercial Motor Vehicle (CMV) safety is crucial in traffic management and public safety. CMVs account for numerous traffic incidents, so monitoring CMV safety and safety inspections is essential for ensuring safe and efficient highway movement. This paper presents the development and real-world application of CMV dashboards designed under the guidance of CMV safety enforcement professionals from the Maryland State Police (MSP), the Maryland Department of Transportation - State Highway Administration (MDOT - SHA), and the Federal Motor Carrier Safety Administration (FMCSA) to enable intuitive and efficient analysis of CMV safety performance measures. First, three CMV safety dashboards enable CMV safety professionals to identify sites with a history of safety performance issues. A supplemental dashboard automates the analysis of CMV enforcement initiatives using the same performance measures. These performance measures are based on CMV probe vehicle speeds, inspection/citation data from Truck Weigh and Inspection Stations (TWIS), patrolling enforcement, and Virtual Weigh Stations (VWS). The authors collaborated with MSP to identify a portion of I-81 in Maryland, susceptible to improvement from targeted CMV enforcement. The supplemental enforcement assessment dashboard was employed to evaluate the impact of enforcement, including the post-enforcement halo effect. The results of the post-enforcement evaluation were mixed, indicating a need for more fine-grained citation data.",
      "authors": [
        "Dhairya Parekh",
        "Mark L. Franz Ph.D",
        "Sara Zahedian Ph.D",
        "Narjes Shayesteh"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T19:24:43+00:00",
          "link": "https://arxiv.org/abs/2507.06351v1",
          "size": "2394kb",
          "version": "v1"
        }
      ],
      "title": "Development and Real-World Application of Commercial Motor Vehicle Safety Enforcement Dashboards",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06351",
        "PDF": "https://arxiv.org/pdf/2507.06351"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is oriented towards the development of dashboards for safety enforcement in the transportation sector and does not mention any aspects related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06605",
      "abstract": "Classical sampling-based motion planners like the RRTs suffer from inefficiencies, particularly in cluttered or high-dimensional spaces, due to their reliance on undirected, random sampling. This paper introduces the Episodic RRT, a novel hybrid planning framework that replaces the primitive of a random point with a learned, multi-step \"exploratory episode\" generated by a Deep Reinforcement Learning agent. By making the DRL agent the engine of exploration, ERRT transforms the search process from a diffuse, volumetric expansion into a directed, branch-like growth. This paradigm shift yields key advantages: it counters the curse of dimensionality with focused exploration, minimizes expensive collision checks by proactively proposing locally valid paths, and improves connectivity by generating inherently connected path segments. We demonstrate through extensive empirical evaluation across 2D, 3D, and 6D environments that ERRT and its variants consistently and significantly outperform their classical counterparts. In a challenging 6D robotic arm scenario, ERRT achieves a 98% success rate compared to 19% for RRT, is up to 107x faster, reduces collision checks by over 99.6%, and finds initial paths that are nearly 50% shorter. Furthermore, its asymptotically optimal variant, ERRT*, demonstrates vastly superior anytime performance, refining solutions to near-optimality up to 29x faster than standard RRT* in 3D environments. Code: https://xinyuwuu.github.io/Episodic_RRT/.",
      "authors": [
        "Xinyu Wu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T07:24:18+00:00",
          "link": "https://arxiv.org/abs/2507.06605v1",
          "size": "2649kb",
          "version": "v1"
        }
      ],
      "title": "Growing Trees with an Agent: Accelerating RRTs with Learned, Multi-Step Episodic Exploration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06605",
        "PDF": "https://arxiv.org/pdf/2507.06605"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a novel motion planning framework with reinforcement learning, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07026",
      "abstract": "The deployment of biased machine learning (ML) models has resulted in adverse effects in crucial sectors such as criminal justice and healthcare. To address these challenges, a diverse range of machine learning fairness interventions have been developed, aiming to mitigate bias and promote the creation of more equitable models. Despite the growing availability of these interventions, their adoption in real-world applications remains limited, with many practitioners unaware of their existence. To address this gap, we systematically identified and compiled a dataset of 62 open source fairness interventions and identified active ones. We conducted an in-depth analysis of their specifications and features to uncover considerations that may drive practitioner preference and to identify the software interventions actively maintained in the open source ecosystem. Our findings indicate that 32% of these interventions have been actively maintained within the past year, and 50% of them offer both bias detection and mitigation capabilities, mostly during inprocessing.",
      "authors": [
        "Sadia Afrin Mim",
        "Fatema Tuz Zohra",
        "Justin Smith and Brittany Johnson"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T16:57:59+00:00",
          "link": "https://arxiv.org/abs/2507.07026v1",
          "size": "269kb",
          "version": "v1"
        }
      ],
      "title": "Exploring Fairness Interventions in Open Source Projects",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07026",
        "HTML": "https://arxiv.org/html/2507.07026v1",
        "PDF": "https://arxiv.org/pdf/2507.07026"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about fairness interventions in open source projects, including bias detection and mitigation, without specific focus on LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2408.12460",
      "abstract": "The human brain has an inherent ability to fill in gaps to perceive figures as complete wholes, even when parts are missing or fragmented. This phenomenon is known as Closure in psychology, one of the Gestalt laws of perceptual organization, explaining how the human brain interprets visual stimuli. Given the importance of Closure for human object recognition, we investigate whether neural networks rely on a similar mechanism. Exploring this crucial human visual skill in neural networks has the potential to highlight their comparability to humans. Recent studies have examined the Closure effect in neural networks. However, they typically focus on a limited selection of Convolutional Neural Networks (CNNs) and have not reached a consensus on their capability to perform Closure. To address these gaps, we present a systematic framework for investigating the Closure principle in neural networks. We introduce well-curated datasets designed to test for Closure effects, including both modal and amodal completion. We then conduct experiments on various CNNs employing different measurements. Our comprehensive analysis reveals that VGG16 and DenseNet-121 exhibit the Closure effect, while other CNNs show variable results. We interpret these findings by blending insights from psychology and neural network research, offering a unique perspective that enhances transparency in understanding neural networks. Our code and dataset will be made available on GitHub.",
      "authors": [
        "Yuyan Zhang",
        "Derya Soydaner",
        "Lisa Ko{\\ss}mann",
        "Fatemeh Behrad",
        "Johan Wagemans"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-22T14:59:37+00:00",
          "link": "https://arxiv.org/abs/2408.12460v1",
          "size": "673kb",
          "version": "v1"
        }
      ],
      "title": "Finding Closure: A Closer Look at the Gestalt Law of Closure in Convolutional Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.12460",
        "HTML": "https://arxiv.org/html/2408.12460",
        "PDF": "https://arxiv.org/pdf/2408.12460"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates the closure principle in neural networks using custom datasets but does not contribute to LLM training data processing or creation."
      },
      "tasks": [
        "Object Recognition"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.08423",
      "abstract": "Facial recognition systems have achieved remarkable success by leveraging deep neural networks, advanced loss functions, and large-scale datasets. However, their performance often deteriorates in real-world scenarios involving low-quality facial images. Such degradations, common in surveillance footage or standoff imaging include low resolution, motion blur, and various distortions, resulting in a substantial domain gap from the high-quality data typically used during training. While existing approaches attempt to address robustness by modifying network architectures or modeling global spatial transformations, they frequently overlook local, non-rigid deformations that are inherently present in real-world settings. In this work, we introduce DArFace, a Deformation-Aware robust Face recognition framework that enhances robustness to such degradations without requiring paired high- and low-quality training samples. Our method adversarially integrates both global transformations (e.g., rotation, translation) and local elastic deformations during training to simulate realistic low-quality conditions. Moreover, we introduce a contrastive objective to enforce identity consistency across different deformed views. Extensive evaluations on low-quality benchmarks including TinyFace, IJB-B, and IJB-C demonstrate that DArFace surpasses state-of-the-art methods, with significant gains attributed to the inclusion of local deformation modeling.The code is available at the following https://github.com/sadafgulshad1/DArFace",
      "authors": [
        "Sadaf Gulshad and Abdullah Aldahlawi Thakaa"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-13T10:35:57+00:00",
          "link": "https://arxiv.org/abs/2505.08423v1",
          "size": "1124kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T08:25:11+00:00",
          "link": "https://arxiv.org/abs/2505.08423v2",
          "size": "1124kb",
          "version": "v2"
        }
      ],
      "title": "DArFace: Deformation Aware Robustness for Low Quality Face Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.08423",
        "HTML": "https://arxiv.org/html/2505.08423v2",
        "PDF": "https://arxiv.org/pdf/2505.08423"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on facial recognition robustness to low-quality images through deformation-aware methods, not on LLM training data processing."
      },
      "tasks": [
        "Face Recognition",
        "Robust Face Recognition"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.06444",
      "abstract": "Existing safety assurance research has primarily focused on training-phase alignment to instill safe behaviors into LLMs. However, recent studies have exposed these methods' susceptibility to diverse jailbreak attacks. Concurrently, inference scaling has significantly advanced LLM reasoning capabilities but remains unexplored in the context of safety assurance. Addressing this gap, our work pioneers inference scaling for robust and effective LLM safety against emerging threats. We reveal that conventional inference scaling techniques, despite their success in reasoning tasks, perform poorly in safety contexts, even falling short of basic approaches like Best-of-N Sampling. We attribute this inefficiency to a newly identified challenge, the exploration--efficiency dilemma, arising from the high computational overhead associated with frequent process reward model (PRM) evaluations. To overcome this dilemma, we propose SAFFRON, a novel inference scaling paradigm tailored explicitly for safety assurance. Central to our approach is the introduction of a multifurcation reward model (MRM) that significantly reduces the required number of reward model evaluations. To operationalize this paradigm, we further propose: (i) a partial supervision training objective for MRM, (ii) a conservative exploration constraint to prevent out-of-distribution explorations, and (iii) a Trie-based key--value caching strategy that facilitates cache sharing across sequences during tree search. Extensive experiments validate the effectiveness of our method. Additionally, we publicly release our trained multifurcation reward model (Saffron-1) and the accompanying token-level safety reward dataset (Safety4M) to accelerate future research in LLM safety. Our code, model, and data are publicly available at https://github.com/q-rz/saffron , and our project homepage is at https://q-rz.github.io/p/saffron .",
      "authors": [
        "Ruizhong Qiu",
        "Gaotang Li",
        "Tianxin Wei",
        "Jingrui He",
        "Hanghang Tong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-06T18:05:45+00:00",
          "link": "https://arxiv.org/abs/2506.06444v1",
          "size": "493kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T07:47:59+00:00",
          "link": "https://arxiv.org/abs/2506.06444v2",
          "size": "498kb",
          "version": "v2"
        }
      ],
      "title": "Saffron-1: Safety Inference Scaling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.06444",
        "HTML": "https://arxiv.org/html/2506.06444v2",
        "PDF": "https://arxiv.org/pdf/2506.06444"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This work involves pioneering inference scaling for LLM safety, introducing a new reward model, and releasing a token-level safety reward dataset 'Safety4M'. It substantially contributes to data processing for LLM safety and dataset creation, thus qualifying as core."
      },
      "tasks": [
        "Attribute"
      ],
      "repo_urls": [
        "https://github.com/q-rz/saffron"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06329",
      "abstract": "While AI presents significant potential for enhancing music mixing and mastering workflows, current research predominantly emphasizes end-to-end automation or generation, often overlooking the collaborative and instructional dimensions vital for co-creative processes. This gap leaves artists, particularly amateurs seeking to develop expertise, underserved. To bridge this, we introduce MixAssist, a novel audio-language dataset capturing the situated, multi-turn dialogue between expert and amateur music producers during collaborative mixing sessions. Comprising 431 audio-grounded conversational turns derived from 7 in-depth sessions involving 12 producers, MixAssist provides a unique resource for training and evaluating audio-language models that can comprehend and respond to the complexities of real-world music production dialogues. Our evaluations, including automated LLM-as-a-judge assessments and human expert comparisons, demonstrate that fine-tuning models such as Qwen-Audio on MixAssist can yield promising results, with Qwen significantly outperforming other tested models in generating helpful, contextually relevant mixing advice. By focusing on co-creative instruction grounded in audio context, MixAssist enables the development of intelligent AI assistants designed to support and augment the creative process in music mixing.",
      "authors": [
        "Michael Clemens",
        "Ana Marasovi\\'c"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T18:33:26+00:00",
          "link": "https://arxiv.org/abs/2507.06329v1",
          "size": "588kb",
          "version": "v1"
        }
      ],
      "title": "MixAssist: An Audio-Language Dataset for Co-Creative AI Assistance in Music Mixing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06329",
        "HTML": "https://arxiv.org/html/2507.06329v1",
        "PDF": "https://arxiv.org/pdf/2507.06329"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper presents MixAssist, a new dataset creation focused on audio-language interactions for music mixing, describing detailed data processing steps aimed at training co-creative AI models. This is directly related to LLM training data creation and processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06432",
      "abstract": "Artificial Intelligence has revolutionised critical care for common conditions. Yet, rare conditions in the intensive care unit (ICU), including recognised rare diseases and low-prevalence conditions in the ICU, remain underserved due to data scarcity and intra-condition heterogeneity. To bridge such gaps, we developed KnowRare, a domain adaptation-based deep learning framework for predicting clinical outcomes for rare conditions in the ICU. KnowRare mitigates data scarcity by initially learning condition-agnostic representations from diverse electronic health records through self-supervised pre-training. It addresses intra-condition heterogeneity by selectively adapting knowledge from clinically similar conditions with a developed condition knowledge graph. Evaluated on two ICU datasets across five clinical prediction tasks (90-day mortality, 30-day readmission, ICU mortality, remaining length of stay, and phenotyping), KnowRare consistently outperformed existing state-of-the-art models. Additionally, KnowRare demonstrated superior predictive performance compared to established ICU scoring systems, including APACHE IV and IV-a. Case studies further demonstrated KnowRare's flexibility in adapting its parameters to accommodate dataset-specific and task-specific characteristics, its generalisation to common conditions under limited data scenarios, and its rationality in selecting source conditions. These findings highlight KnowRare's potential as a robust and practical solution for supporting clinical decision-making and improving care for rare conditions in the ICU.",
      "authors": [
        "Mingcheng Zhu",
        "Yu Liu",
        "Zhiyao Luo",
        "Tingting Zhu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T22:27:19+00:00",
          "link": "https://arxiv.org/abs/2507.06432v1",
          "size": "974kb",
          "version": "v1"
        }
      ],
      "title": "Bridging Data Gaps of Rare Conditions in ICU: A Multi-Disease Adaptation Approach for Clinical Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06432",
        "HTML": "https://arxiv.org/html/2507.06432v1",
        "PDF": "https://arxiv.org/pdf/2507.06432"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores AI for predicting clinical outcomes for rare ICU conditions using domain adaptation, not LLM training data processing or datasets. Its focus is on leveraging electronic health records for clinical predictions."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06798",
      "abstract": "Dialectical systems are a mathematical formalism for modeling an agent updating a knowledge base seeking consistency. Introduced in the 1970s by Roberto Magari, they were originally conceived to capture how a working mathematician or a research community refines beliefs in the pursuit of truth. Dialectical systems also serve as natural models for the belief change of an automated agent, offering a unifying, computable framework for dynamic belief management.\n  The literature distinguishes three main models of dialectical systems: (d-)dialectical systems based on revising beliefs when they are seen to be inconsistent, p-dialectical systems based on revising beliefs based on finding a counterexample, and q-dialectical systems which can do both. We answer an open problem in the literature by proving that q-dialectical systems are strictly more powerful than p-dialectical systems, which are themselves known to be strictly stronger than (d-)dialectical systems. This result highlights the complementary roles of counterexample and contradiction in automated belief revision, and thus also in the reasoning processes of mathematicians and research communities.",
      "authors": [
        "Uri Andrews and Luca San Mauro"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Logic (math.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T12:35:20+00:00",
          "link": "https://arxiv.org/abs/2507.06798v1",
          "size": "41kb",
          "version": "v1"
        }
      ],
      "title": "Comparing Dialectical Systems: Contradiction and Counterexample in Belief Change (Extended Version)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06798",
        "HTML": "https://arxiv.org/html/2507.06798v1",
        "PDF": "https://arxiv.org/pdf/2507.06798"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses dialectical systems for belief revision without mentioning any aspect of LLM training data collection, processing, or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07068",
      "abstract": "As the most important human-machine interfacing tool, an insignificant amount of work has been carried out on Bangla Speech Recognition compared to the English language. Motivated by this, in this work, the performance of speaker-independent isolated speech recognition systems has been implemented and analyzed using a dataset that is created containing both isolated Bangla and English spoken words. An approach using the Mel Frequency Cepstral Coefficient (MFCC) and Deep Feed-Forward Fully Connected Neural Network (DFFNN) of 7 layers as a classifier is proposed in this work to recognize isolated spoken words. This work shows 93.42% recognition accuracy which is better compared to most of the works done previously on Bangla speech recognition considering the number of classes and dataset size.",
      "authors": [
        "Dipayan Bhadra",
        "Mehrab Hosain",
        "Fatema Alam"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T06:35:56+00:00",
          "link": "https://arxiv.org/abs/2507.07068v1",
          "size": "771kb",
          "version": "v1"
        }
      ],
      "title": "Deep Feed-Forward Neural Network for Bangla Isolated Speech Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07068",
        "PDF": "https://arxiv.org/pdf/2507.07068"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses Bangla isolated speech recognition and does not discuss LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2302.04018",
      "abstract": "Event prediction is the ability of anticipating future events, i.e., future real-world occurrences, and aims to support the user in deciding on actions that change future events towards a desired state. An event prediction method learns the relation between features of past events and future events. It is applied to newly observed events to predict corresponding future events that are evaluated with respect to the user's desired future state. If the predicted future events do not comply with this state, actions are taken towards achieving desirable future states. Evidently, event prediction is valuable in many application domains such as business and natural disasters. The diversity of application domains results in a diverse range of methods that are scattered across various research areas which, in turn, use different terminology for event prediction methods. Consequently, sharing methods and knowledge for developing future event prediction methods is restricted. To facilitate knowledge sharing on account of a comprehensive integration and assessment of event prediction methods, we take a systems perspective to integrate event prediction methods into a single system, elicit requirements, and assess existing work with respect to the requirements. Based on the assessment, we identify open challenges and discuss future research directions.",
      "authors": [
        "Janik-Vasily Benzin",
        "Stefanie Rinderle-Ma"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2023-02-08T12:21:02+00:00",
          "link": "https://arxiv.org/abs/2302.04018v1",
          "size": "394kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T14:22:25+00:00",
          "link": "https://arxiv.org/abs/2302.04018v2",
          "size": "796kb",
          "version": "v2"
        }
      ],
      "title": "A Survey on Event Prediction Methods from a Systems Perspective: Bringing Together Disparate Research Areas",
      "links": {
        "Abstract": "https://arxiv.org/abs/2302.04018",
        "HTML": "https://arxiv.org/html/2302.04018v2",
        "PDF": "https://arxiv.org/pdf/2302.04018"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses event prediction methods across various research areas but does not focus on processing or creating LLM training data."
      },
      "tasks": [
        "Prediction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.15843",
      "abstract": "We show that neural networks can be optimized to represent minimum energy paths as continuous functions, offering a flexible alternative to discrete path-search methods such as Nudged Elastic Band (NEB). Our approach parameterizes reaction paths with a network trained on a loss function that discards tangential energy gradients and enables instant estimation of the transition state. We first validate the method on two-dimensional potentials and then demonstrate its advantages over NEB on challenging atomistic systems where (i) poor initial guesses yield unphysical paths, (ii) multiple competing paths exist, or (iii) the reaction follows a complex multi-step mechanism. Results highlight the versatility of the method: for instance, a simple adjustment to the sampling strategy during optimization can help escape local-minimum solutions. Finally, in a low-dimensional setting, we demonstrate that a single neural network can learn from existing paths and generalize to unseen systems, showing promise for a universal reaction path representation.",
      "authors": [
        "Kalyan Ramakrishnan",
        "Lars L. Schaaf",
        "Chen Lin",
        "Guangrun Wang",
        "Philip Torr"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Chemical Physics (physics.chem-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-20T19:44:21+00:00",
          "link": "https://arxiv.org/abs/2502.15843v1",
          "size": "26846kb",
          "version": "v1"
        },
        {
          "date": "2025-06-10T16:12:07+00:00",
          "link": "https://arxiv.org/abs/2502.15843v2",
          "size": "21058kb",
          "version": "v2"
        },
        {
          "date": "2025-07-08T18:11:58+00:00",
          "link": "https://arxiv.org/abs/2502.15843v3",
          "size": "21062kb",
          "version": "v3"
        }
      ],
      "title": "Implicit Neural Representations for Chemical Reaction Paths",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.15843",
        "HTML": "https://arxiv.org/html/2502.15843v3",
        "PDF": "https://arxiv.org/pdf/2502.15843"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores neural networks for representing chemical reaction paths and does not address LLM training data processing or dataset creation."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.06038",
      "abstract": "Building on our previous work introducing Fredholm Neural Networks (Fredholm NNs/ FNNs) for solving integral equations, we extend the framework to tackle forward and inverse problems for linear and semi-linear elliptic partial differential equations. The proposed scheme consists of a deep neural network (DNN) which is designed to represent the iterative process of fixed-point iterations for the solution of elliptic PDEs using the boundary integral method within the framework of potential theory. The number of layers, weights, biases and hyperparameters are computed in an explainable manner based on the iterative scheme, and we therefore refer to this as the Potential Fredholm Neural Network (PFNN). We show that this approach ensures both accuracy and explainability, achieving small errors in the interior of the domain, and near machine-precision on the boundary. We provide a constructive proof for the consistency of the scheme and provide explicit error bounds for both the interior and boundary of the domain, reflected in the layers of the PFNN. These error bounds depend on the approximation of the boundary function and the integral discretization scheme, both of which directly correspond to components of the Fredholm NN architecture. In this way, we provide an explainable scheme that explicitly respects the boundary conditions. We assess the performance of the proposed scheme for the solution of both the forward and inverse problem for linear and semi-linear elliptic PDEs in two dimensions.",
      "authors": [
        "Kyriakos Georgiou",
        "Constantinos Siettos and Athanasios N. Yannacopoulos"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Machine Learning (cs.LG)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T14:40:44+00:00",
          "link": "https://arxiv.org/abs/2507.06038v1",
          "size": "2978kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T13:12:54+00:00",
          "link": "https://arxiv.org/abs/2507.06038v2",
          "size": "2979kb",
          "version": "v2"
        }
      ],
      "title": "Fredholm Neural Networks for forward and inverse problems in elliptic PDEs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06038",
        "HTML": "https://arxiv.org/html/2507.06038v2",
        "PDF": "https://arxiv.org/pdf/2507.06038"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on solving PDEs using Fredholm Neural Networks, not on any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06338",
      "abstract": "This paper presents the first parallel batch-dynamic algorithms for computing spanners and sparsifiers. Our algorithms process any batch of edge insertions and deletions in an $n$-node undirected graph, in $\\text{poly}(\\log n)$ depth and using amortized work near-linear in the batch size. Our concrete results are as follows:\n  - Our base algorithm maintains a spanner with $(2k-1)$ stretch and $\\tilde{O}(n^{1+1/k})$ edges, for any $k\\geq 1$.\n  - Our first extension maintains a sparse spanner with only $O(n)$ edges, and $\\tilde{O}(\\log n)$ stretch.\n  - Our second extension maintains a $t$-bundle of spanners -- i.e., $t$ spanners, each of which is the spanner of the graph remaining after removing the previous ones -- and allows us to maintain cut/spectral sparsifiers with $\\tilde{O}(n)$ edges.",
      "authors": [
        "Mohsen Ghaffari",
        "Jaehyun Koo"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T18:58:08+00:00",
          "link": "https://arxiv.org/abs/2507.06338v1",
          "size": "70kb",
          "version": "v1"
        }
      ],
      "title": "Parallel Batch-Dynamic Algorithms for Spanners, and Extensions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06338",
        "HTML": "https://arxiv.org/html/2507.06338v1",
        "PDF": "https://arxiv.org/pdf/2507.06338"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on parallel batch-dynamic algorithms for computing spanners and sparsifiers, which is unrelated to LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2402.04602",
      "abstract": "This paper addresses the challenge of integrating sequentially arriving data within the quantile regression framework, where the number of features is allowed to grow with the number of observations, the horizon is unknown, and memory is limited. We employ stochastic sub-gradient descent to minimize the empirical check loss and study its statistical properties and regret performance. In our analysis, we unveil the delicate interplay between updating iterates based on individual observations versus batches of observations, revealing distinct regularity properties in each scenario. Our method ensures long-term optimal estimation irrespective of the chosen update strategy. Importantly, our contributions go beyond prior works by achieving exponential-type concentration inequalities and attaining optimal regret and error rates that exhibit only \\textsf{ short-term} sensitivity to initial errors. A key insight from our study is the delicate statistical analyses and the revelation that appropriate stepsize schemes significantly mitigate the impact of initial errors on subsequent errors and regrets. This underscores the robustness of stochastic sub-gradient descent in handling initial uncertainties, emphasizing its efficacy in scenarios where the sequential arrival of data introduces uncertainties regarding both the horizon and the total number of observations. Additionally, when the initial error rate is well-controlled, there is a trade-off between short-term error rate and long-term optimality. Due to the lack of delicate statistical analysis for squared loss, we also briefly discuss its properties and proper schemes. Extensive simulations support our theoretical findings.",
      "authors": [
        "Yinan Shen",
        "Dong Xia and Wen-Xin Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Statistics Theory (math.ST)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)",
        "Methodology (stat.ME)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-07T05:57:42+00:00",
          "link": "https://arxiv.org/abs/2402.04602v1",
          "size": "1523kb",
          "version": "v1"
        },
        {
          "date": "2024-02-18T20:14:24+00:00",
          "link": "https://arxiv.org/abs/2402.04602v2",
          "size": "1538kb",
          "version": "v2"
        },
        {
          "date": "2025-07-08T18:23:30+00:00",
          "link": "https://arxiv.org/abs/2402.04602v3",
          "size": "2451kb",
          "version": "v3"
        }
      ],
      "title": "Online Quantile Regression",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.04602",
        "HTML": "https://arxiv.org/html/2402.04602v3",
        "PDF": "https://arxiv.org/pdf/2402.04602"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus here is on quantile regression with sequentially arriving data, using stochastic sub-gradient descent; it does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.08003",
      "abstract": "Attributing outputs from Large Language Models (LLMs) in adversarial settings-such as cyberattacks and disinformation campaigns-presents significant challenges that are likely to grow in importance. We approach this attribution problem from both a theoretical and an empirical perspective, drawing on formal language theory (identification in the limit) and data-driven analysis of the expanding LLM ecosystem. By modeling an LLM's set of possible outputs as a formal language, we analyze whether finite samples of text can uniquely pinpoint the originating model. Our results show that, under mild assumptions of overlapping capabilities among models, certain classes of LLMs are fundamentally non-identifiable from their outputs alone. We delineate four regimes of theoretical identifiability: (1) an infinite class of deterministic (discrete) LLM languages is not identifiable (Gold's classical result from 1967); (2) an infinite class of probabilistic LLMs is also not identifiable (by extension of the deterministic case); (3) a finite class of deterministic LLMs is identifiable (consistent with Angluin's tell-tale criterion); and (4) even a finite class of probabilistic LLMs can be non-identifiable (we provide a new counterexample establishing this negative result). Complementing these theoretical insights, we quantify the explosion in the number of plausible model origins (hypothesis space) for a given output in recent years. Even under conservative assumptions-each open-source model fine-tuned on at most one new dataset-the count of distinct candidate models doubles approximately every 0.5 years, and allowing multi-dataset fine-tuning combinations yields doubling times as short as 0.28 years. This combinatorial growth, alongside the extraordinary computational cost of brute-force likelihood attribution across all models and potential users, renders exhaustive attribution infeasible in practice.",
      "authors": [
        "Manuel Cebrian",
        "Andres Abeliuk",
        "Jan Arne Telle"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Computers and Society (cs.CY)",
        "Formal Languages and Automata Theory (cs.FL)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-12T18:28:57+00:00",
          "link": "https://arxiv.org/abs/2411.08003v1",
          "size": "249kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T02:35:36+00:00",
          "link": "https://arxiv.org/abs/2411.08003v2",
          "size": "751kb",
          "version": "v2"
        }
      ],
      "title": "Can adversarial attacks by large language models be attributed?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.08003",
        "HTML": "https://arxiv.org/html/2411.08003v2",
        "PDF": "https://arxiv.org/pdf/2411.08003"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the attribution of outputs from Large Language Models in adversarial settings. It does not discuss processing or creation of training data for LLMs."
      },
      "tasks": [
        "Attribute",
        "Language Identification"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.09073",
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities across various NLP tasks but struggle with code-mixed (or code-switched) language understanding. For example, prior work benchmarking the performance of multilingual LLMs on code-mixed translation tasks has demonstrated that current state-of-the-art multilingual LLMs are ineffective in dealing with code-mixed languages. However, the question of how to improve the capability of multilingual LLMs to handle code-mixed language has not received any attention to date. In this paper, we tackle this research gap by proposing CHAI, a novel general-purpose framework for improving the ability of multilingual LLMs to handle code-mixed languages. CHAI relies on three novel contributions made in this paper. First, we explore the ability of LLMs to provide accurate annotations for code-mixed translation tasks. Second, we leverage this ability of LLMs as annotators to generate preference data for code-mixed translation tasks at scale, which are then used within a reinforcement learning from AI feedback (RLAIF) procedure to improve LLMs' capability on code-mixed tasks. Third, we conduct a rigorous experimental evaluation across various real-world datasets and settings. Our analysis shows that CHAI-powered LLMs outperform state-of-the-art open-source LLMs by 25.66% (in terms of win rate adjudicated by human annotators) in code-mixed translation tasks. This work represents a first step towards developing more inclusive code-mixed LLMs.",
      "authors": [
        "Wenbo Zhang",
        "Aditya Majumdar",
        "Amulya Yadav"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-13T22:56:00+00:00",
          "link": "https://arxiv.org/abs/2411.09073v1",
          "size": "710kb",
          "version": "v1"
        },
        {
          "date": "2025-02-26T20:11:35+00:00",
          "link": "https://arxiv.org/abs/2411.09073v2",
          "size": "625kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T05:40:56+00:00",
          "link": "https://arxiv.org/abs/2411.09073v3",
          "size": "1061kb",
          "version": "v3"
        }
      ],
      "title": "CHAI for LLMs: Improving Code-Mixed Translation in Large Language Models through Reinforcement Learning with AI Feedback",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.09073",
        "HTML": "https://arxiv.org/html/2411.09073v3",
        "PDF": "https://arxiv.org/pdf/2411.09073"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper proposes CHAI, a framework for improving LLMs' code-mixed language handling, involving generating preference data and reinforcement learning, which relates to data generation and processing to enhance LLM performance."
      },
      "tasks": [
        "Machine Translation",
        "reinforcement-learning",
        "Reinforcement Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.05814",
      "abstract": "As critical transportation infrastructure, bridges face escalating challenges from aging and deterioration, while traditional manual inspection methods suffer from low efficiency. Although 3D point cloud technology provides a new data-driven paradigm, its application potential is often constrained by the incompleteness of real-world data, which results from missing labels and scanning occlusions. To overcome the bottleneck of insufficient generalization in existing synthetic data methods, this paper proposes a systematic framework for generating 3D bridge data.\n  This framework can automatically generate complete point clouds featuring component-level instance annotations, high-fidelity color, and precise normal vectors. It can be further extended to simulate the creation of diverse and physically realistic incomplete point clouds, designed to support the training of segmentation and completion networks, respectively. Experiments demonstrate that a PointNet++ model trained with our synthetic data achieves a mean Intersection over Union (mIoU) of 84.2% in real-world bridge semantic segmentation. Concurrently, a fine-tuned KT-Net exhibits superior performance on the component completion task.\n  This research offers an innovative methodology and a foundational dataset for the 3D visual analysis of bridge structures, holding significant implications for advancing the automated management and maintenance of infrastructure.",
      "authors": [
        "Wang Wang",
        "Mingyu Shi",
        "Jun Jiang",
        "Wenqian Ma",
        "Chong Liu",
        "Yasutaka Narazaki",
        "Xuguang Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T09:34:55+00:00",
          "link": "https://arxiv.org/abs/2507.05814v1",
          "size": "2508kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T03:13:38+00:00",
          "link": "https://arxiv.org/abs/2507.05814v2",
          "size": "2508kb",
          "version": "v2"
        }
      ],
      "title": "Empowering Bridge Digital Twins by Bridging the Data Gap with a Unified Synthesis Framework",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05814",
        "HTML": "https://arxiv.org/html/2507.05814v2",
        "PDF": "https://arxiv.org/pdf/2507.05814"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a framework for generating 3D bridge data, which is used for infrastructure management and maintenance, not for LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06687",
      "abstract": "This paper presents StixelNExT++, a novel approach to scene representation for monocular perception systems. Building on the established Stixel representation, our method infers 3D Stixels and enhances object segmentation by clustering smaller 3D Stixel units. The approach achieves high compression of scene information while remaining adaptable to point cloud and bird's-eye-view representations. Our lightweight neural network, trained on automatically generated LiDAR-based ground truth, achieves real-time performance with computation times as low as 10 ms per frame. Experimental results on the Waymo dataset demonstrate competitive performance within a 30-meter range, highlighting the potential of StixelNExT++ for collective perception in autonomous systems.",
      "authors": [
        "Marcel Vosshans",
        "Omar Ait-Aider",
        "Youcef Mezouar and Markus Enzweiler"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T09:30:07+00:00",
          "link": "https://arxiv.org/abs/2507.06687v1",
          "size": "8849kb",
          "version": "v1"
        }
      ],
      "title": "StixelNExT++: Lightweight Monocular Scene Segmentation and Representation for Collective Perception",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06687",
        "HTML": "https://arxiv.org/html/2507.06687v1",
        "PDF": "https://arxiv.org/pdf/2507.06687"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on scene segmentation and representation for perception systems with no mention of processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06944",
      "abstract": "This paper seeks an efficient algorithm for stochastic precoding to maximize the long-term average weighted sum rates throughout a multiple-input multiple-output (MIMO) network. Unlike many existing works that assume a particular probability distribution model for fading channels (which is typically Gaussian), our approach merely relies on the first and second moments of fading channels. For the stochastic precoding problem, a naive idea is to directly apply the fractional programming (FP) method to the data rate inside the expectation; it does not work well because the auxiliary variables introduced by FP are then difficult to decide. To address the above issue, we propose using a lower bound to approximate the expectation of data rate. This lower bound stems from a nontrivial use of the matrix FP, and outperforms the existing lower bounds in that it accounts for generalized fading channels whose first and second moments are known. The resulting approximate problem can be efficiently solved in closed form in an iterative fashion. Furthermore, for large-scale MIMO, we improve the efficiency of the proposed algorithm by eliminating the large matrix inverse. Simulations show that the proposed stochastic precoding method outperforms the benchmark methods in both Gaussian and non-Gaussian fading channel cases.",
      "authors": [
        "Wenyu Wang and Kaiming Shen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T15:27:33+00:00",
          "link": "https://arxiv.org/abs/2507.06944v1",
          "size": "616kb",
          "version": "v1"
        }
      ],
      "title": "Fractional Programming for Stochastic Precoding over Generalized Fading Channels",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06944",
        "HTML": "https://arxiv.org/html/2507.06944v1",
        "PDF": "https://arxiv.org/pdf/2507.06944"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about stochastic precoding over fading channels in MIMO networks and does not mention any aspects of LLM training data processing or relevant data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07060",
      "abstract": "Retrosynthesis, the identification of precursor molecules for a target compound, is pivotal for synthesizing complex molecules, but faces challenges in discovering novel pathways beyond predefined templates. Recent large language model (LLM) approaches to retrosynthesis have shown promise but effectively harnessing LLM reasoning capabilities for effective multi-step planning remains an open question. To address this challenge, we introduce DeepRetro, an open-source, iterative, hybrid LLM-based retrosynthetic framework. Our approach integrates the strengths of conventional template-based/Monte Carlo tree search tools with the generative power of LLMs in a step-wise, feedback-driven loop. Initially, synthesis planning is attempted with a template-based engine. If this fails, the LLM subsequently proposes single-step retrosynthetic disconnections. Crucially, these suggestions undergo rigorous validity, stability, and hallucination checks before the resulting precursors are recursively fed back into the pipeline for further evaluation. This iterative refinement allows for dynamic pathway exploration and correction. We demonstrate the potential of this pipeline through benchmark evaluations and case studies, showcasing its ability to identify viable and potentially novel retrosynthetic routes. In particular, we develop an interactive graphical user interface that allows expert human chemists to provide human-in-the-loop feedback to the reasoning algorithm. This approach successfully generates novel pathways for complex natural product compounds, demonstrating the potential for iterative LLM reasoning to advance state-of-art in complex chemical syntheses.",
      "authors": [
        "Shreyas Vinaya Sathyanarayana",
        "Rahil Shah",
        "Sharanabasava D. Hiremath",
        "Rishikesh Panda",
        "Rahul Jana",
        "Riya Singh",
        "Rida Irfan",
        "Ashwin Murali",
        "Bharath Ramsundar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantitative Methods (q-bio.QM)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)",
        "Biomolecules (q-bio.BM)",
        "Molecular Networks (q-bio.MN)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T19:41:39+00:00",
          "link": "https://arxiv.org/abs/2507.07060v1",
          "size": "17286kb",
          "version": "v1"
        }
      ],
      "title": "DeepRetro: Retrosynthetic Pathway Discovery using Iterative LLM Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07060",
        "PDF": "https://arxiv.org/pdf/2507.07060"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on using LLMs for retrosynthetic pathway discovery in chemistry, rather than making contributions to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.07308",
      "abstract": "The growing Machine Learning (ML) services require extensive collections of user data, which may inadvertently include people's private information irrelevant to the services. Various studies have been proposed to protect private attributes by removing them from the data while maintaining the utilities of the data for downstream tasks. Nevertheless, as we theoretically and empirically show in the paper, these methods reveal severe vulnerability because of a common weakness rooted in their adversarial training based strategies. To overcome this limitation, we propose a novel approach, PASS, designed to stochastically substitute the original sample with another one according to certain probabilities, which is trained with a novel loss function soundly derived from information-theoretic objective defined for utility-preserving private attributes protection. The comprehensive evaluation of PASS on various datasets of different modalities, including facial images, human activity sensory signals, and voice recording datasets, substantiates PASS's effectiveness and generalizability.",
      "authors": [
        "Yizhuo Chen",
        "Chun-Fu (Richard) Chen",
        "Hsiang Hsu",
        "Shaohan Hu",
        "Tarek Abdelzaher"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-08T22:48:07+00:00",
          "link": "https://arxiv.org/abs/2506.07308v1",
          "size": "833kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T05:41:13+00:00",
          "link": "https://arxiv.org/abs/2506.07308v2",
          "size": "4606kb",
          "version": "v2"
        }
      ],
      "title": "PASS: Private Attributes Protection with Stochastic Data Substitution",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.07308",
        "HTML": "https://arxiv.org/html/2506.07308v2",
        "PDF": "https://arxiv.org/pdf/2506.07308"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on protecting private attributes in ML datasets via stochastic data substitution, without a specific focus on LLM training data preparation or processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.06608",
      "abstract": "Current prefill-decode (PD) disaggregation is typically deployed at the level of entire serving engines, assigning separate GPUs to handle prefill and decode phases. While effective at reducing latency, this approach demands more hardware. To improve GPU utilization, Chunked Prefill mixes prefill and decode requests within the same batch, but introduces phase interference between prefill and decode.\n  While existing PD disaggregation solutions separate the phases across GPUs, we ask: can the same decoupling be achieved within a single serving engine? The key challenge lies in managing the conflicting resource requirements of prefill and decode when they share the same hardware. In this paper, we first show that chunked prefill requests cause interference with decode requests due to their distinct requirements for GPU resources. Second, we find that GPU resources exhibit diminishing returns. Beyond a saturation point, increasing GPU allocation yields negligible latency improvements. This insight enables us to split a single GPU's resources and dynamically allocate them to prefill and decode on the fly, effectively disaggregating the two phases within the same GPU.\n  Across a range of models and workloads, our system Nexus achieves up to 2.2x higher throughput, 20x lower TTFT, and 2.5x lower TBT than vLLM. It also outperforms SGLang with up to 2x higher throughput, 2x lower TTFT, and 1.7x lower TBT, and achieves 1.4x higher throughput than vLLM-disaggregation using only half the number of GPUs.",
      "authors": [
        "Xiaoxiang Shi",
        "Colin Cai",
        "Junjia Du",
        "Zhanda Zhu",
        "Xingda Wei",
        "Zhihao Jia"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T07:27:18+00:00",
          "link": "https://arxiv.org/abs/2507.06608v1",
          "size": "848kb",
          "version": "v1"
        }
      ],
      "title": "Nexus: Taming Throughput-Latency Tradeoff in LLM Serving via Efficient GPU Sharing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06608",
        "HTML": "https://arxiv.org/html/2507.06608v1",
        "PDF": "https://arxiv.org/pdf/2507.06608"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on improving GPU utilization in LLM serving rather than on LLM training data processing or dataset engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06167",
      "abstract": "We introduce Skywork-R1V3, an advanced, open-source vision-language model (VLM) that pioneers a new approach to visual reasoning. Its key innovation lies in effectively transferring reasoning skills from text-only Large Language Models (LLMs) to visual tasks. The strong performance of Skywork-R1V3 primarily stems from our elaborate post-training RL framework, which effectively activates and enhances the model's reasoning ability, without the need for additional continue pre-training. Through this framework, we further uncover the fundamental role of the connector module in achieving robust cross-modal alignment for multimodal reasoning models. In addition, we introduce a unique indicator of reasoning capability, the entropy of critical reasoning tokens, which has proven highly effective for checkpoint selection during RL training. Skywork-R1V3 achieves state-of-the-art results on MMMU, significantly improving from 64.3% to 76.0%. This performance matches entry-level human capabilities. Remarkably, our RL-powered post-training approach enables even the 38B parameter model to rival top closed-source VLMs. The implementation successfully transfers mathematical reasoning to other subject-related reasoning tasks. We also include an analysis of curriculum learning and reinforcement finetuning strategies, along with a broader discussion on multimodal reasoning. Skywork-R1V3 represents a significant leap in multimodal reasoning, showcasing RL as a powerful engine for advancing open-source VLM capabilities.",
      "authors": [
        "Wei Shen and Jiangbo Pei and Yi Peng and Xuchen Song and Yang Liu and Jian Peng and Haofeng Sun and Yunzhuo Hao and Peiyu Wang and Jianhao Zhang and Yahui Zhou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T16:47:16+00:00",
          "link": "https://arxiv.org/abs/2507.06167v1",
          "size": "5486kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T01:36:17+00:00",
          "link": "https://arxiv.org/abs/2507.06167v2",
          "size": "5486kb",
          "version": "v2"
        }
      ],
      "title": "Skywork-R1V3 Technical Report",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06167",
        "PDF": "https://arxiv.org/pdf/2507.06167"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on visual reasoning and RL frameworks for model enhancement, without contributions related to LLM training data processing or dataset creation."
      },
      "models": [
        {
          "model_path": "Skywork/Skywork-R1V3-38B",
          "downloads": "5",
          "likes": "34",
          "trending_score": "34.0",
          "link": "https://huggingface.co/Skywork/Skywork-R1V3-38B"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06531",
      "abstract": "Trajectory prediction for multi-agent interaction scenarios is a crucial challenge. Most advanced methods model agent interactions by efficiently factorized attention based on the temporal and agent axes. However, this static and foward modeling lacks explicit interactive spatio-temporal coordination, capturing only obvious and immediate behavioral intentions. Alternatively, the modern trajectory prediction framework refines the successive predictions by a fixed-anchor selection strategy, which is difficult to adapt in different future environments. It is acknowledged that human drivers dynamically adjust initial driving decisions based on further assumptions about the intentions of surrounding vehicles. Motivated by human driving behaviors, this paper proposes ILNet, a multi-agent trajectory prediction method with Inverse Learning (IL) attention and Dynamic Anchor Selection (DAS) module. IL Attention employs an inverse learning paradigm to model interactions at neighboring moments, introducing proposed intentions to dynamically encode the spatio-temporal coordination of interactions, thereby enhancing the model's ability to capture complex interaction patterns. Then, the learnable DAS module is proposed to extract multiple trajectory change keypoints as anchors in parallel with almost no increase in parameters. Experimental results show that the ILNet achieves state-of-the-art performance on the INTERACTION and Argoverse motion forecasting datasets. Particularly, in challenged interaction scenarios, ILNet achieves higher accuracy and more multimodal distributions of trajectories over fewer parameters. Our codes are available at https://github.com/mjZeng11/ILNet.",
      "authors": [
        "Mingjin Zeng",
        "Nan Ouyang",
        "Wenkang Wan",
        "Lei Ao",
        "Qing Cai",
        "Kai Sheng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T04:18:01+00:00",
          "link": "https://arxiv.org/abs/2507.06531v1",
          "size": "4525kb",
          "version": "v1"
        }
      ],
      "title": "ILNet: Trajectory Prediction with Inverse Learning Attention for Enhancing Intention Capture",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06531",
        "HTML": "https://arxiv.org/html/2507.06531v1",
        "PDF": "https://arxiv.org/pdf/2507.06531"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is centered around trajectory prediction and does not entail processes related to LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.01951",
      "abstract": "We introduce our first reflective generative model MetaStone-S1, which obtains OpenAI o3-mini's performance via the new Reflective Generative Form. The new form focuses on high-quality reasoning trajectory selection and contains two novelties: 1) A unified interface for policy and process reward model: we share the backbone network and use task-specific heads for reasoning trajectory predicting and scoring respectively, introducing only 53M extra parameters for trajectory scoring. 2) Eliminating the reliance on process-level annotation: we provide a self-supervised process reward model, which can directly learn the high-quality reasoning trajectory selection from the outcome reward. Equipped with the reflective generative form, MetaStone-S1 is naturally suitable for test-time scaling, and we provide three reasoning effort modes (low, medium, and high) based on the controllable thinking length. Experiments demonstrate that our MetaStone-S1 achieves comparable performance to OpenAI o3-mini's series with only 32B parameter size. To support the research community, we have open-sourced MetaStone-S1 at https://github.com/MetaStone-AI/MetaStone-S1.",
      "authors": [
        "Zixiao Wang",
        "Yuxin Wang",
        "Xiaorui Wang",
        "Mengting Xing",
        "Jie Gao",
        "Jianjun Xu",
        "Guangcan Liu",
        "Chenhui Jin",
        "Zhuo Wang",
        "Shengzhuo Zhang",
        "Hongtao Xie"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T17:58:01+00:00",
          "link": "https://arxiv.org/abs/2507.01951v1",
          "size": "893kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T12:28:31+00:00",
          "link": "https://arxiv.org/abs/2507.01951v2",
          "size": "1080kb",
          "version": "v2"
        }
      ],
      "title": "Test-Time Scaling with Reflective Generative Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01951",
        "HTML": "https://arxiv.org/html/2507.01951v2",
        "PDF": "https://arxiv.org/pdf/2507.01951"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a generative model for reasoning trajectory selection, focusing on model enhancements rather than processing or creating LLM training data."
      },
      "models": [
        {
          "model_path": "MetaStoneTec/MetaStone-S1-7B",
          "downloads": "9",
          "likes": "1",
          "trending_score": "1.0",
          "link": "https://huggingface.co/MetaStoneTec/MetaStone-S1-7B"
        },
        {
          "model_path": "MetaStoneTec/MetaStone-S1-1.5B",
          "downloads": "9",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/MetaStoneTec/MetaStone-S1-1.5B"
        },
        {
          "model_path": "MetaStoneTec/MetaStone-S1-32B",
          "downloads": "12",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/MetaStoneTec/MetaStone-S1-32B"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.02009",
      "abstract": "Table structure recognition (TSR) and optical character recognition (OCR) play crucial roles in extracting structured data from tables in scientific documents. However, existing extraction frameworks built on top of TSR and OCR methods often fail to quantify the uncertainties of extracted results. To obtain highly accurate data for scientific domains, all extracted data must be manually verified, which can be time-consuming and labor-intensive. We propose a framework that performs uncertainty-aware data extraction for complex scientific tables, built on conformal prediction, a model-agnostic method for uncertainty quantification (UQ). We explored various uncertainty scoring methods to aggregate the uncertainties introduced by TSR and OCR. We rigorously evaluated the framework using a standard benchmark and an in-house dataset consisting of complex scientific tables in six scientific domains. The results demonstrate the effectiveness of using UQ for extraction error detection, and by manually verifying only 47% of extraction results, the data quality can be improved by 30%. Our work quantitatively demonstrates the role of UQ with the potential of improving the efficiency in the human-machine cooperation process to obtain scientifically usable data from complex tables in scientific documents. All code and data are available on GitHub at https://github.com/lamps-lab/TSR-OCR-UQ/tree/main.",
      "authors": [
        "Kehinde Ajayi",
        "Yi He",
        "Jian Wu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T03:36:15+00:00",
          "link": "https://arxiv.org/abs/2507.02009v1",
          "size": "1321kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T23:08:38+00:00",
          "link": "https://arxiv.org/abs/2507.02009v2",
          "size": "1316kb",
          "version": "v2"
        }
      ],
      "title": "Uncertainty-Aware Complex Scientific Table Data Extraction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02009",
        "HTML": "https://arxiv.org/html/2507.02009v2",
        "PDF": "https://arxiv.org/pdf/2507.02009"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a framework for table data extraction using uncertainty quantification, which is not directly related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05297",
      "abstract": "We prove that any optimal, independent, and zero unanimous fuzzy classification aggregation function of a continuum of individual classifications of $m\\ge 3$ objects into $2\\le p\\le m$ types must be a weighted arithmetic mean.",
      "authors": [
        "Zijun Meng"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Theoretical Economics (econ.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-06T09:13:22+00:00",
          "link": "https://arxiv.org/abs/2507.05297v1",
          "size": "4kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T08:41:46+00:00",
          "link": "https://arxiv.org/abs/2507.05297v2",
          "size": "99kb",
          "version": "v2"
        }
      ],
      "title": "Fuzzy Classification Aggregation for a Continuum of Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05297",
        "HTML": "https://arxiv.org/html/2507.05297v2",
        "PDF": "https://arxiv.org/pdf/2507.05297"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proves a mathematical result related to fuzzy classification aggregation functions, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06529",
      "abstract": "Bayesian optimization (BO) is a powerful paradigm for optimizing expensive black-box functions. Traditional BO methods typically rely on separate hand-crafted acquisition functions and surrogate models for the underlying function, and often operate in a myopic manner. In this paper, we propose a novel direct regret optimization approach that jointly learns the optimal model and non-myopic acquisition by distilling from a set of candidate models and acquisitions, and explicitly targets minimizing the multi-step regret. Our framework leverages an ensemble of Gaussian Processes (GPs) with varying hyperparameters to generate simulated BO trajectories, each guided by an acquisition function chosen from a pool of conventional choices, until a Bayesian early stop criterion is met. These simulated trajectories, capturing multi-step exploration strategies, are used to train an end-to-end decision transformer that directly learns to select next query points aimed at improving the ultimate objective. We further adopt a dense training--sparse learning paradigm: The decision transformer is trained offline with abundant simulated data sampled from ensemble GPs and acquisitions, while a limited number of real evaluations refine the GPs online. Experimental results on synthetic and real-world benchmarks suggest that our method consistently outperforms BO baselines, achieving lower simple regret and demonstrating more robust exploration in high-dimensional or noisy settings.",
      "authors": [
        "Fengxue Zhang and Yuxin Chen"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T04:09:58+00:00",
          "link": "https://arxiv.org/abs/2507.06529v1",
          "size": "747kb",
          "version": "v1"
        }
      ],
      "title": "Direct Regret Optimization in Bayesian Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06529",
        "HTML": "https://arxiv.org/html/2507.06529v1",
        "PDF": "https://arxiv.org/pdf/2507.06529"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on Bayesian optimization with direct regret optimization, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06652",
      "abstract": "Fuzzy systems are a way to allow machines, systems and frameworks to deal with uncertainty, which is not possible in binary systems that most computers use. These systems have already been deployed for certain use cases, and fuzzy systems could be further improved as proposed in this paper. Such technologies to draw inspiration from include machine learning and federated learning. Machine learning is one of the recent breakthroughs of technology and could be applied to fuzzy systems to further improve the results it produces. Federated learning is also one of the recent technologies that have huge potential, which allows machine learning training to improve by reducing privacy risk, reducing burden on networking infrastructure, and reducing latency of the latest model. Aspects from federated learning could be used to improve federated learning, such as applying the idea of updating the fuzzy rules that make up a key part of fuzzy systems, to further improve it over time. This paper discusses how these improvements would be implemented in fuzzy systems, and how it would improve fuzzy systems. It also discusses certain limitations on the potential improvements. It concludes that these proposed ideas and improvements require further investigation to see how far the improvements are, but the potential is there to improve fuzzy systems.",
      "authors": [
        "Arthur Alexander Lim (1)",
        "Zhen Bin It (2)",
        "Jovan Bowen Heng (2) and Tee Hui Teo (2) ((1) The University of Newcastle",
        "Callaghan",
        "Australia (2) Singapore University of Technology and Design",
        "Singapore)"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T08:34:24+00:00",
          "link": "https://arxiv.org/abs/2507.06652v1",
          "size": "400kb",
          "version": "v1"
        }
      ],
      "title": "Federated Learning Inspired Fuzzy Systems: Decentralized Rule Updating for Privacy and Scalable Decision Making",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06652",
        "PDF": "https://arxiv.org/pdf/2507.06652"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses improvements in fuzzy systems using ideas from federated learning, but it does not focus on LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07052",
      "abstract": "This paper introduces Flexible First-Order Stochastic Dominance (FFSD), a mathematically rigorous framework that formalizes Herbert Simon's concept of bounded rationality using the Lean 4 theorem prover. We develop machine-verified proofs demonstrating that FFSD bridges classical expected utility theory with Simon's satisficing behavior through parameterized tolerance thresholds. Our approach yields several key results: (1) a critical threshold $\\varepsilon < 1/2$ that guarantees uniqueness of reference points, (2) an equivalence theorem linking FFSD to expected utility maximization for approximate indicator functions, and (3) extensions to multi-dimensional decision settings. By encoding these concepts in Lean 4's dependent type theory, we provide the first machine-checked formalization of Simon's bounded rationality, creating a foundation for mechanized reasoning about economic decision-making under uncertainty with cognitive limitations. This work contributes to the growing intersection between formal mathematics and economic theory, demonstrating how interactive theorem proving can advance our understanding of behavioral economics concepts that have traditionally been expressed only qualitatively.",
      "authors": [
        "Jingyuan Li and Zhou Lin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Mathematical Finance (q-fin.MF)",
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T06:51:36+00:00",
          "link": "https://arxiv.org/abs/2507.07052v1",
          "size": "32kb",
          "version": "v1"
        }
      ],
      "title": "Quantifying Bounded Rationality: Formal Verification of Simon's Satisficing Through Flexible Stochastic Dominance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07052",
        "HTML": "https://arxiv.org/html/2507.07052v1",
        "PDF": "https://arxiv.org/pdf/2507.07052"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on formal verification and bounded rationality in economic decision-making using theorem proving. It does not discuss LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2310.17295",
      "abstract": "Within the tensor product $K \\mathop{\\otimes_{\\cal R}} C_2'$ of any ${}^*$-continuous Kleene algebra $K$ with the polycyclic ${}^*$-continuous Kleene algebra $C_2'$ over two bracket pairs there is a copy of the fixed-point closure of $K$: the centralizer of $C_2'$ in $K \\mathop{\\otimes_{\\cal R}} C_2'$. Using an automata-theoretic representation of elements of $K\\mathop{\\otimes_{\\cal R}} C_2'$ \\`a la Kleene, with the aid of normal form theorems that restrict the occurrences of brackets on paths through the automata, we develop a foundation for a calculus of context-free expressions without variable binders. We also give some results on the bra-ket ${}^*$-continuous Kleene algebra $C_2$, motivate the ``completeness equation'' that distinguishes $C_2$ from $C_2'$, and show that $C_2'$ already validates a relativized form of this equation.",
      "authors": [
        "Mark Hopkins and Hans Lei{\\ss}"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Formal Languages and Automata Theory (cs.FL)"
      ],
      "submission_historys": [
        {
          "date": "2023-10-26T10:23:02+00:00",
          "link": "https://arxiv.org/abs/2310.17295v1",
          "size": "32kb",
          "version": "v1"
        },
        {
          "date": "2024-09-14T18:42:20+00:00",
          "link": "https://arxiv.org/abs/2310.17295v2",
          "size": "45kb",
          "version": "v2"
        },
        {
          "date": "2025-04-25T13:12:05+00:00",
          "link": "https://arxiv.org/abs/2310.17295v3",
          "size": "44kb",
          "version": "v3"
        },
        {
          "date": "2025-07-09T15:48:35+00:00",
          "link": "https://arxiv.org/abs/2310.17295v4",
          "size": "44kb",
          "version": "v4"
        }
      ],
      "title": "Normal Forms for Elements of ${}^*$-Continuous Kleene Algebras Representing the Context-Free Languages",
      "links": {
        "Abstract": "https://arxiv.org/abs/2310.17295",
        "HTML": "https://arxiv.org/html/2310.17295v4",
        "PDF": "https://arxiv.org/pdf/2310.17295"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper develops a foundation for a calculus of context-free expressions in Kleene algebras, with no mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2311.16286",
      "abstract": "Ordinary differential equations (ODEs) can provide mechanistic models of temporally local changes of processes, where parameters are often informed by external knowledge. While ODEs are popular in systems modeling, they are less established for statistical modeling of longitudinal cohort data, e.g., in a clinical setting. Yet, modeling of local changes could also be attractive for assessing the trajectory of an individual in a cohort in the immediate future given its current status, where ODE parameters could be informed by further characteristics of the individual. However, several hurdles so far limit such use of ODEs, as compared to regression-based function fitting approaches. The potentially higher level of noise in cohort data might be detrimental to ODEs, as the shape of the ODE solution heavily depends on the initial value. In addition, larger numbers of variables multiply such problems and might be difficult to handle for ODEs. To address this, we propose to use each observation in the course of time as the initial value to obtain multiple local ODE solutions and build a combined estimator of the underlying dynamics. Neural networks are used for obtaining a low-dimensional latent space for dynamic modeling from a potentially large number of variables, and for obtaining patient-specific ODE parameters from baseline variables. Simultaneous identification of dynamic models and of a latent space is enabled by recently developed differentiable programming techniques. We illustrate the proposed approach in an application with spinal muscular atrophy patients and a corresponding simulation study. In particular, modeling of local changes in health status at any point in time is contrasted to the interpretation of functions obtained from a global regression. This more generally highlights how different application settings might demand different modeling strategies.",
      "authors": [
        "Maren Hackenberg",
        "Astrid Pechmann",
        "Clemens Kreutz",
        "Janbernd Kirschner",
        "Harald Binder"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Methodology (stat.ME)",
        "Machine Learning (cs.LG)",
        "Applications (stat.AP)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2023-11-27T20:02:55+00:00",
          "link": "https://arxiv.org/abs/2311.16286v1",
          "size": "888kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T09:34:24+00:00",
          "link": "https://arxiv.org/abs/2311.16286v2",
          "size": "1073kb",
          "version": "v2"
        }
      ],
      "title": "A statistical approach to latent dynamic modeling with differential equations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2311.16286",
        "HTML": "https://arxiv.org/html/2311.16286v2",
        "PDF": "https://arxiv.org/pdf/2311.16286"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on statistical modeling using ordinary differential equations for longitudinal cohort data, which is not related to LLM training data processing."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/maren-ha/latentdynamics.jl"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.15802",
      "abstract": "MRI and CT are essential clinical cross-sectional imaging techniques for diagnosing complex conditions. However, large 3D datasets with annotations for deep learning are scarce. While methods like DINOv2 are encouraging for 2D image analysis, these methods have not been applied to 3D medical images. Furthermore, deep learning models often lack explainability due to their \"black-box\" nature. This study aims to extend 2D self-supervised models, specifically DINOv2, to 3D medical imaging while evaluating their potential for explainable outcomes. We introduce the Medical Slice Transformer (MST) framework to adapt 2D self-supervised models for 3D medical image analysis. MST combines a Transformer architecture with a 2D feature extractor, i.e., DINOv2. We evaluate its diagnostic performance against a 3D convolutional neural network (3D ResNet) across three clinical datasets: breast MRI (651 patients), chest CT (722 patients), and knee MRI (1199 patients). Both methods were tested for diagnosing breast cancer, predicting lung nodule dignity, and detecting meniscus tears. Diagnostic performance was assessed by calculating the Area Under the Receiver Operating Characteristic Curve (AUC). Explainability was evaluated through a radiologist's qualitative comparison of saliency maps based on slice and lesion correctness. P-values were calculated using Delong's test. MST achieved higher AUC values compared to ResNet across all three datasets: breast (0.94$\\pm$0.01 vs. 0.91$\\pm$0.02, P=0.02), chest (0.95$\\pm$0.01 vs. 0.92$\\pm$0.02, P=0.13), and knee (0.85$\\pm$0.04 vs. 0.69$\\pm$0.05, P=0.001). Saliency maps were consistently more precise and anatomically correct for MST than for ResNet. Self-supervised 2D models like DINOv2 can be effectively adapted for 3D medical imaging using MST, offering enhanced diagnostic accuracy and explainability compared to convolutional neural networks.",
      "authors": [
        "Gustav M\\\"uller-Franzes",
        "Firas Khader",
        "Robert Siepmann",
        "Tianyu Han",
        "Jakob Nikolas Kather",
        "Sven Nebelung",
        "Daniel Truhn"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-24T12:11:11+00:00",
          "link": "https://arxiv.org/abs/2411.15802v1",
          "size": "2276kb",
          "version": "v1"
        }
      ],
      "title": "Medical Slice Transformer: Improved Diagnosis and Explainability on 3D Medical Images with DINOv2",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.15802",
        "PDF": "https://arxiv.org/pdf/2411.15802"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a framework for 3D medical imaging analysis using Transformers, without touching on LLM training data processing or creation."
      },
      "tasks": [
        "Classification",
        "Diagnostic",
        "Explainable artificial intelligence",
        "Explainable Models",
        "Lung Nodule Classification",
        "Medical Image Analysis"
      ],
      "repo_urls": [
        "https://github.com/mueller-franzes/mst"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.15079",
      "abstract": "Modern intelligent transportation systems rely on accurate spatiotemporal traffic analysis to optimize urban mobility and infrastructure resilience. However, pervasive missing data caused by sensor failures and heterogeneous sensing gaps fundamentally hinders reliable traffic modeling. This paper proposes a Neural Canonical Polyadic Factorization (NCPF) model that synergizes low-rank tensor algebra with deep representation learning for robust traffic data imputation. The model innovatively embeds CP decomposition into neural architecture through learnable embedding projections, where sparse traffic tensors are encoded into dense latent factors across road segments, time intervals, and mobility metrics. A hierarchical feature fusion mechanism employs Hadamard products to explicitly model multilinear interactions, while stacked multilayer perceptron layers nonlinearly refine these representations to capture complex spatiotemporal couplings. Extensive evaluations on six urban traffic datasets demonstrate NCPF's superiority over six state-of-the-art baselines. By unifying CP decomposition's interpretable factor analysis with neural network's nonlinear expressive power, NCPF provides a principled yet flexible approaches for high-dimensional traffic data imputation, offering critical support for next-generation transportation digital twins and adaptive traffic control systems.",
      "authors": [
        "Wenyu Luo",
        "Yikai Hou and Peng Tang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-18T02:45:25+00:00",
          "link": "https://arxiv.org/abs/2506.15079v1",
          "size": "610kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T04:06:21+00:00",
          "link": "https://arxiv.org/abs/2506.15079v2",
          "size": "610kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T14:45:44+00:00",
          "link": "https://arxiv.org/abs/2506.15079v3",
          "size": "610kb",
          "version": "v3"
        }
      ],
      "title": "Neural Canonical Polyadic Factorization for Traffic Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.15079",
        "HTML": "https://arxiv.org/html/2506.15079v3",
        "PDF": "https://arxiv.org/pdf/2506.15079"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on traffic data imputation using Neural Canonical Polyadic Factorization, which is unrelated to LLM training data processing or dataset creation."
      },
      "tasks": [
        "Imputation",
        "Representation Learning",
        "tensor algebra",
        "Traffic Data Imputation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06461",
      "abstract": "Reducing energy consumption has become a pressing need for modern machine learning, which has achieved many of its most impressive results by scaling to larger and more energy-consumptive neural networks. Unfortunately, the main algorithm for training such networks, backpropagation, poses significant challenges for custom hardware accelerators, due to both its serial dependencies and the memory footprint needed to store forward activations for the backward pass. Alternatives to backprop, although less effective, do exist; here the main computational bottleneck becomes matrix multiplication. In this study, we derive forward-forward algorithms for binary, stochastic units. Binarization of the activations transforms matrix multiplications into indexing operations, which can be executed efficiently in hardware. Stochasticity, combined with tied weights across units with different biases, bypasses the information bottleneck imposed by binary units. Furthermore, although slow and expensive in traditional hardware, binary sampling that is very fast can be implemented cheaply with p-bits (probabilistic bits), novel devices made up of unstable magnets. We evaluate our proposed algorithms on the MNIST, Fashion-MNIST, and CIFAR-10 datasets, showing that its performance is close to real-valued forward-forward, but with an estimated energy savings of about one order of magnitude.",
      "authors": [
        "Risi Jaiswal",
        "Supriyo Datta",
        "and Joseph G. Makin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T00:29:06+00:00",
          "link": "https://arxiv.org/abs/2507.06461v1",
          "size": "213kb",
          "version": "v1"
        }
      ],
      "title": "Energy-Efficient Supervised Learning with a Binary Stochastic Forward-Forward Algorithm",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06461",
        "PDF": "https://arxiv.org/pdf/2507.06461"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on energy-efficient supervised learning through a binary stochastic forward-forward algorithm, which does not pertain to the processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06490",
      "abstract": "We introduce the new AXU hash function decBRWHash, which is parameterised by the positive integer $c$ and is based on Bernstein-Rabin-Winograd (BRW) polynomials. Choosing $c>1$ gives a hash function which can be implemented using $c$-way single instruction multiple data (SIMD) instructions. We report a set of very comprehensive hand optimised assembly implementations of 4-decBRWHash using avx2 SIMD instructions available on modern Intel processors. For comparison, we also report similar carefully optimised avx2 assembly implementations of polyHash, an AXU hash function based on usual polynomials. Our implementations are over prime order fields, specifically the primes $2^{127}-1$ and $2^{130}-5$. For the prime $2^{130}-5$, for avx2 implementations, compared to the famous Poly1305 hash function, 4-decBRWHash is faster for messages which are a few hundred bytes long and achieves a speed-up of about 16% for message lengths in a few kilobytes range and improves to a speed-up of about 23% for message lengths in a few megabytes range.",
      "authors": [
        "Kaushik Nath and Palash Sarkar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T02:27:33+00:00",
          "link": "https://arxiv.org/abs/2507.06490v1",
          "size": "36kb",
          "version": "v1"
        }
      ],
      "title": "Vectorised Hashing Based on Bernstein-Rabin-Winograd Polynomials over Prime Order Fields",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06490",
        "HTML": "https://arxiv.org/html/2507.06490v1",
        "PDF": "https://arxiv.org/pdf/2507.06490"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a new hash function and does not relate to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.21730",
      "abstract": "We introduce a novel approach to reduce the number of times required for reprogramming memristors on bit-sliced compute-in-memory crossbars for deep neural networks (DNNs). Our idea addresses the limited non-volatile memory endurance, which restrict the number of times they can be reprogrammed.\n  To reduce reprogramming demands, we employ two techniques: (1) we organize weights into sorted sections to schedule reprogramming of similar crossbars, maximizing memristor state reuse, and (2) we reprogram only a fraction of randomly selected memristors in low-order columns, leveraging their bit-level distribution and recognizing their relatively small impact on model accuracy.\n  We evaluate our approach for state-of-the-art models on the ImageNet-1K dataset. We demonstrate a substantial reduction in crossbar reprogramming by 3.7x for ResNet-50 and 21x for ViT-Base, while maintaining model accuracy within a 1% margin.",
      "authors": [
        "Matheus Farias",
        "H. T. Kung"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)",
        "Artificial Intelligence (cs.AI)",
        "Emerging Technologies (cs.ET)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-29T04:34:02+00:00",
          "link": "https://arxiv.org/abs/2410.21730v1",
          "size": "1044kb",
          "version": "v1"
        }
      ],
      "title": "Efficient Reprogramming of Memristive Crossbars for DNNs: Weight Sorting and Bit Stucking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.21730",
        "HTML": "https://arxiv.org/html/2410.21730",
        "PDF": "https://arxiv.org/pdf/2410.21730"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on reprogramming memristive crossbars for DNNs, addressing hardware efficiency rather than LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.06519",
      "abstract": "This paper addresses the challenges of Rhythmic Insertion Tasks (RIT), where a robot must repeatedly perform high-precision insertions, such as screwing a nut into a bolt with a wrench. The inherent difficulty of RIT lies in achieving millimeter-level accuracy and maintaining consistent performance over multiple repetitions, particularly when factors like nut rotation and friction introduce additional complexity. We propose a sim-to-real framework that integrates a reinforcement learning-based insertion policy with a failure forecasting module. By representing the wrench's pose in the nut's coordinate frame rather than the robot's frame, our approach significantly enhances sim-to-real transferability. The insertion policy, trained in simulation, leverages real-time 6D pose tracking to execute precise alignment, insertion, and rotation maneuvers. Simultaneously, a neural network predicts potential execution failures, triggering a simple recovery mechanism that lifts the wrench and retries the insertion. Extensive experiments in both simulated and real-world environments demonstrate that our method not only achieves a high one-time success rate but also robustly maintains performance over long-horizon repetitive tasks.",
      "authors": [
        "Yuhan Liu",
        "Xinyu Zhang",
        "Haonan Chang",
        "Abdeslam Boularias"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T03:38:44+00:00",
          "link": "https://arxiv.org/abs/2507.06519v1",
          "size": "4049kb",
          "version": "v1"
        }
      ],
      "title": "Failure Forecasting Boosts Robustness of Sim2Real Rhythmic Insertion Policies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06519",
        "HTML": "https://arxiv.org/html/2507.06519v1",
        "PDF": "https://arxiv.org/pdf/2507.06519"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on enhancing sim-to-real transferability for robotic rhythmic insertion tasks using reinforcement learning, without any emphasis on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07104",
      "abstract": "Building state-of-the-art Vision-Language Models (VLMs) with strong captioning capabilities typically necessitates training on billions of high-quality image-text pairs, requiring millions of GPU hours. This paper introduces the Vision-Language-Vision (VLV) auto-encoder framework, which strategically leverages key pretrained components: a vision encoder, the decoder of a Text-to-Image (T2I) diffusion model, and subsequently, a Large Language Model (LLM). Specifically, we establish an information bottleneck by regularizing the language representation space, achieved through freezing the pretrained T2I diffusion decoder. Our VLV pipeline effectively distills knowledge from the text-conditioned diffusion model using continuous embeddings, demonstrating comprehensive semantic understanding via high-quality reconstructions. Furthermore, by fine-tuning a pretrained LLM to decode the intermediate language representations into detailed descriptions, we construct a state-of-the-art (SoTA) captioner comparable to leading models like GPT-4o and Gemini 2.0 Flash. Our method demonstrates exceptional cost-efficiency and significantly reduces data requirements; by primarily utilizing single-modal images for training and maximizing the utility of existing pretrained models (image encoder, T2I diffusion model, and LLM), it circumvents the need for massive paired image-text datasets, keeping the total training expenditure under $1,000 USD.",
      "authors": [
        "Tiezheng Zhang",
        "Yitong Li",
        "Yu-cheng Chou",
        "Jieneng Chen",
        "Alan Yuille",
        "Chen Wei",
        "Junfei Xiao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T17:59:04+00:00",
          "link": "https://arxiv.org/abs/2507.07104v1",
          "size": "12217kb",
          "version": "v1"
        }
      ],
      "title": "Vision-Language-Vision Auto-Encoder: Scalable Knowledge Distillation from Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07104",
        "HTML": "https://arxiv.org/html/2507.07104v1",
        "PDF": "https://arxiv.org/pdf/2507.07104"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper describes a framework for building Vision-Language Models leveraging existing pretrained components, mentioning reduced data requirements, but primarily focuses on model architecture and knowledge distillation rather than detailed data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06911",
      "abstract": "The proliferation of data-intensive Artificial Intelligence (AI) applications at the network edge demands a fundamental shift in RAN design, from merely consuming AI for network optimization, to actively enabling distributed AI workloads. This paradigm shift presents a significant opportunity for network operators to monetize AI at the edge while leveraging existing infrastructure investments. To realize this vision, this article presents a novel converged O-RAN and AI-RAN architecture that unifies orchestration and management of both telecommunications and AI workloads on shared infrastructure. The proposed architecture extends the Open RAN principles of modularity, disaggregation, and cloud-nativeness to support heterogeneous AI deployments. We introduce two key architectural innovations: (i) the AI-RAN Orchestrator, which extends the O-RAN Service Management and Orchestration (SMO) to enable integrated resource and allocation across RAN and AI workloads; and (ii) AI-RAN sites that provide distributed edge AI platforms with real-time processing capabilities. The proposed system supports flexible deployment options, allowing AI workloads to be orchestrated with specific timing requirements (real-time or batch processing) and geographic targeting. The proposed architecture addresses the orchestration requirements for managing heterogeneous workloads at different time scales while maintaining open, standardized interfaces and multi-vendor interoperability.",
      "authors": [
        "Michele Polese",
        "Niloofar Mohamadi",
        "Salvatore D'Oro",
        "Tommaso Melodia"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Artificial Intelligence (cs.AI)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T14:49:11+00:00",
          "link": "https://arxiv.org/abs/2507.06911v1",
          "size": "3832kb",
          "version": "v1"
        }
      ],
      "title": "Beyond Connectivity: An Open Architecture for AI-RAN Convergence in 6G",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06911",
        "HTML": "https://arxiv.org/html/2507.06911v1",
        "PDF": "https://arxiv.org/pdf/2507.06911"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on AI-RAN architecture for network optimization and edge computing, not on LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06968",
      "abstract": "Instruction tuning has become a foundation for unlocking the capabilities of large-scale pretrained models and improving their performance on complex tasks. Thus, the construction of high-quality instruction datasets is crucial for enhancing model performance and generalizability. Although current instruction datasets have reached tens of millions of samples, models finetuned on them may still struggle with complex instruction following and tasks in rare domains. This is primarily due to limited expansion in both ``coverage'' (coverage of task types and knowledge areas) and ``depth'' (instruction complexity) of the instruction set. To address this issue, we propose a systematic instruction data construction framework, which integrates a hierarchical labeling system, an informative seed selection algorithm, an evolutionary data synthesis process, and a model deficiency diagnosis with targeted data generation. These components form an iterative closed-loop to continuously enhance the coverage and depth of instruction data. Based on this framework, we construct InfinityInstruct-Subject, a high-quality dataset containing ~1.5 million instructions. Experiments on multiple foundation models and benchmark tasks demonstrate its effectiveness in improving instruction-following capabilities. Further analyses suggest that InfinityInstruct-Subject shows enlarged coverage and depth compared to comparable synthesized instruction datasets. Our work lays a theoretical and practical foundation for the efficient, continuous evolution of instruction datasets, moving from data quantity expansion to qualitative improvement.",
      "authors": [
        "Li Du",
        "Hanyu Zhao",
        "Yiming Ju",
        "Tengfei Pan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T15:59:02+00:00",
          "link": "https://arxiv.org/abs/2507.06968v1",
          "size": "9019kb",
          "version": "v1"
        }
      ],
      "title": "Scaling Towards the Information Boundary of Instruction Set: InfinityInstruct-Subject Technical Report",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06968",
        "HTML": "https://arxiv.org/html/2507.06968v1",
        "PDF": "https://arxiv.org/pdf/2507.06968"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper discusses constructing a high-quality instruction dataset using a detailed systematic framework, which involves data synthesis and targeted data generation, directly relating to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.18428",
      "abstract": "In this paper, we derive a periodic model from a one dimensional nonlocal eikonal equation set on the full space modeling dislocation dynamics. Thanks to a gradient entropy estimate, we show that this periodic model converges toward the initial one when the period goes to infinity. Moreover, we design a semi-explicit numerical scheme for the periodic model that we introduce. We show the well-posedness of the scheme and a discrete gradient entropy inequality. We also prove the convergence of the scheme and we present some numerical experiments.",
      "authors": [
        "Diana Al Zareef",
        "Ahmad El Hajj",
        "Hassan Ibrahim",
        "Antoine Zurek"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-30T15:31:59+00:00",
          "link": "https://arxiv.org/abs/2501.18428v1",
          "size": "163kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T09:13:19+00:00",
          "link": "https://arxiv.org/abs/2501.18428v2",
          "size": "164kb",
          "version": "v2"
        }
      ],
      "title": "Convergence of a semi-explicit scheme for a one dimensional periodic nonlocal eikonal equation modeling dislocation dynamics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.18428",
        "HTML": "https://arxiv.org/html/2501.18428v2",
        "PDF": "https://arxiv.org/pdf/2501.18428"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on numerical schemes for dislocation dynamics based on eikonal equations, lacking any discussion of LLM training data processing or data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06358",
      "abstract": "The number of species within ecosystems is influenced not only by their intrinsic characteristics but also by the spatial scale considered. As the sampled area expands, species richness increases, a phenomenon described by the species-area relationship (SAR). The accumulation dynamics of the SAR results from a complex interplay of biotic and abiotic processes operating at various spatial scales. However, the challenge of collecting exhaustive biodiversity records across spatial scales has hindered a comprehensive understanding of these dynamics. Here, we develop a deep learning approach that leverages sampling theory and small-scale ecological surveys to spatially resolve the scale-dependency of species richness. We demonstrate its performance by predicting the species richness of vascular plant communities across Europe, and evaluate the predictions against an independent dataset of plant community inventories. Our model improves species richness estimates by 32\\% and delivers spatially explicit patterns of species richness and turnover for sampling areas ranging from square meters to hundreds of square kilometers. Explainable AI techniques further disentangle how drivers of species richness operate across spatial scales. The ability of our model to represent the multi-scale nature of biodiversity is essential to deliver robust biodiversity assessments and forecasts under global change.",
      "authors": [
        "Victor Boussange",
        "Philipp Brun",
        "Johanna T. Malle",
        "Gabriele Midolo",
        "Jeanne Portier",
        "Th\\'eophile Sanchez",
        "Niklaus E. Zimmermann",
        "Irena Axmanov\\'a",
        "Helge Bruelheide",
        "Milan Chytr\\'y",
        "Stephan Kambach",
        "Zde\\v{n}ka Lososov\\'a",
        "Martin Ve\\v{c}e\\v{r}a",
        "Idoia Biurrun",
        "Klaus T. Ecker",
        "Jonathan Lenoir",
        "Jens-Christian Svenning",
        "Dirk Nikolaus Karger"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Populations and Evolution (q-bio.PE)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T19:42:33+00:00",
          "link": "https://arxiv.org/abs/2507.06358v1",
          "size": "2421kb",
          "version": "v1"
        }
      ],
      "title": "Deep learning-based species-area models reveal multi-scale patterns of species richness and turnover",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06358",
        "HTML": "https://arxiv.org/html/2507.06358v1",
        "PDF": "https://arxiv.org/pdf/2507.06358"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes deep learning models applied to biodiversity assessments and species richness estimation, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06581",
      "abstract": "Manual annotation of airway regions in computed tomography images is a time-consuming and expertise-dependent task. Automatic airway segmentation is therefore a prerequisite for enabling rapid bronchoscopic navigation and the clinical deployment of bronchoscopic robotic systems. Although convolutional neural network methods have gained considerable attention in airway segmentation, the unique tree-like structure of airways poses challenges for conventional and deformable convolutions, which often fail to focus on fine airway structures, leading to missed segments and discontinuities. To address this issue, this study proposes a novel tubular feature extraction network, named TfeNet. TfeNet introduces a novel direction-aware convolution operation that first applies spatial rotation transformations to adjust the sampling positions of linear convolution kernels. The deformed kernels are then represented as line segments or polylines in 3D space. Furthermore, a tubular feature fusion module (TFFM) is designed based on asymmetric convolution and residual connection strategies, enhancing the network's focus on subtle airway structures. Extensive experiments conducted on one public dataset and two datasets used in airway segmentation challenges demonstrate that the proposed TfeNet achieves more accuracy and continuous airway structure predictions compared with existing methods. In particular, TfeNet achieves the highest overall score of 94.95% on the current largest airway segmentation dataset, Airway Tree Modeling(ATM22), and demonstrates advanced performance on the lung fibrosis dataset(AIIB23). The code is available at https://github.com/QibiaoWu/TfeNet.",
      "authors": [
        "Qibiao Wu",
        "Yagang Wang and Qian Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T06:15:20+00:00",
          "link": "https://arxiv.org/abs/2507.06581v1",
          "size": "3512kb",
          "version": "v1"
        }
      ],
      "title": "Airway Segmentation Network for Enhanced Tubular Feature Extraction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06581",
        "HTML": "https://arxiv.org/html/2507.06581v1",
        "PDF": "https://arxiv.org/pdf/2507.06581"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a novel convolutional neural network for airway segmentation in medical images, focusing on enhancing feature extraction for segmentation tasks without discussing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07095",
      "abstract": "Generating diverse and natural human motion sequences based on textual descriptions constitutes a fundamental and challenging research area within the domains of computer vision, graphics, and robotics. Despite significant advancements in this field, current methodologies often face challenges regarding zero-shot generalization capabilities, largely attributable to the limited size of training datasets. Moreover, the lack of a comprehensive evaluation framework impedes the advancement of this task by failing to identify directions for improvement. In this work, we aim to push text-to-motion into a new era, that is, to achieve the generalization ability of zero-shot. To this end, firstly, we develop an efficient annotation pipeline and introduce MotionMillion-the largest human motion dataset to date, featuring over 2,000 hours and 2 million high-quality motion sequences. Additionally, we propose MotionMillion-Eval, the most comprehensive benchmark for evaluating zero-shot motion generation. Leveraging a scalable architecture, we scale our model to 7B parameters and validate its performance on MotionMillion-Eval. Our results demonstrate strong generalization to out-of-domain and complex compositional motions, marking a significant step toward zero-shot human motion generation. The code is available at https://github.com/VankouF/MotionMillion-Codes.",
      "authors": [
        "Ke Fan",
        "Shunlin Lu",
        "Minyue Dai",
        "Runyi Yu",
        "Lixing Xiao",
        "Zhiyang Dou",
        "Junting Dong",
        "Lizhuang Ma",
        "Jingbo Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T17:52:04+00:00",
          "link": "https://arxiv.org/abs/2507.07095v1",
          "size": "4079kb",
          "version": "v1"
        }
      ],
      "title": "Go to Zero: Towards Zero-shot Motion Generation with Million-scale Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07095",
        "HTML": "https://arxiv.org/html/2507.07095v1",
        "PDF": "https://arxiv.org/pdf/2507.07095"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper introduces MotionMillion, a large dataset with detailed data processing steps for annotation and evaluation in motion generation, emphasizing the creation and preparation of training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.04209",
      "abstract": "We show the mutual information between the targets in a Gray-Wyner Network as a bound that separates Wyner's lossy common information and G\\'acs-K\\\"orner lossy common information. The results are a generalization of the lossless case presented by Wyner (1975).",
      "authors": [
        "Anderson de Andrade"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-06T01:39:00+00:00",
          "link": "https://arxiv.org/abs/2507.04209v1",
          "size": "6kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T20:03:51+00:00",
          "link": "https://arxiv.org/abs/2507.04209v2",
          "size": "4kb",
          "version": "v2"
        }
      ],
      "title": "Mutual Information Bounds for Lossy Common Information",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.04209",
        "HTML": "https://arxiv.org/html/2507.04209v2",
        "PDF": "https://arxiv.org/pdf/2507.04209"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on mutual information theory in Gray-Wyner Networks, which does not relate to LLM training data processing or its enhancement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06856",
      "abstract": "Despite modifying only a small localized input region, adversarial patches can drastically change the prediction of computer vision models. However, prior methods either cannot perform satisfactorily under targeted attack scenarios or fail to produce contextually coherent adversarial patches, causing them to be easily noticeable by human examiners and insufficiently stealthy against automatic patch defenses. In this paper, we introduce IAP, a novel attack framework that generates highly invisible adversarial patches based on perceptibility-aware localization and perturbation optimization schemes. Specifically, IAP first searches for a proper location to place the patch by leveraging classwise localization and sensitivity maps, balancing the susceptibility of patch location to both victim model prediction and human visual system, then employs a perceptibility-regularized adversarial loss and a gradient update rule that prioritizes color constancy for optimizing invisible perturbations. Comprehensive experiments across various image benchmarks and model architectures demonstrate that IAP consistently achieves competitive attack success rates in targeted settings with significantly improved patch invisibility compared to existing baselines. In addition to being highly imperceptible to humans, IAP is shown to be stealthy enough to render several state-of-the-art patch defenses ineffective.",
      "authors": [
        "Subrat Kishore Dutta and Xiao Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T13:58:40+00:00",
          "link": "https://arxiv.org/abs/2507.06856v1",
          "size": "11285kb",
          "version": "v1"
        }
      ],
      "title": "IAP: Invisible Adversarial Patch Attack through Perceptibility-Aware Localization and Perturbation Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06856",
        "HTML": "https://arxiv.org/html/2507.06856v1",
        "PDF": "https://arxiv.org/pdf/2507.06856"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a method for generating invisible adversarial patches in computer vision, which does not relate to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06931",
      "abstract": "Decentralized learning offers a promising approach to crowdsource data consumptions and computational workloads across geographically distributed compute interconnected through peer-to-peer networks, accommodating the exponentially increasing demands. However, proper incentives are still in absence, considerably discouraging participation. Our vision is that a fair incentive mechanism relies on fair attribution of contributions to participating nodes, which faces non-trivial challenges arising from the localized connections making influence ``cascade'' in a decentralized network. To overcome this, we design the first method to estimate \\textbf{D}ata \\textbf{I}nfluence \\textbf{C}ascad\\textbf{E} (DICE) in a decentralized environment. Theoretically, the framework derives tractable approximations of influence cascade over arbitrary neighbor hops, suggesting the influence cascade is determined by an interplay of data, communication topology, and the curvature of loss landscape. DICE also lays the foundations for applications including selecting suitable collaborators and identifying malicious behaviors. Project page is available at https://raiden-zhu.github.io/blog/2025/DICE/.",
      "authors": [
        "Tongtian Zhu",
        "Wenhao Li",
        "Can Wang",
        "Fengxiang He"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Multiagent Systems (cs.MA)",
        "Social and Information Networks (cs.SI)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T15:13:44+00:00",
          "link": "https://arxiv.org/abs/2507.06931v1",
          "size": "9835kb",
          "version": "v1"
        }
      ],
      "title": "DICE: Data Influence Cascade in Decentralized Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06931",
        "HTML": "https://arxiv.org/html/2507.06931v1",
        "PDF": "https://arxiv.org/pdf/2507.06931"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper presents a framework (DICE) for estimating data influence cascade in decentralized learning, which may involve data processing aspects, but it does not specifically focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07050",
      "abstract": "Diffusion models have emerged as a powerful class of generative models, achieving state-of-the-art results in continuous data domains such as image and video generation. Their core mechanism involves a forward diffusion process that gradually transforms structured data into a Gaussian-like distribution, followed by a learned reverse process to reconstruct the data. While successful in continuous modalities, applying this framework to discrete data-particularly natural language-remains challenging due to token dependency complexities and the lack of a defined generation order.This thesis investigates the feasibility and performance of discrete diffusion models for natural language generation. Specifically, we evaluate the Discrete Denoising Diffusion Probabilistic Model (D3PM) and compare it with traditional autoregressive (AR) language models. To assess generative performance, we use Bits Per Token (BPT), Negative Log-Likelihood (NLL), Perplexity (PPL), and Batch Processing Speed.\n  Results show the best-performing D3PM model achieves a BPT of 5.72, with a mean of 8.05. The AR model outperforms in compression with a lower mean BPT of 4.59, but D3PM achieves higher processing speed, reaching up to 3.97 batches per sec., indicating potential for parallel generation.All evaluations were conducted under consistent conditions-generating 100,000 tokens per model with a fixed batch size of four-for fair comparison. This research presents a detailed analysis of diffusion-based vs. autoregressive models, highlighting trade-offs in generative quality and efficiency. Findings emphasize both the promise and limitations of diffusion models for discrete data, supporting future work in non-autoregressive language generation.",
      "authors": [
        "Ashen Weligalle"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T23:43:02+00:00",
          "link": "https://arxiv.org/abs/2507.07050v1",
          "size": "2993kb",
          "version": "v1"
        }
      ],
      "title": "Discrete Diffusion Models for Language Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07050",
        "HTML": "https://arxiv.org/html/2507.07050v1",
        "PDF": "https://arxiv.org/pdf/2507.07050"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research examines diffusion models for language generation and compares their performance with autoregressive models, without addressing LLM training data processing or development."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.11298",
      "abstract": "We introduce $\\textit{sorted weight sectioning}$ (SWS): a weight allocation algorithm that places sorted deep neural network (DNN) weight sections on bit-sliced compute-in-memory (CIM) crossbars to reduce analog-to-digital converter (ADC) energy consumption. Data conversions are the most energy-intensive process in crossbar operation. SWS effectively reduces this cost leveraging (1) small weights and (2) zero weights (weight sparsity).\n  DNN weights follow bell-shaped distributions, with most weights near zero. Using SWS, we only need low-order crossbar columns for sections with low-magnitude weights. This reduces the quantity and resolution of ADCs used, exponentially decreasing ADC energy costs without significantly degrading DNN accuracy.\n  Unstructured sparsification further sharpens the weight distribution with small accuracy loss. However, it presents challenges in hardware tracking of zeros: we cannot switch zero rows to other layer weights in unsorted crossbars without index matching. SWS efficiently addresses unstructured sparse models using offline remapping of zeros into earlier sections, which reveals full sparsity potential and maximizes energy efficiency.\n  Our method reduces ADC energy use by 89.5% on unstructured sparse BERT models. Overall, this paper introduces a novel algorithm to promote energy-efficient CIM crossbars for unstructured sparse DNN workloads.",
      "authors": [
        "Matheus Farias and H. T. Kung"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)",
        "Artificial Intelligence (cs.AI)",
        "Emerging Technologies (cs.ET)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-15T05:37:16+00:00",
          "link": "https://arxiv.org/abs/2410.11298v1",
          "size": "1370kb",
          "version": "v1"
        },
        {
          "date": "2024-10-29T04:39:50+00:00",
          "link": "https://arxiv.org/abs/2410.11298v2",
          "size": "1370kb",
          "version": "v2"
        }
      ],
      "title": "Sorted Weight Sectioning for Energy-Efficient Unstructured Sparse DNNs on Compute-in-Memory Crossbars",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.11298",
        "HTML": "https://arxiv.org/html/2410.11298",
        "PDF": "https://arxiv.org/pdf/2410.11298"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces an algorithm for energy-efficient processing in DNNs using compute-in-memory crossbars, unrelated to processing or creating LLM training data."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.06405",
      "abstract": "Human Activity Recognition (HAR) with wearable sensors is essential for applications in healthcare, fitness, and human-computer interaction. Bio-impedance sensing offers unique advantages for fine-grained motion capture but remains underutilized due to the scarcity of labeled data. We introduce SImpHAR, a novel framework addressing this limitation through two core contributions. First, we propose a simulation pipeline that generates realistic bio-impedance signals from 3D human meshes using shortest-path estimation, soft-body physics, and text-to-motion generation serving as a digital twin for data augmentation. Second, we design a two-stage training strategy with decoupled approach that enables broader activity coverage without requiring label-aligned synthetic data. We evaluate SImpHAR on our collected ImpAct dataset and two public benchmarks, showing consistent improvements over state-of-the-art methods, with gains of up to 22.3% and 21.8%, in terms of accuracy and macro F1 score, respectively. Our results highlight the promise of simulation-driven augmentation and modular training for impedance-based HAR.",
      "authors": [
        "Lala Shakti Swarup Ray",
        "Mengxi Liu",
        "Deepika Gurung",
        "Bo Zhou",
        "Sungho Suh",
        "Paul Lukowicz"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T21:15:12+00:00",
          "link": "https://arxiv.org/abs/2507.06405v1",
          "size": "12756kb",
          "version": "v1"
        }
      ],
      "title": "SImpHAR: Advancing impedance-based human activity recognition using 3D simulation and text-to-motion models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06405",
        "HTML": "https://arxiv.org/html/2507.06405v1",
        "PDF": "https://arxiv.org/pdf/2507.06405"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces SImpHAR, which involves a simulation pipeline for generating bio-impedance signals, a form of data augmentation. This directly contributes to improving data quality for modeling, thus aligning with LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06794",
      "abstract": "Self-supervised learning (SSL) models such as Wav2Vec 2.0 and HuBERT have shown remarkable success in extracting phonetic information from raw audio without labelled data. While prior work has demonstrated that SSL embeddings encode phonetic features at the frame level, it remains unclear whether these models preserve temporal structure, specifically, whether embeddings at phoneme boundaries reflect the identity and order of adjacent phonemes. This study investigates the extent to which boundary-sensitive embeddings from HubertSoft, a soft-clustering variant of HuBERT, encode phoneme transitions. Using the CORPRES Russian speech corpus, we labelled 20 ms embedding windows with triplets of phonemes corresponding to their start, centre, and end segments. A neural network was trained to predict these positions separately, and multiple evaluation metrics, such as ordered, unordered accuracy and a flexible centre accuracy, were used to assess temporal sensitivity. Results show that embeddings extracted at phoneme boundaries capture both phoneme identity and temporal order, with especially high accuracy at segment boundaries. Confusion patterns further suggest that the model encodes articulatory detail and coarticulatory effects. These findings contribute to our understanding of the internal structure of SSL speech representations and their potential for phonological analysis and fine-grained transcription tasks.",
      "authors": [
        "Anastasia Ananeva",
        "Anton Tomilov",
        "Marina Volkova"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T12:29:27+00:00",
          "link": "https://arxiv.org/abs/2507.06794v1",
          "size": "1150kb",
          "version": "v1"
        }
      ],
      "title": "Revealing the Hidden Temporal Structure of HubertSoft Embeddings based on the Russian Phonetic Corpus",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06794",
        "HTML": "https://arxiv.org/html/2507.06794v1",
        "PDF": "https://arxiv.org/pdf/2507.06794"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on analyzing self-supervised learning models for phonetic feature extraction and phonological analysis, and not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07058",
      "abstract": "The automated classification of phonocardiogram (PCG) recordings represents a substantial advancement in cardiovascular diagnostics. This paper presents a systematic comparison of four distinct models for heart murmur detection: two specialized convolutional neural networks (CNNs) and two zero-shot universal audio transformers (BEATs), evaluated using fixed-length and heart cycle normalization approaches. Utilizing the PhysioNet2022 dataset, a custom heart cycle normalization method tailored to individual cardiac rhythms is introduced. The findings indicate the following AUROC values: the CNN model with fixed-length windowing achieves 79.5%, the CNN model with heart cycle normalization scores 75.4%, the BEATs transformer with fixed-length windowing achieves 65.7%, and the BEATs transformer with heart cycle normalization results in 70.1%.\n  The findings indicate that physiological signal constraints, especially those introduced by different normalization strategies, have a substantial impact on model performance. The research provides evidence-based guidelines for architecture selection in clinical settings, emphasizing the need for a balance between accuracy and computational efficiency. Although specialized CNNs demonstrate superior performance overall, the zero-shot transformer models may offer promising efficiency advantages during development, such as faster training and evaluation cycles, despite their lower classification accuracy. These findings highlight the potential of automated classification systems to enhance cardiac diagnostics and improve patient care.",
      "authors": [
        "Martin Sondermann",
        "Pinar Bisgin",
        "Niklas Tschorn",
        "Anja Burmann",
        "Christoph M. Friedrich"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T13:17:26+00:00",
          "link": "https://arxiv.org/abs/2507.07058v1",
          "size": "510kb",
          "version": "v1"
        }
      ],
      "title": "Comparative Analysis of CNN and Transformer Architectures with Heart Cycle Normalization for Automated Phonocardiogram Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07058",
        "HTML": "https://arxiv.org/html/2507.07058v1",
        "PDF": "https://arxiv.org/pdf/2507.07058"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is focused on comparing different models for phonocardiogram classification and does not involve any LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2310.02395",
      "abstract": "Branching and merging are common practices in collaborative software development, increasing developer's productivity. Despite such benefits, developers need to merge software and resolve merge conflicts. While modern merge techniques can resolve textual conflicts automatically, they fail when the conflict arises at the semantic level. Although semantic merge tools have been proposed, they are usually based on heavyweight static analyses or need explicit specifications of program behavior. In this work, we take a different route and propose SAM (SemAntic Merge), a semantic merge tool based on the automated generation of unit tests that are used as partial specifications. To evaluate SAM's feasibility for detecting conflicts, we perform an empirical study analyzing more than 80 pairs of changes integrated into common class elements from 51 merge scenarios. Furthermore, we also assess how the four unit-test generation tools used by SAM contribute to conflict identification. We propose and assess the adoption of Testability Transformations and Serialization. Our results show that SAM best performs when combining only the tests generated by Differential EvoSuite and EvoSuite and using the proposed Testability Transformations (nine detected conflicts out of 28). These results reinforce previous findings about the potential of using test-case generation to detect test conflicts.",
      "authors": [
        "L\\'euson Da Silva",
        "Paulo Borba",
        "Toni Maciel",
        "Wardah Mahmood",
        "Thorsten Berger",
        "Jo\\~ao Moisakis",
        "Aldiberg Gomes",
        "Vin\\'icius Leite"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2023-10-03T19:36:28+00:00",
          "link": "https://arxiv.org/abs/2310.02395v1",
          "size": "2217kb",
          "version": "v1"
        }
      ],
      "title": "Detecting Semantic Conflicts with Unit Tests",
      "links": {
        "Abstract": "https://arxiv.org/abs/2310.02395",
        "HTML": "https://arxiv.org/html/2310.02395",
        "PDF": "https://arxiv.org/pdf/2310.02395"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a semantic merge tool for software development, specifically detecting semantic conflicts with unit tests, and does not address any topic related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.03772",
      "abstract": "The evaluation of large language model (LLM) outputs is increasingly performed by other LLMs, a setup commonly known as \"LLM-as-a-judge\", or autograders. While autograders offer a scalable alternative to human evaluation, they have shown mixed reliability and may exhibit systematic biases, depending on response type, scoring methodology, domain specificity, or other factors. Here we propose a statistical framework based on Bayesian generalised linear models (GLMs) that enables researchers to simultaneously assess their autograders while addressing their primary research questions (e.g., LLM evaluation). Our approach models evaluation outcomes (e.g., scores or pairwise preferences) as a function of properties of the grader (e.g., human vs. autograder) and the evaluated item (e.g., response length or the LLM that generated it), allowing for explicit quantification of scoring differences and potential biases within a unified framework. In addition, our method can be used to augment traditional metrics such as inter-rater agreement, by providing uncertainty estimates and clarifying sources of disagreement. Overall, this approach contributes to more robust and interpretable use of autograders in LLM evaluation, enabling both performance analysis and bias detection.",
      "authors": [
        "Magda Dubois",
        "Harry Coppock",
        "Mario Giulianelli",
        "Timo Flesch",
        "Lennart Luettgau and Cozmin Ududec"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-04T18:45:10+00:00",
          "link": "https://arxiv.org/abs/2507.03772v1",
          "size": "2987kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T16:28:55+00:00",
          "link": "https://arxiv.org/abs/2507.03772v2",
          "size": "3380kb",
          "version": "v2"
        }
      ],
      "title": "Skewed Score: A statistical framework to assess autograders",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.03772",
        "HTML": "https://arxiv.org/html/2507.03772v2",
        "PDF": "https://arxiv.org/pdf/2507.03772"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about evaluating LLM outputs using autograders and assessing their biases; it does not discuss any processing or engineering of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06569",
      "abstract": "Edge detection (ED) remains a fundamental task in computer vision, yet its performance is often hindered by the ambiguous nature of non-edge pixels near object boundaries. The widely adopted Weighted Binary Cross-Entropy (WBCE) loss treats all non-edge pixels uniformly, overlooking the structural nuances around edges and often resulting in blurred predictions. In this paper, we propose the Edge-Boundary-Texture (EBT) loss, a novel objective that explicitly divides pixels into three categories, edge, boundary, and texture, and assigns each a distinct supervisory weight. This tri-class formulation enables more structured learning by guiding the model to focus on both edge precision and contextual boundary localization. We theoretically show that the EBT loss generalizes the WBCE loss, with the latter becoming a limit case. Extensive experiments across multiple benchmarks demonstrate the superiority of the EBT loss both quantitatively and perceptually. Furthermore, the consistent use of unified hyperparameters across all models and datasets, along with robustness to their moderate variations, indicates that the EBT loss requires minimal fine-tuning and is easily deployable in practice.",
      "authors": [
        "Hao Shu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T05:47:26+00:00",
          "link": "https://arxiv.org/abs/2507.06569v1",
          "size": "34152kb",
          "version": "v1"
        }
      ],
      "title": "Edge-Boundary-Texture Loss: A Tri-Class Generalization of Weighted Binary Cross-Entropy for Enhanced Edge Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06569",
        "HTML": "https://arxiv.org/html/2507.06569v1",
        "PDF": "https://arxiv.org/pdf/2507.06569"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a new loss function for edge detection in computer vision, with no mention of LLM training data processing or datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06694",
      "abstract": "Accurate short-term state forecasting is essential for efficient and stable operation of modern power systems, especially in the context of increasing variability introduced by renewable and distributed energy resources. As these systems evolve rapidly, it becomes increasingly important to reliably predict their states in the short term to ensure operational stability, support control decisions, and enable interpretable monitoring of sensor and machine behavior. Modern power systems often span multiple physical domains - including electrical, mechanical, hydraulic, and thermal - posing significant challenges for modeling and prediction. Graph Neural Networks (GNNs) have emerged as a promising data-driven framework for system state estimation and state forecasting in such settings. By leveraging the topological structure of sensor networks, GNNs can implicitly learn inter-sensor relationships and propagate information across the network. However, most existing GNN-based methods are designed under the assumption of homogeneous sensor relationships and are typically constrained to a single physical domain. This limitation restricts their ability to integrate and reason over heterogeneous sensor data commonly encountered in real-world energy systems, such as those used in energy conversion infrastructure. In this work, we propose the use of Heterogeneous Graph Attention Networks to address these limitations. Our approach models both homogeneous intra-domain and heterogeneous inter-domain relationships among sensor data from two distinct physical domains - hydraulic and electrical - which exhibit fundamentally different temporal dynamics. Experimental results demonstrate that our method significantly outperforms conventional baselines on average by 35.5% in terms of normalized root mean square error, confirming its effectiveness in multi-domain, multi-rate power system state forecasting.",
      "authors": [
        "Raffael Theiler",
        "Olga Fink"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Signal Processing (eess.SP)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T09:39:14+00:00",
          "link": "https://arxiv.org/abs/2507.06694v1",
          "size": "2451kb",
          "version": "v1"
        }
      ],
      "title": "Heterogeneous Graph Neural Networks for Short-term State Forecasting in Power Systems across Domains and Time Scales: A Hydroelectric Power Plant Case Study",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06694",
        "HTML": "https://arxiv.org/html/2507.06694v1",
        "PDF": "https://arxiv.org/pdf/2507.06694"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with state forecasting in power systems using graph neural networks and does not address LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06971",
      "abstract": "Panoramic perception holds significant potential for autonomous driving, enabling vehicles to acquire a comprehensive 360{\\deg} surround view in a single shot. However, autonomous driving is a data-driven task. Complete panoramic data acquisition requires complex sampling systems and annotation pipelines, which are time-consuming and labor-intensive. Although existing street view generation models have demonstrated strong data regeneration capabilities, they can only learn from the fixed data distribution of existing datasets and cannot achieve high-quality, controllable panoramic generation. In this paper, we propose the first panoramic generation method Percep360 for autonomous driving. Percep360 enables coherent generation of panoramic data with control signals based on the stitched panoramic data. Percep360 focuses on two key aspects: coherence and controllability. Specifically, to overcome the inherent information loss caused by the pinhole sampling process, we propose the Local Scenes Diffusion Method (LSDM). LSDM reformulates the panorama generation as a spatially continuous diffusion process, bridging the gaps between different data distributions. Additionally, to achieve the controllable generation of panoramic images, we propose a Probabilistic Prompting Method (PPM). PPM dynamically selects the most relevant control cues, enabling controllable panoramic image generation. We evaluate the effectiveness of the generated images from three perspectives: image quality assessment (i.e., no-reference and with reference), controllability, and their utility in real-world Bird's Eye View (BEV) segmentation. Notably, the generated data consistently outperforms the original stitched images in no-reference quality metrics and enhances downstream perception models. The source code will be publicly available at https://github.com/Bryant-Teng/Percep360.",
      "authors": [
        "Fei Teng",
        "Kai Luo",
        "Sheng Wu",
        "Siyu Li",
        "Pujun Guo",
        "Jiale Wei",
        "Kunyu Peng",
        "Jiaming Zhang",
        "Kailun Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T16:01:41+00:00",
          "link": "https://arxiv.org/abs/2507.06971v1",
          "size": "4700kb",
          "version": "v1"
        }
      ],
      "title": "Hallucinating 360{\\deg}: Panoramic Street-View Generation via Local Scenes Diffusion and Probabilistic Prompting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06971",
        "HTML": "https://arxiv.org/html/2507.06971v1",
        "PDF": "https://arxiv.org/pdf/2507.06971"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses panoramic street-view generation using diffusion methods and probabilistic prompting, not related to LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06815",
      "abstract": "Audio question answering (AQA) requires models to understand acoustic content and perform complex reasoning. Current models struggle with dataset imbalances and unstable training dynamics. This work combines curriculum learning with statistical data balancing to address these challenges. The method labels question difficulty using language models, then trains progressively from easy to hard examples. Statistical filtering removes overrepresented audio categories, and guided decoding constrains outputs to valid multiple-choice formats. Experiments on the DCASE 2025 training set and five additional public datasets show that data curation improves accuracy by 11.7% over baseline models, achieving 64.2% on the DCASE 2025 benchmark.",
      "authors": [
        "Gijs Wijngaard",
        "Elia Formisano",
        "Michele Esposito",
        "Michel Dumontier"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T13:06:14+00:00",
          "link": "https://arxiv.org/abs/2507.06815v1",
          "size": "497kb",
          "version": "v1"
        }
      ],
      "title": "Data-Balanced Curriculum Learning for Audio Question Answering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06815",
        "HTML": "https://arxiv.org/html/2507.06815v1",
        "PDF": "https://arxiv.org/pdf/2507.06815"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper's primary contribution is focused on data processing, particularly combining curriculum learning with statistical data balancing and filtering. It involves data curation efforts that improve data quality and model performance, which is directly relevant to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06848",
      "abstract": "Weakly Supervised Semantic Segmentation (WSSS) is a challenging problem that has been extensively studied in recent years. Traditional approaches often rely on external modules like Class Activation Maps to highlight regions of interest and generate pseudo segmentation masks. In this work, we propose an end-to-end method that directly utilizes the attention maps learned by a Vision Transformer (ViT) for WSSS. We propose training a sparse ViT with multiple [CLS] tokens (one for each class), using a random masking strategy to promote [CLS] token - class assignment. At inference time, we aggregate the different self-attention maps of each [CLS] token corresponding to the predicted labels to generate pseudo segmentation masks. Our proposed approach enhances the interpretability of self-attention maps and ensures accurate class assignments. Extensive experiments on two standard benchmarks and three specialized datasets demonstrate that our method generates accurate pseudo-masks, outperforming related works. Those pseudo-masks can be used to train a segmentation model which achieves results comparable to fully-supervised models, significantly reducing the need for fine-grained labeled data.",
      "authors": [
        "Joelle Hanna and Damian Borth"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T13:53:34+00:00",
          "link": "https://arxiv.org/abs/2507.06848v1",
          "size": "8144kb",
          "version": "v1"
        }
      ],
      "title": "Know Your Attention Maps: Class-specific Token Masking for Weakly Supervised Semantic Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06848",
        "HTML": "https://arxiv.org/html/2507.06848v1",
        "PDF": "https://arxiv.org/pdf/2507.06848"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on semantic segmentation using attention maps and not on LLM training data processing or improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.15628",
      "abstract": "Interpreting the internal process of neural models has long been a challenge. This challenge remains relevant in the era of large language models (LLMs) and in-context learning (ICL); for example, ICL poses a new issue of interpreting which example in the few-shot examples contributed to identifying/solving the task. To this end, in this paper, we design synthetic diagnostic tasks of inductive reasoning, inspired by the generalization tests typically adopted in psycholinguistics. Here, most in-context examples are ambiguous w.r.t. their underlying rule, and one critical example disambiguates it. The question is whether conventional input attribution (IA) methods can track such a reasoning process, i.e., identify the influential example, in ICL. Our experiments provide several practical findings; for example, a certain simple IA method works the best, and the larger the model, the generally harder it is to interpret the ICL with gradient-based IA methods.",
      "authors": [
        "Mengyu Ye",
        "Tatsuki Kuribayashi",
        "Goro Kobayashi",
        "Jun Suzuki"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-20T07:35:42+00:00",
          "link": "https://arxiv.org/abs/2412.15628v1",
          "size": "296kb",
          "version": "v1"
        },
        {
          "date": "2025-02-17T07:12:33+00:00",
          "link": "https://arxiv.org/abs/2412.15628v2",
          "size": "423kb",
          "version": "v2"
        },
        {
          "date": "2025-02-18T06:17:50+00:00",
          "link": "https://arxiv.org/abs/2412.15628v3",
          "size": "423kb",
          "version": "v3"
        },
        {
          "date": "2025-06-03T01:49:25+00:00",
          "link": "https://arxiv.org/abs/2412.15628v4",
          "size": "524kb",
          "version": "v4"
        },
        {
          "date": "2025-07-09T06:33:14+00:00",
          "link": "https://arxiv.org/abs/2412.15628v5",
          "size": "524kb",
          "version": "v5"
        }
      ],
      "title": "Can Input Attributions Explain Inductive Reasoning in In-Context Learning?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.15628",
        "HTML": "https://arxiv.org/html/2412.15628v5",
        "PDF": "https://arxiv.org/pdf/2412.15628"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on interpreting neural model processes and does not discuss LLM training data processing or create a new dataset."
      },
      "tasks": [
        "Diagnostic",
        "In-Context Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06643",
      "abstract": "Learning from sparse labels is a challenge commonplace in the medical domain. This is due to numerous factors, such as annotation cost, and is especially true for newly introduced tasks. When dense pixel-level annotations are needed, this becomes even more unfeasible. However, being able to learn from just a few annotations at the pixel-level, while extremely difficult and underutilized, can drive progress in studies where perfect annotations are not immediately available. This work tackles the challenge of learning the dense prediction task of keypoint localization from a few point annotations in the context of 2d carcinosis keypoint localization from laparoscopic video frames for diagnostic planning of advanced ovarian cancer patients. To enable this, we formulate the problem as a sparse heatmap regression from a few point annotations per image and propose a new loss function, called Crag and Tail loss, for efficient learning. Our proposed loss function effectively leverages positive sparse labels while minimizing the impact of false negatives or missed annotations. Through an extensive ablation study, we demonstrate the effectiveness of our approach in achieving accurate dense localization of carcinosis keypoints, highlighting its potential to advance research in scenarios where dense annotations are challenging to obtain.",
      "authors": [
        "Farahdiba Zarin",
        "Riccardo Oliva",
        "Vinkle Srivastav",
        "Armine Vardazaryan",
        "Andrea Rosati",
        "Alice Zampolini Faustini",
        "Giovanni Scambia",
        "Anna Fagotti",
        "Pietro Mascagni",
        "Nicolas Padoy"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T08:14:46+00:00",
          "link": "https://arxiv.org/abs/2507.06643v1",
          "size": "1112kb",
          "version": "v1"
        }
      ],
      "title": "Learning from Sparse Point Labels for Dense Carcinosis Localization in Advanced Ovarian Cancer Assessment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06643",
        "PDF": "https://arxiv.org/pdf/2507.06643"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses learning from sparse labels for dense localization in medical images, focusing on a new loss function for heatmap regression, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06747",
      "abstract": "Object navigation in open-world environments remains a formidable and pervasive challenge for robotic systems, particularly when it comes to executing long-horizon tasks that require both open-world object detection and high-level task planning. Traditional methods often struggle to integrate these components effectively, and this limits their capability to deal with complex, long-range navigation missions. In this paper, we propose LOVON, a novel framework that integrates large language models (LLMs) for hierarchical task planning with open-vocabulary visual detection models, tailored for effective long-range object navigation in dynamic, unstructured environments. To tackle real-world challenges including visual jittering, blind zones, and temporary target loss, we design dedicated solutions such as Laplacian Variance Filtering for visual stabilization. We also develop a functional execution logic for the robot that guarantees LOVON's capabilities in autonomous navigation, task adaptation, and robust task completion. Extensive evaluations demonstrate the successful completion of long-sequence tasks involving real-time detection, search, and navigation toward open-vocabulary dynamic targets. Furthermore, real-world experiments across different legged robots (Unitree Go2, B2, and H1-2) showcase the compatibility and appealing plug-and-play feature of LOVON.",
      "authors": [
        "Daojie Peng",
        "Jiahang Cao",
        "Qiang Zhang",
        "Jun Ma"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T11:02:46+00:00",
          "link": "https://arxiv.org/abs/2507.06747v1",
          "size": "6371kb",
          "version": "v1"
        }
      ],
      "title": "LOVON: Legged Open-Vocabulary Object Navigator",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06747",
        "HTML": "https://arxiv.org/html/2507.06747v1",
        "PDF": "https://arxiv.org/pdf/2507.06747"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a framework for object navigation using LLMs, but it does not focus on training data processing or creation related to LLM pretraining or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06980",
      "abstract": "Large language models (LLMs) have demonstrated impressive performance in code generation, particularly when augmented with chain-of-thought (CoT) prompting techniques. They break down requirements into intermediate reasoning steps, which act as design rationales to guide LLMs in writing code like human programmers. Thus, the quality of these steps is crucial for ensuring the correctness and reliability of the generated code. However, little is known about the quality of CoT generated by LLMs. To what extent can we trust the thoughts generated by LLMs? How good are they? This paper empirically explores the external and internal factors of why LLMs generate unsatisfactory CoTs by analyzing 1,023 failed code samples on two widely used code generation benchmarks. We also evaluate their impact on code generation performance by analyzing 210 CoT-code pairs and refining the unsatisfied CoTs by prompting LLMs. Our study reveals three key findings: (1) External factors (53.60%), such as unclear requirements and lack of context, mainly affect CoT quality, while internal factors (40.10%) stem from LLMs' misunderstanding prompts. (2) Even when CoTs are correct, 18.5% of the generated code contains errors due to instruction-following issues; conversely, 11.90% of correct code is paired with flawed CoTs. (3) Refining low-quality CoTs is feasible, i.e., LLMs improve when given detailed problem descriptions. These findings highlight key challenges in CoT-based code generation and suggest directions for improving LLM reasoning and reliability.",
      "authors": [
        "Binquan Zhang",
        "Li Zhang",
        "Zhiwen Luo",
        "Yuxin Du",
        "Fang Liu",
        "Song Wang",
        "Lin Shi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T16:07:20+00:00",
          "link": "https://arxiv.org/abs/2507.06980v1",
          "size": "869kb",
          "version": "v1"
        }
      ],
      "title": "Are They All Good? Evaluating the Quality of CoTs in LLM-based Code Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06980",
        "HTML": "https://arxiv.org/html/2507.06980v1",
        "PDF": "https://arxiv.org/pdf/2507.06980"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The study analyzes code generation performance using LLMs but focuses on evaluating CoTs rather than processing or creating training data. It does briefly address the impact of CoTs on performance, which is partly related to training data quality."
      },
      "source": "arXiv"
    },
    {
      "id": "2303.08334",
      "abstract": "The Sinc approximation applied to double-exponentially decaying functions is referred to as the DE-Sinc approximation. Because of its high efficiency, this method has been used in various applications. In the Sinc approximation, the mesh size and truncation numbers should be optimally selected to achieve its best performance. However, the standard selection formula has only been \"near-optimally\" selected because the optimal formula of the mesh size cannot be expressed in terms of elementary functions of truncation numbers. In this study, we propose two improved selection formulas. The first one is based on the concept by an earlier research that resulted in a better selection formula for the double-exponential formula. The formula performs slightly better than the standard one, but is still not optimal. As a second selection formula, we introduce a new parameter to propose truly optimal selection formula. We provide explicit error bounds for both selection formulas. Numerical comparisons show that the first formula gives a better error bound than the standard formula, and the second formula gives a much better error bound than the standard and first formulas.",
      "authors": [
        "Tomoaki Okayama and Shota Ogawa"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2023-03-15T02:50:32+00:00",
          "link": "https://arxiv.org/abs/2303.08334v1",
          "size": "31kb",
          "version": "v1"
        },
        {
          "date": "2023-05-08T13:14:04+00:00",
          "link": "https://arxiv.org/abs/2303.08334v2",
          "size": "31kb",
          "version": "v2"
        },
        {
          "date": "2023-08-23T05:45:15+00:00",
          "link": "https://arxiv.org/abs/2303.08334v3",
          "size": "32kb",
          "version": "v3"
        }
      ],
      "title": "Improvement of selection formulas of mesh size and truncation numbers for the DE-Sinc approximation and its theoretical error bound",
      "links": {
        "Abstract": "https://arxiv.org/abs/2303.08334",
        "PDF": "https://arxiv.org/pdf/2303.08334"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on Sinc approximation improvements, including mesh size and truncation numbers, which are unrelated to LLM training data processing or data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.01475",
      "abstract": "Not every directed acyclic graph (DAG) whose underlying undirected graph is planar admits an upward planar drawing. We are interested in pushing the notion of upward drawings beyond planarity by considering upward $k$-planar drawings of DAGs in which the edges are monotonically increasing in a common direction and every edge is crossed at most $k$ times for some integer $k \\ge 1$. We show that the number of crossings per edge in a monotone drawing is in general unbounded for the class of bipartite outerplanar, cubic, or bounded pathwidth DAGs. However, it is at most two for outerpaths and it is at most quadratic in the bandwidth in general. From the computational point of view, we prove that testing upward-$k$-planarity is NP-complete already for $k=1$ and even for restricted instances for which upward planarity testing is polynomial. On the positive side, we can decide in linear time whether a single-source DAG admits an upward 1-planar drawing in which all vertices are incident to the outer face.",
      "authors": [
        "Patrizio Angelini",
        "Therese Biedl",
        "Markus Chimani",
        "Sabine Cornelsen",
        "Giordano Da Lozzo",
        "Seok-Hee Hong",
        "Giuseppe Liotta",
        "Maurizio Patrignani",
        "Sergey Pupyrev",
        "Ignaz Rutter",
        "Alexander Wolff"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Geometry (cs.CG)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-02T21:55:00+00:00",
          "link": "https://arxiv.org/abs/2409.01475v1",
          "size": "1076kb",
          "version": "v1"
        },
        {
          "date": "2025-02-09T13:56:00+00:00",
          "link": "https://arxiv.org/abs/2409.01475v2",
          "size": "646kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T13:13:47+00:00",
          "link": "https://arxiv.org/abs/2409.01475v3",
          "size": "753kb",
          "version": "v3"
        }
      ],
      "title": "The Price of Upwardness",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.01475",
        "HTML": "https://arxiv.org/html/2409.01475v3",
        "PDF": "https://arxiv.org/pdf/2409.01475"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with the geometric and computational aspects of drawing directed acyclic graphs and does not address LLM training data processing or dataset engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06392",
      "abstract": "Formation control allows agents to maintain geometric patterns using local information, but most existing methods assume ideal communication. This paper introduces a goal-oriented framework combining control, cooperative positioning, and communication scheduling for first-order formation tracking. Each agent estimates its position using 6G network-based triangulation, and the scheduling of information updates is governed by Age of Information (AoI) and Value of Information (VoI) metrics. We design three lightweight, signaling-free scheduling policies and assess their impact on formation quality. Simulation results demonstrate the effectiveness of the proposed approach in maintaining accurate formations with no additional communication overhead, showing that worst-case formation adherence increases by 20%.",
      "authors": [
        "Federico Chiariotti and Marco Fabris"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T20:59:48+00:00",
          "link": "https://arxiv.org/abs/2507.06392v1",
          "size": "2626kb",
          "version": "v1"
        }
      ],
      "title": "VoI-aware Scheduling Schemes for Multi-Agent Formation Control",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06392",
        "HTML": "https://arxiv.org/html/2507.06392v1",
        "PDF": "https://arxiv.org/pdf/2507.06392"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper involves scheduling schemes for multi-agent systems in formation control, which does not relate to LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06622",
      "abstract": "Building on the success of Large Language Models (LLMs), LLM-based representations have dominated the document representation landscape, achieving great performance on the document embedding benchmarks. However, the high-dimensional, computationally expensive embeddings from LLMs tend to be either too generic or inefficient for domain-specific applications. To address these limitations, we introduce FuDoBa a Bayesian optimisation-based method that integrates LLM-based embeddings with domain-specific structured knowledge, sourced both locally and from external repositories like WikiData. This fusion produces low-dimensional, task-relevant representations while reducing training complexity and yielding interpretable early-fusion weights for enhanced classification performance. We demonstrate the effectiveness of our approach on six datasets in two domains, showing that when paired with robust AutoML-based classifiers, our proposed representation learning approach performs on par with, or surpasses, those produced solely by the proprietary LLM-based embedding baselines.",
      "authors": [
        "Boshko Koloski and Senja Pollak and Roberto Navigli and Bla\\v{z} \\v{S}krlj"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T07:49:55+00:00",
          "link": "https://arxiv.org/abs/2507.06622v1",
          "size": "5334kb",
          "version": "v1"
        }
      ],
      "title": "FuDoBa: Fusing Document and Knowledge Graph-based Representations with Bayesian Optimisation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06622",
        "HTML": "https://arxiv.org/html/2507.06622v1",
        "PDF": "https://arxiv.org/pdf/2507.06622"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a method that optimizes LLM-based embeddings for specific applications but does not focus significantly on processing large-scale LLM training data or dataset creation processes."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06654",
      "abstract": "Result diversification (RD) is a crucial technique in Text-to-Image Retrieval for enhancing the efficiency of a practical application. Conventional methods focus solely on increasing the diversity metric of image appearances. However, the diversity metric and its desired value vary depending on the application, which limits the applications of RD. This paper proposes a novel task called CDR-CA (Contextual Diversity Refinement of Composite Attributes). CDR-CA aims to refine the diversities of multiple attributes, according to the application's context. To address this task, we propose Multi-Source DPPs, a simple yet strong baseline that extends the Determinantal Point Process (DPP) to multi-sources. We model MS-DPP as a single DPP model with a unified similarity matrix based on a manifold representation. We also introduce Tangent Normalization to reflect contexts. Extensive experiments demonstrate the effectiveness of the proposed method. Our code is publicly available at https://github.com/NEC-N-SOGI/msdpp.",
      "authors": [
        "Naoya Sogi",
        "Takashi Shibata",
        "Makoto Terao",
        "Masanori Suganuma",
        "Takayuki Okatani"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T08:38:46+00:00",
          "link": "https://arxiv.org/abs/2507.06654v1",
          "size": "3744kb",
          "version": "v1"
        }
      ],
      "title": "MS-DPPs: Multi-Source Determinantal Point Processes for Contextual Diversity Refinement of Composite Attributes in Text to Image Retrieval",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06654",
        "HTML": "https://arxiv.org/html/2507.06654v1",
        "PDF": "https://arxiv.org/pdf/2507.06654"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on a novel task in text-to-image retrieval and proposes a baseline for it. There is no mention of LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06997",
      "abstract": "This paper explores the application of a federated learning-based multi-agent reinforcement learning (MARL) strategy to enhance physical-layer security (PLS) in a multi-cellular network within the context of beyond 5G networks. At each cell, a base station (BS) operates as a deep reinforcement learning (DRL) agent that interacts with the surrounding environment to maximize the secrecy rate of legitimate users in the presence of an eavesdropper. This eavesdropper attempts to intercept the confidential information shared between the BS and its authorized users. The DRL agents are deemed to be federated since they only share their network parameters with a central server and not the private data of their legitimate users. Two DRL approaches, deep Q-network (DQN) and Reinforce deep policy gradient (RDPG), are explored and compared. The results demonstrate that RDPG converges more rapidly than DQN. In addition, we demonstrate that the proposed method outperforms the distributed DRL approach. Furthermore, the outcomes illustrate the trade-off between security and complexity.",
      "authors": [
        "Deemah H. Tashman",
        "Soumaya Cherkaoui",
        "and Walaa Hamouda"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Emerging Technologies (cs.ET)",
        "Machine Learning (cs.LG)",
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T16:24:15+00:00",
          "link": "https://arxiv.org/abs/2507.06997v1",
          "size": "453kb",
          "version": "v1"
        }
      ],
      "title": "Federated Learning-based MARL for Strengthening Physical-Layer Security in B5G Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06997",
        "HTML": "https://arxiv.org/html/2507.06997v1",
        "PDF": "https://arxiv.org/pdf/2507.06997"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with federated learning and reinforcement learning strategies for network security, without any mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2212.13449",
      "abstract": "Consider a population of heterogenous agents whose choice behaviors are partially \\textit{comparable} according to a given \\textit{primitive ordering}.The set of choice functions admissible in the population specifies a \\textit{choice model}. As a criterion to guide the model selection process, we propose \\textit{self-progressiveness}, ensuring that each aggregate choice behavior explained by the model has a unique orderly representation within the model itself. We establish an equivalence between self-progressive choice models and well-known algebraic structures called \\textit{lattices}.\n  This equivalence provides for a precise recipe to restrict or extend any choice model for unique orderly representation. Following this recipe, we identify the set of choice functions that are essential for the unique orderly representation of random utility functions. This extended model offers an intuitive explanation for the \\textit{choice overload} phenomena. We provide the necessary and sufficient conditions for identifying the underlying primitive ordering.",
      "authors": [
        "Kemal Yildiz"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Theoretical Economics (econ.TH)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2022-12-27T11:12:18+00:00",
          "link": "https://arxiv.org/abs/2212.13449v1",
          "size": "18kb",
          "version": "v1"
        },
        {
          "date": "2023-01-09T10:20:51+00:00",
          "link": "https://arxiv.org/abs/2212.13449v2",
          "size": "18kb",
          "version": "v2"
        },
        {
          "date": "2023-01-28T16:03:33+00:00",
          "link": "https://arxiv.org/abs/2212.13449v3",
          "size": "20kb",
          "version": "v3"
        },
        {
          "date": "2023-03-17T16:20:53+00:00",
          "link": "https://arxiv.org/abs/2212.13449v4",
          "size": "24kb",
          "version": "v4"
        },
        {
          "date": "2023-04-11T06:33:27+00:00",
          "link": "https://arxiv.org/abs/2212.13449v5",
          "size": "24kb",
          "version": "v5"
        },
        {
          "date": "2023-06-12T02:05:49+00:00",
          "link": "https://arxiv.org/abs/2212.13449v6",
          "size": "24kb",
          "version": "v6"
        },
        {
          "date": "2023-09-13T14:35:53+00:00",
          "link": "https://arxiv.org/abs/2212.13449v7",
          "size": "25kb",
          "version": "v7"
        },
        {
          "date": "2023-09-21T10:16:49+00:00",
          "link": "https://arxiv.org/abs/2212.13449v8",
          "size": "25kb",
          "version": "v8"
        },
        {
          "date": "2024-03-09T20:44:23+00:00",
          "link": "https://arxiv.org/abs/2212.13449v9",
          "size": "31kb",
          "version": "v9"
        },
        {
          "date": "2024-08-08T13:01:05+00:00",
          "link": "https://arxiv.org/abs/2212.13449v10",
          "size": "31kb",
          "version": "v10"
        },
        {
          "date": "2024-10-24T17:59:01+00:00",
          "link": "https://arxiv.org/abs/2212.13449v11",
          "size": "31kb",
          "version": "v11"
        },
        {
          "date": "2025-04-03T14:38:09+00:00",
          "link": "https://arxiv.org/abs/2212.13449v12",
          "size": "31kb",
          "version": "v12"
        },
        {
          "date": "2025-07-09T09:53:34+00:00",
          "link": "https://arxiv.org/abs/2212.13449v13",
          "size": "31kb",
          "version": "v13"
        }
      ],
      "title": "Self-progressive choice models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2212.13449",
        "HTML": "https://arxiv.org/html/2212.13449",
        "PDF": "https://arxiv.org/pdf/2212.13449"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper isn't related to LLM training data; it discusses choice models and behaviors in heterogeneous agents, focusing on model selection criteria."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2506.22675",
      "abstract": "Invariant prediction [Peters et al., 2016] analyzes feature/outcome data from multiple environments to identify invariant features - those with a stable predictive relationship to the outcome. Such features support generalization to new environments and help reveal causal mechanisms. Previous methods have primarily tackled this problem through hypothesis testing or regularized optimization. Here we develop Bayesian Invariant Prediction (BIP), a probabilistic model for invariant prediction. BIP encodes the indices of invariant features as a latent variable and recover them by posterior inference. Under the assumptions of Peters et al. [2016], the BIP posterior targets the true invariant features. We prove that the posterior is consistent and that greater environment heterogeneity leads to faster posterior contraction. To handle many features, we design an efficient variational approximation called VI-BIP. In simulations and real data, we find that BIP and VI-BIP are more accurate and scalable than existing methods for invariant prediction.",
      "authors": [
        "Luhuan Wu",
        "Mingzhang Yin",
        "Yixin Wang",
        "John P. Cunningham",
        "David M. Blei"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T22:58:37+00:00",
          "link": "https://arxiv.org/abs/2506.22675v1",
          "size": "170kb",
          "version": "v1"
        },
        {
          "date": "2025-07-02T22:33:39+00:00",
          "link": "https://arxiv.org/abs/2506.22675v2",
          "size": "169kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T15:42:31+00:00",
          "link": "https://arxiv.org/abs/2506.22675v3",
          "size": "170kb",
          "version": "v3"
        }
      ],
      "title": "Bayesian Invariance Modeling of Multi-Environment Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22675",
        "HTML": "https://arxiv.org/html/2506.22675v3",
        "PDF": "https://arxiv.org/pdf/2506.22675"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a modeling approach for invariant feature prediction across environments, focusing on prediction accuracy and causal inference, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06497",
      "abstract": "Gaps between established security standards and their practical implementation have the potential to introduce vulnerabilities, possibly exposing them to security risks. To effectively address and mitigate these security and compliance challenges, security risk management strategies are essential. However, it must adhere to well-established strategies and industry standards to ensure consistency, reliability, and compatibility both within and across organizations. In this paper, we introduce a new hybrid risk assessment framework called TELSAFE, which employs probabilistic modeling for quantitative risk assessment and eliminates the influence of expert opinion bias. The framework encompasses both qualitative and quantitative assessment phases, facilitating effective risk management strategies tailored to the unique requirements of organizations. A specific use case utilizing Common Vulnerabilities and Exposures (CVE)-related data demonstrates the framework's applicability and implementation in real-world scenarios, such as in the telecommunications industry.",
      "authors": [
        "Sarah Ali Siddiqui and Chandra Thapa and Derui Wang and Rayne Holland and Wei Shao and Seyit Camtepe and Hajime Suzuki and Rajiv Shah"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T02:45:00+00:00",
          "link": "https://arxiv.org/abs/2507.06497v1",
          "size": "1375kb",
          "version": "v1"
        }
      ],
      "title": "TELSAFE: Security Gap Quantitative Risk Assessment Framework",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06497",
        "HTML": "https://arxiv.org/html/2507.06497v1",
        "PDF": "https://arxiv.org/pdf/2507.06497"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a risk assessment framework for security standards and does not discuss LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06707",
      "abstract": "We study the bias-variance tradeoff within a multiscale approximation framework. Our approach utilizes a given quasi-approximation operator, repeatedly applied in an error-correction scheme over a hierarchical data structure. We introduce a new bias measurement, the bias ratio, to quantitatively assess the improvements made by multiscale approximations and demonstrate that this multiscale strategy effectively reduces the bias component of the approximation error, thereby providing a more flexible and robust framework for addressing scattered data approximation problems. Our findings exhibit consistent bias decay across various scenarios, including applications to manifold-valued functions.",
      "authors": [
        "Asaf Abas",
        "Nir Sharon"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T10:02:12+00:00",
          "link": "https://arxiv.org/abs/2507.06707v1",
          "size": "172kb",
          "version": "v1"
        }
      ],
      "title": "Multiscale Approximation as a Bias-Reducing Strategy for Scalar and Manifold-Valued Functions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06707",
        "HTML": "https://arxiv.org/html/2507.06707v1",
        "PDF": "https://arxiv.org/pdf/2507.06707"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on multiscale approximation strategies for bias-reduction in scattered data approximation problems and does not discuss LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21285",
      "abstract": "While slow-thinking large language models (LLMs) exhibit reflection-like reasoning, commonly referred to as the \"aha moment:, their ability to generate informative critiques and refine prior solutions remains limited. In this paper, we introduce Double-Checker, a principled framework designed to enhance the reasoning capabilities of slow-thinking LLMs by fostering explicit self-critique and iterative refinement of their previous solutions. By fine-tuning on our curated 1,730 self-critical instances, Double-Checker empowers long-CoT LLMs to iteratively critique and refine their outputs during inference until they evaluate their solutions as correct under self-generated critiques. We validate the efficacy of Double-Checker across a comprehensive suite of reasoning benchmarks, demonstrating that iterative self-critique significantly enhances the reasoning capabilities of long-CoT LLMs. Notably, our Double-Checker increases the pass@1 performance on challenging AIME benchmarks from 4.4% to 18.2% compared to the original long-CoT LLMs. These results highlight a promising direction for developing more trustworthy and effective LLMs capable of structured self-critique. Our codes and data are available at https://github.com/XinXU-USTC/DoubleChecker",
      "authors": [
        "Xin Xu",
        "Tianhao Chen",
        "Fan Zhang",
        "Wanlong Liu",
        "Pengxiang Li",
        "Ajay Kumar Jaiswal",
        "Yuchen Yan",
        "Jishan Hu",
        "Yang Wang",
        "Hao Chen",
        "Shiwei Liu",
        "Shizhe Diao",
        "Can Yang",
        "Lu Yin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T14:05:45+00:00",
          "link": "https://arxiv.org/abs/2506.21285v1",
          "size": "988kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T03:35:19+00:00",
          "link": "https://arxiv.org/abs/2506.21285v2",
          "size": "989kb",
          "version": "v2"
        }
      ],
      "title": "Double-Checker: Enhancing Reasoning of Slow-Thinking LLMs via Self-Critical Fine-Tuning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21285",
        "HTML": "https://arxiv.org/html/2506.21285v2",
        "PDF": "https://arxiv.org/pdf/2506.21285"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "Although the paper involves fine-tuning of LLMs, its focus is primarily on enhancing reasoning capabilities through self-critique and refinement processes rather than on substantial training data processing or engineering methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.03498",
      "abstract": "Feature generation (FG) aims to enhance the prediction potential of original data by constructing high-order feature combinations and removing redundant features. It is a key preprocessing step for tabular scientific data to improve downstream machine-learning model performance. Traditional methods face the following two challenges when dealing with the feature generation of scientific data: First, the effective construction of high-order feature combinations in scientific data necessitates profound and extensive domain-specific expertise. Secondly, as the order of feature combinations increases, the search space expands exponentially, imposing prohibitive human labor consumption. Advancements in the Data-Centric Artificial Intelligence (DCAI) paradigm have opened novel avenues for automating feature generation processes. Inspired by that, this paper revisits the conventional feature generation workflow and proposes the Multi-agent Feature Generation (MAFG) framework. Specifically, in the iterative exploration stage, multi-agents will construct mathematical transformation equations collaboratively, synthesize and identify feature combinations ex-hibiting high information content, and leverage a reinforcement learning mechanism to evolve their strategies. Upon completing the exploration phase, MAFG integrates the large language models (LLMs) to interpreta-tively evaluate the generated features of each significant model performance breakthrough. Experimental results and case studies consistently demonstrate that the MAFG framework effectively automates the feature generation process and significantly enhances various downstream scientific data mining tasks.",
      "authors": [
        "Meng Xiao",
        "Junfeng Zhou",
        "Yuanchun Zhou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-04T11:52:09+00:00",
          "link": "https://arxiv.org/abs/2507.03498v1",
          "size": "2538kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T11:30:58+00:00",
          "link": "https://arxiv.org/abs/2507.03498v2",
          "size": "2699kb",
          "version": "v2"
        }
      ],
      "title": "Reinforcement Learning-based Feature Generation Algorithm for Scientific Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.03498",
        "PDF": "https://arxiv.org/pdf/2507.03498"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper primarily focuses on feature generation for tabular scientific data and improving machine-learning model performance, and does not primarily address LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06712",
      "abstract": "State estimation for nonlinear dynamical systems is a critical challenge in control and engineering applications, particularly when only partial and noisy measurements are available. This paper introduces a novel Adaptive Physics-Informed Neural Network-based Observer (PINN-Obs) for accurate state estimation in nonlinear systems. Unlike traditional model-based observers, which require explicit system transformations or linearization, the proposed framework directly integrates system dynamics and sensor data into a physics-informed learning process. The observer adaptively learns an optimal gain matrix, ensuring convergence of the estimated states to the true system states. A rigorous theoretical analysis establishes formal convergence guarantees, demonstrating that the proposed approach achieves uniform error minimization under mild observability conditions. The effectiveness of PINN-Obs is validated through extensive numerical simulations on diverse nonlinear systems, including an induction motor model, a satellite motion system, and benchmark academic examples. Comparative experimental studies against existing observer designs highlight its superior accuracy, robustness, and adaptability.",
      "authors": [
        "Ayoub Farkane",
        "Mohamed Boutayeb",
        "Mustapha Oudani and Mounir Ghogho"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Dynamical Systems (math.DS)",
        "Chaotic Dynamics (nlin.CD)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T10:09:45+00:00",
          "link": "https://arxiv.org/abs/2507.06712v1",
          "size": "332kb",
          "version": "v1"
        }
      ],
      "title": "PINN-Obs: Physics-Informed Neural Network-Based Observer for Nonlinear Dynamical Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06712",
        "HTML": "https://arxiv.org/html/2507.06712v1",
        "PDF": "https://arxiv.org/pdf/2507.06712"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on using Physics-Informed Neural Networks for state estimation in nonlinear systems, with no mention of LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2404.02353",
      "abstract": "Deep Learning models are incredibly data-hungry and require very large labeled datasets for supervised learning. As a consequence, these models often suffer from overfitting, limiting their ability to generalize to real-world examples. Recent advancements in diffusion models have enabled the generation of photorealistic images based on textual inputs. Leveraging the substantial datasets used to train these diffusion models, we propose a technique to utilize generated images to augment existing datasets. This paper explores various strategies for effective data augmentation to improve the out-of-domain generalization capabilities of deep learning models.",
      "authors": [
        "Sahiti Yerramilli",
        "Jayant Sravan Tamarapalli",
        "Tanmay Girish Kulkarni",
        "Jonathan Francis",
        "Eric Nyberg"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-02T22:54:24+00:00",
          "link": "https://arxiv.org/abs/2404.02353v1",
          "size": "676kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T05:00:43+00:00",
          "link": "https://arxiv.org/abs/2404.02353v2",
          "size": "676kb",
          "version": "v2"
        }
      ],
      "title": "Semantic Augmentation in Images using Language",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.02353",
        "HTML": "https://arxiv.org/html/2404.02353v2",
        "PDF": "https://arxiv.org/pdf/2404.02353"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper proposes using generated images for data augmentation, which briefly mentions a data preprocessing step, but focuses primarily on deep learning models and their generalization rather than LLM training data processing."
      },
      "tasks": [
        "Data Augmentation",
        "Deep Learning",
        "Domain Generalization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.17399",
      "abstract": "Supervised deep learning has become the method of choice for image denoising. It involves the training of neural networks on large datasets composed of pairs of noisy and clean images. However, the necessity of training data that are specific to the targeted application constrains the widespread use of denoising networks. Recently, several approaches have been developed to overcome this difficulty by whether artificially generating realistic clean/noisy image pairs, or training exclusively on noisy images. In this paper, we show that, contrary to popular belief, denoising networks specialized in the removal of Gaussian noise can be efficiently leveraged in favor of real-world image denoising, even without additional training. For this to happen, an appropriate variance-stabilizing transform (VST) has to be applied beforehand. We propose an algorithm termed Noise2VST for the learning of such a model-free VST. Our approach requires only the input noisy image and an off-the-shelf Gaussian denoiser. We demonstrate through extensive experiments the efficiency and superiority of Noise2VST in comparison to existing methods trained in the absence of specific clean/noisy pairs.",
      "authors": [
        "S\\'ebastien Herbreteau and Michael Unser"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-24T16:23:46+00:00",
          "link": "https://arxiv.org/abs/2407.17399v1",
          "size": "18943kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T17:32:24+00:00",
          "link": "https://arxiv.org/abs/2407.17399v2",
          "size": "20649kb",
          "version": "v2"
        }
      ],
      "title": "Self-Calibrated Variance-Stabilizing Transformations for Real-World Image Denoising",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.17399",
        "HTML": "https://arxiv.org/html/2407.17399v2",
        "PDF": "https://arxiv.org/pdf/2407.17399"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper explores real-world image denoising and introduces Noise2VST, a method that relates to training data filtering by improving transformation, but it doesn't primarily focus on LLM training data processing."
      },
      "tasks": [
        "Denoising",
        "Image Denoising"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.02091",
      "abstract": "Generative artificial intelligence (AI) enables automated content production, including coding in software development, which can significantly influence developer participation and performance. To explore its impact on collaborative open-source software (OSS) development, we investigate the role of GitHub Copilot, a generative AI pair programmer, in OSS development where multiple distributed developers voluntarily collaborate. Using GitHub's proprietary Copilot usage data, combined with public OSS repository data obtained from GitHub, we find that Copilot use increases project-level code contributions by 5.9%. This gain is driven by a 2.1% increase in individual code contributions and a 3.4% rise in developer coding participation. However, these benefits come at a cost as coordination time for code integration increases by 8% due to more code discussions enabled by AI pair programmers. This reveals an important tradeoff: While AI expands who can contribute and how much they contribute, it slows coordination in collective development efforts. Despite this tension, the combined effect of these two competing forces remains positive, indicating a net gain in overall project-level productivity from using AI pair programmers. Interestingly, we also find the effects differ across developer roles. Peripheral developers show relatively smaller gains in project-level code contributions and face a higher increase in coordination time than core developers, likely due to the difference in their project familiarity. In summary, our study underscores the dual role of AI pair programmers in affecting project-level code contributions and coordination time in OSS development. Our findings on the differential effects between core and peripheral developers also provide important implications for the structure of OSS communities in the long run.",
      "authors": [
        "Fangchen Song",
        "Ashish Agarwal",
        "Wen Wen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)",
        "General Economics (econ.GN)",
        "Economics (q-fin.EC)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-02T23:26:10+00:00",
          "link": "https://arxiv.org/abs/2410.02091v1",
          "size": "1094kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T17:44:42+00:00",
          "link": "https://arxiv.org/abs/2410.02091v2",
          "size": "1974kb",
          "version": "v2"
        }
      ],
      "title": "The Impact of Generative AI on Collaborative Open-Source Software Development: Evidence from GitHub Copilot",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.02091",
        "PDF": "https://arxiv.org/pdf/2410.02091"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates the use of AI in software development contexts but does not involve or discuss LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2501.06927",
      "abstract": "Current state-of-the-art 3D reconstruction models face limitations in building extra-large scale outdoor scenes, primarily due to the lack of sufficiently large-scale and detailed datasets. In this paper, we present a extra-large fine-grained dataset with 10 billion points composed of 41,006 drone-captured high-resolution aerial images, covering 20 diverse and culturally significant scenes from worldwide locations such as Cambridge Uni main buildings, the Pyramids, and the Forbidden City Palace. Compared to existing datasets, ours offers significantly larger scale and higher detail, uniquely suited for fine-grained 3D applications. Each scene contains an accurate spatial layout and comprehensive structural information, supporting detailed 3D reconstruction tasks. By reconstructing environments using these detailed images, our dataset supports multiple applications, including outputs in the widely adopted COLMAP format, establishing a novel benchmark for evaluating state-of-the-art large-scale Gaussian Splatting methods.The dataset's flexibility encourages innovations and supports model plug-ins, paving the way for future 3D breakthroughs. All datasets and code will be open-sourced for community use.",
      "authors": [
        "Xinyi Zheng and Steve Zhang and Weizhe Lin and Aaron Zhang and Walterio W. Mayol-Cuevas and Yunze Liu and Junxiao Shen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-12T20:36:39+00:00",
          "link": "https://arxiv.org/abs/2501.06927v1",
          "size": "15247kb",
          "version": "v1"
        },
        {
          "date": "2025-02-02T05:08:46+00:00",
          "link": "https://arxiv.org/abs/2501.06927v2",
          "size": "15247kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T14:35:04+00:00",
          "link": "https://arxiv.org/abs/2501.06927v3",
          "size": "37603kb",
          "version": "v3"
        }
      ],
      "title": "CULTURE3D: A Large-Scale and Diverse Dataset of Cultural Landmarks and Terrains for Gaussian-Based Scene Rendering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.06927",
        "HTML": "https://arxiv.org/html/2501.06927v3",
        "PDF": "https://arxiv.org/pdf/2501.06927"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the creation of a 3D reconstruction dataset for Gaussian-based scene rendering, without any mention of LLM training data processing or data engineering relevant to language models."
      },
      "tasks": [
        "NeRF"
      ],
      "repo_urls": [
        "https://github.com/openinterx/culture3d"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.02579",
      "abstract": "Recent advances in reinforcement learning (RL) for large language model (LLM) fine-tuning show promise in addressing multi-objective tasks but still face significant challenges, including competing objective balancing, low training efficiency, poor scalability, and limited explainability. Leveraging ensemble learning principles, we introduce an Ensemble Multi-Objective RL (EMORL) framework that fine-tunes multiple models with individual objectives while optimizing their aggregation after the fine-tuning to improve efficiency and flexibility. Our method is the first to aggregate the hidden states of individual models, incorporating contextual information from multiple objectives. This approach is supported by a hierarchical grid search algorithm that identifies optimal weighted combinations. We evaluate EMORL on counselor reflection generation tasks, using text classification models to score the generations and provide rewards during RL fine-tuning. Through comprehensive experiments on the PAIR and Psych8k datasets, we demonstrate the advantages of EMORL against existing baselines: significantly lower and more stable training consumption ($17,529\\pm 1,650$ data points and $6,573\\pm 147.43$ seconds), improved scalability and explainability, and comparable performance across multiple objectives.",
      "authors": [
        "Lingxiao Kong",
        "Cong Yang",
        "Susanne Neufang",
        "Oya Deniz Beyan",
        "Zeyd Boukhers"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-05T11:30:46+00:00",
          "link": "https://arxiv.org/abs/2505.02579v1",
          "size": "3723kb",
          "version": "v1"
        },
        {
          "date": "2025-05-06T06:26:11+00:00",
          "link": "https://arxiv.org/abs/2505.02579v2",
          "size": "3724kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T13:45:07+00:00",
          "link": "https://arxiv.org/abs/2505.02579v3",
          "size": "3617kb",
          "version": "v3"
        }
      ],
      "title": "EMORL: Ensemble Multi-Objective Reinforcement Learning for Efficient and Flexible LLM Fine-Tuning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.02579",
        "HTML": "https://arxiv.org/html/2505.02579v3",
        "PDF": "https://arxiv.org/pdf/2505.02579"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces the EMORL framework for efficient LLM fine-tuning using reinforcement learning, focusing on optimizing the fine-tuning process which involves LLM training data processing for improved performance and efficiency."
      },
      "tasks": [
        "Ensemble Learning",
        "Large Language Model",
        "Multi-Objective Reinforcement Learning",
        "Reinforcement Learning (RL)"
      ],
      "repo_urls": [
        "https://github.com/engineerkong/emorl"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.00659",
      "abstract": "Anti-analysis techniques, particularly packing, challenge malware analysts, making packer identification fundamental. Existing packer identifiers have significant limitations: signature-based methods lack flexibility and struggle against dynamic evasion, while Machine Learning approaches require extensive training data, limiting scalability and adaptability. Consequently, achieving accurate and adaptable packer identification remains an open problem. This paper presents PackHero, a scalable and efficient methodology for identifying packers using a novel static approach. PackHero employs a Graph Matching Network and clustering to match and group Call Graphs from programs packed with known packers. We evaluate our approach on a public dataset of malware and benign samples packed with various packers, demonstrating its effectiveness and scalability across varying sample sizes. PackHero achieves a macro-average F1-score of 93.7% with just 10 samples per packer, improving to 98.3% with 100 samples. Notably, PackHero requires fewer samples to achieve stable performance compared to other Machine Learning-based tools. Overall, PackHero matches the performance of State-of-the-art signature-based tools, outperforming them in handling Virtualization-based packers such as Themida/Winlicense, with a recall of 100%.",
      "authors": [
        "Marco Di Gennaro",
        "Mario D'Onghia",
        "Mario Polino",
        "Stefano Zanero",
        "Michele Carminati"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-31T18:01:50+00:00",
          "link": "https://arxiv.org/abs/2506.00659v1",
          "size": "328kb",
          "version": "v1"
        }
      ],
      "title": "PackHero: A Scalable Graph-based Approach for Efficient Packer Identification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.00659",
        "HTML": "https://arxiv.org/html/2506.00659",
        "PDF": "https://arxiv.org/pdf/2506.00659"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces PackHero, a methodology for identifying software packers, which is focused on cybersecurity and not concerned with LLM training data processing."
      },
      "tasks": [
        "Graph Matching"
      ],
      "repo_urls": [
        "https://github.com/necst/packhero"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06334",
      "abstract": "We present the first parallel batch-dynamic algorithm for approximating coreness decomposition with worst-case update times. Given any batch of edge insertions and deletions, our algorithm processes all these updates in $ \\text{poly}(\\log n)$ depth, using a worst-case work bound of $b\\cdot \\text{poly}(\\log n)$ where $b$ denotes the batch size. This means the batch gets processed in $\\tilde{O}(b/p)$ time, given $p$ processors, which is optimal up to logarithmic factors. Previously, an algorithm with similar guarantees was known by the celebrated work of Liu, Shi, Yu, Dhulipala, and Shun [SPAA'22], but with the caveat of the work bound, and thus the runtime, being only amortized.",
      "authors": [
        "Mohsen Ghaffari",
        "Jaehyun Koo"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T18:44:08+00:00",
          "link": "https://arxiv.org/abs/2507.06334v1",
          "size": "46kb",
          "version": "v1"
        }
      ],
      "title": "Parallel Batch-Dynamic Coreness Decomposition with Worst-Case Guarantees",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06334",
        "HTML": "https://arxiv.org/html/2507.06334v1",
        "PDF": "https://arxiv.org/pdf/2507.06334"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a parallel batch-dynamic algorithm for coreness decomposition with worst-case guarantees, with no mention of LLM training data processing or related data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06389",
      "abstract": "This paper leverages linear systems theory to propose a principled measure of complexity for network systems. We focus on a network of first-order scalar linear systems interconnected through a directed graph. By locally filtering out the effect of nodal dynamics in the interconnected system, we propose a new quantitative index of network complexity rooted in the notion of McMillan degree of a linear system. First, we show that network systems with the same interconnection structure share the same complexity index for almost all choices of their interconnection weights. Then, we investigate the dependence of the proposed index on the topology of the network and the pattern of heterogeneity of the nodal dynamics. Specifically, we find that the index depends on the matching number of subgraphs identified by nodal dynamics of different nature, highlighting the joint impact of network architecture and component diversity on overall system complexity.",
      "authors": [
        "Giacomo Baggio and Marco Fabris"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T20:56:51+00:00",
          "link": "https://arxiv.org/abs/2507.06389v1",
          "size": "205kb",
          "version": "v1"
        }
      ],
      "title": "How Complex is a Complex Network? Insights from Linear Systems Theory",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06389",
        "HTML": "https://arxiv.org/html/2507.06389v1",
        "PDF": "https://arxiv.org/pdf/2507.06389"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses network complexity using linear systems theory, with no relation to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06770",
      "abstract": "Quantum relays are central to both quantum communication and distributed quantum computing, enabling long-distance transmission and modular architectures. Unlike classical repeaters, quantum repeaters preserve coherence without amplifying quantum information, relying on entanglement swapping and quantum error correction to overcome loss and decoherence. In this work, we investigate the transmission of quantum information via quantum relay channels. Our three-terminal relay model captures the trade-off between repeater-assisted and repeaterless communication strategies. We propose a decode-forward coding scheme and analyze both entanglement-assisted and unassisted scenarios. Our framework allows for different entanglement topologies between the transmitter, the relay and the destination receiver, recovering known results on entanglement-assisted and unassisted communication. Furthermore, we discuss the interpretation of coding with quantum side information. These findings serve as a stepping stone for the design of secure, efficient, and reliable quantum networks and the practical realization of quantum repeaters and long-range quantum key distribution.",
      "authors": [
        "Yigal Ilin and Uzi Pereg"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T12:01:19+00:00",
          "link": "https://arxiv.org/abs/2507.06770v1",
          "size": "107kb",
          "version": "v1"
        }
      ],
      "title": "Relaying Quantum Information",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06770",
        "HTML": "https://arxiv.org/html/2507.06770v1",
        "PDF": "https://arxiv.org/pdf/2507.06770"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper examines quantum information transmission and does not mention LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2407.08277",
      "abstract": "In this work, we present a novel approach for general object segmentation from a monocular image, eliminating the need for manually labeled training data and enabling rapid, straightforward training and adaptation with minimal data. Our model initially learns from LiDAR during the training process, which is subsequently removed from the system, allowing it to function solely on monocular imagery. This study leverages the concept of the Stixel-World to recognize a medium level representation of its surroundings. Our network directly predicts a 2D multi-layer Stixel-World and is capable of recognizing and locating multiple, superimposed objects within an image. Due to the scarcity of comparable works, we have divided the capabilities into modules and present a free space detection in our experiments section. Furthermore, we introduce an improved method for generating Stixels from LiDAR data, which we use as ground truth for our network.",
      "authors": [
        "Marcel Vosshans",
        "Omar Ait-Aider",
        "Youcef Mezouar and Markus Enzweiler"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-11T08:25:51+00:00",
          "link": "https://arxiv.org/abs/2407.08277v1",
          "size": "14720kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T09:38:35+00:00",
          "link": "https://arxiv.org/abs/2407.08277v2",
          "size": "14686kb",
          "version": "v2"
        }
      ],
      "title": "StixelNExT: Toward Monocular Low-Weight Perception for Object Segmentation and Free Space Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.08277",
        "HTML": "https://arxiv.org/html/2407.08277v2",
        "PDF": "https://arxiv.org/pdf/2407.08277"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on object segmentation from monocular images and introduces a method involving LiDAR data, with no mention of LLM training data processing."
      },
      "tasks": [
        "Semantic Segmentation"
      ],
      "repo_urls": [
        "https://github.com/MarcelVSHNS/StixelNExT"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.05582",
      "abstract": "Reduced biquaternion (RB), as a four-dimensional algebra highly suitable for representing color pixels, has recently garnered significant attention from numerous scholars. In this paper, for color image processing problems, we introduce a concept of the non-negative RB matrix and then use the multiplication properties of RB to propose a non-negative RB matrix factorization (NRBMF) model. The NRBMF model is introduced to address the challenge of reasonably establishing a non-negative quaternion matrix factorization model, which is primarily hindered by the multiplication properties of traditional quaternions. Furthermore, this paper transforms the problem of solving the NRBMF model into an RB alternating non-negative least squares (RB-ANNLS) problem. Then, by introducing a method to compute the gradient of the real function with RB matrix variables, we solve the RB-ANNLS optimization problem using the RB projected gradient algorithm and conduct a convergence analysis of the algorithm. Finally, we validate the effectiveness and superiority of the proposed NRBMF model in color face recognition.",
      "authors": [
        "Jifei Miao",
        "Junjun Pan",
        "and Michael K. Ng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-10T15:25:42+00:00",
          "link": "https://arxiv.org/abs/2408.05582v1",
          "size": "2139kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T06:27:15+00:00",
          "link": "https://arxiv.org/abs/2408.05582v2",
          "size": "2179kb",
          "version": "v2"
        }
      ],
      "title": "Non-Negative Reduced Biquaternion Matrix Factorization with Applications in Color Face Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.05582",
        "HTML": "https://arxiv.org/html/2408.05582v2",
        "PDF": "https://arxiv.org/pdf/2408.05582"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a non-negative matrix factorization technique for color image processing in face recognition. It doesn't relate to LLM training data processing."
      },
      "tasks": [
        "Face Recognition"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.23325",
      "abstract": "Speech codecs serve as bridges between speech signals and large language models. An ideal codec for speech language models should not only preserve acoustic information but also capture rich semantic information. However, existing speech codecs struggle to balance high-quality audio reconstruction with ease of modeling by language models. In this study, we analyze the limitations of previous codecs in balancing semantic richness and acoustic fidelity. We propose XY-Tokenizer, a novel codec that mitigates the conflict between semantic and acoustic capabilities through multi-stage, multi-task learning. Experimental results demonstrate that XY-Tokenizer achieves performance in both semantic and acoustic tasks comparable to that of state-of-the-art codecs operating at similar bitrates, even though those existing codecs typically excel in only one aspect. Specifically, XY-Tokenizer achieves strong text alignment, surpassing distillation-based semantic modeling methods such as SpeechTokenizer and Mimi, while maintaining a speaker similarity score of 0.83 between reconstructed and original audio. The reconstruction performance of XY-Tokenizer is comparable to that of BigCodec, the current state-of-the-art among acoustic-only codecs, which achieves a speaker similarity score of 0.84 at a similar bitrate. Code and models are available at https://github.com/gyt1145028706/XY-Tokenizer.",
      "authors": [
        "Yitian Gong",
        "Luozhijie Jin",
        "Ruifan Deng",
        "Dong Zhang",
        "Xin Zhang",
        "Qinyuan Cheng",
        "Zhaoye Fei",
        "Shimin Li",
        "Xipeng Qiu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T16:51:50+00:00",
          "link": "https://arxiv.org/abs/2506.23325v1",
          "size": "562kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T17:40:35+00:00",
          "link": "https://arxiv.org/abs/2506.23325v2",
          "size": "562kb",
          "version": "v2"
        }
      ],
      "title": "XY-Tokenizer: Mitigating the Semantic-Acoustic Conflict in Low-Bitrate Speech Codecs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23325",
        "HTML": "https://arxiv.org/html/2506.23325v2",
        "PDF": "https://arxiv.org/pdf/2506.23325"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a codec for speech models but does not focus on any aspect of LLM training data processing, instead it aims to balance semantic richness and acoustic fidelity in speech codecs."
      },
      "models": [
        {
          "model_path": "MCplayer/XY_Tokenizer",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/MCplayer/XY_Tokenizer"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06582",
      "abstract": "Environments with controllable dynamics are usually understood in terms of explicit models. However, such models are not always available, but may sometimes be learned by exploring an environment. In this work, we investigate using an information measure called \"predicted information gain\" to determine the most informative regions of an environment to explore next. Applying methods from reinforcement learning allows good suboptimal exploring policies to be found, and leads to reliable estimates of the underlying controllable dynamics. This approach is demonstrated by comparing with several myopic exploration approaches.",
      "authors": [
        "Peter N. Loxley and Friedrich T. Sommer"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T06:20:24+00:00",
          "link": "https://arxiv.org/abs/2507.06582v1",
          "size": "106kb",
          "version": "v1"
        }
      ],
      "title": "Learning controllable dynamics through informative exploration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06582",
        "HTML": "https://arxiv.org/html/2507.06582v1",
        "PDF": "https://arxiv.org/pdf/2507.06582"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores informative exploration policies in environments with controllable dynamics using reinforcement learning, without making contributions to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06858",
      "abstract": "This study presents findings from long-term biometric evaluations conducted at the Biometric Evaluation Center (bez). Over the course of two and a half years, our ongoing research with over 400 participants representing diverse ethnicities, genders, and age groups were regularly assessed using a variety of biometric tools and techniques at the controlled testing facilities. Our findings are based on the General Data Protection Regulation-compliant local bez database with more than 238.000 biometric data sets categorized into multiple biometric modalities such as face and finger. We used state-of-the-art face recognition algorithms to analyze long-term comparison scores. Our results show that these scores fluctuate more significantly between individual days than over the entire measurement period. These findings highlight the importance of testing biometric characteristics of the same individuals over a longer period of time in a controlled measurement environment and lays the groundwork for future advancements in biometric data analysis.",
      "authors": [
        "Mathias Schulz",
        "Alexander Spenke",
        "Pia Funk",
        "Florian Bl\\\"umel",
        "Markus Rohde",
        "Ralph Breithaupt",
        "Gerd Nolden",
        "Norbert Jung",
        "Robert Lange"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T13:59:31+00:00",
          "link": "https://arxiv.org/abs/2507.06858v1",
          "size": "865kb",
          "version": "v1"
        }
      ],
      "title": "Longitudinal Study of Facial Biometrics at the BEZ: Temporal Variance Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06858",
        "HTML": "https://arxiv.org/html/2507.06858v1",
        "PDF": "https://arxiv.org/pdf/2507.06858"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study analyzes biometric data in facial recognition systems over time and does not involve LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06637",
      "abstract": "We propose Path Signatures Logistic Regression (PSLR), a semi-parametric framework for classifying vector-valued functional data with scalar covariates. Classical functional logistic regression models rely on linear assumptions and fixed basis expansions, which limit flexibility and degrade performance under irregular sampling. PSLR overcomes these issues by leveraging truncated path signatures to construct a finite-dimensional, basis-free representation that captures nonlinear and cross-channel dependencies. By embedding trajectories as time-augmented paths, PSLR extracts stable, geometry-aware features that are robust to sampling irregularity without requiring a common time grid, while still preserving subject-specific timing patterns. We establish theoretical guarantees for the existence and consistent estimation of the optimal truncation order, along with non-asymptotic risk bounds. Experiments on synthetic and real-world datasets show that PSLR outperforms traditional functional classifiers in accuracy, robustness, and interpretability, particularly under non-uniform sampling schemes. Our results highlight the practical and theoretical benefits of integrating rough path theory into modern functional data analysis.",
      "authors": [
        "Pengcheng Zeng and Siyuan Jiang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T08:06:50+00:00",
          "link": "https://arxiv.org/abs/2507.06637v1",
          "size": "685kb",
          "version": "v1"
        }
      ],
      "title": "Semi-parametric Functional Classification via Path Signatures Logistic Regression",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06637",
        "HTML": "https://arxiv.org/html/2507.06637v1",
        "PDF": "https://arxiv.org/pdf/2507.06637"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a semi-parametric framework for functional classification using logistic regression, but does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2311.15480",
      "abstract": "There has recently been a sharp increase in interest in Artificial Intelligence-Generated Content (AIGC). Despite this, musical components such as time signatures have not been studied sufficiently to form an algorithmic determination approach for new compositions, especially lyrical songs. This is likely because of the neglect of musical details, which is critical for constructing a robust framework. Specifically, time signatures establish the fundamental rhythmic structure for almost all aspects of a song, including the phrases and notes. In this paper, we propose a novel approach that only uses lyrics as input to automatically generate a fitting time signature for lyrical songs and uncover the latent rhythmic structure utilizing explainable machine learning models. In particular, we devise multiple methods that are associated with discovering lyrical patterns and creating new features that simultaneously contain lyrical, rhythmic, and statistical information. In this approach, the best of our experimental results reveal a 97.6% F1 score and a 0.996 Area Under the Curve (AUC) of the Receiver Operating Characteristic (ROC) score. In conclusion, our research directly generates time signatures from lyrics automatically for new scores utilizing machine learning, which is an innovative idea that approaches an understudied component of musicology and therefore contributes significantly to the future of Artificial Intelligence (AI) music generation.",
      "authors": [
        "Callie C. Liao",
        "Duoduo Liao",
        "Jesse Guessford"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Multimedia (cs.MM)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2023-11-27T01:44:02+00:00",
          "link": "https://arxiv.org/abs/2311.15480v1",
          "size": "1007kb",
          "version": "v1"
        },
        {
          "date": "2024-01-28T19:53:22+00:00",
          "link": "https://arxiv.org/abs/2311.15480v2",
          "size": "1010kb",
          "version": "v2"
        }
      ],
      "title": "Automatic Time Signature Determination for New Scores Using Lyrics for Latent Rhythmic Structure",
      "links": {
        "Abstract": "https://arxiv.org/abs/2311.15480",
        "PDF": "https://arxiv.org/pdf/2311.15480"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a method for generating time signatures from lyrics. It is focused on music composition and does not discuss LLM training data processing."
      },
      "tasks": [
        "Music Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.06405",
      "abstract": "Let $(X_1,d_1),\\dots, (X_N,d_N)$ be metric spaces, where $d_i: X_i \\times X_i \\rightarrow [0,1]$ is a distance function for $i=1,\\dots,N$. Let $\\mathcal{X}$ denote the set theoretic product $X_1\\times \\cdots \\times X_N$. Let $\\mathcal{G} = \\left(\\mathcal{V},\\mathcal{E}\\right)$ be a directed graph with vertex set $\\mathcal{V} =\\{1,\\dots, N\\}$, and let $\\mathcal{P} = \\{p_{ij}\\}$ be a collection of weights, where each $p_{ij}\\in (0, 1]$ is associated with the edge $(i,j) \\in \\mathcal{E}$. We introduce the function $d_{\\mathcal{X},\\mathcal{G},\\mathcal{P}}: \\mathcal{X}\\times \\mathcal{X} \\to [0,1]$ defined by \\begin{align*} d_{\\mathcal{X},\\mathcal{G},\\mathcal{P}}(\\mathbf{g},\\mathbf{h}) := \\left(1 - \\frac{1}{N}\\sum_{j=1}^N \\prod_{i=1}^N \\left[1- d_i(g_i,h_i)\\right]^{\\frac{1}{p_{ji}}} \\right), \\end{align*} for all $\\mathbf{g},\\mathbf{h} \\in \\mathcal{X}$. In this paper we show that $d_{\\mathcal{X},\\mathcal{G},\\mathcal{P}}$ defines a metric space over $\\mathcal{X}$. Then we determine how this distance behaves under various graph operations, including disjoint unions and Cartesian products. We investigate two limiting cases: (a) when $d_{\\mathcal{X},\\mathcal{G},\\mathcal{P}}$ is defined over a finite field, leading to a broad generalization of graph-based distances commonly studied in error-correcting code theory; and (b) when the metric is extended to graphons, enabling the measurement of distances in a continuous graph limit setting.",
      "authors": [
        "Mahir Bilen Can and Shantanu Chakrabartty"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)",
        "Metric Geometry (math.MG)",
        "Statistics Theory (math.ST)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-09T20:04:57+00:00",
          "link": "https://arxiv.org/abs/2505.06405v1",
          "size": "42kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T00:33:19+00:00",
          "link": "https://arxiv.org/abs/2505.06405v2",
          "size": "5197kb",
          "version": "v2"
        }
      ],
      "title": "Mixing and Merging Metric Spaces using Directed Graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.06405",
        "HTML": "https://arxiv.org/html/2505.06405v2",
        "PDF": "https://arxiv.org/pdf/2505.06405"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses metric spaces and graph operations, without any focus on LLM training data processing or data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06881",
      "abstract": "The Architecture Analysis & Design Language (AADL) is an architecture description language for design of cyber-physical systems--machines controlled by software. The AADL standard, SAE International AS5506D, describes Run-Time Services (RTS) to be provided to execute AADL models in accordance with semantics defined by the standard. The RTS of primary concern are transport services and timing services. Although, the study presented in [1] sets a foundation for the formal semantics of AADL, but without modeling time. This paper extends and simplifies this formalization using a modal logic defined by a Kripke structure, to explicitly include time. The RTS defined in the AADL standard are also expanded to support reactive state-transition machines of the Behavior Specification annex standard language (BA) and its closely-related, formally-defined counterpart, the Behavior Language for Embedded Systems with Software (BLESS). An example of AADL RTS with time, implemented by the High Assurance Modeling and Rapid Engineering for Embedded Systems (HAMR) for state-transition machine behavior written in BLESS, is also presented.",
      "authors": [
        "Brian R Larson",
        "Ehsan Ahmad"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T14:17:42+00:00",
          "link": "https://arxiv.org/abs/2507.06881v1",
          "size": "316kb",
          "version": "v1"
        }
      ],
      "title": "Formalization of the AADL Run-Time Services with Time",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06881",
        "HTML": "https://arxiv.org/html/2507.06881v1",
        "PDF": "https://arxiv.org/pdf/2507.06881"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper formalizes AADL Run-Time Services for cyber-physical systems and does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06992",
      "abstract": "Despite significant advancements in adapting Large Language Models (LLMs) for radiology report generation (RRG), clinical adoption remains challenging due to difficulties in accurately mapping pathological and anatomical features to their corresponding text descriptions. Additionally, semantic agnostic feature extraction further hampers the generation of accurate diagnostic reports. To address these challenges, we introduce Medical Concept Aligned Radiology Report Generation (MCA-RG), a knowledge-driven framework that explicitly aligns visual features with distinct medical concepts to enhance the report generation process. MCA-RG utilizes two curated concept banks: a pathology bank containing lesion-related knowledge, and an anatomy bank with anatomical descriptions. The visual features are aligned with these medical concepts and undergo tailored enhancement. We further propose an anatomy-based contrastive learning procedure to improve the generalization of anatomical features, coupled with a matching loss for pathological features to prioritize clinically relevant regions. Additionally, a feature gating mechanism is employed to filter out low-quality concept features. Finally, the visual features are corresponding to individual medical concepts, and are leveraged to guide the report generation process. Experiments on two public benchmarks (MIMIC-CXR and CheXpert Plus) demonstrate that MCA-RG achieves superior performance, highlighting its effectiveness in radiology report generation.",
      "authors": [
        "Qilong Xing",
        "Zikai Song",
        "Youjia Zhang",
        "Na Feng",
        "Junqing Yu",
        "Wei Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T16:15:38+00:00",
          "link": "https://arxiv.org/abs/2507.06992v1",
          "size": "1099kb",
          "version": "v1"
        }
      ],
      "title": "MCA-RG: Enhancing LLMs with Medical Concept Alignment for Radiology Report Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06992",
        "HTML": "https://arxiv.org/html/2507.06992v1",
        "PDF": "https://arxiv.org/pdf/2507.06992"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper touches on feature extraction and filtering techniques to improve LLM performance in radiology report generation, but does not focus primarily on training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.01182",
      "abstract": "Humanoid robots, with their human-like form, are uniquely suited for interacting in environments built for people. However, enabling humanoids to reason, plan, and act in complex open-world settings remains a challenge. World models, models that predict the future outcome of a given action, can support these capabilities by serving as a dynamics model in long-horizon planning and generating synthetic data for policy learning. We introduce Humanoid World Models (HWM), a family of lightweight, open-source models that forecast future egocentric video conditioned on humanoid control tokens. We train two types of generative models, Masked Transformers and Flow-Matching, on 100 hours of humanoid demonstrations. Additionally, we explore architectural variants with different attention mechanisms and parameter-sharing strategies. Our parameter-sharing techniques reduce model size by 33-53% with minimal impact on performance or visual fidelity. HWMs are designed to be trained and deployed in practical academic and small-lab settings, such as 1-2 GPUs.",
      "authors": [
        "Muhammad Qasim Ali",
        "Aditya Sridhar",
        "Shahbuland Matiana",
        "Alex Wong",
        "Mohammad Al-Sharman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-01T21:33:36+00:00",
          "link": "https://arxiv.org/abs/2506.01182v1",
          "size": "6571kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T20:18:16+00:00",
          "link": "https://arxiv.org/abs/2506.01182v2",
          "size": "6635kb",
          "version": "v2"
        }
      ],
      "title": "Humanoid World Models: Open World Foundation Models for Humanoid Robotics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.01182",
        "HTML": "https://arxiv.org/html/2506.01182v2",
        "PDF": "https://arxiv.org/pdf/2506.01182"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on humanoid robotics and the development of predictive models for such robots using egocentric video data, not on the processing of LLM training data."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.06064",
      "abstract": "This paper presents Wrapless -- a lending protocol that enables the collateralization of bitcoins without requiring a trusted wrapping mechanism. The protocol facilitates a \"loan channel\" on the Bitcoin blockchain, allowing bitcoins to be locked as collateral for loans issued on any blockchain that supports Turing-complete smart contracts. The protocol is designed in a way that makes it economically irrational for each involved party to manipulate the loan rules. There is still a significant research area to bring the protocol closer to traditional AMM financial instruments.",
      "authors": [
        "Oleksandr Kurbatov",
        "Kyrylo Baibula",
        "Yaroslava Chopa",
        "Sergey Kozlov",
        "Oleh Komendant",
        "Illia Dovhopolyi",
        "Dmitrii Kurbatov",
        "Zakhar Naumets",
        "Yuliia Aritkulova",
        "Pavel Kravchenko",
        "Volodymyr Dubinin",
        "Lasha Antadze",
        "Yaroslav Panasenko and Mykhailo Velykodnyi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T15:08:30+00:00",
          "link": "https://arxiv.org/abs/2507.06064v1",
          "size": "306kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T13:49:58+00:00",
          "link": "https://arxiv.org/abs/2507.06064v2",
          "size": "306kb",
          "version": "v2"
        }
      ],
      "title": "Wrapless: The trustless lending protocol on top of Bitcoin",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06064",
        "HTML": "https://arxiv.org/html/2507.06064v2",
        "PDF": "https://arxiv.org/pdf/2507.06064"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a lending protocol on the Bitcoin blockchain, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06446",
      "abstract": "This paper addresses a shortcoming in adaptive control, that the property of a regressor being persistently exciting (PE) is not well-behaved. One can construct regressors that upend the commonsense notion that excitation should not be created out of nothing. To amend the situation, a notion of regularity of regressors is needed. We are naturally led to a broad class of regular regressors that enjoy the property that their excitation is always confined to a subspace, a foundational result called the PE decomposition. A geometric characterization of regressor excitation opens up new avenues for adaptive control, as we demonstrate by formulating a number of new adaptive control problems.",
      "authors": [
        "Erick Mejia Uzeda (1)",
        "Mireille E. Broucke (1) ((1) University of Toronto)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T23:22:25+00:00",
          "link": "https://arxiv.org/abs/2507.06446v1",
          "size": "72kb",
          "version": "v1"
        }
      ],
      "title": "On Regular Regressors in Adaptive Control",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06446",
        "HTML": "https://arxiv.org/html/2507.06446v1",
        "PDF": "https://arxiv.org/pdf/2507.06446"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses issues in adaptive control related to regressors, with no relation to LLM training data processing or dataset engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.12022",
      "abstract": "Existing approaches to mathematical reasoning with large language models (LLMs) rely on Chain-of-Thought (CoT) for generalizability or Tool-Integrated Reasoning (TIR) for precise computation. While efforts have been made to combine these methods, they primarily rely on post-selection or predefined strategies, leaving an open question: whether LLMs can autonomously adapt their reasoning strategy based on their inherent capabilities. In this work, we propose TATA (Teaching LLMs According to Their Aptitude), an adaptive framework that enables LLMs to personalize their reasoning strategy spontaneously, aligning it with their intrinsic aptitude. TATA incorporates base-LLM-aware data selection during supervised fine-tuning (SFT) to tailor training data to the model's unique abilities. This approach equips LLMs to autonomously determine and apply the appropriate reasoning strategy at test time. We evaluate TATA through extensive experiments on six mathematical reasoning benchmarks, using both general-purpose and math-specialized LLMs. Empirical results demonstrate that TATA effectively combines the complementary strengths of CoT and TIR, achieving superior or comparable performance with improved inference efficiency compared to TIR alone. Further analysis underscores the critical role of aptitude-aware data selection in enabling LLMs to make effective and adaptive reasoning decisions and align reasoning strategies with model capabilities.",
      "authors": [
        "Xin Xu",
        "Yan Xu",
        "Tianhao Chen",
        "Yuchen Yan",
        "Chengwu Liu",
        "Zaoyu Chen",
        "Yufei Wang",
        "Yichun Yin",
        "Yasheng Wang",
        "Lifeng Shang",
        "Qun Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-17T16:56:23+00:00",
          "link": "https://arxiv.org/abs/2502.12022v1",
          "size": "428kb",
          "version": "v1"
        },
        {
          "date": "2025-02-26T04:38:54+00:00",
          "link": "https://arxiv.org/abs/2502.12022v2",
          "size": "431kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T03:50:21+00:00",
          "link": "https://arxiv.org/abs/2502.12022v3",
          "size": "430kb",
          "version": "v3"
        }
      ],
      "title": "Teaching LLMs According to Their Aptitude: Adaptive Reasoning for Mathematical Problem Solving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.12022",
        "HTML": "https://arxiv.org/html/2502.12022v3",
        "PDF": "https://arxiv.org/pdf/2502.12022"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper discusses aptitude-aware data selection during supervised fine-tuning, which is a method of tailoring training data to enhance model abilities, aligning it with LLM training data processing methodologies."
      },
      "tasks": [
        "Math",
        "Mathematical Problem-Solving",
        "Mathematical Reasoning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.16029",
      "abstract": "Designing and evaluating microservice scheduling policies is challenging, particularly under dynamic conditions such as complex call-graph dependencies and varying cross-node networking conditions. Moreover, deploying such systems in real-world cloud-edge environments to evaluate scheduling strategies is often impractical due to complexity, cost, and limited accessibility. This highlights the need for an emulation framework that can faithfully emulate the characteristics of the cloud-edge continuum. These characteristics include dynamic topology changes, latency-sensitive service chains, and varying networking conditions, all of which must be accurately modeled for meaningful evaluation. In this work, iDynamics addresses these challenges by providing a configurable and extensible framework that captures the essential dynamics of running microservice applications in cloud-edge environments, enabling systematic development and testing of microservice scheduling strategies. The framework comprises modular components, such as the Graph Dynamics Analyzer, Networking Dynamics Manager, and Scheduling Policy Extender. This enables fine-grained environmental control and facilitates systematic comparisons of different scheduling strategies. Extensive experiments on a real cloud-edge testbed demonstrate that iDynamics effectively captures diverse dynamic scenarios encountered in microservice deployments, offering a robust solution for designing and evaluating different policies under realistic and controllable conditions.",
      "authors": [
        "Ming Chen",
        "Muhammed Tawfiqul Islam",
        "Maria Rodriguez Read",
        "Rajkumar Buyya"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-20T10:52:50+00:00",
          "link": "https://arxiv.org/abs/2503.16029v1",
          "size": "2239kb",
          "version": "v1"
        },
        {
          "date": "2025-03-21T03:03:15+00:00",
          "link": "https://arxiv.org/abs/2503.16029v2",
          "size": "2239kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T08:51:13+00:00",
          "link": "https://arxiv.org/abs/2503.16029v3",
          "size": "3192kb",
          "version": "v3"
        }
      ],
      "title": "iDynamics: A Novel Framework for Evaluating Microservice Scheduling Policies under Controllable Dynamics in Cloud-Edge Continuum",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.16029",
        "HTML": "https://arxiv.org/html/2503.16029v3",
        "PDF": "https://arxiv.org/pdf/2503.16029"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about evaluating microservice scheduling policies under dynamic conditions and does not relate to LLM training data processing or dataset engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06523",
      "abstract": "Video Multimodal Large Language Models (VideoMLLMs) have achieved remarkable progress in both Video-to-Text and Text-to-Video tasks. However, they often suffer fro hallucinations, generating content that contradicts the visual input. Existing evaluation methods are limited to one task (e.g., V2T) and also fail to assess hallucinations in open-ended, free-form responses. To address this gap, we propose FIFA, a unified FaIthFulness evAluation framework that extracts comprehensive descriptive facts, models their semantic dependencies via a Spatio-Temporal Semantic Dependency Graph, and verifies them using VideoQA models. We further introduce Post-Correction, a tool-based correction framework that revises hallucinated content. Extensive experiments demonstrate that FIFA aligns more closely with human judgment than existing evaluation methods, and that Post-Correction effectively improves factual consistency in both text and video generation.",
      "authors": [
        "Liqiang Jing",
        "Viet Lai",
        "Seunghyun Yoon",
        "Trung Bui",
        "Xinya Du"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Computation and Language (cs.CL)",
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T03:51:27+00:00",
          "link": "https://arxiv.org/abs/2507.06523v1",
          "size": "5542kb",
          "version": "v1"
        }
      ],
      "title": "FIFA: Unified Faithfulness Evaluation Framework for Text-to-Video and Video-to-Text Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06523",
        "PDF": "https://arxiv.org/pdf/2507.06523"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes an evaluation framework for text-to-video and video-to-text tasks, focusing on faithfulness evaluation and not on LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2310.06441",
      "abstract": "Relational concept analysis (RCA) is an extension of formal concept analysis allowing to deal with several related contexts simultaneously. It has been designed for learning description logic theories from data and used within various applications. A puzzling observation about RCA is that it returns a single family of concept lattices although, when the data feature circular dependencies, other solutions may be considered acceptable. The semantics of RCA, provided in an operational way, does not shed light on this issue. In this report, we define these acceptable solutions as those families of concept lattices which belong to the space determined by the initial contexts (well-formed), cannot scale new attributes (saturated), and refer only to concepts of the family (self-supported). We adopt a functional view on the RCA process by defining the space of well-formed solutions and two functions on that space: one expansive and the other contractive. We show that the acceptable solutions are the common fixed points of both functions. This is achieved step-by-step by starting from a minimal version of RCA that considers only one single context defined on a space of contexts and a space of lattices. These spaces are then joined into a single space of context-lattice pairs, which is further extended to a space of indexed families of context-lattice pairs representing the objects manippulated by RCA. We show that RCA returns the least element of the set of acceptable solutions. In addition, it is possible to build dually an operation that generates its greatest element. The set of acceptable solutions is a complete sublattice of the interval between these two elements. Its structure and how the defined functions traverse it are studied in detail.",
      "authors": [
        "J\\'er\\^ome Euzenat (MOEX)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2023-10-10T09:13:46+00:00",
          "link": "https://arxiv.org/abs/2310.06441v1",
          "size": "264kb",
          "version": "v1"
        },
        {
          "date": "2024-01-08T14:36:42+00:00",
          "link": "https://arxiv.org/abs/2310.06441v2",
          "size": "278kb",
          "version": "v2"
        },
        {
          "date": "2024-01-09T12:41:53+00:00",
          "link": "https://arxiv.org/abs/2310.06441v3",
          "size": "277kb",
          "version": "v3"
        },
        {
          "date": "2025-07-09T05:01:42+00:00",
          "link": "https://arxiv.org/abs/2310.06441v4",
          "size": "129kb",
          "version": "v4"
        }
      ],
      "title": "Stepwise functional refoundation of relational concept analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2310.06441",
        "HTML": "https://arxiv.org/html/2310.06441v4",
        "PDF": "https://arxiv.org/pdf/2310.06441"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses relational concept analysis and its theoretical framework, which is unrelated to any aspect of LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.06587",
      "abstract": "Nanophotonics, an interdisciplinary field merging nanotechnology and photonics, has enabled transformative advancements across diverse sectors including green energy, biomedicine, and optical computing. This review comprehensively examines recent progress in nanophotonic principles and applications, highlighting key innovations in material design, device engineering, and system integration. In renewable energy, nanophotonic allows light-trapping nanostructures and spectral control in perovskite solar cells, concentrating solar power, and thermophotovoltaics. That have significantly enhanced solar conversion efficiencies, approaching theoretical limits. For biosensing, nanophotonic platforms achieve unprecedented sensitivity in detecting biomolecules, pathogens, and pollutants, enabling real-time diagnostics and environmental monitoring. Medical applications leverage tailored light-matter interactions for precision photothermal therapy, image-guided surgery, and early disease detection. Furthermore, nanophotonics underpins next-generation optical neural networks and neuromorphic computing, offering ultra-fast, energy-efficient alternatives to von Neumann architectures. Despite rapid growth, challenges in scalability, fabrication costs, and material stability persist. Future advancements will rely on novel materials, AI-driven design optimization, and multidisciplinary approaches to enable scalable, low-cost deployment. This review summarizes recent progress and highlights future trends, including novel material systems, multidisciplinary approaches, and enhanced computational capabilities, to pave the way for transformative applications in this rapidly evolving field.",
      "authors": [
        "Osama M. Halawa",
        "Esraa Ahmed",
        "Malk M. Abdelrazek",
        "Yasser M. Nagy",
        "Omar A. M. Abdelraouf"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optics (physics.optics)",
        "Emerging Technologies (cs.ET)",
        "Applied Physics (physics.app-ph)",
        "Medical Physics (physics.med-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T06:37:12+00:00",
          "link": "https://arxiv.org/abs/2507.06587v1",
          "size": "4114kb",
          "version": "v1"
        }
      ],
      "title": "Illuminating the Future: Nanophotonics for Future Green Technologies, Precision Healthcare, and Optical Computing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06587",
        "PDF": "https://arxiv.org/pdf/2507.06587"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on nanophotonics, with applications in fields like green energy, biomedicine, and optical computing, and does not mention or contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.09312",
      "abstract": "Repetitive DNA sequences underpin genome architecture and evolutionary processes, yet they remain challenging to classify accurately. Terrier is a deep learning model designed to overcome these challenges by classifying repetitive DNA sequences using a publicly available, curated repeat sequence library trained under the RepeatMasker schema. Poor representation of taxa within repeat databases often limits the classification accuracy and reproducibility of current repeat annotation methods, limiting our understanding of repeat evolution and function. Terrier overcomes these challenges by leveraging deep learning for improved accuracy. Trained on Repbase, which includes over 100,000 repeat families -- four times more than Dfam -- Terrier maps 97.1% of Repbase sequences to RepeatMasker categories, offering the most comprehensive classification system available. When benchmarked against DeepTE, TERL, and TEclass2 in model organisms (rice, fruit flies, humans, and mice), Terrier achieved superior accuracy while classifying a broader range of sequences. Further validation in non-model amphibian, flatworm and Northern krill genomes highlights its effectiveness in improving classification in non-model species, facilitating research on repeat-driven evolution, genomic instability, and phenotypic variation.",
      "authors": [
        "Robert Turnbull",
        "Neil D. Young",
        "Edoardo Tescari",
        "Lee F. Skerratt",
        "Tiffany A. Kosch"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Genomics (q-bio.GN)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-12T12:03:26+00:00",
          "link": "https://arxiv.org/abs/2503.09312v1",
          "size": "448kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T02:48:47+00:00",
          "link": "https://arxiv.org/abs/2503.09312v2",
          "size": "450kb",
          "version": "v2"
        }
      ],
      "title": "Terrier: A Deep Learning Repeat Classifier",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.09312",
        "HTML": "https://arxiv.org/html/2503.09312v2",
        "PDF": "https://arxiv.org/pdf/2503.09312"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about classifying repetitive DNA sequences with deep learning models and does not address LLM training data processing."
      },
      "tasks": [
        "Deep Learning"
      ],
      "repo_urls": [
        "https://github.com/rbturnbull/terrier"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.06151",
      "abstract": "Imitation learning (IL) has shown promise in robot locomotion but is often limited to learning a single expert policy, constraining behavior diversity and robustness in unpredictable real-world scenarios. To address this, we introduce Quality Diversity Inverse Reinforcement Learning (QD-IRL), a novel framework that integrates quality-diversity optimization with IRL methods, enabling agents to learn diverse behaviors from limited demonstrations. This work introduces Extrinsic Behavioral Curiosity (EBC), which allows agents to receive additional curiosity rewards from an external critic based on how novel the behaviors are with respect to a large behavioral archive. To validate the effectiveness of EBC in exploring diverse locomotion behaviors, we evaluate our method on multiple robot locomotion tasks. EBC improves the performance of QD-IRL instances with GAIL, VAIL, and DiffAIL across all included environments by up to 185%, 42%, and 150%, even surpassing expert performance by 20% in Humanoid. Furthermore, we demonstrate that EBC is applicable to Gradient-Arborescence-based Quality Diversity Reinforcement Learning (QD-RL) algorithms, where it substantially improves performance and provides a generic technique for diverse robot locomotion. The source code of this work is provided at https://github.com/vanzll/EBC.",
      "authors": [
        "Zhenglin Wan",
        "Xingrui Yu",
        "David Mark Bossens",
        "Yueming Lyu",
        "Qing Guo",
        "Flint Xiaofeng Fan",
        "Yew Soon Ong",
        "Ivor Tsang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-08T15:49:33+00:00",
          "link": "https://arxiv.org/abs/2410.06151v1",
          "size": "33315kb",
          "version": "v1"
        },
        {
          "date": "2025-07-06T13:54:02+00:00",
          "link": "https://arxiv.org/abs/2410.06151v2",
          "size": "2662kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T09:55:36+00:00",
          "link": "https://arxiv.org/abs/2410.06151v3",
          "size": "2662kb",
          "version": "v3"
        }
      ],
      "title": "Diversifying Robot Locomotion Behaviors with Extrinsic Behavioral Curiosity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.06151",
        "HTML": "https://arxiv.org/html/2410.06151v3",
        "PDF": "https://arxiv.org/pdf/2410.06151"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on robot locomotion and imitation learning, particularly behavior diversity, with no substantive content related to LLM training data processing."
      },
      "tasks": [
        "continuous-control",
        "Continuous Control",
        "Diversity",
        "Imitation Learning",
        "MuJoCo"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.02505",
      "abstract": "We aim to develop a goal specification method that is semantically clear, spatially sensitive, domain-agnostic, and intuitive for human users to guide agent interactions in 3D environments. Specifically, we propose a novel cross-view goal alignment framework that allows users to specify target objects using segmentation masks from their camera views rather than the agent's observations. We highlight that behavior cloning alone fails to align the agent's behavior with human intent when the human and agent camera views differ significantly. To address this, we introduce two auxiliary objectives: cross-view consistency loss and target visibility loss, which explicitly enhance the agent's spatial reasoning ability. According to this, we develop ROCKET-2, a state-of-the-art agent trained in Minecraft, achieving an improvement in the efficiency of inference 3x to 6x compared to ROCKET-1. We show that ROCKET-2 can directly interpret goals from human camera views, enabling better human-agent interaction. Remarkably, ROCKET-2 demonstrates zero-shot generalization capabilities: despite being trained exclusively on the Minecraft dataset, it can adapt and generalize to other 3D environments like Doom, DMLab, and Unreal through a simple action space mapping.",
      "authors": [
        "Shaofei Cai",
        "Zhancun Mu",
        "Anji Liu",
        "Yitao Liang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-04T11:16:46+00:00",
          "link": "https://arxiv.org/abs/2503.02505v1",
          "size": "25058kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T17:13:26+00:00",
          "link": "https://arxiv.org/abs/2503.02505v2",
          "size": "17753kb",
          "version": "v2"
        }
      ],
      "title": "ROCKET-2: Steering Visuomotor Policy via Cross-View Goal Alignment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.02505",
        "HTML": "https://arxiv.org/html/2503.02505v2",
        "PDF": "https://arxiv.org/pdf/2503.02505"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on developing a goal specification method for agent interactions in 3D environments, rather than on LLM training data processing."
      },
      "models": [
        {
          "model_path": "phython96/ROCKET-2-1.5x-17w",
          "downloads": "21",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/phython96/ROCKET-2-1.5x-17w"
        },
        {
          "model_path": "phython96/ROCKET-2-1x-22w",
          "downloads": "51",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/phython96/ROCKET-2-1x-22w"
        }
      ],
      "tasks": [
        "Minecraft",
        "Spatial Reasoning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.11951",
      "abstract": "This paper introduces SagaLLM, a structured multi-agent architecture designed to address four foundational limitations of current LLM-based planning systems: unreliable self-validation, context loss, lack of transactional safeguards, and insufficient inter-agent coordination. While recent frameworks leverage LLMs for task decomposition and multi-agent communication, they often fail to ensure consistency, rollback, or constraint satisfaction across distributed workflows. SagaLLM bridges this gap by integrating the Saga transactional pattern with persistent memory, automated compensation, and independent validation agents. It leverages LLMs' generative reasoning to automate key tasks traditionally requiring hand-coded coordination logic, including state tracking, dependency analysis, log schema generation, and recovery orchestration. Although SagaLLM relaxes strict ACID guarantees, it ensures workflow-wide consistency and recovery through modular checkpointing and compensable execution. Empirical evaluations across planning domains demonstrate that standalone LLMs frequently violate interdependent constraints or fail to recover from disruptions. In contrast, SagaLLM achieves significant improvements in consistency, validation accuracy, and adaptive coordination under uncertainty, establishing a robust foundation for real-world, scalable LLM-based multi-agent systems.",
      "authors": [
        "Edward Y. Chang",
        "Longling Geng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-15T01:43:03+00:00",
          "link": "https://arxiv.org/abs/2503.11951v1",
          "size": "102kb",
          "version": "v1"
        },
        {
          "date": "2025-03-18T05:00:47+00:00",
          "link": "https://arxiv.org/abs/2503.11951v2",
          "size": "139kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T03:31:59+00:00",
          "link": "https://arxiv.org/abs/2503.11951v3",
          "size": "121kb",
          "version": "v3"
        }
      ],
      "title": "SagaLLM: Context Management, Validation, and Transaction Guarantees for Multi-Agent LLM Planning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.11951",
        "HTML": "https://arxiv.org/html/2503.11951v3",
        "PDF": "https://arxiv.org/pdf/2503.11951"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on multi-agent architecture for LLM planning and coordination, without substantive discussion on training data processing or new dataset creation."
      },
      "tasks": [
        "Decision Making",
        "Management"
      ],
      "repo_urls": [
        "https://github.com/genglongling/SagaLLM"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.05791",
      "abstract": "Graphical user interface (GUI) agents autonomously operate across platforms (e.g., Linux) to complete tasks by interacting with visual elements. Specifically, a user instruction is decomposed into a sequence of action proposals, each corresponding to an interaction with the GUI. After each action, the agent observes the updated GUI environment to plan the next step. However, two main challenges arise: i) resolving ambiguity in task planning (i.e., the action proposal sequence), where selecting an appropriate plan is non-trivial, as many valid ones may exist; ii) accurately grounding actions in complex and high-resolution interfaces, i.e., precisely interacting with visual targets.\n  This paper investigates the two aforementioned challenges with our GUI Test-time Scaling Agent, namely GTA1. First, to select the most appropriate action proposal, we introduce a test-time scaling method. At each step, we sample multiple candidate action proposals and leverage a judge model to evaluate and select the most suitable one. It trades off computation for better decision quality by concurrent sampling, shortening task execution steps, and improving overall performance. Second, we propose a model that achieves improved accuracy when grounding the selected action proposal to its corresponding visual elements. Our key insight is that reinforcement learning (RL) facilitates visual grounding through inherent objective alignments, rewarding successful clicks on interface elements.\n  Experimentally, our method establishes state-of-the-art performance across diverse benchmarks. For example, GTA1-7B achieves 50.1%, 92.4%, and 67.7% accuracies on Screenspot-Pro, Screenspot-V2, and OSWorld-G, respectively. When paired with a planner applying our test-time scaling strategy, it exhibits state-of-the-art agentic performance (e.g., 45.2% task success rate on OSWorld). We open-source our code and models here.",
      "authors": [
        "Yan Yang and Dongxu Li and Yutong Dai and Yuhao Yang and Ziyang Luo and Zirui Zhao and Zhiyuan Hu and Junzhe Huang and Amrita Saha and Zeyuan Chen and Ran Xu and Liyuan Pan and Caiming Xiong and Junnan Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T08:52:18+00:00",
          "link": "https://arxiv.org/abs/2507.05791v1",
          "size": "28450kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T01:16:44+00:00",
          "link": "https://arxiv.org/abs/2507.05791v2",
          "size": "28451kb",
          "version": "v2"
        }
      ],
      "title": "GTA1: GUI Test-time Scaling Agent",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05791",
        "HTML": "https://arxiv.org/html/2507.05791v2",
        "PDF": "https://arxiv.org/pdf/2507.05791"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a GUI agent for task execution rather than any aspect of LLM training data processing. The primary contribution is related to decision-making in GUI interactions."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06415",
      "abstract": "Long-context reasoning requires accurately identifying relevant information in extensive, noisy input contexts. Previous research shows that using test-time learning to encode context directly into model parameters can effectively enable reasoning over noisy information. However, meta-learning methods for enabling test-time learning are prohibitively memory-intensive, preventing their application to long context settings. In this work, we propose PERK (Parameter Efficient Reasoning over Knowledge), a scalable approach for learning to encode long input contexts using gradient updates to a lightweight model adapter at test time. Specifically, PERK employs two nested optimization loops in a meta-training phase. The inner loop rapidly encodes contexts into a low-rank adapter (LoRA) that serves as a parameter-efficient memory module for the base model. Concurrently, the outer loop learns to use the updated adapter to accurately recall and reason over relevant information from the encoded long context. Our evaluations on several long-context reasoning tasks show that PERK significantly outperforms the standard prompt-based long-context baseline, achieving average absolute performance gains of up to 90% for smaller models (GPT-2) and up to 27% for our largest evaluated model, Qwen-2.5-0.5B. In general, PERK is more robust to reasoning complexity, length extrapolation, and the locations of relevant information in contexts. Finally, we show that while PERK is memory-intensive during training, it scales more efficiently at inference time than prompt-based long-context inference.",
      "authors": [
        "Zeming Chen",
        "Angelika Romanou",
        "Gail Weiss",
        "Antoine Bosselut"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T21:38:45+00:00",
          "link": "https://arxiv.org/abs/2507.06415v1",
          "size": "2981kb",
          "version": "v1"
        }
      ],
      "title": "PERK: Long-Context Reasoning as Parameter-Efficient Test-Time Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06415",
        "HTML": "https://arxiv.org/html/2507.06415v1",
        "PDF": "https://arxiv.org/pdf/2507.06415"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses a method for encoding long input contexts for reasoning tasks, which involves an innovative meta-training phase. However, it does not focus specifically on the processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06435",
      "abstract": "Understanding how policy language evolves over time is critical for assessing global responses to complex challenges such as climate change. Temporal analysis helps stakeholders, including policymakers and researchers, to evaluate past priorities, identify emerging themes, design governance strategies, and develop mitigation measures. Traditional approaches, such as manual thematic coding, are time-consuming and limited in capturing the complex, interconnected nature of global policy discourse. With the increasing relevance of unsupervised machine learning, these limitations can be addressed, particularly under high-volume, complex, and high-dimensional data conditions. In this work, we explore a novel approach that applies the dynamic embedded topic model (DETM) to analyze the evolution of global climate policy discourse. A probabilistic model designed to capture the temporal dynamics of topics over time. We collected a corpus of United Nations Framework Convention on Climate Change (UNFCCC) policy decisions from 1995 to 2023, excluding 2020 due to the postponement of COP26 as a result of the COVID-19 pandemic. The model reveals shifts from early emphases on greenhouse gases and international conventions to recent focuses on implementation, technical collaboration, capacity building, finance, and global agreements. Section 3 presents the modeling pipeline, including preprocessing, model training, and visualization of temporal word distributions. Our results show that DETM is a scalable and effective tool for analyzing the evolution of global policy discourse. Section 4 discusses the implications of these findings and we concluded with future directions and refinements to extend this approach to other policy domains.",
      "authors": [
        "Rafiu Adekoya Badekale and Adewale Akinfaderin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T22:30:01+00:00",
          "link": "https://arxiv.org/abs/2507.06435v1",
          "size": "1945kb",
          "version": "v1"
        }
      ],
      "title": "Temporal Analysis of Climate Policy Discourse: Insights from Dynamic Embedded Topic Modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06435",
        "HTML": "https://arxiv.org/html/2507.06435v1",
        "PDF": "https://arxiv.org/pdf/2507.06435"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the temporal analysis of climate policy discourse using dynamic embedded topic modeling, with no discussion of LLM training data collection, processing, or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06674",
      "abstract": "The recent surge in State Space Models (SSMs), particularly the emergence of Mamba, has established them as strong alternatives or complementary modules to Transformers across diverse domains. In this work, we aim to explore the potential of Mamba-based architectures for text-to-music generation. We adopt discrete tokens of Residual Vector Quantization (RVQ) as the modeling representation and empirically find that a single-layer codebook can capture semantic information in music. Motivated by this observation, we focus on modeling a single-codebook representation and adapt SiMBA, originally designed as a Mamba-based encoder, to function as a decoder for sequence modeling. We compare its performance against a standard Transformer-based decoder. Our results suggest that, under limited-resource settings, SiMBA achieves much faster convergence and generates outputs closer to the ground truth. This demonstrates the promise of SSMs for efficient and expressive text-to-music generation. We put audio examples on Github.",
      "authors": [
        "Wei-Jaw Lee",
        "Fang-Chih Hsieh",
        "Xuanjun Chen",
        "Fang-Duo Tsai",
        "Yi-Hsuan Yang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T09:05:18+00:00",
          "link": "https://arxiv.org/abs/2507.06674v1",
          "size": "189kb",
          "version": "v1"
        }
      ],
      "title": "Exploring State-Space-Model based Language Model in Music Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06674",
        "HTML": "https://arxiv.org/html/2507.06674v1",
        "PDF": "https://arxiv.org/pdf/2507.06674"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the use of State Space Models for text-to-music generation, focusing on model architecture and sequence modeling rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06967",
      "abstract": "Physics-Informed Neural Networks (PINNs) are increasingly used to approximate solutions of partial differential equations (PDEs), especially in high dimensions. In real-world applications, data samples are noisy, so it is important to know when a predictor can still achieve low empirical risk. However, little is known about the conditions under which a PINN can do so effectively. We prove a lower bound on the size of neural networks required for the supervised PINN empirical risk to fall below the variance of noisy supervision labels. Specifically, if a predictor achieves an empirical risk $O(\\eta)$ below $\\sigma^2$ (variance of supervision data), then necessarily $d_N\\log d_N\\gtrsim N_s \\eta^2$, where $N_s$ is the number of samples and $d_N$ is the number of trainable parameters of the PINN. A similar constraint applies to the fully unsupervised PINN setting when boundary labels are sampled noisily. Consequently, increasing the number of noisy supervision labels alone does not provide a ``free lunch'' in reducing empirical risk. We also show empirically that PINNs can indeed achieve empirical risks below $\\sigma^2$ under such conditions. As a case study, we investigate PINNs applied to the Hamilton--Jacobi--Bellman (HJB) PDE. Our findings lay the groundwork for quantitatively understanding the parameter requirements for training PINNs in the presence of noise.",
      "authors": [
        "Sebastien Andre-Sloan",
        "Anirbit Mukherjee",
        "Matthew Colbrook"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T15:58:26+00:00",
          "link": "https://arxiv.org/abs/2507.06967v1",
          "size": "72kb",
          "version": "v1"
        }
      ],
      "title": "Noisy PDE Training Requires Bigger PINNs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06967",
        "HTML": "https://arxiv.org/html/2507.06967v1",
        "PDF": "https://arxiv.org/pdf/2507.06967"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates parameter requirements for training physics-informed neural networks with noisy data, unrelated to LLM training data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23921",
      "abstract": "We often attribute human characteristics to large language models (LLMs) and claim that they \"know\" certain things. LLMs have an internal probabilistic knowledge that represents information retained during training. How can we assess the veracity of this knowledge? We examine two common methods for probing the veracity of LLMs and discover several assumptions that are flawed. To address these flawed assumptions, we introduce sAwMIL (short for Sparse Aware Multiple-Instance Learning), a probing method that utilizes the internal activations of LLMs to separate statements into true, false, and neither. sAwMIL is based on multiple-instance learning and conformal prediction. We evaluate sAwMIL on 5 validity criteria across 16 open-source LLMs, including both default and chat-based variants, as well as on 3 new datasets. Among the insights we provide are: (1) the veracity signal is often concentrated in the third quarter of an LLM's depth; (2) truth and falsehood signals are not always symmetric; (3) linear probes perform better on chat models than on default models; (4) nonlinear probes may be required to capture veracity signals for some LLMs with reinforcement learning from human feedback or knowledge distillation; and (5) LLMs capture a third type of signal that is distinct from true and false and is neither true nor false. These findings provide a reliable method for verifying what LLMs \"know\" and how certain they are of their probabilistic internal knowledge.",
      "authors": [
        "Germans Savcisens",
        "Tina Eliassi-Rad"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T14:49:28+00:00",
          "link": "https://arxiv.org/abs/2506.23921v1",
          "size": "38525kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T21:09:56+00:00",
          "link": "https://arxiv.org/abs/2506.23921v2",
          "size": "39477kb",
          "version": "v2"
        }
      ],
      "title": "The Trilemma of Truth in Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23921",
        "HTML": "https://arxiv.org/html/2506.23921v2",
        "PDF": "https://arxiv.org/pdf/2506.23921"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study examines the veracity of information retained by LLMs, involving techniques for probing internal activations but does not focus on the processing of LLM training data."
      },
      "datasets": [
        {
          "dataset_name": "carlomarxx/trilemma-of-truth",
          "downloads": "53",
          "likes": "0",
          "link": "https://huggingface.co/datasets/carlomarxx/trilemma-of-truth"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06243",
      "abstract": "Breast cancer (BC) remains a significant global health challenge, with personalized treatment selection complicated by the disease's molecular and clinical heterogeneity. BC treatment decisions rely on various patient-specific clinical factors, and machine learning (ML) offers a powerful approach to predicting treatment outcomes. This study utilizes The Cancer Genome Atlas (TCGA) breast cancer clinical dataset to develop ML models for predicting the likelihood of undergoing chemotherapy or hormonal therapy. The models are trained using five-fold cross-validation and evaluated through performance metrics, including accuracy, precision, recall, specificity, sensitivity, F1-score, and area under the receiver operating characteristic curve (AUROC). Model uncertainty is assessed using bootstrap techniques, while SHAP values enhance interpretability by identifying key predictors. Among the tested models, the Gradient Boosting Machine (GBM) achieves the highest stable performance (accuracy = 0.7718, AUROC = 0.8252), followed by Extreme Gradient Boosting (XGBoost) (accuracy = 0.7557, AUROC = 0.8044) and Adaptive Boosting (AdaBoost) (accuracy = 0.7552, AUROC = 0.8016). These findings underscore the potential of ML in supporting personalized breast cancer treatment decisions through data-driven insights.",
      "authors": [
        "Md Nahid Hasan",
        "Md Monzur Murshed",
        "Md Mahadi Hasan",
        "and Faysal A. Chowdhury"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Applications (stat.AP)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T18:33:15+00:00",
          "link": "https://arxiv.org/abs/2507.06243v1",
          "size": "353kb",
          "version": "v1"
        }
      ],
      "title": "A Machine Learning Framework for Breast Cancer Treatment Classification Using a Novel Dataset",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06243",
        "HTML": "https://arxiv.org/html/2507.06243v1",
        "PDF": "https://arxiv.org/pdf/2507.06243"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with applying machine learning to a breast cancer treatment dataset, focusing on model development and evaluation rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06877",
      "abstract": "Multi-domain recommendation leverages domain-general knowledge to improve recommendations across several domains. However, as platforms expand to dozens or hundreds of scenarios, training all domains in a unified model leads to performance degradation due to significant inter-domain differences. Existing domain grouping methods, based on business logic or data similarities, often fail to capture the true transfer relationships required for optimal grouping. To effectively cluster domains, we propose Causal Domain Clustering (CDC). CDC models domain transfer patterns within a large number of domains using two distinct effects: the Isolated Domain Affinity Matrix for modeling non-interactive domain transfers, and the Hybrid Domain Affinity Matrix for considering dynamic domain synergy or interference under joint training. To integrate these two transfer effects, we introduce causal discovery to calculate a cohesion-based coefficient that adaptively balances their contributions. A Co-Optimized Dynamic Clustering algorithm iteratively optimizes target domain clustering and source domain selection for training. CDC significantly enhances performance across over 50 domains on public datasets and in industrial settings, achieving a 4.9% increase in online eCPM. Code is available at https://github.com/Chrissie-Law/Causal-Domain-Clustering-for-Multi-Domain-Recommendation",
      "authors": [
        "Huishi Luo",
        "Yiqing Wu",
        "Yiwen Chen",
        "Fuzhen Zhuang",
        "Deqing Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T14:15:47+00:00",
          "link": "https://arxiv.org/abs/2507.06877v1",
          "size": "1091kb",
          "version": "v1"
        }
      ],
      "title": "CDC: Causal Domain Clustering for Multi-Domain Recommendation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06877",
        "HTML": "https://arxiv.org/html/2507.06877v1",
        "PDF": "https://arxiv.org/pdf/2507.06877"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a method for multi-domain recommendation systems, focusing on clustering domains for better recommendations, without detailing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06925",
      "abstract": "We revisit the problem of designing sublinear algorithms for estimating the average degree of an $n$-vertex graph. The standard access model for graphs allows for the following queries: sampling a uniform random vertex, the degree of a vertex, sampling a uniform random neighbor of a vertex, and ``pair queries'' which determine if a pair of vertices form an edge. In this model, original results [Goldreich-Ron, RSA 2008; Eden-Ron-Seshadhri, SIDMA 2019] on this problem prove that the complexity of getting $(1+\\varepsilon)$-multiplicative approximations to the average degree, ignoring $\\varepsilon$-dependencies, is $\\Theta(\\sqrt{n})$. When random edges can be sampled, it is known that the average degree can estimated in $\\widetilde{O}(n^{1/3})$ queries, even without pair queries [Motwani-Panigrahy-Xu, ICALP 2007; Beretta-Tetek, TALG 2024].\n  We give a nearly optimal algorithm in the standard access model with random edge samples. Our algorithm makes $\\widetilde{O}(n^{1/4})$ queries exploiting the power of pair queries. We also analyze the ``full neighborhood access\" model wherein the entire adjacency list of a vertex can be obtained with a single query; this model is relevant in many practical applications. In a weaker version of this model, we give an algorithm that makes $\\widetilde{O}(n^{1/5})$ queries. Both these results underscore the power of {\\em structural queries}, such as pair queries and full neighborhood access queries, for estimating the average degree. We give nearly matching lower bounds, ignoring $\\varepsilon$-dependencies, for all our results.\n  So far, almost all algorithms for estimating average degree assume that the number of vertices, $n$, is known. Inspired by [Beretta-Tetek, TALG 2024], we study this problem when $n$ is unknown and show that structural queries do not help in estimating average degree in this setting.",
      "authors": [
        "Lorenzo Beretta",
        "Deeparnab Chakrabarty",
        "C. Seshadhri"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T15:06:22+00:00",
          "link": "https://arxiv.org/abs/2507.06925v1",
          "size": "86kb",
          "version": "v1"
        }
      ],
      "title": "Faster Estimation of the Average Degree of a Graph Using Random Edges and Structural Queries",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06925",
        "PDF": "https://arxiv.org/pdf/2507.06925"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses algorithms for estimating graph properties and does not address LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2406.17295",
      "abstract": "Predicting properties from coordinate-category data -- sets of vectors paired with categorical information -- is fundamental to computational science. In materials science, this challenge manifests as predicting properties like formation energies or elastic moduli from crystal structures comprising atomic positions (vectors) and element types (categorical information). While large language models (LLMs) have increasingly been applied to such tasks, with researchers encoding structural data as text, optimal strategies for achieving reliable predictions remain elusive. Here, we report fundamental limitations in LLM's ability to learn from coordinate information in coordinate-category data. Through systematic experiments using synthetic datasets with tunable coordinate and category contributions, combined with a comprehensive benchmarking framework (MatText) spanning multiple representations and model scales, we find that LLMs consistently fail to capture coordinate information while excelling at category patterns. This geometric blindness persists regardless of model size (up to 70B parameters), dataset scale (up to 2M structures), or text representation strategy. Our findings suggest immediate practical implications: for materials property prediction tasks dominated by structural effects, specialized geometric architectures consistently outperform LLMs by significant margins, as evidenced by a clear \"GNN-LM wall\" in performance benchmarks. Based on our analysis, we provide concrete guidelines for architecture selection in scientific machine learning, while highlighting the critical importance of understanding model inductive biases when tackling scientific prediction problems.",
      "authors": [
        "Nawaf Alampara",
        "Santiago Miret",
        "Kevin Maik Jablonka"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Materials Science (cond-mat.mtrl-sci)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-25T05:45:07+00:00",
          "link": "https://arxiv.org/abs/2406.17295v1",
          "size": "10687kb",
          "version": "v1"
        },
        {
          "date": "2024-06-28T13:28:04+00:00",
          "link": "https://arxiv.org/abs/2406.17295v2",
          "size": "12294kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T17:37:23+00:00",
          "link": "https://arxiv.org/abs/2406.17295v3",
          "size": "8338kb",
          "version": "v3"
        }
      ],
      "title": "Less can be more for predicting properties with large language models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.17295",
        "PDF": "https://arxiv.org/pdf/2406.17295"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates limitations of LLMs in property prediction from coordinate-category data but does not focus on LLM training data processing techniques or the creation of new data for LLM pretraining or tuning."
      },
      "models": [
        {
          "model_path": "n0w0f/MatText-cifp1-2m",
          "downloads": "8",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/n0w0f/MatText-cifp1-2m"
        },
        {
          "model_path": "n0w0f/MatText-cifsymmetrized-2m",
          "downloads": "20",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/n0w0f/MatText-cifsymmetrized-2m"
        },
        {
          "model_path": "n0w0f/MatText-crystal-txt-llm-2m",
          "downloads": "23",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/n0w0f/MatText-crystal-txt-llm-2m"
        },
        {
          "model_path": "n0w0f/MatText-slices-2m",
          "downloads": "10",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/n0w0f/MatText-slices-2m"
        },
        {
          "model_path": "n0w0f/MatText-zmatrix-2m",
          "downloads": "10",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/n0w0f/MatText-zmatrix-2m"
        },
        {
          "model_path": "n0w0f/MatText-atom-seq-plusplus-2m",
          "downloads": "25",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/n0w0f/MatText-atom-seq-plusplus-2m"
        },
        {
          "model_path": "n0w0f/MatText-atom-seq-2m",
          "downloads": "23",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/n0w0f/MatText-atom-seq-2m"
        }
      ],
      "datasets": [
        {
          "dataset_name": "n0w0f/MatText",
          "downloads": "5431",
          "likes": "7",
          "link": "https://huggingface.co/datasets/n0w0f/MatText"
        }
      ],
      "tasks": [
        "Benchmarking"
      ],
      "repo_urls": [
        "https://github.com/lamalab-org/mattext"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06787",
      "abstract": "This article presents a novel stream function-based navigational control system for obstacle avoidance, where obstacles are represented as two-dimensional (2D) rigid surfaces in inviscid, incompressible flows. The approach leverages the vortex panel method (VPM) and incorporates safety margins to control the stream function and flow properties around virtual surfaces, enabling navigation in complex, partially observed environments using real-time sensing. To address the limitations of the VPM in managing relative distance and avoiding rapidly accelerating obstacles at close proximity, the system integrates a model predictive controller (MPC) based on higher-order control barrier functions (HOCBF). This integration incorporates VPM trajectory generation, state estimation, and constraint handling into a receding-horizon optimization problem. The 2D rigid surfaces are enclosed using minimum bounding ellipses (MBEs), while an adaptive Kalman filter (AKF) captures and predicts obstacle dynamics, propagating these estimates into the MPC-HOCBF for rapid avoidance maneuvers. Evaluation is conducted using a PX4-powered Clover drone Gazebo simulator and real-time experiments involving a COEX Clover quadcopter equipped with a 360 degree LiDAR sensor.",
      "authors": [
        "Sean Smith",
        "Emmanuel Witrant",
        "Ya-Jun Pan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T12:23:30+00:00",
          "link": "https://arxiv.org/abs/2507.06787v1",
          "size": "7550kb",
          "version": "v1"
        }
      ],
      "title": "Stream Function-Based Navigation for Complex Quadcopter Obstacle Avoidance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06787",
        "HTML": "https://arxiv.org/html/2507.06787v1",
        "PDF": "https://arxiv.org/pdf/2507.06787"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a navigation system for quadcopter obstacle avoidance using control methods, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06979",
      "abstract": "Contrastive Learning (CL), a leading paradigm in Self-Supervised Learning (SSL), typically relies on pairs of data views generated through augmentation. While multiple augmentations per instance (more than two) improve generalization in supervised learning, current CL methods handle additional views suboptimally by simply aggregating different pairwise objectives. This approach suffers from four critical limitations: (L1) it utilizes multiple optimization terms per data point resulting to conflicting objectives, (L2) it fails to model all interactions across views and data points, (L3) it inherits fundamental limitations (e.g. alignment-uniformity coupling) from pairwise CL losses, and (L4) it prevents fully realizing the benefits of increased view multiplicity observed in supervised settings. We address these limitations through two novel loss functions: MV-InfoNCE, which extends InfoNCE to incorporate all possible view interactions simultaneously in one term per data point, and MV-DHEL, which decouples alignment from uniformity across views while scaling interaction complexity with view multiplicity. Both approaches are theoretically grounded - we prove they asymptotically optimize for alignment of all views and uniformity, providing principled extensions to multi-view contrastive learning. Our empirical results on ImageNet1K and three other datasets demonstrate that our methods consistently outperform existing multi-view approaches and effectively scale with increasing view multiplicity. We also apply our objectives to multimodal data and show that, in contrast to other contrastive objectives, they can scale beyond just two modalities. Most significantly, ablation studies reveal that MV-DHEL with five or more views effectively mitigates dimensionality collapse by fully utilizing the embedding space, thereby delivering multi-view benefits observed in supervised learning.",
      "authors": [
        "Panagiotis Koromilas",
        "Efthymios Georgiou",
        "Giorgos Bouritsas",
        "Theodoros Giannakopoulos",
        "Mihalis A. Nicolaou",
        "Yannis Panagakis"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T16:07:17+00:00",
          "link": "https://arxiv.org/abs/2507.06979v1",
          "size": "830kb",
          "version": "v1"
        }
      ],
      "title": "A Principled Framework for Multi-View Contrastive Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06979",
        "HTML": "https://arxiv.org/html/2507.06979v1",
        "PDF": "https://arxiv.org/pdf/2507.06979"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses contrastive learning for multi-view data, focusing on new loss functions and their theoretical justifications, without addressing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2109.01629",
      "abstract": "In this paper, we introduce an angle notion called the singular angle for nonlinear systems from an input-output perspective. The proposed system singular angle, based on the angle between $L_2$-signals, describes an upper bound for the ''rotating effect'' from system input to output signals. It quantifies passivity and serves as a counterpart to system $L_2$-gain. It also provides an alternative to a recently defined notion of system phase which adopts complexification of real-valued signals via the Hilbert transform. A nonlinear small angle theorem is established for feedback stability analysis, which involves a comparison of the loop system angle with $\\pi$. The theorem generalizes the classical passivity theorem via a tradeoff between the singular angles of open-loop systems.",
      "authors": [
        "Chao Chen",
        "Di Zhao",
        "Sei Zhen Khong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2021-09-03T17:16:05+00:00",
          "link": "https://arxiv.org/abs/2109.01629v1",
          "size": "116kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T14:14:21+00:00",
          "link": "https://arxiv.org/abs/2109.01629v2",
          "size": "263kb",
          "version": "v2"
        }
      ],
      "title": "The Singular Angle of Nonlinear Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2109.01629",
        "HTML": "https://arxiv.org/html/2109.01629v2",
        "PDF": "https://arxiv.org/pdf/2109.01629"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces the singular angle notion for nonlinear systems but does not relate to LLM training data processing or data engineering operations."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2401.17196",
      "abstract": "In text classification, creating an adversarial example means subtly perturbing a few words in a sentence without changing its meaning, causing it to be misclassified by a classifier. A concerning observation is that a significant portion of adversarial examples generated by existing methods change only one word. This single-word perturbation vulnerability represents a significant weakness in classifiers, which malicious users can exploit to efficiently create a multitude of adversarial examples. This paper studies this problem and makes the following key contributions: (1) We introduce a novel metric \\r{ho} to quantitatively assess a classifier's robustness against single-word perturbation. (2) We present the SP-Attack, designed to exploit the single-word perturbation vulnerability, achieving a higher attack success rate, better preserving sentence meaning, while reducing computation costs compared to state-of-the-art adversarial methods. (3) We propose SP-Defense, which aims to improve \\r{ho} by applying data augmentation in learning. Experimental results on 4 datasets and BERT and distilBERT classifiers show that SP-Defense improves \\r{ho} by 14.6% and 13.9% and decreases the attack success rate of SP-Attack by 30.4% and 21.2% on two classifiers respectively, and decreases the attack success rate of existing attack methods that involve multiple-word perturbations.",
      "authors": [
        "Lei Xu",
        "Sarah Alnegheimish",
        "Laure Berti-Equille",
        "Alfredo Cuesta-Infante",
        "Kalyan Veeramachaneni"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-01-30T17:30:44+00:00",
          "link": "https://arxiv.org/abs/2401.17196v1",
          "size": "1328kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T21:02:09+00:00",
          "link": "https://arxiv.org/abs/2401.17196v2",
          "size": "1025kb",
          "version": "v2"
        }
      ],
      "title": "Single Word Change is All You Need: Designing Attacks and Defenses for Text Classifiers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.17196",
        "HTML": "https://arxiv.org/html/2401.17196v2",
        "PDF": "https://arxiv.org/pdf/2401.17196"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes methods for attacking and defending text classifiers using data augmentation to improve robustness. It briefly involves some data preprocessing (data augmentation) but does not focus on processing LLM training data."
      },
      "tasks": [
        "All",
        "Data Augmentation",
        "Sentence",
        "text-classification",
        "Text Classification"
      ],
      "source": "arXiv"
    },
    {
      "id": "2405.09005",
      "abstract": "In this study, we introduce a novel family of tensor networks, termed constrained matrix product states (MPS), designed to incorporate exactly arbitrary discrete linear constraints, including inequalities, into sparse block structures. These tensor networks are particularly tailored for modeling distributions with support strictly over the feasible space, offering benefits such as reducing the search space in optimization problems, alleviating overfitting, improving training efficiency, and decreasing model size. Central to our approach is the concept of a quantum region, an extension of quantum numbers traditionally used in U(1) symmetric tensor networks, adapted to capture any linear constraint, including the unconstrained scenario. We further develop a novel canonical form for these new MPS, which allow for the merging and factorization of tensor blocks according to quantum region fusion rules and permit optimal truncation schemes. Utilizing this canonical form, we apply an unsupervised training strategy to optimize arbitrary objective functions subject to discrete linear constraints. Our method's efficacy is demonstrated by solving the quadratic knapsack problem, achieving superior performance compared to a leading nonlinear integer programming solver. Additionally, we analyze the complexity and scalability of our approach, demonstrating its potential in addressing complex constrained combinatorial optimization problems.",
      "authors": [
        "Javier Lopez-Piqueres",
        "Jing Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Machine Learning (cs.LG)",
        "Numerical Analysis (cs.NA)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-15T00:13:18+00:00",
          "link": "https://arxiv.org/abs/2405.09005v1",
          "size": "2588kb",
          "version": "v1"
        },
        {
          "date": "2024-06-06T12:29:48+00:00",
          "link": "https://arxiv.org/abs/2405.09005v2",
          "size": "3270kb",
          "version": "v2"
        },
        {
          "date": "2025-01-23T17:21:43+00:00",
          "link": "https://arxiv.org/abs/2405.09005v3",
          "size": "3703kb",
          "version": "v3"
        },
        {
          "date": "2025-04-27T05:50:07+00:00",
          "link": "https://arxiv.org/abs/2405.09005v4",
          "size": "4009kb",
          "version": "v4"
        },
        {
          "date": "2025-07-09T00:36:21+00:00",
          "link": "https://arxiv.org/abs/2405.09005v5",
          "size": "1281kb",
          "version": "v5"
        }
      ],
      "title": "Cons-training Tensor Networks: Embedding and Optimization Over Discrete Linear Constraints",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.09005",
        "HTML": "https://arxiv.org/html/2405.09005v5",
        "PDF": "https://arxiv.org/pdf/2405.09005"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes a novel family of tensor networks for modeling distributions with linear constraints, focused on optimization problems, not LLM training data processing."
      },
      "tasks": [
        "Combinatorial Optimization",
        "Tensor Networks"
      ],
      "repo_urls": [
        "https://github.com/javilopiq/constraintnet.jl"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06878",
      "abstract": "The increasing integration of AI tools in education presents both opportunities and challenges, particularly regarding the development of the students' critical thinking skills. This position paper argues that while AI can support learning, its unchecked use may lead to cognitive atrophy, loss of agency, emotional risks, and ethical concerns, ultimately undermining the core goals of education. Drawing on cognitive science and pedagogy, the paper explores how over-reliance on AI can disrupt meaningful learning, foster dependency and conformity, undermine the students' self-efficacy, academic integrity, and well-being, and raise concerns about questionable privacy practices. It also highlights the importance of considering the students' perspectives and proposes actionable strategies to ensure that AI serves as a meaningful support rather than a cognitive shortcut. The paper advocates for an intentional, transparent, and critically informed use of AI that empowers rather than diminishes the learner.",
      "authors": [
        "Lucile Favero",
        "Juan-Antonio P\\'erez-Ortiz",
        "Tanja K\\\"aser",
        "Nuria Oliver"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T14:15:49+00:00",
          "link": "https://arxiv.org/abs/2507.06878v1",
          "size": "177kb",
          "version": "v1"
        }
      ],
      "title": "Do AI tutors empower or enslave learners? Toward a critical use of AI in education",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06878",
        "HTML": "https://arxiv.org/html/2507.06878v1",
        "PDF": "https://arxiv.org/pdf/2507.06878"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This position paper addresses the impact of AI tutors on education, emphasizing ethical and cognitive aspects, without discussing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06884",
      "abstract": "Virtual testing has emerged as an effective approach to accelerate the deployment of automated driving systems. Nevertheless, existing simulation toolchains encounter difficulties in integrating rapid, automated scenario generation with simulation environments supporting advanced automated driving capabilities. To address this limitation, a full-stack toolchain is presented, enabling automatic scenario generation from real-world datasets and efficient validation through a co-simulation platform based on CarMaker, ROS, and Apollo. The simulation results demonstrate the effectiveness of the proposed toolchain. A demonstration video showcasing the toolchain is available at the provided link: https://youtu.be/taJw_-CmSiY.",
      "authors": [
        "Dong Bi and Yongqi Zhao and Zhengguo Gu and Tomislav Mihalj and Jia Hu and Arno Eichberger"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T14:19:58+00:00",
          "link": "https://arxiv.org/abs/2507.06884v1",
          "size": "2857kb",
          "version": "v1"
        }
      ],
      "title": "Toward a Full-Stack Co-Simulation Platform for Testing of Automated Driving Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06884",
        "HTML": "https://arxiv.org/html/2507.06884v1",
        "PDF": "https://arxiv.org/pdf/2507.06884"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a co-simulation platform for automated driving systems and does not address any aspect of LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07031",
      "abstract": "As AI models become ubiquitous in our daily lives, there has been an increasing demand for transparency in ML services. However, the model owner does not want to reveal the weights, as they are considered trade secrets. To solve this problem, researchers have turned to zero-knowledge proofs of ML model inference. These proofs convince the user that the ML model output is correct, without revealing the weights of the model to the user. Past work on these provers can be placed into two categories. The first method compiles the ML model into a low-level circuit, and proves the circuit using a ZK-SNARK. The second method uses custom cryptographic protocols designed only for a specific class of models. Unfortunately, the first method is highly inefficient, making it impractical for the large models used today, and the second method does not generalize well, making it difficult to update in the rapidly changing field of machine learning. To solve this, we propose ZKTorch, an open source end-to-end proving system that compiles ML models into base cryptographic operations called basic blocks, each proved using specialized protocols. ZKTorch is built on top of a novel parallel extension to the Mira accumulation scheme, enabling succinct proofs with minimal accumulation overhead. These contributions allow ZKTorch to achieve at least a $3\\times$ reduction in the proof size compared to specialized protocols and up to a $6\\times$ speedup in proving time over a general-purpose ZKML framework.",
      "authors": [
        "Bing-Jyue Chen and Lilia Tang and Daniel Kang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T17:03:21+00:00",
          "link": "https://arxiv.org/abs/2507.07031v1",
          "size": "225kb",
          "version": "v1"
        }
      ],
      "title": "ZKTorch: Compiling ML Inference to Zero-Knowledge Proofs via Parallel Proof Accumulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07031",
        "HTML": "https://arxiv.org/html/2507.07031v1",
        "PDF": "https://arxiv.org/pdf/2507.07031"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on compiling ML inference to zero-knowledge proofs via parallel proof accumulation, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07033",
      "abstract": "Contrastive learning (CL) has recently emerged as an alternative to traditional supervised machine learning solutions by enabling rich representations from unstructured and unlabeled data. However, CL and, more broadly, self-supervised learning (SSL) methods often demand a large amount of data and computational resources, posing challenges for deployment on resource-constrained edge devices. In this work, we explore the feasibility and efficiency of SSL techniques for edge-based learning, focusing on trade-offs between model performance and energy efficiency. In particular, we analyze how different SSL techniques adapt to limited computational, data, and energy budgets, evaluating their effectiveness in learning robust representations under resource-constrained settings. Moreover, we also consider the energy costs involved in labeling data and assess how semi-supervised learning may assist in reducing the overall energy consumed to train CL models. Through extensive experiments, we demonstrate that tailored SSL strategies can achieve competitive performance while reducing resource consumption by up to 4X, underscoring their potential for energy-efficient learning at the edge.",
      "authors": [
        "Roberto Pereira",
        "Fernanda Fam\\'a",
        "Asal Rangrazi",
        "Marco Miozzo",
        "Charalampos Kalalas",
        "and Paolo Dini"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T17:03:50+00:00",
          "link": "https://arxiv.org/abs/2507.07033v1",
          "size": "1013kb",
          "version": "v1"
        }
      ],
      "title": "Self-Supervised Learning at the Edge: The Cost of Labeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07033",
        "HTML": "https://arxiv.org/html/2507.07033v1",
        "PDF": "https://arxiv.org/pdf/2507.07033"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores self-supervised learning techniques' efficiency for edge-based learning, with no focus on LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06868",
      "abstract": "We show that the probability distribution of the error exponent in i.i.d. code ensembles over classical-quantum (CQ) channels with arbitrary output states accumulates above a threshold that is strictly larger than the CQ random coding exponent (RCE) at low rates, while coinciding with it at rates close to the mutual information of the channel. This result, combined with the work by Dalai [1] and the recent ones by Renes [2] and Li and Yang [3], implies that the ensemble distribution of error exponents concentrates around the CQ RCE in the high rate regime. Moreover, in the same rate regime the threshold we derive coincides with the ensemble-average of the exponent, that is, the typical random coding (TRC) exponent [4].",
      "authors": [
        "Giuseppe Cocco and Javier Rodr\\'iguez Fonollosa"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T14:09:15+00:00",
          "link": "https://arxiv.org/abs/2507.06868v1",
          "size": "44kb",
          "version": "v1"
        }
      ],
      "title": "On the Error Exponent Distribution of Code Ensembles over Classical-Quantum Channels",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06868",
        "HTML": "https://arxiv.org/html/2507.06868v1",
        "PDF": "https://arxiv.org/pdf/2507.06868"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study focuses on error exponents in code ensembles over classical-quantum channels and does not pertain to LLM training data processing or related data engineering techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06955",
      "abstract": "Accurate cortical surface reconstruction from magnetic resonance imaging (MRI) data is crucial for reliable neuroanatomical analyses. Current methods have to contend with complex cortical geometries, strict topological requirements, and often produce surfaces with overlaps, self-intersections, and topological defects. To overcome these shortcomings, we introduce SimCortex, a deep learning framework that simultaneously reconstructs all brain surfaces (left/right white-matter and pial) from T1-weighted(T1w) MRI volumes while preserving topological properties. Our method first segments the T1w image into a nine-class tissue label map. From these segmentations, we generate subject-specific, collision-free initial surface meshes. These surfaces serve as precise initializations for subsequent multiscale diffeomorphic deformations. Employing stationary velocity fields (SVFs) integrated via scaling-and-squaring, our approach ensures smooth, topology-preserving transformations with significantly reduced surface collisions and self-intersections. Evaluations on standard datasets demonstrate that SimCortex dramatically reduces surface overlaps and self-intersections, surpassing current methods while maintaining state-of-the-art geometric accuracy.",
      "authors": [
        "Kaveh Moradkhani",
        "R Jarrett Rushmore",
        "Sylvain Bouix"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T15:38:38+00:00",
          "link": "https://arxiv.org/abs/2507.06955v1",
          "size": "8573kb",
          "version": "v1"
        }
      ],
      "title": "SimCortex: Collision-free Simultaneous Cortical Surfaces Reconstruction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06955",
        "HTML": "https://arxiv.org/html/2507.06955v1",
        "PDF": "https://arxiv.org/pdf/2507.06955"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "SimCortex introduces a method for cortical surface reconstruction from MRI data, which does not pertain to the processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2308.03952",
      "abstract": "Cloud computing has become popular thanks to the widespread use of Infrastructure as Code (IaC) tools, allowing the community to conveniently manage and configure cloud infrastructure using scripts. However, the scripting process itself does not automatically prevent practitioners from introducing misconfigurations, vulnerabilities, or privacy risks. As a result, ensuring security relies on practitioners understanding and the adoption of explicit policies, guidelines, or best practices. In order to understand how practitioners deal with this problem, in this work, we perform an empirical study analyzing the adoption of IaC scripted security best practices. First, we select and categorize widely recognized Terraform security practices promulgated in the industry for popular cloud providers such as AWS, Azure, and Google Cloud. Next, we assess the adoption of these practices by each cloud provider, analyzing a sample of 812 open-source projects hosted on GitHub. For that, we scan each project configuration files, looking for policy implementation through static analysis (checkov). Additionally, we investigate GitHub measures that might be correlated with adopting these best practices. The category Access policy emerges as the most widely adopted in all providers, while Encryption in rest are the most neglected policies. Regarding GitHub measures correlated with best practice adoption, we observe a positive, strong correlation between a repository number of stars and adopting practices in its cloud infrastructure. Based on our findings, we provide guidelines for cloud practitioners to limit infrastructure vulnerability and discuss further aspects associated with policies that have yet to be extensively embraced within the industry.",
      "authors": [
        "Alexandre Verdet",
        "Mohammad Hamdaqa",
        "Leuson Da Silva",
        "Foutse Khomh"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2023-08-07T23:43:32+00:00",
          "link": "https://arxiv.org/abs/2308.03952v1",
          "size": "2869kb",
          "version": "v1"
        }
      ],
      "title": "Exploring Security Practices in Infrastructure as Code: An Empirical Study",
      "links": {
        "Abstract": "https://arxiv.org/abs/2308.03952",
        "PDF": "https://arxiv.org/pdf/2308.03952"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on security practices in Infrastructure as Code, unrelated to LLM training data processing or creation."
      },
      "repo_urls": [
        "https://github.com/averdet/master-terraform-sec-adoption"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.05167",
      "abstract": "Recent large language models (LLMs) support long contexts ranging from 128K to 1M tokens. A popular method for evaluating these capabilities is the needle-in-a-haystack (NIAH) test, which involves retrieving a \"needle\" (relevant information) from a \"haystack\" (long irrelevant context). Extensions of this approach include increasing distractors, fact chaining, and in-context reasoning. However, in these benchmarks, models can exploit existing literal matches between the needle and haystack to simplify the task. To address this, we introduce NoLiMa, a benchmark extending NIAH with a carefully designed needle set, where questions and needles have minimal lexical overlap, requiring models to infer latent associations to locate the needle within the haystack. We evaluate 13 popular LLMs that claim to support contexts of at least 128K tokens. While they perform well in short contexts (<1K), performance degrades significantly as context length increases. At 32K, for instance, 11 models drop below 50% of their strong short-length baselines. Even GPT-4o, one of the top-performing exceptions, experiences a reduction from an almost-perfect baseline of 99.3% to 69.7%. Our analysis suggests these declines stem from the increased difficulty the attention mechanism faces in longer contexts when literal matches are absent, making it harder to retrieve relevant information. Even models enhanced with reasoning capabilities or CoT prompting struggle to maintain performance in long contexts. We publicly release the dataset and evaluation code at https://github.com/adobe-research/NoLiMa.",
      "authors": [
        "Ali Modarressi",
        "Hanieh Deilamsalehy",
        "Franck Dernoncourt",
        "Trung Bui",
        "Ryan A. Rossi",
        "Seunghyun Yoon",
        "Hinrich Sch\\\"utze"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-07T18:49:46+00:00",
          "link": "https://arxiv.org/abs/2502.05167v1",
          "size": "351kb",
          "version": "v1"
        },
        {
          "date": "2025-03-26T13:23:30+00:00",
          "link": "https://arxiv.org/abs/2502.05167v2",
          "size": "351kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T14:35:23+00:00",
          "link": "https://arxiv.org/abs/2502.05167v3",
          "size": "574kb",
          "version": "v3"
        }
      ],
      "title": "NoLiMa: Long-Context Evaluation Beyond Literal Matching",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.05167",
        "HTML": "https://arxiv.org/html/2502.05167v3",
        "PDF": "https://arxiv.org/pdf/2502.05167"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces NoLiMa, a benchmark for long-context evaluation, and mentions dataset release, but it primarily focuses on model evaluation rather than training data processing."
      },
      "datasets": [
        {
          "dataset_name": "amodaresi/NoLiMa",
          "downloads": "136",
          "likes": "10",
          "link": "https://huggingface.co/datasets/amodaresi/NoLiMa"
        }
      ],
      "tasks": [],
      "repo_urls": [
        "https://github.com/adobe-research/NoLiMa"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06639",
      "abstract": "In digital pathology, whole-slide images (WSIs) are often difficult to handle due to their gigapixel scale, so most approaches train patch encoders via self-supervised learning (SSL) and then aggregate the patch-level embeddings via multiple instance learning (MIL) or slide encoders for downstream tasks. However, patch-level SSL may overlook complex domain-specific features that are essential for biomarker prediction, such as mutation status and molecular characteristics, as SSL methods rely only on basic augmentations selected for natural image domains on small patch-level area. Moreover, SSL methods remain less data efficient than fully supervised approaches, requiring extensive computational resources and datasets to achieve competitive performance. To address these limitations, we present EXAONE Path 2.0, a pathology foundation model that learns patch-level representations under direct slide-level supervision. Using only 37k WSIs for training, EXAONE Path 2.0 achieves state-of-the-art average performance across 10 biomarker prediction tasks, demonstrating remarkable data efficiency.",
      "authors": [
        "Myungjang Pyeon",
        "Janghyeon Lee",
        "Minsoo Lee",
        "Juseung Yun",
        "Hwanil Choi",
        "Jonghyun Kim",
        "Jiwon Kim",
        "Yi Hu",
        "Jongseong Jang",
        "Soonyoung Lee"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T08:09:05+00:00",
          "link": "https://arxiv.org/abs/2507.06639v1",
          "size": "3645kb",
          "version": "v1"
        }
      ],
      "title": "EXAONE Path 2.0: Pathology Foundation Model with End-to-End Supervision",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06639",
        "HTML": "https://arxiv.org/html/2507.06639v1",
        "PDF": "https://arxiv.org/pdf/2507.06639"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The methodology involves training with limited data using a pathology foundation model, hinting at data efficiency improvements, but it centers around domain-specific model training rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06926",
      "abstract": "Non-Fungible Tokens (NFTs) offer a promising mechanism to protect Australian and Indigenous artists' copyright. They represent and transfer the value of artwork in digital form. Before adopting NFTs to protect Australian artwork, we in this paper investigate them empericially. We focus on examining the details of NFT structure. We start from the underlying structure of NFTs to show how they represent copyright for both artists and production owners, as well as how they aim to safeguard or secure the value of digital artworks. We then involve data collection from various types of sources with different storage methods, including on-chain, centralized, and decentralized systems. Based on both metadata and artwork content, we present our analysis and discussion on the following key issues: copyright, security and artist identification. The final results of the evaluation, unfortnately, show that the NFT is NOT ready to protect Australian and Indigenous artists' copyright.",
      "authors": [
        "Ruiqiang Li",
        "Brian Yecies",
        "Qin Wang",
        "Shiping Chen",
        "Jun Shen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Computers and Society (cs.CY)",
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T15:07:17+00:00",
          "link": "https://arxiv.org/abs/2507.06926v1",
          "size": "996kb",
          "version": "v1"
        }
      ],
      "title": "Are NFTs Ready to Keep Australian Artists Engaged?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06926",
        "HTML": "https://arxiv.org/html/2507.06926v1",
        "PDF": "https://arxiv.org/pdf/2507.06926"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on the efficacy of NFTs for protecting artists' copyright, with no relation to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06966",
      "abstract": "Background: Accurate deformable image registration (DIR) is required for contour propagation and dose accumulation in MR-guided adaptive radiotherapy (MRgART). This study trained and evaluated a deep learning DIR method for domain invariant MR-MR registration. Methods: A progressively refined registration and segmentation (ProRSeg) method was trained with 262 pairs of 3T MR simulation scans from prostate cancer patients using weighted segmentation consistency loss. ProRSeg was tested on same- (58 pairs), cross- (72 1.5T MR Linac pairs), and mixed-domain (42 MRSim-MRL pairs) datasets for contour propagation accuracy of clinical target volume (CTV), bladder, and rectum. Dose accumulation was performed for 42 patients undergoing 5-fraction MRgART. Results: ProRSeg demonstrated generalization for bladder with similar Dice Similarity Coefficients across domains (0.88, 0.87, 0.86). For rectum and CTV, performance was domain-dependent with higher accuracy on cross-domain MRL dataset (DSCs 0.89) versus same-domain data. The model's strong cross-domain performance prompted us to study the feasibility of using it for dose accumulation. Dose accumulation showed 83.3% of patients met CTV coverage (D95 >= 40.0 Gy) and bladder sparing (D50 <= 20.0 Gy) constraints. All patients achieved minimum mean target dose (>40.4 Gy), but only 9.5% remained under upper limit (<42.0 Gy). Conclusions: ProRSeg showed reasonable multi-domain MR-MR registration performance for prostate cancer patients with preliminary feasibility for evaluating treatment compliance to clinical constraints.",
      "authors": [
        "Sudharsan Madhavan",
        "Chengcheng Gui",
        "Lando Bosma",
        "Josiah Simeth",
        "Jue Jiang",
        "Nicolas Cote",
        "Nima Hassan Rezaeian",
        "Himanshu Nagar",
        "Victoria Brennan",
        "Neelam Tyagi",
        "Harini Veeraraghavan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Medical Physics (physics.med-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T15:55:32+00:00",
          "link": "https://arxiv.org/abs/2507.06966v1",
          "size": "929kb",
          "version": "v1"
        }
      ],
      "title": "Segmentation Regularized Training for Multi-Domain Deep Learning Registration applied to MR-Guided Prostate Cancer Radiotherapy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06966",
        "PDF": "https://arxiv.org/pdf/2507.06966"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study focuses on deformable image registration for adaptive radiotherapy, which involves domain-specific data analysis rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07002",
      "abstract": "Quantum hashing is a useful technique that allows us to construct memory-efficient algorithms and secure quantum protocols. First, we present a circuit that implements the phase form of quantum hashing using $2^{n-1}$ CNOT gates, where n is the number of control qubits. Our method outperforms existing approaches and reduces the circuit depth. Second, we propose an algorithm that provides a trade-off between the number of CNOT gates (and consequently, the circuit depth) and the precision of rotation angles. This is particularly important in the context of NISQ (Noisy Intermediate-Scale Quantum) devices, where hardware-imposed angle precision limit remains a critical constraint.",
      "authors": [
        "Ilnar Zinnatullin and Kamil Khadiev"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Computational Complexity (cs.CC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T16:32:15+00:00",
          "link": "https://arxiv.org/abs/2507.07002v1",
          "size": "1308kb",
          "version": "v1"
        }
      ],
      "title": "Efficient Algorithms for Quantum Hashing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07002",
        "HTML": "https://arxiv.org/html/2507.07002v1",
        "PDF": "https://arxiv.org/pdf/2507.07002"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on efficient algorithms for quantum hashing and does not pertain to LLM training data processing, data engineering, or creation of datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2310.17170",
      "abstract": "Decoder-only methods, such as GPT, have demonstrated superior performance in many areas compared to traditional encoder-decoder structure transformer methods. Over the years, end-to-end methods based on the traditional transformer structure, like MOTR, have achieved remarkable performance in multi-object tracking. However,the substantial computational resource consumption of these methods, coupled with the optimization challenges posed by dynamic data, results in less favorable inference speeds and training times. To address the aforementioned issues, this paper optimized the network architecture and proposed an effective training strategy to mitigate the problem of prolonged training times, thereby developing DecoderTracker, a novel end-to-end tracking method. Subsequently, to tackle the optimization challenges arising from dynamic data, this paper introduced DecoderTracker+ by incorporating a Fixed-Size Query Memory and refining certain attention layers. Our methods, without any bells and whistles, outperforms MOTR on multiple benchmarks, \\textcolor{black}{featuring a 2 to 3 times faster inference than MOTR}, respectively. The proposed method is implemented in open-source code, accessible at https://github.com/liaopan-lp/MO-YOLO.",
      "authors": [
        "Liao Pan and Yang Feng and Zhao Wenhui and Yua Jinwen and Zhang Dingwen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2023-10-26T05:49:44+00:00",
          "link": "https://arxiv.org/abs/2310.17170v1",
          "size": "1155kb",
          "version": "v1"
        },
        {
          "date": "2024-01-25T12:37:51+00:00",
          "link": "https://arxiv.org/abs/2310.17170v2",
          "size": "6646kb",
          "version": "v2"
        },
        {
          "date": "2024-04-05T10:07:24+00:00",
          "link": "https://arxiv.org/abs/2310.17170v3",
          "size": "9640kb",
          "version": "v3"
        },
        {
          "date": "2024-05-24T03:53:26+00:00",
          "link": "https://arxiv.org/abs/2310.17170v4",
          "size": "4070kb",
          "version": "v4"
        },
        {
          "date": "2025-06-14T09:48:28+00:00",
          "link": "https://arxiv.org/abs/2310.17170v5",
          "size": "8895kb",
          "version": "v5"
        },
        {
          "date": "2025-07-09T02:15:44+00:00",
          "link": "https://arxiv.org/abs/2310.17170v6",
          "size": "9352kb",
          "version": "v6"
        }
      ],
      "title": "DecoderTracker: Decoder-Only Method for Multiple-Object Tracking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2310.17170",
        "HTML": "https://arxiv.org/html/2310.17170",
        "PDF": "https://arxiv.org/pdf/2310.17170"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a method for optimizing network architecture for multi-object tracking with decoder-only methods. It does not discuss LLM training data processing."
      },
      "tasks": [
        "Decoder",
        "Multi-Object Tracking",
        "Multiple Object Tracking",
        "Object",
        "object-detection",
        "Object Detection",
        "Object Tracking"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06342",
      "abstract": "We present SymFlux, a novel deep learning framework that performs symbolic regression to identify Hamiltonian functions from their corresponding vector fields on the standard symplectic plane. SymFlux models utilize hybrid CNN-LSTM architectures to learn and output the symbolic mathematical expression of the underlying Hamiltonian. Training and validation are conducted on newly developed datasets of Hamiltonian vector fields, a key contribution of this work. Our results demonstrate the model's effectiveness in accurately recovering these symbolic expressions, advancing automated discovery in Hamiltonian mechanics.",
      "authors": [
        "M.A. Evangelista-Alvarado",
        "P. Su\\'arez-Serrato"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Dynamical Systems (math.DS)",
        "Symplectic Geometry (math.SG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T19:07:16+00:00",
          "link": "https://arxiv.org/abs/2507.06342v1",
          "size": "1536kb",
          "version": "v1"
        }
      ],
      "title": "SymFlux: deep symbolic regression of Hamiltonian vector fields",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06342",
        "HTML": "https://arxiv.org/html/2507.06342v1",
        "PDF": "https://arxiv.org/pdf/2507.06342"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on symbolic regression to identify Hamiltonian functions. It discusses model architecture and does not involve LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06427",
      "abstract": "Large Language Models (LLMs) are traditionally viewed as black-box algorithms, therefore reducing trustworthiness and obscuring potential approaches to increasing performance on downstream tasks. In this work, we apply an effective LLM decomposition method using a dictionary-learning approach with sparse autoencoders. This helps extract monosemantic features from polysemantic LLM neurons. Remarkably, our work identifies model-internal misunderstanding, allowing the automatic reformulation of the prompts with additional annotations to improve the interpretation by LLMs. Moreover, this approach demonstrates a significant performance improvement in downstream tasks, such as mathematical reasoning and metaphor detection.",
      "authors": [
        "Shun Wang",
        "Tyler Loakman",
        "Youbo Lei",
        "Yi Liu",
        "Bohao Yang",
        "Yuting Zhao",
        "Dong Yang",
        "Chenghua Lin"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T22:17:52+00:00",
          "link": "https://arxiv.org/abs/2507.06427v1",
          "size": "8054kb",
          "version": "v1"
        }
      ],
      "title": "Exploring Task Performance with Interpretable Models via Sparse Auto-Encoders",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06427",
        "PDF": "https://arxiv.org/pdf/2507.06427"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper discusses improving model interpretation with sparse autoencoders, the primary focus is on enhancing performance on downstream tasks, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06593",
      "abstract": "In HDR video reconstruction, exposure fluctuations in reference images from alternating exposure methods often result in flickering. To address this issue, we propose a dual-camera system (DCS) for HDR video acquisition, where one camera is assigned to capture consistent reference sequences, while the other is assigned to capture non-reference sequences for information supplementation. To tackle the challenges posed by video data, we introduce an exposure-adaptive fusion network (EAFNet) to achieve more robust results. EAFNet introduced a pre-alignment subnetwork to explore the influence of exposure, selectively emphasizing the valuable features across different exposure levels. Then, the enhanced features are fused by the asymmetric cross-feature fusion subnetwork, which explores reference-dominated attention maps to improve image fusion by aligning cross-scale features and performing cross-feature fusion. Finally, the reconstruction subnetwork adopts a DWT-based multiscale architecture to reduce ghosting artifacts and refine features at different resolutions. Extensive experimental evaluations demonstrate that the proposed method achieves state-of-the-art performance on different datasets, validating the great potential of the DCS in HDR video reconstruction. The codes and data captured by DCS will be available at https://github.com/zqqqyu/DCS.",
      "authors": [
        "Qianyu Zhang",
        "Bolun Zheng",
        "Hangjia Pan",
        "Lingyu Zhu",
        "Zunjie Zhu",
        "Zongpeng Li",
        "Shiqi Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T07:09:42+00:00",
          "link": "https://arxiv.org/abs/2507.06593v1",
          "size": "22697kb",
          "version": "v1"
        }
      ],
      "title": "Capturing Stable HDR Videos Using a Dual-Camera System",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06593",
        "HTML": "https://arxiv.org/html/2507.06593v1",
        "PDF": "https://arxiv.org/pdf/2507.06593"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes capturing HDR videos using a dual-camera system and does not relate to LLM training data processing or data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06864",
      "abstract": "Digital work environments in IT and knowledge-based sectors demand high levels of attention management, task juggling, and self-regulation. For adults with ADHD, these settings often amplify challenges such as time blindness, digital distraction, emotional reactivity, and executive dysfunction. These individuals prefer low-touch, easy-to-use interventions for daily tasks. Conventional productivity tools often fail to support the cognitive variability and overload experienced by neurodivergent professionals. This paper presents a framework that blends Systems Thinking, Human-in-the-Loop design, AI/ML, and privacy-first adaptive agents to support ADHD-affected users. The assistant senses tab usage, application focus, and inactivity using on-device ML. These cues are used to infer attention states and deliver nudges, reflective prompts, or accountability-based presence (body doubling) that aid regulation without disruption. Technically grounded in AI, the approach views attention as shaped by dynamic feedback loops. The result is a replicable model for adaptive, inclusive support tools in high-distraction work environments.",
      "authors": [
        "Raghavendra Deshmukh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T14:05:13+00:00",
          "link": "https://arxiv.org/abs/2507.06864v1",
          "size": "524kb",
          "version": "v1"
        }
      ],
      "title": "Toward Neurodivergent-Aware Productivity: A Systems and AI-Based Human-in-the-Loop Framework for ADHD-Affected Professionals",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06864",
        "HTML": "https://arxiv.org/html/2507.06864v1",
        "PDF": "https://arxiv.org/pdf/2507.06864"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a framework for ADHD professionals using AI/ML for adaptive support in digital work environments, with no focus on LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.19960",
      "abstract": "Recent advances in deep learning have revolutionized seismic monitoring, yet developing a foundation model that performs well across multiple complex tasks remains challenging, particularly when dealing with degraded signals or data scarcity. This work presents SeisMoLLM, the first foundation model that utilizes cross-modal transfer for seismic monitoring, to unleash the power of large-scale pre-training from a large language model without requiring direct pre-training on seismic datasets. Through elaborate waveform tokenization and fine-tuning of pre-trained GPT-2 model, SeisMoLLM achieves state-of-the-art performance on the DiTing and STEAD datasets across five critical tasks: back-azimuth estimation, epicentral distance estimation, magnitude estimation, phase picking, and first-motion polarity classification. It attains 36 best results out of 43 task metrics and 12 top scores out of 16 few-shot generalization metrics, with many relative improvements ranging from 10% to 50%. In addition to its superior performance, SeisMoLLM maintains efficiency comparable to or even better than lightweight models in both training and inference. These findings establish SeisMoLLM as a promising foundation model for practical seismic monitoring and highlight cross-modal transfer as an exciting new direction for earthquake studies, showcasing the potential of advanced deep learning techniques to propel seismology research forward.",
      "authors": [
        "Xinghao Wang",
        "Feng Liu",
        "Rui Su",
        "Zhihui Wang",
        "Lihua Fang",
        "Lianqing Zhou",
        "Lei Bai",
        "Wanli Ouyang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-27T10:35:53+00:00",
          "link": "https://arxiv.org/abs/2502.19960v1",
          "size": "3098kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T07:08:00+00:00",
          "link": "https://arxiv.org/abs/2502.19960v2",
          "size": "2392kb",
          "version": "v2"
        }
      ],
      "title": "SeisMoLLM: Advancing Seismic Monitoring via Cross-modal Transfer with Pre-trained Large Language Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.19960",
        "HTML": "https://arxiv.org/html/2502.19960v2",
        "PDF": "https://arxiv.org/pdf/2502.19960"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper presents SeisMoLLM, which involves cross-modal transfer for seismic monitoring. Although it leverages pre-trained LLMs, it does not focus on LLM training data processing techniques."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Large Language Model"
      ],
      "repo_urls": [
        "https://github.com/StarMoonWang/SeisMoLLM"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06393",
      "abstract": "We show that head functions on syntactic objects extend the magma structure to a hypermagma, with the c-command relation compatible with the magma operation and the m-command relation with the hypermagma. We then show that the structure of head and complement and specifier, additional modifier positions, and the structure of phases in the Extended Projection can be formulated as a bud generating system of a colored operad, in a form similar to the structure of theta roles. We also show that, due to the special form of the colored operad generators, the filtering of freely generated syntactic objects by these coloring rules can be equivalently formulated as a filtering in the course of structure formation via a colored Merge, which can in turn be related to the hypermagma structure. The rules on movement by Internal Merge with respect to phases, the Extended Projection Principle, Empty Category Principle, and Phase Impenetrability Condition are all subsumed into the form of the colored operad generators. Movement compatibilities between the phase structure and the theta roles assignments can then be formulated in terms of the respective colored operads and a transduction of colored operads.",
      "authors": [
        "Matilde Marcolli",
        "Riny Huijbregts",
        "Richard K. Larson"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Quantum Algebra (math.QA)",
        "Rings and Algebras (math.RA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T21:01:13+00:00",
          "link": "https://arxiv.org/abs/2507.06393v1",
          "size": "48kb",
          "version": "v1"
        }
      ],
      "title": "Hypermagmas and Colored Operads: Heads, Phases, and Theta Roles",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06393",
        "PDF": "https://arxiv.org/pdf/2507.06393"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper's focus on syntactic structures and conceptual frameworks like hypermagmas and operads does not address LLM training data processing or any related data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06484",
      "abstract": "Despite large-scale pretraining endowing models with language and vision reasoning capabilities, improving their spatial reasoning capability remains challenging due to the lack of data grounded in the 3D world. While it is possible for humans to manually create immersive and interactive worlds through 3D graphics, as seen in applications such as VR, gaming, and robotics, this process remains highly labor-intensive. In this paper, we propose a scalable method for generating high-quality 3D environments that can serve as training data for foundation models. We recast 3D environment building as a sequential decision-making problem, employing Vision-Language-Models (VLMs) as policies that output actions to jointly craft a 3D environment's layout, materials, lighting, and assets. Our proposed framework, 3D-Generalist, trains VLMs to generate more prompt-aligned 3D environments via self-improvement fine-tuning. We demonstrate the effectiveness of 3D-Generalist and the proposed training strategy in generating simulation-ready 3D environments. Furthermore, we demonstrate its quality and scalability in synthetic data generation by pretraining a vision foundation model on the generated data. After fine-tuning the pre-trained model on downstream tasks, we show that it surpasses models pre-trained on meticulously human-crafted synthetic data and approaches results achieved with real data orders of magnitude larger.",
      "authors": [
        "Fan-Yun Sun",
        "Shengguang Wu",
        "Christian Jacobsen",
        "Thomas Yim",
        "Haoming Zou",
        "Alex Zook",
        "Shangru Li",
        "Yu-Hsin Chou",
        "Ethem Can",
        "Xunlei Wu",
        "Clemens Eppner",
        "Valts Blukis",
        "Jonathan Tremblay",
        "Jiajun Wu",
        "Stan Birchfield",
        "Nick Haber"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T02:00:17+00:00",
          "link": "https://arxiv.org/abs/2507.06484v1",
          "size": "32418kb",
          "version": "v1"
        }
      ],
      "title": "3D-Generalist: Self-Improving Vision-Language-Action Models for Crafting 3D Worlds",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06484",
        "HTML": "https://arxiv.org/html/2507.06484v1",
        "PDF": "https://arxiv.org/pdf/2507.06484"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper introduces a scalable method for generating 3D environments as training data, detailing a framework for synthetic data creation to improve model pretraining, aligning well with LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06906",
      "abstract": "Semantic scene understanding, including the perception and classification of moving agents, is essential to enabling safe and robust driving behaviours of autonomous vehicles. Cameras and LiDARs are commonly used for semantic scene understanding. However, both sensor modalities face limitations in adverse weather and usually do not provide motion information. Radar sensors overcome these limitations and directly offer information about moving agents by measuring the Doppler velocity, but the measurements are comparably sparse and noisy. In this paper, we address the problem of panoptic segmentation in sparse radar point clouds to enhance scene understanding. Our approach, called SemRaFiner, accounts for changing density in sparse radar point clouds and optimizes the feature extraction to improve accuracy. Furthermore, we propose an optimized training procedure to refine instance assignments by incorporating a dedicated data augmentation. Our experiments suggest that our approach outperforms state-of-the-art methods for radar-based panoptic segmentation.",
      "authors": [
        "Matthias Zeller",
        "Daniel Casado Herraez",
        "Bengisu Ayan",
        "Jens Behley",
        "Michael Heidingsfeld",
        "Cyrill Stachniss"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T14:45:18+00:00",
          "link": "https://arxiv.org/abs/2507.06906v1",
          "size": "8271kb",
          "version": "v1"
        }
      ],
      "title": "SemRaFiner: Panoptic Segmentation in Sparse and Noisy Radar Point Clouds",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06906",
        "PDF": "https://arxiv.org/pdf/2507.06906"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on panoptic segmentation in sparse radar point clouds, with no discussion on LLM training data processing or dataset creation for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06946",
      "abstract": "Device-to-Device (D2D) communication is a promising solution to meet the growing demands of 5G and future 6G networks by enabling direct communication between user devices. It enhances spectral efficiency (SE) and energy efficiency (EE), reduces latency, and supports proximity-based services. As wireless systems evolve toward 5G and 6G paradigms, the integration of D2D with advanced cellular technologies introduces new opportunities and challenges. This survey paper reviews the architectural foundations of D2D communication and explores its integration with key 5G/6G enabling technologies. We review standardization efforts, analyze core challenges, and highlight future research directions to unlock the full potential of D2D in next-generation wireless networks.",
      "authors": [
        "Mohammad Reza Fasihi and Brian L. Mark"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T15:29:09+00:00",
          "link": "https://arxiv.org/abs/2507.06946v1",
          "size": "7288kb",
          "version": "v1"
        }
      ],
      "title": "Device-to-Device Communication in 5G/6G: Architectural Foundations and Convergence with Enabling Technologies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06946",
        "HTML": "https://arxiv.org/html/2507.06946v1",
        "PDF": "https://arxiv.org/pdf/2507.06946"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The work is a survey on device-to-device communication in 5G/6G networks, without any content related to LLM training data processing or data engineering methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06378",
      "abstract": "While tokenization is a key step in language modeling, with effects on model training and performance, it remains unclear how to effectively evaluate tokenizer quality. One proposed dimension of tokenizer quality is the extent to which tokenizers preserve linguistically meaningful subwords, aligning token boundaries with morphological boundaries within a word. We expand MorphScore (Arnett & Bergen, 2025), which previously covered 22 languages, to support a total of 70 languages. The updated MorphScore offers more flexibility in evaluation and addresses some of the limitations of the original version. We then correlate our alignment scores with downstream task performance for five pre-trained languages models on seven tasks, with at least one task in each of the languages in our sample. We find that morphological alignment does not explain very much variance in model performance, suggesting that morphological alignment alone does not measure dimensions of tokenization quality relevant to model performance.",
      "authors": [
        "Catherine Arnett",
        "Marisa Hudspeth",
        "Brendan O'Connor"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T20:32:26+00:00",
          "link": "https://arxiv.org/abs/2507.06378v1",
          "size": "472kb",
          "version": "v1"
        }
      ],
      "title": "Evaluating Morphological Alignment of Tokenizers in 70 Languages",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06378",
        "HTML": "https://arxiv.org/html/2507.06378v1",
        "PDF": "https://arxiv.org/pdf/2507.06378"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The abstract focuses on evaluating tokenizers across multiple languages, which involves LLM tokenization processes\u2014a part of data preprocessing. However, it does not focus primarily on data processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07048",
      "abstract": "Large Multimodal Models (LMMs) are increasingly applied to meal images for nutrition analysis. However, existing work primarily evaluates proprietary models, such as GPT-4. This leaves the broad range of LLMs underexplored. Additionally, the influence of integrating contextual metadata and its interaction with various reasoning modifiers remains largely uncharted. This work investigates how interpreting contextual metadata derived from GPS coordinates (converted to location/venue type), timestamps (transformed into meal/day type), and the food items present can enhance LMM performance in estimating key nutritional values. These values include calories, macronutrients (protein, carbohydrates, fat), and portion sizes. We also introduce ACETADA, a new food-image dataset slated for public release. This open dataset provides nutrition information verified by the dietitian and serves as the foundation for our analysis. Our evaluation across eight LMMs (four open-weight and four closed-weight) first establishes the benefit of contextual metadata integration over straightforward prompting with images alone. We then demonstrate how this incorporation of contextual information enhances the efficacy of reasoning modifiers, such as Chain-of-Thought, Multimodal Chain-of-Thought, Scale Hint, Few-Shot, and Expert Persona. Empirical results show that integrating metadata intelligently, when applied through straightforward prompting strategies, can significantly reduce the Mean Absolute Error (MAE) and Mean Absolute Percentage Error (MAPE) in predicted nutritional values. This work highlights the potential of context-aware LMMs for improved nutrition analysis.",
      "authors": [
        "Bruce Coburn",
        "Jiangpeng He",
        "Megan E. Rollo",
        "Satvinder S. Dhaliwal",
        "Deborah A. Kerr and Fengqing Zhu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T17:10:33+00:00",
          "link": "https://arxiv.org/abs/2507.07048v1",
          "size": "27135kb",
          "version": "v1"
        }
      ],
      "title": "Evaluating Large Multimodal Models for Nutrition Analysis: A Benchmark Enriched with Contextual Metadata",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07048",
        "HTML": "https://arxiv.org/html/2507.07048v1",
        "PDF": "https://arxiv.org/pdf/2507.07048"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a new dataset (ACETADA) enhanced with contextual metadata for nutrition analysis but primarily focuses on evaluation and model performance, without substantial emphasis on general LLM training data processing methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06376",
      "abstract": "Over the last few years, Large Language Models (LLMs) have emerged as a valuable tool for Electronic Design Automation (EDA). State-of-the-art research in LLM-aided design has demonstrated the ability of LLMs to generate syntactically correct RTL code, showcasing encouraging prospects for integrating AI into the hardware design process. A key enabler of these advancements is the availability of high-quality benchmarks to evaluate new approaches. However, existing datasets and benchmarks fall short of system-level design, as they focus primarily on component-level information and low-complexity designs. To address this gap, we introduce the System-Level Design Benchmark (SLDB), a dataset tailored for evaluating LLMs in system-level integration and configuration tasks. SLDB includes a curated benchmark suite of 10 baseline SoC designs, whose components can be combined into an exponential number of distinct tile-based SoCs through a synthetic library. The dataset provides full SoC configurations, accelerator integration code, communication parameters, and accelerator-aware system configurations, along with testing-application code, compatible with the ESP platform[1].",
      "authors": [
        "Elisavet Lydia Alvanaki",
        "Kevin Lee",
        "Luca P. Carloni"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T20:27:08+00:00",
          "link": "https://arxiv.org/abs/2507.06376v1",
          "size": "1143kb",
          "version": "v1"
        }
      ],
      "title": "SLDB: An End-To-End Heterogeneous System-on-Chip Benchmark Suite for LLM-Aided Design",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06376",
        "HTML": "https://arxiv.org/html/2507.06376v1",
        "PDF": "https://arxiv.org/pdf/2507.06376"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a benchmark suite for evaluating LLMs in system-level integration for hardware design, but it does not contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06469",
      "abstract": "Graph representation learning has become a mainstream method for fraud detection due to its strong expressive power, which focuses on enhancing node representations through improved neighborhood knowledge capture. However, the focus on local interactions leads to imbalanced transmission of global topological information and increased risk of node-specific information being overwhelmed during aggregation due to the imbalance between fraud and benign nodes. In this paper, we first summarize the impact of topology and class imbalance on downstream tasks in GNN-based fraud detection, as the problem of imbalanced supervisory messages is caused by fraudsters' topological behavior obfuscation and identity feature concealment. Based on statistical validation, we propose a novel dual-view graph representation learning method to mitigate Message imbalance in Fraud Detection(MimbFD). Specifically, we design a topological message reachability module for high-quality node representation learning to penetrate fraudsters' camouflage and alleviate insufficient propagation. Then, we introduce a local confounding debiasing module to adjust node representations, enhancing the stable association between node representations and labels to balance the influence of different classes. Finally, we conducted experiments on three public fraud datasets, and the results demonstrate that MimbFD exhibits outstanding performance in fraud detection.",
      "authors": [
        "Yudan Song",
        "Yuecen Wei",
        "Yuhang Lu",
        "Qingyun Sun",
        "Minglai Shao",
        "Li-e Wang",
        "Chunming Hu",
        "Xianxian Li",
        "Xingcheng Fu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T01:00:55+00:00",
          "link": "https://arxiv.org/abs/2507.06469v1",
          "size": "6119kb",
          "version": "v1"
        }
      ],
      "title": "Mitigating Message Imbalance in Fraud Detection with Dual-View Graph Representation Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06469",
        "HTML": "https://arxiv.org/html/2507.06469v1",
        "PDF": "https://arxiv.org/pdf/2507.06469"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on graph representation learning for fraud detection, addressing issues related to topological behavior and node representation. It does not discuss any data processing techniques related to LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06500",
      "abstract": "Due to the broadcast nature of wireless communications, physical-layer security has attracted increasing concerns from both academia and industry. Artificial noise (AN), as one of the promising physical-layer security techniques, is capable of utilizing the spatial degree-of-freedom of channels to effectively enhance the security of wireless communications. In contrast to other physicallayer security techniques, the key distinguishing feature of AN is to generate specific interfering signals according to channel characteristics, increasing the secrecy capacity by reducing the wiretap channel capacity without affecting the legitimate channel capacity. Hence, this paper provides the latest survey of AN, including its evolution, modeling, backgrounds, applications, and future trends. Initially, we introduce the development, fundamentals, and backgrounds of AN. Subsequently, we highlight a comprehensive survey of the current state of research on various AN-empowered scenarios and AN-combined technologies. Finally, we discuss some technical challenges to tackle for AN-aided wireless security in the future.",
      "authors": [
        "Hong Niu",
        "Yue Xiao",
        "Xia Lei",
        "Jiangong Chen",
        "Zhihan Xiao",
        "Mao Li",
        "and Chau Yuen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T02:54:05+00:00",
          "link": "https://arxiv.org/abs/2507.06500v1",
          "size": "2250kb",
          "version": "v1"
        }
      ],
      "title": "A Survey on Artificial Noise for Physical Layer Security: Opportunities, Technologies, Guidelines, Advances, and Trends",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06500",
        "HTML": "https://arxiv.org/html/2507.06500v1",
        "PDF": "https://arxiv.org/pdf/2507.06500"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is a survey on artificial noise for physical layer security in wireless communications, with no focus on LLM training data or its processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06625",
      "abstract": "Deep reinforcement learning has shown remarkable success in continuous control tasks, yet often requires extensive training data, struggles with complex, long-horizon planning, and fails to maintain safety constraints during operation. Meanwhile, Model Predictive Control (MPC) offers explainability and constraint satisfaction, but typically yields only locally optimal solutions and demands careful cost function design. This paper introduces the Q-guided STein variational model predictive Actor-Critic (Q-STAC), a novel framework that bridges these approaches by integrating Bayesian MPC with actor-critic reinforcement learning through constrained Stein Variational Gradient Descent (SVGD). Our method optimizes control sequences directly using learned Q-values as objectives, eliminating the need for explicit cost function design while leveraging known system dynamics to enhance sample efficiency and ensure control signals remain within safe boundaries. Extensive experiments on 2D navigation and robotic manipulation tasks demonstrate that Q-STAC achieves superior sample efficiency, robustness, and optimality compared to state-of-the-art algorithms, while maintaining the high expressiveness of policy distributions. Experiment videos are available on our website: https://sites.google.com/view/q-stac",
      "authors": [
        "Shizhe Cai",
        "Jayadeep Jacob",
        "Zeya Yin",
        "Fabio Ramos"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T07:53:53+00:00",
          "link": "https://arxiv.org/abs/2507.06625v1",
          "size": "3691kb",
          "version": "v1"
        }
      ],
      "title": "Q-STAC: Q-Guided Stein Variational Model Predictive Actor-Critic",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06625",
        "HTML": "https://arxiv.org/html/2507.06625v1",
        "PDF": "https://arxiv.org/pdf/2507.06625"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on deep reinforcement learning framework which integrates MPC with actor-critic learning, unrelated to LLM training data processing or data quality improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06905",
      "abstract": "Loco-Manipulation for humanoid robots aims to enable robots to integrate mobility with upper-body tracking capabilities. Most existing approaches adopt hierarchical architectures that decompose control into isolated upper-body (manipulation) and lower-body (locomotion) policies. While this decomposition reduces training complexity, it inherently limits coordination between subsystems and contradicts the unified whole-body control exhibited by humans. We demonstrate that a single unified policy can achieve a combination of tracking accuracy, large workspace, and robustness for humanoid loco-manipulation. We propose the Unified Loco-Manipulation Controller (ULC), a single-policy framework that simultaneously tracks root velocity, root height, torso rotation, and dual-arm joint positions in an end-to-end manner, proving the feasibility of unified control without sacrificing performance. We achieve this unified control through key technologies: sequence skill acquisition for progressive learning complexity, residual action modeling for fine-grained control adjustments, command polynomial interpolation for smooth motion transitions, random delay release for robustness to deploy variations, load randomization for generalization to external disturbances, and center-of-gravity tracking for providing explicit policy gradients to maintain stability. We validate our method on the Unitree G1 humanoid robot with 3-DOF (degrees-of-freedom) waist. Compared with strong baselines, ULC shows better tracking performance to disentangled methods and demonstrating larger workspace coverage. The unified dual-arm tracking enables precise manipulation under external loads while maintaining coordinated whole-body control for complex loco-manipulation tasks.",
      "authors": [
        "Wandong Sun",
        "Luying Feng",
        "Baoshi Cao",
        "Yang Liu",
        "Yaochu Jin",
        "Zongwu Xie"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T14:44:52+00:00",
          "link": "https://arxiv.org/abs/2507.06905v1",
          "size": "9702kb",
          "version": "v1"
        }
      ],
      "title": "ULC: A Unified and Fine-Grained Controller for Humanoid Loco-Manipulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06905",
        "HTML": "https://arxiv.org/html/2507.06905v1",
        "PDF": "https://arxiv.org/pdf/2507.06905"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on creating a unified control policy for humanoid robots, which is unrelated to the processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2407.10174",
      "abstract": "Building on Whitney's classical method of triangulating smooth manifolds, we show that every compact $d$-dimensional smooth manifold admits a triangulation with dual graph of twin-width at most $d^{O(d)}$. In particular, it follows that every compact 3-manifold has a triangulation with dual graph of bounded twin-width. This is in sharp contrast to the case of treewidth, where for any natural number $n$ there exists a closed 3-manifold such that every triangulation thereof has dual graph with treewidth at least $n$. To establish this result, we bound the twin-width of the incidence graph of the $d$-skeleton of the second barycentric subdivision of the $2d$-dimensional hypercubic honeycomb. We also show that every compact, piecewise-linear (hence smooth) $d$-dimensional manifold has triangulations where the dual graph has an arbitrarily large twin-width.",
      "authors": [
        "\\'Edouard Bonnet",
        "Krist\\'of Husz\\'ar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Geometric Topology (math.GT)",
        "Computational Geometry (cs.CG)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-14T12:09:25+00:00",
          "link": "https://arxiv.org/abs/2407.10174v1",
          "size": "329kb",
          "version": "v1"
        }
      ],
      "title": "On the twin-width of smooth manifolds",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.10174",
        "PDF": "https://arxiv.org/pdf/2407.10174"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses geometrical properties of smooth manifolds and triangulations; it does not engage with LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2408.01926",
      "abstract": "We proposed the tensor-input tree (TT) method for scalar-on-tensor and tensor-on-tensor regression problems. We first address scalar-on-tensor problem by proposing scalar-output regression tree models whose input variable are tensors (i.e., multi-way arrays). We devised and implemented fast randomized and deterministic algorithms for efficient fitting of scalar-on-tensor trees, making TT competitive against tensor-input GP models. Based on scalar-on-tensor tree models, we extend our method to tensor-on-tensor problems using additive tree ensemble approaches. Theoretical justification and extensive experiments on real and synthetic datasets are provided to illustrate the performance of TT.",
      "authors": [
        "Hengrui Luo",
        "Akira Horiguchi",
        "Li Ma"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Methodology (stat.ME)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-04T04:42:02+00:00",
          "link": "https://arxiv.org/abs/2408.01926v1",
          "size": "4441kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T20:12:10+00:00",
          "link": "https://arxiv.org/abs/2408.01926v2",
          "size": "2668kb",
          "version": "v2"
        }
      ],
      "title": "Efficient Decision Trees for Tensor Regressions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.01926",
        "HTML": "https://arxiv.org/html/2408.01926v2",
        "PDF": "https://arxiv.org/pdf/2408.01926"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a tensor regression method, specifically tensor-input trees, without any focus on LLM training data processing or creating datasets for such models."
      },
      "tasks": [
        "regression"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.16412",
      "abstract": "This pilot study presents the development of the InfoTech Assistant, a domain-specific, multimodal chatbot engineered to address queries in bridge evaluation and infrastructure technology. By integrating web data scraping, large language models (LLMs), and Retrieval-Augmented Generation (RAG), the InfoTech Assistant provides accurate and contextually relevant responses. Data, including textual descriptions and images, are sourced from publicly available documents on the InfoTechnology website and organized in JSON format to facilitate efficient querying. The architecture of the system includes an HTML-based interface and a Flask back end connected to the Llama 3.1 model via LLM Studio. Evaluation results show approximately 95 percent accuracy on domain-specific tasks, with high similarity scores confirming the quality of response matching. This RAG-enhanced setup enables the InfoTech Assistant to handle complex, multimodal queries, offering both textual and visual information in its responses. The InfoTech Assistant demonstrates strong potential as a dependable tool for infrastructure professionals, delivering high accuracy and relevance in its domain-specific outputs.",
      "authors": [
        "Sai Surya Gadiraju",
        "Duoduo Liao",
        "Akhila Kudupudi",
        "Santosh Kasula",
        "Charitha Chalasani"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-21T00:34:52+00:00",
          "link": "https://arxiv.org/abs/2412.16412v1",
          "size": "2511kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T01:07:01+00:00",
          "link": "https://arxiv.org/abs/2412.16412v2",
          "size": "1828kb",
          "version": "v2"
        }
      ],
      "title": "InfoTech Assistant: A Multimodal Conversational Agent for InfoTechnology Web Portal Queries",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.16412",
        "HTML": "https://arxiv.org/html/2412.16412v2",
        "PDF": "https://arxiv.org/pdf/2412.16412"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a multimodal conversational agent for infrastructure queries, without contributions to LLM training data processing or dataset creation."
      },
      "tasks": [
        "Chatbot",
        "RAG",
        "Retrieval-augmented Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.21460",
      "abstract": "We describe and analyze a computionally efficient refitting procedure for computing high-probability upper bounds on the instance-wise mean-squared prediction error of penalized nonparametric estimates based on least-squares minimization. Requiring only a single dataset and black box access to the prediction method, it consists of three steps: computing suitable residuals, symmetrizing and scaling them with a pre-factor $\\rho$, and using them to define and solve a modified prediction problem recentered at the current estimate. We refer to it as wild refitting, since it uses Rademacher residual symmetrization as in a wild bootstrap variant. Under relatively mild conditions allowing for noise heterogeneity, we establish a high probability guarantee on its performance, showing that the wild refit with a suitably chosen wild noise scale $\\rho$ gives an upper bound on prediction error. This theoretical analysis provides guidance into the design of such procedures, including how the residuals should be formed, the amount of noise rescaling in the wild sub-problem needed for upper bounds, and the local stability properties of the block-box procedure. We illustrate the applicability of this procedure to various problems, including non-rigid structure-from-motion recovery with structured matrix penalties; plug-and-play image restoration with deep neural network priors; and randomized sketching with kernel methods.",
      "authors": [
        "Martin J. Wainwright"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Statistics Theory (math.ST)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T16:41:55+00:00",
          "link": "https://arxiv.org/abs/2506.21460v1",
          "size": "30554kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T23:47:24+00:00",
          "link": "https://arxiv.org/abs/2506.21460v2",
          "size": "10513kb",
          "version": "v2"
        }
      ],
      "title": "Wild refitting for black box prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21460",
        "HTML": "https://arxiv.org/html/2506.21460v2",
        "PDF": "https://arxiv.org/pdf/2506.21460"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a refitting procedure to calculate prediction error bounds using a single dataset, focusing on methodology for prediction rather than on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06250",
      "abstract": "The Model Context Protocol (MCP) has emerged as a widely adopted mechanism for connecting large language models to external tools and resources. While MCP promises seamless extensibility and rich integrations, it also introduces a substantially expanded attack surface: any plugin can inherit broad system privileges with minimal isolation or oversight. In this work, we conduct the first large-scale empirical analysis of MCP security risks. We develop an automated static analysis framework and systematically examine 2,562 real-world MCP applications spanning 23 functional categories. Our measurements reveal that network and system resource APIs dominate usage patterns, affecting 1,438 and 1,237 servers respectively, while file and memory resources are less frequent but still significant. We find that Developer Tools and API Development plugins are the most API-intensive, and that less popular plugins often contain disproportionately high-risk operations. Through concrete case studies, we demonstrate how insufficient privilege separation enables privilege escalation, misinformation propagation, and data tampering. Based on these findings, we propose a detailed taxonomy of MCP resource access, quantify security-relevant API usage, and identify open challenges for building safer MCP ecosystems, including dynamic permission models and automated trust assessment.",
      "authors": [
        "Zhihao Li",
        "Kun Li",
        "Boyang Ma",
        "Minghui Xu",
        "Yue Zhang",
        "Xiuzhen Cheng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-05T03:39:30+00:00",
          "link": "https://arxiv.org/abs/2507.06250v1",
          "size": "686kb",
          "version": "v1"
        }
      ],
      "title": "We Urgently Need Privilege Management in MCP: A Measurement of API Usage in MCP Ecosystems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06250",
        "HTML": "https://arxiv.org/html/2507.06250v1",
        "PDF": "https://arxiv.org/pdf/2507.06250"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper conducts an analysis of API usage in MCP ecosystems and security concerns, which are not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06264",
      "abstract": "The success of machine learning algorithms is inherently related to the extraction of meaningful features, as they play a pivotal role in the performance of these algorithms. Central to this challenge is the quality of data representation. However, the ability to generalize and extract these features effectively from unseen datasets is also crucial. In light of this, we introduce a novel concept: the polyrepresentation. Polyrepresentation integrates multiple representations of the same modality extracted from distinct sources, for example, vector embeddings from the Siamese Network, self-supervised models, and interpretable radiomic features. This approach yields better performance metrics compared to relying on a single representation. Additionally, in the context of X-ray images, we demonstrate the transferability of the created polyrepresentation to a smaller dataset, underscoring its potential as a pragmatic and resource-efficient approach in various image-related solutions. It is worth noting that the concept of polyprepresentation on the example of medical data can also be applied to other domains, showcasing its versatility and broad potential impact.",
      "authors": [
        "Weronika Hryniewska-Guzik",
        "Przemyslaw Biecek"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T22:05:50+00:00",
          "link": "https://arxiv.org/abs/2507.06264v1",
          "size": "1397kb",
          "version": "v1"
        }
      ],
      "title": "X-ray transferable polyrepresentation learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06264",
        "HTML": "https://arxiv.org/html/2507.06264v1",
        "PDF": "https://arxiv.org/pdf/2507.06264"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces polyrepresentation learning for better data representation but focuses on feature extraction and generalization rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06704",
      "abstract": "Issue Tracking Systems (ITSs), such as GitHub and Jira, are popular tools that support Software Engineering (SE) organisations through the management of ``issues'', which represent different SE artefacts such as requirements, development tasks, and maintenance items. ITSs also support internal linking between issues, and external linking to other tools and information sources. This provides SE organisations key forms of documentation, including forwards and backwards traceability (e.g., Feature Requests linked to sprint releases and code commits linked to Bug Reports). An Issue Tracking Ecosystem (ITE) is the aggregate of the central ITS and the related SE artefacts, stakeholders, and processes -- with an emphasis on how these contextual factors interact with the ITS. The quality of ITEs is central to the success of these organisations and their software products. There are challenges, however, within ITEs, including complex networks of interlinked artefacts and diverse workflows. While ITSs have been the subject of study in SE research for decades, ITEs as a whole need further exploration.\n  In this thesis, I undertake the challenge of understanding ITEs at a broader level, addressing these questions regarding complexity and diversity. I interviewed practitioners and performed archival analysis on a diverse set of ITSs. These analyses revealed the context-dependent nature of ITE problems, highlighting the need for context-specific ITE research. While previous work has produced many solutions to specific ITS problems, these solutions are not consistently framed in a context-rich and comparable way, leading to a desire for more aligned solutions across research and practice. To address this emergent information and lack of alignment, I created the Best Practice Ontology for ITEs. <... truncated due to arXiv abstract character limit ...>",
      "authors": [
        "Lloyd Montgomery"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T09:57:13+00:00",
          "link": "https://arxiv.org/abs/2507.06704v1",
          "size": "5468kb",
          "version": "v1"
        }
      ],
      "title": "Issue Tracking Ecosystems: Context and Best Practices",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06704",
        "HTML": "https://arxiv.org/html/2507.06704v1",
        "PDF": "https://arxiv.org/pdf/2507.06704"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with issue tracking systems in software engineering, without any focus on LLM training data or data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2112.13988",
      "abstract": "The deep-learning-based least squares method has shown successful results in solving high-dimensional non-linear partial differential equations (PDEs). However, this method usually converges slowly. To speed up the convergence of this approach, an active-learning-based sampling algorithm is proposed in this paper. This algorithm actively chooses the most informative training samples from a probability density function based on residual errors to facilitate error reduction. In particular, points with larger residual errors will have more chances of being selected for training. This algorithm imitates the human learning process: learners are likely to spend more time repeatedly studying mistakes than other tasks they have correctly finished. A series of numerical results are illustrated to demonstrate the effectiveness of our active-learning-based sampling in high dimensions to speed up the convergence of the deep-learning-based least squares method.",
      "authors": [
        "Wenhan Gao and Chunmei Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2021-12-28T04:03:23+00:00",
          "link": "https://arxiv.org/abs/2112.13988v1",
          "size": "27115kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T20:54:32+00:00",
          "link": "https://arxiv.org/abs/2112.13988v2",
          "size": "13562kb",
          "version": "v2"
        }
      ],
      "title": "Active Learning Based Sampling for High-Dimensional Nonlinear Partial Differential Equations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2112.13988",
        "HTML": "https://arxiv.org/html/2112.13988v2",
        "PDF": "https://arxiv.org/pdf/2112.13988"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper presents an active-learning-based sampling algorithm which selectively chooses training samples based on error, an aspect of training data processing, but focuses primarily on solving PDEs and improving convergence speed rather than LLM data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.18497",
      "abstract": "We investigate how Large Language Models (LLMs) distinguish between memorization and generalization at the neuron level. Through carefully designed tasks, we identify distinct neuron subsets responsible for each behavior. Experiments on both a GPT-2 model trained from scratch and a pretrained LLaMA-3.2 model fine-tuned with LoRA show consistent neuron-level specialization. We further demonstrate that inference-time interventions on these neurons can steer the model's behavior toward memorization or generalization. To assess robustness, we evaluate intra-task and inter-task consistency, confirming that these neuron-behavior associations reflect generalizable patterns rather than dataset-specific artifacts. Our findings reveal modular structure in LLMs and enable controlling memorization and generalization behaviors at inference time.",
      "authors": [
        "Ko-Wei Huang",
        "Yi-Fu Fu",
        "Ching-Yu Tsai",
        "Yu-Chieh Tu",
        "Tzu-Ling Cheng",
        "Cheng-Yu Lin",
        "Yi-Ting Yang",
        "Heng-Yi Liu",
        "Keng-Te Liao",
        "Da-Cheng Juan",
        "Shou-De Lin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-24T15:28:56+00:00",
          "link": "https://arxiv.org/abs/2412.18497v1",
          "size": "4460kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T15:14:46+00:00",
          "link": "https://arxiv.org/abs/2412.18497v2",
          "size": "3202kb",
          "version": "v2"
        }
      ],
      "title": "Neuron-Level Differentiation of Memorization and Generalization in Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.18497",
        "HTML": "https://arxiv.org/html/2412.18497v2",
        "PDF": "https://arxiv.org/pdf/2412.18497"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper examines neuron-level behaviors in LLMs but does not focus on LLM training data processing. It primarily deals with model architecture and behavior without substantive data engineering contributions."
      },
      "tasks": [
        "Memorization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06744",
      "abstract": "Weakly supervised text-to-person image matching, as a crucial approach to reducing models' reliance on large-scale manually labeled samples, holds significant research value. However, existing methods struggle to predict complex one-to-many identity relationships, severely limiting performance improvements. To address this challenge, we propose a local-and-global dual-granularity identity association mechanism. Specifically, at the local level, we explicitly establish cross-modal identity relationships within a batch, reinforcing identity constraints across different modalities and enabling the model to better capture subtle differences and correlations. At the global level, we construct a dynamic cross-modal identity association network with the visual modality as the anchor and introduce a confidence-based dynamic adjustment mechanism, effectively enhancing the model's ability to identify weakly associated samples while improving overall sensitivity. Additionally, we propose an information-asymmetric sample pair construction method combined with consistency learning to tackle hard sample mining and enhance model robustness. Experimental results demonstrate that the proposed method substantially boosts cross-modal matching accuracy, providing an efficient and practical solution for text-to-person image matching.",
      "authors": [
        "Yafei Zhang",
        "Yongle Shang",
        "Huafeng Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T10:59:13+00:00",
          "link": "https://arxiv.org/abs/2507.06744v1",
          "size": "2318kb",
          "version": "v1"
        }
      ],
      "title": "Dual-Granularity Cross-Modal Identity Association for Weakly-Supervised Text-to-Person Image Matching",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06744",
        "HTML": "https://arxiv.org/html/2507.06744v1",
        "PDF": "https://arxiv.org/pdf/2507.06744"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving cross-modal identity association for image matching, without any mention of LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06802",
      "abstract": "Speech tokenization is crucial in digital speech processing, converting continuous speech signals into discrete units for various computational tasks. This paper introduces a novel speech tokenizer with broad applicability across downstream tasks. While recent advances in residual vector quantization (RVQ) have incorporated semantic elements, they often neglect critical acoustic features. We propose an advanced approach that simultaneously encodes both linguistic and acoustic information, preserving prosodic and emotional content. Our method significantly enhances speech representation fidelity across diverse applications. Empirical evaluations demonstrate its effectiveness in speech coding, voice conversion, emotion recognition, and multimodal language modeling, without requiring additional training. This versatility underscores its potential as a key tool for advancing AI-driven speech processing.",
      "authors": [
        "Wonjin Jung",
        "Sungil Kang",
        "Dong-Yeon Cho"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T12:43:39+00:00",
          "link": "https://arxiv.org/abs/2507.06802v1",
          "size": "410kb",
          "version": "v1"
        }
      ],
      "title": "Speech Tokenizer is Key to Consistent Representation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06802",
        "HTML": "https://arxiv.org/html/2507.06802v1",
        "PDF": "https://arxiv.org/pdf/2507.06802"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on speech tokenization and representation, which doesn't involve processing or creation of LLM training data specifically."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06828",
      "abstract": "Image denoising is a fundamental task in computer vision, particularly in medical ultrasound (US) imaging, where speckle noise significantly degrades image quality. Although recent advancements in deep neural networks have led to substantial improvements in denoising for natural images, these methods cannot be directly applied to US speckle noise, as it is not purely random. Instead, US speckle arises from complex wave interference within the body microstructure, making it tissue-dependent. This dependency means that obtaining two independent noisy observations of the same scene, as required by pioneering Noise2Noise, is not feasible. Additionally, blind-spot networks also cannot handle US speckle noise due to its high spatial dependency. To address this challenge, we introduce Speckle2Self, a novel self-supervised algorithm for speckle reduction using only single noisy observations. The key insight is that applying a multi-scale perturbation (MSP) operation introduces tissue-dependent variations in the speckle pattern across different scales, while preserving the shared anatomical structure. This enables effective speckle suppression by modeling the clean image as a low-rank signal and isolating the sparse noise component. To demonstrate its effectiveness, Speckle2Self is comprehensively compared with conventional filter-based denoising algorithms and SOTA learning-based methods, using both realistic simulated US images and human carotid US images. Additionally, data from multiple US machines are employed to evaluate model generalization and adaptability to images from unseen domains. \\textit{Code and datasets will be released upon acceptance.",
      "authors": [
        "Xuesong Li",
        "Nassir Navab",
        "Zhongliang Jiang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T13:28:00+00:00",
          "link": "https://arxiv.org/abs/2507.06828v1",
          "size": "10726kb",
          "version": "v1"
        }
      ],
      "title": "Speckle2Self: Self-Supervised Ultrasound Speckle Reduction Without Clean Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06828",
        "HTML": "https://arxiv.org/html/2507.06828v1",
        "PDF": "https://arxiv.org/pdf/2507.06828"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a self-supervised denoising algorithm for ultrasound images, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06119",
      "abstract": "Notable breakthroughs in unified understanding and generation modeling have led to remarkable advancements in image understanding, reasoning, production and editing, yet current foundational models predominantly focus on processing images, creating a gap in the development of unified models for video understanding and generation. This report presents Omni-Video, an efficient and effective unified framework for video understanding, generation, as well as instruction-based editing. Our key insight is to teach existing multimodal large language models (MLLMs) to produce continuous visual clues that are used as the input of diffusion decoders, which produce high-quality videos conditioned on these visual clues. To fully unlock the potential of our system for unified video modeling, we integrate several technical improvements: 1) a lightweight architectural design that respectively attaches a vision head on the top of MLLMs and a adapter before the input of diffusion decoders, the former produce visual tokens for the latter, which adapts these visual tokens to the conditional space of diffusion decoders; and 2) an efficient multi-stage training scheme that facilitates a fast connection between MLLMs and diffusion decoders with limited data and computational resources. We empirically demonstrate that our model exhibits satisfactory generalization abilities across video generation, editing and understanding tasks.",
      "authors": [
        "Zhiyu Tan",
        "Hao Yang",
        "Luozheng Qin",
        "Jia Gong",
        "Mengping Yang",
        "Hao Li"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T16:02:16+00:00",
          "link": "https://arxiv.org/abs/2507.06119v1",
          "size": "7922kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T12:27:27+00:00",
          "link": "https://arxiv.org/abs/2507.06119v2",
          "size": "7922kb",
          "version": "v2"
        }
      ],
      "title": "Omni-Video: Democratizing Unified Video Understanding and Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06119",
        "HTML": "https://arxiv.org/html/2507.06119v2",
        "PDF": "https://arxiv.org/pdf/2507.06119"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a model framework for video processing but does not mention LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2406.05615",
      "abstract": "Humans use multiple senses to comprehend the environment. Vision and language are two of the most vital senses since they allow us to easily communicate our thoughts and perceive the world around us. There has been a lot of interest in creating video-language understanding systems with human-like senses since a video-language pair can mimic both our linguistic medium and visual environment with temporal dynamics. In this survey, we review the key tasks of these systems and highlight the associated challenges. Based on the challenges, we summarize their methods from model architecture, model training, and data perspectives. We also conduct performance comparison among the methods, and discuss promising directions for future research.",
      "authors": [
        "Thong Nguyen",
        "Yi Bin",
        "Junbin Xiao",
        "Leigang Qu",
        "Yicong Li",
        "Jay Zhangjie Wu",
        "Cong-Duy Nguyen",
        "See-Kiong Ng",
        "Luu Anh Tuan"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-09T02:36:28+00:00",
          "link": "https://arxiv.org/abs/2406.05615v1",
          "size": "32776kb",
          "version": "v1"
        },
        {
          "date": "2024-07-01T16:05:01+00:00",
          "link": "https://arxiv.org/abs/2406.05615v2",
          "size": "32777kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T07:26:18+00:00",
          "link": "https://arxiv.org/abs/2406.05615v3",
          "size": "32535kb",
          "version": "v3"
        }
      ],
      "title": "Video-Language Understanding: A Survey from Model Architecture, Model Training, and Data Perspectives",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.05615",
        "HTML": "https://arxiv.org/html/2406.05615v3",
        "PDF": "https://arxiv.org/pdf/2406.05615"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is a survey on video-language understanding systems, mainly discussing model architectures, training, and data perspectives without specific focus on processing data for LLM training."
      },
      "tasks": [
        "model"
      ],
      "repo_urls": [
        "https://github.com/nguyentthong/video-language-understanding"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06266",
      "abstract": "In the face of global economic uncertainty, financial auditing has become essential for regulatory compliance and risk mitigation. Traditional manual auditing methods are increasingly limited by large data volumes, complex business structures, and evolving fraud tactics. This study proposes an AI-driven framework for enterprise financial audits and high-risk identification, leveraging machine learning to improve efficiency and accuracy. Using a dataset from the Big Four accounting firms (EY, PwC, Deloitte, KPMG) from 2020 to 2025, the research examines trends in risk assessment, compliance violations, and fraud detection. The dataset includes key indicators such as audit project counts, high-risk cases, fraud instances, compliance breaches, employee workload, and client satisfaction, capturing both audit behaviors and AI's impact on operations. To build a robust risk prediction model, three algorithms - Support Vector Machine (SVM), Random Forest (RF), and K-Nearest Neighbors (KNN) - are evaluated. SVM uses hyperplane optimization for complex classification, RF combines decision trees to manage high-dimensional, nonlinear data with resistance to overfitting, and KNN applies distance-based learning for flexible performance. Through hierarchical K-fold cross-validation and evaluation using F1-score, accuracy, and recall, Random Forest achieves the best performance, with an F1-score of 0.9012, excelling in identifying fraud and compliance anomalies. Feature importance analysis reveals audit frequency, past violations, employee workload, and client ratings as key predictors. The study recommends adopting Random Forest as a core model, enhancing features via engineering, and implementing real-time risk monitoring. This research contributes valuable insights into using machine learning for intelligent auditing and risk management in modern enterprises.",
      "authors": [
        "Tingyu Yuan",
        "Xi Zhang",
        "Xuanjing Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Risk Management (q-fin.RM)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Applications (stat.AP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T00:22:49+00:00",
          "link": "https://arxiv.org/abs/2507.06266v1",
          "size": "619kb",
          "version": "v1"
        }
      ],
      "title": "Machine Learning based Enterprise Financial Audit Framework and High Risk Identification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06266",
        "PDF": "https://arxiv.org/pdf/2507.06266"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a machine learning framework for financial audits and risk identification, with no mention of LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06433",
      "abstract": "Electroencephalography (EEG) allows monitoring of brain activity, providing insights into the functional dynamics of various brain regions and their roles in cognitive processes. EEG is a cornerstone in sleep research, serving as the primary modality of polysomnography, the gold standard in the field. However, EEG signals are prone to artifacts caused by both internal (device-specific) factors and external (environmental) interferences. As sleep studies are becoming larger, most rely on automatic sleep staging, a process highly susceptible to artifacts, leading to erroneous sleep scores. This paper addresses this challenge by introducing eegFloss, an open-source Python package to utilize eegUsability, a novel machine learning (ML) model designed to detect segments with artifacts in sleep EEG recordings. eegUsability has been trained and evaluated on manually artifact-labeled EEG data collected from 15 participants over 127 nights using the Zmax headband. It demonstrates solid overall classification performance (F1-score is approximately 0.85, Cohens kappa is 0.78), achieving a high recall rate of approximately 94% in identifying channel-wise usable EEG data, and extends beyond Zmax. Additionally, eegFloss offers features such as automatic time-in-bed detection using another ML model named eegMobility, filtering out certain artifacts, and generating hypnograms and sleep statistics. By addressing a fundamental challenge faced by most sleep studies, eegFloss can enhance the precision and rigor of their analysis as well as the accuracy and reliability of their outcomes.",
      "authors": [
        "Niloy Sikder",
        "Paul Zerr",
        "Mahdad Jafarzadeh Esfahani",
        "Martin Dresler",
        "Matthias Krauledat"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Signal Processing (eess.SP)",
        "Quantitative Methods (q-bio.QM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T22:27:43+00:00",
          "link": "https://arxiv.org/abs/2507.06433v1",
          "size": "6385kb",
          "version": "v1"
        }
      ],
      "title": "eegFloss: A Python package for refining sleep EEG recordings using machine learning models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06433",
        "PDF": "https://arxiv.org/pdf/2507.06433"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents the eegFloss package for detecting artifacts in EEG recordings, with no connection to LLM training data processing or dataset creation specifically for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06452",
      "abstract": "Diagnosing performance bottlenecks in modern software is essential yet challenging, particularly as applications become more complex and rely on custom resource management policies. While traditional profilers effectively identify execution bottlenecks by tracing system-level metrics, they fall short when it comes to application-level resource contention caused by waiting for application-level events. In this work, we introduce OmniResource Profiling, a performance analysis approach that integrates system-level and application-level resource tracing to diagnose resource bottlenecks comprehensively. gigiProfiler, our realization of OmniResource Profiling, uses a hybrid LLM-static analysis approach to identify application-defined resources offline and analyze their impact on performance during buggy executions to uncover the performance bottleneck. gigiProfiler then samples and records critical variables related to these bottleneck resources during buggy execution and compares their value with those from normal executions to identify the root causes. We evaluated gigiProfiler on 12 real-world performance issues across five applications. gigiProfiler accurately identified performance bottlenecks in all cases. gigiProfiler also successfully diagnosed the root causes of two newly emerged, previously undiagnosed problems, with the findings confirmed by developers.",
      "authors": [
        "Yigong Hu",
        "Haodong Zheng",
        "Yicheng Liu",
        "Dedong Xie",
        "Youliang Huang",
        "Baris Kasikci"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Performance (cs.PF)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T23:31:58+00:00",
          "link": "https://arxiv.org/abs/2507.06452v1",
          "size": "459kb",
          "version": "v1"
        }
      ],
      "title": "gigiProfiler: Diagnosing Performance Issues by Uncovering Application Resource Bottlenecks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06452",
        "HTML": "https://arxiv.org/html/2507.06452v1",
        "PDF": "https://arxiv.org/pdf/2507.06452"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a profiling tool for diagnosing resource bottlenecks in software applications, with no mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06538",
      "abstract": "Graph representation learning is a powerful method to extract features from graph-structured data, such as analog/mixed-signal (AMS) circuits. However, training deep learning models for AMS designs is severely limited by the scarcity of integrated circuit design data. In this work, we present CircuitGPS, a few-shot learning method for parasitic effect prediction in AMS circuits. The circuit netlist is represented as a heterogeneous graph, with the coupling capacitance modeled as a link. CircuitGPS is pre-trained on link prediction and fine-tuned on edge regression. The proposed method starts with a small-hop sampling technique that converts a link or a node into a subgraph. Then, the subgraph embeddings are learned with a hybrid graph Transformer. Additionally, CircuitGPS integrates a low-cost positional encoding that summarizes the positional and structural information of the sampled subgraph. CircuitGPS improves the accuracy of coupling existence by at least 20\\% and reduces the MAE of capacitance estimation by at least 0.067 compared to existing methods. Our method demonstrates strong inherent scalability, enabling direct application to diverse AMS circuit designs through zero-shot learning. Furthermore, the ablation studies provide valuable insights into graph models for representation learning.",
      "authors": [
        "Shan Shen",
        "Yibin Zhang",
        "Hector Rodriguez Rodriguez",
        "Wenjian Yu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T04:42:18+00:00",
          "link": "https://arxiv.org/abs/2507.06538v1",
          "size": "932kb",
          "version": "v1"
        }
      ],
      "title": "Few-shot Learning on AMS Circuits and Its Application to Parasitic Capacitance Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06538",
        "HTML": "https://arxiv.org/html/2507.06538v1",
        "PDF": "https://arxiv.org/pdf/2507.06538"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a few-shot learning method for AMS circuit prediction. It does not involve any processing or manipulation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2301.12692",
      "abstract": "Sinc-collocation methods are known to be efficient for Fredholm integral equations of the second kind, even if functions in the equations have endpoint singularity. However, existing methods have the disadvantage of inconsistent collocation points. This inconsistency complicates the implementation of such methods, particularly for large-scale problems. To overcome this drawback, this study proposes another Sinc-collocation methods with consistent collocation points. The results of a theoretical error analysis show that the proposed methods have the same convergence property as existing methods. Numerical experiments suggest the superiority of the proposed methods in terms of implementation and computational cost.",
      "authors": [
        "Tomoaki Okayama"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2023-01-30T06:50:39+00:00",
          "link": "https://arxiv.org/abs/2301.12692v1",
          "size": "42kb",
          "version": "v1"
        },
        {
          "date": "2023-02-21T03:20:28+00:00",
          "link": "https://arxiv.org/abs/2301.12692v2",
          "size": "42kb",
          "version": "v2"
        },
        {
          "date": "2023-06-12T05:47:36+00:00",
          "link": "https://arxiv.org/abs/2301.12692v3",
          "size": "43kb",
          "version": "v3"
        }
      ],
      "title": "Sinc-collocation methods with consistent collocation points for Fredholm integral equations of the second kind",
      "links": {
        "Abstract": "https://arxiv.org/abs/2301.12692",
        "HTML": "https://arxiv.org/html/2301.12692",
        "PDF": "https://arxiv.org/pdf/2301.12692"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes Sinc-collocation methods for integral equations, which is unrelated to any aspect of LLM training data processing or engineering."
      },
      "repo_urls": [
        "https://github.com/okayamat/sinc-colloc-fredholm"
      ],
      "source": "arXiv"
    },
    {
      "id": "2304.00050",
      "abstract": "Batch effects in high-dimensional Cytometry by Time-of-Flight (CyTOF) data pose a challenge for comparative analysis across different experimental conditions or time points. Traditional batch normalization methods may fail to preserve the complex topological structures inherent in cellular populations. In this paper, we present a residual neural network-based method for point set registration specifically tailored to address batch normalization in CyTOF data while preserving the topological structure of cellular populations. By viewing the alignment problem as the movement of cells sampled from a target distribution along a regularized displacement vector field, similar to coherent point drift (CPD), our approach introduces a Jacobian-based cost function and geometry-aware statistical distances to ensure local topology preservation. We provide justification for the k-Nearest Neighbour (kNN) graph preservation of the target data when the Jacobian cost is applied, which is crucial for maintaining biological relationships between cells. Furthermore, we introduce a stochastic approximation for high-dimensional registration, making alignment feasible for the high-dimensional space of CyTOF data. Our method is demonstrated on high-dimensional CyTOF dataset, effectively aligning distributions of cells while preserving the kNN-graph structure. This enables accurate batch normalization, facilitating reliable comparative analysis in biomedical research.",
      "authors": [
        "Muhammad S. Battikh",
        "Artem Lensky"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2023-03-31T18:06:26+00:00",
          "link": "https://arxiv.org/abs/2304.00050v1",
          "size": "5228kb",
          "version": "v1"
        },
        {
          "date": "2023-06-26T10:50:37+00:00",
          "link": "https://arxiv.org/abs/2304.00050v2",
          "size": "5195kb",
          "version": "v2"
        },
        {
          "date": "2024-11-27T12:22:50+00:00",
          "link": "https://arxiv.org/abs/2304.00050v3",
          "size": "5276kb",
          "version": "v3"
        },
        {
          "date": "2025-07-09T09:41:42+00:00",
          "link": "https://arxiv.org/abs/2304.00050v4",
          "size": "2931kb",
          "version": "v4"
        }
      ],
      "title": "Batch Normalization in Cytometry Data by kNN-Graph Preservation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2304.00050",
        "HTML": "https://arxiv.org/html/2304.00050v4",
        "PDF": "https://arxiv.org/pdf/2304.00050"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses batch normalization in high-dimensional CyTOF data specific to biological research, which does not pertain to LLM training data collection or processing."
      },
      "tasks": [
        "Point Cloud Registration"
      ],
      "repo_urls": [
        "https://github.com/muhammadsaeedbatikh/knn-res_demo"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.19952",
      "abstract": "Money laundering is the process that intends to legalize the income derived from illicit activities, thus facilitating their entry into the monetary flow of the economy without jeopardizing their source. It is crucial to identify such activities accurately and reliably in order to enforce anti-money laundering (AML). Despite considerable efforts to AML, a large number of such activities still go undetected. Rule-based methods were first introduced and are still widely used in current detection systems. With the rise of machine learning, graph-based learning methods have gained prominence in detecting illicit accounts through the analysis of money transfer graphs. Nevertheless, these methods generally assume that the transaction graph is centralized, whereas in practice, money laundering activities usually span multiple financial institutions. Due to regulatory, legal, commercial, and customer privacy concerns, institutions tend not to share data, restricting their utility in practical usage. In this paper, we propose the first algorithm that supports performing AML over multiple institutions while protecting the security and privacy of local data. To evaluate, we construct Alipay-ECB, a real-world dataset comprising digital transactions from Alipay, the world's largest mobile payment platform, alongside transactions from E-Commerce Bank (ECB). The dataset includes over 200 million accounts and 300 million transactions, covering both intra-institution transactions and those between Alipay and ECB. This makes it the largest real-world transaction graph available for analysis. The experimental results demonstrate that our methods can effectively identify cross-institution money laundering subgroups. Additionally, experiments on synthetic datasets also demonstrate that our method is efficient, requiring only a few minutes on datasets with millions of transactions.",
      "authors": [
        "Zhihua Tian",
        "Yuan Ding",
        "Wenjie Qu",
        "Xiang Yu",
        "Enchao Gong",
        "Jian Liu",
        "Kui Ren"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Computers and Society (cs.CY)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-27T10:22:55+00:00",
          "link": "https://arxiv.org/abs/2502.19952v1",
          "size": "1925kb",
          "version": "v1"
        },
        {
          "date": "2025-06-02T14:06:01+00:00",
          "link": "https://arxiv.org/abs/2502.19952v2",
          "size": "1467kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T13:39:50+00:00",
          "link": "https://arxiv.org/abs/2502.19952v3",
          "size": "1467kb",
          "version": "v3"
        }
      ],
      "title": "Towards Collaborative Anti-Money Laundering Among Financial Institutions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.19952",
        "HTML": "https://arxiv.org/html/2502.19952v3",
        "PDF": "https://arxiv.org/pdf/2502.19952"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper involves constructing a large real-world transaction graph dataset, Alipay-ECB, but its primary focus is on anti-money laundering methods over multiple institutions rather than LLM training data processing."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/zhihuat/Collaborative-AML"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06383",
      "abstract": "In this study, we propose a fuzzy system for conducting short-term transactions in the forex market. The system is designed to enhance common strategies in the forex market using fuzzy logic, thereby improving the accuracy of transactions. Traditionally, technical strategies based on oscillator indicators have relied on predefined ranges for indicators such as Relative Strength Index (RSI), Commodity Channel Indicator (CCI), and Stochastic to determine entry points for trades. However, the use of these classic indicators has yielded suboptimal results due to the changing nature of the market over time. In our proposed approach, instead of employing classical indicators, we introduce a fuzzy Mamdani system for each indicator. The results obtained from these systems are then combined through voting to design a trading robot. Our findings demonstrate a considerable increase in the profitability factor compared to three other methods. Additionally, net profit, gross profit, and maximum capital reduction are calculated and compared across all approaches.",
      "authors": [
        "Mustafa Shabani",
        "Alireza Nasiri and Hassan Nafardi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Logic in Computer Science (cs.LO)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T20:33:30+00:00",
          "link": "https://arxiv.org/abs/2507.06383v1",
          "size": "647kb",
          "version": "v1"
        }
      ],
      "title": "Forex Trading Robot Using Fuzzy Logic",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06383",
        "PDF": "https://arxiv.org/pdf/2507.06383"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a fuzzy logic system for forex trading, which is unrelated to LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06943",
      "abstract": "With the significance of continuous-variable quantum computing increasing thanks to the achievements of light-based quantum hardware, making it available to learner audiences outside physics has been an important yet seldom-tackled challenge. Similarly, the rising focus on fault-tolerant quantum computing has shed light on quantum error correction schemes, turning it into the locus of attention for industry and academia alike. In this paper, we explore the widely adopted framework of quantum error correction based on continuous variable systems and suggest a guide on building a self-contained learning session targeting the famous Gottesman-Kitaev-Preskill (GKP) code through its geometric intuition.",
      "authors": [
        "Richard A. Wolf",
        "Pavithran Iyer"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Emerging Technologies (cs.ET)",
        "Physics Education (physics.ed-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T15:26:15+00:00",
          "link": "https://arxiv.org/abs/2507.06943v1",
          "size": "91kb",
          "version": "v1"
        }
      ],
      "title": "No physics required! A visual-based introduction to GKP qubits for computer scientists",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06943",
        "HTML": "https://arxiv.org/html/2507.06943v1",
        "PDF": "https://arxiv.org/pdf/2507.06943"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses quantum computing and error correction codes, without any discussion on LLM training data processing or data engineering activities."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.03236",
      "abstract": "The safety alignment of Language Models (LMs) is a critical concern, yet their integrity can be challenged by direct parameter manipulation attacks, such as those potentially induced by fault injection. As LMs are increasingly deployed using low-precision quantization for efficiency, this paper investigates the efficacy of such attacks for jailbreaking aligned LMs across different quantization schemes. We propose gradient-guided attacks, including a tailored progressive bit-level search algorithm introduced herein and a comparative word-level (single weight update) attack. Our evaluation on Llama-3.2-3B, Phi-4-mini, and Llama-3-8B across FP16 (baseline), and weight-only quantization (FP8, INT8, INT4) reveals that quantization significantly influences attack success. While attacks readily achieve high success (>80% Attack Success Rate, ASR) on FP16 models, within an attack budget of 25 perturbations, FP8 and INT8 models exhibit ASRs below 20% and 50%, respectively. Increasing the perturbation budget up to 150 bit-flips, FP8 models maintained ASR below 65%, demonstrating some resilience compared to INT8 and INT4 models that have high ASR. In addition, analysis of perturbation locations revealed differing architectural targets across quantization schemes, with (FP16, INT4) and (INT8, FP8) showing similar characteristics. Besides, jailbreaks induced in FP16 models were highly transferable to subsequent FP8/INT8 quantization (<5% ASR difference), though INT4 significantly reduced transferred ASR (avg. 35% drop). These findings highlight that while common quantization schemes, particularly FP8, increase the difficulty of direct parameter manipulation jailbreaks, vulnerabilities can still persist, especially through post-attack quantization.",
      "authors": [
        "Noureldin Zahran",
        "Ahmad Tahmasivand",
        "Ihsen Alouani",
        "Khaled Khasawneh and Mohammed E. Fouda"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-04T00:48:48+00:00",
          "link": "https://arxiv.org/abs/2507.03236v1",
          "size": "1877kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T20:54:53+00:00",
          "link": "https://arxiv.org/abs/2507.03236v2",
          "size": "1877kb",
          "version": "v2"
        }
      ],
      "title": "On Jailbreaking Quantized Language Models Through Fault Injection Attacks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.03236",
        "HTML": "https://arxiv.org/html/2507.03236v2",
        "PDF": "https://arxiv.org/pdf/2507.03236"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates fault injection attacks on quantized language models for security concerns, with no focus on processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06928",
      "abstract": "Generalized Category Discovery (GCD) aims to recognize unlabeled images from known and novel classes by distinguishing novel classes from known ones, while also transferring knowledge from another set of labeled images with known classes. Existing GCD methods rely on self-supervised vision transformers such as DINO for representation learning. However, focusing solely on the global representation of the DINO CLS token introduces an inherent trade-off between discriminability and generalization. In this paper, we introduce an adaptive part discovery and learning method, called APL, which generates consistent object parts and their correspondences across different similar images using a set of shared learnable part queries and DINO part priors, without requiring any additional annotations. More importantly, we propose a novel all-min contrastive loss to learn discriminative yet generalizable part representation, which adaptively highlights discriminative object parts to distinguish similar categories for enhanced discriminability while simultaneously sharing other parts to facilitate knowledge transfer for improved generalization. Our APL can easily be incorporated into different GCD frameworks by replacing their CLS token feature with our part representations, showing significant enhancements on fine-grained datasets.",
      "authors": [
        "Qiyuan Dai",
        "Hanzhuo Huang",
        "Yu Wu",
        "Sibei Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T15:10:21+00:00",
          "link": "https://arxiv.org/abs/2507.06928v1",
          "size": "3993kb",
          "version": "v1"
        }
      ],
      "title": "Adaptive Part Learning for Fine-Grained Generalized Category Discovery: A Plug-and-Play Enhancement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06928",
        "HTML": "https://arxiv.org/html/2507.06928v1",
        "PDF": "https://arxiv.org/pdf/2507.06928"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on enhancing Generalized Category Discovery using adaptive part learning with vision transformers, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2307.06464",
      "abstract": "By organizing knowledge within a research field, Systematic Reviews (SR) provide valuable leads to steer research. Evidence suggests that SRs have become first-class artifacts in software engineering. However, the tedious manual effort associated with the screening phase of SRs renders these studies a costly and error-prone endeavor. While screening has traditionally been considered not amenable to automation, the advent of generative AI-driven chatbots, backed with large language models is set to disrupt the field. In this report, we propose an approach to leverage these novel technological developments for automating the screening of SRs. We assess the consistency, classification performance, and generalizability of ChatGPT in screening articles for SRs and compare these figures with those of traditional classifiers used in SR automation. Our results indicate that ChatGPT is a viable option to automate the SR processes, but requires careful considerations from developers when integrating ChatGPT into their SR tools.",
      "authors": [
        "Eugene Syriani",
        "Istvan David",
        "Gauransh Kumar"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Computation and Language (cs.CL)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2023-07-12T21:39:42+00:00",
          "link": "https://arxiv.org/abs/2307.06464v1",
          "size": "580kb",
          "version": "v1"
        }
      ],
      "title": "Assessing the Ability of ChatGPT to Screen Articles for Systematic Reviews",
      "links": {
        "Abstract": "https://arxiv.org/abs/2307.06464",
        "PDF": "https://arxiv.org/pdf/2307.06464"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses the use of ChatGPT for article screening in systematic reviews, mentioning LLMs in an application context; however, it does not primarily focus on processing or creating LLM training data."
      },
      "tasks": [
        "Articles"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.23952",
      "abstract": "AI systems increasingly support human decision-making across domains of professional, skill-based, and personal activity. While previous work has examined how AI might affect human autonomy globally, the effects of AI on domain-specific autonomy -- the capacity for self-governed action within defined realms of skill or expertise -- remain understudied. We analyze how AI decision-support systems affect two key components of domain-specific autonomy: skilled competence (the ability to make informed judgments within one's domain) and authentic value-formation (the capacity to form genuine domain-relevant values and preferences). By engaging with prior investigations and analyzing empirical cases across medical, financial, and educational domains, we demonstrate how the absence of reliable failure indicators and the potential for unconscious value shifts can erode domain-specific autonomy both immediately and over time. We then develop a constructive framework for autonomy-preserving AI support systems. We propose specific socio-technical design patterns -- including careful role specification, implementation of defeater mechanisms, and support for reflective practice -- that can help maintain domain-specific autonomy while leveraging AI capabilities. This framework provides concrete guidance for developing AI systems that enhance rather than diminish human agency within specialized domains of action.",
      "authors": [
        "Stefan Buijsman",
        "Sarah E. Carter",
        "Juan Pablo Berm\\'udez"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "General Economics (econ.GN)",
        "Economics (q-fin.EC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T15:20:10+00:00",
          "link": "https://arxiv.org/abs/2506.23952v1",
          "size": "457kb",
          "version": "v1"
        },
        {
          "date": "2025-07-01T05:46:26+00:00",
          "link": "https://arxiv.org/abs/2506.23952v2",
          "size": "457kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T09:55:27+00:00",
          "link": "https://arxiv.org/abs/2506.23952v3",
          "size": "457kb",
          "version": "v3"
        }
      ],
      "title": "Autonomy by Design: Preserving Human Autonomy in AI Decision-Support",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23952",
        "PDF": "https://arxiv.org/pdf/2506.23952"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on AI decision-support systems and human autonomy, without discussing LLM training data processing or data engineering methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06373",
      "abstract": "Medical evacuation is one of the United States Army's most storied and critical mission sets, responsible for efficiently and expediently evacuating the battlefield ill and injured. Medical evacuation planning involves designing a robust network of medical platforms and facilities capable of moving and treating large numbers of casualties. Until now, there has not been a medium to simulate these networks in a classroom setting and evaluate both offline planning and online decision-making performance. This work describes the Medical Evacuation Wargaming Initiative (MEWI), a three-dimensional multiplayer simulation developed in Unity that replicates battlefield constraints and uncertainties. MEWI accurately models patient interactions at casualty collection points, ambulance exchange points, medical treatment facilities, and evacuation platforms. Two operational scenarios are introduced: an amphibious island assault in the Pacific and a Eurasian conflict across a sprawling road and river network. These scenarios pit students against the clock to save as many casualties as possible while adhering to doctrinal lessons learned during didactic training. We visualize performance data collected from two iterations of the MEWI Pacific scenario executed in the United States Army's Medical Evacuation Doctrine Course. We consider post-wargame Likert survey data from student participants and external observer notes to identify key planning decision points, document medical evacuation lessons learned, and quantify general utility. Results indicate that MEWI participation substantially improves uptake of medical evacuation lessons learned and co-operative decision-making. MEWI is a substantial step forward in the field of high-fidelity training tools for medical education, and our study findings offer critical insights into improving medical evacuation education and operations across the joint force.",
      "authors": [
        "Jeremy Fischer",
        "Ram Krishnamoorthy",
        "Vishal Kumar",
        "Mahdi Al-Husseini"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)",
        "Human-Computer Interaction (cs.HC)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T20:20:27+00:00",
          "link": "https://arxiv.org/abs/2507.06373v1",
          "size": "6015kb",
          "version": "v1"
        }
      ],
      "title": "Digital Wargames to Enhance Military Medical Evacuation Decision-Making",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06373",
        "PDF": "https://arxiv.org/pdf/2507.06373"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on simulating medical evacuation operations via a wargaming initiative for educational purposes and does not discuss any aspect of LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2405.19531",
      "abstract": "Advances in robotics have been driving the development of human-robot interaction (HRI) technologies. However, accurately perceiving human actions and achieving adaptive control remains a challenge in facilitating seamless coordination between human and robotic movements. In this paper, we propose a hierarchical procedural framework to enable dynamic robot-assisted hand-object interaction (HOI). An open-loop hierarchy leverages the RGB-based 3D reconstruction of the human hand, based on which motion primitives have been designed to translate hand motions into robotic actions. The low-level coordination hierarchy fine-tunes the robot's action by using the continuously updated 3D hand models. Experimental validation demonstrates the effectiveness of the hierarchical control architecture. The adaptive coordination between human and robot behavior has achieved a delay of $\\leq 0.3$ seconds in the tele-interaction scenario. A case study of ring-wearing tasks indicates the potential application of this work in assistive technologies such as healthcare and manufacturing.",
      "authors": [
        "Mingqi Yuan",
        "Huijiang Wang",
        "Kai-Fung Chu",
        "Fumiya Iida",
        "Bo Li",
        "Wenjun Zeng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-29T21:20:16+00:00",
          "link": "https://arxiv.org/abs/2405.19531v1",
          "size": "21007kb",
          "version": "v1"
        },
        {
          "date": "2025-04-01T14:35:16+00:00",
          "link": "https://arxiv.org/abs/2405.19531v2",
          "size": "21834kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T09:30:00+00:00",
          "link": "https://arxiv.org/abs/2405.19531v3",
          "size": "4589kb",
          "version": "v3"
        }
      ],
      "title": "Hierarchical Procedural Framework for Low-latency Robot-Assisted Hand-Object Interaction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.19531",
        "HTML": "https://arxiv.org/html/2405.19531v3",
        "PDF": "https://arxiv.org/pdf/2405.19531"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on robot-assisted hand-object interaction, using hierarchical procedural frameworks without any LLM training data processing discussion."
      },
      "tasks": [
        "3D Reconstruction",
        "Hand Pose Estimation",
        "Pose Estimation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.03160",
      "abstract": "The recent advancements of Small Language Models (SLMs) have opened new possibilities for efficient code generation. SLMs offer lightweight and cost-effective alternatives to Large Language Models (LLMs), making them attractive for use in resource-constrained environments. However, empirical understanding of SLMs, particularly their capabilities, limitations, and performance trade-offs in code generation remains limited. This study presents a comprehensive empirical evaluation of 20 open-source SLMs ranging from 0.4B to 10B parameters on five diverse code-related benchmarks (HumanEval, MBPP, Mercury, HumanEvalPack, and CodeXGLUE). The models are assessed along three dimensions: i) functional correctness of generated code, ii) computational efficiency and iii) performance across multiple programming languages. The findings of this study reveal that several compact SLMs achieve competitive results while maintaining a balance between performance and efficiency, making them viable for deployment in resource-constrained environments. However, achieving further improvements in accuracy requires switching to larger models. These models generally outperform their smaller counterparts, but they require much more computational power. We observe that for 10% performance improvements, models can require nearly a 4x increase in VRAM consumption, highlighting a trade-off between effectiveness and scalability. Besides, the multilingual performance analysis reveals that SLMs tend to perform better in languages such as Python, Java, and PHP, while exhibiting relatively weaker performance in Go, C++, and Ruby. However, statistical analysis suggests these differences are not significant, indicating a generalizability of SLMs across programming languages. Based on the findings, this work provides insights into the design and selection of SLMs for real-world code generation tasks.",
      "authors": [
        "Md Mahade Hasan and Muhammad Waseem and Kai-Kristian Kemell and Jussi Rasku and Juha Ala-Rantala and Pekka Abrahamsson"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T20:32:36+00:00",
          "link": "https://arxiv.org/abs/2507.03160v1",
          "size": "705kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T10:11:30+00:00",
          "link": "https://arxiv.org/abs/2507.03160v2",
          "size": "705kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T06:49:35+00:00",
          "link": "https://arxiv.org/abs/2507.03160v3",
          "size": "705kb",
          "version": "v3"
        }
      ],
      "title": "Assessing Small Language Models for Code Generation: An Empirical Study with Benchmarks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.03160",
        "HTML": "https://arxiv.org/html/2507.03160v3",
        "PDF": "https://arxiv.org/pdf/2507.03160"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper conducts empirical evaluations of small language models on code generation tasks, focusing on model performance and efficiency rather than the processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06512",
      "abstract": "With advances in large language models (LLMs), new opportunities have emerged to develop tools that support the digital hardware design process. In this work, we explore how LLMs can assist with explaining the root cause of design issues and bugs that are revealed during synthesis and simulation, a necessary milestone on the pathway towards widespread use of LLMs in the hardware design process and for hardware security analysis. We find promising results: for our corpus of 34 different buggy scenarios, OpenAI's o3-mini reasoning model reached a correct determination 100% of the time under pass@5 scoring, with other state of the art models and configurations usually achieving more than 80% performance and more than 90% when assisted with retrieval-augmented generation.",
      "authors": [
        "Siyu Qiu and Muzhi Wang and Raheel Afsharmazayejani and Mohammad Moradi Shahmiri and Benjamin Tan and Hammond Pearce"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T03:25:52+00:00",
          "link": "https://arxiv.org/abs/2507.06512v1",
          "size": "542kb",
          "version": "v1"
        }
      ],
      "title": "Towards LLM-based Root Cause Analysis of Hardware Design Failures",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06512",
        "HTML": "https://arxiv.org/html/2507.06512v1",
        "PDF": "https://arxiv.org/pdf/2507.06512"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses using LLMs for root cause analysis in hardware design, focusing on applications of LLMs rather than any data processing or preparation for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06565",
      "abstract": "Large-language models turn writing into a live exchange between humans and software. We capture this new medium with a discursive-network model that treats people and LLMs as equal nodes and tracks how their statements circulate. Broadening the focus from isolated hallucinations, we define invalidation (any factual, logical, or structural breach) and show it follows four hazards: drift from truth, self-repair, fresh fabrication, and external detection. A general mathematical model of discursive networks is developed to provide valuable insights: A network governed only by drift and self-repair stabilizes at a modest error rate; adding fabrication reproduces the high rates seen in current LLMs. Giving each false claim even a small chance of peer review shifts the system to a truth-dominant state. We operationalize peer review with the open-source \\emph{Flaws-of-Others (FOO) algorithm}: a configurable loop in which any set of agents critique one another while a harmoniser merges their verdicts. The takeaway is practical and cultural: reliability in this new medium comes not from perfecting single models but from wiring imperfect ones into networks that keep each other honest.",
      "authors": [
        "Juan B. Guti\\'errez"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T05:39:56+00:00",
          "link": "https://arxiv.org/abs/2507.06565v1",
          "size": "742kb",
          "version": "v1"
        }
      ],
      "title": "The Flaws of Others: An LLM-driven Framework for Scientific Knowledge Production",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06565",
        "HTML": "https://arxiv.org/html/2507.06565v1",
        "PDF": "https://arxiv.org/pdf/2507.06565"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces an LLM-driven framework for scientific knowledge production, it primarily focuses on a discursive-network model and peer review process rather than on processing LLM training data directly."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06578",
      "abstract": "In this paper, the existence of perfect and quasi-perfect splitter sets in finite abelian groups is studied, motivated by their application in coding theory for flash memory storage. For perfect splitter sets we view them as splittings of $\\mathbb{Z}_n$, and using cyclotomic polynomials we derive a general condition for the existence of such splittings under certain circumstances. We further establish a relation between $B[-k, k](q)$ and $B[-(k-1), k+1](q)$ splitter sets, and give a necessary and sufficient condition for the existence of perfect $B[-1, 5](q)$ splitter sets. Finally, two nonexistence results for quasi-perfect splitter sets are presented.",
      "authors": [
        "Zhiyu Yuan",
        "Rongquan Feng and Gennian Ge"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T06:10:09+00:00",
          "link": "https://arxiv.org/abs/2507.06578v1",
          "size": "18kb",
          "version": "v1"
        }
      ],
      "title": "On the Existence and Nonexistence of Splitter Sets",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06578",
        "HTML": "https://arxiv.org/html/2507.06578v1",
        "PDF": "https://arxiv.org/pdf/2507.06578"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses mathematical properties of splitter sets in finite abelian groups and their application in coding theory, with no focus on LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07028",
      "abstract": "It is known that real Mutually Unbiased Bases (MUBs) do not exist for any dimension $d > 2$ which is not divisible by 4. Thus, the next combinatorial question is how one can construct Approximate Real MUBs (ARMUBs) in this direction with encouraging parameters. In this paper, for the first time, we show that it is possible to construct $> \\lceil \\sqrt{d} \\rceil$ many ARMUBs for certain odd dimensions $d$ of the form $d = (4n-t)s$, $t = 1, 2, 3$, where $n$ is a natural number and $s$ is an odd prime power. Our method exploits any available $4n \\times 4n$ real Hadamard matrix $H_{4n}$ (conjectured to be true) and uses this to construct an orthogonal matrix ${Y}_{4n-t}$ of size $(4n - t) \\times (4n - t)$, such that the absolute value of each entry varies a little from $\\frac{1}{4n-t}$. In our construction, the absolute value of the inner product between any pair of basis vectors from two different ARMUBs will be $\\leq \\frac{1}{\\sqrt{d}}(1 + O(d^{-\\frac{1}{2}})) < 2$, for proper choices of parameters, the class of dimensions $d$ being infinitely large.",
      "authors": [
        "Ajeet Kumar",
        "Rakesh Kumar",
        "Subhamoy Maitra",
        "Uddipto Mandal"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T16:58:56+00:00",
          "link": "https://arxiv.org/abs/2507.07028v1",
          "size": "31kb",
          "version": "v1"
        }
      ],
      "title": "On Construction of Approximate Real Mutually Unbiased Bases for an infinite class of dimensions $d \\not\\equiv 0 \\bmod 4$",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07028",
        "HTML": "https://arxiv.org/html/2507.07028v1",
        "PDF": "https://arxiv.org/pdf/2507.07028"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper involves the construction of mathematical structures (MUBs) and does not relate to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.14931",
      "abstract": "We propose Hier-SLAM++, a comprehensive Neuro-Symbolic semantic 3D Gaussian Splatting SLAM method with both RGB-D and monocular input featuring an advanced hierarchical categorical representation, which enables accurate pose estimation as well as global 3D semantic mapping. The parameter usage in semantic SLAM systems increases significantly with the growing complexity of the environment, making scene understanding particularly challenging and costly. To address this problem, we introduce a novel hierarchical representation that encodes both semantic and geometric information in a compact form into 3D Gaussian Splatting, leveraging the capabilities of large language models (LLMs) as well as the 3D generative model. By utilizing the proposed hierarchical tree structure, semantic information is symbolically represented and learned in an end-to-end manner. We further introduce an advanced semantic loss designed to optimize hierarchical semantic information through both Intra-level and Inter-level optimizations. Additionally, we propose an improved SLAM system to support both RGB-D and monocular inputs using a feed-forward model. To the best of our knowledge, this is the first semantic monocular Gaussian Splatting SLAM system, significantly reducing sensor requirements for 3D semantic understanding and broadening the applicability of semantic Gaussian SLAM system. We conduct experiments on both synthetic and real-world datasets, demonstrating superior or on-par performance with state-of-the-art methods, while significantly reducing storage and training time requirements. Our project page is available at: https://hierslampp.github.io/",
      "authors": [
        "Boying Li",
        "Vuong Chi Hao",
        "Peter J. Stuckey",
        "Ian Reid",
        "Hamid Rezatofighi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-20T06:27:40+00:00",
          "link": "https://arxiv.org/abs/2502.14931v1",
          "size": "1064kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T00:27:05+00:00",
          "link": "https://arxiv.org/abs/2502.14931v2",
          "size": "5192kb",
          "version": "v2"
        }
      ],
      "title": "Hier-SLAM++: Neuro-Symbolic Semantic SLAM with a Hierarchically Categorical Gaussian Splatting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.14931",
        "HTML": "https://arxiv.org/html/2502.14931v2",
        "PDF": "https://arxiv.org/pdf/2502.14931"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a semantic SLAM system using neuro-symbolic methods and does not discuss any aspect of LLM training data collection, processing, or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06352",
      "abstract": "This study presents an analytical method for tuning PI controllers in First-Order with Time Delay (FOTD) systems, leveraging the Lambert W function. The Lambert W function enables exact pole placement, yielding analytical expressions for PI gains. The proposed approach identifies a critical condition that achieves a step response without overshoot with minimum settling time, while also providing explicit tuning rules for systems where controlled overshoot is specified. The method demonstrates strong agreement with established empirical Chien-Hrones-Reswick tuning rules for both non-overshooting and overshooting cases, bridging the gap between theoretical analysis and empirical results.",
      "authors": [
        "Senol Gulgonul"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T19:25:01+00:00",
          "link": "https://arxiv.org/abs/2507.06352v1",
          "size": "342kb",
          "version": "v1"
        }
      ],
      "title": "Revisiting Chien-Hrones-Reswick Method for an Analytical Solution",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06352",
        "PDF": "https://arxiv.org/pdf/2507.06352"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study provides analytical methods for tuning PI controllers, focusing on control systems, without discussing data processing relevant to LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06723",
      "abstract": "Malware developers exploit the fact that most detection models focus on the entire binary to extract the feature rather than on the regions of potential maliciousness. Therefore, they reverse engineer a benign binary and inject malicious code into it. This obfuscation technique circumvents the malware detection models and deceives the ML classifiers due to the prevalence of benign features compared to malicious features. However, extracting the features from the potential malicious regions enhances the accuracy and decreases false positives. Hence, we propose a novel model named PotentRegion4MalDetect that extracts features from the potential malicious regions. PotentRegion4MalDetect determines the nodes with potential maliciousness in the partially preprocessed Control Flow Graph (CFG) using the malicious strings given by StringSifter. Then, it extracts advanced features of the identified potential malicious regions alongside the features from the completely preprocessed CFG. The features extracted from the completely preprocessed CFG mitigate obfuscation techniques that attempt to disguise malicious content, such as suspicious strings. The experiments reveal that the PotentRegion4MalDetect requires fewer entries to save the features for all binaries than the model focusing on the entire binary, reducing memory overhead, faster computation, and lower storage requirements. These advanced features give an 8.13% increase in SHapley Additive exPlanations (SHAP) Absolute Mean and a 1.44% increase in SHAP Beeswarm value compared to those extracted from the entire binary. The advanced features outperform the features extracted from the entire binary by producing more than 99% accuracy, precision, recall, AUC, F1-score, and 0.064% FPR.",
      "authors": [
        "Rama Krishna Koppanati",
        "Monika Santra",
        "and Sateesh Kumar Peddoju"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T10:32:17+00:00",
          "link": "https://arxiv.org/abs/2507.06723v1",
          "size": "18703kb",
          "version": "v1"
        }
      ],
      "title": "PotentRegion4MalDetect: Advanced Features from Potential Malicious Regions for Malware Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06723",
        "HTML": "https://arxiv.org/html/2507.06723v1",
        "PDF": "https://arxiv.org/pdf/2507.06723"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on advanced feature extraction for malware detection and not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.08740",
      "abstract": "Specimen-associated biodiversity data are crucial for biological, environmental, and conservation sciences. A rate shift is needed to extract data from specimen images efficiently, moving beyond human-mediated transcription. We developed `Hespi' (HErbarium Specimen sheet PIpeline) using advanced computer vision techniques to extract pre-catalogue data from primary specimen labels on herbarium specimens. Hespi integrates two object detection models: one for detecting the components of the sheet and another for fields on the primary primary specimen label. It classifies labels as printed, typed, handwritten, or mixed and uses Optical Character Recognition (OCR) and Handwritten Text Recognition (HTR) for extraction. The text is then corrected against authoritative taxon databases and refined using a multimodal Large Language Model (LLM). Hespi accurately detects and extracts text from specimen sheets across international herbaria, and its modular design allows users to train and integrate custom models.",
      "authors": [
        "Robert Turnbull and Emily Fitzgerald and Karen Thompson and Joanne L. Birch"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-11T11:59:40+00:00",
          "link": "https://arxiv.org/abs/2410.08740v1",
          "size": "5294kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T03:54:32+00:00",
          "link": "https://arxiv.org/abs/2410.08740v2",
          "size": "5276kb",
          "version": "v2"
        }
      ],
      "title": "Hespi: A pipeline for automatically detecting information from hebarium specimen sheets",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.08740",
        "HTML": "https://arxiv.org/html/2410.08740v2",
        "PDF": "https://arxiv.org/pdf/2410.08740"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper focuses on extracting information from herbarium specimen sheets using computer vision and LLMs, it does not focus on creating or processing LLM training data, thus only briefly involving LLMs in a secondary role."
      },
      "tasks": [
        "Handwritten Text Recognition",
        "HTR",
        "Language Modelling",
        "Large Language Model",
        "Multimodal Large Language Model",
        "object-detection",
        "Object Detection",
        "Optical Character Recognition",
        "Optical Character Recognition (OCR)"
      ],
      "repo_urls": [
        "https://github.com/rbturnbull/hespi"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.05963",
      "abstract": "Recent advances in diffusion transformer models for motion-guided video generation, such as Tora, have shown significant progress. In this paper, we present Tora2, an enhanced version of Tora, which introduces several design improvements to expand its capabilities in both appearance and motion customization. Specifically, we introduce a decoupled personalization extractor that generates comprehensive personalization embeddings for multiple open-set entities, better preserving fine-grained visual details compared to previous methods. Building on this, we design a gated self-attention mechanism to integrate trajectory, textual description, and visual information for each entity. This innovation significantly reduces misalignment in multimodal conditioning during training. Moreover, we introduce a contrastive loss that jointly optimizes trajectory dynamics and entity consistency through explicit mapping between motion and personalization embeddings. Tora2 is, to our best knowledge, the first method to achieve simultaneous multi-entity customization of appearance and motion for video generation. Experimental results demonstrate that Tora2 achieves competitive performance with state-of-the-art customization methods while providing advanced motion control capabilities, which marks a critical advancement in multi-condition video generation. Project page: https://ali-videoai.github.io/Tora2_page/.",
      "authors": [
        "Zhenghao Zhang",
        "Junchao Liao",
        "Xiangyu Meng",
        "Long Qin",
        "Weizhi Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T13:11:40+00:00",
          "link": "https://arxiv.org/abs/2507.05963v1",
          "size": "8826kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T07:01:34+00:00",
          "link": "https://arxiv.org/abs/2507.05963v2",
          "size": "8826kb",
          "version": "v2"
        }
      ],
      "title": "Tora2: Motion and Appearance Customized Diffusion Transformer for Multi-Entity Video Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05963",
        "HTML": "https://arxiv.org/html/2507.05963v2",
        "PDF": "https://arxiv.org/pdf/2507.05963"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on video generation using a diffusion transformer model, which does not involve processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.03521",
      "abstract": "Over the past few years, neural network methods have evolved in various directions for approximating partial differential equations (PDEs). A promising new development is the integration of neural networks with classical numerical techniques such as finite elements and finite differences. In this paper, we introduce a new class of Physics-Informed Neural Networks (PINNs) trained using discontinuous Galerkin finite element methods. Unlike standard collocation-based PINNs that rely on pointwise gradient evaluations and Monte Carlo quadrature, our approach computes the loss functional using finite element interpolation and integration. This avoids costly pointwise derivative computations, particularly advantageous for elliptic PDEs requiring second-order derivatives, and inherits key stability and accuracy benefits from the finite element framework. We present a convergence analysis based on variational arguments and support our theoretical findings with numerical experiments that demonstrate improved efficiency and robustness.",
      "authors": [
        "Georgios Grekas",
        "Charalambos G. Makridakis and Tristan Pryer"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Computational Physics (physics.comp-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-04T12:16:57+00:00",
          "link": "https://arxiv.org/abs/2507.03521v1",
          "size": "817kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T10:59:30+00:00",
          "link": "https://arxiv.org/abs/2507.03521v2",
          "size": "817kb",
          "version": "v2"
        }
      ],
      "title": "PINN-DG: Residual neural network methods trained with Finite Elements",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.03521",
        "HTML": "https://arxiv.org/html/2507.03521v2",
        "PDF": "https://arxiv.org/pdf/2507.03521"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a new class of neural networks for approximating partial differential equations, and does not discuss any aspects related to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05656",
      "abstract": "Computational pathology (CoPath) leverages histopathology images to enhance diagnostic precision and reproducibility in clinical pathology. However, publicly available datasets for CoPath that are annotated with extensive histological tissue type (HTT) taxonomies at a granular level remain scarce due to the significant expertise and high annotation costs required. Existing datasets, such as the Atlas of Digital Pathology (ADP), address this by offering diverse HTT annotations generalized to multiple organs, but limit the capability for in-depth studies on specific organ diseases. Building upon this foundation, we introduce ADPv2, a novel dataset focused on gastrointestinal histopathology. Our dataset comprises 20,004 image patches derived from healthy colon biopsy slides, annotated according to a hierarchical taxonomy of 32 distinct HTTs of 3 levels. Furthermore, we train a multilabel representation learning model following a two-stage training procedure on our ADPv2 dataset. We leverage the VMamba architecture and achieving a mean average precision (mAP) of 0.88 in multilabel classification of colon HTTs. Finally, we show that our dataset is capable of an organ-specific in-depth study for potential biomarker discovery by analyzing the model's prediction behavior on tissues affected by different colon diseases, which reveals statistical patterns that confirm the two pathological pathways of colon cancer development. Our dataset is publicly available at https://zenodo.org/records/15307021",
      "authors": [
        "Zhiyuan Yang",
        "Kai Li",
        "Sophia Ghamoshi Ramandi",
        "Patricia Brassard",
        "Hakim Khellaf",
        "Vincent Quoc-Huy Trinh",
        "Jennifer Zhang",
        "Lina Chen",
        "Corwyn Rowsell",
        "Sonal Varma",
        "Kostas Plataniotis",
        "Mahdi S. Hosseini"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)",
        "Quantitative Methods (q-bio.QM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T04:19:10+00:00",
          "link": "https://arxiv.org/abs/2507.05656v1",
          "size": "14373kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T15:16:20+00:00",
          "link": "https://arxiv.org/abs/2507.05656v2",
          "size": "14373kb",
          "version": "v2"
        }
      ],
      "title": "ADPv2: A Hierarchical Histological Tissue Type-Annotated Dataset for Potential Biomarker Discovery of Colorectal Disease",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05656",
        "HTML": "https://arxiv.org/html/2507.05656v2",
        "PDF": "https://arxiv.org/pdf/2507.05656"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes the creation of a novel histological dataset (ADPv2) and its application in biomarker discovery for colorectal disease, but it does not focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06379",
      "abstract": "Compute governance can underpin international institutions for the governance of frontier AI. To demonstrate this I explore four institutions for governing and developing frontier AI. Next steps for compute-indexed domestic frontier AI regulation could include risk assessments and pre-approvals, data centre usage reports, and release gate regulation. Domestic regimes could be harmonized and monitored through an International AI Agency - an International Atomic Energy Agency (IAEA) for AI. This could be backed up by a Secure Chips Agreement - a Non-Proliferation Treaty (NPT) for AI. This would be a non-proliferation regime for advanced chips, building on the chip export controls - states that do not have an IAIA-certified frontier regulation regime would not be allowed to import advanced chips. Frontier training runs could be carried out by a megaproject between the USA and its allies - a US-led Allied Public-Private Partnership for frontier AI. As a project to develop advanced AI, this could have significant advantages over alternatives led by Big Tech or particular states: it could be more legitimate, secure, safe, non-adversarial, peaceful, and less prone to misuse. For each of these four scenarios, a key incentive for participation is access to the advanced AI chips that are necessary for frontier training runs and large-scale inference. Together, they can create a situation in which governments can be reassured that frontier AI is developed and deployed in a secure manner with misuse minimised and benefits widely shared. Building these institutions may take years or decades, but progress is incremental and evolutionary and the first steps have already been taken.",
      "authors": [
        "Haydn Belfield"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T20:32:28+00:00",
          "link": "https://arxiv.org/abs/2507.06379v1",
          "size": "1358kb",
          "version": "v1"
        }
      ],
      "title": "Domestic frontier AI regulation, an IAEA for AI, an NPT for AI, and a US-led Allied Public-Private Partnership for AI: Four institutions for governing and developing frontier AI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06379",
        "HTML": "https://arxiv.org/html/2507.06379v1",
        "PDF": "https://arxiv.org/pdf/2507.06379"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses governance and regulation of AI, without any focus on LLM training data processes or improvements."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06438",
      "abstract": "Tools that can generate computer code in response to inputs written in natural language, such as ChatGPT, pose an existential threat to Computer Science education in its current form, since students can now use these tools to solve assignments without much effort. While that risk has already been recognized by scholars, the proportion of the student body that is incurring in this new kind of plagiarism is still an open problem. We conducted a pilot study in a large CS class (n=120) to assess the feasibility of estimating AI plagiarism through anonymous surveys and interviews. More than 25% of the survey respondents admitted to committing AI plagiarism. Conversely, only one student accepted to be interviewed. Given the high levels of misconduct acknowledgment, we conclude that surveys are an effective method for studies on the matter, while interviews should be avoided or designed in a way that can entice participation.",
      "authors": [
        "Kal\\'eu Delphino"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T22:40:44+00:00",
          "link": "https://arxiv.org/abs/2507.06438v1",
          "size": "932kb",
          "version": "v1"
        }
      ],
      "title": "Assessing the Prevalence of AI-assisted Cheating in Programming Courses: A Pilot Study",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06438",
        "PDF": "https://arxiv.org/pdf/2507.06438"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper conducts a study on AI-assisted cheating in programming courses and does not deal with any aspect of LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06795",
      "abstract": "The emergence of open-source large language models (LLMs) has expanded opportunities for enterprise applications; however, many organizations still lack the infrastructure to deploy and maintain large-scale models. As a result, small LLMs (sLLMs) have become a practical alternative, despite their inherent performance limitations. While Domain Adaptive Continual Pretraining (DACP) has been previously explored as a method for domain adaptation, its utility in commercial applications remains under-examined. In this study, we validate the effectiveness of applying a DACP-based recipe across diverse foundation models and service domains. Through extensive experiments and real-world evaluations, we demonstrate that DACP-applied sLLMs achieve substantial gains in target domain performance while preserving general capabilities, offering a cost-efficient and scalable solution for enterprise-level deployment.",
      "authors": [
        "Seonwu Kim",
        "Yohan Na",
        "Kihun Kim",
        "Hanhee Cho",
        "Geun Lim",
        "Mintae Kim",
        "Seongik Park",
        "Ki Hyun Kim",
        "Youngsub Han",
        "Byoung-Ki Jeon"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T12:30:42+00:00",
          "link": "https://arxiv.org/abs/2507.06795v1",
          "size": "1050kb",
          "version": "v1"
        }
      ],
      "title": "Efficient Industrial sLLMs through Domain Adaptive Continual Pretraining: Method, Evaluation and Applications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06795",
        "HTML": "https://arxiv.org/html/2507.06795v1",
        "PDF": "https://arxiv.org/pdf/2507.06795"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper explores Domain Adaptive Continual Pretraining for small LLMs, mentioning domain adaptation techniques but not primarily focusing on data processing steps for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.14920",
      "abstract": "Quantitative Structure-Activity Relationship (QSAR) modeling is a cornerstone of computational drug discovery. This research demonstrates the successful application of a Quantum Multiple Kernel Learning (QMKL) framework to enhance QSAR classification, showing a notable performance improvement over classical methods. We apply this methodology to a dataset for identifying DYRK1A kinase inhibitors. The workflow involves converting SMILES representations into numerical molecular descriptors, reducing dimensionality via Principal Component Analysis (PCA), and employing a Support Vector Machine (SVM) trained on an optimized combination of multiple quantum and classical kernels. By benchmarking the QMKL-SVM against a classical Gradient Boosting model, we show that the quantum-enhanced approach achieves a superior AUC score, highlighting its potential to provide a quantum advantage in challenging cheminformatics classification tasks.",
      "authors": [
        "Alejandro Giraldo and Daniel Ruiz and Mariano Caruso and Javier Mancilla and Guido Bellomo"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-17T19:00:47+00:00",
          "link": "https://arxiv.org/abs/2506.14920v1",
          "size": "152kb",
          "version": "v1"
        },
        {
          "date": "2025-06-24T15:57:50+00:00",
          "link": "https://arxiv.org/abs/2506.14920v2",
          "size": "153kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T05:09:16+00:00",
          "link": "https://arxiv.org/abs/2506.14920v3",
          "size": "153kb",
          "version": "v3"
        }
      ],
      "title": "Q2SAR: A Quantum Multiple Kernel Learning Approach for Drug Discovery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.14920",
        "HTML": "https://arxiv.org/html/2506.14920v3",
        "PDF": "https://arxiv.org/pdf/2506.14920"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research applies quantum machine learning to drug discovery using QSAR modeling. It involves neither LLMs nor their training data processing."
      },
      "tasks": [
        "Benchmarking",
        "Drug Discovery"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.05116",
      "abstract": "Recent large-scale Vision Language Action (VLA) models have shown superior performance in robotic manipulation tasks guided by natural language. However, their generalization remains limited when applied to novel objects or unfamiliar environments that lie outside the training distribution. To address this, many existing approaches integrate additional components such as depth estimation, segmentation, or even diffusion to improve generalization, at the cost of adding significant computation overhead, resulting in low efficiency. This motivates the exploration of efficient action prediction methods, which are independent of additional high-level visual representations or diffusion techniques. In this work, we propose VOTE, an efficient and general framework for the optimization and acceleration of VLA models. In details, we propose a novel tokenizer-free fine-tuning approach for parallel accurate action prediction, which reduces computational overhead and accelerates inference speed. Additionally, we adopt an ensemble voting strategy for the action sampling, which significantly improves model performance and enhances generalization. Experimental results show that our method achieves state-of-the-art performance with 35$\\times$ faster inference and 145 Hz throughput. All the details and codes will be open-sourced.",
      "authors": [
        "Juyi Lin",
        "Amir Taherin",
        "Arash Akbari",
        "Arman Akbari",
        "Lei Lu",
        "Guangyu Chen",
        "Taskin Padir",
        "Xiaomeng Yang",
        "Weiwei Chen",
        "Yiqian Li",
        "Xue Lin",
        "David Kaeli",
        "Pu Zhao",
        "and Yanzhi Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T15:30:55+00:00",
          "link": "https://arxiv.org/abs/2507.05116v1",
          "size": "660kb",
          "version": "v1"
        }
      ],
      "title": "VOTE: Vision-Language-Action Optimization with Trajectory Ensemble Voting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05116",
        "HTML": "https://arxiv.org/html/2507.05116",
        "PDF": "https://arxiv.org/pdf/2507.05116"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses a tokenizer-free fine-tuning method for VLA models, which may involve some data processing but focuses primarily on model optimization rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07100",
      "abstract": "Domain-Incremental Learning (DIL) focuses on continual learning in non-stationary environments, requiring models to adjust to evolving domains while preserving historical knowledge. DIL faces two critical challenges in the context of imbalanced data: intra-domain class imbalance and cross-domain class distribution shifts. These challenges significantly hinder model performance, as intra-domain imbalance leads to underfitting of few-shot classes, while cross-domain shifts require maintaining well-learned many-shot classes and transferring knowledge to improve few-shot class performance in old domains. To overcome these challenges, we introduce the Dual-Balance Collaborative Experts (DCE) framework. DCE employs a frequency-aware expert group, where each expert is guided by specialized loss functions to learn features for specific frequency groups, effectively addressing intra-domain class imbalance. Subsequently, a dynamic expert selector is learned by synthesizing pseudo-features through balanced Gaussian sampling from historical class statistics. This mechanism navigates the trade-off between preserving many-shot knowledge of previous domains and leveraging new data to improve few-shot class performance in earlier tasks. Extensive experimental results on four benchmark datasets demonstrate DCE's state-of-the-art performance.",
      "authors": [
        "Lan Li",
        "Da-Wei Zhou",
        "Han-Jia Ye",
        "De-Chuan Zhan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T17:57:07+00:00",
          "link": "https://arxiv.org/abs/2507.07100v1",
          "size": "730kb",
          "version": "v1"
        }
      ],
      "title": "Addressing Imbalanced Domain-Incremental Learning through Dual-Balance Collaborative Experts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07100",
        "HTML": "https://arxiv.org/html/2507.07100v1",
        "PDF": "https://arxiv.org/pdf/2507.07100"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "While the paper tackles domain-incremental learning issues, it does not focus on LLM training data processing or preparation, but rather on model adaptation and performance metrics."
      },
      "source": "arXiv"
    },
    {
      "id": "2311.18564",
      "abstract": "Seam cutting has shown significant effectiveness in the composition phase of image stitching, particularly for scenarios involving parallax. However, conventional implementations typically position seam-cutting as a downstream process contingent upon successful image alignment. This approach inherently assumes the existence of locally aligned regions where visually plausible seams can be established. Current alignment methods frequently fail to satisfy this prerequisite in large parallax scenarios despite considerable research efforts dedicated to improving alignment accuracy. In this paper, we propose an alignment-compensation paradigm that dissociates seam quality from initial alignment accuracy by integrating a Local Patch Alignment Module (LPAM) into the seam-cutting pipeline. Concretely, given the aligned images with an estimated initial seam, our method first identifies low-quality pixels along the seam through a seam quality assessment, then performs localized SIFT-flow alignment on the critical patches enclosing these pixels. Finally, we recomposite the aligned patches using adaptive seam-cutting and merge them into the original aligned images to generate the final mosaic. Comprehensive experiments on large parallax stitching datasets demonstrate that LPAM significantly enhances stitching quality while maintaining computational efficiency. The code is available at https://github.com/tlliao/LPAM_seam-cutting.",
      "authors": [
        "Tianli Liao",
        "Chenyang Zhao",
        "Lei Li and Heling Cao"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2023-11-30T13:55:29+00:00",
          "link": "https://arxiv.org/abs/2311.18564v1",
          "size": "9758kb",
          "version": "v1"
        },
        {
          "date": "2025-01-19T15:28:24+00:00",
          "link": "https://arxiv.org/abs/2311.18564v2",
          "size": "11993kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T02:43:36+00:00",
          "link": "https://arxiv.org/abs/2311.18564v3",
          "size": "10981kb",
          "version": "v3"
        }
      ],
      "title": "Leveraging Local Patch Alignment to Seam-cutting for Large Parallax Image Stitching",
      "links": {
        "Abstract": "https://arxiv.org/abs/2311.18564",
        "HTML": "https://arxiv.org/html/2311.18564v3",
        "PDF": "https://arxiv.org/pdf/2311.18564"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with an image stitching method involving seam-cutting and local patch alignment, which is unrelated to processing LLM training data."
      },
      "tasks": [
        "Image Stitching"
      ],
      "repo_urls": [
        "https://github.com/tlliao/lpam_seam-cutting"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.02825",
      "abstract": "Benchmarks are essential for quantitatively tracking progress in AI. As AI agents become increasingly capable, researchers and practitioners have introduced agentic benchmarks to evaluate agents on complex, real-world tasks. These benchmarks typically measure agent capabilities by evaluating task outcomes via specific reward designs. However, we show that many agentic benchmarks have issues in task setup or reward design. For example, SWE-bench Verified uses insufficient test cases, while TAU-bench counts empty responses as successful. Such issues can lead to under- or overestimation of agents' performance by up to 100% in relative terms. To make agentic evaluation rigorous, we introduce the Agentic Benchmark Checklist (ABC), a set of guidelines that we synthesized from our benchmark-building experience, a survey of best practices, and previously reported issues. When applied to CVE-Bench, a benchmark with a particularly complex evaluation design, ABC reduces the performance overestimation by 33%.",
      "authors": [
        "Yuxuan Zhu",
        "Tengjun Jin",
        "Yada Pruksachatkun",
        "Andy Zhang",
        "Shu Liu",
        "Sasha Cui",
        "Sayash Kapoor",
        "Shayne Longpre",
        "Kevin Meng",
        "Rebecca Weiss",
        "Fazl Barez",
        "Rahul Gupta",
        "Jwala Dhamala",
        "Jacob Merizian",
        "Mario Giulianelli",
        "Harry Coppock",
        "Cozmin Ududec",
        "Jasjeet Sekhon",
        "Jacob Steinhardt",
        "Antony Kellerman",
        "Sarah Schwettmann",
        "Matei Zaharia",
        "Ion Stoica",
        "Percy Liang",
        "Daniel Kang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T17:35:31+00:00",
          "link": "https://arxiv.org/abs/2507.02825v1",
          "size": "671kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T21:45:08+00:00",
          "link": "https://arxiv.org/abs/2507.02825v2",
          "size": "671kb",
          "version": "v2"
        }
      ],
      "title": "Establishing Best Practices for Building Rigorous Agentic Benchmarks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02825",
        "HTML": "https://arxiv.org/html/2507.02825v2",
        "PDF": "https://arxiv.org/pdf/2507.02825"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on establishing benchmarks for evaluating AI agents, which involves task setup and reward design, not on processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06274",
      "abstract": "Watermarking is a promising defense against the misuse of large language models (LLMs), yet it remains vulnerable to scrubbing and spoofing attacks. This vulnerability stems from an inherent trade-off governed by watermark window size: smaller windows resist scrubbing better but are easier to reverse-engineer, enabling low-cost statistics-based spoofing attacks. This work breaks this trade-off by introducing a novel mechanism, equivalent texture keys, where multiple tokens within a watermark window can independently support the detection. Based on the redundancy, we propose a novel watermark scheme with Sub-vocabulary decomposed Equivalent tExture Key (SEEK). It achieves a Pareto improvement, increasing the resilience against scrubbing attacks without compromising robustness to spoofing. Experiments demonstrate SEEK's superiority over prior method, yielding spoofing robustness gains of +88.2%/+92.3%/+82.0% and scrubbing robustness gains of +10.2%/+6.4%/+24.6% across diverse dataset settings.",
      "authors": [
        "Huanming Shen and Baizhou Huang and Xiaojun Wan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T11:14:00+00:00",
          "link": "https://arxiv.org/abs/2507.06274v1",
          "size": "8178kb",
          "version": "v1"
        }
      ],
      "title": "Enhancing LLM Watermark Resilience Against Both Scrubbing and Spoofing Attacks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06274",
        "HTML": "https://arxiv.org/html/2507.06274v1",
        "PDF": "https://arxiv.org/pdf/2507.06274"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper presents a novel watermark scheme for LLMs to defend against attacks, focusing on resilience techniques rather than processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06535",
      "abstract": "Graph representation learning on Analog-Mixed Signal (AMS) circuits is crucial for various downstream tasks, e.g., parasitic estimation. However, the scarcity of design data, the unbalanced distribution of labels, and the inherent diversity of circuit implementations pose significant challenges to learning robust and transferable circuit representations. To address these limitations, we propose CircuitGCL, a novel graph contrastive learning framework that integrates representation scattering and label rebalancing to enhance transferability across heterogeneous circuit graphs. CircuitGCL employs a self-supervised strategy to learn topology-invariant node embeddings through hyperspherical representation scattering, eliminating dependency on large-scale data. Simultaneously, balanced mean squared error (MSE) and softmax cross-entropy (bsmCE) losses are introduced to mitigate label distribution disparities between circuits, enabling robust and transferable parasitic estimation. Evaluated on parasitic capacitance estimation (edge-level task) and ground capacitance classification (node-level task) across TSMC 28nm AMS designs, CircuitGCL outperforms all state-of-the-art (SOTA) methods, with the $R^2$ improvement of $33.64\\% \\sim 44.20\\%$ for edge regression and F1-score gain of $0.9\\times \\sim 2.1\\times$ for node classification. Our code is available at \\href{https://anonymous.4open.science/r/CircuitGCL-099B/README.md}{here}.",
      "authors": [
        "Shan Shen",
        "Shenglu Hua",
        "Jiajun Zou",
        "Jiawei Liu",
        "Jianwang Zhai",
        "Chuan Shi",
        "Wenjian Yu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T04:31:10+00:00",
          "link": "https://arxiv.org/abs/2507.06535v1",
          "size": "2495kb",
          "version": "v1"
        }
      ],
      "title": "Transferable Parasitic Estimation via Graph Contrastive Learning and Label Rebalancing in AMS Circuits",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06535",
        "PDF": "https://arxiv.org/pdf/2507.06535"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on graph representation learning for AMS circuits and parasitic estimation, without discussing any aspect of LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06689",
      "abstract": "We propose a novel spatial-temporal graph Mamba (STG-Mamba) for the music-guided dance video synthesis task, i.e., to translate the input music to a dance video. STG-Mamba consists of two translation mappings: music-to-skeleton translation and skeleton-to-video translation. In the music-to-skeleton translation, we introduce a novel spatial-temporal graph Mamba (STGM) block to effectively construct skeleton sequences from the input music, capturing dependencies between joints in both the spatial and temporal dimensions. For the skeleton-to-video translation, we propose a novel self-supervised regularization network to translate the generated skeletons, along with a conditional image, into a dance video. Lastly, we collect a new skeleton-to-video translation dataset from the Internet, containing 54,944 video clips. Extensive experiments demonstrate that STG-Mamba achieves significantly better results than existing methods.",
      "authors": [
        "Hao Tang",
        "Ling Shao",
        "Zhenyu Zhang",
        "Luc Van Gool",
        "Nicu Sebe"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T09:33:23+00:00",
          "link": "https://arxiv.org/abs/2507.06689v1",
          "size": "19122kb",
          "version": "v1"
        }
      ],
      "title": "Spatial-Temporal Graph Mamba for Music-Guided Dance Video Synthesis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06689",
        "HTML": "https://arxiv.org/html/2507.06689v1",
        "PDF": "https://arxiv.org/pdf/2507.06689"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper mentions the creation of a new dataset for dance video synthesis, its primary contribution is model methodology for skeletal and video translation, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2310.11482",
      "abstract": "The integration of large pre-trained models (PTMs) into Class-Incremental Learning (CIL) has facilitated the development of computationally efficient strategies such as First-Session Adaptation (FSA), which fine-tunes the model solely on the first task while keeping it frozen for subsequent tasks. Although effective in homogeneous task sequences, these approaches struggle when faced with the heterogeneity of real-world task distributions. We introduce Plasticity-Enhanced Test-Time Adaptation in Class-Incremental Learning (PLASTIC), a method that reinstates plasticity in CIL while preserving model stability. PLASTIC leverages Test-Time Adaptation (TTA) by dynamically fine-tuning LayerNorm parameters on unlabeled test data, enabling adaptability to evolving tasks and improving robustness against data corruption. To prevent TTA-induced model divergence and maintain stable learning across tasks, we introduce a teacher-student distillation framework, ensuring that adaptation remains controlled and generalizable. Extensive experiments across multiple benchmarks demonstrate that PLASTIC consistently outperforms both conventional and state-of-the-art PTM-based CIL approaches, while also exhibiting inherent robustness to data corruptions. Code is available at: https://github.com/IemProg/PLASTIC.",
      "authors": [
        "Imad Eddine Marouf",
        "Subhankar Roy",
        "St\\'ephane Lathuili\\`ere",
        "Enzo Tartaglione"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2023-10-17T13:06:39+00:00",
          "link": "https://arxiv.org/abs/2310.11482v1",
          "size": "2049kb",
          "version": "v1"
        },
        {
          "date": "2024-03-14T15:10:05+00:00",
          "link": "https://arxiv.org/abs/2310.11482v2",
          "size": "1866kb",
          "version": "v2"
        },
        {
          "date": "2025-07-08T20:46:01+00:00",
          "link": "https://arxiv.org/abs/2310.11482v3",
          "size": "423kb",
          "version": "v3"
        }
      ],
      "title": "Enhancing Plasticity for First Session Adaptation Continual Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2310.11482",
        "HTML": "https://arxiv.org/html/2310.11482v3",
        "PDF": "https://arxiv.org/pdf/2310.11482"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a method for enhancing continual learning with PLASTIC, focusing on model adaptation techniques and robustness, with brief mention but no focus on training data processing."
      },
      "tasks": [
        "class-incremental learning",
        "Class Incremental Learning",
        "Incremental Learning",
        "Test-time Adaptation"
      ],
      "repo_urls": [
        "https://github.com/iemprog/mimi"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.12399",
      "abstract": "Current financial large language models (FinLLMs) struggle with two critical limitations: the absence of objective evaluation metrics to assess the quality of stock analysis reports and a lack of depth in stock analysis, which impedes their ability to generate professional-grade insights. To address these challenges, this paper introduces FinSphere, a stock analysis agent, along with three major contributions: (1) AnalyScore, a systematic evaluation framework for assessing stock analysis quality, (2) Stocksis, a dataset curated by industry experts to enhance LLMs' stock analysis capabilities, and (3) FinSphere, an AI agent that can generate high-quality stock analysis reports in response to user queries. Experiments demonstrate that FinSphere achieves superior performance compared to both general and domain-specific LLMs, as well as existing agent-based systems, even when they are enhanced with real-time data access and few-shot guidance. The integrated framework, which combines real-time data feeds, quantitative tools, and an instruction-tuned LLM, yields substantial improvements in both analytical quality and practical applicability for real-world stock analysis.",
      "authors": [
        "Shijie Han",
        "Jingshu Zhang",
        "Yiqing Shen",
        "Kaiyuan Yan and Hongguang Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Information Retrieval (cs.IR)",
        "Computational Finance (q-fin.CP)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-08T07:50:50+00:00",
          "link": "https://arxiv.org/abs/2501.12399v1",
          "size": "807kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T03:59:49+00:00",
          "link": "https://arxiv.org/abs/2501.12399v2",
          "size": "531kb",
          "version": "v2"
        }
      ],
      "title": "FinSphere, a Real-Time Stock Analysis Agent Powered by Instruction-Tuned LLMs and Domain Tools",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.12399",
        "HTML": "https://arxiv.org/html/2501.12399v2",
        "PDF": "https://arxiv.org/pdf/2501.12399"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper mentions Stocksis, a dataset curated to enhance LLM's stock analysis capabilities, but the primary focus is on the analysis framework rather than significant contributions to LLM training data processing."
      },
      "tasks": [
        "AI Agent"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06543",
      "abstract": "Deriving compact and temporally aware visual representations from dynamic scenes is essential for successful execution of sequential scene understanding tasks such as visual tracking and robotic manipulation. In this paper, we introduce Token Bottleneck (ToBo), a simple yet intuitive self-supervised learning pipeline that squeezes a scene into a bottleneck token and predicts the subsequent scene using minimal patches as hints. The ToBo pipeline facilitates the learning of sequential scene representations by conservatively encoding the reference scene into a compact bottleneck token during the squeeze step. In the expansion step, we guide the model to capture temporal dynamics by predicting the target scene using the bottleneck token along with few target patches as hints. This design encourages the vision backbone to embed temporal dependencies, thereby enabling understanding of dynamic transitions across scenes. Extensive experiments in diverse sequential tasks, including video label propagation and robot manipulation in simulated environments demonstrate the superiority of ToBo over baselines. Moreover, deploying our pre-trained model on physical robots confirms its robustness and effectiveness in real-world environments. We further validate the scalability of ToBo across different model scales.",
      "authors": [
        "Taekyung Kim",
        "Dongyoon Han",
        "Byeongho Heo",
        "Jeongeun Park",
        "Sangdoo Yun"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T04:57:29+00:00",
          "link": "https://arxiv.org/abs/2507.06543v1",
          "size": "21666kb",
          "version": "v1"
        }
      ],
      "title": "Token Bottleneck: One Token to Remember Dynamics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06543",
        "HTML": "https://arxiv.org/html/2507.06543v1",
        "PDF": "https://arxiv.org/pdf/2507.06543"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a self-supervised learning pipeline for visual representations and does not address LLM training data processing, collection, or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06669",
      "abstract": "Markerless Motion Capture (MoCap) using smartphone cameras is a promising approach to making exergames more accessible and cost-effective for health and rehabilitation. Unlike traditional systems requiring specialized hardware, recent advancements in AI-powered pose estimation enable movement tracking using only a mobile device. For an upcoming study, a mobile application with real-time exergames including markerless motion capture is being developed. However, implementing such technology introduces key challenges, including balancing accuracy and real-time responsiveness, ensuring proper user interaction. Future research should explore optimizing AI models for realtime performance, integrating adaptive gamification, and refining user-centered design principles. By overcoming these challenges, smartphone-based exergames could become powerful tools for engaging users in physical activity and rehabilitation, extending their benefits to a broader audience.",
      "authors": [
        "Mathieu Phosanarack (LAMIH",
        "UPHF)",
        "Laura Wallard (LAMIH",
        "UPHF)",
        "Sophie Lepreux (LAMIH",
        "UPHF)",
        "Christophe Kolski (LAMIH)",
        "Eug\\'enie Avril (LAMIH",
        "UPHF)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T08:58:59+00:00",
          "link": "https://arxiv.org/abs/2507.06669v1",
          "size": "319kb",
          "version": "v1"
        }
      ],
      "title": "Smartphone Exergames with Real-Time Markerless Motion Capture: Challenges and Trade-offs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06669",
        "PDF": "https://arxiv.org/pdf/2507.06669"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper examines challenges in smartphone-based markerless motion capture for exergames, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06853",
      "abstract": "Molecular structure elucidation from spectra is a foundational problem in chemistry, with profound implications for compound identification, synthesis, and drug development. Traditional methods rely heavily on expert interpretation and lack scalability. Pioneering machine learning methods have introduced retrieval-based strategies, but their reliance on finite libraries limits generalization to novel molecules. Generative models offer a promising alternative, yet most adopt autoregressive SMILES-based architectures that overlook 3D geometry and struggle to integrate diverse spectral modalities. In this work, we present DiffSpectra, a generative framework that directly infers both 2D and 3D molecular structures from multi-modal spectral data using diffusion models. DiffSpectra formulates structure elucidation as a conditional generation process. Its denoising network is parameterized by Diffusion Molecule Transformer, an SE(3)-equivariant architecture that integrates topological and geometric information. Conditioning is provided by SpecFormer, a transformer-based spectral encoder that captures intra- and inter-spectral dependencies from multi-modal spectra. Extensive experiments demonstrate that DiffSpectra achieves high accuracy in structure elucidation, recovering exact structures with 16.01% top-1 accuracy and 96.86% top-20 accuracy through sampling. The model benefits significantly from 3D geometric modeling, SpecFormer pre-training, and multi-modal conditioning. These results highlight the effectiveness of spectrum-conditioned diffusion modeling in addressing the challenge of molecular structure elucidation. To our knowledge, DiffSpectra is the first framework to unify multi-modal spectral reasoning and joint 2D/3D generative modeling for de novo molecular structure elucidation.",
      "authors": [
        "Liang Wang",
        "Yu Rong",
        "Tingyang Xu",
        "Zhenyi Zhong",
        "Zhiyuan Liu",
        "Pengju Wang",
        "Deli Zhao",
        "Qiang Liu",
        "Shu Wu",
        "Liang Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Chemical Physics (physics.chem-ph)",
        "Molecular Networks (q-bio.MN)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T13:57:20+00:00",
          "link": "https://arxiv.org/abs/2507.06853v1",
          "size": "10813kb",
          "version": "v1"
        }
      ],
      "title": "DiffSpectra: Molecular Structure Elucidation from Spectra using Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06853",
        "HTML": "https://arxiv.org/html/2507.06853v1",
        "PDF": "https://arxiv.org/pdf/2507.06853"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses molecular structure elucidation using generative models and diffusion methods. It does not focus on LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06920",
      "abstract": "Large language models (LLMs) have recently achieved notable success in code-generation benchmarks such as HumanEval and LiveCodeBench. However, a detailed examination reveals that these evaluation suites often comprise only a limited number of homogeneous test cases, resulting in subtle faults going undetected. This not only artificially inflates measured performance but also compromises accurate reward estimation in reinforcement learning frameworks utilizing verifiable rewards (RLVR). To address these critical shortcomings, we systematically investigate the test-case generation (TCG) task by proposing multi-dimensional metrics designed to rigorously quantify test-suite thoroughness. Furthermore, we introduce a human-LLM collaborative method (SAGA), leveraging human programming expertise with LLM reasoning capability, aimed at significantly enhancing both the coverage and the quality of generated test cases. In addition, we develop a TCGBench to facilitate the study of the TCG task. Experiments show that SAGA achieves a detection rate of 90.62% and a verifier accuracy of 32.58% on TCGBench. The Verifier Accuracy (Verifier Acc) of the code generation evaluation benchmark synthesized by SAGA is 10.78% higher than that of LiveCodeBench-v6. These results demonstrate the effectiveness of our proposed method. We hope this work contributes to building a scalable foundation for reliable LLM code evaluation, further advancing RLVR in code generation, and paving the way for automated adversarial test synthesis and adaptive benchmark integration.",
      "authors": [
        "Zihan Ma",
        "Taolin Zhang",
        "Maosong Cao",
        "Wenwei Zhang",
        "Minnan Luo",
        "Songyang Zhang",
        "Kai Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T14:58:47+00:00",
          "link": "https://arxiv.org/abs/2507.06920v1",
          "size": "4361kb",
          "version": "v1"
        }
      ],
      "title": "Rethinking Verification for LLM Code Generation: From Generation to Testing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06920",
        "HTML": "https://arxiv.org/html/2507.06920v1",
        "PDF": "https://arxiv.org/pdf/2507.06920"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses code generation and evaluation using LLMs, particularly focusing on test case generation and evaluation metrics, without contributions to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2004.08705",
      "abstract": "In multiple domains such as malware detection, automated driving systems, or fraud detection, classification algorithms are susceptible to being attacked by malicious agents willing to perturb the value of instance covariates to pursue certain goals. Such problems pertain to the field of adversarial machine learning and have been mainly dealt with, perhaps implicitly, through game-theoretic ideas with strong underlying common knowledge assumptions. These are not realistic in numerous application domains in relation to security and business competition. We present an alternative Bayesian decision theoretic framework that accounts for the uncertainty about the attacker's behavior using adversarial risk analysis concepts. In doing so, we also present core ideas in adversarial machine learning to a statistical audience. A key ingredient in our framework is the ability to sample from the distribution of originating instances given the, possibly attacked, observed ones. We propose an initial procedure based on approximate Bayesian computation usable during operations; within it, we simulate the attacker's problem taking into account our uncertainty about his elements. Large-scale problems require an alternative scalable approach implementable during the training stage. Globally, we are able to robustify statistical classification algorithms against malicious attacks.",
      "authors": [
        "Victor Gallego",
        "Roi Naveiro",
        "Alberto Redondo",
        "David Rios Insua",
        "Fabrizio Ruggeri"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)",
        "Computation (stat.CO)"
      ],
      "submission_historys": [
        {
          "date": "2020-04-18T21:21:56+00:00",
          "link": "https://arxiv.org/abs/2004.08705v1",
          "size": "797kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T15:04:25+00:00",
          "link": "https://arxiv.org/abs/2004.08705v2",
          "size": "964kb",
          "version": "v2"
        }
      ],
      "title": "Protecting Classifiers From Attacks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2004.08705",
        "HTML": "https://arxiv.org/html/2004.08705v2",
        "PDF": "https://arxiv.org/pdf/2004.08705"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses adversarial machine learning and protecting classifiers from attacks, focusing on classification algorithms and adversarial risk analysis, without mentioning LLM training data processing."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/roinaveiro/ACRA_2"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.05455",
      "abstract": "Automatic toxic language detection is critical for creating safe, inclusive online spaces. However, it is a highly subjective task, with perceptions of toxic language shaped by community norms and lived experience. Existing toxicity detection models are typically trained on annotations that collapse diverse annotator perspectives into a single ground truth, erasing important context-specific notions of toxicity such as reclaimed language. To address this, we introduce MODELCITIZENS, a dataset of 6.8K social media posts and 40K toxicity annotations across diverse identity groups. To capture the role of conversational context on toxicity, typical of social media posts, we augment MODELCITIZENS posts with LLM-generated conversational scenarios. State-of-the-art toxicity detection tools (e.g. OpenAI Moderation API, GPT-o4-mini) underperform on MODELCITIZENS, with further degradation on context-augmented posts. Finally, we release LLAMACITIZEN-8B and GEMMACITIZEN-12B, LLaMA- and Gemma-based models finetuned on MODELCITIZENS, which outperform GPT-o4-mini by 5.5% on in-distribution evaluations. Our findings highlight the importance of community-informed annotation and modeling for inclusive content moderation. The data, models and code are available at https://github.com/asuvarna31/modelcitizens.",
      "authors": [
        "Ashima Suvarna",
        "Christina Chance",
        "Karolina Naranjo",
        "Hamid Palangi",
        "Sophie Hao",
        "Thomas Hartvigsen",
        "Saadia Gabriel"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T20:15:18+00:00",
          "link": "https://arxiv.org/abs/2507.05455v1",
          "size": "1871kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T02:57:34+00:00",
          "link": "https://arxiv.org/abs/2507.05455v2",
          "size": "1871kb",
          "version": "v2"
        }
      ],
      "title": "ModelCitizens: Representing Community Voices in Online Safety",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05455",
        "HTML": "https://arxiv.org/html/2507.05455v2",
        "PDF": "https://arxiv.org/pdf/2507.05455"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper introduces a new dataset called MODELCITIZENS, with detailed steps for augmenting posts with LLM-generated conversational scenarios, which significantly involve data processing and synthesis."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06883",
      "abstract": "Manifold optimization (MO) is a powerful mathematical framework that can be applied to solving complex optimization problems with objective functions (OFs) and constraints on complex geometric structures, which is particularly useful in advanced power systems. We explore the application of MO techniques, which offer a robust framework for solving complex, non-convex optimization problems in electrical power distribution systems (EPDS) and electrical power transmission systems (EPTS), particularly for power flow analysis. This paper introduces the principles of MO and demonstrates its advantages over conventional methods by applying it to power flow optimization. For EPDS, a cost function derived from a backward-forward sweep (BFS) algorithm is optimized using the Manopt toolbox, yielding high accuracy and competitive computational times on 14-bus, 33-bus, and 69-bus systems when compared to established solvers. Similarly, for EPTS, MO applied via Manopt to 3-bus and 4-bus systems effectively solves power flow equations, matching traditional methods such as Newton-Raphson in performance. The study highlights that tools such as Manopt can mitigate implementation complexities, positioning MO as an efficient and accessible tool for power system analysis and potentially broader planning applications. The paper provides a comprehensive tutorial on MO, detailing its theoretical foundations, practical methodologies, and specific applications in power systems, particularly in power flow optimization.",
      "authors": [
        "Lucca Rodrigues Pinto",
        "Wilson de Souza Junior",
        "Jaime Laelson Jacob",
        "Luis Alfonso Gallego Pareja",
        "Taufik Abr\\~ao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)",
        "Applications (stat.AP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T14:19:13+00:00",
          "link": "https://arxiv.org/abs/2507.06883v1",
          "size": "1691kb",
          "version": "v1"
        }
      ],
      "title": "Manifolds in Power Systems Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06883",
        "HTML": "https://arxiv.org/html/2507.06883v1",
        "PDF": "https://arxiv.org/pdf/2507.06883"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on manifold optimization techniques for power system optimization and does not discuss LLM training data collection, processing, or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06822",
      "abstract": "Manipulating articulated tools, such as tweezers or scissors, has rarely been explored in previous research. Unlike rigid tools, articulated tools change their shape dynamically, creating unique challenges for dexterous robotic hands. In this work, we present a hierarchical, goal-conditioned reinforcement learning (GCRL) framework to improve the manipulation capabilities of anthropomorphic robotic hands using articulated tools. Our framework comprises two policy layers: (1) a low-level policy that enables the dexterous hand to manipulate the tool into various configurations for objects of different sizes, and (2) a high-level policy that defines the tool's goal state and controls the robotic arm for object-picking tasks. We employ an encoder, trained on synthetic pointclouds, to estimate the tool's affordance states--specifically, how different tool configurations (e.g., tweezer opening angles) enable grasping of objects of varying sizes--from input point clouds, thereby enabling precise tool manipulation. We also utilize a privilege-informed heuristic policy to generate replay buffer, improving the training efficiency of the high-level policy. We validate our approach through real-world experiments, showing that the robot can effectively manipulate a tweezer-like tool to grasp objects of diverse shapes and sizes with a 70.8 % success rate. This study highlights the potential of RL to advance dexterous robotic manipulation of articulated tools.",
      "authors": [
        "Wei Xu",
        "Yanchao Zhao",
        "Weichao Guo",
        "Xinjun Sheng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T13:11:12+00:00",
          "link": "https://arxiv.org/abs/2507.06822v1",
          "size": "3850kb",
          "version": "v1"
        }
      ],
      "title": "Hierarchical Reinforcement Learning for Articulated Tool Manipulation with Multifingered Hand",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06822",
        "HTML": "https://arxiv.org/html/2507.06822v1",
        "PDF": "https://arxiv.org/pdf/2507.06822"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with hierarchical reinforcement learning for tool manipulation in robotics, without addressing LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07037",
      "abstract": "We develop a theoretical framework for understanding how cognitive load affects information processing in financial markets and test it using exogenous variation in disclosure complexity. Our model distinguishes between attention allocation and cognitive processing capacity, showing that complex information creates differential effects across investor types. Using a comprehensive dataset of corporate disclosures and a novel identification strategy based on regulatory changes, we find that cognitive load significantly impairs price discovery, with effects concentrated among less sophisticated investors. A one-standard-deviation increase in cognitive complexity reduces information incorporation speed by 18\\% and increases mispricing duration by 23\\%. We provide evidence for three theoretical mechanisms: selective attention, processing errors, and strategic complexity. Our findings suggest that cognitive constraints create systematic inefficiencies in financial markets, with important implications for disclosure regulation and market design.",
      "authors": [
        "Yimin Du and Guolin Tang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "General Finance (q-fin.GN)",
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-18T05:45:27+00:00",
          "link": "https://arxiv.org/abs/2507.07037v1",
          "size": "12kb",
          "version": "v1"
        }
      ],
      "title": "Cognitive Load and Information Processing in Financial Markets: Theory and Evidence from Disclosure Complexity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07037",
        "HTML": "https://arxiv.org/html/2507.07037v1",
        "PDF": "https://arxiv.org/pdf/2507.07037"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses cognitive load in financial markets related to disclosure complexity and does not address LLM training data processing or data engineering concerns."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.03511",
      "abstract": "Finding correspondences between 3D shapes is an important and long-standing problem in computer vision, graphics and beyond. While approaches based on machine learning dominate modern 3D shape matching, almost all existing (learning-based) methods require that at least one of the involved shapes is complete. In contrast, the most challenging and arguably most practically relevant setting of matching partially observed shapes, is currently underexplored. One important factor is that existing datasets contain only a small number of shapes (typically below 100), which are unable to serve data-hungry machine learning approaches, particularly in the unsupervised regime. In addition, the type of partiality present in existing datasets is often artificial and far from realistic. To address these limitations and to encourage research on these relevant settings, we provide a generic and flexible framework for the procedural generation of challenging partial shape matching scenarios. Our framework allows for a virtually infinite generation of partial shape matching instances from a finite set of shapes with complete geometry. Further, we manually create cross-dataset correspondences between seven existing (complete geometry) shape matching datasets, leading to a total of 2543 shapes. Based on this, we propose several challenging partial benchmark settings, for which we evaluate respective state-of-the-art methods as baselines.",
      "authors": [
        "Viktoria Ehm",
        "Nafie El Amrani",
        "Yizheng Xie",
        "Lennart Bastian",
        "Maolin Gao",
        "Weikang Wang",
        "Lu Sang",
        "Dongliang Cao",
        "Tobias Wei{\\ss}berg",
        "Zorah L\\\"ahner",
        "Daniel Cremers",
        "Florian Bernard"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-05T21:08:19+00:00",
          "link": "https://arxiv.org/abs/2411.03511v1",
          "size": "21000kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T16:23:36+00:00",
          "link": "https://arxiv.org/abs/2411.03511v2",
          "size": "29891kb",
          "version": "v2"
        }
      ],
      "title": "Beyond Complete Shapes: A Quantitative Evaluation of 3D Shape Matching Algorithms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.03511",
        "HTML": "https://arxiv.org/html/2411.03511v2",
        "PDF": "https://arxiv.org/pdf/2411.03511"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper evaluates 3D shape matching algorithms and provides a framework for generating matching scenarios, not focusing on LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2506.20623",
      "abstract": "Closed-loop learning is the process of repeatedly estimating a model from data generated from the model itself. It is receiving great attention due to the possibility that large neural network models may, in the future, be primarily trained with data generated by artificial neural networks themselves. We study this process for models that belong to exponential families, deriving equations of motions that govern the dynamics of the parameters. We show that maximum likelihood estimation of the parameters endows sufficient statistics with the martingale property and that as a result the process converges to absorbing states that amplify initial biases present in the data. However, we show that this outcome may be prevented if the data contains at least one data point generated from a ground truth model, by relying on maximum a posteriori estimation or by introducing regularisation.",
      "authors": [
        "Fariba Jangjoo",
        "Matteo Marsili",
        "Yasser Roudi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
        "Data Analysis, Statistics and Probability (physics.data-an)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T17:12:22+00:00",
          "link": "https://arxiv.org/abs/2506.20623v1",
          "size": "1220kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T08:24:09+00:00",
          "link": "https://arxiv.org/abs/2506.20623v2",
          "size": "1191kb",
          "version": "v2"
        }
      ],
      "title": "Lost in Retraining: Roaming the Parameter Space of Exponential Families Under Closed-Loop Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20623",
        "HTML": "https://arxiv.org/html/2506.20623v2",
        "PDF": "https://arxiv.org/pdf/2506.20623"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses closed-loop learning and dynamics of model parameters but does not focus on LLM training data processing, collection, or engineering for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06367",
      "abstract": "We study geometric properties of the gradient flow for learning deep linear convolutional networks. For linear fully connected networks, it has been shown recently that the corresponding gradient flow on parameter space can be written as a Riemannian gradient flow on function space (i.e., on the product of weight matrices) if the initialization satisfies a so-called balancedness condition. We establish that the gradient flow on parameter space for learning linear convolutional networks can be written as a Riemannian gradient flow on function space regardless of the initialization. This result holds for $D$-dimensional convolutions with $D \\geq 2$, and for $D =1$ it holds if all so-called strides of the convolutions are greater than one. The corresponding Riemannian metric depends on the initialization.",
      "authors": [
        "El Mehdi Achour and Kathl\\'en Kohn and Holger Rauhut"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Algebraic Geometry (math.AG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T20:04:00+00:00",
          "link": "https://arxiv.org/abs/2507.06367v1",
          "size": "28kb",
          "version": "v1"
        }
      ],
      "title": "The Riemannian Geometry associated to Gradient Flows of Linear Convolutional Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06367",
        "HTML": "https://arxiv.org/html/2507.06367v1",
        "PDF": "https://arxiv.org/pdf/2507.06367"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper studies geometric properties of gradient flows in convolutional networks, focusing on Riemannian geometry. It does not involve any processing related to LLM training data or dataset enhancement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06436",
      "abstract": "In this paper, we propose a digital agent (DA)-assisted resource management scheme for enhanced user quality of experience (QoE) in integrated sensing and communication (ISAC) networks. Particularly, user QoE is a comprehensive metric that integrates quality of service (QoS), user behavioral dynamics, and environmental complexity. The novel DA module includes a user status prediction model, a QoS factor selection model, and a QoE fitting model, which analyzes historical user status data to construct and update user-specific QoE models. Users are clustered into different groups based on their QoE models. A Cram\\'er-Rao bound (CRB) model is utilized to quantify the impact of allocated communication resources on sensing accuracy. A joint optimization problem of communication and computing resource management is formulated to maximize long-term user QoE while satisfying CRB and resource constraints. A two-layer data-model-driven algorithm is developed to solve the formulated problem, where the top layer utilizes an advanced deep reinforcement learning algorithm to make group-level decisions, and the bottom layer uses convex optimization techniques to make user-level decisions. Simulation results based on a real-world dataset demonstrate that the proposed DA-assisted resource management scheme outperforms benchmark schemes in terms of user QoE.",
      "authors": [
        "Xinyu Huang and Yixiao Zhang and Yingying Pei and Jianzhe Xue and Xuemin Shen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T22:30:18+00:00",
          "link": "https://arxiv.org/abs/2507.06436v1",
          "size": "334kb",
          "version": "v1"
        }
      ],
      "title": "Experience-Centric Resource Management in ISAC Networks: A Digital Agent-Assisted Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06436",
        "PDF": "https://arxiv.org/pdf/2507.06436"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses resource management in ISAC networks for quality of experience enhancement, without addressing LLM training data processing or related data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06517",
      "abstract": "Large Language Models (LLMs) have achieved impressive accomplishments in recent years. However, the increasing memory consumption of KV cache has possessed a significant challenge to the inference system. Eviction methods have revealed the inherent redundancy within the KV cache, demonstrating its potential for reduction, particularly in deeper layers. However, KV cache reduction for shallower layers has been found to be insufficient. Based on our observation that, the KV cache exhibits a high degree of similarity. Based on this observation, we proposed a novel KV cache reduction method, SpindleKV, which balances both shallow and deep layers. For deep layers, we employ an attention weight based eviction method, while for shallow layers, we apply a codebook based replacement approach which is learnt by similarity and merging policy. Moreover, SpindleKV addressed the Grouped-Query Attention (GQA) dilemma faced by other attention based eviction methods. Experiments on two common benchmarks with three different LLMs shown that SpindleKV obtained better KV cache reduction effect compared to baseline methods, while preserving similar or even better model performance.",
      "authors": [
        "Zicong Tang",
        "Shi Luohe",
        "Zuchao Li",
        "Baoyuan Qi",
        "Guoming Liu",
        "Lefei Zhang",
        "Ping Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T03:33:44+00:00",
          "link": "https://arxiv.org/abs/2507.06517v1",
          "size": "9239kb",
          "version": "v1"
        }
      ],
      "title": "SpindleKV: A Novel KV Cache Reduction Method Balancing Both Shallow and Deep Layers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06517",
        "HTML": "https://arxiv.org/html/2507.06517v1",
        "PDF": "https://arxiv.org/pdf/2507.06517"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a method for KV cache reduction during LLM inference, dealing with computational efficiency rather than training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06561",
      "abstract": "As conspiracy theories gain traction, it has become crucial to research effective intervention strategies that can foster evidence and science-based discussions in conspiracy theory communities online. This study presents a novel framework using insider language to contest conspiracy theory ideology in climate change denialism on Reddit. Focusing on discussions in two Reddit communities, our research investigates reactions to pro-social and evidence-based intervention messages for two cohorts of users: climate change deniers and climate change supporters. Specifically, we combine manual and generative AI-based methods to craft intervention messages and deploy the interventions as replies on Reddit posts and comments through transparently labeled bot accounts. On the one hand, we find that evidence-based interventions with neutral language foster positive engagement, encouraging open discussions among believers of climate change denialism. On the other, climate change supporters respond positively, actively participating and presenting additional evidence. Our study contributes valuable insights into the process and challenges of automatically delivering interventions in conspiracy theory communities on social media, and helps inform future research on social media interventions.",
      "authors": [
        "Ruican zhong",
        "Shruti Phadke",
        "Beth Goldberg",
        "Tanushree Mitra"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T05:29:48+00:00",
          "link": "https://arxiv.org/abs/2507.06561v1",
          "size": "2048kb",
          "version": "v1"
        }
      ],
      "title": "Towards Designing Social Interventions for Online Climate Change Denialism Discussions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06561",
        "HTML": "https://arxiv.org/html/2507.06561v1",
        "PDF": "https://arxiv.org/pdf/2507.06561"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper studies social interventions on Reddit for climate change denialism, using generative AI to craft messages, lacking focus on LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06806",
      "abstract": "Plant traits such as leaf carbon content and leaf mass are essential variables in the study of biodiversity and climate change. However, conventional field sampling cannot feasibly cover trait variation at ecologically meaningful spatial scales. Machine learning represents a valuable solution for plant trait prediction across ecosystems, leveraging hyperspectral data from remote sensing. Nevertheless, trait prediction from hyperspectral data is challenged by label scarcity and substantial domain shifts (\\eg across sensors, ecological distributions), requiring robust cross-domain methods. Here, we present GreenHyperSpectra, a pretraining dataset encompassing real-world cross-sensor and cross-ecosystem samples designed to benchmark trait prediction with semi- and self-supervised methods. We adopt an evaluation framework encompassing in-distribution and out-of-distribution scenarios. We successfully leverage GreenHyperSpectra to pretrain label-efficient multi-output regression models that outperform the state-of-the-art supervised baseline. Our empirical analyses demonstrate substantial improvements in learning spectral representations for trait prediction, establishing a comprehensive methodological framework to catalyze research at the intersection of representation learning and plant functional traits assessment. All code and data are available at: https://github.com/echerif18/HyspectraSSL.",
      "authors": [
        "Eya Cherif (1",
        "2 and 3)",
        "Arthur Ouaknine (3 and 4)",
        "Luke A. Brown (5)",
        "Phuong D. Dao (6",
        "7 and 8)",
        "Kyle R. Kovach (9)",
        "Bing Lu (10)",
        "Daniel Mederer (1)",
        "Hannes Feilhauer (1",
        "2",
        "12 and 13)",
        "Teja Kattenborn (11 and 12) and David Rolnick (3 and 4) ((1) Institute for Earth System Science and Remote Sensing",
        "Leipzig University",
        "Germany",
        "(2) Center for Scalable Data Analytics and Artificial Intelligence (ScaDS.AI)",
        "Leipzig University",
        "Germany",
        "(3) Mila Quebec AI Institute",
        "Canada",
        "(4) McGill University",
        "Canada",
        "(5) School of Science",
        "Engineering and Environment",
        "University of Salford",
        "UK",
        "(6) Department of Agricultural Biology",
        "Colorado State University",
        "USA",
        "(7) Graduate Degree Program in Ecology",
        "Colorado State University",
        "USA",
        "(8) School of Global Environmental Sustainability",
        "Colorado State University",
        "USA",
        "(9) Department of Forest and Wildlife Ecology",
        "University of Wisconsin",
        "USA",
        "(10) Department of Geography",
        "Simon Fraser University",
        "Canada",
        "(11) Chair of Sensor-based Geoinformatics (geosense)",
        "University of Freiburg",
        "Germany",
        "(12) German Centre for Integrative Biodiversity Research (iDiv)",
        "Halle-Jena-Leipzig",
        "Germany",
        "(13) Helmholtz-Centre for Environmental Research (UFZ)",
        "Leipzig",
        "Germany)"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T12:51:46+00:00",
          "link": "https://arxiv.org/abs/2507.06806v1",
          "size": "24429kb",
          "version": "v1"
        }
      ],
      "title": "GreenHyperSpectra: A multi-source hyperspectral dataset for global vegetation trait prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06806",
        "HTML": "https://arxiv.org/html/2507.06806v1",
        "PDF": "https://arxiv.org/pdf/2507.06806"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper presents the creation of GreenHyperSpectra, a pretraining dataset with explicit focus on design for training robustness across domains, indicating a significant contribution to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06899",
      "abstract": "Graphical User Interface (GUI) agents powered by Large Vision-Language Models (LVLMs) have emerged as a revolutionary approach to automating human-machine interactions, capable of autonomously operating personal devices (e.g., mobile phones) or applications within the device to perform complex real-world tasks in a human-like manner. However, their close integration with personal devices raises significant security concerns, with many threats, including backdoor attacks, remaining largely unexplored. This work reveals that the visual grounding of GUI agent-mapping textual plans to GUI elements-can introduce vulnerabilities, enabling new types of backdoor attacks. With backdoor attack targeting visual grounding, the agent's behavior can be compromised even when given correct task-solving plans. To validate this vulnerability, we propose VisualTrap, a method that can hijack the grounding by misleading the agent to locate textual plans to trigger locations instead of the intended targets. VisualTrap uses the common method of injecting poisoned data for attacks, and does so during the pre-training of visual grounding to ensure practical feasibility of attacking. Empirical results show that VisualTrap can effectively hijack visual grounding with as little as 5% poisoned data and highly stealthy visual triggers (invisible to the human eye); and the attack can be generalized to downstream tasks, even after clean fine-tuning. Moreover, the injected trigger can remain effective across different GUI environments, e.g., being trained on mobile/web and generalizing to desktop environments. These findings underscore the urgent need for further research on backdoor attack risks in GUI agents.",
      "authors": [
        "Ziang Ye",
        "Yang Zhang",
        "Wentao Shi",
        "Xiaoyu You",
        "Fuli Feng",
        "Tat-Seng Chua"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T14:36:00+00:00",
          "link": "https://arxiv.org/abs/2507.06899v1",
          "size": "828kb",
          "version": "v1"
        }
      ],
      "title": "VisualTrap: A Stealthy Backdoor Attack on GUI Agents via Visual Grounding Manipulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06899",
        "HTML": "https://arxiv.org/html/2507.06899v1",
        "PDF": "https://arxiv.org/pdf/2507.06899"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses vulnerabilities in GUI agents related to visual grounding during pre-training but does not focus on LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.04133",
      "abstract": "Agentic AI systems, built upon large language models (LLMs) and deployed in multi-agent configurations, are redefining intelligence, autonomy, collaboration, and decision-making across enterprise and societal domains. This review presents a structured analysis of \\textbf{Trust, Risk, and Security Management (TRiSM)} in the context of LLM-based Agentic Multi-Agent Systems (AMAS). We begin by examining the conceptual foundations of Agentic AI and highlight its architectural distinctions from traditional AI agents. We then adapt and extend the AI TRiSM framework for Agentic AI, structured around four key pillars: Explainability, ModelOps, Security, Privacy and Governance, each contextualized to the challenges of multi-agent LLM systems. A novel risk taxonomy is proposed to capture the unique threats and vulnerabilities of Agentic AI, ranging from coordination failures to prompt-based adversarial manipulation. To support practical assessment in Agentic AI works, we introduce two novel metrics: the Component Synergy Score (CSS), which quantifies the quality of inter-agent collaboration, and the Tool Utilization Efficacy (TUE), which evaluates the efficiency of tool use within agent workflows. We further discuss strategies for improving explainability in Agentic AI , as well as approaches to enhancing security and privacy through encryption, adversarial robustness, and regulatory compliance. The review concludes with a research roadmap for the responsible development and deployment of Agentic AI, outlining critical directions to align emerging systems with TRiSM principles for safe, transparent, and accountable operation.",
      "authors": [
        "Shaina Raza",
        "Ranjan Sapkota",
        "Manoj Karkee",
        "Christos Emmanouilidis"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-04T16:26:11+00:00",
          "link": "https://arxiv.org/abs/2506.04133v1",
          "size": "879kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T20:26:07+00:00",
          "link": "https://arxiv.org/abs/2506.04133v2",
          "size": "5055kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T17:33:49+00:00",
          "link": "https://arxiv.org/abs/2506.04133v3",
          "size": "5059kb",
          "version": "v3"
        }
      ],
      "title": "TRiSM for Agentic AI: A Review of Trust, Risk, and Security Management in LLM-based Agentic Multi-Agent Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.04133",
        "HTML": "https://arxiv.org/html/2506.04133v3",
        "PDF": "https://arxiv.org/pdf/2506.04133"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on trust, risk, and security management in LLM-based multi-agent systems, not on the collection or processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06761",
      "abstract": "Manchu, a critically endangered language essential for understanding early modern Eastern Eurasian history, lacks effective OCR systems that can handle real-world historical documents. This study develops high-performing OCR systems by fine-tuning three open-source vision-language models (LLaMA-3.2-11B, Qwen2.5-VL-7B, Qwen2.5-VL-3B) on 60,000 synthetic Manchu word images using parameter-efficient training. LLaMA-3.2-11B achieved exceptional performance with 98.3\\% word accuracy and 0.0024 character error rate on synthetic data, while crucially maintaining 93.1\\% accuracy on real-world handwritten documents. Comparative evaluation reveals substantial advantages over traditional approaches: while a CRNN baseline achieved 99.8\\% synthetic accuracy, it suffered severe degradation to 72.5\\% on real documents. Our approach demonstrates effective synthetic-to-real domain transfer, providing a cost-effective solution deployable on accessible infrastructure. This work establishes a transferable framework for endangered language OCR that removes technical and financial barriers in digital humanities, enabling historians and linguists to process historical archives without specialized computing resources. Code and model weights are available at https://github.com/mic7ch1/ManchuAI-OCR.",
      "authors": [
        "Yan Hon Michael Chung and Donghyeok Choi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T11:38:20+00:00",
          "link": "https://arxiv.org/abs/2507.06761v1",
          "size": "205kb",
          "version": "v1"
        }
      ],
      "title": "Finetuning Vision-Language Models as OCR Systems for Low-Resource Languages: A Case Study of Manchu",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06761",
        "HTML": "https://arxiv.org/html/2507.06761v1",
        "PDF": "https://arxiv.org/pdf/2507.06761"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper involves fine-tuning vision-language models on synthetic data for Manchu OCR, but the primary focus is not on data processing techniques or engineering for LLMs. It lacks significant contributions to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07030",
      "abstract": "The rapid advancement of conversational search systems revolutionizes how information is accessed by enabling the multi-turn interaction between the user and the system. Existing conversational search systems are usually built with two different models. This separation restricts the system from leveraging the intrinsic knowledge of the models simultaneously, which cannot ensure the effectiveness of retrieval benefiting the generation. The existing studies for developing unified models cannot fully address the aspects of understanding conversational context, managing retrieval independently, and generating responses. In this paper, we explore how to unify dense retrieval and response generation for large language models in conversation. We conduct joint fine-tuning with different objectives and design two mechanisms to reduce the inconsistency risks while mitigating data discrepancy. The evaluations on five conversational search datasets demonstrate that our unified model can mutually improve both tasks and outperform the existing baselines.",
      "authors": [
        "Fengran Mo",
        "Yifan Gao",
        "Chuan Meng",
        "Xin Liu",
        "Zhuofeng Wu",
        "Kelong Mao",
        "Zhengyang Wang",
        "Pei Chen",
        "Zheng Li",
        "Xian Li",
        "Bing Yin",
        "Meng Jiang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T17:02:40+00:00",
          "link": "https://arxiv.org/abs/2507.07030v1",
          "size": "109kb",
          "version": "v1"
        }
      ],
      "title": "UniConv: Unifying Retrieval and Response Generation for Large Language Models in Conversations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07030",
        "HTML": "https://arxiv.org/html/2507.07030v1",
        "PDF": "https://arxiv.org/pdf/2507.07030"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses joint fine-tuning to unify dense retrieval and response generation for LLMs, touching on mitigating data discrepancy, but it does not primarily focus on LLM training data processing methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07032",
      "abstract": "Protein structure prediction is essential for drug discovery and understanding biological functions. While recent advancements like AlphaFold have achieved remarkable accuracy, most folding models rely heavily on multiple sequence alignments (MSAs) to boost prediction performance. This dependency limits their effectiveness on low-homology proteins and orphan proteins, where MSA information is sparse or unavailable. To address this limitation, we propose PLAME, a novel MSA design model that leverages evolutionary embeddings from pretrained protein language models. Unlike existing methods, PLAME introduces pretrained representations to enhance evolutionary information and employs a conservation-diversity loss to enhance generation quality. Additionally, we propose a novel MSA selection method to effectively screen high-quality MSAs and improve folding performance. We also propose a sequence quality assessment metric that provides an orthogonal perspective to evaluate MSA quality. On the AlphaFold2 benchmark of low-homology and orphan proteins, PLAME achieves state-of-the-art performance in folding enhancement and sequence quality assessment, with consistent improvements demonstrated on AlphaFold3. Ablation studies validate the effectiveness of the MSA selection method, while extensive case studies on various protein types provide insights into the relationship between AlphaFold's prediction quality and MSA characteristics. Furthermore, we demonstrate that PLAME can serve as an adapter achieving AlphaFold2-level accuracy with the ESMFold's inference speed.",
      "authors": [
        "Hanqun Cao",
        "Xinyi Zhou",
        "Zijun Gao",
        "Chenyu Wang",
        "Xin Gao",
        "Zhi Zhang",
        "Chunbin Gu",
        "Ge Liu",
        "Pheng-Ann Heng"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Quantitative Methods (q-bio.QM)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-17T04:11:30+00:00",
          "link": "https://arxiv.org/abs/2507.07032v1",
          "size": "11718kb",
          "version": "v1"
        }
      ],
      "title": "PLAME: Leveraging Pretrained Language Models to Generate Enhanced Protein Multiple Sequence Alignments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07032",
        "HTML": "https://arxiv.org/html/2507.07032v1",
        "PDF": "https://arxiv.org/pdf/2507.07032"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about leveraging pretrained language models for protein MSA generation, which does not involve processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.04596",
      "abstract": "We develop and evaluate a method for learning solution operators to nonlinear problems governed by partial differential equations (PDEs). The approach is based on a finite element discretization and aims at representing the solution operator by a multilayer perceptron (MLP) that takes problem data variables as input and gives a prediction of the finite element solution as output. The variables will typically correspond to parameters in a parametrization of input data such as boundary conditions, coefficients, and right-hand sides. The output will be an approximation of the corresponding finite element solution, thus enabling support and enhancement by the standard finite element method (FEM) both theoretically and practically. The loss function is most often an energy functional and we formulate efficient parallelizable training algorithms based on assembling the energy locally on each element. For large problems, the learning process can be made more efficient by using only a small fraction of randomly chosen elements in the mesh in each iteration. The approach is evaluated on several relevant test cases, where learning the finite element solution operator turns out to be beneficial, both in its own right but also by combination with standard FEM theory and software.",
      "authors": [
        "Mats G. Larson",
        "Carl Lundholm",
        "Anna Persson"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-05T20:19:16+00:00",
          "link": "https://arxiv.org/abs/2412.04596v1",
          "size": "434kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T19:01:16+00:00",
          "link": "https://arxiv.org/abs/2412.04596v2",
          "size": "856kb",
          "version": "v2"
        }
      ],
      "title": "Learning Nonlinear Finite Element Solution Operators using Multilayer Perceptrons and Energy Minimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.04596",
        "HTML": "https://arxiv.org/html/2412.04596v2",
        "PDF": "https://arxiv.org/pdf/2412.04596"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a method for learning solution operators for PDEs using finite element methods, with no focus on LLM training data or its processing."
      },
      "tasks": [
        "Operator learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06533",
      "abstract": "Accurate prediction of wind flow fields in urban canopies is crucial for ensuring pedestrian comfort, safety, and sustainable urban design. Traditional methods using wind tunnels and Computational Fluid Dynamics, such as Large-Eddy Simulations (LES), are limited by high costs, computational demands, and time requirements. This study presents a deep neural network (DNN) approach for fast and accurate predictions of urban wind flow fields, reducing computation time from an order of 10 hours on 32 CPUs for one LES evaluation to an order of 1 second on a single GPU using the DNN model. We employ a U-Net architecture trained on LES data including 252 synthetic urban configurations at seven wind directions ($0^{o}$ to $90^{o}$ in $15^{o}$ increments). The model predicts two key quantities of interest: mean velocity magnitude and streamwise turbulence intensity, at multiple heights within the urban canopy. The U-net uses 2D building representations augmented with signed distance functions and their gradients as inputs, forming a $256\\times256\\times9$ tensor. In addition, a Spatial Attention Module is used for feature transfer through skip connections. The loss function combines the root-mean-square error of predictions, their gradient magnitudes, and L2 regularization. Model evaluation on 50 test cases demonstrates high accuracy with an overall mean relative error of 9.3% for velocity magnitude and 5.2% for turbulence intensity. This research shows the potential of deep learning approaches to provide fast, accurate urban wind assessments essential for creating comfortable and safe urban environments. Code is available at https://github.com/tvarg/Urban-FlowUnet.git",
      "authors": [
        "Themistoklis Vargiemezis and Catherine Gorl\\'e"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computational Physics (physics.comp-ph)",
        "Machine Learning (cs.LG)",
        "Fluid Dynamics (physics.flu-dyn)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T04:25:13+00:00",
          "link": "https://arxiv.org/abs/2507.06533v1",
          "size": "19207kb",
          "version": "v1"
        }
      ],
      "title": "From large-eddy simulations to deep learning: A U-net model for fast urban canopy flow predictions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06533",
        "HTML": "https://arxiv.org/html/2507.06533v1",
        "PDF": "https://arxiv.org/pdf/2507.06533"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses using a U-net model for urban canopy flow predictions, focusing on model architecture rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06762",
      "abstract": "Semantic conflicts arise when a developer introduces changes to a codebase that unintentionally affect the behavior of changes integrated in parallel by other developers. Traditional merge tools are unable to detect such conflicts, so complementary tools like SMAT have been proposed. SMAT relies on generating and executing unit tests: if a test fails on the base version, passes on a developer's modified version, but fails again after merging with another developer's changes, a semantic conflict is indicated. While SMAT is effective at detecting conflicts, it suffers from a high rate of false negatives, partly due to the limitations of unit test generation tools such as Randoop and Evosuite. To investigate whether large language models (LLMs) can overcome these limitations, we propose and integrate a new test generation tool based on Code Llama 70B into SMAT. We explore the model's ability to generate tests using different interaction strategies, prompt contents, and parameter configurations. Our evaluation uses two samples: a benchmark with simpler systems from related work, and a more significant sample based on complex, real-world systems. We assess the effectiveness of the new SMAT extension in detecting conflicts. Results indicate that, although LLM-based test generation remains challenging and computationally expensive in complex scenarios, there is promising potential for improving semantic conflict detection.\n  --\n  Conflitos sem^anticos surgem quando um desenvolvedor introduz mudan\\c{c}as em uma base de c\\'odigo que afetam, de forma n~ao intencional, o comportamento de altera\\c{c}~oes integradas em paralelo por outros desenvolvedores. Ferramentas tradicionais de merge n~ao conseguem detectar esse tipo de conflito, por isso ferramentas complementares como o SMAT foram propostas. O SMAT depende da gera\\c{c}~ao e execu\\c{c}~ao de testes de unidade: se um teste falha na vers~ao base, passa na vers~ao modificada por um desenvolvedor, mas volta a falhar ap\\'os o merge com as mudan\\c{c}as de outro desenvolvedor, um conflito sem^antico \\'e identificado. Embora o SMAT seja eficaz na detec\\c{c}~ao de conflitos, apresenta alta taxa de falsos negativos, em parte devido \\`as limita\\c{c}~oes das ferramentas de gera\\c{c}~ao de testes como Randoop e Evosuite. Para investigar se modelos de linguagem de grande porte (LLMs) podem superar essas limita\\c{c}~oes, propomos e integramos ao SMAT uma nova ferramenta de gera\\c{c}~ao de testes baseada no Code Llama 70B. Exploramos a capacidade do modelo de gerar testes utilizando diferentes estrat\\'egias de intera\\c{c}~ao, conte\\'udos de prompts e configura\\c{c}~oes de par^ametros. Nossa avalia\\c{c}~ao utiliza duas amostras: um benchmark com sistemas mais simples, usados em trabalhos relacionados, e uma amostra mais significativa baseada em sistemas complexos e reais. Avaliamos a efic\\'acia da nova extens~ao do SMAT na detec\\c{c}~ao de conflitos. Os resultados indicam que, embora a gera\\c{c}~ao de testes por LLM em cen\\'arios complexos ainda seja desafiadora e custosa computacionalmente, h\\'a potencial promissor para aprimorar a detec\\c{c}~ao de conflitos sem^anticos.",
      "authors": [
        "Nathalia Barbosa (1)",
        "Paulo Borba (1)",
        "L\\'euson Da Silva (2) ((1) Centro de Inform\\'atica",
        "Universidade Federal de Pernambuco",
        "Brasil",
        "(2) Polytechnique Montreal",
        "Canad\\'a)"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T11:38:53+00:00",
          "link": "https://arxiv.org/abs/2507.06762v1",
          "size": "478kb",
          "version": "v1"
        }
      ],
      "title": "Leveraging LLMs for Semantic Conflict Detection via Unit Test Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06762",
        "PDF": "https://arxiv.org/pdf/2507.06762"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses leveraging LLMs for semantic conflict detection via unit test generation, which does not involve LLM training data processing or data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06824",
      "abstract": "This paper presents a method for online estimation of contact properties during in-hand sliding manipulation with a parallel gripper. We estimate the static and Coulomb friction as well as the contact radius from tactile measurements of contact forces and sliding velocities. The method is validated in both simulation and real-world experiments. Furthermore, we propose a heuristic to deal with fast slip-stick dynamics which can adversely affect the estimation.",
      "authors": [
        "Gabriel Arslan Waltersson",
        "Yiannis Karayiannidis"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T13:13:17+00:00",
          "link": "https://arxiv.org/abs/2507.06824v1",
          "size": "3509kb",
          "version": "v1"
        }
      ],
      "title": "Friction Estimation for In-Hand Planar Motion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06824",
        "HTML": "https://arxiv.org/html/2507.06824v1",
        "PDF": "https://arxiv.org/pdf/2507.06824"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on friction estimation in in-hand planar motion. It does not discuss LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.16575",
      "abstract": "Since 2023, Vector Quantization (VQ)-based discrete generation methods have rapidly dominated human motion generation, primarily surpassing diffusion-based continuous generation methods in standard performance metrics. However, VQ-based methods have inherent limitations. Representing continuous motion data as limited discrete tokens leads to inevitable information loss, reduces the diversity of generated motions, and restricts their ability to function effectively as motion priors or generation guidance. In contrast, the continuous space generation nature of diffusion-based methods makes them well-suited to address these limitations and with even potential for model scalability. In this work, we systematically investigate why current VQ-based methods perform well and explore the limitations of existing diffusion-based methods from the perspective of motion data representation and distribution. Drawing on these insights, we preserve the inherent strengths of a diffusion-based human motion generation model and gradually optimize it with inspiration from VQ-based approaches. Our approach introduces a human motion diffusion model enabled to perform masked autoregression, optimized with a reformed data representation and distribution. Additionally, we propose a more robust evaluation method to assess different approaches. Extensive experiments on various datasets demonstrate our method outperforms previous methods and achieves state-of-the-art performances.",
      "authors": [
        "Zichong Meng",
        "Yiming Xie",
        "Xiaogang Peng",
        "Zeyu Han",
        "Huaizu Jiang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-25T16:59:42+00:00",
          "link": "https://arxiv.org/abs/2411.16575v1",
          "size": "2436kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T20:15:01+00:00",
          "link": "https://arxiv.org/abs/2411.16575v2",
          "size": "2441kb",
          "version": "v2"
        }
      ],
      "title": "Rethinking Diffusion for Text-Driven Human Motion Generation: Redundant Representations, Evaluation, and Masked Autoregression",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.16575",
        "HTML": "https://arxiv.org/html/2411.16575v2",
        "PDF": "https://arxiv.org/pdf/2411.16575"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper primarily focuses on human motion generation models and their optimization, with no emphasis on processing LLM training data or data engineering tasks associated with LLMs."
      },
      "tasks": [
        "Motion Generation",
        "Quantization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.14541",
      "abstract": "The rapid advancement of Large Language Models (LLMs) has opened new opportunities in recommender systems by enabling zero-shot recommendation without conventional training. Despite their potential, most existing works rely solely on users' purchase histories, leaving significant room for improvement by incorporating user-generated textual data, such as reviews and product descriptions. Addressing this gap, we propose PURE, a novel LLM-based recommendation framework that builds and maintains evolving user profiles by systematically extracting and summarizing key information from user reviews. PURE consists of three core components: a Review Extractor for identifying user preferences and key product features, a Profile Updater for refining and updating user profiles, and a Recommender for generating personalized recommendations using the most current profile. To evaluate PURE, we introduce a continuous sequential recommendation task that reflects real-world scenarios by adding reviews over time and updating predictions incrementally. Our experimental results on Amazon datasets demonstrate that PURE outperforms existing LLM-based methods, effectively leveraging long-term user information while managing token limitations.",
      "authors": [
        "Seunghwan Bang",
        "Hwanjun Song"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-20T13:20:19+00:00",
          "link": "https://arxiv.org/abs/2502.14541v1",
          "size": "209kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T10:55:06+00:00",
          "link": "https://arxiv.org/abs/2502.14541v2",
          "size": "153kb",
          "version": "v2"
        }
      ],
      "title": "LLM-based User Profile Management for Recommender System",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.14541",
        "HTML": "https://arxiv.org/html/2502.14541v2",
        "PDF": "https://arxiv.org/pdf/2502.14541"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper presents PURE, which includes extracting and summarizing user-generated textual data to build LLM-based user profiles, a relevant contribution to processing textual data to improve dataset quality for recommender systems."
      },
      "tasks": [
        "Management",
        "Recommendation Systems",
        "Sequential Recommendation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.20659",
      "abstract": "For reinforcement learning agents to be deployed in high-risk settings, they must achieve a high level of robustness to unfamiliar scenarios. One method for improving robustness is unsupervised environment design (UED), a suite of methods aiming to maximise an agent's generalisability across configurations of an environment. In this work, we study UED from an optimisation perspective, providing stronger theoretical guarantees for practical settings than prior work. Whereas previous methods relied on guarantees if they reach convergence, our framework employs a nonconvex-strongly-concave objective for which we provide a provably convergent algorithm in the zero-sum setting. We empirically verify the efficacy of our method, outperforming prior methods in a number of environments with varying difficulties.",
      "authors": [
        "Nathan Monette",
        "Alistair Letcher",
        "Michael Beukman",
        "Matthew T. Jackson",
        "Alexander Rutherford",
        "Alexander D. Goldie",
        "Jakob N. Foerster"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-27T03:07:26+00:00",
          "link": "https://arxiv.org/abs/2505.20659v1",
          "size": "1089kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T09:50:34+00:00",
          "link": "https://arxiv.org/abs/2505.20659v2",
          "size": "1090kb",
          "version": "v2"
        }
      ],
      "title": "An Optimisation Framework for Unsupervised Environment Design",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.20659",
        "HTML": "https://arxiv.org/html/2505.20659v2",
        "PDF": "https://arxiv.org/pdf/2505.20659"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is focused on reinforcement learning and optimizing unsupervised environment design, which is unrelated to LLM training data processing or any data engineering tasks for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06515",
      "abstract": "Most recently, researchers have started building large language models (LLMs) powered data systems that allow users to analyze unstructured text documents like working with a database because LLMs are very effective in extracting attributes from documents. In such systems, LLM-based extraction operations constitute the performance bottleneck of query execution due to the high monetary cost and slow LLM inference. Existing systems typically borrow the query optimization principles popular in relational databases to produce query execution plans, which unfortunately are ineffective in minimizing LLM cost. To fill this gap, we propose QUEST, which features a bunch of novel optimization strategies for unstructured document analysis. First, we introduce an index-based strategy to minimize the cost of each extraction operation. With this index, QUEST quickly retrieves the text segments relevant to the target attributes and only feeds them to LLMs. Furthermore, we design an evidence-augmented retrieval strategy to reduce the possibility of missing relevant segments. Moreover, we develop an instance-optimized query execution strategy: because the attribute extraction cost could vary significantly document by document, QUEST produces different plans for different documents. For each document, QUEST produces a plan to minimize the frequency of attribute extraction. The innovations include LLM cost-aware operator ordering strategies and an optimized join execution approach that transforms joins into filters. Extensive experiments on 3 real-world datasets demonstrate the superiority of QUEST, achieving 30%-6x cost savings while improving the F1 score by 10% -27% compared with state-of-the-art baselines.",
      "authors": [
        "Zhaoze Sun",
        "Qiyan Deng",
        "Chengliang Chai",
        "Kaisen Jin",
        "Xinyu Guo",
        "Han Han",
        "Ye Yuan",
        "Guoren Wang",
        "Lei Cao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T03:30:09+00:00",
          "link": "https://arxiv.org/abs/2507.06515v1",
          "size": "6066kb",
          "version": "v1"
        }
      ],
      "title": "QUEST: Query Optimization in Unstructured Document Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06515",
        "HTML": "https://arxiv.org/html/2507.06515v1",
        "PDF": "https://arxiv.org/pdf/2507.06515"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces QUEST, which involves optimizing the processing of unstructured document data for efficient analysis using LLMs\u2014this includes techniques to minimize LLM processing costs, thus contributing directly to LLM data processing improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06607",
      "abstract": "Recent advances in language modeling have demonstrated the effectiveness of State Space Models (SSMs) for efficient sequence modeling. While hybrid architectures such as Samba and the decoder-decoder architecture, YOCO, have shown promising performance gains over Transformers, prior works have not investigated the efficiency potential of representation sharing between SSM layers. In this paper, we introduce the Gated Memory Unit (GMU), a simple yet effective mechanism for efficient memory sharing across layers. We apply it to create SambaY, a decoder-hybrid-decoder architecture that incorporates GMUs in the cross-decoder to share memory readout states from a Samba-based self-decoder. SambaY significantly enhances decoding efficiency, preserves linear pre-filling time complexity, and boosts long-context performance, all while eliminating the need for explicit positional encoding. Through extensive scaling experiments, we demonstrate that our model exhibits a significantly lower irreducible loss compared to a strong YOCO baseline, indicating superior performance scalability under large-scale compute regimes. Our largest model enhanced with Differential Attention, Phi4-mini-Flash-Reasoning, achieves significantly better performance than Phi4-mini-Reasoning on reasoning tasks such as Math500, AIME24/25, and GPQA Diamond without any reinforcement learning, while delivering up to 10x higher decoding throughput on 2K-length prompts with 32K generation length under the vLLM inference framework. We release our training codebase on open-source data at https://github.com/microsoft/ArchScale.",
      "authors": [
        "Liliang Ren",
        "Congcong Chen",
        "Haoran Xu",
        "Young Jin Kim",
        "Adam Atkinson",
        "Zheng Zhan",
        "Jiankai Sun",
        "Baolin Peng",
        "Liyuan Liu",
        "Shuohang Wang",
        "Hao Cheng",
        "Jianfeng Gao",
        "Weizhu Chen",
        "Yelong Shen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T07:27:00+00:00",
          "link": "https://arxiv.org/abs/2507.06607v1",
          "size": "5316kb",
          "version": "v1"
        }
      ],
      "title": "Decoder-Hybrid-Decoder Architecture for Efficient Reasoning with Long Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06607",
        "HTML": "https://arxiv.org/html/2507.06607v1",
        "PDF": "https://arxiv.org/pdf/2507.06607"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a hybrid model architecture for efficient reasoning and does not discuss any aspect of LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06817",
      "abstract": "Accurate knowledge of the state variables in a dynamical system is critical for effective control, diagnosis, and supervision, especially when direct measurements of all states are infeasible. This paper presents a novel approach to designing software sensors for nonlinear dynamical systems expressed in their most general form. Unlike traditional model-based observers that rely on explicit transformations or linearization, the proposed framework integrates neural networks with adaptive Sliding Mode Control (SMC) to design a robust state observer under a less restrictive set of conditions. The learning process is driven by available sensor measurements, which are used to correct the observer's state estimate. The training methodology leverages the system's governing equations as a physics-based constraint, enabling observer synthesis without access to ground-truth state trajectories. By employing a time-varying gain matrix dynamically adjusted by the neural network, the observer adapts in real-time to system changes, ensuring robustness against noise, external disturbances, and variations in system dynamics. Furthermore, we provide sufficient conditions to guarantee estimation error convergence, establishing a theoretical foundation for the observer's reliability. The methodology's effectiveness is validated through simulations on challenging examples, including systems with non-differentiable dynamics and varying observability conditions. These examples, which are often problematic for conventional techniques, serve to demonstrate the robustness and broad applicability of our approach. The results show rapid convergence and high accuracy, underscoring the method's potential for addressing complex state estimation challenges in real-world applications.",
      "authors": [
        "Ayoub Farkane",
        "Mohamed Boutayeb",
        "Mustapha Oudani and Mounir Ghogho"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Dynamical Systems (math.DS)",
        "Machine Learning (cs.LG)",
        "Neural and Evolutionary Computing (cs.NE)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T13:06:58+00:00",
          "link": "https://arxiv.org/abs/2507.06817v1",
          "size": "1524kb",
          "version": "v1"
        }
      ],
      "title": "Designing Robust Software Sensors for Nonlinear Systems via Neural Networks and Adaptive Sliding Mode Control",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06817",
        "HTML": "https://arxiv.org/html/2507.06817v1",
        "PDF": "https://arxiv.org/pdf/2507.06817"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is concerned with designing software sensors and state estimation for nonlinear systems using neural networks and adaptive control, without discussing LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2207.12123",
      "abstract": "Network theory has primarily focused on pairwise relationships, disregarding many-body interactions: neglecting them, however, can lead to misleading representations of complex systems. Hypergraphs represent an increasingly popular alternative for describing polyadic interactions: our innovation lies in leveraging the representation of hypergraphs based on the incidence matrix for extending the entropy-based framework to higher-order structures. In analogy with the Exponential Random Graphs, we name the members of this novel class of models Exponential Random Hypergraphs. Here, we focus on two explicit examples, i.e. the generalisations of the Erd\\\"os-R\\'enyi Model and of the Configuration Model. After discussing their asymptotic properties, we employ them to analyse real-world configurations: more specifically, i) we extend the definition of several network quantities to hypergraphs, ii) compute their expected value under each null model and iii) compare it with the empirical one, in order to detect deviations from random behaviours. Differently from currently available techniques, ours is analytically tractable, scalable and effective in singling out the structural patterns of real-world hypergraphs differing significantly from those emerging as a consequence of simpler, structural constraints.",
      "authors": [
        "Fabio Saracco",
        "Giovanni Petri",
        "Renaud Lambiotte",
        "Tiziano Squartini"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Statistical Mechanics (cond-mat.stat-mech)",
        "Data Analysis, Statistics and Probability (physics.data-an)"
      ],
      "submission_historys": [
        {
          "date": "2022-07-21T16:51:47+00:00",
          "link": "https://arxiv.org/abs/2207.12123v1",
          "size": "168kb",
          "version": "v1"
        },
        {
          "date": "2024-06-14T22:08:01+00:00",
          "link": "https://arxiv.org/abs/2207.12123v2",
          "size": "603kb",
          "version": "v2"
        }
      ],
      "title": "Entropy-based random models for hypergraphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2207.12123",
        "HTML": "https://arxiv.org/html/2207.12123",
        "PDF": "https://arxiv.org/pdf/2207.12123"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents models for hypergraphs and network configurations, focusing on structural patterns and representations, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.10655",
      "abstract": "Autonomous mobile robots are increasingly used in pedestrian-rich environments where safe navigation and appropriate human interaction are crucial. While Deep Reinforcement Learning (DRL) enables socially integrated robot behavior, challenges persist in novel or perturbed scenarios to indicate when and why the policy is uncertain. Unknown uncertainty in decision-making can lead to collisions or human discomfort and is one reason why safe and risk-aware navigation is still an open problem. This work introduces a novel approach that integrates aleatoric, epistemic, and predictive uncertainty estimation into a DRL navigation framework for policy distribution uncertainty estimates. We, therefore, incorporate Observation-Dependent Variance (ODV) and dropout into the Proximal Policy Optimization (PPO) algorithm. For different types of perturbations, we compare the ability of deep ensembles and Monte-Carlo dropout (MC-dropout) to estimate the uncertainties of the policy. In uncertain decision-making situations, we propose to change the robot's social behavior to conservative collision avoidance. The results show improved training performance with ODV and dropout in PPO and reveal that the training scenario has an impact on the generalization. In addition, MC-dropout is more sensitive to perturbations and correlates the uncertainty type to the perturbation better. With the safe action selection, the robot can navigate in perturbed environments with fewer collisions.",
      "authors": [
        "Daniel Fl\\\"ogel",
        "Marcos G\\'omez Villafa\\~ne",
        "Joshua Ransiek",
        "and S\\\"oren Hohmann"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-16T18:49:38+00:00",
          "link": "https://arxiv.org/abs/2409.10655v1",
          "size": "448kb",
          "version": "v1"
        },
        {
          "date": "2025-02-28T15:38:12+00:00",
          "link": "https://arxiv.org/abs/2409.10655v2",
          "size": "4696kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T09:52:36+00:00",
          "link": "https://arxiv.org/abs/2409.10655v3",
          "size": "2363kb",
          "version": "v3"
        }
      ],
      "title": "Disentangling Uncertainty for Safe Social Navigation using Deep Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.10655",
        "HTML": "https://arxiv.org/html/2409.10655v3",
        "PDF": "https://arxiv.org/pdf/2409.10655"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a novel approach to safe navigation in robotics using deep reinforcement learning, but it does not address any aspects of LLM training data or processing techniques."
      },
      "tasks": [
        "Collision Avoidance",
        "Decision Making",
        "Deep Reinforcement Learning",
        "Navigate",
        "reinforcement-learning",
        "Reinforcement Learning",
        "Social Navigation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.10390",
      "abstract": "Transformers excel at discovering patterns in sequential data, yet their fundamental limitations and learning mechanisms remain crucial topics of investigation. In this paper, we study the ability of Transformers to learn pseudo-random number sequences from linear congruential generators (LCGs), defined by the recurrence relation $x_{t+1} = a x_t + c \\;\\mathrm{mod}\\; m$. We find that with sufficient architectural capacity and training data variety, Transformers can perform in-context prediction of LCG sequences with unseen moduli ($m$) and parameters ($a,c$). By analyzing the embedding layers and attention patterns, we uncover how Transformers develop algorithmic structures to learn these sequences in two scenarios of increasing complexity. First, we investigate how Transformers learn LCG sequences with unseen ($a, c$) but fixed modulus; and demonstrate successful learning up to $m = 2^{32}$. We find that models learn to factorize $m$ and utilize digit-wise number representations to make sequential predictions. In the second, more challenging scenario of unseen moduli, we show that Transformers can generalize to unseen moduli up to $m_{\\text{test}} = 2^{16}$. In this case, the model employs a two-step strategy: first estimating the unknown modulus from the context, then utilizing prime factorizations to generate predictions. For this task, we observe a sharp transition in the accuracy at a critical depth $d= 3$. We also find that the number of in-context sequence elements needed to reach high accuracy scales sublinearly with the modulus.",
      "authors": [
        "Tao Tao",
        "Darshil Doshi",
        "Dayal Singh Kalra",
        "Tianyu He",
        "Maissam Barkeshli"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
        "Cryptography and Security (cs.CR)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-14T18:59:40+00:00",
          "link": "https://arxiv.org/abs/2502.10390v1",
          "size": "15560kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T18:20:16+00:00",
          "link": "https://arxiv.org/abs/2502.10390v2",
          "size": "17077kb",
          "version": "v2"
        }
      ],
      "title": "(How) Can Transformers Predict Pseudo-Random Numbers?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.10390",
        "HTML": "https://arxiv.org/html/2502.10390v2",
        "PDF": "https://arxiv.org/pdf/2502.10390"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper investigates Transformers' ability to predict pseudo-random numbers, without discussing any aspect of LLM training data processing or creation."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.06471",
      "abstract": "The rise of graph data in various fields calls for efficient and scalable community detection algorithms. In this paper, we present parallel implementations of two widely used algorithms: Label Propagation and Louvain, specifically designed to leverage the capabilities of Arachne which is a Python-accessible, open-source framework for large-scale graph analysis. Our implementations achieve substantial speedups over existing Python-based tools like NetworkX and igraph, which lack efficient parallelization, and are competitive with parallel frameworks such as NetworKit. Experimental results show that Arachne-based methods outperform these baselines, achieving speedups of up to 710x over NetworkX, 75x over igraph, and 12x over NetworKit. Additionally, we analyze the scalability of our implementation under varying thread counts, demonstrating how different phases contribute to overall performance gains of the parallel Louvain algorithm. Arachne, including our community detection implementation, is open-source and available at https://github.com/Bears-R-Us/arkouda-njit .",
      "authors": [
        "Fuhuan Li",
        "Zhihui Du",
        "David A. Bader"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T01:17:49+00:00",
          "link": "https://arxiv.org/abs/2507.06471v1",
          "size": "225kb",
          "version": "v1"
        }
      ],
      "title": "Designing Parallel Algorithms for Community Detection using Arachne",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06471",
        "HTML": "https://arxiv.org/html/2507.06471v1",
        "PDF": "https://arxiv.org/pdf/2507.06471"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents parallel algorithms for community detection in graph data, focusing on efficiency and scalability, not on processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06780",
      "abstract": "This article introduces an imitation learning method for learning maximum entropy policies that comply with constraints demonstrated by expert trajectories executing a task. The formulation of the method takes advantage of results connecting performance to bounds for the KL-divergence between demonstrated and learned policies, and its objective is rigorously justified through a connection to a probabilistic inference framework for reinforcement learning, incorporating the reinforcement learning objective and the objective to abide by constraints in an entropy maximization setting. The proposed algorithm optimizes the learning objective with dual gradient descent, supporting effective and stable training. Experiments show that the proposed method can learn effective policy models for constraints-abiding behaviour, in settings with multiple constraints of different types, accommodating different modalities of demonstrated behaviour, and with abilities to generalize.",
      "authors": [
        "George Papadopoulos",
        "George A. Vouros"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T12:11:27+00:00",
          "link": "https://arxiv.org/abs/2507.06780v1",
          "size": "4428kb",
          "version": "v1"
        }
      ],
      "title": "Learning safe, constrained policies via imitation learning: Connection to Probabilistic Inference and a Naive Algorithm",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06780",
        "HTML": "https://arxiv.org/html/2507.06780v1",
        "PDF": "https://arxiv.org/pdf/2507.06780"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses an imitation learning method for learning policies based on constraints, without focus on processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07101",
      "abstract": "Conventional wisdom dictates that small batch sizes make language model pretraining and fine-tuning unstable, motivating gradient accumulation, which trades off the number of optimizer steps for a proportional increase in batch size. While it is common to decrease the learning rate for smaller batch sizes, other hyperparameters are often held fixed. In this work, we revisit small batch sizes all the way down to batch size one, and we propose a rule for scaling Adam hyperparameters to small batch sizes. We find that small batch sizes (1) train stably, (2) are consistently more robust to hyperparameter choices, (3) achieve equal or better per-FLOP performance than larger batch sizes, and (4) notably enable stable language model training with vanilla SGD, even without momentum, despite storing no optimizer state. Building on these results, we provide practical recommendations for selecting a batch size and setting optimizer hyperparameters. We further recommend against gradient accumulation unless training on multiple devices with multiple model replicas, bottlenecked by inter-device bandwidth.",
      "authors": [
        "Martin Marek",
        "Sanae Lotfi",
        "Aditya Somasundaram",
        "Andrew Gordon Wilson",
        "Micah Goldblum"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T17:57:36+00:00",
          "link": "https://arxiv.org/abs/2507.07101v1",
          "size": "542kb",
          "version": "v1"
        }
      ],
      "title": "Small Batch Size Training for Language Models: When Vanilla SGD Works, and Why Gradient Accumulation Is Wasteful",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07101",
        "HTML": "https://arxiv.org/html/2507.07101v1",
        "PDF": "https://arxiv.org/pdf/2507.07101"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses batch size effects on language model training stability, but it primarily focuses on training techniques and hyperparameters rather than significant data processing contributions."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07106",
      "abstract": "Recent advances in multimodal large language models (MLLMs) have enabled image-based question-answering capabilities. However, a key limitation is the use of CLIP as the visual encoder; while it can capture coarse global information, it often can miss fine-grained details that are relevant to the input query. To address these shortcomings, this work studies whether pre-trained text-to-image diffusion models can serve as instruction-aware visual encoders. Through an analysis of their internal representations, we find diffusion features are both rich in semantics and can encode strong image-text alignment. Moreover, we find that we can leverage text conditioning to focus the model on regions relevant to the input question. We then investigate how to align these features with large language models and uncover a leakage phenomenon, where the LLM can inadvertently recover information from the original diffusion prompt. We analyze the causes of this leakage and propose a mitigation strategy. Based on these insights, we explore a simple fusion strategy that utilizes both CLIP and conditional diffusion features. We evaluate our approach on both general VQA and specialized MLLM benchmarks, demonstrating the promise of diffusion models for visual understanding, particularly in vision-centric tasks that require spatial and compositional reasoning. Our project page can be found https://vatsalag99.github.io/mustafar/.",
      "authors": [
        "Vatsal Agarwal",
        "Matthew Gwilliam",
        "Gefen Kohavi",
        "Eshan Verma",
        "Daniel Ulbricht",
        "Abhinav Shrivastava"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T17:59:47+00:00",
          "link": "https://arxiv.org/abs/2507.07106v1",
          "size": "32383kb",
          "version": "v1"
        }
      ],
      "title": "Towards Multimodal Understanding via Stable Diffusion as a Task-Aware Feature Extractor",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07106",
        "HTML": "https://arxiv.org/html/2507.07106v1",
        "PDF": "https://arxiv.org/pdf/2507.07106"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper explores using diffusion models as visual encoders for multimodal understanding, focusing on feature extraction and alignment with LLMs, rather than on LLM training data processing directly."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.03785",
      "abstract": "Large Language Models (LLMs) have shown to be effective evaluators across various domains such as machine translations or the scientific domain. Current LLM-as-a-Judge approaches rely mostly on individual assessments or a single round of pairwise assessments, preventing the judge LLM from developing a global ranking perspective. To address this, we present Knockout Assessment, an LLM-asa Judge method using a knockout tournament system with iterative pairwise comparisons. Experiments across three LLMs on two datasets show that knockout assessment improves scoring accuracy, increasing Pearson correlation with expert evaluations by 0.07 on average for university-level exam scoring and machine translation evaluations, aligning LLM assessments more closely with human scoring.",
      "authors": [
        "Isik Baran Sandan",
        "Tu Anh Dinh",
        "Jan Niehues"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-04T09:46:43+00:00",
          "link": "https://arxiv.org/abs/2506.03785v1",
          "size": "279kb",
          "version": "v1"
        },
        {
          "date": "2025-06-05T13:01:33+00:00",
          "link": "https://arxiv.org/abs/2506.03785v2",
          "size": "279kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T10:58:38+00:00",
          "link": "https://arxiv.org/abs/2506.03785v3",
          "size": "279kb",
          "version": "v3"
        }
      ],
      "title": "Knockout LLM Assessment: Using Large Language Models for Evaluations through Iterative Pairwise Comparisons",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.03785",
        "HTML": "https://arxiv.org/html/2506.03785v3",
        "PDF": "https://arxiv.org/pdf/2506.03785"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a method for evaluating LLMs using iterative pairwise comparisons and does not focus on LLM training data processing or data engineering."
      },
      "tasks": [
        "Machine Translation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06411",
      "abstract": "Inspired by the recent success of transformers and multi-stage architectures in video recognition and object detection domains. We thoroughly explore the rich spatio-temporal properties of transformers within a multi-stage architecture paradigm for the temporal action localization (TAL) task. This exploration led to the development of a hierarchical multi-stage transformer architecture called PCL-Former, where each subtask is handled by a dedicated transformer module with a specialized loss function. Specifically, the Proposal-Former identifies candidate segments in an untrimmed video that may contain actions, the Classification-Former classifies the action categories within those segments, and the Localization-Former precisely predicts the temporal boundaries (i.e., start and end) of the action instances. To evaluate the performance of our method, we have conducted extensive experiments on three challenging benchmark datasets: THUMOS-14, ActivityNet-1.3, and HACS Segments. We also conducted detailed ablation experiments to assess the impact of each individual module of our PCL-Former. The obtained quantitative results validate the effectiveness of the proposed PCL-Former, outperforming state-of-the-art TAL approaches by 2.8%, 1.2%, and 4.8% on THUMOS14, ActivityNet-1.3, and HACS datasets, respectively.",
      "authors": [
        "Hayat Ullah",
        "Arslan Munir",
        "Oliver Nina"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T21:28:16+00:00",
          "link": "https://arxiv.org/abs/2507.06411v1",
          "size": "6409kb",
          "version": "v1"
        }
      ],
      "title": "Hierarchical Multi-Stage Transformer Architecture for Context-Aware Temporal Action Localization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06411",
        "HTML": "https://arxiv.org/html/2507.06411v1",
        "PDF": "https://arxiv.org/pdf/2507.06411"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on developing a transformer architecture for temporal action localization in videos and evaluating it on existing datasets. It does not discuss any aspect of LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06653",
      "abstract": "Similarity-based vector search facilitates many important applications such as search and recommendation but is limited by the memory capacity and bandwidth of a single machine due to large datasets and intensive data read. In this paper, we present CoTra, a system that scales up vector search for distributed execution. We observe a tension between computation and communication efficiency, which is the main challenge for good scalability, i.e., handling the local vectors on each machine independently blows up computation as the pruning power of vector index is not fully utilized, while running a global index over all machines introduces rich data dependencies and thus extensive communication. To resolve such tension, we leverage the fact that vector search is approximate in nature and robust to asynchronous execution. In particular, we run collaborative vector search over the machines with algorithm-system co-designs including clustering-based data partitioning to reduce communication, asynchronous execution to avoid communication stall, and task push to reduce network traffic. To make collaborative search efficient, we introduce a suite of system optimizations including task scheduling, communication batching, and storage format. We evaluate CoTra on real datasets and compare with four baselines. The results show that when using 16 machines, the query throughput of CoTra scales to 9.8-13.4x over a single machine and is 2.12-3.58x of the best-performing baseline at 0.95 recall@10.",
      "authors": [
        "Xiangyu Zhi",
        "Meng Chen",
        "Xiao Yan",
        "Baotong Lu",
        "Hui Li",
        "Qianxi Zhang",
        "Qi Chen",
        "James Cheng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T08:36:20+00:00",
          "link": "https://arxiv.org/abs/2507.06653v1",
          "size": "782kb",
          "version": "v1"
        }
      ],
      "title": "Towards Efficient and Scalable Distributed Vector Search with RDMA",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06653",
        "HTML": "https://arxiv.org/html/2507.06653v1",
        "PDF": "https://arxiv.org/pdf/2507.06653"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a system for distributed vector search but does not address LLM training data processing or data creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.08120",
      "abstract": "Unified multimodal models (UMMs) have emerged as a powerful paradigm in foundational computer vision research, demonstrating significant potential in both image understanding and generation. However, existing research in the face domain primarily focuses on $\\textbf{coarse}$ facial attribute understanding, with limited capacity to handle $\\textbf{fine-grained}$ facial attributes and without addressing generation capabilities. To overcome these limitations, we propose UniF$^2$ace, the first UMM tailored specifically for fine-grained face understanding and generation. In general, we train UniF$^2$ace on a self-constructed, specialized dataset utilizing two mutually beneficial diffusion techniques and a two-level mixture-of-experts architecture. Specifically, we first build a large-scale facial dataset, UniF$^2$ace-130K, which contains 130K image-text pairs with one million question-answering pairs that span a wide range of facial attributes. Second, we establish a theoretical connection between discrete diffusion score matching and masked generative models, optimizing both evidence lower bounds simultaneously, which significantly improves the model's ability to synthesize facial details. Finally, we introduce both token-level and sequence-level mixture-of-experts, enabling efficient fine-grained representation learning for both understanding and generation tasks. Extensive experiments on UniF$^2$ace-130K demonstrate that UniF$^2$ace outperforms existing UMMs and generative models, achieving superior performance across both understanding and generation tasks.",
      "authors": [
        "Junzhe Li",
        "Xuerui Qiu",
        "Linrui Xu",
        "Liya Guo",
        "Delin Qu",
        "Tingting Long",
        "Chun Fan",
        "Ming Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-11T07:34:59+00:00",
          "link": "https://arxiv.org/abs/2503.08120v1",
          "size": "24953kb",
          "version": "v1"
        },
        {
          "date": "2025-03-26T02:30:35+00:00",
          "link": "https://arxiv.org/abs/2503.08120v2",
          "size": "24953kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T03:25:22+00:00",
          "link": "https://arxiv.org/abs/2503.08120v3",
          "size": "22241kb",
          "version": "v3"
        }
      ],
      "title": "UniF$^2$ace: Fine-grained Face Understanding and Generation with Unified Multimodal Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.08120",
        "HTML": "https://arxiv.org/html/2503.08120v3",
        "PDF": "https://arxiv.org/pdf/2503.08120"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper details the creation of a new dataset, UniF$^2$ace-130K, with detailed data processing steps for training multimodal models, indicating a core contribution to data processing."
      },
      "tasks": [
        "Attribute",
        "Mixture-of-Experts",
        "Question Answering",
        "Representation Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.19452",
      "abstract": "Machine-learning-based surrogate models offer significant computational efficiency and faster simulations compared to traditional numerical methods, especially for problems requiring repeated evaluations of partial differential equations. This work introduces the Geometry-Informed Neural Operator Transformer (GINOT), which integrates the transformer architecture with the neural operator framework to enable forward predictions on arbitrary geometries. GINOT employs a sampling and grouping strategy together with an attention mechanism to encode surface point clouds that are unordered, exhibit non-uniform point densities, and contain varying numbers of points for different geometries. The geometry information is seamlessly integrated with query points in the solution decoder through the attention mechanism. The performance of GINOT is validated on multiple challenging datasets, showcasing its high accuracy and strong generalization capabilities for complex and arbitrary 2D and 3D geometries.",
      "authors": [
        "Qibang Liu",
        "Weiheng Zhong",
        "Hadi Meidani",
        "Diab Abueidda",
        "Seid Koric",
        "Philippe Geubelle"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computational Physics (physics.comp-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-28T03:39:27+00:00",
          "link": "https://arxiv.org/abs/2504.19452v1",
          "size": "9333kb",
          "version": "v1"
        },
        {
          "date": "2025-04-29T15:30:04+00:00",
          "link": "https://arxiv.org/abs/2504.19452v2",
          "size": "9333kb",
          "version": "v2"
        },
        {
          "date": "2025-05-28T02:52:31+00:00",
          "link": "https://arxiv.org/abs/2504.19452v3",
          "size": "9333kb",
          "version": "v3"
        },
        {
          "date": "2025-07-09T17:13:05+00:00",
          "link": "https://arxiv.org/abs/2504.19452v4",
          "size": "9218kb",
          "version": "v4"
        }
      ],
      "title": "Geometry-Informed Neural Operator Transformer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.19452",
        "HTML": "https://arxiv.org/html/2504.19452v4",
        "PDF": "https://arxiv.org/pdf/2504.19452"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces the Geometry-Informed Neural Operator Transformer (GINOT) and focuses on neural architectures for simulations, which does not involve any specific processing or creation of training data for LLMs."
      },
      "tasks": [
        "Computational Efficiency",
        "Decoder"
      ],
      "repo_urls": [
        "https://github.com/QibangLiu/GINOT"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07010",
      "abstract": "Historically, functional magnetic resonance imaging (fMRI) of the brain has focused primarily on gray matter, particularly the cortical gray matter and associated nuclei. However, recent work has demonstrated that functional activity in white matter also plays a meaningful role in both cognition and learning. In previous work, we introduced the High Angular Resolution Functional Imaging (HARFI) pipeline, which demonstrated both local and global patterns of functional correlation in white matter. Notably, HARFI enabled exploration of asymmetric voxel-wise correlation using odd-order spherical harmonics. Although the original implementation of HARFI was released via GitHub, adoption was limited due to the technical complexity of running the source code. In this work, we present a robust and efficient containerized version of the HARFI pipeline, enabling seamless execution across multiple public datasets. Our goal is to facilitate broader and deeper exploration of functional white matter architecture, especially through the lens of high angular resolution functional correlations. The key innovation of this work is the containerized implementation, which we have made available under a permissive open-source license to support reproducible and accessible research practices.",
      "authors": [
        "Zhiyuan Li",
        "Kurt G. Schilling",
        "and Bennett A. Landman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Medical Physics (physics.med-ph)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T16:40:27+00:00",
          "link": "https://arxiv.org/abs/2507.07010v1",
          "size": "6097kb",
          "version": "v1"
        }
      ],
      "title": "Robust Containerization of the High Angular Resolution Functional Imaging (HARFI) Pipeline",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07010",
        "PDF": "https://arxiv.org/pdf/2507.07010"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work pertains to the containerization of a functional imaging pipeline for fMRI data and does not relate to the processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.06355",
      "abstract": "Multimodal transformers integrate diverse data types like images, audio, and text, advancing tasks such as audio-visual understanding and image-text retrieval; yet their high parameterization limits deployment on resource-constrained edge devices. Split Learning (SL), which partitions models at a designated cut-layer to offload compute-intensive operations to the server, offers a promising approach for distributed training of multimodal transformers, though its application remains underexplored. We present MPSL, a parallel SL approach for computational efficient fine-tuning of multimodal transformers in a distributed manner, while eliminating label sharing, client synchronization, and per-client sub-model management. MPSL employs lightweight client-side tokenizers and a unified modality-agnostic encoder, allowing flexible adaptation to task-specific needs. Our evaluation across 7 multimodal datasets demonstrates that MPSL matches or outperforms Federated Learning, reduces client-side computations by 250x, and achieves superior scalability in communication cost with model growth. Through extensive analysis, we highlight task suitability, trade-offs, and scenarios where MPSL excels, inspiring further exploration.",
      "authors": [
        "Timo Fudala",
        "Vasileios Tsouvalas",
        "Nirvana Meratnia"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-10T11:10:41+00:00",
          "link": "https://arxiv.org/abs/2502.06355v1",
          "size": "2527kb",
          "version": "v1"
        },
        {
          "date": "2025-07-04T14:11:17+00:00",
          "link": "https://arxiv.org/abs/2502.06355v2",
          "size": "1615kb",
          "version": "v2"
        },
        {
          "date": "2025-07-08T21:12:11+00:00",
          "link": "https://arxiv.org/abs/2502.06355v3",
          "size": "1620kb",
          "version": "v3"
        }
      ],
      "title": "Fine-tuning Multimodal Transformers on Edge: A Parallel Split Learning Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.06355",
        "HTML": "https://arxiv.org/html/2502.06355v3",
        "PDF": "https://arxiv.org/pdf/2502.06355"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses split learning for fine-tuning multimodal transformers but does not focus on processing LLM training data specifically."
      },
      "tasks": [
        "Federated Learning",
        "Image-text Retrieval",
        "Management",
        "Text Retrieval"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06442",
      "abstract": "Wearable cameras are increasingly used as an observational and interventional tool for human behaviors by providing detailed visual data of hand-related activities. This data can be leveraged to facilitate memory recall for logging of behavior or timely interventions aimed at improving health. However, continuous processing of RGB images from these cameras consumes significant power impacting battery lifetime, generates a large volume of unnecessary video data for post-processing, raises privacy concerns, and requires substantial computational resources for real-time analysis. We introduce THOR, a real-time adaptive spatio-temporal RGB frame sampling method that leverages thermal sensing to capture hand-object patches and classify them in real-time. We use low-resolution thermal camera data to identify moments when a person switches from one hand-related activity to another, and adjust the RGB frame sampling rate by increasing it during activity transitions and reducing it during periods of sustained activity. Additionally, we use the thermal cues from the hand to localize the region of interest (i.e., the hand-object interaction) in each RGB frame, allowing the system to crop and process only the necessary part of the image for activity recognition. We develop a wearable device to validate our method through an in-the-wild study with 14 participants and over 30 activities, and further evaluate it on Ego4D (923 participants across 9 countries, totaling 3,670 hours of video). Our results show that using only 3% of the original RGB video data, our method captures all the activity segments, and achieves hand-related activity recognition F1-score (95%) comparable to using the entire RGB video (94%). Our work provides a more practical path for the longitudinal use of wearable cameras to monitor hand-related activities and health-risk behaviors in real time.",
      "authors": [
        "Soroush Shahi",
        "Farzad Shahabi",
        "Rama Nabulsi",
        "Glenn Fernandes",
        "Aggelos Katsaggelos",
        "Nabil Alshurafa"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T22:56:21+00:00",
          "link": "https://arxiv.org/abs/2507.06442v1",
          "size": "48075kb",
          "version": "v1"
        }
      ],
      "title": "THOR: Thermal-guided Hand-Object Reasoning via Adaptive Vision Sampling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06442",
        "PDF": "https://arxiv.org/pdf/2507.06442"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a method for hand-object reasoning using adaptive vision sampling, but there is no mention of LLM training data processing or related data engineering techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06361",
      "abstract": "We present an instance of utility-grade quantum computation by calculating the ground-state energy of a 125-site flat Kagome lattice under the antiferromagnetic Heisenberg model (KAFH), using IBM's Falcon and Hummingbird quantum processors. For spin-1/2 KAFH, our best per-site ground-state energy estimate reaches -0.417J, and after applying open-boundary corrections, it closely approaches the established thermodynamic value of -0.438J. To achieve this, we propose a hybrid approach that splits the variational quantum eigensolver (VQE) into local (classical) and global (quantum) components for efficient hardware utilization. We further introduce a Hamiltonian engineering strategy that increases coupling on defect triangles to mimic loop-flip dynamics, allowing us to simplify the ansatz while retaining physical accuracy. Using a single-repetition, hardware-efficient ansatz, we entangle up to 103 qubits with high fidelity to determine the Hamiltonian's lowest eigenvalue. This work demonstrates the scalability of VQE for frustrated 2D systems and lays the foundation for future studies using deeper ansatz circuits and larger lattices.",
      "authors": [
        "Muhammad Ahsan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T19:49:17+00:00",
          "link": "https://arxiv.org/abs/2507.06361v1",
          "size": "7365kb",
          "version": "v1"
        }
      ],
      "title": "Experimental Ground-State Energy of a 125-Site Flat Kagome Antiferromagnet via Hamiltonian Engineering on Quantum Computer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06361",
        "HTML": "https://arxiv.org/html/2507.06361v1",
        "PDF": "https://arxiv.org/pdf/2507.06361"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents quantum computation for calculating energy values, including Hamiltonian engineering strategies. It does not involve any aspect of LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06662",
      "abstract": "Category-level object pose estimation, which predicts the pose of objects within a known category without prior knowledge of individual instances, is essential in applications like warehouse automation and manufacturing. Existing methods relying on RGB images or point cloud data often struggle with object occlusion and generalization across different instances and categories. This paper proposes a multimodal-based keypoint learning framework (MK-Pose) that integrates RGB images, point clouds, and category-level textual descriptions. The model uses a self-supervised keypoint detection module enhanced with attention-based query generation, soft heatmap matching and graph-based relational modeling. Additionally, a graph-enhanced feature fusion module is designed to integrate local geometric information and global context. MK-Pose is evaluated on CAMERA25 and REAL275 dataset, and is further tested for cross-dataset capability on HouseCat6D dataset. The results demonstrate that MK-Pose outperforms existing state-of-the-art methods in both IoU and average precision without shape priors. Codes will be released at \\href{https://github.com/yangyifanYYF/MK-Pose}{https://github.com/yangyifanYYF/MK-Pose}.",
      "authors": [
        "Yifan Yang",
        "Peili Song",
        "Enfan Lan",
        "Dong Liu and Jingtai Liu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T08:46:40+00:00",
          "link": "https://arxiv.org/abs/2507.06662v1",
          "size": "863kb",
          "version": "v1"
        }
      ],
      "title": "MK-Pose: Category-Level Object Pose Estimation via Multimodal-Based Keypoint Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06662",
        "HTML": "https://arxiv.org/html/2507.06662v1",
        "PDF": "https://arxiv.org/pdf/2507.06662"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on object pose estimation using multimodal data (RGB images, point clouds, and textual descriptions) and does not discuss LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2311.14136",
      "abstract": "The rapid growth of Internet of Things (IoT) devices and applications has led to an increased demand for advanced analytics and machine learning techniques capable of handling the challenges associated with data privacy, security, and scalability. Federated learning (FL) and blockchain technologies have emerged as promising approaches to address these challenges by enabling decentralized, secure, and privacy-preserving model training on distributed data sources. In this paper, we present a novel IoT solution that combines the incremental learning vector quantization algorithm (XuILVQ) with Ethereum blockchain technology to facilitate secure and efficient data sharing, model training, and prototype storage in a distributed environment. Our proposed architecture addresses the shortcomings of existing blockchain-based FL solutions by reducing computational and communication overheads while maintaining data privacy and security. We assess the performance of our system through a series of experiments, showcasing its potential to enhance the accuracy and efficiency of machine learning tasks in IoT settings.",
      "authors": [
        "Carlos Beis-Penedo",
        "Francisco Troncoso-Pastoriza",
        "Rebeca P. D\\'iaz-Redondo",
        "Ana Fern\\'andez-Vilas",
        "Manuel Fern\\'andez-Veiga and Mart\\'in Gonz\\'alez Soto"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Cryptography and Security (cs.CR)",
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2023-11-23T18:06:05+00:00",
          "link": "https://arxiv.org/abs/2311.14136v1",
          "size": "564kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T11:08:49+00:00",
          "link": "https://arxiv.org/abs/2311.14136v2",
          "size": "581kb",
          "version": "v2"
        }
      ],
      "title": "A Blockchain Solution for Collaborative Machine Learning over IoT",
      "links": {
        "Abstract": "https://arxiv.org/abs/2311.14136",
        "HTML": "https://arxiv.org/html/2311.14136v2",
        "PDF": "https://arxiv.org/pdf/2311.14136"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a blockchain-based solution for federated learning in IoT environments. It focuses on decentralized model training, not on LLM training data processing or data engineering."
      },
      "tasks": [
        "Federated Learning",
        "Incremental Learning",
        "Privacy Preserving",
        "Quantization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.11461",
      "abstract": "Achieving successful scan matching is essential for LiDAR odometry. However, in challenging environments with adverse weather conditions or repetitive geometric patterns, LiDAR odometry performance is degraded due to incorrect scan matching. Recently, the emergence of frequency-modulated continuous wave 4D LiDAR and 4D radar technologies has provided the potential to address these unfavorable conditions. The term 4D refers to point cloud data characterized by range, azimuth, and elevation along with Doppler velocity. Although 4D data is available, most scan matching methods for 4D LiDAR and 4D radar still establish correspondence by repeatedly identifying the closest points between consecutive scans, overlooking the Doppler information. This paper introduces, for the first time, a simple Doppler velocity-based correspondence -- Doppler Correspondence -- that is invariant to translation and small rotation of the sensor, with its geometric and kinematic foundations. Extensive experiments demonstrate that the proposed method enables the direct matching of consecutive point clouds without an iterative process, making it computationally efficient. Additionally, it provides a more robust correspondence estimation in environments with repetitive geometric patterns.The implementation of our proposed method is publicly available at https://github.com/Tars0523/Doppler Correspondence.",
      "authors": [
        "Jiwoo Kim",
        "Geunsik Bae",
        "Changseung Kim",
        "Jinwoo Lee",
        "Woojae Shin",
        "Hyondong Oh"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-17T05:37:07+00:00",
          "link": "https://arxiv.org/abs/2502.11461v1",
          "size": "31595kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T01:24:36+00:00",
          "link": "https://arxiv.org/abs/2502.11461v2",
          "size": "17433kb",
          "version": "v2"
        }
      ],
      "title": "Doppler Correspondence: Non-Iterative Scan Matching With Doppler Velocity-Based Correspondence",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.11461",
        "HTML": "https://arxiv.org/html/2502.11461v2",
        "PDF": "https://arxiv.org/pdf/2502.11461"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a method for scan matching in LiDAR odometry using Doppler velocity, which is unrelated to LLM training data processing, data collection, or data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06457",
      "abstract": "Transformers face quadratic complexity and memory issues with long sequences, prompting the adoption of linear attention mechanisms using fixed-size hidden states. However, linear models often suffer from limited recall performance, leading to hybrid architectures that combine linear and full attention layers. Despite extensive hybrid architecture research, the choice of linear attention component has not been deeply explored. We systematically evaluate various linear attention models across generations - vector recurrences to advanced gating mechanisms - both standalone and hybridized. To enable this comprehensive analysis, we trained and open-sourced 72 models: 36 at 340M parameters (20B tokens) and 36 at 1.3B parameters (100B tokens), covering six linear attention variants across five hybridization ratios. Benchmarking on standard language modeling and recall tasks reveals that superior standalone linear models do not necessarily excel in hybrids. While language modeling remains stable across linear-to-full attention ratios, recall significantly improves with increased full attention layers, particularly below a 3:1 ratio. Our study highlights selective gating, hierarchical recurrence, and controlled forgetting as critical for effective hybrid models. We recommend architectures such as HGRN-2 or GatedDeltaNet with a linear-to-full ratio between 3:1 and 6:1 to achieve Transformer-level recall efficiently. Our models are open-sourced at https://huggingface.co/collections/m-a-p/hybrid-linear-attention-research-686c488a63d609d2f20e2b1e.",
      "authors": [
        "Dustin Wang",
        "Rui-Jie Zhu",
        "Steven Abreu",
        "Yong Shan",
        "Taylor Kergan",
        "Yuqi Pan",
        "Yuhong Chou",
        "Zheng Li",
        "Ge Zhang",
        "Wenhao Huang",
        "Jason Eshraghian"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T23:54:11+00:00",
          "link": "https://arxiv.org/abs/2507.06457v1",
          "size": "1292kb",
          "version": "v1"
        }
      ],
      "title": "A Systematic Analysis of Hybrid Linear Attention",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06457",
        "HTML": "https://arxiv.org/html/2507.06457v1",
        "PDF": "https://arxiv.org/pdf/2507.06457"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on evaluating hybrid linear attention models and their performance in language modeling, without any focus on processing or creating training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06590",
      "abstract": "We introduce MOST, a novel motion diffusion model via temporal clip Banzhaf interaction, aimed at addressing the persistent challenge of generating human motion from rare language prompts. While previous approaches struggle with coarse-grained matching and overlook important semantic cues due to motion redundancy, our key insight lies in leveraging fine-grained clip relationships to mitigate these issues. MOST's retrieval stage presents the first formulation of its kind - temporal clip Banzhaf interaction - which precisely quantifies textual-motion coherence at the clip level. This facilitates direct, fine-grained text-to-motion clip matching and eliminates prevalent redundancy. In the generation stage, a motion prompt module effectively utilizes retrieved motion clips to produce semantically consistent movements. Extensive evaluations confirm that MOST achieves state-of-the-art text-to-motion retrieval and generation performance by comprehensively addressing previous challenges, as demonstrated through quantitative and qualitative results highlighting its effectiveness, especially for rare prompts.",
      "authors": [
        "Yin Wang",
        "Mu li",
        "Zhiying Leng",
        "Frederick W. B. Li and Xiaohui Liang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T06:51:36+00:00",
          "link": "https://arxiv.org/abs/2507.06590v1",
          "size": "4639kb",
          "version": "v1"
        }
      ],
      "title": "MOST: Motion Diffusion Model for Rare Text via Temporal Clip Banzhaf Interaction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06590",
        "HTML": "https://arxiv.org/html/2507.06590v1",
        "PDF": "https://arxiv.org/pdf/2507.06590"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a motion diffusion model (MOST) aimed at generating human motion from language prompts, without discussing LLM training data processing or related data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06670",
      "abstract": "Recent breakthroughs in singing voice synthesis (SVS) have heightened the demand for high-quality annotated datasets, yet manual annotation remains prohibitively labor-intensive and resource-intensive. Existing automatic singing annotation (ASA) methods, however, primarily tackle isolated aspects of the annotation pipeline. To address this fundamental challenge, we present STARS, which is, to our knowledge, the first unified framework that simultaneously addresses singing transcription, alignment, and refined style annotation. Our framework delivers comprehensive multi-level annotations encompassing: (1) precise phoneme-audio alignment, (2) robust note transcription and temporal localization, (3) expressive vocal technique identification, and (4) global stylistic characterization including emotion and pace. The proposed architecture employs hierarchical acoustic feature processing across frame, word, phoneme, note, and sentence levels. The novel non-autoregressive local acoustic encoders enable structured hierarchical representation learning. Experimental validation confirms the framework's superior performance across multiple evaluation dimensions compared to existing annotation approaches. Furthermore, applications in SVS training demonstrate that models utilizing STARS-annotated data achieve significantly enhanced perceptual naturalness and precise style control. This work not only overcomes critical scalability challenges in the creation of singing datasets but also pioneers new methodologies for controllable singing voice synthesis. Audio samples are available at https://gwx314.github.io/stars-demo/.",
      "authors": [
        "Wenxiang Guo",
        "Yu Zhang",
        "Changhao Pan",
        "Zhiyuan Zhu",
        "Ruiqi Li",
        "Zhetao Chen",
        "Wenhao Xu",
        "Fei Wu",
        "Zhou Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T08:59:32+00:00",
          "link": "https://arxiv.org/abs/2507.06670v1",
          "size": "779kb",
          "version": "v1"
        }
      ],
      "title": "STARS: A Unified Framework for Singing Transcription, Alignment, and Refined Style Annotation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06670",
        "HTML": "https://arxiv.org/html/2507.06670v1",
        "PDF": "https://arxiv.org/pdf/2507.06670"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a framework for automatic annotation of singing data, which indirectly relates to data processing for singing voice synthesis (SVS), but the focus is not on LLM training data processing per se."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23581",
      "abstract": "Object detection plays a crucial role in many security-sensitive applications. However, several recent studies have shown that object detectors can be easily fooled by physically realizable attacks, \\eg, adversarial patches and recent adversarial textures, which pose realistic and urgent threats. Adversarial Training (AT) has been recognized as the most effective defense against adversarial attacks. While AT has been extensively studied in the $l_\\infty$ attack settings on classification models, AT against physically realizable attacks on object detectors has received limited exploration. Early attempts are only performed to defend against adversarial patches, leaving AT against a wider range of physically realizable attacks under-explored. In this work, we consider defending against various physically realizable attacks with a unified AT method. We propose PBCAT, a novel Patch-Based Composite Adversarial Training strategy. PBCAT optimizes the model by incorporating the combination of small-area gradient-guided adversarial patches and imperceptible global adversarial perturbations covering the entire image. With these designs, PBCAT has the potential to defend against not only adversarial patches but also unseen physically realizable attacks such as adversarial textures. Extensive experiments in multiple settings demonstrated that PBCAT significantly improved robustness against various physically realizable attacks over state-of-the-art defense methods. Notably, it improved the detection accuracy by 29.7\\% over previous defense methods under one recent adversarial texture attack.",
      "authors": [
        "Xiao Li",
        "Yiming Zhu",
        "Yifan Huang",
        "Wei Zhang",
        "Yingzhe He",
        "Jie Shi",
        "Xiaolin Hu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T07:36:21+00:00",
          "link": "https://arxiv.org/abs/2506.23581v1",
          "size": "533kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T13:36:11+00:00",
          "link": "https://arxiv.org/abs/2506.23581v2",
          "size": "533kb",
          "version": "v2"
        }
      ],
      "title": "PBCAT: Patch-based composite adversarial training against physically realizable attacks on object detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23581",
        "HTML": "https://arxiv.org/html/2506.23581v2",
        "PDF": "https://arxiv.org/pdf/2506.23581"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on adversarial training to defend against attacks in object detection, with no substantive focus on processing training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06844",
      "abstract": "We study the problem of online personalized decentralized learning with $N$ statistically heterogeneous clients collaborating to accelerate local training. An important challenge in this setting is to select relevant collaborators to reduce gradient variance while mitigating the introduced bias. To tackle this, we introduce a gradient-based collaboration criterion, allowing each client to dynamically select peers with similar gradients during the optimization process. Our criterion is motivated by a refined and more general theoretical analysis of the All-for-one algorithm, proved to be optimal in Even et al. (2022) for an oracle collaboration scheme. We derive excess loss upper-bounds for smooth objective functions, being either strongly convex, non-convex, or satisfying the Polyak-Lojasiewicz condition; our analysis reveals that the algorithm acts as a variance reduction method where the speed-up depends on a sufficient variance. We put forward two collaboration methods instantiating the proposed general schema; and we show that one variant preserves the optimality of All-for-one. We validate our results with experiments on synthetic and real datasets.",
      "authors": [
        "Constantin Philippenko",
        "Batiste Le Bars",
        "Kevin Scaman",
        "Laurent Massouli\\'e"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T13:44:27+00:00",
          "link": "https://arxiv.org/abs/2507.06844v1",
          "size": "1148kb",
          "version": "v1"
        }
      ],
      "title": "Adaptive collaboration for online personalized distributed learning with heterogeneous clients",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06844",
        "HTML": "https://arxiv.org/html/2507.06844v1",
        "PDF": "https://arxiv.org/pdf/2507.06844"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on decentralized learning and client collaboration to improve local training, with no mention of processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06973",
      "abstract": "Vision-Language Models (VLMs) have become prominent in open-world image recognition for their strong generalization abilities. Yet, their effectiveness in practical applications is compromised by domain shifts and distributional changes, especially when test data distributions diverge from training data. Therefore, the paradigm of test-time adaptation (TTA) has emerged, enabling the use of online off-the-shelf data at test time, supporting independent sample predictions, and eliminating reliance on test annotations. Traditional TTA methods, however, often rely on costly training or optimization processes, or make unrealistic assumptions about accessing or storing historical training and test data. Instead, this study proposes FreeTTA, a training-free and universally available method that makes no assumptions, to enhance the flexibility of TTA. More importantly, FreeTTA is the first to explicitly model the test data distribution, enabling the use of intrinsic relationships among test samples to enhance predictions of individual samples without simultaneous access--a direction not previously explored. FreeTTA achieves these advantages by introducing an online EM algorithm that utilizes zero-shot predictions from VLMs as priors to iteratively compute the posterior probabilities of each online test sample and update parameters. Experiments demonstrate that FreeTTA achieves stable and significant improvements compared to state-of-the-art methods across 15 datasets in both cross-domain and out-of-distribution settings.",
      "authors": [
        "Qiyuan Dai",
        "Sibei Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T16:03:07+00:00",
          "link": "https://arxiv.org/abs/2507.06973v1",
          "size": "384kb",
          "version": "v1"
        }
      ],
      "title": "Free on the Fly: Enhancing Flexibility in Test-Time Adaptation with Online EM",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06973",
        "HTML": "https://arxiv.org/html/2507.06973v1",
        "PDF": "https://arxiv.org/pdf/2507.06973"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a test-time adaptation method for vision-language models and does not focus on data processing specific to LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.12510",
      "abstract": "Endoluminal endoscopic procedures are essential for diagnosing colorectal cancer and other severe conditions in the digestive tract, urogenital system, and airways. 3D reconstruction and novel-view synthesis from endoscopic images are promising tools for enhancing diagnosis. Moreover, integrating physiological deformations and interaction with the endoscope enables the development of simulation tools from real video data. However, constrained camera trajectories and view-dependent lighting create artifacts, leading to inaccurate or overfitted reconstructions. We present PR-ENDO, a novel 3D reconstruction framework leveraging the unique property of endoscopic imaging, where a single light source is closely aligned with the camera. Our method separates light effects from tissue properties. PR-ENDO enhances 3D Gaussian Splatting with a physically based relightable model. We boost the traditional light transport formulation with a specialized MLP capturing complex light-related effects while ensuring reduced artifacts and better generalization across novel views. PR-ENDO achieves superior reconstruction quality compared to baseline methods on both public and in-house datasets. Unlike existing approaches, PR-ENDO enables tissue modifications while preserving a physically accurate response to light, making it closer to real-world clinical use.",
      "authors": [
        "Joanna Kaleta",
        "Weronika Smolak-Dy\\.zewska",
        "Dawid Malarz",
        "Diego Dall'Alba",
        "Przemys{\\l}aw Korzeniowski",
        "Przemys{\\l}aw Spurek"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-19T13:52:30+00:00",
          "link": "https://arxiv.org/abs/2411.12510v1",
          "size": "31523kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T10:50:26+00:00",
          "link": "https://arxiv.org/abs/2411.12510v2",
          "size": "3594kb",
          "version": "v2"
        }
      ],
      "title": "PR-ENDO: Physically Based Relightable Gaussian Splatting for Endoscopy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.12510",
        "HTML": "https://arxiv.org/html/2411.12510v2",
        "PDF": "https://arxiv.org/pdf/2411.12510"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a 3D reconstruction framework for endoscopic imaging, not related to LLM training data processing or improvement."
      },
      "tasks": [
        "Novel View Synthesis"
      ],
      "repo_urls": [
        "https://github.com/SanoScience/PR-ENDO"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06267",
      "abstract": "Non-autonomous differential equations are crucial for modeling systems influenced by external signals, yet fitting these models to data becomes particularly challenging when the signals change abruptly. To address this problem, we propose a novel parameter estimation method utilizing functional approximations with artificial neural networks. Our approach, termed Harmonic Approximation of Discontinuous External Signals using Neural Networks (HADES-NN), operates in two iterated stages. In the first stage, the algorithm employs a neural network to approximate the discontinuous signal with a smooth function. In the second stage, it uses this smooth approximate signal to estimate model parameters. HADES-NN gives highly accurate and precise parameter estimates across various applications, including circadian clock systems regulated by external light inputs measured via wearable devices and the mating response of yeast to external pheromone signals. HADES-NN greatly extends the range of model systems that can be fit to real-world measurements.",
      "authors": [
        "Hyeontae Jo",
        "Kre\\v{s}imir Josi\\'c",
        "Jae Kyoung Kim"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T00:42:42+00:00",
          "link": "https://arxiv.org/abs/2507.06267v1",
          "size": "1810kb",
          "version": "v1"
        }
      ],
      "title": "Neural Network-Based Parameter Estimation for Non-Autonomous Differential Equations with Discontinuous Signals",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06267",
        "HTML": "https://arxiv.org/html/2507.06267v1",
        "PDF": "https://arxiv.org/pdf/2507.06267"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on parameter estimation for non-autonomous differential equations using neural networks, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06502",
      "abstract": "As a prominent data modality task, time series forecasting plays a pivotal role in diverse applications. With the remarkable advancements in Large Language Models (LLMs), the adoption of LLMs as the foundational architecture for time series modeling has gained significant attention. Although existing models achieve some success, they rarely both model time and frequency characteristics in a pretraining-finetuning paradigm leading to suboptimal performance in predictions of complex time series, which requires both modeling periodicity and prior pattern knowledge of signals. We propose MoFE-Time, an innovative time series forecasting model that integrates time and frequency domain features within a Mixture of Experts (MoE) network. Moreover, we use the pretraining-finetuning paradigm as our training framework to effectively transfer prior pattern knowledge across pretraining and finetuning datasets with different periodicity distributions. Our method introduces both frequency and time cells as experts after attention modules and leverages the MoE routing mechanism to construct multidimensional sparse representations of input signals. In experiments on six public benchmarks, MoFE-Time has achieved new state-of-the-art performance, reducing MSE and MAE by 6.95% and 6.02% compared to the representative methods Time-MoE. Beyond the existing evaluation benchmarks, we have developed a proprietary dataset, NEV-sales, derived from real-world business scenarios. Our method achieves outstanding results on this dataset, underscoring the effectiveness of the MoFE-Time model in practical commercial applications.",
      "authors": [
        "Yiwen Liu",
        "Chenyu Zhang",
        "Junjie Song",
        "Siqi Chen",
        "Sun Yin",
        "Zihan Wang",
        "Lingming Zeng",
        "Yuji Cao",
        "Junming Jiao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T03:00:56+00:00",
          "link": "https://arxiv.org/abs/2507.06502v1",
          "size": "1289kb",
          "version": "v1"
        }
      ],
      "title": "MoFE-Time: Mixture of Frequency Domain Experts for Time-Series Forecasting Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06502",
        "HTML": "https://arxiv.org/html/2507.06502v1",
        "PDF": "https://arxiv.org/pdf/2507.06502"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper proposes a new time series forecasting model using LLMs, it briefly mentions the creation of a proprietary dataset but does not focus on data processing methods for LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06530",
      "abstract": "Helping deaf and hard-of-hearing people communicate more easily is the main goal of Automatic Sign Language Translation. Although most past research has focused on turning sign language into text, doing the reverse, turning spoken English into sign language animations, has been largely overlooked. That's because it involves multiple steps, such as understanding speech, translating it into sign-friendly grammar, and generating natural human motion. In this work, we introduce a complete pipeline that converts English speech into smooth, realistic 3D sign language animations. Our system starts with Whisper to translate spoken English into text. Then, we use a MarianMT machine translation model to translate that text into American Sign Language (ASL) gloss, a simplified version of sign language that captures meaning without grammar. This model performs well, reaching BLEU scores of 0.7714 and 0.8923. To make the gloss translation more accurate, we also use word embeddings such as Word2Vec and FastText to understand word meanings. Finally, we animate the translated gloss using a 3D keypoint-based motion system trained on Sign3D-WLASL, a dataset we created by extracting body, hand, and face key points from real ASL videos in the WLASL dataset. To support the gloss translation stage, we also built a new dataset called BookGlossCorpus-CG, which turns everyday English sentences from the BookCorpus dataset into ASL gloss using grammar rules. Our system stitches everything together by smoothly interpolating between signs to create natural, continuous animations. Unlike previous works like How2Sign and Phoenix-2014T that focus on recognition or use only one type of data, our pipeline brings together audio, text, and motion in a single framework that goes all the way from spoken English to lifelike 3D sign language animation.",
      "authors": [
        "Kazi Mahathir Rahman",
        "Naveed Imtiaz Nafis",
        "Md. Farhan Sadik",
        "Mohammad Al Rafi",
        "Mehedi Hasan Shahed"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T04:13:49+00:00",
          "link": "https://arxiv.org/abs/2507.06530v1",
          "size": "1163kb",
          "version": "v1"
        }
      ],
      "title": "Speak2Sign3D: A Multi-modal Pipeline for English Speech to American Sign Language Animation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06530",
        "HTML": "https://arxiv.org/html/2507.06530v1",
        "PDF": "https://arxiv.org/pdf/2507.06530"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces a complete pipeline for processing data from English speech to ASL animations, involving the creation of datasets with detailed data processing steps, significant for LLM training data preparation and generation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06732",
      "abstract": "Sign Language Translation (SLT) attempts to convert sign language videos into spoken sentences. However, many existing methods struggle with the disparity between visual and textual representations during end-to-end learning. Gloss-based approaches help to bridge this gap by leveraging structured linguistic information. While, gloss-free methods offer greater flexibility and remove the burden of annotation, they require effective alignment strategies. Recent advances in Large Language Models (LLMs) have enabled gloss-free SLT by generating text-like representations from sign videos. In this work, we introduce a novel hierarchical pre-training strategy inspired by the structure of sign language, incorporating pseudo-glosses and contrastive video-language alignment. Our method hierarchically extracts features at frame, segment, and video levels, aligning them with pseudo-glosses and the spoken sentence to enhance translation quality. Experiments demonstrate that our approach improves BLEU-4 and ROUGE scores while maintaining efficiency.",
      "authors": [
        "Sobhan Asasi",
        "Mohamed Ilyes Lakhal",
        "Richard Bowden"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T10:45:50+00:00",
          "link": "https://arxiv.org/abs/2507.06732v1",
          "size": "1550kb",
          "version": "v1"
        }
      ],
      "title": "Hierarchical Feature Alignment for Gloss-Free Sign Language Translation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06732",
        "HTML": "https://arxiv.org/html/2507.06732v1",
        "PDF": "https://arxiv.org/pdf/2507.06732"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on Sign Language Translation using large language models but does not discuss training data processing or engineering aspects for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06960",
      "abstract": "A common class of algorithms for informative path planning (IPP) follows boustrophedon (\"as the ox turns\") patterns, which aim to achieve uniform area coverage. However, IPP is often applied in scenarios where anomalies, such as plant diseases, pollution, or hurricane damage, appear in clusters. In such cases, prioritizing the exploration of anomalous regions over uniform coverage is beneficial. This work introduces a class of algorithms referred to as bounom\\=odes (\"as the ox grazes\"), which alternates between uniform boustrophedon sampling and targeted exploration of detected anomaly clusters. While uniform sampling can be designed using geometric principles, close exploration of clusters depends on the spatial distribution of anomalies and must be learned. In our implementation, the close exploration behavior is learned using deep reinforcement learning algorithms. Experimental evaluations demonstrate that the proposed approach outperforms several established baselines.",
      "authors": [
        "Samuel Matloob",
        "Ayan Dutta",
        "O. Patrick Kreidl",
        "Swapnonel Roy and Ladislau B\\\"ol\\\"oni"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T15:46:22+00:00",
          "link": "https://arxiv.org/abs/2507.06960v1",
          "size": "269kb",
          "version": "v1"
        }
      ],
      "title": "Bounomodes: the grazing ox algorithm for exploration of clustered anomalies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06960",
        "HTML": "https://arxiv.org/html/2507.06960v1",
        "PDF": "https://arxiv.org/pdf/2507.06960"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on informative path planning algorithms for anomaly exploration, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.00254",
      "abstract": "In this work, we propose a lightweight decoder based solely on belief-propagation (BP), augmented with a speculative post-processing strategy inspired by classical Chase decoding. Our method identifies unreliable bits via BP oscillation statistics, generates a set of modified test patterns, and decodes them in parallel using low-iteration BP. We demonstrate that our approach can achieve logical error rates comparable to or even better than BP-OSD, but has lower latency over its parallelization for a variety of bivariate bicycle codes, which significantly reduces decoding complexity.",
      "authors": [
        "Ming Wang",
        "Ang Li",
        "and Frank Mueller"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T20:47:28+00:00",
          "link": "https://arxiv.org/abs/2507.00254v1",
          "size": "164kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T23:52:22+00:00",
          "link": "https://arxiv.org/abs/2507.00254v2",
          "size": "164kb",
          "version": "v2"
        }
      ],
      "title": "Fully Parallelized BP Decoding for Quantum LDPC Codes Can Outperform BP-OSD",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.00254",
        "HTML": "https://arxiv.org/html/2507.00254v2",
        "PDF": "https://arxiv.org/pdf/2507.00254"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on quantum LDPC code decoding improvements using belief-propagation, with no mention of LLM training data processing or related data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06813",
      "abstract": "Federated Learning (FL) enables collaborative model training across distributed clients while preserving data privacy. While existing approaches for aggregating client-specific classification heads and adapted backbone parameters require architectural modifications or loss function changes, our method uniquely leverages intrinsic training signals already available during standard optimization. We present LIVAR (Layer Importance and VARiance-based merging), which introduces: i) a variance-weighted classifier aggregation scheme using naturally emergent feature statistics, and ii) an explainability-driven LoRA merging technique based on SHAP analysis of existing update parameter patterns. Without any architectural overhead, LIVAR achieves state-of-the-art performance on multiple benchmarks while maintaining seamless integration with existing FL methods. This work demonstrates that effective model merging can be achieved solely through existing training signals, establishing a new paradigm for efficient federated model aggregation. The code will be made publicly available upon acceptance.",
      "authors": [
        "Cosimo Fiorini",
        "Matteo Mosconi",
        "Pietro Buzzega",
        "Riccardo Salami",
        "Simone Calderara"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T13:03:23+00:00",
          "link": "https://arxiv.org/abs/2507.06813v1",
          "size": "2891kb",
          "version": "v1"
        }
      ],
      "title": "Intrinsic Training Signals for Federated Learning Aggregation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06813",
        "HTML": "https://arxiv.org/html/2507.06813v1",
        "PDF": "https://arxiv.org/pdf/2507.06813"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses federated learning and model aggregation techniques without mentioning or focusing on LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2404.14384",
      "abstract": "As quantum technology advances, the efficient design of quantum circuits has become an important area of research. This paper provides an introduction to the MCT quantum circuit design problem for reversible Boolean functions with the necessary background in quantum computing to comprehend the problem. While this is a well-studied problem, optimization models that minimize the true objective have only been explored recently. This paper introduces a new optimization model and symmetry-breaking constraints that improve solving time by up to two orders of magnitude compared to earlier work when a Constraint Programming solver is used. Experiments with up to seven qubits and using up to 15 quantum gates result in several new best-known circuits, obtained by any method, for well-known benchmarks. Several in-depth analyses are presented to validate the effectiveness of the symmetry-breaking constraints from multiple perspectives. Finally, an extensive comparison with other approaches shows that optimization models may require more time but can provide superior circuits with optimality guarantees.",
      "authors": [
        "Jihye Jung",
        "Kevin Dalmeijer",
        "Pascal Van Hentenryck"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Emerging Technologies (cs.ET)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-22T17:37:17+00:00",
          "link": "https://arxiv.org/abs/2404.14384v1",
          "size": "2523kb",
          "version": "v1"
        },
        {
          "date": "2024-07-04T19:37:44+00:00",
          "link": "https://arxiv.org/abs/2404.14384v2",
          "size": "2901kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T12:23:38+00:00",
          "link": "https://arxiv.org/abs/2404.14384v3",
          "size": "3044kb",
          "version": "v3"
        }
      ],
      "title": "Optimizing Multiple-Control Toffoli Quantum Circuit Design with Constraint Programming",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.14384",
        "PDF": "https://arxiv.org/pdf/2404.14384"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about optimizing quantum circuits using constraint programming and does not discuss LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.15370",
      "abstract": "Text-based foundation models have become an important part of scientific discovery, with molecular foundation models accelerating advancements in material science and molecular design.However, existing models are constrained by closed-vocabulary tokenizers that capture only a fraction of molecular space. In this work, we systematically evaluate 34 tokenizers, including 19 chemistry-specific ones, and reveal significant gaps in their coverage of the SMILES molecular representation. To assess the impact of tokenizer choice, we introduce n-gram language models as a low-cost proxy and validate their effectiveness by pretraining and finetuning 18 RoBERTa-style encoders for molecular property prediction. To overcome the limitations of existing tokenizers, we propose two new tokenizers -- Smirk and Smirk-GPE -- with full coverage of the OpenSMILES specification. The proposed tokenizers systematically integrate nuclear, electronic, and geometric degrees of freedom; facilitating applications in pharmacology, agriculture, biology, and energy storage. Our results highlight the need for open-vocabulary modeling and chemically diverse benchmarks in cheminformatics.",
      "authors": [
        "Alexius Wadell",
        "Anoushka Bhutani",
        "Venkatasubramanian Viswanathan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Chemical Physics (physics.chem-ph)",
        "Biomolecules (q-bio.BM)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-19T02:36:04+00:00",
          "link": "https://arxiv.org/abs/2409.15370v1",
          "size": "425kb",
          "version": "v1"
        },
        {
          "date": "2025-02-07T18:36:17+00:00",
          "link": "https://arxiv.org/abs/2409.15370v2",
          "size": "462kb",
          "version": "v2"
        },
        {
          "date": "2025-07-08T21:38:03+00:00",
          "link": "https://arxiv.org/abs/2409.15370v3",
          "size": "547kb",
          "version": "v3"
        }
      ],
      "title": "Tokenization for Molecular Foundation Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.15370",
        "HTML": "https://arxiv.org/html/2409.15370v3",
        "PDF": "https://arxiv.org/pdf/2409.15370"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses tokenization for molecular models, aiming to improve data processing for molecular representation but does not primarily focus on LLM training data processing."
      },
      "tasks": [
        "Diversity",
        "Molecular Property Prediction",
        "molecular representation",
        "Property Prediction",
        "scientific discovery"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.12513",
      "abstract": "Auto-regressive Large Language Models (LLMs) demonstrate remarkable performance across different domains such as vision and language processing. However, due to sequential processing through a stack of transformer layers, autoregressive decoding faces significant computation/latency challenges, particularly in resource-constrained environments like mobile and edge devices. Existing approaches in literature that aim to improve latency via skipping layers have two distinct flavors - 1) Early exit, and 2) Input-agnostic heuristics where tokens exit at pre-determined layers irrespective of input sequence. Both the above strategies have limitations - the former cannot be applied to handle KV Caching necessary for speed-ups in modern framework and the latter does not capture the variation in layer importance across tasks or more generally, across input sequences. To address both limitations, we propose FiRST, an algorithm that reduces inference latency by using layer-specific routers to select a subset of transformer layers adaptively for each input sequence - the prompt (during the prefill stage) decides which layers will be skipped during decoding. FiRST preserves compatibility with KV caching enabling faster inference while being quality-aware. FiRST is model-agnostic and can be easily enabled on any pre-trained LLM. Our approach reveals that input adaptivity is critical - indeed, different task-specific middle layers play a crucial role in evolving hidden representations depending on tasks. Extensive experiments show that FiRST significantly reduces latency while outperforming other layer selection strategies in quality metics. It retains competitive performance to base model (without layer skipping) and in some cases, even improves upon it. FiRST is thus a promising and efficient solution for LLM deployment in low-resource environments.",
      "authors": [
        "Akriti Jain",
        "Saransh Sharma",
        "Koyel Mukherjee",
        "Soumyabrata Pal"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-16T12:45:35+00:00",
          "link": "https://arxiv.org/abs/2410.12513v1",
          "size": "1326kb",
          "version": "v1"
        },
        {
          "date": "2024-12-17T09:11:47+00:00",
          "link": "https://arxiv.org/abs/2410.12513v2",
          "size": "1693kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T04:43:59+00:00",
          "link": "https://arxiv.org/abs/2410.12513v3",
          "size": "527kb",
          "version": "v3"
        }
      ],
      "title": "FiRST: Finetuning Router-Selective Transformers for Input-Adaptive Latency Reduction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.12513",
        "HTML": "https://arxiv.org/html/2410.12513v3",
        "PDF": "https://arxiv.org/pdf/2410.12513"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "Focuses on reducing inference latency in LLMs by implementing a layer selection strategy during processing, but does not primarily contribute to or modify LLM training data."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2506.14774",
      "abstract": "Clinical decision-making is inherently complex, often influenced by cognitive biases, incomplete information, and case ambiguity. Large Language Models (LLMs) have shown promise as tools for supporting clinical decision-making, yet their typical one-shot or limited-interaction usage may overlook the complexities of real-world medical practice. In this work, we propose a hybrid human-AI framework, MedSyn, where physicians and LLMs engage in multi-step, interactive dialogues to refine diagnoses and treatment decisions. Unlike static decision-support tools, MedSyn enables dynamic exchanges, allowing physicians to challenge LLM suggestions while the LLM highlights alternative perspectives. Through simulated physician-LLM interactions, we assess the potential of open-source LLMs as physician assistants. Results show open-source LLMs are promising as physician assistants in the real world. Future work will involve real physician interactions to further validate MedSyn's usefulness in diagnostic accuracy and patient outcomes.",
      "authors": [
        "Burcu Sayin and Ipek Baris Schlicht and Ngoc Vo Hong and Sara Allievi and Jacopo Staiano and Pasquale Minervini and Andrea Passerini"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-07T09:37:18+00:00",
          "link": "https://arxiv.org/abs/2506.14774v1",
          "size": "1133kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T21:35:13+00:00",
          "link": "https://arxiv.org/abs/2506.14774v2",
          "size": "360kb",
          "version": "v2"
        }
      ],
      "title": "MedSyn: Enhancing Diagnostics with Human-AI Collaboration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.14774",
        "PDF": "https://arxiv.org/pdf/2506.14774"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study proposes a framework for human-AI collaboration in clinical decision-making using interactions with LLMs. It does not focus on the processing of LLM training data itself."
      },
      "tasks": [
        "Decision Making",
        "Diagnostic"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.15212",
      "abstract": "Scaling has not yet been convincingly demonstrated for pure self-supervised learning from video. However, prior work has focused evaluations on semantic-related tasks $\\unicode{x2013}$ action classification, ImageNet classification, etc. In this paper we focus on evaluating self-supervised learning on non-semantic vision tasks that are more spatial (3D) and temporal (+1D = 4D), such as camera pose estimation, point and object tracking, and depth estimation. We show that by learning from very large video datasets, masked auto-encoding (MAE) with transformer video models actually scales, consistently improving performance on these 4D tasks, as model size increases from 20M all the way to the largest by far reported self-supervised video model $\\unicode{x2013}$ 22B parameters. Rigorous apples-to-apples comparison with many recent image and video models demonstrates the benefits of scaling 4D representations. Pretrained models are available at https://github.com/google-deepmind/representations4d .",
      "authors": [
        "Jo\\~ao Carreira",
        "Dilara Gokay",
        "Michael King",
        "Chuhan Zhang",
        "Ignacio Rocco",
        "Aravindh Mahendran",
        "Thomas Albert Keck",
        "Joseph Heyward",
        "Skanda Koppula",
        "Etienne Pot",
        "Goker Erdogan",
        "Yana Hasson",
        "Yi Yang",
        "Klaus Greff",
        "Guillaume Le Moing",
        "Sjoerd van Steenkiste",
        "Daniel Zoran",
        "Drew A. Hudson",
        "Pedro V\\'elez",
        "Luisa Polan\\'ia",
        "Luke Friedman",
        "Chris Duvarney",
        "Ross Goroshin",
        "Kelsey Allen",
        "Jacob Walker",
        "Rishabh Kabra",
        "Eric Aboussouan",
        "Jennifer Sun",
        "Thomas Kipf",
        "Carl Doersch",
        "Viorica P\\u{a}tr\\u{a}ucean",
        "Dima Damen",
        "Pauline Luc",
        "Mehdi S. M. Sajjadi",
        "Andrew Zisserman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-19T18:59:51+00:00",
          "link": "https://arxiv.org/abs/2412.15212v1",
          "size": "12269kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T16:58:07+00:00",
          "link": "https://arxiv.org/abs/2412.15212v2",
          "size": "10507kb",
          "version": "v2"
        }
      ],
      "title": "Scaling 4D Representations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.15212",
        "HTML": "https://arxiv.org/html/2412.15212v2",
        "PDF": "https://arxiv.org/pdf/2412.15212"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper evaluates self-supervised learning using large video datasets for spatial and temporal tasks without addressing LLM training data processing."
      },
      "tasks": [
        "Action Classification",
        "Camera Pose Estimation",
        "Depth Estimation",
        "Object Tracking",
        "Pose Estimation",
        "Self-Supervised Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06273",
      "abstract": "The increasing complexity of cardiovascular diseases and limitations in traditional healing methods mandate the invention of new drug delivery systems that assure targeted, effective, and regulated treatments, contributing directly to UN SDGs 3 and 9, thereby encouraging the utilization of sustainable medical technologies in healthcare. This study investigates the flow of a Casson-Maxwell nanofluid through a stenosed arterial domain. The quantities, such as skin friction and heat transfer rate, are analysed in detail. The Casson-Maxwell fluid shows a lower velocity profile than the Casson fluids, which indicates the improved residence time for efficient drug delivery. The heat transfer rate shows an increase with higher volume fractions of copper and aluminium oxide nanoparticles and a decrease with higher volume fractions of silver nanoparticles. The skin friction coefficient decreases by 219% with a unit increase in the Maxwell parameter, whereas it increases by 66.1% with a unit rise in the Casson parameter. This work supports SDGs 4 and 17 by fostering interdisciplinary learning and collaboration in fluid dynamics and healthcare innovation. Additionally, the rate of heat flow was forecasted (with an overall R-value of 0.99457) using the Levenberg-Marquardt backpropagation training scheme under the influence of magneto-radiative, linear heat source and Casson-Maxwell parameters along with the tri-metallic nanoparticle volume fractions. It is also observed that the drag coefficient is most sensitive to the changes in the Maxwell parameter.",
      "authors": [
        "S P Shivakumar",
        "Gunisetty Ramasekhar",
        "P Nimmy",
        "Sujesh Areekara",
        "L Thanuja",
        "T V Smitha",
        "S Devanathan",
        "Ganesh R Naik",
        "K V Nagaraja"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Medical Physics (physics.med-ph)",
        "Artificial Intelligence (cs.AI)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)",
        "Biological Physics (physics.bio-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T08:04:40+00:00",
          "link": "https://arxiv.org/abs/2507.06273v1",
          "size": "3984kb",
          "version": "v1"
        }
      ],
      "title": "Magneto-radiative modelling and artificial neural network optimization of biofluid flow in a stenosed arterial domain",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06273",
        "PDF": "https://arxiv.org/pdf/2507.06273"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study investigates biofluid flow and models related to cardiovascular diseases, without relevance to LLM training data processing or dataset preparation techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06396",
      "abstract": "Prompt engineering for LLMs remains complex, with existing frameworks either hiding complexity behind restrictive APIs or providing inflexible canned patterns that resist customization -- making sophisticated agentic programming challenging. We present the Prompt Declaration Language (PDL), a novel approach to prompt representation that tackles this fundamental complexity by bringing prompts to the forefront, enabling manual and automatic prompt tuning while capturing the composition of LLM calls together with rule-based code and external tools. By abstracting away the plumbing for such compositions, PDL aims at improving programmer productivity while providing a declarative representation that is amenable to optimization. This paper demonstrates PDL's utility through a real-world case study of a compliance agent. Tuning the prompting pattern of this agent yielded up to 4x performance improvement compared to using a canned agent and prompt pattern.",
      "authors": [
        "Mandana Vaziri and Louis Mandel and Yuji Watanabe and Hirokuni Kitahara and Martin Hirzel and Anca Sailer"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Programming Languages (cs.PL)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T21:03:22+00:00",
          "link": "https://arxiv.org/abs/2507.06396v1",
          "size": "439kb",
          "version": "v1"
        }
      ],
      "title": "Representing Prompting Patterns with PDL: Compliance Agent Case Study",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06396",
        "HTML": "https://arxiv.org/html/2507.06396v1",
        "PDF": "https://arxiv.org/pdf/2507.06396"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses prompt engineering and tuning but does not focus on LLM training data processing, collection, or preparation, which is central to the task. Instead, it emphasizes prompt representation and optimization in LLM usage."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06976",
      "abstract": "While automated vehicles hold the potential to significantly reduce traffic accidents, their perception systems remain vulnerable to sensor degradation caused by adverse weather and environmental occlusions. Collective perception, which enables vehicles to share information, offers a promising approach to overcoming these limitations. However, to this date collective perception in adverse weather is mostly unstudied. Therefore, we conduct the first study of LiDAR-based collective perception under diverse weather conditions and present a novel multi-task architecture for LiDAR-based collective perception under adverse weather. Adverse weather conditions can not only degrade perception capabilities, but also negatively affect bandwidth requirements and latency due to the introduced noise that is also transmitted and processed. Denoising prior to communication can effectively mitigate these issues. Therefore, we propose DenoiseCP-Net, a novel multi-task architecture for LiDAR-based collective perception under adverse weather conditions. DenoiseCP-Net integrates voxel-level noise filtering and object detection into a unified sparse convolution backbone, eliminating redundant computations associated with two-stage pipelines. This design not only reduces inference latency and computational cost but also minimizes communication overhead by removing non-informative noise. We extended the well-known OPV2V dataset by simulating rain, snow, and fog using our realistic weather simulation models. We demonstrate that DenoiseCP-Net achieves near-perfect denoising accuracy in adverse weather, reduces the bandwidth requirements by up to 23.6% while maintaining the same detection accuracy and reducing the inference latency for cooperative vehicles.",
      "authors": [
        "Sven Teufel",
        "Dominique Mayer",
        "J\\\"org Gamerdinger and Oliver Bringmann"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T16:05:25+00:00",
          "link": "https://arxiv.org/abs/2507.06976v1",
          "size": "9132kb",
          "version": "v1"
        }
      ],
      "title": "DenoiseCP-Net: Efficient Collective Perception in Adverse Weather via Joint LiDAR-Based 3D Object Detection and Denoising",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06976",
        "HTML": "https://arxiv.org/html/2507.06976v1",
        "PDF": "https://arxiv.org/pdf/2507.06976"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a LiDAR-based collective perception system for automated vehicles and does not address LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2402.05371",
      "abstract": "Recent studies have demonstrated the immense potential of exploiting muscle actuator morphology for natural and robust movement -- in simulation. A validation on real robotic hardware is yet missing. In this study, we emulate muscle actuator properties on hardware in real-time, taking advantage of modern and affordable electric motors. We demonstrate that our setup can emulate a simplified muscle model on a real robot while being controlled by a learned policy. We improve upon an existing muscle model by deriving a damping rule that ensures that the model is not only performant and stable but also tuneable for the real hardware. Our policies are trained by reinforcement learning entirely in simulation, where we show that previously reported benefits of muscles extend to the case of quadruped locomotion and hopping: the learned policies are more robust and exhibit more regular gaits. Finally, we confirm that the learned policies can be executed on real hardware and show that sim-to-real transfer with real-time emulated muscles on a quadruped robot is possible. These results show that artificial muscles can be highly beneficial actuators for future generations of robust legged robots.",
      "authors": [
        "Pierre Schumacher",
        "Lorenz Krause",
        "Jan Schneider",
        "Dieter B\\\"uchler",
        "Georg Martius",
        "Daniel Haeufle"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-08T03:01:51+00:00",
          "link": "https://arxiv.org/abs/2402.05371v1",
          "size": "4006kb",
          "version": "v1"
        }
      ],
      "title": "Learning to Control Emulated Muscles in Real Robots: Towards Exploiting Bio-Inspired Actuator Morphology",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.05371",
        "HTML": "https://arxiv.org/html/2402.05371",
        "PDF": "https://arxiv.org/pdf/2402.05371"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research pertains to muscle actuator modeling and reinforcement learning for robot control, without addressing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06380",
      "abstract": "Complex neural networks require substantial memory to store a large number of synaptic weights. This work introduces WINGs (Automatic Weight Generator for Secure and Storage-Efficient Deep Learning Models), a novel framework that dynamically generates layer weights in a fully connected neural network (FC) and compresses the weights in convolutional neural networks (CNNs) during inference, significantly reducing memory requirements without sacrificing accuracy. WINGs framework uses principal component analysis (PCA) for dimensionality reduction and lightweight support vector regression (SVR) models to predict layer weights in the FC networks, removing the need for storing full-weight matrices and achieving substantial memory savings. It also preferentially compresses the weights in low-sensitivity layers of CNNs using PCA and SVR with sensitivity analysis. The sensitivity-aware design also offers an added level of security, as any bit-flip attack with weights in compressed layers has an amplified and readily detectable effect on accuracy. WINGs achieves 53x compression for the FC layers and 28x for AlexNet with MNIST dataset, and 18x for Alexnet with CIFAR-10 dataset with 1-2% accuracy loss. This significant reduction in memory results in higher throughput and lower energy for DNN inference, making it attractive for resource-constrained edge applications.",
      "authors": [
        "Habibur Rahaman",
        "Atri Chatterjee",
        "Swarup Bhunia"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T20:33:02+00:00",
          "link": "https://arxiv.org/abs/2507.06380v1",
          "size": "8503kb",
          "version": "v1"
        }
      ],
      "title": "Secure and Storage-Efficient Deep Learning Models for Edge AI Using Automatic Weight Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06380",
        "HTML": "https://arxiv.org/html/2507.06380v1",
        "PDF": "https://arxiv.org/pdf/2507.06380"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes a method for weight generation and compression for deep learning models in edge AI, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06482",
      "abstract": "Federated learning aims at training models collaboratively across participants while protecting privacy. However, one major challenge for this paradigm is the data heterogeneity issue, where biased data preferences across multiple clients, harming the model's convergence and performance. In this paper, we first introduce powerful diffusion models into the federated learning paradigm and show that diffusion representations are effective steers during federated training. To explore the possibility of using diffusion representations in handling data heterogeneity, we propose a novel diffusion-inspired Federated paradigm with Diffusion Representation Collaboration, termed FedDifRC, leveraging meaningful guidance of diffusion models to mitigate data heterogeneity. The key idea is to construct text-driven diffusion contrasting and noise-driven diffusion regularization, aiming to provide abundant class-related semantic information and consistent convergence signals. On the one hand, we exploit the conditional feedback from the diffusion model for different text prompts to build a text-driven contrastive learning strategy. On the other hand, we introduce a noise-driven consistency regularization to align local instances with diffusion denoising representations, constraining the optimization region in the feature space. In addition, FedDifRC can be extended to a self-supervised scheme without relying on any labeled data. We also provide a theoretical analysis for FedDifRC to ensure convergence under non-convex objectives. The experiments on different scenarios validate the effectiveness of FedDifRC and the efficiency of crucial components.",
      "authors": [
        "Huan Wang",
        "Haoran Li",
        "Huaming Chen",
        "Jun Yan",
        "Jiahua Shi",
        "Jun Shen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T01:57:57+00:00",
          "link": "https://arxiv.org/abs/2507.06482v1",
          "size": "18230kb",
          "version": "v1"
        }
      ],
      "title": "FedDifRC: Unlocking the Potential of Text-to-Image Diffusion Models in Heterogeneous Federated Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06482",
        "HTML": "https://arxiv.org/html/2507.06482v1",
        "PDF": "https://arxiv.org/pdf/2507.06482"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses the use of diffusion models in federated learning but does not focus on any substantial contributions to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06731",
      "abstract": "We recently introduced a scale of kernel-based greedy schemes for approximating the solutions of elliptic boundary value problems. The procedure is based on a generalized interpolation framework in reproducing kernel Hilbert spaces and was coined PDE-$\\beta$-greedy procedure, where the parameter $\\beta \\geq 0$ is used in a greedy selection criterion and steers the degree of function adaptivity. Algebraic convergence rates have been obtained for Sobolev-space kernels and solutions of finite smoothness. We now report a result of exponential convergence rates for the case of infinitely smooth kernels and solutions. We furthermore extend the approximation scheme to the case of parametric PDEs by the use of state-parameter product kernels. In the surrogate modelling context, the resulting approach can be interpreted as an a priori model reduction approach, as no solution snapshots need to be precomputed. Numerical results show the efficiency of the approximation procedure for problems which occur as challenges for other parametric MOR procedures: non-affine geometry parametrizations, moving sources or high-dimensional domains.",
      "authors": [
        "Bernard Haasdonk",
        "Gabriele Santin",
        "Tizian Wenzel"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T10:45:21+00:00",
          "link": "https://arxiv.org/abs/2507.06731v1",
          "size": "1929kb",
          "version": "v1"
        }
      ],
      "title": "Kernel-based Greedy Approximation of Parametric Elliptic Boundary Value Problems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06731",
        "HTML": "https://arxiv.org/html/2507.06731v1",
        "PDF": "https://arxiv.org/pdf/2507.06731"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses kernel-based greedy approximation for solving elliptic boundary value problems, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06867",
      "abstract": "Many real-world classification problems, such as plant identification, have extremely long-tailed class distributions. In order for prediction sets to be useful in such settings, they should (i) provide good class-conditional coverage, ensuring that rare classes are not systematically omitted from the prediction sets, and (ii) be a reasonable size, allowing users to easily verify candidate labels. Unfortunately, existing conformal prediction methods, when applied to the long-tailed setting, force practitioners to make a binary choice between small sets with poor class-conditional coverage or sets with very good class-conditional coverage but that are extremely large. We propose methods with guaranteed marginal coverage that smoothly trade off between set size and class-conditional coverage. First, we propose a conformal score function, prevalence-adjusted softmax, that targets a relaxed notion of class-conditional coverage called macro-coverage. Second, we propose a label-weighted conformal prediction method that allows us to interpolate between marginal and class-conditional conformal prediction. We demonstrate our methods on Pl@ntNet and iNaturalist, two long-tailed image datasets with 1,081 and 8,142 classes, respectively.",
      "authors": [
        "Tiffany Ding",
        "Jean-Baptiste Fermanian",
        "Joseph Salmon"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)",
        "Methodology (stat.ME)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T14:08:50+00:00",
          "link": "https://arxiv.org/abs/2507.06867v1",
          "size": "6034kb",
          "version": "v1"
        }
      ],
      "title": "Conformal Prediction for Long-Tailed Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06867",
        "HTML": "https://arxiv.org/html/2507.06867v1",
        "PDF": "https://arxiv.org/pdf/2507.06867"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses conformal prediction methods for classification problems with long-tailed distributions, without discussing LLM training data processing or enhancements."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06907",
      "abstract": "Autonomous driving is rapidly advancing as a key application of machine learning, yet ensuring the safety of these systems remains a critical challenge. Traffic sign recognition, an essential component of autonomous vehicles, is particularly vulnerable to adversarial attacks that can compromise driving safety. In this paper, we propose an N-version machine learning (NVML) framework that integrates a safety-aware weighted soft voting mechanism. Our approach utilizes Failure Mode and Effects Analysis (FMEA) to assess potential safety risks and assign dynamic, safety-aware weights to the ensemble outputs. We evaluate the robustness of three-version NVML systems employing various voting mechanisms against adversarial samples generated using the Fast Gradient Sign Method (FGSM) and Projected Gradient Descent (PGD) attacks. Experimental results demonstrate that our NVML approach significantly enhances the robustness and safety of traffic sign recognition systems under adversarial conditions.",
      "authors": [
        "Linyun Gao",
        "Qiang Wen",
        "Fumio Machida"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T14:46:31+00:00",
          "link": "https://arxiv.org/abs/2507.06907v1",
          "size": "42kb",
          "version": "v1"
        }
      ],
      "title": "Robust and Safe Traffic Sign Recognition using N-version with Weighted Voting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06907",
        "HTML": "https://arxiv.org/html/2507.06907v1",
        "PDF": "https://arxiv.org/pdf/2507.06907"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is centered on improving the robustness and safety of traffic sign recognition systems, which does not relate to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.10422",
      "abstract": "Answering natural language (NL) questions about tables, known as Tabular Question Answering (TQA), is crucial because it allows users to quickly and efficiently extract meaningful insights from structured data, effectively bridging the gap between human language and machine-readable formats. Many of these tables are derived from web sources or real-world scenarios, which require meticulous data preparation (or data prep) to ensure accurate responses. However, preparing such tables for NL questions introduces new requirements that extend beyond traditional data preparation. This question-ware data preparation involves specific tasks such as column derivation and filtering tailored to particular questions, as well as question-aware value normalization or conversion, highlighting the need for a more nuanced approach in this context. Because each of the above tasks is unique, a single model (or agent) may not perform effectively across all scenarios. In this paper, we propose AutoPrep, a large language model (LLM)-based multiagent framework that leverages the strengths of multiple agents, each specialized in a certain type of data prep, ensuring more accurate and contextually relevant responses. Given an NL question over a table, AutoPrep performs data prep through three key components. Planner: Determines a logical plan, outlining a sequence of high-level operations. Programmer: Translates this logical plan into a physical plan by generating the corresponding low-level code. Executor: Executes the generated code to process the table. To support this multi-agent framework, we design a novel Chain-ofClauses reasoning mechanism for high-level operation suggestion, and a tool-augmented method for low-level code generation.",
      "authors": [
        "Meihao Fan and Ju Fan and Nan Tang and Lei Cao and Guoliang Li and Xiaoyong Du"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-10T11:03:49+00:00",
          "link": "https://arxiv.org/abs/2412.10422v1",
          "size": "3435kb",
          "version": "v1"
        },
        {
          "date": "2025-01-02T01:11:46+00:00",
          "link": "https://arxiv.org/abs/2412.10422v2",
          "size": "5434kb",
          "version": "v2"
        },
        {
          "date": "2025-05-02T00:11:48+00:00",
          "link": "https://arxiv.org/abs/2412.10422v3",
          "size": "6811kb",
          "version": "v3"
        },
        {
          "date": "2025-07-09T05:24:56+00:00",
          "link": "https://arxiv.org/abs/2412.10422v4",
          "size": "6814kb",
          "version": "v4"
        }
      ],
      "title": "AutoPrep: Natural Language Question-Aware Data Preparation with a Multi-Agent Framework",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.10422",
        "HTML": "https://arxiv.org/html/2412.10422v4",
        "PDF": "https://arxiv.org/pdf/2412.10422"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "AutoPrep involves a novel, LLM-based multi-agent framework for data preparation that is specifically targeted at ensuring contextually relevant responses, outlining clear data processing tasks valuable for training data enhancement."
      },
      "tasks": [
        "Code Generation",
        "Large Language Model",
        "Question Answering"
      ],
      "repo_urls": [
        "https://github.com/fmh1art/autoprep"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.11647",
      "abstract": "Camera control has been actively studied in text or image conditioned video generation tasks. However, altering camera trajectories of a given video remains under-explored, despite its importance in the field of video creation. It is non-trivial due to the extra constraints of maintaining multiple-frame appearance and dynamic synchronization. To address this, we present ReCamMaster, a camera-controlled generative video re-rendering framework that reproduces the dynamic scene of an input video at novel camera trajectories. The core innovation lies in harnessing the generative capabilities of pre-trained text-to-video models through a simple yet powerful video conditioning mechanism--its capability is often overlooked in current research. To overcome the scarcity of qualified training data, we construct a comprehensive multi-camera synchronized video dataset using Unreal Engine 5, which is carefully curated to follow real-world filming characteristics, covering diverse scenes and camera movements. It helps the model generalize to in-the-wild videos. Lastly, we further improve the robustness to diverse inputs through a meticulously designed training strategy. Extensive experiments show that our method substantially outperforms existing state-of-the-art approaches. Our method also finds promising applications in video stabilization, super-resolution, and outpainting. Our code and dataset are publicly available at: https://github.com/KwaiVGI/ReCamMaster.",
      "authors": [
        "Jianhong Bai",
        "Menghan Xia",
        "Xiao Fu",
        "Xintao Wang",
        "Lianrui Mu",
        "Jinwen Cao",
        "Zuozhu Liu",
        "Haoji Hu",
        "Xiang Bai",
        "Pengfei Wan",
        "Di Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-14T17:59:31+00:00",
          "link": "https://arxiv.org/abs/2503.11647v1",
          "size": "5324kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T08:09:06+00:00",
          "link": "https://arxiv.org/abs/2503.11647v2",
          "size": "5493kb",
          "version": "v2"
        }
      ],
      "title": "ReCamMaster: Camera-Controlled Generative Rendering from A Single Video",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.11647",
        "HTML": "https://arxiv.org/html/2503.11647v2",
        "PDF": "https://arxiv.org/pdf/2503.11647"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper describes the creation of a new dataset using Unreal Engine 5 for video generation tasks, detailing the data curation process. This is a core contribution to LLM training data processing as it involves dataset creation with clear data processing steps."
      },
      "datasets": [
        {
          "dataset_name": "KwaiVGI/MultiCamVideo-Dataset",
          "downloads": "1007",
          "likes": "16",
          "link": "https://huggingface.co/datasets/KwaiVGI/MultiCamVideo-Dataset"
        },
        {
          "dataset_name": "shubhamkalantri/MultiCamVideoTar",
          "downloads": "177",
          "likes": "0",
          "link": "https://huggingface.co/datasets/shubhamkalantri/MultiCamVideoTar"
        }
      ],
      "tasks": [
        "Super-Resolution",
        "Video Generation",
        "Video Stabilization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.00282",
      "abstract": "This paper presents a general framework for conducting efficient inference on parameters derived from unstructured data, which include text, images, audio, and video. Economists have long used unstructured data by first extracting low-dimensional structured features (e.g., the topic or sentiment of a text), since the raw data are too high-dimensional and uninterpretable to include directly in empirical analyses. The rise of deep neural networks has accelerated this practice by greatly reducing the costs of extracting structured data at scale, but neural networks do not make generically unbiased predictions. This potentially propagates bias to the downstream estimators that incorporate imputed structured data, and the availability of different off-the-shelf neural networks with different biases moreover raises p-hacking concerns. To address these challenges, we reframe inference with unstructured data as a problem of missing structured data, where structured variables are imputed from high-dimensional unstructured inputs. This perspective allows us to apply classic results from semiparametric inference, leading to estimators that are valid, efficient, and robust. We formalize this approach with MAR-S, a framework that unifies and extends existing methods for debiased inference using machine learning predictions, connecting them to familiar problems such as causal inference. Within this framework, we develop robust and efficient estimators for both descriptive and causal estimands and address challenges like inference with aggregated and transformed missing structured data-a common scenario that is not covered by existing work. These methods-and the accompanying implementation package-provide economists with accessible tools for constructing unbiased estimators using unstructured data in a wide range of applications, as we demonstrate by re-analyzing several influential studies.",
      "authors": [
        "Jacob Carlson and Melissa Dell"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Econometrics (econ.EM)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-01T04:11:25+00:00",
          "link": "https://arxiv.org/abs/2505.00282v1",
          "size": "372kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T19:10:25+00:00",
          "link": "https://arxiv.org/abs/2505.00282v2",
          "size": "373kb",
          "version": "v2"
        }
      ],
      "title": "A Unifying Framework for Robust and Efficient Inference with Unstructured Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.00282",
        "HTML": "https://arxiv.org/html/2505.00282v2",
        "PDF": "https://arxiv.org/pdf/2505.00282"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses a framework for inference with unstructured data, potentially including text. However, its focus is on inference and estimation methods rather than processing or handling training datasets specifically for LLMs."
      },
      "tasks": [
        "Causal Inference",
        "Descriptive"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.22637",
      "abstract": "The recent introduction of diffusion models in dataset distillation has shown promising potential in creating compact surrogate datasets for large, high-resolution target datasets, offering improved efficiency and performance over traditional bi-level/uni-level optimization methods. However, current diffusion-based dataset distillation approaches overlook the evaluation process and exhibit two critical inconsistencies in the distillation process: (1) Objective Inconsistency, where the distillation process diverges from the evaluation objective, and (2) Condition Inconsistency, leading to mismatches between generated images and their corresponding conditions. To resolve these issues, we introduce Condition-aware Optimization with Objective-guided Sampling (CaO$_2$), a two-stage diffusion-based framework that aligns the distillation process with the evaluation objective. The first stage employs a probability-informed sample selection pipeline, while the second stage refines the corresponding latent representations to improve conditional likelihood. CaO$_2$ achieves state-of-the-art performance on ImageNet and its subsets, surpassing the best-performing baselines by an average of 2.3% accuracy.",
      "authors": [
        "Haoxuan Wang",
        "Zhenghao Zhao",
        "Junyi Wu",
        "Yuzhang Shang",
        "Gaowen Liu",
        "Yan Yan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T21:02:05+00:00",
          "link": "https://arxiv.org/abs/2506.22637v1",
          "size": "2593kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T03:21:09+00:00",
          "link": "https://arxiv.org/abs/2506.22637v2",
          "size": "2530kb",
          "version": "v2"
        }
      ],
      "title": "CaO$_2$: Rectifying Inconsistencies in Diffusion-Based Dataset Distillation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22637",
        "HTML": "https://arxiv.org/html/2506.22637v2",
        "PDF": "https://arxiv.org/pdf/2506.22637"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper discusses a method for improving dataset distillation using diffusion models to create compact surrogate datasets, addressing inconsistencies in current methods, making a significant contribution to data processing for model training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06715",
      "abstract": "Large language models (LLMs), including zero-shot and few-shot paradigms, have shown promising capabilities in clinical text generation. However, real-world applications face two key challenges: (1) patient data is highly unstructured, heterogeneous, and scattered across multiple note types and (2) clinical notes are often long and semantically dense, making naive prompting infeasible due to context length constraints and the risk of omitting clinically relevant information.\n  We introduce CLI-RAG (Clinically Informed Retrieval-Augmented Generation), a domain-specific framework for structured and clinically grounded text generation using LLMs. It incorporates a novel hierarchical chunking strategy that respects clinical document structure and introduces a task-specific dual-stage retrieval mechanism. The global stage identifies relevant note types using evidence-based queries, while the local stage extracts high-value content within those notes creating relevance at both document and section levels.\n  We apply the system to generate structured progress notes for individual hospital visits using 15 clinical note types from the MIMIC-III dataset. Experiments show that it preserves temporal and semantic alignment across visits, achieving an average alignment score of 87.7%, surpassing the 80.7% baseline from real clinician-authored notes. The generated outputs also demonstrate high consistency across LLMs, reinforcing deterministic behavior essential for reproducibility, reliability, and clinical trust.",
      "authors": [
        "Garapati Keerthana",
        "Manik Gupta"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T10:13:38+00:00",
          "link": "https://arxiv.org/abs/2507.06715v1",
          "size": "375kb",
          "version": "v1"
        }
      ],
      "title": "CLI-RAG: A Retrieval-Augmented Framework for Clinically Structured and Context Aware Text Generation with LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06715",
        "HTML": "https://arxiv.org/html/2507.06715v1",
        "PDF": "https://arxiv.org/pdf/2507.06715"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses a framework involving structured text generation using LLMs with a novel retrieval mechanism, but it focuses on application-specific text generation rather than core LLM training data processing contributions."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06740",
      "abstract": "This paper investigates an elliptic interface problem with discontinuous diffusion coefficients on unfitted meshes, employing the CutFEM method. The main contribution is the a posteriori error analysis based on equilibrated fluxes belonging to the immersed Raviart-Thomas space. We establish sharp reliability and local efficiency of a new error estimator, which includes both volume and interface terms, carefully tracking the dependence of the efficiency constant on the diffusion coefficients and the mesh/interface configuration. Numerical results highlight the robustness of the proposed approach.",
      "authors": [
        "Daniela Capatina and Aimene Gouasmi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T10:55:14+00:00",
          "link": "https://arxiv.org/abs/2507.06740v1",
          "size": "5575kb",
          "version": "v1"
        }
      ],
      "title": "Elliptic Interface Problem approximated by CutFEM: II. A posteriori error analysis based on equilibrated fluxes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06740",
        "HTML": "https://arxiv.org/html/2507.06740v1",
        "PDF": "https://arxiv.org/pdf/2507.06740"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with numerical methods for elliptic interface problems, focusing on error analysis, and has no relation to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07063",
      "abstract": "A linear stability analysis of an elastic surface immersed in a viscous fluid is presented. The coupled system is modeled using the method of regularized Stokeslets (MRS), a Lagrangian method for simulating fluid-structure interaction at zero Reynolds number. The linearized system is solved in a doubly periodic domain in a 3D fluid. The eigenvalues determine the theoretical critical time step for numerical stability for a forward Euler time integration, which are then verified numerically across several regularization functions, elastic models, and parameter choices. New doubly periodic regularized Stokeslets are presented, allowing for comparison of the stability properties of different regularization functions. The stability results for a common regularization function are approximated by a power law relating the regularization parameter and the surface discretization for two different elastic models. This relationship is empirically shown to hold in the different setting of a finite surface in a bulk fluid.",
      "authors": [
        "Dana Ferranti and Sarah D. Olson"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Fluid Dynamics (physics.flu-dyn)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T17:25:46+00:00",
          "link": "https://arxiv.org/abs/2507.07063v1",
          "size": "468kb",
          "version": "v1"
        }
      ],
      "title": "Analysis of the stability of an immersed elastic surface using the method of regularized Stokeslets",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07063",
        "HTML": "https://arxiv.org/html/2507.07063v1",
        "PDF": "https://arxiv.org/pdf/2507.07063"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses stability analysis of an elastic surface in fluid dynamics and does not relate to LLM training data processing or any related data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2312.02345",
      "abstract": "With the goal of understanding the visual concepts that CLIP associates with text prompts, we show that the latent space of CLIP can be visualized solely in terms of linear transformations on simple geometric primitives like straight lines and circles. Although existing approaches achieve this by sketch-synthesis-through-optimization, they do so on the space of higher order B\\'ezier curves, which exhibit a wastefully large set of structures that they can evolve into, as most of them are non-essential for generating meaningful sketches. We present CLIPDraw++, an algorithm that provides significantly better visualizations for CLIP text embeddings, using only simple primitive shapes like straight lines and circles. This constrains the set of possible outputs to linear transformations on these primitives, thereby exhibiting an inherently simpler mathematical form. The synthesis process of CLIPDraw++ can be tracked end-to-end, with each visual concept being expressed exclusively in terms of primitives. Project Page: https://clipdrawx.github.io/.",
      "authors": [
        "Nityanand Mathur",
        "Shyam Marjit",
        "Abhra Chaudhuri",
        "Anjan Dutta"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2023-12-04T21:11:42+00:00",
          "link": "https://arxiv.org/abs/2312.02345v1",
          "size": "47726kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T03:21:40+00:00",
          "link": "https://arxiv.org/abs/2312.02345v2",
          "size": "43792kb",
          "version": "v2"
        }
      ],
      "title": "CLIPDraw++: Text-to-Sketch Synthesis with Simple Primitives",
      "links": {
        "Abstract": "https://arxiv.org/abs/2312.02345",
        "HTML": "https://arxiv.org/html/2312.02345v2",
        "PDF": "https://arxiv.org/pdf/2312.02345"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a visualization method for CLIP text embeddings in terms of geometric primitives, not related to the processing of training data for LLMs."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.06269",
      "abstract": "Quantifying uncertainty in neural implicit 3D representations, particularly those utilizing Signed Distance Functions (SDFs), remains a substantial challenge due to computational inefficiencies, scalability issues, and geometric inconsistencies. Existing methods typically neglect direct geometric integration, leading to poorly calibrated uncertainty maps. We introduce BayesSDF, a novel probabilistic framework for uncertainty quantification in neural implicit SDF models, motivated by scientific simulation applications with 3D environments (e.g., forests) such as modeling fluid flow through forests, where precise surface geometry and awareness of fidelity surface geometric uncertainty are essential. Unlike radiance-based models such as NeRF or 3D Gaussian splatting, which lack explicit surface formulations, SDFs define continuous and differentiable geometry, making them better suited for physical modeling and analysis. BayesSDF leverages a Laplace approximation to quantify local surface instability via Hessian-based metrics, enabling computationally efficient, surface-aware uncertainty estimation. Our method shows that uncertainty predictions correspond closely with poorly reconstructed geometry, providing actionable confidence measures for downstream use. Extensive evaluations on synthetic and real-world datasets demonstrate that BayesSDF outperforms existing methods in both calibration and geometric consistency, establishing a strong foundation for uncertainty-aware 3D scene reconstruction, simulation, and robotic decision-making.",
      "authors": [
        "Rushil Desai",
        "Frederik Warburg",
        "Trevor Darrell",
        "Marissa Ramirez de Chanlatte"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T03:21:12+00:00",
          "link": "https://arxiv.org/abs/2507.06269v1",
          "size": "13273kb",
          "version": "v1"
        }
      ],
      "title": "A Probabilistic Approach to Uncertainty Quantification Leveraging 3D Geometry",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06269",
        "HTML": "https://arxiv.org/html/2507.06269v1",
        "PDF": "https://arxiv.org/pdf/2507.06269"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research addresses uncertainty quantification in 3D geometry and SDF models, with no relevance to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06713",
      "abstract": "In the context of dynamic virtual power plants (DVPPs), the integration of frequency containment reserve (FCR) and fast frequency control (FFC) enabled via local compensation of power imbalance represents a significant advancement in decentralized frequency regulation. However, they still have to cope with the limited power and energy capacities associated with commonly available storage solutions. This work combines a disturbance estimation based decentralized local control with distributed imbalance compensation in the event of local shortfall. The layered architecture facilitates fast local corrections in power setpoints while enabling coordination between neighbouring DVPP nodes to leverage the aggregated capacity, ensuring scalable and efficient operation suitable for renewable-heavy future grids. The proposed approach is validated on an illustrative 4-bus system with a high percentage of renewables.",
      "authors": [
        "Saif Ahmad",
        "Seifeddine Ben Elghali and Hafiz Ahmed"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T10:10:16+00:00",
          "link": "https://arxiv.org/abs/2507.06713v1",
          "size": "1992kb",
          "version": "v1"
        }
      ],
      "title": "Coordinated Fast Frequency Regulation in Dynamic Virtual Power Plants via Disturbance Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06713",
        "HTML": "https://arxiv.org/html/2507.06713v1",
        "PDF": "https://arxiv.org/pdf/2507.06713"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with power regulation in dynamic virtual power plants and not with the processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.15645",
      "abstract": "We use SMT technology to address a class of problems involving uninterpreted functions and nonlinear real arithmetic. In particular, we focus on problems commonly found in mathematical competitions, such as the International Mathematical Olympiad (IMO), where the task is to determine all solutions to constraints on an uninterpreted function. Although these problems require only high-school-level mathematics, state-of-the-art SMT solvers often struggle with them. We propose several techniques to improve SMT performance in this setting.",
      "authors": [
        "Chad E. Brown and Karel Chvalovsk\\'y and Mikol\\'a\\v{s} Janota and Mirek Ol\\v{s}\\'ak and Stefan Ratschan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-22T07:09:35+00:00",
          "link": "https://arxiv.org/abs/2504.15645v1",
          "size": "49kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T09:00:31+00:00",
          "link": "https://arxiv.org/abs/2504.15645v2",
          "size": "28kb",
          "version": "v2"
        }
      ],
      "title": "SMT and Functional Equation Solving over the Reals: Challenges from the IMO",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.15645",
        "HTML": "https://arxiv.org/html/2504.15645v2",
        "PDF": "https://arxiv.org/pdf/2504.15645"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with improving SMT solvers for mathematical problems and does not involve the processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06402",
      "abstract": "With the proliferation of wireless electrocardiogram (ECG) systems for health monitoring and authentication, protecting signal integrity against tampering is becoming increasingly important. This paper analyzes the performance of CNN, ResNet, and hybrid Transformer-CNN models for tamper detection. It also evaluates the performance of a Siamese network for ECG based identity verification. Six tampering strategies, including structured segment substitutions and random insertions, are emulated to mimic real world attacks. The one-dimensional ECG signals are transformed into a two dimensional representation in the time frequency domain using the continuous wavelet transform (CWT). The models are trained and evaluated using ECG data from 54 subjects recorded in four sessions 2019 to 2025 outside of clinical settings while the subjects performed seven different daily activities. Experimental results show that in highly fragmented manipulation scenarios, CNN, FeatCNN-TranCNN, FeatCNN-Tran and ResNet models achieved an accuracy exceeding 99.5 percent . Similarly, for subtle manipulations (for example, 50 percent from A and 50 percent from B and, 75 percent from A and 25 percent from B substitutions) our FeatCNN-TranCNN model demonstrated consistently reliable performance, achieving an average accuracy of 98 percent . For identity verification, the pure Transformer-Siamese network achieved an average accuracy of 98.30 percent . In contrast, the hybrid CNN-Transformer Siamese model delivered perfect verification performance with 100 percent accuracy.",
      "authors": [
        "Siddhant Deshpande",
        "Yalemzerf Getnet",
        "Waltenegus Dargie"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Cryptography and Security (cs.CR)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T21:10:07+00:00",
          "link": "https://arxiv.org/abs/2507.06402v1",
          "size": "708kb",
          "version": "v1"
        }
      ],
      "title": "Detection of Intelligent Tampering in Wireless Electrocardiogram Signals Using Hybrid Machine Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06402",
        "HTML": "https://arxiv.org/html/2507.06402v1",
        "PDF": "https://arxiv.org/pdf/2507.06402"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work deals with tampering detection in ECG signals and model evaluations for identity verification, not with LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.09567",
      "abstract": "Recent advancements in reasoning with large language models (RLLMs), such as OpenAI-O1 and DeepSeek-R1, have demonstrated their impressive capabilities in complex domains like mathematics and coding. A central factor in their success lies in the application of long chain-of-thought (Long CoT) characteristics, which enhance reasoning abilities and enable the solution of intricate problems. However, despite these developments, a comprehensive survey on Long CoT is still lacking, limiting our understanding of its distinctions from traditional short chain-of-thought (Short CoT) and complicating ongoing debates on issues like \"overthinking\" and \"inference-time scaling.\" This survey seeks to fill this gap by offering a unified perspective on Long CoT. (1) We first distinguish Long CoT from Short CoT and introduce a novel taxonomy to categorize current reasoning paradigms. (2) Next, we explore the key characteristics of Long CoT: deep reasoning, extensive exploration, and feasible reflection, which enable models to handle more complex tasks and produce more efficient, coherent outcomes compared to the shallower Short CoT. (3) We then investigate key phenomena such as the emergence of Long CoT with these characteristics, including overthinking, and inference-time scaling, offering insights into how these processes manifest in practice. (4) Finally, we identify significant research gaps and highlight promising future directions, including the integration of multi-modal reasoning, efficiency improvements, and enhanced knowledge frameworks. By providing a structured overview, this survey aims to inspire future research and further the development of logical reasoning in artificial intelligence.",
      "authors": [
        "Qiguang Chen",
        "Libo Qin",
        "Jinhao Liu",
        "Dengyun Peng",
        "Jiannan Guan",
        "Peng Wang",
        "Mengkang Hu",
        "Yuhang Zhou",
        "Te Gao",
        "Wanxiang Che"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-12T17:35:03+00:00",
          "link": "https://arxiv.org/abs/2503.09567v1",
          "size": "3319kb",
          "version": "v1"
        },
        {
          "date": "2025-03-13T04:34:15+00:00",
          "link": "https://arxiv.org/abs/2503.09567v2",
          "size": "3319kb",
          "version": "v2"
        },
        {
          "date": "2025-04-09T11:20:18+00:00",
          "link": "https://arxiv.org/abs/2503.09567v3",
          "size": "4590kb",
          "version": "v3"
        },
        {
          "date": "2025-07-09T15:13:24+00:00",
          "link": "https://arxiv.org/abs/2503.09567v4",
          "size": "5137kb",
          "version": "v4"
        }
      ],
      "title": "Towards Reasoning Era: A Survey of Long Chain-of-Thought for Reasoning Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.09567",
        "HTML": "https://arxiv.org/html/2503.09567v4",
        "PDF": "https://arxiv.org/pdf/2503.09567"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is a survey on reasoning paradigms in large language models, focusing on long chain-of-thought but does not discuss aspects of LLM training data processing or engineering."
      },
      "tasks": [
        "Logical Reasoning",
        "Survey"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.10707",
      "abstract": "Tabular in-context learning (ICL) has recently achieved state-of-the-art (SOTA) performance on several tabular prediction tasks. Previously restricted to classification problems on small tables, recent advances such as TabPFN and TabICL have extended its use to larger datasets. While being architecturally efficient and well-adapted to tabular data structures, current table-native ICL architectures, being trained exclusively on synthetic data, do not fully leverage the rich semantics and world knowledge contained in real-world tabular data. On another end of this spectrum, tabular ICL models based on pretrained large language models such as TabuLa-8B integrate deep semantic understanding and world knowledge but are only able to make use of a small amount of context due to inherent architectural limitations. With the aim to combine the best of both these worlds, we introduce ConTextTab, integrating semantic understanding and alignment into a table-native ICL framework. By employing specialized embeddings for different data modalities and by training on large-scale real-world tabular data, our model is competitive with SOTA across a broad set of benchmarks while setting a new standard on the semantically rich CARTE benchmark. Code and checkpoints are available at https://github.com/SAP-samples/contexttab",
      "authors": [
        "Marco Spinaci",
        "Marek Polewczyk",
        "Maximilian Schambach",
        "Sam Thelin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-12T13:57:29+00:00",
          "link": "https://arxiv.org/abs/2506.10707v1",
          "size": "319kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T19:44:57+00:00",
          "link": "https://arxiv.org/abs/2506.10707v2",
          "size": "383kb",
          "version": "v2"
        }
      ],
      "title": "ConTextTab: A Semantics-Aware Tabular In-Context Learner",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.10707",
        "HTML": "https://arxiv.org/html/2506.10707v2",
        "PDF": "https://arxiv.org/pdf/2506.10707"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper's focus is on improving tabular in-context learning with semantics-aware methods but does not primarily contribute to LLM training data processing."
      },
      "models": [
        {
          "model_path": "sap-ai-research/contexttab",
          "downloads": "1125",
          "likes": "1",
          "trending_score": "1.0",
          "link": "https://huggingface.co/sap-ai-research/contexttab"
        }
      ],
      "tasks": [
        "In-Context Learning",
        "World Knowledge"
      ],
      "repo_urls": [
        "https://github.com/sap-samples/contexttab"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.05742",
      "abstract": "Foundation models (FMs) are transforming the field of computational pathology by offering new approaches to analyzing histopathology images. Typically relying on weeks of training on large databases, the creation of FMs is a resource-intensive process in many ways. In this paper, we introduce the extension of our supervised foundation model, Tissue Concepts, to whole slide images, called Tissue Concepts v2 (TCv2), a supervised foundation model for whole slide images to address the issue above. TCv2 uses supervised, end-to-end multitask learning on slide-level labels. Training TCv2 uses a fraction of the training resources compared to self-supervised training. The presented model shows superior performance compared to SSL-trained models in cancer subtyping benchmarks and is fully trained on freely available data. Furthermore, a shared trained attention module provides an additional layer of explainability across different tasks.",
      "authors": [
        "Till Nicke",
        "Daniela Schacherer",
        "Jan Raphael Sch\\\"afer",
        "Natalia Artysh",
        "Antje Prasse",
        "Andr\\'e Homeyer",
        "Andrea Schenk",
        "Henning H\\\"ofener",
        "Johannes Lotz"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T07:42:12+00:00",
          "link": "https://arxiv.org/abs/2507.05742v1",
          "size": "4744kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T13:30:33+00:00",
          "link": "https://arxiv.org/abs/2507.05742v2",
          "size": "4744kb",
          "version": "v2"
        }
      ],
      "title": "Tissue Concepts v2: A Supervised Foundation Model For Whole Slide Images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05742",
        "HTML": "https://arxiv.org/html/2507.05742v2",
        "PDF": "https://arxiv.org/pdf/2507.05742"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces Tissue Concepts v2, a supervised foundation model for whole slide images in computational pathology, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06349",
      "abstract": "Understanding the performance profiles of storage devices and how best to utilize them has always been non-trivial due to factors such as seek times, caching, scheduling, concurrent access, flash wear-out, and garbage collection. However, analytical frameworks that provide simplified abstractions of storage performance can still be accurate enough to evaluate external memory algorithms and data structures at the design stage. For example, the Disk Access Machine (DAM) model assumes that a storage device transfers data in fixed-size blocks of size B and that all transfers have unit latency. This abstraction is already sufficient to explain some of the benefits of data structures such as B-trees and Log-Structured Merge trees (LSM trees); however, storage technology advances have significantly reduced current models' accuracy and utility.\n  This paper introduces the Multi-Queue Solid State Drive (MQSSD) model, a new storage abstraction. This model builds upon previous models and aims to more accurately represent the performance characteristics of modern storage hardware. We identify key performance-critical aspects of modern multi-queue solid-state drives on which we base our model and demonstrate these characteristics on actual hardware. We then show how our model can be applied to LSM-tree-based storage engines to optimize them for modern storage hardware. We highlight that leveraging concurrent access is crucial for fully utilizing the high throughput of multi-queue SSDs, enabling designs that may appear counterintuitive under traditional paradigms We then validate these insights through experiments using Facebook's LSM-tree-based key-value store, RocksDB. We conclude that the MQSSD model offers a more accurate abstraction of modern hardware than previous models, allowing for greater insight and optimization.",
      "authors": [
        "Erin Ransom",
        "Andrew Lim",
        "Michael Mitzenmacher"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T19:20:30+00:00",
          "link": "https://arxiv.org/abs/2507.06349v1",
          "size": "472kb",
          "version": "v1"
        }
      ],
      "title": "Multi-Queue SSD I/O Modeling & Its Implications for Data Structure Design",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06349",
        "HTML": "https://arxiv.org/html/2507.06349v1",
        "PDF": "https://arxiv.org/pdf/2507.06349"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a new model for SSD I/O but does not discuss LLM training data processing. It focuses on storage hardware optimization and not on data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06646",
      "abstract": "We evaluate the performance of four common learned models utilizing INR and VAE structures for compressing phase-only holograms in holographic displays. The evaluated models include a vanilla MLP, SIREN, and FilmSIREN, with TAESD as the representative VAE model. Our experiments reveal that a pretrained image VAE, TAESD, with 2.2M parameters struggles with phase-only hologram compression, revealing the need for task-specific adaptations. Among the INRs, SIREN with 4.9k parameters achieves %40 compression with high quality in the reconstructed 3D images (PSNR = 34.54 dB). These results emphasize the effectiveness of INRs and identify the limitations of pretrained image compression VAEs for hologram compression task.",
      "authors": [
        "Zicong Peng (1)",
        "Yicheng Zhan (1)",
        "Josef Spjut (2) and Kaan Ak\\c{s}it (1) ((1) University College London",
        "(2) NVIDIA)"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T08:19:44+00:00",
          "link": "https://arxiv.org/abs/2507.06646v1",
          "size": "4304kb",
          "version": "v1"
        }
      ],
      "title": "Assessing Learned Models for Phase-only Hologram Compression",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06646",
        "HTML": "https://arxiv.org/html/2507.06646v1",
        "PDF": "https://arxiv.org/pdf/2507.06646"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper evaluates learned models for hologram compression, discussing model architectures and compression techniques rather than any data processing techniques for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06804",
      "abstract": "Automated Theorem Proving (ATP) in formal languages is a foundational challenge for AI. While Large Language Models (LLMs) have driven remarkable progress, a significant gap remains between their powerful informal reasoning capabilities and their weak formal proving performance. Recent studies show that the informal accuracy exceeds 80% while formal success remains below 8% on benchmarks like PutnamBench. We argue this gap persists because current state-of-the-art provers, by tightly coupling reasoning and proving, are trained with paradigms that inadvertently punish deep reasoning in favor of shallow, tactic-based strategies. To bridge this fundamental gap, we propose a novel framework that decouples high-level reasoning from low-level proof generation. Our approach utilizes two distinct, specialized models: a powerful, general-purpose Reasoner to generate diverse, strategic subgoal lemmas, and an efficient Prover to rigorously verify them. This modular design liberates the model's full reasoning potential and bypasses the pitfalls of end-to-end training. We evaluate our method on a challenging set of post-2000 IMO problems, a problem set on which no prior open-source prover has reported success. Our decoupled framework successfully solves 5 of these problems, demonstrating a significant step towards automated reasoning on exceptionally difficult mathematical challenges. To foster future research, we release our full dataset of generated and verified lemmas for a wide range of IMO problems, available at https://tencent-imo.github.io/ .",
      "authors": [
        "Zhenwen Liang",
        "Linfeng Song",
        "Yang Li",
        "Tao Yang",
        "Feng Zhang",
        "Haitao Mi",
        "Dong Yu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T22:38:49+00:00",
          "link": "https://arxiv.org/abs/2507.06804v1",
          "size": "1101kb",
          "version": "v1"
        }
      ],
      "title": "Towards Solving More Challenging IMO Problems via Decoupled Reasoning and Proving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06804",
        "PDF": "https://arxiv.org/pdf/2507.06804"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on a framework for theorem proving, not on the processing or collection of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2405.14030",
      "abstract": "Large vision-language contrastive models (VLCMs), such as CLIP, have become foundational, demonstrating remarkable success across a variety of downstream tasks. Despite their advantages, these models, akin to other foundational systems, inherit biases from the disproportionate distribution of real-world data, leading to misconceptions about the actual environment. Prevalent datasets like ImageNet are often riddled with non-causal, spurious correlations that can diminish VLCM performance in scenarios where these contextual elements are absent. This study presents an investigation into how a simple linear probe can effectively distill task-specific core features from CLIP's embedding for downstream applications. Our analysis reveals that the CLIP text representations are often tainted by spurious correlations, inherited in the biased pre-training dataset. Empirical evidence suggests that relying on visual representations from CLIP, as opposed to text embedding, is more effective to refine the skewed perceptions in VLCMs, emphasizing the superior utility of visual representations in overcoming embedded biases. Our code can be found here.",
      "authors": [
        "Haocheng Dai",
        "Sarang Joshi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-22T22:03:11+00:00",
          "link": "https://arxiv.org/abs/2405.14030v1",
          "size": "671kb",
          "version": "v1"
        },
        {
          "date": "2025-01-01T20:45:27+00:00",
          "link": "https://arxiv.org/abs/2405.14030v2",
          "size": "2049kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T02:54:32+00:00",
          "link": "https://arxiv.org/abs/2405.14030v3",
          "size": "1080kb",
          "version": "v3"
        }
      ],
      "title": "Refining Skewed Perceptions in Vision-Language Contrastive Models through Visual Representations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.14030",
        "HTML": "https://arxiv.org/html/2405.14030v3",
        "PDF": "https://arxiv.org/pdf/2405.14030"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on refining perceptions in vision-language models using visual representations rather than text embeddings but does not discuss any aspect of LLM training data processing."
      },
      "tasks": [
        "Misconceptions"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.04677",
      "abstract": "Given the continuous increase in dataset sizes and the complexity of forecasting models, the trade-off between forecast accuracy and computational cost is emerging as an extremely relevant topic, especially in the context of ensemble learning for time series forecasting. To asses it, we evaluated ten base models and eight ensemble configurations across two large-scale retail datasets (M5 and VN1), considering both point and probabilistic accuracy under varying retraining frequencies. We showed that ensembles consistently improve forecasting performance, particularly in probabilistic settings. However, these gains come at a substantial computational cost, especially for larger, accuracy-driven ensembles. We found that reducing retraining frequency significantly lowers costs, with minimal impact on accuracy, particularly for point forecasts. Moreover, efficiency-driven ensembles offer a strong balance, achieving competitive accuracy with considerably lower costs compared to accuracy-optimized combinations. Most importantly, small ensembles of two or three models are often sufficient to achieve near-optimal results. These findings provide practical guidelines for deploying scalable and cost-efficient forecasting systems, supporting the broader goals of sustainable AI in forecasting. Overall, this work shows that careful ensemble design and retraining strategy selection can yield accurate, robust, and cost-effective forecasts suitable for real-world applications.",
      "authors": [
        "Marco Zanotti"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Applications (stat.AP)",
        "Other Statistics (stat.OT)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-05T06:54:19+00:00",
          "link": "https://arxiv.org/abs/2506.04677v1",
          "size": "2374kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T12:32:09+00:00",
          "link": "https://arxiv.org/abs/2506.04677v2",
          "size": "2412kb",
          "version": "v2"
        }
      ],
      "title": "The cost of ensembling: is it always worth combining?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.04677",
        "HTML": "https://arxiv.org/html/2506.04677v2",
        "PDF": "https://arxiv.org/pdf/2506.04677"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the computational cost and efficiency of ensemble learning for time series forecasting rather than any aspect of LLM training data processing or dataset creation."
      },
      "tasks": [
        "Ensemble Learning",
        "Time Series Forecasting"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06854",
      "abstract": "We show the functional completeness for the connectives of the non-trivial negation inconsistent logic C by using a well-established method implementing purely proof-theoretic notions only. Firstly, given that C contains a strong negation, expressing a notion of direct refutation, the proof needs to be applied in a bilateralist way in that not only higher-order rule schemata for proofs but also for refutations need to be considered. Secondly, given that C is a connexive logic we need to take a connexive understanding of inference as a basis, leading to a different conception of (higher-order) refutation than is usually employed.",
      "authors": [
        "Sara Ayhan and Hrafn Valt\\'yr Oddsson"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Logic (math.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T13:58:07+00:00",
          "link": "https://arxiv.org/abs/2507.06854v1",
          "size": "12kb",
          "version": "v1"
        }
      ],
      "title": "Proof-Theoretic Functional Completeness for the Connexive Logic C",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06854",
        "HTML": "https://arxiv.org/html/2507.06854v1",
        "PDF": "https://arxiv.org/pdf/2507.06854"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses proof-theoretic functional completeness for connexive logic, focusing on negation and refutation, with no relevance to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.09347",
      "abstract": "Large Language Models (LLMs) are increasingly employed as automated evaluators to assess the safety of generated content, yet their reliability in this role remains uncertain. This study evaluates a diverse set of 11 LLM judge models across critical safety domains, examining three key aspects: self-consistency in repeated judging tasks, alignment with human judgments, and susceptibility to input artifacts such as apologetic or verbose phrasing. Our findings reveal that biases in LLM judges can significantly distort the final verdict on which content source is safer, undermining the validity of comparative evaluations. Notably, apologetic language artifacts alone can skew evaluator preferences by up to 98\\%. Contrary to expectations, larger models do not consistently exhibit greater robustness, while smaller models sometimes show higher resistance to specific artifacts. To mitigate LLM evaluator robustness issues, we investigate jury-based evaluations aggregating decisions from multiple models. Although this approach both improves robustness and enhances alignment to human judgements, artifact sensitivity persists even with the best jury configurations. These results highlight the urgent need for diversified, artifact-resistant methodologies to ensure reliable safety assessments.",
      "authors": [
        "Hongyu Chen",
        "Seraphina Goldfarb-Tarrant"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-12T12:49:02+00:00",
          "link": "https://arxiv.org/abs/2503.09347v1",
          "size": "2948kb",
          "version": "v1"
        },
        {
          "date": "2025-06-13T15:07:08+00:00",
          "link": "https://arxiv.org/abs/2503.09347v2",
          "size": "108kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T13:09:13+00:00",
          "link": "https://arxiv.org/abs/2503.09347v3",
          "size": "108kb",
          "version": "v3"
        }
      ],
      "title": "Safer or Luckier? LLMs as Safety Evaluators Are Not Robust to Artifacts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.09347",
        "HTML": "https://arxiv.org/html/2503.09347v3",
        "PDF": "https://arxiv.org/pdf/2503.09347"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper evaluates LLMs as safety evaluators, focusing on their robustness and bias but not on LLM training data processing or engineering."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2504.03635",
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities across a wide range of tasks requiring complex reasoning. However, the effects of scaling on their reasoning abilities remain insufficiently understood. In this paper, we introduce a synthetic multihop reasoning environment designed to closely replicate the structure and distribution of real-world large-scale knowledge graphs. Our reasoning task involves completing missing edges in the graph, which requires advanced multi-hop reasoning and mimics real-world reasoning scenarios. To evaluate this, we pretrain language models (LMs) from scratch solely on triples from the incomplete graph and assess their ability to infer the missing edges. Interestingly, we observe that overparameterization can impair reasoning performance due to excessive memorization. We investigate different factors that affect this U-shaped loss curve, including graph structure, model size, and training steps. To predict the optimal model size for a specific knowledge graph, we find an empirical scaling that linearly maps the knowledge graph search entropy to the optimal model size. This work provides new insights into the relationship between scaling and reasoning in LLMs, shedding light on possible ways to optimize their performance for reasoning tasks.",
      "authors": [
        "Xinyi Wang",
        "Shawn Tan",
        "Mingyu Jin",
        "William Yang Wang",
        "Rameswar Panda",
        "Yikang Shen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-04T17:57:22+00:00",
          "link": "https://arxiv.org/abs/2504.03635v1",
          "size": "4864kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T10:08:34+00:00",
          "link": "https://arxiv.org/abs/2504.03635v2",
          "size": "4864kb",
          "version": "v2"
        }
      ],
      "title": "Do Larger Language Models Imply Better Generalization? A Pretraining Scaling Law for Implicit Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.03635",
        "HTML": "https://arxiv.org/html/2504.03635v2",
        "PDF": "https://arxiv.org/pdf/2504.03635"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates the effects of model scaling on reasoning tasks in LLMs without discussing any specific contributions to LLM training data processing."
      },
      "tasks": [
        "Knowledge Graphs",
        "Memorization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06277",
      "abstract": "Which factors determine AI propensity for military intervention? While the use of AI in war games and military planning is growing exponentially, the simple analysis of key drivers embedded in the models has not yet been done. This paper does a simple conjoint experiment proposing a model to decide on military intervention in 640 vignettes where each was run for 100 times allowing to explore AI decision on military intervention systematically. The analysis finds that largest predictors of AI decision to intervene are high domestic support and high probability of success. Costs such as international condemnation, military deaths, civilian deaths, and negative economic effect are statistically significant, but their effect is around half of domestic support and probability of victory. Closing window of opportunity only reaches statistical significance in interaction with other factors. The results are remarkably consistent across scenarios and across different models (OpenAI GPT, Anthropic Claude, Google Gemini) suggesting a pattern in AI decision-making.",
      "authors": [
        "Maxim Chupilkin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T12:52:08+00:00",
          "link": "https://arxiv.org/abs/2507.06277v1",
          "size": "473kb",
          "version": "v1"
        }
      ],
      "title": "The Prompt War: How AI Decides on a Military Intervention",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06277",
        "PDF": "https://arxiv.org/pdf/2507.06277"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on AI decision-making in military interventions and does not discuss LLM training data processing or dataset creation processes."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06336",
      "abstract": "Quantifying organism-level phenotypes, such as growth dynamics and biomass accumulation, is fundamental to understanding agronomic traits and optimizing crop production. However, quality growing data of plants at scale is difficult to generate. Here we use a mobile robotic platform to capture high-resolution environmental sensing and phenotyping measurements of a large-scale hydroponic leafy greens system. We describe a self-supervised modeling approach to build a map from observed growing data to the entire plant growth trajectory. We demonstrate our approach by forecasting future plant height and harvest mass of crops in this system. This approach represents a significant advance in combining robotic automation and machine learning, as well as providing actionable insights for agronomic research and operational efficiency.",
      "authors": [
        "Adam J Riesselman",
        "Evan M Cofer",
        "Therese LaRue",
        "Wim Meeussen"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Quantitative Methods (q-bio.QM)",
        "Machine Learning (cs.LG)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T18:55:11+00:00",
          "link": "https://arxiv.org/abs/2507.06336v1",
          "size": "1121kb",
          "version": "v1"
        }
      ],
      "title": "Self-supervised learning predicts plant growth trajectories from multi-modal industrial greenhouse data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06336",
        "HTML": "https://arxiv.org/html/2507.06336v1",
        "PDF": "https://arxiv.org/pdf/2507.06336"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with self-supervised learning for predicting plant growth trajectories using a robotic platform, focused on agronomy, lacking any connection to LLM training data processing or quality improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06417",
      "abstract": "This study conducts a comprehensive comparison of four neural network architectures: Convolutional Neural Network, Capsule Network, Convolutional Kolmogorov--Arnold Network, and the newly proposed Capsule--Convolutional Kolmogorov--Arnold Network. The proposed Capsule-ConvKAN architecture combines the dynamic routing and spatial hierarchy capabilities of Capsule Network with the flexible and interpretable function approximation of Convolutional Kolmogorov--Arnold Networks. This novel hybrid model was developed to improve feature representation and classification accuracy, particularly in challenging real-world biomedical image data. The architectures were evaluated on a histopathological image dataset, where Capsule-ConvKAN achieved the highest classification performance with an accuracy of 91.21\\%. The results demonstrate the potential of the newly introduced Capsule-ConvKAN in capturing spatial patterns, managing complex features, and addressing the limitations of traditional convolutional models in medical image classification.",
      "authors": [
        "Laura Pitukov\\'a",
        "Peter Sin\\v{c}\\'ak",
        "L\\'aszl\\'o J\\'ozsef Kov\\'acs"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T21:51:05+00:00",
          "link": "https://arxiv.org/abs/2507.06417v1",
          "size": "778kb",
          "version": "v1"
        }
      ],
      "title": "Capsule-ConvKAN: A Hybrid Neural Approach to Medical Image Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06417",
        "HTML": "https://arxiv.org/html/2507.06417v1",
        "PDF": "https://arxiv.org/pdf/2507.06417"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a hybrid neural architecture for medical image classification. It does not engage with creating or processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06959",
      "abstract": "Vision-language models (VLMs) are prone to hallucinations that critically compromise reliability in medical applications. While preference optimization can mitigate these hallucinations through clinical feedback, its implementation faces challenges such as clinically irrelevant training samples, imbalanced data distributions, and prohibitive expert annotation costs. To address these challenges, we introduce CheXPO, a Chest X-ray Preference Optimization strategy that combines confidence-similarity joint mining with counterfactual rationale. Our approach begins by synthesizing a unified, fine-grained multi-task chest X-ray visual instruction dataset across different question types for supervised fine-tuning (SFT). We then identify hard examples through token-level confidence analysis of SFT failures and use similarity-based retrieval to expand hard examples for balancing preference sample distributions, while synthetic counterfactual rationales provide fine-grained clinical preferences, eliminating the need for additional expert input. Experiments show that CheXPO achieves 8.93% relative performance gain using only 5% of SFT samples, reaching state-of-the-art performance across diverse clinical tasks and providing a scalable, interpretable solution for real-world radiology applications.",
      "authors": [
        "Xiao Liang",
        "Jiawei Hu",
        "Di Wang",
        "Zhi Ma",
        "Lin Zhao",
        "Ronghan Li",
        "Bo Wan",
        "Quan Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T15:40:18+00:00",
          "link": "https://arxiv.org/abs/2507.06959v1",
          "size": "6863kb",
          "version": "v1"
        }
      ],
      "title": "CheXPO: Preference Optimization for Chest X-ray VLMs with Counterfactual Rationale",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06959",
        "HTML": "https://arxiv.org/html/2507.06959v1",
        "PDF": "https://arxiv.org/pdf/2507.06959"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "CheXPO involves creating a new chest X-ray visual instruction dataset with a detailed process, making it relevant for training data processing through synthetic data generation and fine-tuning strategies."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07044",
      "abstract": "Vision Transformers (ViTs) have emerged as a powerful architecture for computer vision tasks due to their ability to model long-range dependencies and global contextual relationships. However, their substantial compute and memory demands hinder efficient deployment in scenarios with strict energy and bandwidth limitations. In this work, we propose OptoViT, the first near-sensor, region-aware ViT accelerator leveraging silicon photonics (SiPh) for real-time and energy-efficient vision processing. Opto-ViT features a hybrid electronic-photonic architecture, where the optical core handles compute-intensive matrix multiplications using Vertical-Cavity Surface-Emitting Lasers (VCSELs) and Microring Resonators (MRs), while nonlinear functions and normalization are executed electronically. To reduce redundant computation and patch processing, we introduce a lightweight Mask Generation Network (MGNet) that identifies regions of interest in the current frame and prunes irrelevant patches before ViT encoding. We further co-optimize the ViT backbone using quantization-aware training and matrix decomposition tailored for photonic constraints. Experiments across device fabrication, circuit and architecture co-design, to classification, detection, and video tasks demonstrate that OptoViT achieves 100.4 KFPS/W with up to 84% energy savings with less than 1.6% accuracy loss, while enabling scalable and efficient ViT deployment at the edge.",
      "authors": [
        "Mehrdad Morsali",
        "Chengwei Zhou",
        "Deniz Najafi",
        "Sreetama Sarkar",
        "Pietro Mercati",
        "Navid Khoshavi",
        "Peter Beerel",
        "Mahdi Nikdast",
        "Gourav Datta",
        "Shaahin Angizi"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T17:07:26+00:00",
          "link": "https://arxiv.org/abs/2507.07044v1",
          "size": "1130kb",
          "version": "v1"
        }
      ],
      "title": "Opto-ViT: Architecting a Near-Sensor Region of Interest-Aware Vision Transformer Accelerator with Silicon Photonics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07044",
        "HTML": "https://arxiv.org/html/2507.07044v1",
        "PDF": "https://arxiv.org/pdf/2507.07044"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "OptoViT deals with near-sensor vision transformer accelerators using silicon photonics, with no mention of LLM training data or associated processing methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.17538",
      "abstract": "As pre-trained language models grow in size, full fine-tuning their parameters on task adaptation data becomes increasingly impractical. To address this challenge, some methods for low-rank adaptation of language models have been proposed, e.g. LoRA, which incorporates trainable low-rank decomposition matrices into only some parameters of the pre-trained model, called adapters. This approach significantly reduces the number of trainable parameters compared to fine-tuning all parameters or adapters. In this work, we look at low-rank adaptation method from the lens of data privacy. We show theoretically that the low-rank adaptation used in LoRA is equivalent to fine-tuning adapters with noisy batch gradients - just like what DPSGD algorithm does. We also quantify the variance of the injected noise as a decreasing function of adaptation rank. By establishing a Berry-Esseen type bound on the total variation distance between the injected noise distribution and a Gaussian noise distribution with the same variance, we show that the dynamics of low-rank adaptation is very close to when DPSGD is performed w.r.t the adapters. Following our theoretical findings and approved by our experimental results, we show that low-rank adaptation provides robustness to membership inference attacks w.r.t the fine-tuning data.",
      "authors": [
        "Saber Malekmohammadi",
        "Golnoosh Farnadi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-26T04:56:49+00:00",
          "link": "https://arxiv.org/abs/2409.17538v1",
          "size": "59kb",
          "version": "v1"
        },
        {
          "date": "2024-10-27T02:54:59+00:00",
          "link": "https://arxiv.org/abs/2409.17538v2",
          "size": "59kb",
          "version": "v2"
        },
        {
          "date": "2024-11-19T20:10:18+00:00",
          "link": "https://arxiv.org/abs/2409.17538v3",
          "size": "59kb",
          "version": "v3"
        },
        {
          "date": "2025-03-29T01:56:56+00:00",
          "link": "https://arxiv.org/abs/2409.17538v4",
          "size": "90kb",
          "version": "v4"
        },
        {
          "date": "2025-04-02T03:18:14+00:00",
          "link": "https://arxiv.org/abs/2409.17538v5",
          "size": "90kb",
          "version": "v5"
        },
        {
          "date": "2025-06-03T16:03:24+00:00",
          "link": "https://arxiv.org/abs/2409.17538v6",
          "size": "1032kb",
          "version": "v6"
        },
        {
          "date": "2025-07-09T17:11:15+00:00",
          "link": "https://arxiv.org/abs/2409.17538v7",
          "size": "1025kb",
          "version": "v7"
        }
      ],
      "title": "Low-Rank Adaptation Secretly Imitates Differentially Private SGD",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.17538",
        "HTML": "https://arxiv.org/html/2409.17538",
        "PDF": "https://arxiv.org/pdf/2409.17538"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work studies low-rank adaptation of LLMs with a focus on data privacy, not directly addressing LLM training data processing or creation."
      },
      "tasks": [
        "LEMMA",
        "Relation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.23244",
      "abstract": "Bayesian Additive Regression Trees (BART) is a nonparametric Bayesian regression technique based on an ensemble of decision trees. It is part of the toolbox of many statisticians. The overall statistical quality of the regression is typically higher than other generic alternatives, and it requires less manual tuning, making it a good default choice. However, it is a niche method compared to its natural competitor XGBoost, due to the longer running time, making sample sizes above 10,000-100,000 a nuisance. I present a GPU-enabled implementation of BART, faster by up to 200x relative to a single CPU core, making BART competitive in running time with XGBoost. This implementation is available in the Python package bartz.",
      "authors": [
        "Giacomo Petrillo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-30T17:29:03+00:00",
          "link": "https://arxiv.org/abs/2410.23244v1",
          "size": "347kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T12:54:23+00:00",
          "link": "https://arxiv.org/abs/2410.23244v2",
          "size": "400kb",
          "version": "v2"
        }
      ],
      "title": "Very fast Bayesian Additive Regression Trees on GPU",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.23244",
        "HTML": "https://arxiv.org/html/2410.23244v2",
        "PDF": "https://arxiv.org/pdf/2410.23244"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a GPU implementation of Bayesian Additive Regression Trees to improve computation speed, without involving LLM training data processing."
      },
      "tasks": [
        "regression"
      ],
      "repo_urls": [
        "https://github.com/gattocrucco/bartz"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.18890",
      "abstract": "Generating ultra-long sequences with large language models (LLMs) has become increasingly crucial but remains a highly time-intensive task, particularly for sequences up to 100K tokens. While traditional speculative decoding methods exist, simply extending their generation limits fails to accelerate the process and can be detrimental. Through an in-depth analysis, we identify three major challenges hindering efficient generation: frequent model reloading, dynamic key-value (KV) management and repetitive generation. To address these issues, we introduce TOKENSWIFT, a novel framework designed to substantially accelerate the generation process of ultra-long sequences while maintaining the target model's inherent quality. Experimental results demonstrate that TOKENSWIFT achieves over 3 times speedup across models of varying scales (1.5B, 7B, 8B, 14B) and architectures (MHA, GQA). This acceleration translates to hours of time savings for ultra-long sequence generation, establishing TOKENSWIFT as a scalable and effective solution at unprecedented lengths. Code can be found at https://github.com/bigai-nlco/TokenSwift.",
      "authors": [
        "Tong Wu",
        "Junzhe Shen",
        "Zixia Jia",
        "Yuxuan Wang and Zilong Zheng"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-26T07:10:08+00:00",
          "link": "https://arxiv.org/abs/2502.18890v1",
          "size": "1007kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T02:35:21+00:00",
          "link": "https://arxiv.org/abs/2502.18890v2",
          "size": "783kb",
          "version": "v2"
        }
      ],
      "title": "TokenSwift: Lossless Acceleration of Ultra Long Sequence Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.18890",
        "HTML": "https://arxiv.org/html/2502.18890v2",
        "PDF": "https://arxiv.org/pdf/2502.18890"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a framework to accelerate sequence generation in LLMs but does not address any aspect of LLM training data processing such as data collection or filtering."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/bigai-nlco/tokenswift"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.07675",
      "abstract": "Query rewrite transforms SQL queries into semantically equivalent forms that run more efficiently. Existing approaches mainly rely on predefined rewrite rules, but they handle a limited subset of queries and can cause performance regressions. This limitation stems from three challenges of rule-based query rewrite: (1) it is hard to discover and verify new rules, (2) fixed rewrite rules do not generalize to new query patterns, and (3) some rewrite techniques cannot be expressed as fixed rules. Motivated by the fact that human experts exhibit significantly better rewrite ability but suffer from scalability, and Large Language Models (LLMs) have demonstrated nearly human-level semantic and reasoning abilities, we propose a new approach of using LLMs to rewrite SQL queries beyond rules. Due to the hallucination problems in LLMs, directly applying LLMs often leads to nonequivalent and suboptimal queries. To address this issue, we propose QUITE (query rewrite), a training-free and feedback-aware system based on LLM agents that rewrites SQL queries into semantically equivalent forms with significantly better performance, covering a broader range of query patterns and rewrite strategies compared to rule-based methods. Firstly, we design a multi-agent framework controlled by a finite state machine (FSM) to equip LLMs with the ability to use external tools and enhance the rewrite process with real-time database feedback. Secondly, we develop a rewrite middleware to enhance the ability of LLMs to generate optimized query equivalents. Finally, we employ a novel hint injection technique to improve execution plans for rewritten queries. Extensive experiments show that QUITE reduces query execution time by up to 35.8% over state-of-the-art approaches and produces 24.1% more rewrites than prior methods, covering query cases that earlier systems did not handle.",
      "authors": [
        "Yuyang Song",
        "Hanxu Yan",
        "Jiale Lao",
        "Yibo Wang",
        "Yufei Li",
        "Yuanchun Zhou",
        "Jianguo Wang",
        "Mingjie Tang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Databases (cs.DB)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-09T11:51:27+00:00",
          "link": "https://arxiv.org/abs/2506.07675v1",
          "size": "1207kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T09:51:35+00:00",
          "link": "https://arxiv.org/abs/2506.07675v2",
          "size": "1197kb",
          "version": "v2"
        }
      ],
      "title": "QUITE: A Query Rewrite System Beyond Rules with LLM Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.07675",
        "HTML": "https://arxiv.org/html/2506.07675v2",
        "PDF": "https://arxiv.org/pdf/2506.07675"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on using LLMs for SQL query rewriting, improving query execution without discussing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06651",
      "abstract": "Learning cross-modal correspondences is essential for image-to-point cloud (I2P) registration. Existing methods achieve this mostly by utilizing metric learning to enforce feature alignment across modalities, disregarding the inherent modality gap between image and point data. Consequently, this paradigm struggles to ensure accurate cross-modal correspondences. To this end, inspired by the cross-modal generation success of recent large diffusion models, we propose Diff$^2$I2P, a fully Differentiable I2P registration framework, leveraging a novel and effective Diffusion prior for bridging the modality gap. Specifically, we propose a Control-Side Score Distillation (CSD) technique to distill knowledge from a depth-conditioned diffusion model to directly optimize the predicted transformation. However, the gradients on the transformation fail to backpropagate onto the cross-modal features due to the non-differentiability of correspondence retrieval and PnP solver. To this end, we further propose a Deformable Correspondence Tuning (DCT) module to estimate the correspondences in a differentiable way, followed by the transformation estimation using a differentiable PnP solver. With these two designs, the Diffusion model serves as a strong prior to guide the cross-modal feature learning of image and point cloud for forming robust correspondences, which significantly improves the registration. Extensive experimental results demonstrate that Diff$^2$I2P consistently outperforms SoTA I2P registration methods, achieving over 7% improvement in registration recall on the 7-Scenes benchmark.",
      "authors": [
        "Juncheng Mu",
        "Chengwei Ren",
        "Weixiang Zhang",
        "Liang Pan",
        "Xiao-Ping Zhang",
        "Yue Gao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T08:30:49+00:00",
          "link": "https://arxiv.org/abs/2507.06651v1",
          "size": "4439kb",
          "version": "v1"
        }
      ],
      "title": "Diff$^2$I2P: Differentiable Image-to-Point Cloud Registration with Diffusion Prior",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06651",
        "HTML": "https://arxiv.org/html/2507.06651v1",
        "PDF": "https://arxiv.org/pdf/2507.06651"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a framework for image-to-point cloud registration using diffusion models, focusing on cross-modal correspondences, without discussing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.15582",
      "abstract": "Photorealistic reconstruction of street scenes is essential for developing real-world simulators in autonomous driving. While recent methods based on 3D/4D Gaussian Splatting (GS) have demonstrated promising results, they still encounter challenges in complex street scenes due to the unpredictable motion of dynamic objects. Current methods typically decompose street scenes into static and dynamic objects, learning the Gaussians in either a supervised manner (e.g., w/ 3D bounding-box) or a self-supervised manner (e.g., w/o 3D bounding-box). However, these approaches do not effectively model the motions of dynamic objects (e.g., the motion speed of pedestrians is clearly different from that of vehicles), resulting in suboptimal scene decomposition. To address this, we propose Explicit Motion Decomposition (EMD), which models the motions of dynamic objects by introducing learnable motion embeddings to the Gaussians, enhancing the decomposition in street scenes. The proposed plug-and-play EMD module compensates for the lack of motion modeling in self-supervised street Gaussian splatting methods. We also introduce tailored training strategies to extend EMD to supervised approaches. Comprehensive experiments demonstrate the effectiveness of our method, achieving state-of-the-art novel view synthesis performance in self-supervised settings. The code is available at: https://qingpowuwu.github.io/emd.",
      "authors": [
        "Xiaobao Wei",
        "Qingpo Wuwu",
        "Zhongyu Zhao",
        "Zhuangzhe Wu",
        "Nan Huang",
        "Ming Lu",
        "Ningning MA",
        "Shanghang Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-23T15:10:04+00:00",
          "link": "https://arxiv.org/abs/2411.15582v1",
          "size": "38510kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T03:09:39+00:00",
          "link": "https://arxiv.org/abs/2411.15582v2",
          "size": "8006kb",
          "version": "v2"
        }
      ],
      "title": "EMD: Explicit Motion Modeling for High-Quality Street Gaussian Splatting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.15582",
        "HTML": "https://arxiv.org/html/2411.15582v2",
        "PDF": "https://arxiv.org/pdf/2411.15582"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses motion modeling for street scene reconstruction, focusing on photorealistic rendering and not on LLM training data or dataset processing."
      },
      "tasks": [
        "Autonomous Driving"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.08268",
      "abstract": "This paper presents the Long Context and Form Output (LCFO) benchmark, a novel evaluation framework for assessing gradual summarization and summary expansion capabilities across diverse domains. LCFO consists of long input documents (5k words average length), each of which comes with three summaries of different lengths (20%, 10%, and 5% of the input text), as well as approximately 15 questions and answers (QA) related to the input content. Notably, LCFO also provides alignments between specific QA pairs and corresponding summaries in 7 domains. The primary motivation behind providing summaries of different lengths is to establish a controllable framework for generating long texts from shorter inputs, i.e. summary expansion. To establish an evaluation metric framework for summarization and summary expansion, we provide human evaluation scores for human-generated outputs, as well as results from various state-of-the-art large language models (LLMs). GPT-4o-mini achieves best human scores among automatic systems in both summarization and summary expansion tasks (~ +10% and +20%, respectively). It even surpasses human output quality in the case of short summaries (~ +7%). Overall automatic metrics achieve low correlations with human evaluation scores (~ 0.4) but moderate correlation on specific evaluation aspects such as fluency and attribution (~ 0.6).",
      "authors": [
        "Marta R. Costa-juss\\`a",
        "Pierre Andrews",
        "Mariano Coria Meglioli",
        "Joy Chen",
        "Joe Chuang",
        "David Dale",
        "Christophe Ropers",
        "Alexandre Mourachko",
        "Eduardo S\\'anchez",
        "Holger Schwenk",
        "Tuan Tran",
        "Arina Turkatenko",
        "Carleigh Wood"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-11T10:35:45+00:00",
          "link": "https://arxiv.org/abs/2412.08268v1",
          "size": "253kb",
          "version": "v1"
        },
        {
          "date": "2024-12-12T17:32:23+00:00",
          "link": "https://arxiv.org/abs/2412.08268v2",
          "size": "253kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T17:25:55+00:00",
          "link": "https://arxiv.org/abs/2412.08268v3",
          "size": "254kb",
          "version": "v3"
        }
      ],
      "title": "LCFO: Long Context and Long Form Output Dataset and Benchmarking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.08268",
        "HTML": "https://arxiv.org/html/2412.08268v3",
        "PDF": "https://arxiv.org/pdf/2412.08268"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper presents the LCFO benchmark, which involves handling large datasets for summarization tasks, but primarily focuses on evaluation and comparison, not on novel data processing techniques or creation tailored for LLM training."
      },
      "datasets": [
        {
          "dataset_name": "facebook/LCFO",
          "downloads": "30",
          "likes": "3",
          "link": "https://huggingface.co/datasets/facebook/LCFO"
        }
      ],
      "tasks": [
        "Benchmarking",
        "Form"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.02247",
      "abstract": "Active speaker detection (ASD) in egocentric videos presents unique challenges due to unstable viewpoints, motion blur, and off-screen speech sources - conditions under which traditional visual-centric methods degrade significantly. We introduce PAIR-Net (Pretrained Audio-Visual Integration with Regularization Network), an effective model that integrates a partially frozen Whisper audio encoder with a fine-tuned AV-HuBERT visual backbone to robustly fuse cross-modal cues. To counteract modality imbalance, we introduce an inter-modal alignment loss that synchronizes audio and visual representations, enabling more consistent convergence across modalities. Without relying on multi-speaker context or ideal frontal views, PAIR-Net achieves state-of-the-art performance on the Ego4D ASD benchmark with 76.6% mAP, surpassing LoCoNet and STHG by 8.2% and 12.9% mAP, respectively. Our results highlight the value of pretrained audio priors and alignment-based fusion for robust ASD under real-world egocentric conditions.",
      "authors": [
        "Yu Wang",
        "Juhyung Ha",
        "and David J. Crandall"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-02T20:49:52+00:00",
          "link": "https://arxiv.org/abs/2506.02247v1",
          "size": "249kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T23:35:30+00:00",
          "link": "https://arxiv.org/abs/2506.02247v2",
          "size": "249kb",
          "version": "v2"
        }
      ],
      "title": "EgoVIS@CVPR: PAIR-Net: Enhancing Egocentric Speaker Detection via Pretrained Audio-Visual Fusion and Alignment Loss",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.02247",
        "HTML": "https://arxiv.org/html/2506.02247v2",
        "PDF": "https://arxiv.org/pdf/2506.02247"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes an audio-visual integration model for active speaker detection in videos. It does not discuss data processing related to LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05966",
      "abstract": "Adam is widely recognized as one of the most effective optimizers for training deep neural networks (DNNs). Despite its remarkable empirical success, its theoretical convergence analysis remains unsatisfactory. Existing works predominantly interpret Adam as a preconditioned stochastic gradient descent with momentum (SGDM), formulated as $\\bm{x}_{t+1} = \\bm{x}_t - \\frac{\\gamma_t}{{\\sqrt{\\bm{v}_t}+\\epsilon}} \\circ \\bm{m}_t$. This perspective necessitates strong assumptions and intricate techniques, resulting in lengthy and opaque convergence proofs that are difficult to verify and extend. In contrast, we propose a novel interpretation by treating Adam as a sign-like optimizer, expressed as $\\bm{x}_{t+1} = \\bm{x}_t - \\gamma_t \\frac{|\\bm{m}_t|}{{\\sqrt{\\bm{v}_t}+\\epsilon}} \\circ {\\rm Sign}(\\bm{m}_t)$. This reformulation significantly simplifies the convergence analysis. For the first time, with some mild conditions, we prove that Adam achieves the optimal rate of ${\\cal O}(\\frac{1}{T^{\\sfrac{1}{4}}})$ rather than the previous ${\\cal O} \\left(\\frac{\\ln T}{T^{\\sfrac{1}{4}}}\\right)$ under weak assumptions of the generalized $p$-affine variance and $(L_0, L_1, q)$-smoothness, without dependence on the model dimensionality or the numerical stability parameter $\\epsilon$. Additionally, our theoretical analysis provides new insights into the role of momentum as a key factor ensuring convergence and offers practical guidelines for tuning learning rates in Adam, further bridging the gap between theory and practice.",
      "authors": [
        "Hanyang Peng",
        "Shuang Qin",
        "Yue Yu",
        "Fangqing Jiang",
        "Hui Wang",
        "Zhouchen Lin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T13:19:26+00:00",
          "link": "https://arxiv.org/abs/2507.05966v1",
          "size": "281kb",
          "version": "v1"
        }
      ],
      "title": "Simple Convergence Proof of Adam From a Sign-like Descent Perspective",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05966",
        "HTML": "https://arxiv.org/html/2507.05966",
        "PDF": "https://arxiv.org/pdf/2507.05966"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper provides a convergence proof for the Adam optimizer and does not address LLM training data processing. The contribution is entirely on optimization theory."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06085",
      "abstract": "This survey reviews prompt tuning, a parameter-efficient approach for adapting language models by prepending trainable continuous vectors while keeping the model frozen. We classify existing approaches into two categories: direct prompt learning and transfer learning. Direct prompt learning methods include: general optimization approaches, encoder-based methods, decomposition strategies, and mixture-of-experts frameworks. Transfer learning methods consist of: general transfer approaches, encoder-based methods, and decomposition strategies. For each method, we analyze method designs, innovations, insights, advantages, and disadvantages, with illustrative visualizations comparing different frameworks. We identify challenges in computational efficiency and training stability, and discuss future directions in improving training robustness and broadening application scope.",
      "authors": [
        "Zongqian Li",
        "Yixuan Su",
        "Nigel Collier"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T15:24:27+00:00",
          "link": "https://arxiv.org/abs/2507.06085v1",
          "size": "1711kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T09:59:12+00:00",
          "link": "https://arxiv.org/abs/2507.06085v2",
          "size": "1711kb",
          "version": "v2"
        }
      ],
      "title": "A Survey on Prompt Tuning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06085",
        "HTML": "https://arxiv.org/html/2507.06085v2",
        "PDF": "https://arxiv.org/pdf/2507.06085"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper surveys prompt tuning, focusing on model adaptation rather than training data processing or new dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06398",
      "abstract": "This paper investigates the Jolting Technologies Hypothesis, which posits superexponential growth (increasing acceleration, or a positive third derivative) in the development of AI capabilities. We develop a theoretical framework and validate detection methodologies through Monte Carlo simulations, while acknowledging that empirical validation awaits suitable longitudinal data. Our analysis focuses on creating robust tools for future empirical studies and exploring the potential implications should the hypothesis prove valid. The study examines how factors such as shrinking idea-to-action intervals and compounding iterative AI improvements drive this jolting pattern. By formalizing jolt dynamics and validating detection methods through simulation, this work provides the mathematical foundation necessary for understanding potential AI trajectories and their consequences for AGI emergence, offering insights for research and policy.",
      "authors": [
        "David Orban"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T21:03:49+00:00",
          "link": "https://arxiv.org/abs/2507.06398v1",
          "size": "554kb",
          "version": "v1"
        }
      ],
      "title": "Jolting Technologies: Superexponential Acceleration in AI Capabilities and Implications for AGI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06398",
        "HTML": "https://arxiv.org/html/2507.06398v1",
        "PDF": "https://arxiv.org/pdf/2507.06398"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "While the paper discusses AI development dynamics, it lacks focus on LLM training data processing or detailing any data engineering practices related to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07015",
      "abstract": "Knowledge distillation as an efficient knowledge transfer technique, has achieved remarkable success in unimodal scenarios. However, in cross-modal settings, conventional distillation methods encounter significant challenges due to data and statistical heterogeneities, failing to leverage the complementary prior knowledge embedded in cross-modal teacher models. This paper empirically reveals two critical issues in existing approaches: distillation path selection and knowledge drift. To address these limitations, we propose MST-Distill, a novel cross-modal knowledge distillation framework featuring a mixture of specialized teachers. Our approach employs a diverse ensemble of teacher models across both cross-modal and multimodal configurations, integrated with an instance-level routing network that facilitates adaptive and dynamic distillation. This architecture effectively transcends the constraints of traditional methods that rely on monotonous and static teacher models. Additionally, we introduce a plug-in masking module, independently trained to suppress modality-specific discrepancies and reconstruct teacher representations, thereby mitigating knowledge drift and enhancing transfer effectiveness. Extensive experiments across five diverse multimodal datasets, spanning visual, audio, and text, demonstrate that our method significantly outperforms existing state-of-the-art knowledge distillation methods in cross-modal distillation tasks. The source code is available at https://github.com/Gray-OREO/MST-Distill.",
      "authors": [
        "Hui Li",
        "Pengfei Yang",
        "Juanyang Chen",
        "Le Dong",
        "Yanxin Chen",
        "Quan Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T16:45:28+00:00",
          "link": "https://arxiv.org/abs/2507.07015v1",
          "size": "2376kb",
          "version": "v1"
        }
      ],
      "title": "MST-Distill: Mixture of Specialized Teachers for Cross-Modal Knowledge Distillation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07015",
        "HTML": "https://arxiv.org/html/2507.07015v1",
        "PDF": "https://arxiv.org/pdf/2507.07015"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a cross-modal knowledge distillation framework, focusing on transferring knowledge between models rather than any processes related to LLM training data preparation or enhancement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07016",
      "abstract": "In this paper, an edge-side model training study is conducted on a resource-limited smart meter. The motivation of grid-edge intelligence and the concept of on-device training are introduced. Then, the technical preparation steps for on-device training are described. A case study on the task of photovoltaic power forecasting is presented, where two representative machine learning models are investigated: a gradient boosting tree model and a recurrent neural network model. To adapt to the resource-limited situation in the smart meter, \"mixed\"- and \"reduced\"-precision training schemes are also devised. Experiment results demonstrate the feasibility of economically achieving grid-edge intelligence via the existing advanced metering infrastructures.",
      "authors": [
        "Jian Huang",
        "Yongli Zhu",
        "Linna Xu",
        "Zhe Zheng",
        "Wenpeng Cui",
        "Mingyang Sun"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T16:45:33+00:00",
          "link": "https://arxiv.org/abs/2507.07016v1",
          "size": "4127kb",
          "version": "v1"
        }
      ],
      "title": "On-Device Training of PV Power Forecasting Models in a Smart Meter for Grid Edge Intelligence",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07016",
        "PDF": "https://arxiv.org/pdf/2507.07016"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research deals with on-device training for PV power forecasting using a smart meter, which does not relate to processing or managing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.03933",
      "abstract": "Multilingual Large Language Models (LLMs) considerably changed how technologies can influence language. While previous technologies could mediate or assist humans, there is now a tendency to offload the task of writing itself to these technologies, enabling them to change our linguistic ecosystem more directly. While they provide us quick access to information and impressively fluent output, beneath their apparent sophistication lies a subtle, more insidious threat: the gradual decline and loss of linguistic diversity. With this opinion piece, I explore how model collapse, with a particular focus on translation technology, can lead to the loss of linguistic forms, grammatical features, and cultural nuance. Model collapse refers to the eventual consequence of self-consuming training loops, where models reinforce their own biases and lose linguistic diversity. Drawing on recent work in Computer Vision, Natural Language Processing (NLP) and Machine Translation (MT), I argue that the tails of our linguistic distributions are vanishing, and with them, the narratives and identities they carry. This is a call to resist linguistic flattening and to reimagine NLP as a field that encourages, values and protects expressive multilingual lexical and linguistic diversity and creativity.",
      "authors": [
        "Eva Vanmassenhove"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-05T07:36:49+00:00",
          "link": "https://arxiv.org/abs/2507.03933v1",
          "size": "6913kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T13:14:29+00:00",
          "link": "https://arxiv.org/abs/2507.03933v2",
          "size": "6907kb",
          "version": "v2"
        }
      ],
      "title": "Losing our Tail -- Again: On (Un)Natural Selection And Multilingual Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.03933",
        "HTML": "https://arxiv.org/html/2507.03933v2",
        "PDF": "https://arxiv.org/pdf/2507.03933"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This opinion piece discusses the impact of LLMs on linguistic diversity, not focusing on the processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06812",
      "abstract": "Co-speech gesture video generation aims to synthesize realistic, audio-aligned videos of speakers, complete with synchronized facial expressions and body gestures. This task presents challenges due to the significant one-to-many mapping between audio and visual content, further complicated by the scarcity of large-scale public datasets and high computational demands. We propose a lightweight framework that utilizes 2D full-body skeletons as an efficient auxiliary condition to bridge audio signals with visual outputs. Our approach introduces a diffusion model conditioned on fine-grained audio segments and a skeleton extracted from the speaker's reference image, predicting skeletal motions through skeleton-audio feature fusion to ensure strict audio coordination and body shape consistency. The generated skeletons are then fed into an off-the-shelf human video generation model with the speaker's reference image to synthesize high-fidelity videos. To democratize research, we present CSG-405-the first public dataset with 405 hours of high-resolution videos across 71 speech types, annotated with 2D skeletons and diverse speaker demographics. Experiments show that our method exceeds state-of-the-art approaches in visual quality and synchronization while generalizing across speakers and contexts.",
      "authors": [
        "Xu Yang",
        "Shaoli Huang",
        "Shenbo Xie",
        "Xuelin Chen",
        "Yifei Liu",
        "Changxing Ding"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T13:02:12+00:00",
          "link": "https://arxiv.org/abs/2507.06812v1",
          "size": "2666kb",
          "version": "v1"
        }
      ],
      "title": "Democratizing High-Fidelity Co-Speech Gesture Video Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06812",
        "HTML": "https://arxiv.org/html/2507.06812v1",
        "PDF": "https://arxiv.org/pdf/2507.06812"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "Primarily focuses on a method for gesture video generation while also providing CSG-405, a novel dataset; however, the dataset creation is tangential to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2403.08599",
      "abstract": "Exploring the internal mechanism of information spreading is critical for understanding and controlling the process. Traditional spreading models often assume individuals play the same role in the spreading process. In reality, however, individuals' diverse characteristics contribute differently to the spreading performance, leading to a heterogeneous infection rate across the system. To investigate network spreading dynamics under heterogeneous infection rates, we integrate two individual-level features -- influence (i.e., the ability to influence neighbors) and susceptibility (i.e., the extent to be influenced by neighbors) -- into the independent cascade model. Our findings reveal significant differences in spreading performance under heterogeneous and constant infection rates, with traditional structural centrality metrics proving more effective in the latter scenario. Additionally, we take the constant and heterogeneous infection rates into a state-of-the-art maximization algorithm, the well-known TIM algorithm, and find the seeds selected by heterogeneous infection rates are more dispersed compared to those under constant rates. Lastly, we find that both individuals' influence and susceptibility are vital to the spreading performance. Strikingly, susceptible individuals are particularly important to spreading when information is disseminated by social celebrities. By integrating influence and susceptibility into the spreading model, we gain a more profound understanding of the underlying mechanisms driving information spreading.",
      "authors": [
        "Chang Su",
        "Fang Zhou",
        "Linyuan L\\\"u"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-13T15:05:36+00:00",
          "link": "https://arxiv.org/abs/2403.08599v1",
          "size": "3343kb",
          "version": "v1"
        }
      ],
      "title": "The role of susceptible individuals in spreading dynamics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.08599",
        "PDF": "https://arxiv.org/pdf/2403.08599"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the spreading dynamics and individual characteristics in network models, without any mention of LLM training data processing or data engineering techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.12629",
      "abstract": "The density matrix renormalization group (DMRG) algorithm is a cornerstone computational method for studying quantum many-body systems, renowned for its accuracy and adaptability. Despite DMRG's broad applicability across fields such as materials science, quantum chemistry, and quantum computing, numerous independent implementations have been developed. This survey maps the rapidly expanding DMRG software landscape, providing a comprehensive comparison of features among 35 existing packages. We found significant overlap in features among the packages when comparing key aspects, such as parallelism strategies for high-performance computing and symmetry-adapted formulations that enhance efficiency. This overlap suggests opportunities for modularization of common operations, including tensor operations, symmetry representations, and eigensolvers, as the packages are mostly independent and share few third-party library dependencies where functionality is factored out. More widespread modularization and standardization would result in reduced duplication of efforts and improved interoperability. We believe that the proliferation of packages and the current lack of standard interfaces and modularity are more social than technical. We aim to raise awareness of existing packages, guide researchers in finding a suitable package for their needs, and help developers identify opportunities for collaboration, modularity standardization, and optimization. Ultimately, this work emphasizes the value of greater cohesion and modularity, which would benefit DMRG software, allowing these powerful algorithms to tackle more complex and ambitious problems.",
      "authors": [
        "Per Sehlstedt",
        "Jan Brandejs",
        "Paolo Bientinesi",
        "Lars Karlsson"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Physics (physics.comp-ph)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Mathematical Software (cs.MS)",
        "Chemical Physics (physics.chem-ph)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-14T21:12:16+00:00",
          "link": "https://arxiv.org/abs/2506.12629v1",
          "size": "187kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T08:10:15+00:00",
          "link": "https://arxiv.org/abs/2506.12629v2",
          "size": "187kb",
          "version": "v2"
        }
      ],
      "title": "The Software Landscape for the Density Matrix Renormalization Group",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.12629",
        "HTML": "https://arxiv.org/html/2506.12629v2",
        "PDF": "https://arxiv.org/pdf/2506.12629"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper surveys the Density Matrix Renormalization Group software landscape and discusses modularization and optimization, but does not focus on LLM training data processing."
      },
      "repo_urls": [
        "https://github.com/persehlstedt/dmrg-software"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06528",
      "abstract": "Aligning Large Language Models (LLMs) with investor decision-making processes under herd behavior is a critical challenge in behavioral finance, which grapples with a fundamental limitation: the scarcity of real-user data needed for Supervised Fine-Tuning (SFT). While SFT can bridge the gap between LLM outputs and human behavioral patterns, its reliance on massive authentic data imposes substantial collection costs and privacy risks. We propose InvestAlign, a novel framework that constructs high-quality SFT datasets by leveraging theoretical solutions to similar and simple optimal investment problems rather than complex scenarios. Our theoretical analysis demonstrates that training LLMs with InvestAlign-generated data achieves faster parameter convergence than using real-user data, suggesting superior learning efficiency. Furthermore, we develop InvestAgent, an LLM agent fine-tuned with InvestAlign, which demonstrates significantly closer alignment to real-user data than pre-SFT models in both simple and complex investment problems. This highlights our proposed InvestAlign as a promising approach with the potential to address complex optimal investment problems and align LLMs with investor decision-making processes under herd behavior. Our code is publicly available at https://github.com/thu-social-network-research-group/InvestAlign.",
      "authors": [
        "Huisheng Wang",
        "Zhuoshi Pan",
        "Hangjing Zhang",
        "Mingxiao Liu",
        "Hanqing Gao",
        "H. Vicky Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Emerging Technologies (cs.ET)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T04:07:22+00:00",
          "link": "https://arxiv.org/abs/2507.06528v1",
          "size": "647kb",
          "version": "v1"
        }
      ],
      "title": "InvestAlign: Overcoming Data Scarcity in Aligning Large Language Models with Investor Decision-Making Processes under Herd Behavior",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06528",
        "HTML": "https://arxiv.org/html/2507.06528v1",
        "PDF": "https://arxiv.org/pdf/2507.06528"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper's primary contribution involves constructing high-quality supervised fine-tuning datasets using theoretical solutions to investment problems, a direct method for improving data quality in LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2406.18752",
      "abstract": "This paper introduces a family of learning-augmented algorithms for online knapsack problems that achieve near Pareto-optimal consistency-robustness trade-offs through a simple combination of trusted learning-augmented and worst-case algorithms. Our approach relies on succinct, practical predictions -- single values or intervals estimating the minimum value of any item in an offline solution. Additionally, we propose a novel fractional-to-integral conversion procedure, offering new insights for online algorithm design.",
      "authors": [
        "Mohammadreza Daneshvaramoli",
        "Helia Karisani",
        "Adam Lechowicz",
        "Bo Sun",
        "Cameron Musco",
        "Mohammad Hajiesmaili"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-26T20:38:00+00:00",
          "link": "https://arxiv.org/abs/2406.18752v1",
          "size": "2513kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T14:20:53+00:00",
          "link": "https://arxiv.org/abs/2406.18752v2",
          "size": "2657kb",
          "version": "v2"
        }
      ],
      "title": "Near-Optimal Consistency-Robustness Trade-Offs for Learning-Augmented Online Knapsack Problems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.18752",
        "HTML": "https://arxiv.org/html/2406.18752v2",
        "PDF": "https://arxiv.org/pdf/2406.18752"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses learning-augmented algorithms for online knapsack problems, which is unrelated to LLM training data processing."
      },
      "tasks": [
        "Prediction"
      ],
      "repo_urls": [
        "https://github.com/moreda-a/OKP"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.20573",
      "abstract": "The widespread availability of large public datasets is a key factor behind the recent successes of statistical inference and machine learning methods. However, these datasets often contain some low-quality or contaminated data, to which many learning procedures are sensitive. Therefore, the question of whether and how public datasets should be prefiltered to facilitate accurate downstream learning arises. On a technical level this requires the construction of principled data prefiltering methods which are learner-agnostic robust, in the sense of provably protecting a set of pre-specified downstream learners from corrupted data. In this work, we formalize the problem of Learner-Agnostic Robust data Prefiltering (LARP), which aims at finding prefiltering procedures that minimize a worst-case loss over a pre-specified set of learners. We first instantiate our framework in the context of scalar mean estimation with Huber estimators under the Huber data contamination model. We provide a hardness result on a specific problem instance and analyze several natural prefiltering procedures. Our theoretical results indicate that performing LARP on a heterogeneous set of learners leads to some loss in model performance compared to the alternative of prefiltering data for each learner/use-case individually. We explore the resulting utility loss and its dependence on the problem parameters via extensive experiments on real-world image and tabular data, observing statistically significant reduction in utility. Finally, we model the trade-off between the utility drop and the cost of repeated (learner-specific) prefiltering within a game-theoretic framework and showcase benefits of LARP for large datasets.",
      "authors": [
        "Kristian Minchev",
        "Dimitar Iliev Dimitrov",
        "Nikola Konstantinov"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T16:07:59+00:00",
          "link": "https://arxiv.org/abs/2506.20573v1",
          "size": "110kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T14:23:19+00:00",
          "link": "https://arxiv.org/abs/2506.20573v2",
          "size": "126kb",
          "version": "v2"
        }
      ],
      "title": "LARP: Learner-Agnostic Robust Data Prefiltering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20573",
        "HTML": "https://arxiv.org/html/2506.20573v2",
        "PDF": "https://arxiv.org/pdf/2506.20573"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces a robust data prefiltering method called LARP, which is specifically aimed at improving data quality by prefiltering contaminated or low-quality public datasets for more accurate downstream learning, contributing directly to training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06459",
      "abstract": "High-speed vision sensing is essential for real-time perception in applications such as robotics, autonomous vehicles, and industrial automation. Traditional frame-based vision systems suffer from motion blur, high latency, and redundant data processing, limiting their performance in dynamic environments. Event cameras, which capture asynchronous brightness changes at the pixel level, offer a promising alternative but pose challenges in object detection due to sparse and noisy event streams. To address this, we propose an event autoencoder architecture that efficiently compresses and reconstructs event data while preserving critical spatial and temporal features. The proposed model employs convolutional encoding and incorporates adaptive threshold selection and a lightweight classifier to enhance recognition accuracy while reducing computational complexity. Experimental results on the existing Smart Event Face Dataset (SEFD) demonstrate that our approach achieves comparable accuracy to the YOLO-v4 model while utilizing up to $35.5\\times$ fewer parameters. Implementations on embedded platforms, including Raspberry Pi 4B and NVIDIA Jetson Nano, show high frame rates ranging from 8 FPS up to 44.8 FPS. The proposed classifier exhibits up to 87.84x better FPS than the state-of-the-art and significantly improves event-based vision performance, making it ideal for low-power, high-speed applications in real-time edge computing.",
      "authors": [
        "Riadul Islam",
        "Joey Mul\\'e",
        "Dhandeep Challagundla",
        "Shahmir Rizvi",
        "and Sean Carson"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T00:21:15+00:00",
          "link": "https://arxiv.org/abs/2507.06459v1",
          "size": "2724kb",
          "version": "v1"
        }
      ],
      "title": "EA: An Event Autoencoder for High-Speed Vision Sensing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06459",
        "HTML": "https://arxiv.org/html/2507.06459v1",
        "PDF": "https://arxiv.org/pdf/2507.06459"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses the architecture for high-speed vision sensing using event cameras, without discussing the collection, processing, or creation of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06520",
      "abstract": "We present Gradientsys, a next-generation multi-agent scheduling framework that coordinates diverse specialized AI agents using a typed Model-Context Protocol (MCP) and a ReAct-based dynamic planning loop. At its core, Gradientsys employs an LLM-powered scheduler for intelligent one-to-many task dispatch, enabling parallel execution of heterogeneous agents such as PDF parsers, web search modules, GUI controllers, and web builders. The framework supports hybrid synchronous/asynchronous execution, respects agent capacity constraints, and incorporates a robust retry-and-replan mechanism to handle failures gracefully. To promote transparency and trust, Gradientsys includes an observability layer streaming real-time agent activity and intermediate reasoning via Server-Sent Events (SSE). We offer an architectural overview and evaluate Gradientsys against existing frameworks in terms of extensibility, scheduling topology, tool reusability, parallelism, and observability. Experiments on the GAIA general-assistant benchmark show that Gradientsys achieves higher task success rates with reduced latency and lower API costs compared to a MinionS-style baseline, demonstrating the strength of its LLM-driven multi-agent orchestration.",
      "authors": [
        "Xinyuan Song",
        "Zeyu Wang",
        "Siyi Wu",
        "Tianyu Shi",
        "Lynn Ai"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T03:40:56+00:00",
          "link": "https://arxiv.org/abs/2507.06520v1",
          "size": "527kb",
          "version": "v1"
        }
      ],
      "title": "Gradientsys: A Multi-Agent LLM Scheduler with ReAct Orchestration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06520",
        "HTML": "https://arxiv.org/html/2507.06520v1",
        "PDF": "https://arxiv.org/pdf/2507.06520"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a scheduling framework for coordinating AI agents but does not discuss LLM training data processing or enhancement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06640",
      "abstract": "Search engines have become the gateway to information, products, and services, including those concerning healthcare. Access to reproductive health has been especially complicated in the wake of the 2022 Dobbs v. Jackson decision by the Supreme Court of the United States, splintering abortion regulations among the states. In this study, we performed an audit of the advertisements shown to Google Search users seeking information about abortion across the United States during the year following the Dobbs decision. We found that Crisis Pregnancy Centers (CPCs) -- organizations that target women with unexpected or \"crisis\" pregnancies, but do not provide abortions -- accounted for 47% of advertisements, whereas abortion clinics -- for 30%. Advertisements from CPCs were often returned for queries concerning information and safety. The type of advertisements returned, however, varied widely within each state, with Arizona returning the most advertisements from abortion clinics and other pro-choice organizations, and Minnesota the least. The proportion of pro-choice vs. anti-choice advertisements returned also varied over time, but estimates from Staggered Augmented Synthetic Control Methods did not indicate that changes in advertisement results were attributable to changes in state abortion laws. Our findings raise questions about the access to accurate medical information across the U.S. and point to a need for further examination of search engine advertisement policies and geographical bias.",
      "authors": [
        "Yelena Mejova",
        "Ronald E. Robertson",
        "Catherine A. Gimbrone and Sarah McKetta"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T08:10:53+00:00",
          "link": "https://arxiv.org/abs/2507.06640v1",
          "size": "989kb",
          "version": "v1"
        }
      ],
      "title": "Google Search Advertising after Dobbs v. Jackson",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06640",
        "HTML": "https://arxiv.org/html/2507.06640v1",
        "PDF": "https://arxiv.org/pdf/2507.06640"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper audits Google Search advertising related to reproductive health post Dobbs v. Jackson decision, without discussing any aspects of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06939",
      "abstract": "Probabilistic programming has become a standard practice to model stochastic events and learn about the behavior of nature in different scientific contexts, ranging from Genetics and Ecology to Linguistics and Psychology. However, domain practitioners (such as biologists) also need to be experts in statistics in order to select which probabilistic model is suitable for a given particular problem, relying then on probabilistic inference engines such as Stan, Pyro or Edward to fine-tune the parameters of that particular model. Probabilistic Programming would be more useful if the model selection is made automatic, without requiring statistics expertise from the end user. Automatically selecting the model is challenging because of the large search space of probabilistic programs needed to be explored, because the fact that most of that search space contains invalid programs, and because invalid programs may only be detected in some executions, due to its probabilistic nature. We propose a type system to statically reject invalid probabilistic programs, a type-directed synthesis algorithm that guarantees that generated programs are type-safe by construction, and an heuristic search procedure to handle the vast search space. We collect a number of probabilistic programs from the literature, and use them to compare our method with both a type-agnostic random search, and a data-guided method from the literature (DaPPer). Our results show that our technique both outperforms random search and DaPPer, specially on more complex programs. This drastic performance difference in synthesis allows for fast sampling of programs and enables techniques that previously suffered from the complexity of synthesis, such as Genetic Programming, to be applied.",
      "authors": [
        "Guilherme Espada and Alcides Fonseca"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T15:21:22+00:00",
          "link": "https://arxiv.org/abs/2507.06939v1",
          "size": "871kb",
          "version": "v1"
        }
      ],
      "title": "Sound Interval-Based Synthesis for Probabilistic Programs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06939",
        "PDF": "https://arxiv.org/pdf/2507.06939"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on probabilistic programming and model selection. It does not discuss LLM training data processing, nor is there any mention of data collection or engineering relevant to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06972",
      "abstract": "Insects comprise millions of species, many experiencing severe population declines under environmental and habitat changes. High-throughput approaches are crucial for accelerating our understanding of insect diversity, with DNA barcoding and high-resolution imaging showing strong potential for automatic taxonomic classification. However, most image-based approaches rely on individual specimen data, unlike the unsorted bulk samples collected in large-scale ecological surveys. We present the Mixed Arthropod Sample Segmentation and Identification (MassID45) dataset for training automatic classifiers of bulk insect samples. It uniquely combines molecular and imaging data at both the unsorted sample level and the full set of individual specimens. Human annotators, supported by an AI-assisted tool, performed two tasks on bulk images: creating segmentation masks around each individual arthropod and assigning taxonomic labels to over 17 000 specimens. Combining the taxonomic resolution of DNA barcodes with precise abundance estimates of bulk images holds great potential for rapid, large-scale characterization of insect communities. This dataset pushes the boundaries of tiny object detection and instance segmentation, fostering innovation in both ecological and machine learning research.",
      "authors": [
        "Johanna Orsholm",
        "John Quinto",
        "Hannu Autto",
        "Gaia Banelyte",
        "Nicolas Chazot",
        "Jeremy deWaard",
        "Stephanie deWaard",
        "Arielle Farrell",
        "Brendan Furneaux",
        "Bess Hardwick",
        "Nao Ito",
        "Amlan Kar",
        "Oula Kalttop\\\"a\\\"a",
        "Deirdre Kerdraon",
        "Erik Kristensen",
        "Jaclyn McKeown",
        "Tommi Mononen",
        "Ellen Nein",
        "Hanna Rogers",
        "Tomas Roslin",
        "Paula Schmitz",
        "Jayme Sones",
        "Maija Sujala",
        "Amy Thompson",
        "Evgeny V. Zakharov",
        "Iuliia Zarubiieva",
        "Akshita Gupta",
        "Scott C. Lowe",
        "Graham W. Taylor"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T16:03:06+00:00",
          "link": "https://arxiv.org/abs/2507.06972v1",
          "size": "8689kb",
          "version": "v1"
        }
      ],
      "title": "A multi-modal dataset for insect biodiversity with imagery and DNA at the trap and individual level",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06972",
        "HTML": "https://arxiv.org/html/2507.06972v1",
        "PDF": "https://arxiv.org/pdf/2507.06972"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces the MassID45 dataset, detailing the combination of molecular and imaging data for training classifiers. It focuses on creating a new dataset with detailed data processing steps."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06381",
      "abstract": "Gradient Descent (GD) and its variants are the primary tool for enabling efficient training of recurrent dynamical systems such as Recurrent Neural Networks (RNNs), Neural ODEs and Gated Recurrent units (GRUs). The dynamics that are formed in these models exhibit features such as neural collapse and emergence of latent representations that may support the remarkable generalization properties of networks. In neuroscience, qualitative features of these representations are used to compare learning in biological and artificial systems. Despite recent progress, there remains a need for theoretical tools to rigorously understand the mechanisms shaping learned representations, especially in finite, non-linear models. Here, we show that the gradient flow, which describes how the model's dynamics evolve over GD, can be decomposed into a product that involves two operators: a Parameter Operator, K, and a Linearized Flow Propagator, P. K mirrors the Neural Tangent Kernel in feed-forward neural networks, while P appears in Lyapunov stability and optimal control theory. We demonstrate two applications of our decomposition. First, we show how their interplay gives rise to low-dimensional latent dynamics under GD, and, specifically, how the collapse is a result of the network structure, over and above the nature of the underlying task. Second, for multi-task training, we show that the operators can be used to measure how objectives relevant to individual sub-tasks align. We experimentally and theoretically validate these findings, providing an efficient Pytorch package, \\emph{KPFlow}, implementing robust analysis tools for general recurrent architectures. Taken together, our work moves towards building a next stage of understanding of GD learning in non-linear recurrent models.",
      "authors": [
        "James Hazelden",
        "Laura Driscoll",
        "Eli Shlizerman",
        "Eric Shea-Brown"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Dynamical Systems (math.DS)",
        "Neurons and Cognition (q-bio.NC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T20:33:15+00:00",
          "link": "https://arxiv.org/abs/2507.06381v1",
          "size": "4431kb",
          "version": "v1"
        }
      ],
      "title": "KPFlow: An Operator Perspective on Dynamic Collapse Under Gradient Descent Training of Recurrent Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06381",
        "PDF": "https://arxiv.org/pdf/2507.06381"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on developing theoretical tools to understand the dynamics in recurrent neural networks during gradient descent learning, without any focus on LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06706",
      "abstract": "The security of the RSA cryptosystem is based on the intractability of computing Euler's totient function phi(n) for large integers n. Although deriving phi(n) deterministically remains computationally infeasible for cryptographically relevant bit lengths, and machine learning presents a promising alternative for constructing efficient approximations. In this work, we explore a machine learning approach to approximate Euler's totient function phi using linear regression models. We consider a dataset of RSA moduli of 64, 128, 256, 512 and 1024 bits along with their corresponding totient values. The regression model is trained to capture the relationship between the modulus and its totient, and tested on unseen samples to evaluate its prediction accuracy. Preliminary results suggest that phi can be approximated within a small relative error margin, which may be sufficient to aid in certain classes of RSA attacks. This research opens a direction for integrating statistical learning techniques into cryptanalysis, providing insights into the feasibility of attacking cryptosystems using approximation based strategies.",
      "authors": [
        "Gilda Rech Bansimba",
        "Regis F. Babindamana and Beni Blaug N. Ibara"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T10:01:25+00:00",
          "link": "https://arxiv.org/abs/2507.06706v1",
          "size": "374kb",
          "version": "v1"
        }
      ],
      "title": "Approximating Euler Totient Function using Linear Regression on RSA moduli",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06706",
        "HTML": "https://arxiv.org/html/2507.06706v1",
        "PDF": "https://arxiv.org/pdf/2507.06706"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores machine learning for cryptographic purposes, not related to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07045",
      "abstract": "The progression from traditional prompt engineering to a more rigorous discipline of prompt design marks a pivotal shift in human-LLM interaction. As Large Language Models (LLMs) become increasingly embedded in mission-critical applications, there emerges a pressing need for frameworks that are not only explicit and systematic but also minimal enough to remain practical and broadly accessible. While many existing approaches address prompt structuring through elaborate Domain-Specific Languages (DSLs) or multi-layered templates, such methods can impose significant token and cognitive overhead, potentially constraining the model's creative capacity. In this context, we propose the 5C Prompt Contract, a framework that distills prompt design into five intuitive components: Character, Cause, Constraint, Contingency, and Calibration. This minimal cognitive schema explicitly integrates fallback and output optimization directives, fostering reliable, interpretable, and creatively flexible AI interactions. Experimental results demonstrate that the 5C framework consistently achieves superior input token efficiency while maintaining rich and consistent outputs across diverse LLM architectures (OpenAI, Anthropic, DeepSeek, and Gemini), making it particularly suited for individuals and Small-to-Medium Enterprises (SMEs) with limited AI engineering resources.",
      "authors": [
        "Ugur Ari"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T17:07:39+00:00",
          "link": "https://arxiv.org/abs/2507.07045v1",
          "size": "7kb",
          "version": "v1"
        }
      ],
      "title": "5C Prompt Contracts: A Minimalist, Creative-Friendly, Token-Efficient Design Framework for Individual and SME LLM Usage",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07045",
        "HTML": "https://arxiv.org/html/2507.07045v1",
        "PDF": "https://arxiv.org/pdf/2507.07045"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on prompt engineering and the development of a framework for prompt design in LLM usage, without discussing any technical contributions to LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.23132",
      "abstract": "With the rapid growth of the low-altitude economy, there is increasing demand for real-time data collection using UAV-assisted wireless sensor networks. This paper investigates the problem of minimizing the age of information (AoI) in UAV-assisted wireless sensor networks by optimizing the UAV flight routing. We formulate the AoI minimization task and propose a large language model (LLM)-assisted UAV routing algorithm (LAURA). LAURA employs an LLM as intelligent crossover operators within an evolutionary optimization framework to efficiently explore the solution space. Simulation results show that LAURA outperforms benchmark methods in reducing the maximum AoI, especially in scenarios with a large number of sensor nodes.",
      "authors": [
        "Bisheng Wei",
        "Ruichen Zhang",
        "Ruihong Jiang",
        "Mugen Peng",
        "Dusit Niyato"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-29T15:52:08+00:00",
          "link": "https://arxiv.org/abs/2503.23132v1",
          "size": "467kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T07:30:20+00:00",
          "link": "https://arxiv.org/abs/2503.23132v2",
          "size": "454kb",
          "version": "v2"
        }
      ],
      "title": "LAURA: LLM-Assisted UAV Routing for AoI Minimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.23132",
        "HTML": "https://arxiv.org/html/2503.23132v2",
        "PDF": "https://arxiv.org/pdf/2503.23132"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a UAV routing algorithm with LLM assistance for real-time data collection but does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.15959",
      "abstract": "Scientific breakthroughs are widely attributed to the broad recombination of existing knowledge. Yet despite the explosive growth of scientific labor and publications - expanding opportunities for recombination - breakthroughs have not kept pace. To investigate this disconnect, we analyze 41 million papers published between 1965 and 2024. We quantify each paper's atypicality, defined as the recombination of distant knowledge, and its disruption, which we interpret as an indicator of breakthrough innovation. Contrary to recombinant growth theory, we find a robust negative correlation between atypicality and disruption - consistent across fields, time, team size, and even versions of the same paper. Drawing on scientist interviews and large-scale bibliometric analysis, we find that atypicality reflects the extension of dominant ideas through cross-topic recombination, whereas disruption captures their replacement within the same topic - suggesting that recombination tends to consolidate prevailing paradigms, whereas disruption challenges them. Using large language models to distinguish method and theory oriented papers, we show that methods are harder to displace than theories, revealing distinct temporal dynamics in epistemic change.",
      "authors": [
        "Linzhuo Li",
        "Yiling Lin",
        "Lingfei Wu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Digital Libraries (cs.DL)",
        "Physics and Society (physics.soc-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-19T02:00:46+00:00",
          "link": "https://arxiv.org/abs/2506.15959v1",
          "size": "2116kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T15:41:48+00:00",
          "link": "https://arxiv.org/abs/2506.15959v2",
          "size": "2116kb",
          "version": "v2"
        }
      ],
      "title": "Can Recombination Displace Dominant Scientific Ideas",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.15959",
        "PDF": "https://arxiv.org/pdf/2506.15959"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper analyzes scientific paper recombination and disruption using LLMs to classify papers but does not contribute to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06421",
      "abstract": "While additive manufacturing has opened interesting avenues to reimagine manufacturing as a service (MaaS) platform, transmission of design files from client to manufacturer over networks opens up many cybersecurity challenges. Securing client's intellectual property (IP) especially from cyber-attacks emerges as a major challenge. Earlier works introduced streaming, instead of sharing process plan (G-code) files, as a possible solution. However, executing client's G-codes on manufacturer's machines exposes them to potential malicious G-codes. This paper proposes a viable approach when the client and manufacturer do not trust each other and both the client and manufacturer want to preserve their IP of designs and manufacturing process respectively. The proposed approach is based on segmenting and streaming design (STL) files and employing a novel machine-specific STL to G-code translator at the manufacturer's site in real-time for printing. This approach secures design and manufacturing process IPs as demonstrated in a real-world implementation.",
      "authors": [
        "Seyed Ali Ghazi Asgar",
        "Narasimha Reddy",
        "Satish T.S. Bukkapatnam"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T21:59:21+00:00",
          "link": "https://arxiv.org/abs/2507.06421v1",
          "size": "21233kb",
          "version": "v1"
        }
      ],
      "title": "Never Trust the Manufacturer, Never Trust the Client: A Novel Method for Streaming STL Files for Secure Additive",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06421",
        "HTML": "https://arxiv.org/html/2507.06421v1",
        "PDF": "https://arxiv.org/pdf/2507.06421"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on securing intellectual property in additive manufacturing and does not address LLM training data processing or relevant data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2007.14245",
      "abstract": "Crowd counting is a challenging yet critical task in computer vision with applications ranging from public safety to urban planning. Recent advances using Convolutional Neural Networks (CNNs) that estimate density maps have shown significant success. However, accurately counting individuals in highly congested scenes remains an open problem due to severe occlusions, scale variations, and perspective distortions, where people appear at drastically different sizes across the image. In this work, we propose a novel deep learning architecture that effectively addresses these challenges. Our network integrates a ResNet-based feature extractor for capturing rich hierarchical representations, followed by a downsampling block employing dilated convolutions to preserve spatial resolution while expanding the receptive field. An upsampling block using transposed convolutions reconstructs the high-resolution density map. Central to our architecture is a novel Perspective-aware Aggregation Module (PAM) designed to enhance robustness to scale and perspective variations by adaptively aggregating multi-scale contextual information. We detail the training procedure, including the loss functions and optimization strategies used. Our method is evaluated on three widely used benchmark datasets using Mean Absolute Error (MAE) and Mean Squared Error (MSE) as evaluation metrics. Experimental results demonstrate that our model achieves superior performance compared to existing state-of-the-art methods. Additionally, we incorporate principled Bayesian inference techniques to provide uncertainty estimates along with the crowd count predictions, offering a measure of confidence in the model's outputs.",
      "authors": [
        "Abhinav Sagar"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2020-07-11T21:43:20+00:00",
          "link": "https://arxiv.org/abs/2007.14245v1",
          "size": "503kb",
          "version": "v1"
        },
        {
          "date": "2020-08-12T19:57:51+00:00",
          "link": "https://arxiv.org/abs/2007.14245v2",
          "size": "503kb",
          "version": "v2"
        },
        {
          "date": "2022-05-21T14:54:29+00:00",
          "link": "https://arxiv.org/abs/2007.14245v3",
          "size": "0kb",
          "version": "v3"
        },
        {
          "date": "2025-07-09T13:07:00+00:00",
          "link": "https://arxiv.org/abs/2007.14245v4",
          "size": "515kb",
          "version": "v4"
        }
      ],
      "title": "Bayesian Multi-Scale Neural Network for Crowd Counting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2007.14245",
        "HTML": "https://arxiv.org/html/2007.14245v4",
        "PDF": "https://arxiv.org/pdf/2007.14245"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a novel architecture for crowd counting and offers uncertainty estimates but does not discuss LLM training data processing or related data engineering tasks."
      },
      "tasks": [
        "Crowd Counting"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.15670",
      "abstract": "Lung diseases represent a significant global health challenge, with Chest X-Ray (CXR) being a key diagnostic tool due to its accessibility and affordability. Nonetheless, the detection of pulmonary lesions is often hindered by overlapping bone structures in CXR images, leading to potential misdiagnoses. To address this issue, we develop an end-to-end framework called BS-LDM, designed to effectively suppress bone in high-resolution CXR images. This framework is based on conditional latent diffusion models and incorporates a multi-level hybrid loss-constrained vector-quantized generative adversarial network which is crafted for perceptual compression, ensuring the preservation of details. To further enhance the framework's performance, we utilize offset noise in the forward process, and a temporal adaptive thresholding strategy in the reverse process. These additions help minimize discrepancies in generating low-frequency information of soft tissue images. Additionally, we have compiled a high-quality bone suppression dataset named SZCH-X-Rays. This dataset includes 818 pairs of high-resolution CXR and soft tissue images collected from our partner hospital. Moreover, we processed 241 data pairs from the JSRT dataset into negative images, which are more commonly used in clinical practice. Our comprehensive experiments and downstream evaluations reveal that BS-LDM excels in bone suppression, underscoring its clinical value. Our code is available at https://github.com/diaoquesang/BS-LDM.",
      "authors": [
        "Yifei Sun",
        "Zhanghao Chen",
        "Hao Zheng",
        "Wenming Deng",
        "Jin Liu",
        "Wenwen Min",
        "Ahmed Elazab",
        "Xiang Wan",
        "Changmiao Wang",
        "Ruiquan Ge"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-20T08:36:17+00:00",
          "link": "https://arxiv.org/abs/2412.15670v1",
          "size": "15339kb",
          "version": "v1"
        },
        {
          "date": "2024-12-24T08:44:04+00:00",
          "link": "https://arxiv.org/abs/2412.15670v2",
          "size": "15339kb",
          "version": "v2"
        },
        {
          "date": "2024-12-30T02:40:31+00:00",
          "link": "https://arxiv.org/abs/2412.15670v3",
          "size": "3591kb",
          "version": "v3"
        },
        {
          "date": "2025-06-17T09:26:03+00:00",
          "link": "https://arxiv.org/abs/2412.15670v4",
          "size": "2871kb",
          "version": "v4"
        },
        {
          "date": "2025-07-07T01:27:34+00:00",
          "link": "https://arxiv.org/abs/2412.15670v5",
          "size": "2871kb",
          "version": "v5"
        }
      ],
      "title": "BS-LDM: Effective Bone Suppression in High-Resolution Chest X-Ray Images with Conditional Latent Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.15670",
        "HTML": "https://arxiv.org/html/2412.15670",
        "PDF": "https://arxiv.org/pdf/2412.15670"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about an image-processing framework for bone suppression in chest X-rays and does not address LLM training data processing."
      },
      "tasks": [
        "Bone Suppression From Dual Energy Chest X-Rays",
        "Diagnostic",
        "Image Generation"
      ],
      "repo_urls": [
        "https://github.com/diaoquesang/BS-LDM"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.10789",
      "abstract": "We provide the first approximation quality guarantees for the Cuthull-McKee heuristic for reordering symmetric matrices to have low bandwidth, and we provide an algorithm for reconstructing bounded-bandwidth graphs from distance oracles with near-linear query complexity. To prove these results we introduce a new width parameter, BFS width, and we prove polylogarithmic upper and lower bounds on the BFS width of graphs of bounded bandwidth. Unlike other width parameters, such as bandwidth, pathwidth, and treewidth, BFS width can easily be computed in polynomial time. Bounded BFS width implies bounded bandwidth, pathwidth, and treewidth, which in turn imply fixed-parameter tractable algorithms for many problems that are NP-hard for general graphs. In addition to their applications to matrix ordering, we also provide applications of BFS width to graph reconstruction, to reconstruct graphs from distance queries, and graph drawing, to construct arc diagrams of small height.",
      "authors": [
        "David Eppstein",
        "Michael T. Goodrich",
        "Songyu Liu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-16T02:03:04+00:00",
          "link": "https://arxiv.org/abs/2505.10789v1",
          "size": "749kb",
          "version": "v1"
        },
        {
          "date": "2025-05-21T23:19:47+00:00",
          "link": "https://arxiv.org/abs/2505.10789v2",
          "size": "749kb",
          "version": "v2"
        },
        {
          "date": "2025-07-08T22:32:53+00:00",
          "link": "https://arxiv.org/abs/2505.10789v3",
          "size": "483kb",
          "version": "v3"
        }
      ],
      "title": "Bandwidth vs BFS Width in Matrix Reordering, Graph Reconstruction, and Graph Drawing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.10789",
        "HTML": "https://arxiv.org/html/2505.10789v3",
        "PDF": "https://arxiv.org/pdf/2505.10789"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses matrix reordering and graph algorithms, which are unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05711",
      "abstract": "In this paper, we leverage Koopman mode decomposition to analyze the nonlinear and high-dimensional climate systems acting on the observed data space. The dynamics of atmospheric systems are assumed to be equation-free, with the linear evolution of observables derived from measured historical long-term time-series data snapshots, such as monthly sea surface temperature records, to construct a purely data-driven climate dynamics. In particular, sparsity-promoting dynamic mode decomposition is exploited to extract the dominant spatial and temporal modes, which are among the most significant coherent structures underlying climate variability, enabling a more efficient, interpretable, and low-dimensional representation of the system dynamics. We hope that the combined use of Koopman modes and sparsity-promoting techniques will provide insights into the significant climate modes, enabling reduced-order modeling of the climate system and offering a potential framework for predicting and controlling weather and climate variability.",
      "authors": [
        "Zhicheng Zhang and Yoshihiko Susuki and Atsushi Okazaki"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)",
        "Atmospheric and Oceanic Physics (physics.ao-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T06:49:25+00:00",
          "link": "https://arxiv.org/abs/2507.05711v1",
          "size": "4349kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T03:36:52+00:00",
          "link": "https://arxiv.org/abs/2507.05711v2",
          "size": "4343kb",
          "version": "v2"
        }
      ],
      "title": "Sparsity-Promoting Dynamic Mode Decomposition Applied to Sea Surface Temperature Fields",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05711",
        "HTML": "https://arxiv.org/html/2507.05711v2",
        "PDF": "https://arxiv.org/pdf/2507.05711"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper employs dynamic mode decomposition techniques for analyzing sea surface temperature data, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06589",
      "abstract": "In this work, a novel soft continuum robot-inspired antenna array is proposed, featuring tentacle-like structures with multiple antenna elements. The proposed array achieves reconfigurability through continuous deformation of its geometry, in contrast to reconfigurable antennas which incur a per-element control. More specifically, the deformation is modeled by amplitude and spatial frequency parameters. We consider a multi-user multiple-input single-output downlink system, whereby the optimal deformation parameters are found to maximize the sum rate in the network. A successive convex approximation method is adopted to solve the problem. Numerical results show that the proposed deformable array significantly outperforms fixed geometry and per-element reconfigurable arrays in sum rate, demonstrating the benefits of structure-level flexibility for next-generation antenna arrays.",
      "authors": [
        "Elio Faddoul",
        "Andreas Nicolaides",
        "Konstantinos Ntougias",
        "Ioannis Krikidis"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T06:45:58+00:00",
          "link": "https://arxiv.org/abs/2507.06589v1",
          "size": "196kb",
          "version": "v1"
        }
      ],
      "title": "Soft Robotics-Inspired Flexible Antenna Arrays",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06589",
        "HTML": "https://arxiv.org/html/2507.06589v1",
        "PDF": "https://arxiv.org/pdf/2507.06589"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a novel antenna array design inspired by soft robotics, and does not address or involve any aspect of LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06734",
      "abstract": "The role of civil society organizations (CSOs) in monitoring harmful online content is increasingly crucial, especially as platform providers reduce their investment in content moderation. AI tools can assist in detecting and monitoring harmful content at scale. However, few open-source tools offer seamless integration of AI models and social media monitoring infrastructures. Given their thematic expertise and contextual understanding of harmful content, CSOs should be active partners in co-developing technological tools, providing feedback, helping to improve models, and ensuring alignment with stakeholder needs and values, rather than as passive 'consumers'. However, collaborations between the open source community, academia, and civil society remain rare, and research on harmful content seldom translates into practical tools usable by civil society actors. This work in progress explores how CSOs can be meaningfully involved in an AI-assisted open-source monitoring tool of anti-democratic movements on Telegram, which we are currently developing in collaboration with CSO stakeholders.",
      "authors": [
        "Milena Pustet",
        "Elisabeth Steffen",
        "Helena Mihaljevi\\'c",
        "Grischa Stanjek",
        "Yannis Illies"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T10:46:58+00:00",
          "link": "https://arxiv.org/abs/2507.06734v1",
          "size": "163kb",
          "version": "v1"
        }
      ],
      "title": "Civil Society in the Loop: Feedback-Driven Adaptation of (L)LM-Assisted Classification in an Open-Source Telegram Monitoring Tool",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06734",
        "HTML": "https://arxiv.org/html/2507.06734v1",
        "PDF": "https://arxiv.org/pdf/2507.06734"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The work discusses the role of civil society in co-developing open-source tools with AI assistance, but it does not address LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.02195",
      "abstract": "Geometric constraints between feature matches are critical in 3D point cloud registration problems. Existing approaches typically model unordered matches as a consistency graph and sample consistent matches to generate hypotheses. However, explicit graph construction introduces noise, posing great challenges for handcrafted geometric constraints to render consistency. To overcome this, we propose HyperGCT, a flexible dynamic Hyper-GNN-learned geometric ConstrainT that leverages high-order consistency among 3D correspondences. To our knowledge, HyperGCT is the first method that mines robust geometric constraints from dynamic hypergraphs for 3D registration. By dynamically optimizing the hypergraph through vertex and edge feature aggregation, HyperGCT effectively captures the correlations among correspondences, leading to accurate hypothesis generation. Extensive experiments on 3DMatch, 3DLoMatch, KITTI-LC, and ETH show that HyperGCT achieves state-of-the-art performance. Furthermore, HyperGCT is robust to graph noise, demonstrating a significant advantage in terms of generalization.",
      "authors": [
        "Xiyu Zhang",
        "Jiayi Ma",
        "Jianwei Guo",
        "Wei Hu",
        "Zhaoshuai Qi",
        "Fei Hui",
        "Jiaqi Yang",
        "Yanning Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-04T02:05:43+00:00",
          "link": "https://arxiv.org/abs/2503.02195v1",
          "size": "12989kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T02:48:54+00:00",
          "link": "https://arxiv.org/abs/2503.02195v2",
          "size": "12987kb",
          "version": "v2"
        }
      ],
      "title": "HyperGCT: A Dynamic Hyper-GNN-Learned Geometric Constraint for 3D Registration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.02195",
        "HTML": "https://arxiv.org/html/2503.02195v2",
        "PDF": "https://arxiv.org/pdf/2503.02195"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with geometric constraints in 3D point cloud registration and does not involve any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23334",
      "abstract": "Federated learning (FL) has emerged as a promising paradigm for collaboratively training deep learning models across institutions without exchanging sensitive medical data. However, its effectiveness is often hindered by limited data availability and non-independent, identically distributed data across participating clients, which can degrade model performance and generalization. To address these challenges, we propose a generative AI based data augmentation framework that integrates synthetic image sharing into the federated training process for breast cancer diagnosis via ultrasound images. Specifically, we train two simple class-specific Deep Convolutional Generative Adversarial Networks: one for benign and one for malignant lesions. We then simulate a realistic FL setting using three publicly available breast ultrasound image datasets: BUSI, BUS-BRA, and UDIAT. FedAvg and FedProx are adopted as baseline FL algorithms. Experimental results show that incorporating a suitable number of synthetic images improved the average AUC from 0.9206 to 0.9237 for FedAvg and from 0.9429 to 0.9538 for FedProx. We also note that excessive use of synthetic data reduced performance, underscoring the importance of maintaining a balanced ratio of real and synthetic samples. Our findings highlight the potential of generative AI based data augmentation to enhance FL results in the breast ultrasound image classification task.",
      "authors": [
        "Hongyi Pan",
        "Ziliang Hong",
        "Gorkem Durak",
        "Ziyue Xu",
        "Ulas Bagci"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T17:05:50+00:00",
          "link": "https://arxiv.org/abs/2506.23334v1",
          "size": "1048kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T21:03:53+00:00",
          "link": "https://arxiv.org/abs/2506.23334v2",
          "size": "1048kb",
          "version": "v2"
        }
      ],
      "title": "Federated Breast Cancer Detection Enhanced by Synthetic Ultrasound Image Augmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23334",
        "HTML": "https://arxiv.org/html/2506.23334v2",
        "PDF": "https://arxiv.org/pdf/2506.23334"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper involves data augmentation in federated learning via synthetic image generation but does not make a primary contribution to LLM training data processing specifically for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06735",
      "abstract": "Image fusion aims to integrate complementary information across modalities to generate high-quality fused images, thereby enhancing the performance of high-level vision tasks. While global spatial modeling mechanisms show promising results, constructing long-range feature dependencies in the spatial domain incurs substantial computational costs. Additionally, the absence of ground-truth exacerbates the difficulty of capturing complementary features effectively. To tackle these challenges, we propose a Residual Prior-driven Frequency-aware Network, termed as RPFNet. Specifically, RPFNet employs a dual-branch feature extraction framework: the Residual Prior Module (RPM) extracts modality-specific difference information from residual maps, thereby providing complementary priors for fusion; the Frequency Domain Fusion Module (FDFM) achieves efficient global feature modeling and integration through frequency-domain convolution. Additionally, the Cross Promotion Module (CPM) enhances the synergistic perception of local details and global structures through bidirectional feature interaction. During training, we incorporate an auxiliary decoder and saliency structure loss to strengthen the model's sensitivity to modality-specific differences. Furthermore, a combination of adaptive weight-based frequency contrastive loss and SSIM loss effectively constrains the solution space, facilitating the joint capture of local details and global features while ensuring the retention of complementary information. Extensive experiments validate the fusion performance of RPFNet, which effectively integrates discriminative features, enhances texture details and salient objects, and can effectively facilitate the deployment of the high-level vision task.",
      "authors": [
        "Guan Zheng",
        "Xue Wang",
        "Wenhua Qian",
        "Peng Liu",
        "Runzhuo Ma"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T10:48:00+00:00",
          "link": "https://arxiv.org/abs/2507.06735v1",
          "size": "6645kb",
          "version": "v1"
        }
      ],
      "title": "Residual Prior-driven Frequency-aware Network for Image Fusion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06735",
        "HTML": "https://arxiv.org/html/2507.06735v1",
        "PDF": "https://arxiv.org/pdf/2507.06735"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a network for image fusion and does not relate to the processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.09572",
      "abstract": "We present ViTaM-D, a novel visual-tactile framework for reconstructing dynamic hand-object interaction with distributed tactile sensing to enhance contact modeling. Existing methods, relying solely on visual inputs, often fail to capture occluded interactions and object deformation. To address this, we introduce DF-Field, a distributed force-aware contact representation leveraging kinetic and potential energy in hand-object interactions. ViTaM-D first reconstructs interactions using a visual network with contact constraint, then refines contact details through force-aware optimization, improving object deformation modeling. To evaluate deformable object reconstruction, we introduce the HOT dataset, featuring 600 hand-object interaction sequences in a high-precision simulation environment. Experiments on DexYCB and HOT datasets show that ViTaM-D outperforms state-of-the-art methods in reconstruction accuracy for both rigid and deformable objects. DF-Field also proves more effective in refining hand poses and enhancing contact modeling than previous refinement methods. The code, models, and datasets are available at https://sites.google.com/view/vitam-d/.",
      "authors": [
        "Zhenjun Yu",
        "Wenqiang Xu",
        "Pengfei Xie",
        "Yutong Li",
        "Brian W. Anthony",
        "Zhuorui Zhang",
        "Cewu Lu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-14T16:29:45+00:00",
          "link": "https://arxiv.org/abs/2411.09572v1",
          "size": "6642kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T07:53:30+00:00",
          "link": "https://arxiv.org/abs/2411.09572v2",
          "size": "8945kb",
          "version": "v2"
        }
      ],
      "title": "Dynamic Reconstruction of Hand-Object Interaction with Distributed Force-aware Contact Representation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.09572",
        "HTML": "https://arxiv.org/html/2411.09572v2",
        "PDF": "https://arxiv.org/pdf/2411.09572"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on a visual-tactile framework for reconstructing hand-object interactions, not on LLM training data processing or dataset creation for LLMs."
      },
      "tasks": [
        "Dynamic Reconstruction",
        "Object",
        "Object Reconstruction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06430",
      "abstract": "Existing website fingerprinting and traffic classification solutions do not work well when the evaluation context changes, as their performances often heavily rely on context-specific assumptions. To clarify this problem, we take three prior solutions presented for different but similar traffic classification and website fingerprinting tasks, and apply each solution's model to another solution's dataset. We pinpoint dataset-specific and model-specific properties that lead each of them to overperform in their specific evaluation context.\n  As a realistic evaluation context that takes practical labeling constraints into account, we design an evaluation framework using two recent real-world TLS traffic datasets from large-scale networks. The framework simulates a futuristic scenario in which SNIs are hidden in some networks but not in others, and the classifier's goal is to predict destination services in one network's traffic, having been trained on a labelled dataset collected from a different network. Our framework has the distinction of including real-world distribution shift, while excluding concept drift. We show that, even when abundant labeled data is available, the best solutions' performances under distribution shift are between 30% and 40%, and a simple 1-Nearest Neighbor classifier's performance is not far behind. We depict all performances measured on different models, not just the best ones, for a fair representation of traffic models in practice.",
      "authors": [
        "Elham Akbari",
        "Zihao Zhou",
        "Mohammad Ali Salahuddin",
        "Noura Limam",
        "Raouf Boutaba",
        "Bertrand Mathieu",
        "Stephanie Moteau",
        "and Stephane Tuffin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T22:22:50+00:00",
          "link": "https://arxiv.org/abs/2507.06430v1",
          "size": "194kb",
          "version": "v1"
        }
      ],
      "title": "One task to rule them all: A closer look at traffic classification generalizability",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06430",
        "HTML": "https://arxiv.org/html/2507.06430v1",
        "PDF": "https://arxiv.org/pdf/2507.06430"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses traffic classification generalizability and benchmarking in changing evaluation contexts, without addressing LLM training data processing or creation of new datasets for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06584",
      "abstract": "Compilers play a central role in translating high-level code into executable programs, making their correctness essential for ensuring code safety and reliability. While extensive research has focused on verifying the correctness of compilers for single-language compilation, the correctness of cross-language compilation - which involves the interaction between two languages and their respective compilers - remains largely unexplored. To fill this research gap, we propose CrossLangFuzzer, a novel framework that introduces a universal intermediate representation (IR) for JVM-based languages and automatically generates cross-language test programs with diverse type parameters and complex inheritance structures. After generating the initial IR, CrossLangFuzzer applies three mutation techniques - LangShuffler, FunctionRemoval, and TypeChanger - to enhance program diversity. By evaluating both the original and mutated programs across multiple compiler versions, CrossLangFuzzer successfully uncovered 10 confirmed bugs in the Kotlin compiler, 4 confirmed bugs in the Groovy compiler, 7 confirmed bugs in the Scala 3 compiler, 2 confirmed bugs in the Scala 2 compiler, and 1 confirmed bug in the Java compiler. Among all mutators, TypeChanger is the most effective, detecting 11 of the 24 compiler bugs. Furthermore, we analyze the symptoms and root causes of cross-compilation bugs, examining the respective responsibilities of language compilers when incorrect behavior occurs during cross-language compilation. To the best of our knowledge, this is the firstwork specifically focused on identifying and diagnosing compiler bugs in cross-language compilation scenarios. Our research helps to understand these challenges and contributes to improving compiler correctness in multi-language environments.",
      "authors": [
        "Qiong Feng",
        "Xiaotian Ma",
        "Ziyuan Feng",
        "Marat Akhin",
        "Wei Song",
        "Peng Liang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Programming Languages (cs.PL)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T06:33:06+00:00",
          "link": "https://arxiv.org/abs/2507.06584v1",
          "size": "289kb",
          "version": "v1"
        }
      ],
      "title": "Finding Compiler Bugs through Cross-Language Code Generator and Differential Testing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06584",
        "PDF": "https://arxiv.org/pdf/2507.06584"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on identifying compiler bugs through cross-language code generation and differential testing, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06789",
      "abstract": "This work explores the neural network approximation capabilities for functions within the spectral Barron space $\\mathscr{B}^s$, where $s$ is the smoothness index. We demonstrate that for functions in $\\mathscr{B}^{1/2}$, a shallow neural network (a single hidden layer) with $N$ units can achieve an $L^p$-approximation rate of $\\mathcal{O}(N^{-1/2})$. This rate also applies to uniform approximation, differing by at most a logarithmic factor. Our results significantly reduce the smoothness requirement compared to existing theory, which necessitate functions to belong to $\\mathscr{B}^1$ in order to attain the same rate. Furthermore, we show that increasing the network's depth can notably improve the approximation order for functions with small smoothness. Specifically, for networks with $L$ hidden layers, functions in $\\mathscr{B}^s$ with $0 < sL \\le 1/2$ can achieve an approximation rate of $\\mathcal{O}(N^{-sL})$. The rates and prefactors in our estimates are dimension-free. We also confirm the sharpness of our findings, with the lower bound closely aligning with the upper, with a discrepancy of at most one logarithmic factor.",
      "authors": [
        "Yulei Liao",
        "Pingbing Ming",
        "Hao Yu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T12:27:07+00:00",
          "link": "https://arxiv.org/abs/2507.06789v1",
          "size": "413kb",
          "version": "v1"
        }
      ],
      "title": "Sharp uniform approximation for spectral Barron functions by deep neural networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06789",
        "HTML": "https://arxiv.org/html/2507.06789v1",
        "PDF": "https://arxiv.org/pdf/2507.06789"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses approximation capabilities of neural networks for Barron functions, focusing on mathematical theory rather than LLM training-data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2404.02359",
      "abstract": "Multimodal machine learning has gained significant attention in recent years due to its potential for integrating information from multiple modalities to enhance learning and decision-making processes. However, it is commonly observed that unimodal models outperform multimodal models, despite the latter having access to richer information. Additionally, the influence of a single modality often dominates the decision-making process, resulting in suboptimal performance. This research project aims to address these challenges by proposing a novel regularization term that encourages multimodal models to effectively utilize information from all modalities when making decisions. The focus of this project lies in the video-audio domain, although the proposed regularization technique holds promise for broader applications in embodied AI research, where multiple modalities are involved. By leveraging this regularization term, the proposed approach aims to mitigate the issue of unimodal dominance and improve the performance of multimodal machine learning systems. Through extensive experimentation and evaluation, the effectiveness and generalizability of the proposed technique will be assessed. The findings of this research project have the potential to significantly contribute to the advancement of multimodal machine learning and facilitate its application in various domains, including multimedia analysis, human-computer interaction, and embodied AI research.",
      "authors": [
        "Sahiti Yerramilli",
        "Jayant Sravan Tamarapalli",
        "Jonathan Francis",
        "Eric Nyberg"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-02T23:05:56+00:00",
          "link": "https://arxiv.org/abs/2404.02359v1",
          "size": "15kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T04:52:34+00:00",
          "link": "https://arxiv.org/abs/2404.02359v2",
          "size": "15kb",
          "version": "v2"
        }
      ],
      "title": "Attribution Regularization for Multimodal Paradigms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.02359",
        "HTML": "https://arxiv.org/html/2404.02359v2",
        "PDF": "https://arxiv.org/pdf/2404.02359"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on regularization for multimodal machine learning, particularly in video-audio domains, not on LLM training data processing."
      },
      "tasks": [
        "Decision Making"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.04204",
      "abstract": "Eliciting information to reduce uncertainty about a latent entity is a critical task in many application domains, e.g., assessing individual student learning outcomes, diagnosing underlying diseases, or learning user preferences. Though natural language is a powerful medium for this purpose, large language models (LLMs) and existing fine-tuning algorithms lack mechanisms for strategically gathering information to refine their own understanding of the latent entity. To harness the generalization power and world knowledge of LLMs in developing effective information-gathering strategies, we propose an adaptive elicitation framework that actively reduces uncertainty on the latent entity. Since probabilistic modeling of an abstract latent entity is difficult, our framework adopts a predictive view of uncertainty, using a meta-learned language model to simulate future observations and enable scalable uncertainty quantification over complex natural language. Through autoregressive forward simulation, our model quantifies how new questions reduce epistemic uncertainty, enabling the development of sophisticated information-gathering strategies to choose the most informative next queries. In experiments on the 20 questions game, dynamic opinion polling, and adaptive student assessment, our method consistently outperforms baselines in identifying critical unknowns and improving downstream predictions, illustrating the promise of strategic information gathering in natural language settings.",
      "authors": [
        "Jimmy Wang",
        "Thomas Zollo",
        "Richard Zemel",
        "Hongseok Namkoong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-05T15:18:55+00:00",
          "link": "https://arxiv.org/abs/2504.04204v1",
          "size": "6190kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T13:58:35+00:00",
          "link": "https://arxiv.org/abs/2504.04204v2",
          "size": "6214kb",
          "version": "v2"
        }
      ],
      "title": "Adaptive Elicitation of Latent Information Using Natural Language",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.04204",
        "HTML": "https://arxiv.org/html/2504.04204v2",
        "PDF": "https://arxiv.org/pdf/2504.04204"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a framework for adaptive elicitation using LLMs to reduce uncertainty about latent entities, focusing on information-gathering strategies rather than LLM training data processing."
      },
      "datasets": [
        {
          "dataset_name": "namkoong-lab/TwentyQuestions",
          "downloads": "6",
          "likes": "1",
          "link": "https://huggingface.co/datasets/namkoong-lab/TwentyQuestions"
        }
      ],
      "tasks": [
        "Uncertainty Quantification",
        "World Knowledge"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.07793",
      "abstract": "Out-of-distribution (OOD) detection is critical for ensuring the reliability of deep learning systems, particularly in safety-critical applications. Likelihood-based deep generative models have historically faced criticism for their unsatisfactory performance in OOD detection, often assigning higher likelihood to OOD data than in-distribution samples when applied to image data. In this work, we demonstrate that likelihood is not inherently flawed. Rather, several properties in the images space prohibit likelihood as a valid detection score. Given a sufficiently good likelihood estimator, specifically using the probability flow formulation of a diffusion model, we show that likelihood-based methods can still perform on par with state-of-the-art methods when applied in the representation space of pre-trained encoders. The code of our work can be found at $\\href{https://github.com/limchaos/Likelihood-OOD.git}{\\texttt{https://github.com/limchaos/Likelihood-OOD.git}}$.",
      "authors": [
        "Yifan Ding",
        "Arturas Aleksandraus",
        "Amirhossein Ahmadian",
        "Jonas Unger",
        "Fredrik Lindsten and Gabriel Eilertsen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-10T14:30:41+00:00",
          "link": "https://arxiv.org/abs/2504.07793v1",
          "size": "2779kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T12:32:02+00:00",
          "link": "https://arxiv.org/abs/2504.07793v2",
          "size": "2780kb",
          "version": "v2"
        }
      ],
      "title": "Revisiting Likelihood-Based Out-of-Distribution Detection by Modeling Representations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.07793",
        "HTML": "https://arxiv.org/html/2504.07793v2",
        "PDF": "https://arxiv.org/pdf/2504.07793"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses likelihood-based out-of-distribution detection by modeling representations, focusing on improving detection methods rather than LLM training data processing."
      },
      "tasks": [
        "Out-of-Distribution Detection",
        "Out of Distribution (OOD) Detection",
        "valid"
      ],
      "repo_urls": [
        "https://github.com/limchaos/likelihood-ood"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06244",
      "abstract": "Since many applications and services require pseudorandom numbers (PRNs), it is feasible to generate specific PRNs under given key values and input messages using Key Derivation Functions (KDFs). These KDFs are primarily constructed based on Message Authentication Codes (MACs), where the MAC serves as a core component in the generation of pseudorandom numbers. In light of this, the study first examines three MAC algorithms defined by the National Institute of Standards and Technology (NIST): the Keyed-Hash Message Authentication Code (HMAC), the Cipher-based Message Authentication Code (CMAC), and the Keccak-based Message Authentication Code (KMAC). Subsequently, the study explores KDFs based on these MACs, including the Counter Mode KDF, the KMAC-based KDF, and the KDF defined in IEEE 1609.2.1. In experiments, the computation times for generating MACs and the corresponding pseudorandom numbers using each KDF are evaluated. The study further analyzes the advantages, disadvantages, and applicable scenarios for each method. Experimental results indicate that the CMAC and the CMAC-based KDF exhibit the shortest computation times, averaging approximately 0.007 milliseconds and 0.014 milliseconds, respectively.",
      "authors": [
        "Abel C. H. Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Performance (cs.PF)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T23:56:31+00:00",
          "link": "https://arxiv.org/abs/2507.06244v1",
          "size": "755kb",
          "version": "v1"
        }
      ],
      "title": "A Comparative Study and Implementation of Key Derivation Functions Standardized by NIST and IEEE",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06244",
        "PDF": "https://arxiv.org/pdf/2507.06244"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study analyzes key derivation functions and their performance, which are not relevant to LLM training data processing or collection."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07008",
      "abstract": "Used as priors for Bayesian inverse problems, diffusion models have recently attracted considerable attention in the literature. Their flexibility and high variance enable them to generate multiple solutions for a given task, such as inpainting, super-resolution, and deblurring. However, several unresolved questions remain about how well they perform. In this article, we investigate the accuracy of these models when applied to a Gaussian data distribution for deblurring. Within this constrained context, we are able to precisely analyze the discrepancy between the theoretical resolution of inverse problems and their resolution obtained using diffusion models by computing the exact Wasserstein distance between the distribution of the diffusion model sampler and the ideal distribution of solutions to the inverse problem. Our findings allow for the comparison of different algorithms from the literature.",
      "authors": [
        "Emile Pierret",
        "Bruno Galerne"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T16:36:51+00:00",
          "link": "https://arxiv.org/abs/2507.07008v1",
          "size": "15439kb",
          "version": "v1"
        }
      ],
      "title": "Exact Evaluation of the Accuracy of Diffusion Models for Inverse Problems with Gaussian Data Distributions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07008",
        "HTML": "https://arxiv.org/html/2507.07008v1",
        "PDF": "https://arxiv.org/pdf/2507.07008"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates diffusion models in relation to inverse problems and Gaussian data distributions, without emphasis on LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2301.02732",
      "abstract": "Despite the recent increase in research on artificial intelligence for music, prominent correlations between key components of lyrics and rhythm such as keywords, stressed syllables, and strong beats are not frequently studied. This is likely due to challenges such as audio misalignment, inaccuracies in syllabic identification, and most importantly, the need for cross-disciplinary knowledge. To address this lack of research, we propose a novel multimodal lyrics-rhythm matching approach in this paper that specifically matches key components of lyrics and music with each other without any language limitations. We use audio instead of sheet music with readily available metadata, which creates more challenges yet increases the application flexibility of our method. Furthermore, our approach creatively generates several patterns involving various multimodalities, including music strong beats, lyrical syllables, auditory changes in a singer's pronunciation, and especially lyrical keywords, which are utilized for matching key lyrical elements with key rhythmic elements. This advantageous approach not only provides a unique way to study auditory lyrics-rhythm correlations including efficient rhythm-based audio alignment algorithms, but also bridges computational linguistics with music as well as music cognition. Our experimental results reveal an 0.81 probability of matching on average, and around 30% of the songs have a probability of 0.9 or higher of keywords landing on strong beats, including 12% of the songs with a perfect landing. Also, the similarity metrics are used to evaluate the correlation between lyrics and rhythm. It shows that nearly 50% of the songs have 0.70 similarity or higher. In conclusion, our approach contributes significantly to the lyrics-rhythm relationship by computationally unveiling insightful correlations.",
      "authors": [
        "Callie C. Liao",
        "Duoduo Liao",
        "Jesse Guessford"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Machine Learning (cs.LG)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2023-01-06T22:24:53+00:00",
          "link": "https://arxiv.org/abs/2301.02732v1",
          "size": "967kb",
          "version": "v1"
        },
        {
          "date": "2023-03-15T01:12:22+00:00",
          "link": "https://arxiv.org/abs/2301.02732v2",
          "size": "972kb",
          "version": "v2"
        }
      ],
      "title": "Multimodal Lyrics-Rhythm Matching",
      "links": {
        "Abstract": "https://arxiv.org/abs/2301.02732",
        "PDF": "https://arxiv.org/pdf/2301.02732"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on multimodal lyrics-rhythm matching in music and does not discuss any aspect of LLM training data collection, processing, or engineering."
      },
      "tasks": [
        "Rhythm"
      ],
      "source": "arXiv"
    },
    {
      "id": "2403.05427",
      "abstract": "Using stickers in online chatting is very prevalent on social media platforms, where the stickers used in the conversation can express someone's intention/emotion/attitude in a vivid, tactful, and intuitive way. Existing sticker retrieval research typically retrieves stickers based on context and the current utterance delivered by the user. That is, the stickers serve as a supplement to the current utterance. However, in the real-world scenario, using stickers to express what we want to say rather than as a supplement to our words only is also important. Therefore, in this paper, we create a new dataset for sticker retrieval in conversation, called \\textbf{StickerInt}, where stickers are used to reply to previous conversations or supplement our words. Based on the created dataset, we present a simple yet effective framework for sticker retrieval in conversation based on the learning of intention and the cross-modal relationships between conversation context and stickers, coined as \\textbf{Int-RA}. Specifically, we first devise a knowledge-enhanced intention predictor to introduce the intention information into the conversation representations. Subsequently, a relation-aware sticker selector is devised to retrieve the response sticker via cross-modal relationships. Extensive experiments on two datasets show that the proposed model achieves state-of-the-art performance and generalization capability in sticker retrieval. The dataset and source code of this work are released at https://github.com/HITSZ-HLT/Int-RA.",
      "authors": [
        "Bin Liang",
        "Bingbing Wang",
        "Zhixin Bai",
        "Qiwei Lang",
        "Mingwei Sun",
        "Kaiheng Hou",
        "Lanjun Zhou",
        "Ruifeng Xu",
        "Kam-Fai Wong"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-08T16:24:42+00:00",
          "link": "https://arxiv.org/abs/2403.05427v1",
          "size": "2849kb",
          "version": "v1"
        },
        {
          "date": "2024-07-22T09:51:02+00:00",
          "link": "https://arxiv.org/abs/2403.05427v2",
          "size": "3950kb",
          "version": "v2"
        },
        {
          "date": "2024-12-27T19:52:04+00:00",
          "link": "https://arxiv.org/abs/2403.05427v3",
          "size": "3805kb",
          "version": "v3"
        },
        {
          "date": "2025-07-06T08:34:06+00:00",
          "link": "https://arxiv.org/abs/2403.05427v4",
          "size": "3650kb",
          "version": "v4"
        },
        {
          "date": "2025-07-09T13:28:57+00:00",
          "link": "https://arxiv.org/abs/2403.05427v5",
          "size": "2537kb",
          "version": "v5"
        }
      ],
      "title": "Reply with Sticker: New Dataset and Model for Sticker Retrieval",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.05427",
        "HTML": "https://arxiv.org/html/2403.05427v5",
        "PDF": "https://arxiv.org/pdf/2403.05427"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper presents the creation of a new dataset (StickerInt) with detailed processing steps for sticker retrieval, contributing directly to training-data processing via dataset creation."
      },
      "repo_urls": [
        "https://github.com/hitsz-hlt/int-ra"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.19204",
      "abstract": "Incorporating cloud technology with Internet of Medical Things for ubiquitous healthcare has seen many successful applications in the last decade with the advent of machine learning and deep learning techniques. One of these applications, namely voice-based pathology, has yet to receive notable attention from academia and industry. Applying voice analysis to early detection of fatal diseases holds much promise to improve health outcomes and quality of life of patients. In this paper, we propose a novel application of acoustic machine learning based triaging into commoditised conversational virtual assistant systems to pre-screen for onset of diabetes. Specifically, we developed a triaging system which extracts acoustic features from the voices of n=24 older adults when they converse with a virtual assistant and predict the incidence of Diabetes Mellitus (Type 2) or not. Our triaging system achieved hit-rates of 70% and 60% for male and female older adult subjects, respectively. Our proposed triaging uses 7 non-identifiable voice-based features and can operate within resource-constrained embedded systems running voice-based virtual assistants. This application demonstrates the feasibility of applying voice-based pathology analysis to improve health outcomes of older adults within the home environment by early detection of life-changing chronic conditions like diabetes.",
      "authors": [
        "Kelvin Summoogum",
        "Debayan Das",
        "Sathish Kumaran"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-28T15:23:48+00:00",
          "link": "https://arxiv.org/abs/2411.19204v1",
          "size": "550kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T23:01:50+00:00",
          "link": "https://arxiv.org/abs/2411.19204v2",
          "size": "683kb",
          "version": "v2"
        }
      ],
      "title": "A Voice-based Triage for Type 2 Diabetes using a Conversational Virtual Assistant in the Home Environment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.19204",
        "PDF": "https://arxiv.org/pdf/2411.19204"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on voice-based triaging for diabetes detection using virtual assistants, with no involvement in the realm of LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06258",
      "abstract": "Federated recommender systems (FedRec) have emerged as a promising solution for delivering personalized recommendations while safeguarding user privacy. However, recent studies have demonstrated their vulnerability to poisoning attacks. Existing attacks typically target the entire user group, which compromises stealth and increases the risk of detection. In contrast, real-world adversaries may prefer to prompt target items to specific user subgroups, such as recommending health supplements to elderly users. Motivated by this gap, we introduce Spattack, the first targeted poisoning attack designed to manipulate recommendations for specific user subgroups in the federated setting. Specifically, Spattack adopts a two-stage approximation-and-promotion strategy, which first simulates user embeddings of target/non-target subgroups and then prompts target items to the target subgroups. To enhance the approximation stage, we push the inter-group embeddings away based on contrastive learning and augment the target group's relevant item set based on clustering. To enhance the promotion stage, we further propose to adaptively tune the optimization weights between target and non-target subgroups. Besides, an embedding alignment strategy is proposed to align the embeddings between the target items and the relevant items. We conduct comprehensive experiments on three real-world datasets, comparing Spattack against seven state-of-the-art poisoning attacks and seven representative defense mechanisms. Experimental results demonstrate that Spattack consistently achieves strong manipulation performance on the specific user subgroup, while incurring minimal impact on non-target users, even when only 0.1\\% of users are malicious. Moreover, Spattack maintains competitive overall recommendation performance and exhibits strong resilience against existing mainstream defenses.",
      "authors": [
        "Bo Yan",
        "Yurong Hao",
        "Dingqi Liu",
        "Huabin Sun",
        "Pengpeng Qiao",
        "Wei Yang Bryan Lim",
        "Yang Cao",
        "Chuan Shi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T09:40:16+00:00",
          "link": "https://arxiv.org/abs/2507.06258v1",
          "size": "767kb",
          "version": "v1"
        }
      ],
      "title": "Phantom Subgroup Poisoning: Stealth Attacks on Federated Recommender Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06258",
        "HTML": "https://arxiv.org/html/2507.06258v1",
        "PDF": "https://arxiv.org/pdf/2507.06258"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study focuses on poisoning attacks on federated recommender systems, which do not pertain to processing or engineering of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06733",
      "abstract": "Medical anomaly detection (AD) is challenging due to diverse imaging modalities, anatomical variations, and limited labeled data. We propose a novel approach combining visual adapters and prompt learning with Partial Optimal Transport (POT) and contrastive learning (CL) to improve CLIP's adaptability to medical images, particularly for AD. Unlike standard prompt learning, which often yields a single representation, our method employs multiple prompts aligned with local features via POT to capture subtle abnormalities. CL further enforces intra-class cohesion and inter-class separation. Our method achieves state-of-the-art results in few-shot, zero-shot, and cross-dataset scenarios without synthetic data or memory banks. The code is available at https://github.com/mahshid1998/MADPOT.",
      "authors": [
        "Mahshid Shiri and Cigdem Beyan and Vittorio Murino"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T10:45:52+00:00",
          "link": "https://arxiv.org/abs/2507.06733v1",
          "size": "1320kb",
          "version": "v1"
        }
      ],
      "title": "MADPOT: Medical Anomaly Detection with CLIP Adaptation and Partial Optimal Transport",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06733",
        "HTML": "https://arxiv.org/html/2507.06733v1",
        "PDF": "https://arxiv.org/pdf/2507.06733"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a method for medical anomaly detection using CLIP adaptation and partial optimal transport, with no focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06366",
      "abstract": "Predicting the binding affinity of protein-ligand complexes plays a vital role in drug discovery. Unfortunately, progress has been hindered by the lack of large-scale and high-quality binding affinity labels. The widely used PDBbind dataset has fewer than 20K labeled complexes. Self-supervised learning, especially graph contrastive learning (GCL), provides a unique opportunity to break the barrier by pre-training graph neural network models based on vast unlabeled complexes and fine-tuning the models on much fewer labeled complexes. However, the problem faces unique challenges, including a lack of a comprehensive unlabeled dataset with well-defined positive/negative complex pairs and the need to design GCL algorithms that incorporate the unique characteristics of such data. To fill the gap, we propose DecoyDB, a large-scale, structure-aware dataset specifically designed for self-supervised GCL on protein-ligand complexes. DecoyDB consists of high-resolution ground truth complexes (less than 2.5 Angstrom) and diverse decoy structures with computationally generated binding poses that range from realistic to suboptimal (negative pairs). Each decoy is annotated with a Root Mean Squared Deviation (RMSD) from the native pose. We further design a customized GCL framework to pre-train graph neural networks based on DecoyDB and fine-tune the models with labels from PDBbind. Extensive experiments confirm that models pre-trained with DecoyDB achieve superior accuracy, label efficiency, and generalizability.",
      "authors": [
        "Yupu Zhang",
        "Zelin Xu",
        "Tingsong Xiao",
        "Gustavo Seabra",
        "Yanjun Li",
        "Chenglong Li",
        "Zhe Jiang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Biomolecules (q-bio.BM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T20:02:53+00:00",
          "link": "https://arxiv.org/abs/2507.06366v1",
          "size": "242kb",
          "version": "v1"
        }
      ],
      "title": "DecoyDB: A Dataset for Graph Contrastive Learning in Protein-Ligand Binding Affinity Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06366",
        "HTML": "https://arxiv.org/html/2507.06366v1",
        "PDF": "https://arxiv.org/pdf/2507.06366"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper presents DecoyDB, a new dataset designed for self-supervised graph contrastive learning on protein-ligand complexes, with detailed data processing steps for data quality enhancement. It is primarily focused on dataset creation and processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07024",
      "abstract": "We introduce FlexOlmo, a new class of language models (LMs) that supports (1) distributed training without data sharing, where different model parameters are independently trained on closed datasets, and (2) data-flexible inference, where these parameters along with their associated data can be flexibly included or excluded from model inferences with no further training. FlexOlmo employs a mixture-of-experts (MoE) architecture where each expert is trained independently on closed datasets and later integrated through a new domain-informed routing without any joint training. FlexOlmo is trained on FlexMix, a corpus we curate comprising publicly available datasets alongside seven domain-specific sets, representing realistic approximations of closed sets. We evaluate models with up to 37 billion parameters (20 billion active) on 31 diverse downstream tasks. We show that a general expert trained on public data can be effectively combined with independently trained experts from other data owners, leading to an average 41% relative improvement while allowing users to opt out of certain data based on data licensing or permission requirements. Our approach also outperforms prior model merging methods by 10.1% on average and surpasses the standard MoE trained without data restrictions using the same training FLOPs. Altogether, this research presents a solution for both data owners and researchers in regulated industries with sensitive or protected data. FlexOlmo enables benefiting from closed data while respecting data owners' preferences by keeping their data local and supporting fine-grained control of data access during inference.",
      "authors": [
        "Weijia Shi",
        "Akshita Bhagia",
        "Kevin Farhat",
        "Niklas Muennighoff",
        "Pete Walsh",
        "Jacob Morrison",
        "Dustin Schwenk",
        "Shayne Longpre",
        "Jake Poznanski",
        "Allyson Ettinger",
        "Daogao Liu",
        "Margaret Li",
        "Dirk Groeneveld",
        "Mike Lewis",
        "Wen-tau Yih",
        "Luca Soldaini",
        "Kyle Lo",
        "Noah A. Smith",
        "Luke Zettlemoyer",
        "Pang Wei Koh",
        "Hannaneh Hajishirzi",
        "Ali Farhadi",
        "Sewon Min"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T16:54:21+00:00",
          "link": "https://arxiv.org/abs/2507.07024v1",
          "size": "825kb",
          "version": "v1"
        }
      ],
      "title": "FlexOlmo: Open Language Models for Flexible Data Use",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07024",
        "HTML": "https://arxiv.org/html/2507.07024v1",
        "PDF": "https://arxiv.org/pdf/2507.07024"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces a method for data usage during inference and discusses dataset curation, the primary focus is on a model architecture (MoE) and does not primarily detail training-data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06788",
      "abstract": "In this paper we propose a dynamic output-feedback controller synthesis method for discrete-time linear time-invariant systems. The synthesis goal is to render closed-loop system dissipative with respect to a given generic unstructured quadratic supply rate, while the system dynamics is partially represented by input-state data corrupted by a bounded disturbance. The controller synthesis is performed with respect to all systems which are consistent with the available data, and it is formulated in terms of a linear matrix inequality parametrized by a scalar variable, so that the synthesis can be performed using line search and convex optimization. Within the considered setting, the proposed synthesis procedure is non-conservative in a sense that it is based on conditions which are both necessary and sufficient.",
      "authors": [
        "Pietro Kristovi\\'c",
        "Andrej Joki\\'c",
        "Mircea Lazar"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T12:24:25+00:00",
          "link": "https://arxiv.org/abs/2507.06788v1",
          "size": "162kb",
          "version": "v1"
        }
      ],
      "title": "Dynamic Output-Feedback Controller Synthesis for Dissipativity from Noisy Input-State Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06788",
        "HTML": "https://arxiv.org/html/2507.06788v1",
        "PDF": "https://arxiv.org/pdf/2507.06788"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a controller synthesis method for linear systems with partial data, with no relation to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06444",
      "abstract": "Accurate accident anticipation remains challenging when driver cognition and dynamic road conditions are underrepresented in predictive models. In this paper, we propose CAMERA (Context-Aware Multi-modal Enhanced Risk Anticipation), a multi-modal framework integrating dashcam video, textual annotations, and driver attention maps for robust accident anticipation. Unlike existing methods that rely on static or environment-centric thresholds, CAMERA employs an adaptive mechanism guided by scene complexity and gaze entropy, reducing false alarms while maintaining high recall in dynamic, multi-agent traffic scenarios. A hierarchical fusion pipeline with Bi-GRU (Bidirectional GRU) captures spatio-temporal dependencies, while a Geo-Context Vision-Language module translates 3D spatial relationships into interpretable, human-centric alerts. Evaluations on the DADA-2000 and benchmarks show that CAMERA achieves state-of-the-art performance, improving accuracy and lead time. These results demonstrate the effectiveness of modeling driver attention, contextual description, and adaptive risk thresholds to enable more reliable accident anticipation.",
      "authors": [
        "Jiaxun Zhang",
        "Haicheng Liao",
        "Yumu Xie",
        "Chengyue Wang",
        "Yanchen Guan",
        "Bin Rao",
        "Zhenning Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T23:06:36+00:00",
          "link": "https://arxiv.org/abs/2507.06444v1",
          "size": "5083kb",
          "version": "v1"
        }
      ],
      "title": "Eyes on the Road, Mind Beyond Vision: Context-Aware Multi-modal Enhanced Risk Anticipation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06444",
        "HTML": "https://arxiv.org/html/2507.06444v1",
        "PDF": "https://arxiv.org/pdf/2507.06444"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a multi-modal framework for risk anticipation in driving but does not involve LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06472",
      "abstract": "Process mining leverages event data extracted from IT systems to generate insights into the business processes of organizations. Such insights benefit from explicitly considering the frequency of behavior in business processes, which is captured by stochastic process models. Given an observed trace and a stochastic process model, conventional alignment-based conformance checking techniques face a fundamental limitation: They prioritize matching the trace to a model path with minimal deviations, which may, however, lead to selecting an unlikely path. In this paper, we study the problem of matching an observed trace to a stochastic process model by identifying a likely model path with a low edit distance to the trace. We phrase this as an optimization problem and develop a heuristic-guided path-finding algorithm to solve it. Our open-source implementation demonstrates the feasibility of the approach and shows that it can provide new, useful diagnostic insights for analysts.",
      "authors": [
        "Tian Li",
        "Artem Polyvyanyy",
        "and Sander J.J. Leemans"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Formal Languages and Automata Theory (cs.FL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T01:20:53+00:00",
          "link": "https://arxiv.org/abs/2507.06472v1",
          "size": "828kb",
          "version": "v1"
        }
      ],
      "title": "Stochastic Alignments: Matching an Observed Trace to Stochastic Process Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06472",
        "HTML": "https://arxiv.org/html/2507.06472v1",
        "PDF": "https://arxiv.org/pdf/2507.06472"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper studies the alignment of observed traces to stochastic process models for process mining. It does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2310.15460",
      "abstract": "The consensus algorithm is crucial in blockchain for ensuring the validity and security of transactions across the decentralized network. However, achieving consensus among nodes and packaging blocks in blockchain networks is a complex task that requires efficient and secure consensus algorithms. The DPoS consensus algorithm has emerged as a popular choice due to its fast transaction processing and high throughput. Despite these advantages, the algorithm still suffers from weaknesses such as centralization and vulnerability to long-range attacks, which can compromise the integrity of the blockchain network.\n  To combat these problems, we developed an Enhanced Anti-Long-Range Attack DPoS algorithm (HL-DPoS). First, we split nodes into pieces to reduce centralization issues while giving witness nodes the power to report and benefit from malicious node's reports, maintaining high efficiency and high security. Second, we propose a validation method in HL-DPoS that compares consensuses transactions with the longest chain to detect long-range attacks. Algorithm analysis and simulation experiment results demonstrate that our HL-DPoS consensus algorithm improves security while achieving better consensus performance.",
      "authors": [
        "Yang Li",
        "Chunhe Xia",
        "Chunyan Li",
        "Yuan Zhao",
        "Chen Chen",
        "Tianbo Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2023-10-24T02:21:25+00:00",
          "link": "https://arxiv.org/abs/2310.15460v1",
          "size": "1446kb",
          "version": "v1"
        }
      ],
      "title": "HL-DPoS: An Enhanced Anti-Long-Range Attack DPoS Algorithm",
      "links": {
        "Abstract": "https://arxiv.org/abs/2310.15460",
        "PDF": "https://arxiv.org/pdf/2310.15460"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on enhancing a blockchain consensus algorithm and does not mention any aspect of LLM training data processing or data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.09200",
      "abstract": "In this paper, we investigate the Domain Name System (DNS) over QUIC (DoQ) and propose a non-disruptive extension, which can greatly reduce DoQ's resource consumption. This extension can benefit all DNS clients - especially Internet of Things (IoT) devices. This is important because even resource-constrained IoT devices can generate dozens of DNS requests every hour. DNS is a crucial service that correlates IP addresses and domain names. It is traditionally sent as plain-text, favoring low-latency results over security and privacy. The repercussion of this can be eavesdropping and information leakage about IoT devices. To address these concerns, the newest and most promising solution is DoQ. QUIC offers features similar to TCP and TLS while also supporting early data delivery and stream multiplexing. DoQ's specification requires that DNS exchanges occur over independent streams in a long-lived QUIC connection. Our hypothesis is that due to DNS's typically high transaction volume, managing QUIC streams may be overly resource intensive for IoT devices. Therefore, we have designed and implemented a data delivery mode for DoQ using QUIC datagrams, which we believe to be more preferable than stream-based delivery. To test our theory, we analyzed the memory, CPU, signaling, power, and time of each DoQ delivery mode in a setup generating real queries and network traffic. Our novel datagram-based delivery mode proved to be decisively more resource-friendly with little compromise in terms of functionality or performance. Furthermore, our paper is the first to investigate multiple queries over DoQ, to our knowledge.",
      "authors": [
        "Darius Saif and Ashraf Matrawy"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-12T12:59:37+00:00",
          "link": "https://arxiv.org/abs/2504.09200v1",
          "size": "877kb",
          "version": "v1"
        },
        {
          "date": "2025-06-04T18:35:11+00:00",
          "link": "https://arxiv.org/abs/2504.09200v2",
          "size": "3208kb",
          "version": "v2"
        }
      ],
      "title": "A Datagram Extension to DNS over QUIC: Proven Resource Conservation in the Internet of Things",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.09200",
        "HTML": "https://arxiv.org/html/2504.09200",
        "PDF": "https://arxiv.org/pdf/2504.09200"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on an extension to DNS over QUIC to conserve resources in IoT settings, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06332",
      "abstract": "Deep neural networks suffer from significant performance degradation when exposed to common corruptions such as noise, blur, weather, and digital distortions, limiting their reliability in real-world applications. In this paper, we propose AR2 (Attention-Guided Repair for Robustness), a simple yet effective method to enhance the corruption robustness of pretrained CNNs. AR2 operates by explicitly aligning the class activation maps (CAMs) between clean and corrupted images, encouraging the model to maintain consistent attention even under input perturbations. Our approach follows an iterative repair strategy that alternates between CAM-guided refinement and standard fine-tuning, without requiring architectural changes. Extensive experiments show that AR2 consistently outperforms existing state-of-the-art methods in restoring robustness on standard corruption benchmarks (CIFAR-10-C, CIFAR-100-C and ImageNet-C), achieving a favorable balance between accuracy on clean data and corruption robustness. These results demonstrate that AR2 provides a robust and scalable solution for enhancing model reliability in real-world environments with diverse corruptions.",
      "authors": [
        "Fuyuan Zhang",
        "Qichen Wang",
        "Jianjun Zhao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T18:37:00+00:00",
          "link": "https://arxiv.org/abs/2507.06332v1",
          "size": "1356kb",
          "version": "v1"
        }
      ],
      "title": "AR2: Attention-Guided Repair for the Robustness of CNNs Against Common Corruptions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06332",
        "HTML": "https://arxiv.org/html/2507.06332v1",
        "PDF": "https://arxiv.org/pdf/2507.06332"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving robustness of CNNs against common corruptions through a method called AR2, involving CAM-guided refinement and fine-tuning, but it does not discuss any aspects of LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06363",
      "abstract": "In recent years, artificial intelligence has significantly advanced medical image segmentation. However, challenges remain, including efficient 3D medical image processing across diverse modalities and handling data variability. In this work, we introduce Hierarchical Soft Mixture-of-Experts (HoME), a two-level token-routing layer for efficient long-context modeling, specifically designed for 3D medical image segmentation. Built on the Mamba state-space model (SSM) backbone, HoME enhances sequential modeling through sparse, adaptive expert routing. The first stage employs a Soft Mixture-of-Experts (SMoE) layer to partition input sequences into local groups, routing tokens to specialized per-group experts for localized feature extraction. The second stage aggregates these outputs via a global SMoE layer, enabling cross-group information fusion and global context refinement. This hierarchical design, combining local expert routing with global expert refinement improves generalizability and segmentation performance, surpassing state-of-the-art results across datasets from the three most commonly used 3D medical imaging modalities and data quality.",
      "authors": [
        "Szymon P{\\l}otka",
        "Maciej Chrabaszcz",
        "Gizem Mert",
        "Ewa Szczurek",
        "Arkadiusz Sitek"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T19:57:27+00:00",
          "link": "https://arxiv.org/abs/2507.06363v1",
          "size": "29914kb",
          "version": "v1"
        }
      ],
      "title": "Mamba Goes HoME: Hierarchical Soft Mixture-of-Experts for 3D Medical Image Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06363",
        "HTML": "https://arxiv.org/html/2507.06363v1",
        "PDF": "https://arxiv.org/pdf/2507.06363"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a mixture-of-experts model for medical image segmentation, focusing on token routing and model architecture improvements. There is no mention of LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06779",
      "abstract": "Despite the growing success of deep learning (DL) in offline brain-computer interfaces (BCIs), its adoption in real-time applications remains limited due to three primary challenges. First, most DL solutions are designed for offline decoding, making the transition to online decoding unclear. Second, the use of sliding windows in online decoding substantially increases computational complexity. Third, DL models typically require large amounts of training data, which are often scarce in BCI applications. To address these challenges and enable real-time, cross-subject decoding without subject-specific calibration, we introduce realtime adaptive pooling (RAP), a novel parameter-free method. RAP seamlessly modifies the pooling layers of existing offline DL models to meet online decoding requirements. It also reduces computational complexity during training by jointly decoding consecutive sliding windows. To further alleviate data requirements, our method leverages source-free domain adaptation, enabling privacy-preserving adaptation across varying amounts of target data. Our results demonstrate that RAP provides a robust and efficient framework for real-time BCI applications. It preserves privacy, reduces calibration demands, and supports co-adaptive BCI systems, paving the way for broader adoption of DL in online BCIs. These findings lay a strong foundation for developing user-centered, high-performance BCIs that facilitate immediate feedback and user learning.",
      "authors": [
        "Martin Wimpff",
        "Jan Zerfowski",
        "Bin Yang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T12:11:19+00:00",
          "link": "https://arxiv.org/abs/2507.06779v1",
          "size": "1583kb",
          "version": "v1"
        }
      ],
      "title": "Tailoring deep learning for real-time brain-computer interfaces: From offline models to calibration-free online decoding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06779",
        "HTML": "https://arxiv.org/html/2507.06779v1",
        "PDF": "https://arxiv.org/pdf/2507.06779"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on adapting deep learning models for real-time brain-computer interfaces and not on processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07067",
      "abstract": "Training effective artificial intelligence models for telecommunications is challenging due to the scarcity of deployment-specific data. Real data collection is expensive, and available datasets often fail to capture the unique operational conditions and contextual variability of the network environment. Digital twinning provides a potential solution to this problem, as simulators tailored to the current network deployment can generate site-specific data to augment the available training datasets. However, there is a need to develop solutions to bridge the inherent simulation-to-reality (sim-to-real) gap between synthetic and real-world data. This paper reviews recent advances on two complementary strategies: 1) the calibration of digital twins (DTs) through real-world measurements, and 2) the use of sim-to-real gap-aware training strategies to robustly handle residual discrepancies between digital twin-generated and real data. For the latter, we evaluate two conceptually distinct methods that model the sim-to-real gap either at the level of the environment via Bayesian learning or at the level of the training loss via prediction-powered inference.",
      "authors": [
        "Clement Ruah",
        "Houssem Sifaou",
        "Osvaldo Simeone",
        "Bashir M. Al-Hashimi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T17:27:51+00:00",
          "link": "https://arxiv.org/abs/2507.07067v1",
          "size": "2651kb",
          "version": "v1"
        }
      ],
      "title": "How to Bridge the Sim-to-Real Gap in Digital Twin-Aided Telecommunication Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07067",
        "HTML": "https://arxiv.org/html/2507.07067v1",
        "PDF": "https://arxiv.org/pdf/2507.07067"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper discusses digital twin-aided data generation to bridge the sim-to-real gap, which involves augmenting training datasets, but it is more focused on telecommunication networks rather than LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.03088",
      "abstract": "The Segment Anything Model (SAM) has demonstrated strong versatility across various visual tasks. However, its large storage requirements and high computational cost pose challenges for practical deployment. Post-training quantization (PTQ) has emerged as an effective strategy for efficient deployment, but we identify two key challenges in SAM that hinder the effectiveness of existing PTQ methods: the heavy-tailed and skewed distribution of post-GELU activations, and significant inter-channel variation in linear projection activations. To address these challenges, we propose AHCPTQ, an accurate and hardware-efficient PTQ method for SAM. AHCPTQ introduces hardware-compatible Hybrid Log-Uniform Quantization (HLUQ) to manage post-GELU activations, employing log2 quantization for dense small values and uniform quantization for sparse large values to enhance quantization resolution. Additionally, AHCPTQ incorporates Channel-Aware Grouping (CAG) to mitigate inter-channel variation by progressively clustering activation channels with similar distributions, enabling them to share quantization parameters and improving hardware efficiency. The combination of HLUQ and CAG not only enhances quantization effectiveness but also ensures compatibility with efficient hardware execution. For instance, under the W4A4 configuration on the SAM-L model, AHCPTQ achieves 36.6% mAP on instance segmentation with the DINO detector, while achieving a 7.89x speedup and 8.64x energy efficiency over its floating-point counterpart in FPGA implementation.",
      "authors": [
        "Wenlun Zhang and Yunshan Zhong and Shimpei Ando and Kentaro Yoshioka"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Hardware Architecture (cs.AR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-05T01:04:45+00:00",
          "link": "https://arxiv.org/abs/2503.03088v1",
          "size": "2968kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T08:26:21+00:00",
          "link": "https://arxiv.org/abs/2503.03088v2",
          "size": "4034kb",
          "version": "v2"
        }
      ],
      "title": "AHCPTQ: Accurate and Hardware-Compatible Post-Training Quantization for Segment Anything Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.03088",
        "HTML": "https://arxiv.org/html/2503.03088v2",
        "PDF": "https://arxiv.org/pdf/2503.03088"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on an efficient post-training quantization method for a visual model, SAM, rather than processing LLM training data."
      },
      "tasks": [
        "Instance Segmentation",
        "Quantization",
        "Semantic Segmentation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06416",
      "abstract": "Recent boom in foundation models and AI computing have raised growing concerns on the power and energy trajectories of large-scale data centers. This paper focuses on the voltage issues caused by volatile and intensity of data center power demand, which also aligns with recent observations of more frequent voltage disturbances in power grids. To address these data center integration challenges, we propose a dynamic voltage control scheme by harnessing data center's load regulation capabilities. By taking local voltage measurements and adjusting power injections at each data center buses through the dynamic voltage and frequency scaling (DVFS) scheme, we are able to maintain safe voltage magnitude in a distributed fashion with higher data center computing load. Simulations using real large language model (LLM) inference load validate the effectiveness of our proposed mechanism. Both the LLM power data and proposed control scheme are open sourced.",
      "authors": [
        "Yize Chen",
        "Baosen Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T21:44:51+00:00",
          "link": "https://arxiv.org/abs/2507.06416v1",
          "size": "3078kb",
          "version": "v1"
        }
      ],
      "title": "Voltage Regulation in Distribution Systems with Data Center Loads",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06416",
        "HTML": "https://arxiv.org/html/2507.06416v1",
        "PDF": "https://arxiv.org/pdf/2507.06416"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study addresses voltage regulation challenges in power systems due to data center loads, using a dynamic voltage control scheme. It does not involve LLM training data processing or any related techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.04004",
      "abstract": "This paper presents the first photo-realistic LiDAR-Inertial-Camera Gaussian Splatting SLAM system that simultaneously addresses visual quality, geometric accuracy, and real-time performance. The proposed method performs robust and accurate pose estimation within a continuous-time trajectory optimization framework, while incrementally reconstructing a 3D Gaussian map using camera and LiDAR data, all in real time. The resulting map enables high-quality, real-time novel view rendering of both RGB images and depth maps. To effectively address under-reconstruction in regions not covered by the LiDAR, we employ a lightweight zero-shot depth model that synergistically combines RGB appearance cues with sparse LiDAR measurements to generate dense depth maps. The depth completion enables reliable Gaussian initialization in LiDAR-blind areas, significantly improving system applicability for sparse LiDAR sensors. To enhance geometric accuracy, we use sparse but precise LiDAR depths to supervise Gaussian map optimization and accelerate it with carefully designed CUDA-accelerated strategies. Furthermore, we explore how the incrementally reconstructed Gaussian map can improve the robustness of odometry. By tightly incorporating photometric constraints from the Gaussian map into the continuous-time factor graph optimization, we demonstrate improved pose estimation under LiDAR degradation scenarios. We also showcase downstream applications via extending our elaborate system, including video frame interpolation and fast 3D mesh extraction. To support rigorous evaluation, we construct a dedicated LiDAR-Inertial-Camera dataset featuring ground-truth poses, depth maps, and extrapolated trajectories for assessing out-of-sequence novel view synthesis. Both the dataset and code will be made publicly available on project page https://xingxingzuo.github.io/gaussian_lic2.",
      "authors": [
        "Xiaolei Lang",
        "Jiajun Lv",
        "Kai Tang",
        "Laijian Li",
        "Jianxin Huang",
        "Lina Liu",
        "Yong Liu",
        "Xingxing Zuo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-05T11:12:03+00:00",
          "link": "https://arxiv.org/abs/2507.04004v1",
          "size": "19421kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T11:35:52+00:00",
          "link": "https://arxiv.org/abs/2507.04004v2",
          "size": "21731kb",
          "version": "v2"
        }
      ],
      "title": "Gaussian-LIC2: LiDAR-Inertial-Camera Gaussian Splatting SLAM",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.04004",
        "HTML": "https://arxiv.org/html/2507.04004v2",
        "PDF": "https://arxiv.org/pdf/2507.04004"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper mentions the creation of a dataset for SLAM evaluation but focuses primarily on the modeling and application aspects rather than on specific LLM training data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06990",
      "abstract": "As quantum computing advances from theoretical promise to experimental reality, the need for rigorous experiment tracking becomes critical. Drawing inspiration from best practices in machine learning (ML) and artificial intelligence (AI), we argue that reproducibility, scalability, and collaboration in quantum research can benefit significantly from structured tracking workflows. This paper explores the application of MLflow in quantum research, illustrating how it enables better development practices, experiment reproducibility, decision making, and cross-domain integration in an increasingly hybrid classical-quantum landscape.",
      "authors": [
        "Mahee Gamage and Otso Kinanen and Jake Muff and Vlad Stirbu"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T16:14:18+00:00",
          "link": "https://arxiv.org/abs/2507.06990v1",
          "size": "35kb",
          "version": "v1"
        }
      ],
      "title": "Enhancing Quantum Software Development Process with Experiment Tracking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06990",
        "HTML": "https://arxiv.org/html/2507.06990v1",
        "PDF": "https://arxiv.org/pdf/2507.06990"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses experiment tracking in quantum computing and does not address any aspects of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07056",
      "abstract": "The proliferation of Low-Rank Adaptation (LoRA) models has democratized personalized text-to-image generation, enabling users to share lightweight models (e.g., personal portraits) on platforms like Civitai and Liblib. However, this \"share-and-play\" ecosystem introduces critical risks: benign LoRAs can be weaponized by adversaries to generate harmful content (e.g., political, defamatory imagery), undermining creator rights and platform safety. Existing defenses like concept-erasure methods focus on full diffusion models (DMs), neglecting LoRA's unique role as a modular adapter and its vulnerability to adversarial prompt engineering. To bridge this gap, we propose LoRAShield, the first data-free editing framework for securing LoRA models against misuse. Our platform-driven approach dynamically edits and realigns LoRA's weight subspace via adversarial optimization and semantic augmentation. Experimental results demonstrate that LoRAShield achieves remarkable effectiveness, efficiency, and robustness in blocking malicious generations without sacrificing the functionality of the benign task. By shifting the defense to platforms, LoRAShield enables secure, scalable sharing of personalized models, a critical step toward trustworthy generative ecosystems.",
      "authors": [
        "Jiahao Chen",
        "junhao li",
        "Yiming Wang",
        "Zhe Ma",
        "Yi Jiang",
        "Chunyi Zhou",
        "Qingming Li",
        "Tianyu Du",
        "Shouling Ji"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-05T02:53:17+00:00",
          "link": "https://arxiv.org/abs/2507.07056v1",
          "size": "4051kb",
          "version": "v1"
        }
      ],
      "title": "LoRAShield: Data-Free Editing Alignment for Secure Personalized LoRA Sharing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07056",
        "HTML": "https://arxiv.org/html/2507.07056v1",
        "PDF": "https://arxiv.org/pdf/2507.07056"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "Although the paper discusses securing LoRA models, it does not focus primarily on the processing of LLM training data; instead, it addresses model realignment and adversarial usage mitigation."
      },
      "source": "arXiv"
    },
    {
      "id": "2408.00746",
      "abstract": "Over the last years, there has been a significant amount of work studying the power of specific classes of computationally efficient estimators for multiple statistical parametric estimation tasks, including the estimators classes of low-degree polynomials, spectral methods, and others. Despite that, our understanding of the important class of MCMC methods remains quite poorly understood. For instance, for many models of interest, the performance of even zero-temperature (greedy-like) MCMC methods that simply maximize the posterior remains elusive.\n  In this work, we provide an easy to check condition under which the low-temperature Metropolis chain maximizes the posterior in polynomial-time with high probability. The result is generally applicable, and in this work, we use it to derive positive MCMC results for two classical sparse estimation tasks: the sparse tensor PCA model and sparse regression. Interestingly, in both cases, we also leverage the Overlap Gap Property framework for inference (Gamarnik, Zadik AoS '22) to prove that our results are tight: no low-temperature local MCMC method can achieve better performance. In particular, our work identifies the \"low-temperature (local) MCMC threshold\" for both sparse models. Interestingly, in the sparse tensor PCA model our results indicate that low-temperature local MCMC methods significantly underperform compared to other studied time-efficient methods, such as the class of low-degree polynomials.",
      "authors": [
        "Zongchen Chen",
        "Conor Sheehan",
        "Ilias Zadik"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Statistics Theory (math.ST)",
        "Data Structures and Algorithms (cs.DS)",
        "Probability (math.PR)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-01T17:49:55+00:00",
          "link": "https://arxiv.org/abs/2408.00746v1",
          "size": "471kb",
          "version": "v1"
        },
        {
          "date": "2024-08-05T20:16:06+00:00",
          "link": "https://arxiv.org/abs/2408.00746v2",
          "size": "525kb",
          "version": "v2"
        },
        {
          "date": "2025-07-08T21:14:36+00:00",
          "link": "https://arxiv.org/abs/2408.00746v3",
          "size": "462kb",
          "version": "v3"
        }
      ],
      "title": "On the Low-Temperature MCMC threshold: the cases of sparse tensor PCA, sparse regression, and a geometric rule",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.00746",
        "HTML": "https://arxiv.org/html/2408.00746v3",
        "PDF": "https://arxiv.org/pdf/2408.00746"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on MCMC methods for statistical tasks such as sparse tensor PCA and sparse regression. It does not discuss LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2402.03666",
      "abstract": "The practical deployment of diffusion models is still hindered by the high memory and computational overhead. Although quantization paves a way for model compression and acceleration, existing methods face challenges in achieving low-bit quantization efficiently. In this paper, we identify imbalanced activation distributions as a primary source of quantization difficulty, and propose to adjust these distributions through weight finetuning to be more quantization-friendly. We provide both theoretical and empirical evidence supporting finetuning as a practical and reliable solution. Building on this approach, we further distinguish two critical types of quantized layers: those responsible for retaining essential temporal information and those particularly sensitive to bit-width reduction. By selectively finetuning these layers under both local and global supervision, we mitigate performance degradation while enhancing quantization efficiency. Our method demonstrates its efficacy across three high-resolution image generation tasks, obtaining state-of-the-art performance across multiple bit-width settings.",
      "authors": [
        "Haoxuan Wang",
        "Yuzhang Shang",
        "Zhihang Yuan",
        "Junyi Wu",
        "Junchi Yan",
        "Yan Yan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-06T03:39:44+00:00",
          "link": "https://arxiv.org/abs/2402.03666v1",
          "size": "8501kb",
          "version": "v1"
        },
        {
          "date": "2024-02-13T05:22:34+00:00",
          "link": "https://arxiv.org/abs/2402.03666v2",
          "size": "8501kb",
          "version": "v2"
        },
        {
          "date": "2024-09-06T02:02:41+00:00",
          "link": "https://arxiv.org/abs/2402.03666v3",
          "size": "7242kb",
          "version": "v3"
        },
        {
          "date": "2025-06-26T17:36:29+00:00",
          "link": "https://arxiv.org/abs/2402.03666v4",
          "size": "6569kb",
          "version": "v4"
        },
        {
          "date": "2025-07-09T03:25:08+00:00",
          "link": "https://arxiv.org/abs/2402.03666v5",
          "size": "6569kb",
          "version": "v5"
        }
      ],
      "title": "QuEST: Low-bit Diffusion Model Quantization via Efficient Selective Finetuning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.03666",
        "HTML": "https://arxiv.org/html/2402.03666v5",
        "PDF": "https://arxiv.org/pdf/2402.03666"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses quantization of diffusion models for memory and computational efficiency, without discussing training data processing."
      },
      "tasks": [
        "Image Generation",
        "Model Compression",
        "Quantization"
      ],
      "repo_urls": [
        "https://github.com/hatchetProject/QuEST"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.17946",
      "abstract": "Despite being widely applied due to their exceptional capabilities, Large Language Models (LLMs) have been proven to be vulnerable to backdoor attacks. These attacks introduce targeted vulnerabilities into LLMs by poisoning training samples and full-parameter fine-tuning (FPFT). However, this kind of backdoor attack is limited since they require significant computational resources, especially as the size of LLMs increases. Besides, parameter-efficient fine-tuning (PEFT) offers an alternative but the restricted parameter updating may impede the alignment of triggers with target labels. In this study, we first verify that backdoor attacks with PEFT may encounter challenges in achieving feasible performance. To address these issues and improve the effectiveness of backdoor attacks with PEFT, we propose a novel backdoor attack algorithm from the weak-to-strong based on Feature Alignment-enhanced Knowledge Distillation (FAKD). Specifically, we poison small-scale language models through FPFT to serve as the teacher model. The teacher model then covertly transfers the backdoor to the large-scale student model through FAKD, which employs PEFT. Theoretical analysis reveals that FAKD has the potential to augment the effectiveness of backdoor attacks. We demonstrate the superior performance of FAKD on classification tasks across four language models, four backdoor attack algorithms, and two different architectures of teacher models. Experimental results indicate success rates close to 100% for backdoor attacks targeting PEFT.",
      "authors": [
        "Shuai Zhao",
        "Leilei Gan",
        "Zhongliang Guo",
        "Xiaobao Wu",
        "Yanhao Jia",
        "Luwei Xiao",
        "Cong-Duy Nguyen",
        "Luu Anh Tuan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-26T15:20:37+00:00",
          "link": "https://arxiv.org/abs/2409.17946v1",
          "size": "11129kb",
          "version": "v1"
        },
        {
          "date": "2024-10-01T13:01:40+00:00",
          "link": "https://arxiv.org/abs/2409.17946v2",
          "size": "11457kb",
          "version": "v2"
        },
        {
          "date": "2024-10-13T06:33:20+00:00",
          "link": "https://arxiv.org/abs/2409.17946v3",
          "size": "11457kb",
          "version": "v3"
        },
        {
          "date": "2025-07-09T03:32:17+00:00",
          "link": "https://arxiv.org/abs/2409.17946v4",
          "size": "5050kb",
          "version": "v4"
        }
      ],
      "title": "Breaking PEFT Limitations: Leveraging Weak-to-Strong Knowledge Transfer for Backdoor Attacks in LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.17946",
        "HTML": "https://arxiv.org/html/2409.17946v4",
        "PDF": "https://arxiv.org/pdf/2409.17946"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on backdoor attacks in LLMs through knowledge distillation techniques, rather than on the processing or creation of training data."
      },
      "tasks": [
        "Backdoor Attack",
        "Knowledge Distillation",
        "parameter-efficient fine-tuning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06753",
      "abstract": "This paper presents the first application of Kolmogorov-Arnold Convolution for Text (KAConvText) in sentence classification, addressing three tasks: imbalanced binary hate speech detection, balanced multiclass news classification, and imbalanced multiclass ethnic language identification. We investigate various embedding configurations, comparing random to fastText embeddings in both static and fine-tuned settings, with embedding dimensions of 100 and 300 using CBOW and Skip-gram models. Baselines include standard CNNs and CNNs augmented with a Kolmogorov-Arnold Network (CNN-KAN). In addition, we investigated KAConvText with different classification heads - MLP and KAN, where using KAN head supports enhanced interpretability. Results show that KAConvText-MLP with fine-tuned fastText embeddings achieves the best performance of 91.23% accuracy (F1-score = 0.9109) for hate speech detection, 92.66% accuracy (F1-score = 0.9267) for news classification, and 99.82% accuracy (F1-score = 0.9982) for language identification.",
      "authors": [
        "Ye Kyaw Thu",
        "Thura Aung",
        "Thazin Myint Oo",
        "Thepchai Supnithi"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T11:25:35+00:00",
          "link": "https://arxiv.org/abs/2507.06753v1",
          "size": "572kb",
          "version": "v1"
        }
      ],
      "title": "KAConvText: Novel Approach to Burmese Sentence Classification using Kolmogorov-Arnold Convolution",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06753",
        "PDF": "https://arxiv.org/pdf/2507.06753"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on developing a novel approach for Burmese sentence classification using Kolmogorov-Arnold Convolution. It does not address LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06850",
      "abstract": "The rapid adoption of Large Language Model (LLM) agents and multi-agent systems enables unprecedented capabilities in natural language processing and generation. However, these systems have introduced unprecedented security vulnerabilities that extend beyond traditional prompt injection attacks. This paper presents the first comprehensive evaluation of LLM agents as attack vectors capable of achieving complete computer takeover through the exploitation of trust boundaries within agentic AI systems where autonomous entities interact and influence each other. We demonstrate that adversaries can leverage three distinct attack surfaces - direct prompt injection, RAG backdoor attacks, and inter-agent trust exploitation - to coerce popular LLMs (including GPT-4o, Claude-4 and Gemini-2.5) into autonomously installing and executing malware on victim machines. Our evaluation of 17 state-of-the-art LLMs reveals an alarming vulnerability hierarchy: while 41.2% of models succumb to direct prompt injection, 52.9% are vulnerable to RAG backdoor attacks, and a critical 82.4% can be compromised through inter-agent trust exploitation. Notably, we discovered that LLMs which successfully resist direct malicious commands will execute identical payloads when requested by peer agents, revealing a fundamental flaw in current multi-agent security models. Our findings demonstrate that only 5.9% of tested models (1/17) proved resistant to all attack vectors, with the majority exhibiting context-dependent security behaviors that create exploitable blind spots. Our findings also highlight the need to increase awareness and research on the security risks of LLMs, showing a paradigm shift in cybersecurity threats, where AI tools themselves become sophisticated attack vectors.",
      "authors": [
        "Matteo Lupinacci",
        "Francesco Aurelio Pironti",
        "Francesco Blefari",
        "Francesco Romeo",
        "Luigi Arena",
        "Angelo Furfaro"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T13:54:58+00:00",
          "link": "https://arxiv.org/abs/2507.06850v1",
          "size": "442kb",
          "version": "v1"
        }
      ],
      "title": "The Dark Side of LLMs Agent-based Attacks for Complete Computer Takeover",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06850",
        "HTML": "https://arxiv.org/html/2507.06850v1",
        "PDF": "https://arxiv.org/pdf/2507.06850"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates security vulnerabilities in LLM agents, without any focus on training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06983",
      "abstract": "Cognitive radio networks (CRNs) are acknowledged for their ability to tackle the issue of spectrum under-utilization. In the realm of CRNs, this paper investigates the energy efficiency issue and addresses the critical challenge of optimizing system reliability for overlay CRN access mode. Randomly dispersed secondary users (SUs) serving as relays for primary users (PUs) are considered, in which one of these relays is designated to harvest energy through the time switching-energy harvesting (EH) protocol. Moreover, this relay amplifies-and-forwards (AF) the PU's messages and broadcasts them along with its own across cascaded $\\kappa$-$\\mu$ fading channels. The power splitting protocol is another EH approach utilized by the SU and PU receivers to enhance the amount of energy in their storage devices. In addition, the SU transmitters and the SU receiver are deployed with multiple antennas for reception and apply the maximal ratio combining approach. The outage probability is utilized to assess both networks' reliability. Then, an energy efficiency evaluation is performed to determine the effectiveness of EH on the system. Finally, an optimization problem is provided with the goal of maximizing the data rate of the SUs by optimizing the time switching and the power allocation parameters of the SU relay.",
      "authors": [
        "Deemah H. Tashman",
        "Soumaya Cherkaoui",
        "and Walaa Hamouda"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Emerging Technologies (cs.ET)",
        "Networking and Internet Architecture (cs.NI)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T16:08:44+00:00",
          "link": "https://arxiv.org/abs/2507.06983v1",
          "size": "449kb",
          "version": "v1"
        }
      ],
      "title": "Maximizing Reliability in Overlay Radio Networks with Time Switching and Power Splitting Energy Harvesting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06983",
        "HTML": "https://arxiv.org/html/2507.06983v1",
        "PDF": "https://arxiv.org/pdf/2507.06983"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "It explores optimizing energy efficiency and reliability in cognitive radio networks, focusing on overlay and energy harvesting techniques, without touching on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2405.15625",
      "abstract": "We present a novel method for training score-based generative models which uses nonlinear noising dynamics to improve learning of structured distributions. Generalizing to a nonlinear drift allows for additional structure to be incorporated into the dynamics, thus making the training better adapted to the data, e.g., in the case of multimodality or (approximate) symmetries. Such structure can be obtained from the data by an inexpensive preprocessing step. The nonlinear dynamics introduces new challenges into training which we address in two ways: 1) we develop a new nonlinear denoising score matching (NDSM) method, 2) we introduce neural control variates in order to reduce the variance of the NDSM training objective. We demonstrate the effectiveness of this method on several examples: a) a collection of low-dimensional examples, motivated by clustering in latent space, b) high-dimensional images, addressing issues with mode imbalance, small training sets, and approximate symmetries, the latter being a challenge for methods based on equivariant neural networks, which require exact symmetries, c) latent space representation of high-dimensional data, demonstrating improved performance with greatly reduced computational cost. Our method learns score-based generative models with less data by flexibly incorporating structure arising in the dataset.",
      "authors": [
        "Jeremiah Birrell",
        "Markos A. Katsoulakis",
        "Luc Rey-Bellet",
        "Benjamin J. Zhang",
        "Wei Zhu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-24T15:14:23+00:00",
          "link": "https://arxiv.org/abs/2405.15625v1",
          "size": "38839kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T21:02:36+00:00",
          "link": "https://arxiv.org/abs/2405.15625v2",
          "size": "4283kb",
          "version": "v2"
        }
      ],
      "title": "Nonlinear denoising score matching for enhanced learning of structured distributions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.15625",
        "HTML": "https://arxiv.org/html/2405.15625v2",
        "PDF": "https://arxiv.org/pdf/2405.15625"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper mentions preprocessing steps for structured distribution learning but focuses on nonlinear score-based generative models rather than LLM training-data processing."
      },
      "tasks": [
        "Denoising"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.06036",
      "abstract": "Transformer-based large language models (LLMs) rely on contextual embeddings which generate different (continuous) representations for the same token depending on its surrounding context. Nonetheless, words and tokens typically have a limited number of senses (or meanings). We propose multi-sense embeddings as a drop-in replacement for each token in order to capture the range of their uses in a language. To construct a sense embedding dictionary, we apply a clustering algorithm to embeddings generated by an LLM and consider the cluster centers as representative sense embeddings. In addition, we propose a novel knowledge distillation method that leverages the sense dictionary to learn a smaller student model that mimics the senses from the much larger base LLM model, offering significant space and inference time savings, while maintaining competitive performance. Via thorough experiments on various benchmarks, we showcase the effectiveness of our sense embeddings and knowledge distillation approach. We share our code at https://github.com/Qitong-Wang/SenseDict",
      "authors": [
        "Qitong Wang",
        "Mohammed J. Zaki",
        "Georgios Kollias",
        "Vasileios Kalantzis"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-08T13:36:36+00:00",
          "link": "https://arxiv.org/abs/2504.06036v1",
          "size": "1215kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T20:39:07+00:00",
          "link": "https://arxiv.org/abs/2504.06036v2",
          "size": "684kb",
          "version": "v2"
        }
      ],
      "title": "Multi-Sense Embeddings for Language Models and Knowledge Distillation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.06036",
        "HTML": "https://arxiv.org/html/2504.06036v2",
        "PDF": "https://arxiv.org/pdf/2504.06036"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses multi-sense embeddings and knowledge distillation, which involves deriving and learning from sense embeddings. While it pertains to token representation, it does not substantially focus on LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.07446",
      "abstract": "Tracking a target person from robot-egocentric views is crucial for developing autonomous robots that provide continuous personalized assistance or collaboration in Human-Robot Interaction (HRI) and Embodied AI. However, most existing target person tracking (TPT) benchmarks are limited to controlled laboratory environments with few distractions, clean backgrounds, and short-term occlusions. In this paper, we introduce a large-scale dataset designed for TPT in crowded and unstructured environments, demonstrated through a robot-person following task. The dataset is collected by a human pushing a sensor-equipped cart while following a target person, capturing human-like following behavior and emphasizing long-term tracking challenges, including frequent occlusions and the need for re-identification from numerous pedestrians. It includes multi-modal data streams, including odometry, 3D LiDAR, IMU, panoramic images, and RGB-D images, along with exhaustively annotated 2D bounding boxes of the target person across 48 sequences, both indoors and outdoors. Using this dataset and visual annotations, we perform extensive experiments with existing SOTA TPT methods, offering a thorough analysis of their limitations and suggesting future research directions.",
      "authors": [
        "Hanjing Ye",
        "Yu Zhan",
        "Weixi Situ",
        "Guangcheng Chen",
        "Jingwen Yu",
        "Ziqi Zhao",
        "Kuanqi Cai",
        "Arash Ajoudani",
        "Hong Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-12T11:10:24+00:00",
          "link": "https://arxiv.org/abs/2505.07446v1",
          "size": "28236kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T13:47:58+00:00",
          "link": "https://arxiv.org/abs/2505.07446v2",
          "size": "35769kb",
          "version": "v2"
        }
      ],
      "title": "TPT-Bench: A Large-Scale, Long-Term and Robot-Egocentric Dataset for Benchmarking Target Person Tracking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.07446",
        "HTML": "https://arxiv.org/html/2505.07446v2",
        "PDF": "https://arxiv.org/pdf/2505.07446"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a dataset for evaluating person tracking tasks in robotics, but does not relate to LLM training data processing or creation for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.00511",
      "abstract": "In this paper, we present the VMSE U-Net and VM-Unet CBAM+ model, two cutting-edge deep learning architectures designed to enhance medical image segmentation. Our approach integrates Squeeze-and-Excitation (SE) and Convolutional Block Attention Module (CBAM) techniques into the traditional VM U-Net framework, significantly improving segmentation accuracy, feature localization, and computational efficiency. Both models show superior performance compared to the baseline VM-Unet across multiple datasets. Notably, VMSEUnet achieves the highest accuracy, IoU, precision, and recall while maintaining low loss values. It also exhibits exceptional computational efficiency with faster inference times and lower memory usage on both GPU and CPU. Overall, the study suggests that the enhanced architecture VMSE-Unet is a valuable tool for medical image analysis. These findings highlight its potential for real-world clinical applications, emphasizing the importance of further research to optimize accuracy, robustness, and computational efficiency.",
      "authors": [
        "Sayandeep Kanrar",
        "Raja Piyush",
        "Qaiser Razi",
        "Debanshi Chakraborty",
        "Vikas Hassija",
        "GSS Chalapathi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T07:27:11+00:00",
          "link": "https://arxiv.org/abs/2507.00511v1",
          "size": "850kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T04:27:07+00:00",
          "link": "https://arxiv.org/abs/2507.00511v2",
          "size": "850kb",
          "version": "v2"
        }
      ],
      "title": "Medical Image Segmentation Using Advanced Unet: VMSE-Unet and VM-Unet CBAM+",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.00511",
        "HTML": "https://arxiv.org/html/2507.00511v2",
        "PDF": "https://arxiv.org/pdf/2507.00511"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with improved architectures for medical image segmentation without any focus on processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06260",
      "abstract": "Nova Premier is Amazon's most capable multimodal foundation model and teacher for model distillation. It processes text, images, and video with a one-million-token context window, enabling analysis of large codebases, 400-page documents, and 90-minute videos in a single prompt. We present the first comprehensive evaluation of Nova Premier's critical risk profile under the Frontier Model Safety Framework. Evaluations target three high-risk domains -- Chemical, Biological, Radiological & Nuclear (CBRN), Offensive Cyber Operations, and Automated AI R&D -- and combine automated benchmarks, expert red-teaming, and uplift studies to determine whether the model exceeds release thresholds. We summarize our methodology and report core findings. Based on this evaluation, we find that Nova Premier is safe for public release as per our commitments made at the 2025 Paris AI Safety Summit. We will continue to enhance our safety evaluation and mitigation pipelines as new risks and capabilities associated with frontier models are identified.",
      "authors": [
        "Satyapriya Krishna",
        "Ninareh Mehrabi",
        "Abhinav Mohanty",
        "Matteo Memelli",
        "Vincent Ponzo",
        "Payal Motwani",
        "Rahul Gupta"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T13:33:35+00:00",
          "link": "https://arxiv.org/abs/2507.06260v1",
          "size": "113kb",
          "version": "v1"
        }
      ],
      "title": "Evaluating the Critical Risks of Amazon's Nova Premier under the Frontier Model Safety Framework",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06260",
        "HTML": "https://arxiv.org/html/2507.06260v1",
        "PDF": "https://arxiv.org/pdf/2507.06260"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on evaluating the safety risks of a multimodal model under a specific safety framework, with no emphasis on processing or creating training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06467",
      "abstract": "Relational databases are foundational to numerous domains, including business intelligence, scientific research, and enterprise systems. However, accessing and analyzing structured data often requires proficiency in SQL, which is a skill that many end users lack. With the development of Natural Language Processing (NLP) technology, the Text-to-SQL systems attempt to bridge this gap by translating natural language questions into executable SQL queries via an automated algorithm. Yet, when operating on complex real-world databases, the Text-to-SQL systems often suffer from ambiguity due to natural ambiguity in natural language queries. These ambiguities pose a significant challenge for existing Text-to-SQL translation systems, which tend to commit early to a potentially incorrect interpretation. To address this, we propose an interactive Text-to-SQL framework that models SQL generation as a probabilistic reasoning process over multiple candidate queries. Rather than producing a single deterministic output, our system maintains a distribution over possible SQL outputs and seeks to resolve uncertainty through user interaction. At each interaction step, the system selects a branching decision and formulates a clarification question aimed at disambiguating that aspect of the query. Crucially, we adopt a principled decision criterion based on Expected Information Gain to identify the clarification that will, in expectation, most reduce the uncertainty in the SQL distribution.",
      "authors": [
        "Luyu Qiu",
        "Jianing Li",
        "Chi Su",
        "Lei Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T00:59:49+00:00",
          "link": "https://arxiv.org/abs/2507.06467v1",
          "size": "501kb",
          "version": "v1"
        }
      ],
      "title": "Interactive Text-to-SQL via Expected Information Gain for Disambiguation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06467",
        "HTML": "https://arxiv.org/html/2507.06467v1",
        "PDF": "https://arxiv.org/pdf/2507.06467"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper primarily addresses a Text-to-SQL translation challenge and involves probabilistic reasoning for SQL ambiguity, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06826",
      "abstract": "This paper presents a physics-informed neural network (PINN) for modeling first-order Ambisonic (FOA) room impulse responses (RIRs). PINNs have demonstrated promising performance in sound field interpolation by combining the powerful modeling capability of neural networks and the physical principles of sound propagation. In room acoustics, PINNs have typically been trained to represent the sound pressure measured by omnidirectional microphones where the wave equation or its frequency-domain counterpart, i.e., the Helmholtz equation, is leveraged. Meanwhile, FOA RIRs additionally provide spatial characteristics and are useful for immersive audio generation with a wide range of applications. In this paper, we extend the PINN framework to model FOA RIRs. We derive two physics-informed priors for FOA RIRs based on the correspondence between the particle velocity and the (X, Y, Z)-channels of FOA. These priors associate the predicted W-channel and other channels through their partial derivatives and impose the physically feasible relationship on the four channels. Our experiments confirm the effectiveness of the proposed method compared with a neural network without the physics-informed prior.",
      "authors": [
        "Yoshiki Masuyama",
        "Fran\\c{c}ois G. Germain",
        "Gordon Wichern",
        "Christopher Ick",
        "Jonathan Le Roux"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T13:23:45+00:00",
          "link": "https://arxiv.org/abs/2507.06826v1",
          "size": "580kb",
          "version": "v1"
        }
      ],
      "title": "Physics-Informed Direction-Aware Neural Acoustic Fields",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06826",
        "HTML": "https://arxiv.org/html/2507.06826v1",
        "PDF": "https://arxiv.org/pdf/2507.06826"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses physics-informed neural networks for acoustics but does not involve any aspects of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.10410",
      "abstract": "In multistage group testing, the tests within the same stage are considered nonadaptive, while those conducted across different stages are adaptive. Specifically, when the pools within the same stage are disjoint, meaning that the entire set is divided into several disjoint subgroups, it is referred to as a multistage group partition testing problem, denoted as the (n, d, s) problem, where n, d, and s represent the total number of items, defectives, and stages respectively. This paper presents exact solutions for the (n, 1, s) and (n, d, 2) problems for the first time. Additionally, a general dynamic programming approach is developed for the (n, d, s) problem. Significantly we give the sharp upper and lower bounds estimates. If the defective number in unknown but bounded, we can provide an algorithm with an optimal competitive ratio in the asymptotic sense. While assuming the prior distribution of the defective items, we also establish a well performing upper and lower bound estimate to the expectation of optimal strategy",
      "authors": [
        "Guojiang Shao"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-16T15:44:27+00:00",
          "link": "https://arxiv.org/abs/2409.10410v1",
          "size": "142kb",
          "version": "v1"
        },
        {
          "date": "2025-04-11T09:59:02+00:00",
          "link": "https://arxiv.org/abs/2409.10410v2",
          "size": "142kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T08:00:21+00:00",
          "link": "https://arxiv.org/abs/2409.10410v3",
          "size": "147kb",
          "version": "v3"
        }
      ],
      "title": "Sharp Estimates for Optimal Multistage Group Partition Testing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.10410",
        "HTML": "https://arxiv.org/html/2409.10410v3",
        "PDF": "https://arxiv.org/pdf/2409.10410"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work is focused on multistage group testing strategies and algorithm development, with no relevant content on LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06508",
      "abstract": "When analyzing connection patterns within graphs, subgraph counting serves as an effective and fundamental approach. Edge-local differential privacy (edge-LDP) and shuffle model have been employed to achieve subgraph counting under a privacy-preserving situation. Existing algorithms are plagued by high time complexity, excessive download costs, low accuracy, or dependence on trusted third parties. To address the aforementioned challenges, we propose the Noisy Adjacency Matrix (NAM), which combines differential privacy with the adjacency matrix of the graph. NAM offers strong versatility and scalability, making it applicable to a wider range of DP variants, DP mechanisms, and graph types. Based on NAM, we designed five algorithms (TriOR, TriTR, TriMTR, QuaTR, and 2STAR) to count three types of subgraphs: triangles, quadrangles, and 2-stars. Theoretical and experimental results demonstrate that in triangle counting, TriOR maximizes accuracy with reduced time complexity among one-round algorithms, TriTR achieves optimal accuracy, TriMTR achieves the highest accuracy under low download costs, and QuaTR stands as the first quadrangle counting algorithm under pure edge-LDP. We implement edge-LDP for noisy data via a confidence interval-inspired method, providing DP guarantees on randomized data. Our 2STAR algorithm achieves the highest accuracy in 2-star counting and can be derived as a byproduct of two-round triangle or quadrangle counting algorithms, enabling efficient joint estimation of triangle, quadrangle, and 2-star counts within two query rounds.",
      "authors": [
        "Jintao Guo",
        "Ying Zhou",
        "Chao Li",
        "Guixun Luo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T03:13:15+00:00",
          "link": "https://arxiv.org/abs/2507.06508v1",
          "size": "2174kb",
          "version": "v1"
        }
      ],
      "title": "Subgraph Counting under Edge Local Differential Privacy Based on Noisy Adjacency Matrix",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06508",
        "HTML": "https://arxiv.org/html/2507.06508v1",
        "PDF": "https://arxiv.org/pdf/2507.06508"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses subgraph counting with differential privacy, which is unrelated to LLM training data processing or enhancing data quality for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06765",
      "abstract": "This document proposes a parametric activation function (ac.f.) aimed at improving multidimensional nonlinear data regression. It is a established knowledge that nonlinear ac.f.'s are required for learning nonlinear datasets. This work shows that smoothness and gradient properties of the ac.f. further impact the performance of large neural networks in terms of overfitting and sensitivity to model parameters. Smooth but vanishing-gradient ac.f.'s such as ELU or SiLU have limited performance and non-smooth ac.f.'s such as RELU and Leaky-RELU further impart discontinuity in the trained model. Improved performance is demonstrated with a smooth \"Leaky Exponential Linear Unit\", with non-zero gradient that can be trained. A novel diffusion-loss metric is also proposed to gauge the performance of the trained models in terms of overfitting.",
      "authors": [
        "Enda D.V. Bigarella"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T11:49:15+00:00",
          "link": "https://arxiv.org/abs/2507.06765v1",
          "size": "285kb",
          "version": "v1"
        }
      ],
      "title": "Robust Deep Network Learning of Nonlinear Regression Tasks by Parametric Leaky Exponential Linear Units (LELUs) and a Diffusion Metric",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06765",
        "HTML": "https://arxiv.org/html/2507.06765v1",
        "PDF": "https://arxiv.org/pdf/2507.06765"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a new parametric activation function to improve neural network performance, specifically in regression tasks, and does not discuss LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2305.18811",
      "abstract": "PyPOTS is an open-source Python library dedicated to data mining and analysis on multivariate partially-observed time series with missing values. Particularly, it provides easy access to diverse algorithms categorized into five tasks: imputation, forecasting, anomaly detection, classification, and clustering. The included models represent a diverse set of methodological paradigms, offering a unified and well-documented interface suitable for both academic research and practical applications. With robustness and scalability in its design philosophy, best practices of software construction, for example, unit testing, continuous integration and continuous delivery, code coverage, maintainability evaluation, interactive tutorials, and parallelization, are carried out as principles during the development of PyPOTS. The toolbox is available on PyPI, Anaconda, and Docker. PyPOTS is open source and publicly available on GitHub https://github.com/WenjieDu/PyPOTS.",
      "authors": [
        "Wenjie Du",
        "Yiyuan Yang",
        "Linglong Qian",
        "Jun Wang",
        "Qingsong Wen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2023-05-30T07:57:05+00:00",
          "link": "https://arxiv.org/abs/2305.18811v1",
          "size": "95kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T16:03:16+00:00",
          "link": "https://arxiv.org/abs/2305.18811v2",
          "size": "22kb",
          "version": "v2"
        }
      ],
      "title": "PyPOTS: A Python Toolkit for Machine Learning on Partially-Observed Time Series",
      "links": {
        "Abstract": "https://arxiv.org/abs/2305.18811",
        "HTML": "https://arxiv.org/html/2305.18811v2",
        "PDF": "https://arxiv.org/pdf/2305.18811"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "PyPOTS is a toolkit for machine learning on time series with missing values, focusing on tasks like imputation and anomaly detection rather than LLM data processing or dataset creation."
      },
      "tasks": [
        "Anomaly Detection",
        "Classification",
        "Classification on Time Series with Missing Data",
        "Clustering",
        "Imputation",
        "Irregular Time Series",
        "Missing Values",
        "Multivariate Time Series Imputation",
        "Philosophy",
        "Time Series",
        "Time Series Analysis",
        "Time Series Anomaly Detection",
        "Time Series Classification",
        "Time Series Clustering",
        "Time Series Forecasting",
        "Traffic Data Imputation"
      ],
      "repo_urls": [
        "https://github.com/WenjieDu/TSDB",
        "https://github.com/wenjiedu/awesome_imputation",
        "https://github.com/WenjieDu/PyPOTS",
        "https://github.com/WenjieDu/PyGrinder",
        "https://github.com/wenjiedu/brewpots"
      ],
      "source": "arXiv"
    },
    {
      "id": "2406.17709",
      "abstract": "In this study, we introduce MGA-Net, a novel mask-guided attention neural network, which extends the U-net model for precision neonatal brain imaging. MGA-Net is designed to extract the brain from other structures and reconstruct high-quality brain images. The network employs a common encoder and two decoders: one for brain mask extraction and the other for brain region reconstruction. A key feature of MGA-Net is its high-level mask-guided attention module, which leverages features from the brain mask decoder to enhance image reconstruction. To enable the same encoder and decoder to process both MRI and ultrasound (US) images, MGA-Net integrates sinusoidal positional encoding. This encoding assigns distinct positional values to MRI and US images, allowing the model to effectively learn from both modalities. Consequently, features learned from a single modality can aid in learning a modality with less available data, such as US. We extensively validated the proposed MGA-Net on diverse datasets from varied clinical settings and neonatal age groups. The metrics used for assessment included the DICE similarity coefficient, recall, and accuracy for image segmentation; structural similarity for image reconstruction; and root mean squared error for total brain volume estimation from 3D ultrasound images. Our results demonstrate that MGA-Net significantly outperforms traditional methods, offering superior performance in brain extraction and segmentation while achieving high precision in image reconstruction and volumetric analysis. Thus, MGA-Net represents a robust and effective preprocessing tool for MRI and 3D ultrasound images, marking a significant advance in neuroimaging that enhances both research and clinical diagnostics in the neonatal period and beyond.",
      "authors": [
        "Bahram Jafrasteh",
        "Simon Pedro Lubian-Lopez",
        "Emiliano Trimarco",
        "Macarena Roman Ruiz",
        "Carmen Rodriguez Barrios",
        "Yolanda Marin Almagro",
        "Isabel Benavente-Fernandez"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Computation (stat.CO)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-25T16:48:18+00:00",
          "link": "https://arxiv.org/abs/2406.17709v1",
          "size": "6982kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T18:07:51+00:00",
          "link": "https://arxiv.org/abs/2406.17709v2",
          "size": "10288kb",
          "version": "v2"
        }
      ],
      "title": "Mask-Guided Attention U-Net for Enhanced Neonatal Brain Extraction and Image Preprocessing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.17709",
        "HTML": "https://arxiv.org/html/2406.17709v2",
        "PDF": "https://arxiv.org/pdf/2406.17709"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a neural network for neonatal brain imaging enhancement and image preprocessing, which does not pertain to LLM training data processing."
      },
      "tasks": [
        "Decoder",
        "Image Reconstruction",
        "Image Segmentation",
        "Semantic Segmentation"
      ],
      "repo_urls": [
        "https://github.com/bahramjafrasteh/mga-net"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06346",
      "abstract": "We study a resource-constrained variant of the Random Disambiguation Path (RDP) problem, a generalization of the Stochastic Obstacle Scene (SOS) problem, in which a navigating agent must reach a target in a spatial environment populated with uncertain obstacles. Each ambiguous obstacle may be disambiguated at a (possibly) heterogeneous resource cost, subject to a global disambiguation budget. We formulate this constrained planning problem as a Weight-Constrained Shortest Path Problem (WCSPP) with risk-adjusted edge costs that incorporate probabilistic blockage and traversal penalties. To solve it, we propose a novel algorithmic framework-COLOGR-combining Lagrangian relaxation with a two-phase vertex elimination (TPVE) procedure. The method prunes infeasible and suboptimal paths while provably preserving the optimal solution, and leverages dual bounds to guide efficient search. We establish correctness, feasibility guarantees, and surrogate optimality under mild assumptions. Our analysis also demonstrates that COLOGR frequently achieves zero duality gap and offers improved computational complexity over prior constrained path-planning methods. Extensive simulation experiments validate the algorithm's robustness across varying obstacle densities, sensor accuracies, and risk models, consistently outperforming greedy baselines and approaching offline-optimal benchmarks. The proposed framework is broadly applicable to stochastic network design, mobility planning, and constrained decision-making under uncertainty.",
      "authors": [
        "Li Zhou",
        "Elvan Ceyhan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computation (stat.CO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T19:12:46+00:00",
          "link": "https://arxiv.org/abs/2507.06346v1",
          "size": "4519kb",
          "version": "v1"
        }
      ],
      "title": "Solving the Constrained Random Disambiguation Path Problem via Lagrangian Relaxation and Graph Reduction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06346",
        "HTML": "https://arxiv.org/html/2507.06346v1",
        "PDF": "https://arxiv.org/pdf/2507.06346"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a constrained path-planning problem and its solution. It makes no mention of LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06404",
      "abstract": "Evaluating and comparing the performance of autonomous Humanoid Robots is challenging, as success rate metrics are difficult to reproduce and fail to capture the complexity of robot movement trajectories, critical in Human-Robot Interaction and Collaboration (HRIC). To address these challenges, we propose a general evaluation framework that measures the quality of Imitation Learning (IL) methods by focusing on trajectory performance. We devise the Neural Meta Evaluator (NeME), a deep learning model trained to classify actions from robot joint trajectories. NeME serves as a meta-evaluator to compare the performance of robot control policies, enabling policy evaluation without requiring human involvement in the loop. We validate our framework on ergoCub, a humanoid robot, using teleoperation data and comparing IL methods tailored to the available platform. The experimental results indicate that our method is more aligned with the success rate obtained on the robot than baselines, offering a reproducible, systematic, and insightful means for comparing the performance of multimodal imitation learning approaches in complex HRI tasks.",
      "authors": [
        "Matteo Tiezzi",
        "Tommaso Apicella",
        "Carlos Cardenas-Perez",
        "Giovanni Fregonese",
        "Stefano Dafarra",
        "Pietro Morerio",
        "Daniele Pucci",
        "Alessio Del Bue"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T21:12:57+00:00",
          "link": "https://arxiv.org/abs/2507.06404v1",
          "size": "983kb",
          "version": "v1"
        }
      ],
      "title": "Learning to Evaluate Autonomous Behaviour in Human-Robot Interaction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06404",
        "HTML": "https://arxiv.org/html/2507.06404v1",
        "PDF": "https://arxiv.org/pdf/2507.06404"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study presents a framework for evaluating autonomous robot behavior, without any discussion on LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06647",
      "abstract": "The visualization of volumetric medical data is crucial for enhancing diagnostic accuracy and improving surgical planning and education. Cinematic rendering techniques significantly enrich this process by providing high-quality visualizations that convey intricate anatomical details, thereby facilitating better understanding and decision-making in medical contexts. However, the high computing cost and low rendering speed limit the requirement of interactive visualization in practical applications. In this paper, we introduce ClipGS, an innovative Gaussian splatting framework with the clipping plane supported, for interactive cinematic visualization of volumetric medical data. To address the challenges posed by dynamic interactions, we propose a learnable truncation scheme that automatically adjusts the visibility of Gaussian primitives in response to the clipping plane. Besides, we also design an adaptive adjustment model to dynamically adjust the deformation of Gaussians and refine the rendering performance. We validate our method on five volumetric medical data (including CT and anatomical slice data), and reach an average 36.635 PSNR rendering quality with 156 FPS and 16.1 MB model size, outperforming state-of-the-art methods in rendering quality and efficiency.",
      "authors": [
        "Chengkun Li",
        "Yuqi Tong",
        "Kai Chen",
        "Zhenya Yang",
        "Ruiyang Li",
        "Shi Qiu",
        "Jason Ying-Kuen Chan",
        "Pheng-Ann Heng",
        "Qi Dou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T08:24:28+00:00",
          "link": "https://arxiv.org/abs/2507.06647v1",
          "size": "8990kb",
          "version": "v1"
        }
      ],
      "title": "ClipGS: Clippable Gaussian Splatting for Interactive Cinematic Visualization of Volumetric Medical Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06647",
        "HTML": "https://arxiv.org/html/2507.06647v1",
        "PDF": "https://arxiv.org/pdf/2507.06647"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a framework for visualizing medical data, focusing on rendering techniques and model efficiency, without involving LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06650",
      "abstract": "Estimating individual-level treatment effect from observational data is a fundamental problem in causal inference and has attracted increasing attention in the fields of education, healthcare, and public policy.In this work, we concentrate on the study of disentangled representation methods that have shown promising outcomes by decomposing observed covariates into instrumental, confounding, and adjustment factors. However, most of the previous work has primarily revolved around generative models or hard decomposition methods for covariates, which often struggle to guarantee the attainment of precisely disentangled factors. In order to effectively model different causal relationships, we propose a novel treatment effect estimation algorithm that incorporates a mixture of experts with multi-head attention and a linear orthogonal regularizer to softly decompose the pre-treatment variables, and simultaneously eliminates selection bias via importance sampling re-weighting techniques. We conduct extensive experiments on both public semi-synthetic and real-world production datasets. The experimental results clearly demonstrate that our algorithm outperforms the state-of-the-art methods focused on individual treatment effects.",
      "authors": [
        "Hui Meng",
        "Keping Yang",
        "Xuyu Peng and Bo Zheng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T08:29:37+00:00",
          "link": "https://arxiv.org/abs/2507.06650v1",
          "size": "801kb",
          "version": "v1"
        }
      ],
      "title": "Deep Disentangled Representation Network for Treatment Effect Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06650",
        "HTML": "https://arxiv.org/html/2507.06650v1",
        "PDF": "https://arxiv.org/pdf/2507.06650"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The main focus of the paper is on treatment effect estimation and causal inference, using disentangled representation methods, which is not related to LLM data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.14498",
      "abstract": "Krylov subspace methods are linear solvers based on matrix-vector multiplications and vector operations. While easily parallelizable, they are sensitive to rounding errors and may experience convergence issues. ILU(0), an incomplete LU factorization with zero fill-in, is a well-known preconditioning technique that enhances convergence for sparse matrices. In this paper, we implement a double-precision and multiple-precision ILU(0) preconditioner, compatible with product-type Krylov subspace methods, and evaluate its performance.",
      "authors": [
        "Tomonori Kouya"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-20T05:33:02+00:00",
          "link": "https://arxiv.org/abs/2504.14498v1",
          "size": "180kb",
          "version": "v1"
        }
      ],
      "title": "Assessing the Performance of Mixed-Precision ILU(0)-Preconditioned Multiple-Precision Real and Complex Krylov Subspace Methods",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.14498",
        "HTML": "https://arxiv.org/html/2504.14498",
        "PDF": "https://arxiv.org/pdf/2504.14498"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses numerical methods and preconditioning techniques in the context of linear algebra and does not relate to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.19030",
      "abstract": "Large Language Model (LLM) services fundamentally differ from traditional Deep Neural Network (DNN) applications in wireless networks. We identify three critical distinctions: (1) unlike traditional DNNs with unidirectional data flows, LLM's multimodal interactions create bidirectional heavy loads with contrasting bottlenecks, requiring direction-aware resource scheduling; (2) while traditional DNNs exhibit fixed computational patterns, LLM's highly variable inference times interact complexly with network slicing, causing dynamic bottleneck migration; and (3) in contrast to predictable DNN traffic, LLM's token streams demonstrate unprecedented burstiness and state dependencies. These insights motivate WiLLM, the first open-source framework, implemented as a wireless platform, for LLM service research. Built on OpenAirInterface, WiLLM introduces several technical innovations: dynamic slice compatibility, universal UE compatibility through application-layer tunneling, multi-UE multi-slice scheduling, dual-mode resource allocation, and cross-layer APIs. In addition, WiLLM eliminates the need for specialized wireless expertise, enabling researchers and developers to experiment with LLM services over realistic cellular networks. We demonstrate the platform's capabilities through a smart glasses case study and provide a comprehensive dataset of \\~1.6 million synchronized measurements. The complete system, dataset, and appendix are available at https://openwillm.github.io.",
      "authors": [
        "Boyi Liu",
        "Yongguang Lu",
        "Jianguo Zhao",
        "Qiang Yang",
        "Wen Wu",
        "Lin Chen",
        "Jagmohan Chauhan",
        "Jun Zhang"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T18:37:55+00:00",
          "link": "https://arxiv.org/abs/2506.19030v1",
          "size": "7774kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T05:10:03+00:00",
          "link": "https://arxiv.org/abs/2506.19030v2",
          "size": "7770kb",
          "version": "v2"
        }
      ],
      "title": "WiLLM: an Open Framework for LLM Services over Wireless Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19030",
        "HTML": "https://arxiv.org/html/2506.19030v2",
        "PDF": "https://arxiv.org/pdf/2506.19030"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on LLM services over wireless systems and introduces a framework for LLM service research within this context. It does not discuss any aspect of LLM training data collection, processing, or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06763",
      "abstract": "The framework is designed to improve performance in the analysis of combined as well as single anatomical perspectives for MRI disease diagnosis. It specifically addresses the performance degradation observed in state-of-the-art (SOTA) models, particularly when processing axial, coronal, and sagittal anatomical planes. The paper introduces the FOLC-Net framework, which incorporates a novel federated-optimized lightweight architecture with approximately 1.217 million parameters and a storage requirement of only 0.9 MB. FOLC-Net integrates Manta-ray foraging optimization (MRFO) mechanisms for efficient model structure generation, global model cloning for scalable training, and ConvNeXt for enhanced client adaptability. The model was evaluated on combined multi-view data as well as individual views, such as axial, coronal, and sagittal, to assess its robustness in various medical imaging scenarios. Moreover, FOLC-Net tests a ShallowFed model on different data to evaluate its ability to generalize beyond the training dataset. The results show that FOLC-Net outperforms existing models, particularly in the challenging sagittal view. For instance, FOLC-Net achieved an accuracy of 92.44% on the sagittal view, significantly higher than the 88.37% accuracy of study method (DL + Residual Learning) and 88.95% of DL models. Additionally, FOLC-Net demonstrated improved accuracy across all individual views, providing a more reliable and robust solution for medical image analysis in decentralized environments. FOLC-Net addresses the limitations of existing SOTA models by providing a framework that ensures better adaptability to individual views while maintaining strong performance in multi-view settings. The incorporation of MRFO, global model cloning, and ConvNeXt ensures that FOLC-Net performs better in real-world medical applications.",
      "authors": [
        "Saif Ur Rehman Khan",
        "Muhammad Nabeel Asim",
        "Sebastian Vollmer",
        "Andreas Dengel"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T11:40:41+00:00",
          "link": "https://arxiv.org/abs/2507.06763v1",
          "size": "26557kb",
          "version": "v1"
        }
      ],
      "title": "FOLC-Net: A Federated-Optimized Lightweight Architecture for Enhanced MRI Disease Diagnosis across Axial, Coronal, and Sagittal Views",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06763",
        "HTML": "https://arxiv.org/html/2507.06763v1",
        "PDF": "https://arxiv.org/pdf/2507.06763"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a federated-optimized lightweight architecture for MRI disease diagnosis, which does not pertain to LLM training data collection, processing, or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06821",
      "abstract": "Multi-modal emotion recognition has garnered increasing attention as it plays a significant role in human-computer interaction (HCI) in recent years. Since different discrete emotions may exist at the same time, compared with single-class emotion recognition, emotion distribution learning (EDL) that identifies a mixture of basic emotions has gradually emerged as a trend. However, existing EDL methods face challenges in mining the heterogeneity among multiple modalities. Besides, rich semantic correlations across arbitrary basic emotions are not fully exploited. In this paper, we propose a multi-modal emotion distribution learning framework, named HeLo, aimed at fully exploring the heterogeneity and complementary information in multi-modal emotional data and label correlation within mixed basic emotions. Specifically, we first adopt cross-attention to effectively fuse the physiological data. Then, an optimal transport (OT)-based heterogeneity mining module is devised to mine the interaction and heterogeneity between the physiological and behavioral representations. To facilitate label correlation learning, we introduce a learnable label embedding optimized by correlation matrix alignment. Finally, the learnable label embeddings and label correlation matrices are integrated with the multi-modal representations through a novel label correlation-driven cross-attention mechanism for accurate emotion distribution learning. Experimental results on two publicly available datasets demonstrate the superiority of our proposed method in emotion distribution learning.",
      "authors": [
        "Chuhang Zheng",
        "Chunwei Tian",
        "Jie Wen",
        "Daoqiang Zhang",
        "and Qi Zhu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T13:08:58+00:00",
          "link": "https://arxiv.org/abs/2507.06821v1",
          "size": "11235kb",
          "version": "v1"
        }
      ],
      "title": "HeLo: Heterogeneous Multi-Modal Fusion with Label Correlation for Emotion Distribution Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06821",
        "HTML": "https://arxiv.org/html/2507.06821v1",
        "PDF": "https://arxiv.org/pdf/2507.06821"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on emotion distribution learning using a multi-modal fusion framework. It does not contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.01735",
      "abstract": "Reward Models (RMs) are crucial to aligning large language models (LLMs), but the degree to which an RM specialized to one task (e.g. writing) generalizes to new tasks (e.g. math) is often not known a priori, often making using only one fixed RM to train LLMs suboptimal. However, optimizing LLMs with multiple RMs simultaneously can incur a prohibitively high computational cost and lead to conflicting signals from different RMs that may degrade performance. To address these challenges, we introduce LASeR (Learning to Adaptively Select Rewards), which frames reward model selection as a multi-armed bandit problem, efficiently and iteratively training LLMs using multiple RMs by selecting the most well-suited RM for each instance. On commonsense and math reasoning tasks, we show that LASeR boosts iterative LLM training, improving the absolute average accuracy of Llama-3-8B over three datasets by 2.67% over an ensemble of RM scores while also showing superior efficiency (e.g., a 2x speedup). Moreover, on WildChat (open-ended instruction-following tasks), LASeR leads to a 72.69% AlpacaEval win rate over the RM score ensemble baseline. Extending to long-context generation, LASeR improves by 2.96 F1 points (avg.) on single-document QA tasks and 2.97 F1 points on few-shot learning over the RM score ensemble baseline with best-of-n sampling.",
      "authors": [
        "Duy Nguyen",
        "Archiki Prasad",
        "Elias Stengel-Eskin",
        "Mohit Bansal"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-02T16:46:38+00:00",
          "link": "https://arxiv.org/abs/2410.01735v1",
          "size": "1298kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T17:19:50+00:00",
          "link": "https://arxiv.org/abs/2410.01735v2",
          "size": "1305kb",
          "version": "v2"
        }
      ],
      "title": "LASeR: Learning to Adaptively Select Reward Models with Multi-Armed Bandits",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.01735",
        "HTML": "https://arxiv.org/html/2410.01735v2",
        "PDF": "https://arxiv.org/pdf/2410.01735"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses optimizing LLM training by selecting appropriate reward models, but it doesn't primarily focus on LLM training data processing operations like data collection or filtering."
      },
      "tasks": [
        "Instruction Following",
        "Math",
        "Multi-Armed Bandits"
      ],
      "repo_urls": [
        "https://github.com/duykhuongnguyen/laser-mab"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.01909",
      "abstract": "Objective: Clinical implementation of deformable image registration (DIR) requires voxel-based spatial accuracy metrics such as manually identified landmarks, which are challenging to implement for highly mobile gastrointestinal (GI) organs. To address this, patient-specific digital twins (DT) modeling temporally varying motion were created to assess the accuracy of DIR methods. Approach: 21 motion phases simulating digestive GI motion as 4D sequences were generated from static 3D patient scans using published analytical GI motion models through a semi-automated pipeline. Eleven datasets, including six T2w FSE MRI (T2w MRI), two T1w 4D golden-angle stack-of-stars, and three contrast-enhanced CT scans. The motion amplitudes of the DTs were assessed against real patient stomach motion amplitudes extracted from independent 4D MRI datasets. The generated DTs were then used to assess six different DIR methods using target registration error, Dice similarity coefficient, and the 95th percentile Hausdorff distance using summary metrics and voxel-level granular visualizations. Finally, for a subset of T2w MRI scans from patients treated with MR-guided radiation therapy, dose distributions were warped and accumulated to assess dose warping errors, including evaluations of DIR performance in both low- and high-dose regions for patient-specific error estimation. Main results: Our proposed pipeline synthesized DTs modeling realistic GI motion, achieving mean and maximum motion amplitudes and a mean log Jacobian determinant within 0.8 mm and 0.01, respectively, similar to published real-patient gastric motion data. It also enables the extraction of detailed quantitative DIR performance metrics and rigorous validation of dose mapping accuracy. Significance: The pipeline enables rigorously testing DIR tools for dynamic, anatomically complex regions enabling granular spatial and dosimetric accuracies.",
      "authors": [
        "Jorge Tapias Gomez",
        "Nishant Nadkarni",
        "Lando S. Bosma",
        "Jue Jiang",
        "Ergys D. Subashi",
        "William P. Segars",
        "James M. Balter",
        "Mert R Sabuncu",
        "Neelam Tyagi and Harini Veeraraghavan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T17:22:47+00:00",
          "link": "https://arxiv.org/abs/2507.01909v1",
          "size": "14067kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T15:55:53+00:00",
          "link": "https://arxiv.org/abs/2507.01909v2",
          "size": "14067kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T16:36:58+00:00",
          "link": "https://arxiv.org/abs/2507.01909v3",
          "size": "14068kb",
          "version": "v3"
        }
      ],
      "title": "Modality-agnostic, patient-specific digital twins modeling temporally varying digestive motion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01909",
        "PDF": "https://arxiv.org/pdf/2507.01909"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses digital twins and image registration, focusing on clinical implementation and motion modeling, with no connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06265",
      "abstract": "Understanding how different AI models encode the same high-level concepts, such as objects or attributes, remains challenging because each model typically produces its own isolated representation. Existing interpretability methods like Sparse Autoencoders (SAEs) produce latent concepts individually for each model, resulting in incompatible concept spaces and limiting cross-model interpretability. To address this, we introduce SPARC (Sparse Autoencoders for Aligned Representation of Concepts), a new framework that learns a single, unified latent space shared across diverse architectures and modalities (e.g., vision models like DINO, and multimodal models like CLIP). SPARC's alignment is enforced through two key innovations: (1) a Global TopK sparsity mechanism, ensuring all input streams activate identical latent dimensions for a given concept; and (2) a Cross-Reconstruction Loss, which explicitly encourages semantic consistency between models. On Open Images, SPARC dramatically improves concept alignment, achieving a Jaccard similarity of 0.80, more than tripling the alignment compared to previous methods. SPARC creates a shared sparse latent space where individual dimensions often correspond to similar high-level concepts across models and modalities, enabling direct comparison of how different architectures represent identical concepts without requiring manual alignment or model-specific analysis. As a consequence of this aligned representation, SPARC also enables practical applications such as text-guided spatial localization in vision-only models and cross-model/cross-modal retrieval. Code and models are available at https://github.com/AtlasAnalyticsLab/SPARC.",
      "authors": [
        "Ali Nasiri-Sarvi",
        "Hassan Rivaz",
        "Mahdi S. Hosseini"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T22:29:00+00:00",
          "link": "https://arxiv.org/abs/2507.06265v1",
          "size": "44060kb",
          "version": "v1"
        }
      ],
      "title": "SPARC: Concept-Aligned Sparse Autoencoders for Cross-Model and Cross-Modal Interpretability",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06265",
        "HTML": "https://arxiv.org/html/2507.06265v1",
        "PDF": "https://arxiv.org/pdf/2507.06265"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on cross-model and cross-modal interpretability using Sparse Autoencoders and does not discuss LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06400",
      "abstract": "Multiple object tracking (MOT) technology has made significant progress in terrestrial applications, but underwater tracking scenarios remain underexplored despite their importance to marine ecology and aquaculture. We present Multiple Fish Tracking Dataset 2025 (MFT25), the first comprehensive dataset specifically designed for underwater multiple fish tracking, featuring 15 diverse video sequences with 408,578 meticulously annotated bounding boxes across 48,066 frames. Our dataset captures various underwater environments, fish species, and challenging conditions including occlusions, similar appearances, and erratic motion patterns. Additionally, we introduce Scale-aware and Unscented Tracker (SU-T), a specialized tracking framework featuring an Unscented Kalman Filter (UKF) optimized for non-linear fish swimming patterns and a novel Fish-Intersection-over-Union (FishIoU) matching that accounts for the unique morphological characteristics of aquatic species. Extensive experiments demonstrate that our SU-T baseline achieves state-of-the-art performance on MFT25, with 34.1 HOTA and 44.6 IDF1, while revealing fundamental differences between fish tracking and terrestrial object tracking scenarios. MFT25 establishes a robust foundation for advancing research in underwater tracking systems with important applications in marine biology, aquaculture monitoring, and ecological conservation. The dataset and codes are released at https://vranlee.github.io/SU-T/.",
      "authors": [
        "Weiran Li",
        "Yeqiang Liu",
        "Qiannan Guo",
        "Yijie Wei",
        "Hwa Liang Leo",
        "Zhenbo Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T21:08:12+00:00",
          "link": "https://arxiv.org/abs/2507.06400v1",
          "size": "9769kb",
          "version": "v1"
        }
      ],
      "title": "When Trackers Date Fish: A Benchmark and Framework for Underwater Multiple Fish Tracking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06400",
        "HTML": "https://arxiv.org/html/2507.06400v1",
        "PDF": "https://arxiv.org/pdf/2507.06400"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on developing a dataset for underwater fish tracking and a tracking framework, with no emphasis on LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06623",
      "abstract": "The data extraction stages of reviews are resource-intensive, and researchers may seek to expediate data extraction using online (large language models) LLMs and review protocols. Claude 3.5 Sonnet was used to trial two approaches that used a review protocol to prompt data extraction from 10 evidence sources included in a case study scoping review. A protocol-based approach was also used to review extracted data. Limited performance evaluation was undertaken which found high accuracy for the two extraction approaches (83.3% and 100%) when extracting simple, well-defined citation details; accuracy was lower (9.6% and 15.8%) when extracting more complex, subjective data items. Considering all data items, both approaches had precision >90% but low recall (<25%) and F1 scores (<40%). The context of a complex scoping review, open response types and methodological approach likely impacted performance due to missed and misattributed data. LLM feedback considered the baseline extraction accurate and suggested minor amendments: four of 15 (26.7%) to citation details and 8 of 38 (21.1%) to key findings data items were considered to potentially add value. However, when repeating the process with a dataset featuring deliberate errors, only 2 of 39 (5%) errors were detected. Review-protocol-based methods used for expediency require more robust performance evaluation across a range of LLMs and review contexts with comparison to conventional prompt engineering approaches. We recommend researchers evaluate and report LLM performance if using them similarly to conduct data extraction or review extracted data. LLM feedback contributed to protocol adaptation and may assist future review protocol drafting.",
      "authors": [
        "James Stewart-Evans",
        "Emma Wilson",
        "Tessa Langley",
        "Andrew Prayle",
        "Angela Hands",
        "Karen Exley",
        "Jo Leonardi-Bee"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T07:50:55+00:00",
          "link": "https://arxiv.org/abs/2507.06623v1",
          "size": "2453kb",
          "version": "v1"
        }
      ],
      "title": "Expediting data extraction using a large language model (LLM) and scoping review protocol: a methodological study within a complex scoping review",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06623",
        "PDF": "https://arxiv.org/pdf/2507.06623"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses using LLMs for data extraction in review contexts which relates to using LLMs as tools for data processing. However, it doesn't make fundamental contributions to LLM training data processing itself."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06996",
      "abstract": "Electronic Health Records (EHR) are time-series relational databases that record patient interactions and medical events over time, serving as a critical resource for healthcare research and applications. However, privacy concerns and regulatory restrictions limit the sharing and utilization of such sensitive data, necessitating the generation of synthetic EHR datasets. Unlike previous EHR synthesis methods, which typically generate medical records consisting of expert-chosen features (e.g. a few vital signs or structured codes only), we introduce RawMed, the first framework to synthesize multi-table, time-series EHR data that closely resembles raw EHRs. Using text-based representation and compression techniques, RawMed captures complex structures and temporal dynamics with minimal preprocessing. We also propose a new evaluation framework for multi-table time-series synthetic EHRs, assessing distributional similarity, inter-table relationships, temporal dynamics, and privacy. Validated on two open-source EHR datasets, RawMed outperforms baseline models in fidelity and utility. The code is available at https://github.com/eunbyeol-cho/RawMed.",
      "authors": [
        "Eunbyeol Cho",
        "Jiyoun Kim",
        "Minjae Lee",
        "Sungjin Park",
        "Edward Choi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T16:22:22+00:00",
          "link": "https://arxiv.org/abs/2507.06996v1",
          "size": "298kb",
          "version": "v1"
        }
      ],
      "title": "Generating Multi-Table Time Series EHR from Latent Space with Minimal Preprocessing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06996",
        "HTML": "https://arxiv.org/html/2507.06996v1",
        "PDF": "https://arxiv.org/pdf/2507.06996"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper presents RawMed, a framework for synthesizing EHR datasets through text-based representation and compression techniques. It focuses on generating synthetic datasets with minimal preprocessing, which is directly related to data generation for training data creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07041",
      "abstract": "Differentially Private Stochastic Gradient Descent (DP-SGD) has been widely used for solving optimization problems with privacy guarantees in machine learning and statistics. Despite this, a systematic non-asymptotic convergence analysis for DP-SGD, particularly in the context of online problems and local differential privacy (LDP) models, remains largely elusive. Existing non-asymptotic analyses have focused on non-private optimization methods, and hence are not applicable to privacy-preserving optimization problems. This work initiates the analysis to bridge this gap and opens the door to non-asymptotic convergence analysis of private optimization problems. A general framework is investigated for the online LDP model in stochastic optimization problems. We assume that sensitive information from individuals is collected sequentially and aim to estimate, in real-time, a static parameter that pertains to the population of interest. Most importantly, we conduct a comprehensive non-asymptotic convergence analysis of the proposed estimators in finite-sample situations, which gives their users practical guidelines regarding the effect of various hyperparameters, such as step size, parameter dimensions, and privacy budgets, on convergence rates. Our proposed estimators are validated in the theoretical and practical realms by rigorous mathematical derivations and carefully constructed numerical experiments.",
      "authors": [
        "Enze Shi",
        "Jinhan Xie",
        "Bei Jiang",
        "Linglong Kong",
        "Xuming He"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Methodology (stat.ME)",
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T17:06:01+00:00",
          "link": "https://arxiv.org/abs/2507.07041v1",
          "size": "2622kb",
          "version": "v1"
        }
      ],
      "title": "Non-Asymptotic Analysis of Online Local Private Learning with SGD",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07041",
        "HTML": "https://arxiv.org/html/2507.07041v1",
        "PDF": "https://arxiv.org/pdf/2507.07041"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study focuses on non-asymptotic convergence analysis of differentially private stochastic gradient descent in online learning problems, without discussing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.20853",
      "abstract": "Pre-training Transformers in FP4 precision is becoming a promising approach to gain substantial speedup, but it comes with a considerable loss of accuracy. Microscaling (MX) data format provides a fine-grained per-group quantization method to improve the representation ability of the FP4 format and is supported by the next-generation Blackwell GPU architecture. However, training with MXFP4 data format still results in significant degradation and there is a lack of systematic research on the reason.\n  In this work, we propose a novel training method TetraJet for a more accurate FP4 training. We comprehensively evaluate all of the quantizers involved in the training, and identify the weight oscillation problem in the forward pass as the main source of the degradation in MXFP4 training. Therefore, we introduce two novel methods, EMA Quantizer (Q-EMA) and Adaptive Ramping Optimizer (Q-Ramping), to resolve the oscillation problem. Extensive experiments on Vision Transformers demonstrate that TetraJet consistently outperforms the existing 4-bit training methods, and Q-EMA & Q-Ramping can provide additional enhancement by effectively reducing oscillation. We decreased the accuracy degradation by more than $50\\%$ compared to the baseline, and can even achieve competitive performance compared to full precision training. The codes are available at https://github.com/thu-ml/TetraJet-MXFP4Training",
      "authors": [
        "Yuxiang Chen",
        "Haocheng Xi",
        "Jun Zhu",
        "Jianfei Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-28T08:51:55+00:00",
          "link": "https://arxiv.org/abs/2502.20853v1",
          "size": "559kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T03:07:28+00:00",
          "link": "https://arxiv.org/abs/2502.20853v2",
          "size": "351kb",
          "version": "v2"
        }
      ],
      "title": "Oscillation-Reduced MXFP4 Training for Vision Transformers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.20853",
        "HTML": "https://arxiv.org/html/2502.20853v2",
        "PDF": "https://arxiv.org/pdf/2502.20853"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving training methods for Vision Transformers using FP4 precision, primarily through novel quantization techniques, but does not focus on LLM training data processing."
      },
      "tasks": [
        "Quantization"
      ],
      "repo_urls": [
        "https://github.com/thu-ml/tetrajet-mxfp4training"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.06505",
      "abstract": "Recent advancements in text-to-image generation have spurred interest in personalized human image generation, which aims to create novel images featuring specific human identities as reference images indicate. Although existing methods achieve high-fidelity identity preservation, they often struggle with limited multi-ID usability and inadequate facial editability. We present DynamicID, a tuning-free framework supported by a dual-stage training paradigm that inherently facilitates both single-ID and multi-ID personalized generation with high fidelity and flexible facial editability. Our key innovations include: 1) Semantic-Activated Attention (SAA), which employs query-level activation gating to minimize disruption to the original model when injecting ID features and achieve multi-ID personalization without requiring multi-ID samples during training. 2) Identity-Motion Reconfigurator (IMR), which leverages contrastive learning to effectively disentangle and re-entangle facial motion and identity features, thereby enabling flexible facial editing. Additionally, we have developed a curated VariFace-10k facial dataset, comprising 10k unique individuals, each represented by 35 distinct facial images. Experimental results demonstrate that DynamicID outperforms state-of-the-art methods in identity fidelity, facial editability, and multi-ID personalization capability.",
      "authors": [
        "Xirui Hu",
        "Jiahao Wang",
        "Hao Chen",
        "Weizhan Zhang",
        "Benqi Wang",
        "Yikun Li",
        "Haishun Nan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-09T08:16:19+00:00",
          "link": "https://arxiv.org/abs/2503.06505v1",
          "size": "22915kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T10:21:24+00:00",
          "link": "https://arxiv.org/abs/2503.06505v2",
          "size": "23665kb",
          "version": "v2"
        }
      ],
      "title": "DynamicID: Zero-Shot Multi-ID Image Personalization with Flexible Facial Editability",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.06505",
        "HTML": "https://arxiv.org/html/2503.06505v2",
        "PDF": "https://arxiv.org/pdf/2503.06505"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The focus is on personalized image generation with a new dataset developed for evaluation, but it does not substantively focus on LLM training data processing."
      },
      "models": [
        {
          "model_path": "meteorite2023/DynamicID",
          "downloads": "0",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/meteorite2023/DynamicID"
        }
      ],
      "tasks": [
        "Contrastive Learning",
        "Facial Editing",
        "Image Generation",
        "Text to Image Generation",
        "Text-to-Image Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.05519",
      "abstract": "We consider the problem of implementing deontic modal logic. We show how (deontic) modal operators can be expressed elegantly using default negation (negation-as-failure) and strong negation present in answer set programming (ASP). We propose using global constraints of ASP to represent obligations and impermissibilities of deontic modal logic. We show that our proposed representation results in the various paradoxes of deontic modal logic being elegantly resolved.",
      "authors": [
        "Gopal Gupta",
        "Abhiramon Rajasekharan",
        "Alexis R. Tudor",
        "Elmer Salazar",
        "Joaqu\\'in Arias"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T22:31:54+00:00",
          "link": "https://arxiv.org/abs/2507.05519v1",
          "size": "279kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T16:04:20+00:00",
          "link": "https://arxiv.org/abs/2507.05519v2",
          "size": "279kb",
          "version": "v2"
        }
      ],
      "title": "Modeling (Deontic) Modal Operators With the s(CASP) Goal-directed Predicate Answer Set Programming System",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05519",
        "HTML": "https://arxiv.org/html/2507.05519v2",
        "PDF": "https://arxiv.org/pdf/2507.05519"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is centered on implementing deontic modal logic using answer set programming, with no discussion on LLM training data or dataset processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06679",
      "abstract": "Recent advances in large vision-language models (VLMs) have shown remarkable progress in solving the text-promptable object counting problem. Representative methods typically specify text prompts with object category information in images. This however is insufficient for training the model to accurately distinguish the number of objects in the counting task. To this end, we propose QUANet, which introduces novel quantity-oriented text prompts with a vision-text quantity alignment loss to enhance the model's quantity awareness. Moreover, we propose a dual-stream adaptive counting decoder consisting of a Transformer stream, a CNN stream, and a number of Transformer-to-CNN enhancement adapters (T2C-adapters) for density map prediction. The T2C-adapters facilitate the effective knowledge communication and aggregation between the Transformer and CNN streams. A cross-stream quantity ranking loss is proposed in the end to optimize the ranking orders of predictions from the two streams. Extensive experiments on standard benchmarks such as FSC-147, CARPK, PUCPR+, and ShanghaiTech demonstrate our model's strong generalizability for zero-shot class-agnostic counting. Code is available at https://github.com/viscom-tongji/QUANet",
      "authors": [
        "Miaojing Shi",
        "Xiaowen Zhang",
        "Zijie Yue",
        "Yong Luo",
        "Cairong Zhao and Li Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T09:12:33+00:00",
          "link": "https://arxiv.org/abs/2507.06679v1",
          "size": "6315kb",
          "version": "v1"
        }
      ],
      "title": "Text-promptable Object Counting via Quantity Awareness Enhancement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06679",
        "HTML": "https://arxiv.org/html/2507.06679v1",
        "PDF": "https://arxiv.org/pdf/2507.06679"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses the problem of text-promptable object counting using vision-language models and does not focus on LLM training data processing or dataset creation for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "1811.08522",
      "abstract": "We consider an unconstrained tangential Dirichlet boundary control problem for the Stokes equations with an $ L^2 $ penalty on the boundary control. The contribution of this paper is twofold. First, we obtain well-posedness and regularity results for the tangential Dirichlet control problem on a convex polygonal domain. The analysis contains new features not found in similar Dirichlet control problems for the Poisson equation; an interesting result is that the optimal control has higher local regularity on the individual edges of the domain compared to the global regularity on the entire boundary. Second, we propose and analyze a hybridizable discontinuous Galerkin (HDG) method to approximate the solution. For convex polygonal domains, our theoretical convergence rate for the control is optimal with respect to the global regularity on the entire boundary. We present numerical experiments to demonstrate the performance of the HDG method.",
      "authors": [
        "Wei Gong",
        "Weiwei Hu",
        "Mariano Mateos",
        "John R. Singler",
        "Yangwen Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2018-11-20T22:45:34+00:00",
          "link": "https://arxiv.org/abs/1811.08522v1",
          "size": "287kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T06:31:00+00:00",
          "link": "https://arxiv.org/abs/1811.08522v2",
          "size": "366kb",
          "version": "v2"
        }
      ],
      "title": "Analysis of a hybridizable discontinuous Galerkin scheme for the tangential control of the Stokes system",
      "links": {
        "Abstract": "https://arxiv.org/abs/1811.08522",
        "HTML": "https://arxiv.org/html/1811.08522v2",
        "PDF": "https://arxiv.org/pdf/1811.08522"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses a discontinuous Galerkin method for boundary control problems in the Stokes system, but does not discuss LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2308.05423",
      "abstract": "Physics Informed Neural Networks is a numerical method which uses neural networks to approximate solutions of partial differential equations. It has received a lot of attention and is currently used in numerous physical and engineering problems. The mathematical understanding of these methods is limited, and in particular, it seems that, a consistent notion of stability is missing. Towards addressing this issue we consider model problems of partial differential equations, namely linear elliptic and parabolic PDEs. Motivated by tools of nonlinear calculus of variations we systematically show that coercivity of the energies and associated compactness provide a consistent framework for stability. For time discrete training we show that if these properties fail to hold then methods may become unstable. Furthermore, using tools of $\\Gamma$- convergence we provide new convergence results for weak solutions by only requiring that the neural network spaces are chosen to have suitable approximation properties. While our analysis is motivated by neural network-based approximation spaces, the framework developed here is applicable to any class of discrete functions satisfying the relevant approximation properties, and hence may serve as a foundation for the broader study of variational nonlinear PDE solvers.",
      "authors": [
        "Dimitrios Gazoulis",
        "Ioannis Gkanis and Charalambos G. Makridakis"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2023-08-10T08:35:55+00:00",
          "link": "https://arxiv.org/abs/2308.05423v1",
          "size": "657kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T08:57:32+00:00",
          "link": "https://arxiv.org/abs/2308.05423v2",
          "size": "488kb",
          "version": "v2"
        }
      ],
      "title": "On the Stability and Convergence of Physics Informed Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2308.05423",
        "HTML": "https://arxiv.org/html/2308.05423v2",
        "PDF": "https://arxiv.org/pdf/2308.05423"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper examines stability and convergence in Physics Informed Neural Networks for solving PDEs, which is unrelated to LLM training data engineering or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.06700",
      "abstract": "Computing accessible information for an ensemble of quantum states is a basic problem in quantum information theory. The optimality criterion recently obtained in [7], when applied to specific ensembles of states, leads to nontrivial tight lower bounds for the Shannon entropy that are discrete relatives of the famous log-Sobolev inequality. In this light, the hypothesis of globally information-optimal measurement for an ensemble of equiangular equiprobable states (quantum pyramids) put forward and numerically substantiated in [2] is reconsidered and the corresponding tight entropy inequalities are proposed and proved. Via the optimality criterion, this provides also the first proof of the conjecture concerning globally information-optimal observables for quantum pyramids put forward in [2].",
      "authors": [
        "A. S. Holevo",
        "A. V. Utkin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Information Theory (cs.IT)",
        "Mathematical Physics (math-ph)",
        "Information Theory (math.IT)",
        "Mathematical Physics (math.MP)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-07T07:50:49+00:00",
          "link": "https://arxiv.org/abs/2506.06700v1",
          "size": "21kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T14:12:28+00:00",
          "link": "https://arxiv.org/abs/2506.06700v2",
          "size": "25kb",
          "version": "v2"
        }
      ],
      "title": "Quantum accessible information and classical entropy inequalities",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.06700",
        "HTML": "https://arxiv.org/html/2506.06700v2",
        "PDF": "https://arxiv.org/pdf/2506.06700"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with quantum information theory and entropy inequalities, unrelated to any process of LLM training data collection, processing, or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05558",
      "abstract": "We present A1, an agentic execution driven system that transforms any LLM into an end-to-end exploit generator. A1 has no hand-crafted heuristics and provides the agent with six domain-specific tools that enable autonomous vulnerability discovery. The agent can flexibly leverage these tools to understand smart contract behavior, generate exploit strategies, test them on blockchain states, and refine approaches based on execution feedback. All outputs are concretely validated to eliminate false positives.\n  The evaluation across 36 real-world vulnerable contracts on Ethereum and Binance Smart Chain demonstrates a 62.96% (17 out of 27) success rate on the VERITE benchmark. Beyond the VERITE dataset, A1 identified 9 additional vulnerable contracts, with 5 cases occurring after the strongest model's training cutoff date. Across all 26 successful cases, A1 extracts up to 8.59 million USD per case and 9.33 million USD total. Through 432 experiments across six LLMs, we analyze iteration-wise performance showing diminishing returns with average marginal gains of +9.7%, +3.7%, +5.1%, and +2.8% for iterations 2-5 respectively, with per-experiment costs ranging $0.01-$3.59. A Monte Carlo analysis of 19 historical attacks shows success probabilities of 85.9%-88.8% without detection delays.\n  We investigate whether an attacker or a defender benefits most from deploying A1 as a continuous on-chain scanning system. Our model shows that OpenAI's o3-pro maintains profitability up to a 30.0 days scanning delay at 0.100% vulnerability incidence rates, while faster models require >=1.000% rates to break-even. The findings exposes a troubling asymmetry: at 0.1% vulnerability rates, attackers achieve an on-chain scanning profitability at a \\$6000 exploit value, while defenders require \\$60000, raising fundamental questions about whether AI agents inevitably favor exploitation over defense.",
      "authors": [
        "Arthur Gervais and Liyi Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T00:45:26+00:00",
          "link": "https://arxiv.org/abs/2507.05558v1",
          "size": "1615kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T11:25:39+00:00",
          "link": "https://arxiv.org/abs/2507.05558v2",
          "size": "1615kb",
          "version": "v2"
        }
      ],
      "title": "AI Agent Smart Contract Exploit Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05558",
        "HTML": "https://arxiv.org/html/2507.05558v2",
        "PDF": "https://arxiv.org/pdf/2507.05558"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a system for generating smart contract exploits utilizing pre-existing LLMs but does not focus on training data processing or dataset creation for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06262",
      "abstract": "Data poisoning attacks pose significant threats to machine learning models by introducing malicious data into the training process, thereby degrading model performance or manipulating predictions. Detecting and sifting out poisoned data is an important method to prevent data poisoning attacks. Limited by classical computation frameworks, upcoming larger-scale and more complex datasets may pose difficulties for detection. We introduce the unique speedup of quantum computing for the first time in the task of detecting data poisoning. We present Q-Detection, a quantum-classical hybrid defense method for detecting poisoning attacks. Q-Detection also introduces the Q-WAN, which is optimized using quantum computing devices. Experimental results using multiple quantum simulation libraries show that Q-Detection effectively defends against label manipulation and backdoor attacks. The metrics demonstrate that Q-Detection consistently outperforms the baseline methods and is comparable to the state-of-the-art. Theoretical analysis shows that Q-Detection is expected to achieve more than a 20% speedup using quantum computing power.",
      "authors": [
        "Haoqi He and Xiaokai Lin and Jiancai Chen and Yan Xiao"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T18:43:34+00:00",
          "link": "https://arxiv.org/abs/2507.06262v1",
          "size": "435kb",
          "version": "v1"
        }
      ],
      "title": "Q-Detection: A Quantum-Classical Hybrid Poisoning Attack Detection Method",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06262",
        "HTML": "https://arxiv.org/html/2507.06262v1",
        "PDF": "https://arxiv.org/pdf/2507.06262"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses detecting poisoned data, which involves some aspect of data filtering, but its primary focus is on defense mechanisms against poisoning attacks rather than broader training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06449",
      "abstract": "Federated Learning (FL), as a distributed learning paradigm, trains models over distributed clients' data. FL is particularly beneficial for distributed training of Diffusion Models (DMs), which are high-quality image generators that require diverse data. However, challenges such as high communication costs and data heterogeneity persist in training DMs similar to training Transformers and Convolutional Neural Networks. Limited research has addressed these issues in FL environments. To address this gap and challenges, we introduce a novel approach, FedPhD, designed to efficiently train DMs in FL environments. FedPhD leverages Hierarchical FL with homogeneity-aware model aggregation and selection policy to tackle data heterogeneity while reducing communication costs. The distributed structured pruning of FedPhD enhances computational efficiency and reduces model storage requirements in clients. Our experiments across multiple datasets demonstrate that FedPhD achieves high model performance regarding Fr\\'echet Inception Distance (FID) scores while reducing communication costs by up to $88\\%$. FedPhD outperforms baseline methods achieving at least a $34\\%$ improvement in FID, while utilizing only $56\\%$ of the total computation and communication resources.",
      "authors": [
        "Qianyu Long",
        "Qiyuan Wang",
        "Christos Anagnostopoulos and Daning Bi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T23:24:07+00:00",
          "link": "https://arxiv.org/abs/2507.06449v1",
          "size": "1303kb",
          "version": "v1"
        }
      ],
      "title": "FedPhD: Federated Pruning with Hierarchical Learning of Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06449",
        "HTML": "https://arxiv.org/html/2507.06449v1",
        "PDF": "https://arxiv.org/pdf/2507.06449"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "While the paper discusses federated learning and efficient training of diffusion models, it does not address LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06485",
      "abstract": "Despite advances in reinforcement learning (RL)-based video reasoning with large language models (LLMs), data collection and finetuning remain significant challenges. These methods often rely on large-scale supervised fine-tuning (SFT) with extensive video data and long Chain-of-Thought (CoT) annotations, making them costly and hard to scale. To address this, we present Video-RTS, a new approach to improve video reasoning capability with drastically improved data efficiency by combining data-efficient RL with a video-adaptive test-time scaling (TTS) strategy. Based on observations about the data scaling of RL samples, we skip the resource-intensive SFT step and employ efficient pure-RL training with output-based rewards, requiring no additional annotations or extensive fine-tuning. Furthermore, to utilize computational resources more efficiently, we introduce a sparse-to-dense video TTS strategy that improves inference by iteratively adding frames based on output consistency. We validate our approach on multiple video reasoning benchmarks, showing that Video-RTS surpasses existing video reasoning models by an average of 2.4% in accuracy using only 3.6% training samples. For example, Video-RTS achieves a 4.2% improvement on Video-Holmes, a recent and challenging video reasoning benchmark, and a 2.6% improvement on MMVU. Notably, our pure RL training and adaptive video TTS offer complementary strengths, enabling Video-RTS's strong reasoning performance.",
      "authors": [
        "Ziyang Wang",
        "Jaehong Yoon",
        "Shoubin Yu",
        "Md Mohaiminul Islam",
        "Gedas Bertasius",
        "Mohit Bansal"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T02:06:13+00:00",
          "link": "https://arxiv.org/abs/2507.06485v1",
          "size": "552kb",
          "version": "v1"
        }
      ],
      "title": "Video-RTS: Rethinking Reinforcement Learning and Test-Time Scaling for Efficient and Enhanced Video Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06485",
        "HTML": "https://arxiv.org/html/2507.06485v1",
        "PDF": "https://arxiv.org/pdf/2507.06485"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper on Video-RTS focuses on reinforcement learning for video reasoning tasks using LLMs, mentioning data efficiency through pure RL training that doesn't involve additional data annotations. However, it doesn't primarily contribute to general LLM training-data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06507",
      "abstract": "In the past year, Generative Recommendations (GRs) have undergone substantial advancements, especially in leveraging the powerful sequence modeling and reasoning capabilities of Large Language Models (LLMs) to enhance overall recommendation performance. LLM-based GRs are forming a new paradigm that is distinctly different from discriminative recommendations, showing strong potential to replace traditional recommendation systems heavily dependent on complex hand-crafted features. In this paper, we provide a comprehensive survey aimed at facilitating further research of LLM-based GRs. Initially, we outline the general preliminaries and application cases of LLM-based GRs. Subsequently, we introduce the main considerations when LLM-based GRs are applied in real industrial scenarios. Finally, we explore promising directions for LLM-based GRs. We hope that this survey contributes to the ongoing advancement of the GR domain.",
      "authors": [
        "Zhen Yang",
        "Haitao Lin",
        "Jiawei xue",
        "Ziji Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T03:13:08+00:00",
          "link": "https://arxiv.org/abs/2507.06507v1",
          "size": "57kb",
          "version": "v1"
        }
      ],
      "title": "GR-LLMs: Recent Advances in Generative Recommendation Based on Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06507",
        "HTML": "https://arxiv.org/html/2507.06507v1",
        "PDF": "https://arxiv.org/pdf/2507.06507"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is a survey of recent advances in generative recommendation systems using LLMs, focusing on application cases and considerations rather than LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07059",
      "abstract": "This article explores how Chinese female users tactically mobilise platform features and hashtag practices to construct vernacular forms and an exclusive space of feminist resistance under algorithmic and cultural constraints. Focusing on the reappropriation of the hashtag Baby Supplementary Food (BSF), a female-dominated lifestyle app with over 300 million users, we analyse how users create a female-centered counterpublic through self-infantilisation, algorithmic play, and aesthetic withdrawal. Using the Computer-Assisted Learning and Measurement (CALM) framework, we analysed 1580 posts and propose the concept of girlhood feminism: an affective, culturally grounded form of soft resistance that refuses patriarchal life scripts without seeking direct confrontation or visibility. Rather than challenging censorship and misogyny directly, users rework platform affordances and domestic idioms to carve out emotional and symbolic spaces of dissent. Situated within the broader dynamics of East Asia's compressed modernity, this essay challenges liberal feminist paradigms grounded in confrontation and transparency. It advances a regionally grounded framework for understanding how gendered publics are navigated, negotiated, and quietly reimagined in algorithmically governed spaces.",
      "authors": [
        "Meng Liang",
        "Xiaoyue Zhang",
        "Linqi Ye"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T20:12:24+00:00",
          "link": "https://arxiv.org/abs/2507.07059v1",
          "size": "1356kb",
          "version": "v1"
        }
      ],
      "title": "Girlhood Feminism as Soft Resistance: Affective Counterpublics and Algorithmic Negotiation on RedNote",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07059",
        "PDF": "https://arxiv.org/pdf/2507.07059"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper examines social dynamics on a lifestyle app and feminist practices, which are not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2407.03010",
      "abstract": "In this paper, we introduce the Context-Aware Video Instance Segmentation (CAVIS), a novel framework designed to enhance instance association by integrating contextual information adjacent to each object. To efficiently extract and leverage this information, we propose the Context-Aware Instance Tracker (CAIT), which merges contextual data surrounding the instances with the core instance features to improve tracking accuracy. Additionally, we design the Prototypical Cross-frame Contrastive (PCC) loss, which ensures consistency in object-level features across frames, thereby significantly enhancing matching accuracy. CAVIS demonstrates superior performance over state-of-the-art methods on all benchmark datasets in video instance segmentation (VIS) and video panoptic segmentation (VPS). Notably, our method excels on the OVIS dataset, known for its particularly challenging videos. Project page: https://seung-hun-lee.github.io/projects/CAVIS/",
      "authors": [
        "Seunghun Lee",
        "Jiwan Seo",
        "Kiljoon Han",
        "Minwoo Choi",
        "Sunghoon Im"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-03T11:11:16+00:00",
          "link": "https://arxiv.org/abs/2407.03010v1",
          "size": "2452kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T12:23:10+00:00",
          "link": "https://arxiv.org/abs/2407.03010v2",
          "size": "3963kb",
          "version": "v2"
        }
      ],
      "title": "CAVIS: Context-Aware Video Instance Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.03010",
        "HTML": "https://arxiv.org/html/2407.03010v2",
        "PDF": "https://arxiv.org/pdf/2407.03010"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "It introduces a framework for video instance segmentation enhancement through contextual information, which does not involve LLM training data processing."
      },
      "tasks": [
        "Instance Segmentation",
        "Panoptic Segmentation",
        "Segmentation",
        "Semantic Segmentation",
        "Video Instance Segmentation",
        "Video Panoptic Segmentation"
      ],
      "repo_urls": [
        "https://github.com/Seung-Hun-Lee/CAVIS"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.05763",
      "abstract": "Integrating powerful but computationally expensive Pre-trained Language Models (PLMs) with Graph Neural Networks (GNNs) is a key challenge, especially on text-rich heterophilic graphs. We propose the Graph Masked Language Model (GMLM), a framework designed for the efficient and effective fusion of graph structure and text semantics. GMLM employs a two-stage process: first, a contrastive pre-training stage with a novel soft masking technique builds a robust multi-scale GNN; second, an end-to-end fine-tuning stage uses a dynamic active node selection strategy for scalability and a bi-directional cross-attention module for deep fusion. Experiments on five heterophilic benchmarks show GMLM achieves state-of-the-art results on four, significantly outperforming prior GNN and large LLM-based methods. For instance, it improves accuracy on the Texas dataset by over 8\\% and on Wisconsin by nearly 5\\%. Our work demonstrates that a sophisticated, deeply-integrated architecture can be more effective and efficient than larger, general-purpose models for text-rich graph representation learning.",
      "authors": [
        "Aarush Sinha"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-24T07:44:01+00:00",
          "link": "https://arxiv.org/abs/2503.05763v1",
          "size": "920kb",
          "version": "v1"
        },
        {
          "date": "2025-03-21T16:42:49+00:00",
          "link": "https://arxiv.org/abs/2503.05763v2",
          "size": "37638kb",
          "version": "v2"
        },
        {
          "date": "2025-06-02T08:42:48+00:00",
          "link": "https://arxiv.org/abs/2503.05763v3",
          "size": "4201kb",
          "version": "v3"
        },
        {
          "date": "2025-07-08T06:21:27+00:00",
          "link": "https://arxiv.org/abs/2503.05763v4",
          "size": "107kb",
          "version": "v4"
        },
        {
          "date": "2025-07-09T03:08:21+00:00",
          "link": "https://arxiv.org/abs/2503.05763v5",
          "size": "107kb",
          "version": "v5"
        }
      ],
      "title": "GMLM: Bridging Graph Neural Networks and Language Models for Heterophilic Node Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.05763",
        "HTML": "https://arxiv.org/html/2503.05763v5",
        "PDF": "https://arxiv.org/pdf/2503.05763"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper primarily focuses on integrating GNNs with PLMs for node classification, but does not make substantial contributions to LLM training data processing."
      },
      "tasks": [
        "Graph Learning",
        "Knowledge Graphs",
        "Node Classification"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.04431",
      "abstract": "Medical decision-making is a critical task, where errors can result in serious, potentially life-threatening consequences. While full automation remains challenging, hybrid frameworks that combine machine intelligence with human oversight offer a practical alternative. In this paper, we present MedGellan, a lightweight, annotation-free framework that uses a Large Language Model (LLM) to generate clinical guidance from raw medical records, which is then used by a physician to predict diagnoses. MedGellan uses a Bayesian-inspired prompting strategy that respects the temporal order of clinical data. Preliminary experiments show that the guidance generated by the LLM with MedGellan improves diagnostic performance, particularly in recall and $F_1$ score.",
      "authors": [
        "Debodeep Banerjee",
        "Burcu Sayin",
        "Stefano Teso",
        "Andrea Passerini"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-06T15:31:01+00:00",
          "link": "https://arxiv.org/abs/2507.04431v1",
          "size": "76kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T18:16:26+00:00",
          "link": "https://arxiv.org/abs/2507.04431v2",
          "size": "76kb",
          "version": "v2"
        }
      ],
      "title": "MedGellan: LLM-Generated Medical Guidance to Support Physicians",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.04431",
        "HTML": "https://arxiv.org/html/2507.04431v2",
        "PDF": "https://arxiv.org/pdf/2507.04431"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "MedGellan leverages LLM to generate medical guidance from raw medical records but does not focus primarily on processing or enhancing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06426",
      "abstract": "Typically, learned robot controllers are trained via relatively unsystematic regimens and evaluated with coarse-grained outcome measures such as average cumulative reward. The typical approach is useful to compare learning algorithms but provides limited insight into the effects of different training regimens and little understanding about the richness and complexity of learned behaviors. Likewise, human infants and other animals are \"trained\" via unsystematic regimens, but in contrast, developmental psychologists evaluate their performance in highly-controlled experiments with fine-grained measures such as success, speed of walking, and prospective adjustments. However, the study of learned behavior in human infants is limited by the practical constraints of training and testing babies. Here, we present a case study that applies methods from developmental psychology to study the learned behavior of the simulated bipedal robot Cassie. Following research on infant walking, we systematically designed reinforcement learning training regimens and tested the resulting controllers in simulated environments analogous to those used for babies--but without the practical constraints. Results reveal new insights into the behavioral impact of different training regimens and the development of Cassie's learned behaviors relative to infants who are learning to walk. This interdisciplinary baby-robot approach provides inspiration for future research designed to systematically test effects of training on the development of complex learned robot behaviors.",
      "authors": [
        "Devin Crowley",
        "Whitney G. Cole",
        "Christina M. Hospodar",
        "Ruiting Shen",
        "Karen E. Adolph",
        "Alan Fern"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T22:14:05+00:00",
          "link": "https://arxiv.org/abs/2507.06426v1",
          "size": "7926kb",
          "version": "v1"
        }
      ],
      "title": "Evaluating Robots Like Human Infants: A Case Study of Learned Bipedal Locomotion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06426",
        "HTML": "https://arxiv.org/html/2507.06426v1",
        "PDF": "https://arxiv.org/pdf/2507.06426"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study analyzes learned behaviors in robots using developmental psychology methods and does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06701",
      "abstract": "Imitation Learning from Observation (IfO) offers a powerful way to learn behaviors at large-scale: Unlike behavior cloning or offline reinforcement learning, IfO can leverage action-free demonstrations and thus circumvents the need for costly action-labeled demonstrations or reward functions. However, current IfO research focuses on idealized scenarios with mostly bimodal-quality data distributions, restricting the meaningfulness of the results. In contrast, this paper investigates more nuanced distributions and introduces a method to learn from such data, moving closer to a paradigm in which imitation learning can be performed iteratively via self-improvement. Our method adapts RL-based imitation learning to action-free demonstrations, using a value function to transfer information between expert and non-expert data. Through comprehensive evaluation, we delineate the relation between different data distributions and the applicability of algorithms and highlight the limitations of established methods. Our findings provide valuable insights for developing more robust and practical IfO techniques on a path to scalable behaviour learning.",
      "authors": [
        "Michael Bloesch",
        "Markus Wulfmeier",
        "Philemon Brakel",
        "Todor Davchev",
        "Martina Zambelli",
        "Jost Tobias Springenberg",
        "Abbas Abdolmaleki",
        "William F Whitney",
        "Nicolas Heess",
        "Roland Hafner",
        "Martin Riedmiller"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T09:55:23+00:00",
          "link": "https://arxiv.org/abs/2507.06701v1",
          "size": "1135kb",
          "version": "v1"
        }
      ],
      "title": "Value from Observations: Towards Large-Scale Imitation Learning via Self-Improvement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06701",
        "HTML": "https://arxiv.org/html/2507.06701v1",
        "PDF": "https://arxiv.org/pdf/2507.06701"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses imitation learning from observation without focusing on LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06974",
      "abstract": "We present FRaN-X, a Framing and Narratives Explorer that automatically detects entity mentions and classifies their narrative roles directly from raw text. FRaN-X comprises a two-stage system that combines sequence labeling with fine-grained role classification to reveal how entities are portrayed as protagonists, antagonists, or innocents, using a unique taxonomy of 22 fine-grained roles nested under these three main categories. The system supports five languages (Bulgarian, English, Hindi, Russian, and Portuguese) and two domains (the Russia-Ukraine Conflict and Climate Change). It provides an interactive web interface for media analysts to explore and compare framing across different sources, tackling the challenge of automatically detecting and labeling how entities are framed. Our system allows end users to focus on a single article as well as analyze up to four articles simultaneously. We provide aggregate level analysis including an intuitive graph visualization that highlights the narrative a group of articles are pushing. Our system includes a search feature for users to look up entities of interest, along with a timeline view that allows analysts to track an entity's role transitions across different contexts within the article. The FRaN-X system and the trained models are licensed under an MIT License. FRaN-X is publicly accessible at https://fran-x.streamlit.app/ and a video demonstration is available at https://youtu.be/VZVi-1B6yYk.",
      "authors": [
        "Artur Muratov",
        "Hana Fatima Shaikh",
        "Vanshikaa Jani",
        "Tarek Mahmoud",
        "Zhuohan Xie",
        "Daniil Orel",
        "Aaryamonvikram Singh",
        "Yuxia Wang",
        "Aadi Joshi",
        "Hasan Iqbal",
        "Ming Shan Hee",
        "Dhruv Sahnan",
        "Nikolaos Nikolaidis",
        "Purifica\\c{c}\\~ao Silvano",
        "Dimitar Dimitrov",
        "Roman Yangarber",
        "Ricardo Campos",
        "Al\\'ipio Jorge",
        "Nuno Guimar\\~aes",
        "Elisa Sartori",
        "Nicolas Stefanovitch",
        "Giovanni Da San Martino",
        "Jakub Piskorski",
        "Preslav Nakov"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T16:04:51+00:00",
          "link": "https://arxiv.org/abs/2507.06974v1",
          "size": "2298kb",
          "version": "v1"
        }
      ],
      "title": "FRaN-X: FRaming and Narratives-eXplorer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06974",
        "HTML": "https://arxiv.org/html/2507.06974v1",
        "PDF": "https://arxiv.org/pdf/2507.06974"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "FRaN-X is focused on narrative role detection in text using a predefined system, not on processing or creating LLM training datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07036",
      "abstract": "Spatial phenomena often exhibit heterogeneity across spatial extents and in proximity, making them complex to model-especially in dynamic regions like ice shelves and sea ice. In this study, we address this challenge by exploring the linkages between sea ice retreat and Antarctic ice shelf (AIS) melt. Although atmospheric forcing and basal melting have been widely studied, the direct impact of sea ice retreat on AIS mass loss remains underexplored. Traditional models treat sea ice and AIS as separate systems. It limits their ability to capture localized linkages and cascading feedback. To overcome this, we propose Spatial-Link, a novel graph-based framework that quantifies spatial heterogeneity to capture linkages between sea ice retreat and AIS melt. Our method constructs a spatial graph using Delaunay triangulation of satellite-derived ice change matrices, where nodes represent regions of significant change and edges encode proximity and directional consistency. We extract and statistically validate linkage paths using breadth-first search and Monte Carlo simulations. Results reveal non-local, spatially heterogeneous coupling patterns, suggesting sea ice loss can initiate or amplify downstream AIS melt. Our analysis shows how sea ice retreat evolves over an oceanic grid and progresses toward ice shelves-establishing a direct linkage. To our knowledge, this is the first proposed methodology linking sea ice retreat to AIS melt. Spatial-Link offers a scalable, data-driven tool to improve sea-level rise projections and inform climate adaptation strategies.",
      "authors": [
        "Maloy Kumar Devnath",
        "Sudip Chakraborty",
        "Vandana P. Janeja"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-18T17:19:07+00:00",
          "link": "https://arxiv.org/abs/2507.07036v1",
          "size": "33991kb",
          "version": "v1"
        }
      ],
      "title": "Modeling Heterogeneity across Varying Spatial Extents: Discovering Linkages between Sea Ice Retreat and Ice Shelve Melt in the Antarctic",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07036",
        "HTML": "https://arxiv.org/html/2507.07036v1",
        "PDF": "https://arxiv.org/pdf/2507.07036"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on modeling spatial phenomena and linkages between Antarctic ice shelf melt and sea ice retreat, which does not involve LLM training data processing or data engineering for LLM purposes."
      },
      "source": "arXiv"
    },
    {
      "id": "1302.1314",
      "abstract": "The Sinc quadrature and the Sinc indefinite integration are approximation formulas for definite integration and indefinite integration, respectively, which can be applied on any interval by using an appropriate variable transformation. Their convergence rates have been analyzed for typical cases including finite, semi-infinite, and infinite intervals. In addition, for verified automatic integration, more explicit error bounds that are computable have been recently given on a finite interval. In this paper, such explicit error bounds are given in the remaining cases on semi-infinite and infinite intervals.",
      "authors": [
        "Tomoaki Okayama"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2013-02-06T10:31:17+00:00",
          "link": "https://arxiv.org/abs/1302.1314v1",
          "size": "27kb",
          "version": "v1"
        },
        {
          "date": "2013-10-20T05:08:07+00:00",
          "link": "https://arxiv.org/abs/1302.1314v2",
          "size": "28kb",
          "version": "v2"
        }
      ],
      "title": "Error Estimates with Explicit Constants for Sinc Quadrature and Sinc Indefinite Integration over Infinite Intervals",
      "links": {
        "Abstract": "https://arxiv.org/abs/1302.1314",
        "PDF": "https://arxiv.org/pdf/1302.1314"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on Sinc quadrature and indefinite integration over infinite intervals, which pertains to numerical analysis rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06360",
      "abstract": "We present Pyrosome, a generic framework for modular language metatheory that embodies a novel approach to extensible semantics and compilation, implemented in Coq. Common techniques for semantic reasoning are often tied to the specific structures of the languages and compilers that they support. In Pyrosome, verified compilers are fully extensible, meaning that to extend a language (even with a new kind of effect) simply requires defining and verifying the compilation of the new feature, reusing the old correctness theorem for all other cases. The novel enabling idea is an inductive formulation of equivalence preservation that supports the addition of new rules to the source language, target language, and compiler.\n  Pyrosome defines a formal, deeply embedded notion of programming languages with semantics given by dependently sorted equational theories, so all compiler-correctness proofs boil down to type-checking and equational reasoning. We support vertical composition of any compilers expressed in our framework in addition to feature extension. As a case study, we present a multipass compiler from System F with simple references, through CPS translation and closure conversion. Specifically, we demonstrate how we can build such a compiler incrementally by starting with a compiler for simply typed lambda-calculus and adding natural numbers, the unit type, recursive functions, and a global heap, then extending judgments with a type environment and adding type abstraction, all while reusing the original theorems. We also present a linear version of the simply typed CPS pass and compile a small imperative language to the simply typed target to show how Pyrosome handles substructural typing and imperative features.",
      "authors": [
        "Dustin Jamner",
        "Gabriel Kammer",
        "Ritam Nag",
        "Adam Chlipala"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T19:47:55+00:00",
          "link": "https://arxiv.org/abs/2507.06360v1",
          "size": "121kb",
          "version": "v1"
        }
      ],
      "title": "Pyrosome: Verified Compilation for Modular Metatheory",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06360",
        "HTML": "https://arxiv.org/html/2507.06360v1",
        "PDF": "https://arxiv.org/pdf/2507.06360"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on verified compilation within a modular language framework, particularly through Pyrosome. It does not discuss training data processing related to LLMs or any dataset-related operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06419",
      "abstract": "Reward modeling (RM), which captures human preferences to align large language models (LLMs), is increasingly employed in tasks such as model finetuning, response filtering, and ranking. However, due to the inherent complexity of human preferences and the limited coverage of available datasets, reward models often fail under distributional shifts or adversarial perturbations. Existing approaches for identifying such failure modes typically rely on prior knowledge about preference distributions or failure attributes, limiting their practicality in real-world settings where such information is unavailable. In this work, we propose a tractable, preference-distribution agnostic method for discovering reward model failure modes via reward guided controlled decoding. Building on this, we introduce REFORM, a self-improving reward modeling framework that enhances robustness by using the reward model itself to guide the generation of falsely scored responses. These adversarial examples are then used to augment the training data and patch the reward model's misaligned behavior. We evaluate REFORM on two widely used preference datasets Anthropic Helpful Harmless (HH) and PKU Beavertails and demonstrate that it significantly improves robustness without sacrificing reward quality. Notably, REFORM preserves performance both in direct evaluation and in downstream policy training, and further improves alignment quality by removing spurious correlations.",
      "authors": [
        "Pankayaraj Pathmanathan and Furong Huang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T21:56:33+00:00",
          "link": "https://arxiv.org/abs/2507.06419v1",
          "size": "11754kb",
          "version": "v1"
        }
      ],
      "title": "Reward Models Can Improve Themselves: Reward-Guided Adversarial Failure Mode Discovery for Robust Reward Modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06419",
        "HTML": "https://arxiv.org/html/2507.06419v1",
        "PDF": "https://arxiv.org/pdf/2507.06419"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces REFORM, a method that enhances reward models by generating adversarial examples, which are then used to augment training data and improve data processing during fine-tuning, focusing on LLM alignment."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06539",
      "abstract": "This paper proposes a high-quality dataset construction method for complex contract information extraction tasks in industrial scenarios and fine-tunes a large language model based on this dataset. Firstly, cluster analysis is performed on industrial contract texts, and GPT-4 and GPT-3.5 are used to extract key information from the original contract data, obtaining high-quality data annotations. Secondly, data augmentation is achieved by constructing new texts, and GPT-3.5 generates unstructured contract texts from randomly combined keywords, improving model robustness. Finally, the large language model is fine-tuned based on the high-quality dataset. Experimental results show that the model achieves excellent overall performance while ensuring high field recall and precision and considering parsing efficiency. LoRA, data balancing, and data augmentation effectively enhance model accuracy and robustness. The proposed method provides a novel and efficient solution for industrial contract information extraction tasks.",
      "authors": [
        "Yunyang Cao",
        "Yanjun Li",
        "Silong Dai"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T04:46:31+00:00",
          "link": "https://arxiv.org/abs/2507.06539v1",
          "size": "2613kb",
          "version": "v1"
        }
      ],
      "title": "Large Language Model for Extracting Complex Contract Information in Industrial Scenes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06539",
        "HTML": "https://arxiv.org/html/2507.06539v1",
        "PDF": "https://arxiv.org/pdf/2507.06539"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper describes a method that creates a high-quality dataset for fine-tuning LLMs, detailing processes like cluster analysis, data augmentation and annotation, which are significant data processing operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06736",
      "abstract": "In the context of growing concerns about power disruptions, grid reliability and the need for decarbonization, this study evaluates a broad range of clean backup power systems (BPSs) to replace traditional emergency diesel generators. A scenario-based stochastic optimization framework using actual load profiles and outage probabilities is proposed to assess the most promising options from a pool of 27 technologies. This framework allows a comparison of cost-effectiveness and environmental impact of individual technologies and hybrid BPSs across various scenarios. The results highlight the trade-off between total annual system cost and emissions. Significant emission reductions can be achieved at moderate cost increases but deep decarbonization levels incur higher costs. Primary and secondary batteries are included in optimal clean fuel-based systems across all decarbonization levels, combining cost-effective power delivery and long-term storage benefits. The findings highlight the often-overlooked importance of fuel replacement on both emissions and costs. Among the assessed technologies, ammonia generators and hydrogen fuel cells combined with secondary iron-air batteries emerge as cost-effective solutions for achieving decarbonization goals. To ensure a broad range of applicability, the study outlines the impact of emergency fuel purchases, varying demand patterns and demand response options on the optimal BPS. The research findings are valuable for optimizing the design of clean BPSs to economically meet the needs of many facility types and decarbonization targets.",
      "authors": [
        "Jonas Schweiger",
        "Ruaridh Macdonald"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T10:48:31+00:00",
          "link": "https://arxiv.org/abs/2507.06736v1",
          "size": "3575kb",
          "version": "v1"
        }
      ],
      "title": "Techno-economic analysis of decarbonized backup power systems using scenario-based stochastic optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06736",
        "HTML": "https://arxiv.org/html/2507.06736v1",
        "PDF": "https://arxiv.org/pdf/2507.06736"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on techno-economic analysis of clean backup power systems, which is unrelated to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07102",
      "abstract": "Compositional understanding is crucial for human intelligence, yet it remains unclear whether contemporary vision models exhibit it. The dominant machine learning paradigm is built on the premise that scaling data and model sizes will improve out-of-distribution performance, including compositional generalization. We test this premise through controlled experiments that systematically vary data scale, concept diversity, and combination coverage. We find that compositional generalization is driven by data diversity, not mere data scale. Increased combinatorial coverage forces models to discover a linearly factored representational structure, where concepts decompose into additive components. We prove this structure is key to efficiency, enabling perfect generalization from few observed combinations. Evaluating pretrained models (DINO, CLIP), we find above-random yet imperfect performance, suggesting partial presence of this structure. Our work motivates stronger emphasis on constructing diverse datasets for compositional generalization, and considering the importance of representational structure that enables efficient compositional learning. Code available at https://github.com/oshapio/visual-compositional-generalization.",
      "authors": [
        "Arnas Uselis",
        "Andrea Dittadi",
        "Seong Joon Oh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T17:59:03+00:00",
          "link": "https://arxiv.org/abs/2507.07102v1",
          "size": "1681kb",
          "version": "v1"
        }
      ],
      "title": "Does Data Scaling Lead to Visual Compositional Generalization?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07102",
        "HTML": "https://arxiv.org/html/2507.07102v1",
        "PDF": "https://arxiv.org/pdf/2507.07102"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on compositional generalization in vision models, emphasizing the role of data diversity over data scaling but does not discuss specifics of LLM training data processing or improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06567",
      "abstract": "Mixture-of-Experts (MoE) models improve the scalability of large language models (LLMs) by activating only a small subset of relevant experts per input. However, the sheer number of expert networks in an MoE model introduces a significant storage burden for an edge device. To address this challenge, we consider a scenario where experts are dispersed within an edge network for distributed inference. Based on the popular Top-$K$ expert selection strategy, we formulate a latency minimization problem by optimizing expert caching on edge servers under storage constraints. When $K=1$, the problem reduces to a monotone submodular maximization problem with knapsack constraints, for which we design a greedy-based algorithm with a $(1 - 1/e)$-approximation guarantee. For the general case where $K\\geq1$, expert co-activation within the same MoE layer introduces non-submodularity, causing greedy methods to be ineffective. To tackle this issue, we propose a successive greedy decomposition method to decompose the original problem into a series of subproblems, with each being solved by a dynamic programming approach. Furthermore, we design an accelerated algorithm based on the max-convolution technique to obtain the approximate solution with a provable guarantee in polynomial time. Simulation results on various MoE models demonstrate that our method significantly reduces inference latency compared to existing baselines.",
      "authors": [
        "Qian Chen",
        "Xianhao Chen",
        "Kaibin Huang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T05:43:43+00:00",
          "link": "https://arxiv.org/abs/2507.06567v1",
          "size": "883kb",
          "version": "v1"
        }
      ],
      "title": "SlimCaching: Edge Caching of Mixture-of-Experts for Distributed Inference",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06567",
        "HTML": "https://arxiv.org/html/2507.06567v1",
        "PDF": "https://arxiv.org/pdf/2507.06567"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on optimizing expert caching in distributed inference on edge devices, which is not related to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.11222",
      "abstract": "Mixture of Experts (MoE) models are well known for effectively scaling model capacity while preserving computational overheads. In this paper, we establish a rigorous relation between MoE and the self-attention mechanism, showing that each row of a self-attention matrix can be written as a quadratic gating mixture of linear experts. Motivated by this connection, we conduct a comprehensive convergence analysis of MoE models with two different quadratic gating functions, namely the quadratic polynomial gate and the quadratic monomial gate, offering useful insights into the design of gating and experts for the MoE framework. First, our analysis indicates that the use of the quadratic monomial gate yields an improved sample efficiency for estimating parameters and experts compared to the quadratic polynomial gate. Second, parameter and expert estimation rates become significantly faster when employing non-linear experts in place of linear experts. Combining these theoretical insights with the above link between MoE and self-attention, we propose a novel \\emph{active-attention} mechanism where we apply a non-linear activation function to the value matrix in the formula of self-attention. Finally, we demonstrate that the proposed active-attention outperforms the standard self-attention through several extensive experiments in various tasks, including image classification, language modeling, and multivariate time series forecasting.",
      "authors": [
        "Pedram Akbarian",
        "Huy Nguyen",
        "Xing Han",
        "Nhat Ho"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-15T03:06:37+00:00",
          "link": "https://arxiv.org/abs/2410.11222v1",
          "size": "1224kb",
          "version": "v1"
        },
        {
          "date": "2024-10-16T01:30:15+00:00",
          "link": "https://arxiv.org/abs/2410.11222v2",
          "size": "1223kb",
          "version": "v2"
        },
        {
          "date": "2025-07-08T22:45:25+00:00",
          "link": "https://arxiv.org/abs/2410.11222v3",
          "size": "1237kb",
          "version": "v3"
        }
      ],
      "title": "Quadratic Gating Mixture of Experts: Statistical Insights into Self-Attention",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.11222",
        "HTML": "https://arxiv.org/html/2410.11222v3",
        "PDF": "https://arxiv.org/pdf/2410.11222"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores connections between mixture of experts and self-attention mechanisms without discussing LLM training data processing techniques or dataset creation."
      },
      "tasks": [
        "Computational Efficiency",
        "Mixture-of-Experts",
        "parameter estimation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.04670",
      "abstract": "Recent advancements in multimodal large language models (MLLM) have shown a strong ability in visual perception, reasoning abilities, and vision-language understanding. However, the visual matching ability of MLLMs is rarely studied, despite finding the visual correspondence of objects is essential in computer vision. Our research reveals that the matching capabilities in recent MLLMs still exhibit systematic shortcomings, even with current strong MLLMs models, GPT-4o. In particular, we construct a Multimodal Visual Matching (MMVM) benchmark to fairly benchmark over 30 different MLLMs. The MMVM benchmark is built from 15 open-source datasets and Internet videos with manual annotation. We categorize the data samples of MMVM benchmark into eight aspects based on the required cues and capabilities to more comprehensively evaluate and analyze current MLLMs. In addition, we have designed an automatic annotation pipeline to generate the MMVM SFT dataset, including 220K visual matching data with reasoning annotation. To our knowledge, this is the first visual corresponding dataset and benchmark for the MLLM community. Finally, we present CoLVA, a novel contrastive MLLM with two novel technical designs: fine-grained vision expert with object-level contrastive learning and instruction augmentation strategy. The former learns instance discriminative tokens, while the latter further improves instruction following ability. CoLVA-InternVL2-4B achieves an overall accuracy (OA) of 49.80\\% on the MMVM benchmark, surpassing GPT-4o and the best open-source MLLM, Qwen2VL-72B, by 7.15\\% and 11.72\\% OA, respectively. These results demonstrate the effectiveness of our MMVM SFT dataset and our novel technical designs. Code, benchmark, dataset, and models will be released.",
      "authors": [
        "Yikang Zhou",
        "Tao Zhang",
        "Shilin Xu",
        "Shihao Chen",
        "Qianyu Zhou",
        "Yunhai Tong",
        "Shunping Ji",
        "Jiangning Zhang",
        "Lu Qi",
        "Xiangtai Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-08T18:30:53+00:00",
          "link": "https://arxiv.org/abs/2501.04670v1",
          "size": "21301kb",
          "version": "v1"
        },
        {
          "date": "2025-01-31T16:12:22+00:00",
          "link": "https://arxiv.org/abs/2501.04670v2",
          "size": "11426kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T08:04:21+00:00",
          "link": "https://arxiv.org/abs/2501.04670v3",
          "size": "12139kb",
          "version": "v3"
        }
      ],
      "title": "Are They the Same? Exploring Visual Correspondence Shortcomings of Multimodal LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.04670",
        "HTML": "https://arxiv.org/html/2501.04670v3",
        "PDF": "https://arxiv.org/pdf/2501.04670"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces a new dataset, the MMVM SFT dataset, with detailed data processing steps including the creation of an automatic annotation pipeline and manual annotation from diverse sources, which is a substantial contribution to training data processing."
      },
      "models": [
        {
          "model_path": "zhouyik/colva_internvl2_4b",
          "downloads": "15",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/zhouyik/colva_internvl2_4b"
        }
      ],
      "tasks": [
        "Contrastive Learning"
      ],
      "repo_urls": [
        "https://github.com/zhouyiks/colva"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.04320",
      "abstract": "Causal inference is often portrayed as fundamentally distinct from predictive modeling, with its own terminology, goals, and intellectual challenges. But at its core, causal inference is simply a structured instance of prediction under distribution shift. In both cases, we begin with labeled data from a source domain and seek to generalize to a target domain where outcomes are not observed. The key difference is that in causal inference, the labels -- potential outcomes -- are selectively observed based on treatment assignment, introducing bias that must be addressed through assumptions. This perspective reframes causal estimation as a familiar generalization problem and highlights how techniques from predictive modeling, such as reweighting and domain adaptation, apply directly to causal tasks. It also clarifies that causal assumptions are not uniquely strong -- they are simply more explicit. By viewing causal inference through the lens of prediction, we demystify its logic, connect it to familiar tools, and make it more accessible to practitioners and educators alike.",
      "authors": [
        "Carlos Fern\\'andez-Lor\\'ia"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Methodology (stat.ME)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-06T01:37:50+00:00",
          "link": "https://arxiv.org/abs/2504.04320v1",
          "size": "1082kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T05:38:26+00:00",
          "link": "https://arxiv.org/abs/2504.04320v2",
          "size": "526kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T10:00:04+00:00",
          "link": "https://arxiv.org/abs/2504.04320v3",
          "size": "509kb",
          "version": "v3"
        }
      ],
      "title": "Causal Inference Isn't Special: Why It's Just Another Prediction Problem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.04320",
        "HTML": "https://arxiv.org/html/2504.04320v3",
        "PDF": "https://arxiv.org/pdf/2504.04320"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on reframing causal inference as a prediction problem and discusses generalization across domains, with no focus on LLM training data processing."
      },
      "tasks": [
        "Causal Inference",
        "Domain Adaptation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.05314",
      "abstract": "In order to mitigate economical, ecological, and societal challenges in electric scooter (e-scooter) sharing systems, we develop an autonomous e-scooter prototype. Our vision is to design a fully autonomous prototype that can find its way to the next parking spot, high-demand area, or charging station. In this work, we propose a path-following model predictive control solution to enable localization and navigation in an urban environment with a provided path to follow. We design a closed-loop architecture that solves the localization and path following problem while allowing the e-scooter to maintain its balance with a previously developed reaction wheel mechanism. Our model predictive control approach facilitates state and input constraints, e.g., adhering to the path width, while remaining executable on a Raspberry Pi 5. We demonstrate the efficacy of our approach in a real-world experiment on our prototype.",
      "authors": [
        "David Meister",
        "Robin Str\\\"asser",
        "Felix Br\\\"andle",
        "Marc Seidel",
        "Benno Bassler",
        "Nathan Gerber",
        "Jan Kautz",
        "Elena Rommel",
        "Frank Allg\\\"ower"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-08T15:01:01+00:00",
          "link": "https://arxiv.org/abs/2505.05314v1",
          "size": "679kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T15:39:18+00:00",
          "link": "https://arxiv.org/abs/2505.05314v2",
          "size": "679kb",
          "version": "v2"
        }
      ],
      "title": "Path-following model predictive control for autonomous e-scooters",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.05314",
        "PDF": "https://arxiv.org/pdf/2505.05314"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research describes an autonomous e-scooter navigation system, with no mention of LLM training data processing or dataset creation."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.00754",
      "abstract": "The integration of Large Language Model (LLMs) blocks with Vision Transformers (ViTs) holds immense promise for vision-only tasks by leveraging the rich semantic knowledge and reasoning capabilities of LLMs. However, a fundamental challenge lies in the inherent modality mismatch between text-centric pretraining of LLMs and vision-centric training of ViTs. Direct fusion often fails to fully exploit the LLM's potential and suffers from unstable finetuning. As a result, LLM blocks are kept frozen while only the vision components are learned. As a remedy to these challenges, we introduce Language-Unlocked Vision Transformers (LUViT), a novel approach that bridges this modality mismatch through a synergistic pre-training strategy. LUViT co-adapts a ViT backbone and an LLM fusion block by (1) employing Masked Auto-Encoding (MAE) to pre-train the ViT for richer visual representations, and (2) concurrently training Low-Rank Adaptation (LoRA) layers within the LLM block using the MAE objective. This joint optimization guides the ViT to produce LLM-aligned features and the LLM to effectively interpret visual information. We demonstrate through extensive experiments that LUViT significantly improves performance on various downstream vision tasks, showcasing a more effective and efficient pathway to harness LLM knowledge for visual understanding.",
      "authors": [
        "Selim Kuzucu",
        "Muhammad Ferjad Naeem",
        "Anna Kukleva",
        "Federico Tombari",
        "Bernt Schiele"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T13:58:21+00:00",
          "link": "https://arxiv.org/abs/2507.00754v1",
          "size": "1422kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T19:44:08+00:00",
          "link": "https://arxiv.org/abs/2507.00754v2",
          "size": "1421kb",
          "version": "v2"
        }
      ],
      "title": "Language-Unlocked ViT (LUViT): Empowering Self-Supervised Vision Transformers with LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.00754",
        "HTML": "https://arxiv.org/html/2507.00754v2",
        "PDF": "https://arxiv.org/pdf/2507.00754"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses enhancing vision transformers using LLMs, mentioning pretraining but does not primarily address LLM training data processing or dataset creation methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06814",
      "abstract": "Low-Light Image Enhancement (LLIE) aims to restore vivid content and details from corrupted low-light images. However, existing standard RGB (sRGB) color space-based LLIE methods often produce color bias and brightness artifacts due to the inherent high color sensitivity. While Hue, Saturation, and Value (HSV) color space can decouple brightness and color, it introduces significant red and black noise artifacts. To address this problem, we propose a new color space for LLIE, namely Horizontal/Vertical-Intensity (HVI), defined by the HV color map and learnable intensity. The HV color map enforces small distances for the red coordinates to remove red noise artifacts, while the learnable intensity compresses the low-light regions to remove black noise artifacts. Additionally, we introduce the Color and Intensity Decoupling Network+ (HVI-CIDNet+), built upon the HVI color space, to restore damaged content and mitigate color distortion in extremely dark regions. Specifically, HVI-CIDNet+ leverages abundant contextual and degraded knowledge extracted from low-light images using pre-trained vision-language models, integrated via a novel Prior-guided Attention Block (PAB). Within the PAB, latent semantic priors can promote content restoration, while degraded representations guide precise color correction, both particularly in extremely dark regions through the meticulously designed cross-attention fusion mechanism. Furthermore, we construct a Region Refinement Block that employs convolution for information-rich regions and self-attention for information-scarce regions, ensuring accurate brightness adjustments. Comprehensive results from benchmark experiments demonstrate that the proposed HVI-CIDNet+ outperforms the state-of-the-art methods on 10 datasets.",
      "authors": [
        "Qingsen Yan",
        "Kangbiao Shi",
        "Yixu Feng",
        "Tao Hu",
        "Peng Wu",
        "Guansong Pang",
        "Yanning Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T13:03:34+00:00",
          "link": "https://arxiv.org/abs/2507.06814v1",
          "size": "9855kb",
          "version": "v1"
        }
      ],
      "title": "HVI-CIDNet+: Beyond Extreme Darkness for Low-Light Image Enhancement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06814",
        "PDF": "https://arxiv.org/pdf/2507.06814"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "Focuses on a new method for low-light image enhancement and color space definition with no connection to LLM training data processing or related dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06827",
      "abstract": "Internet has significantly improved the quality of citizens across the world. Though the internet coverage is quite high, 40% of global population do not have access to broadband internet. This paper presents an analysis of a field survey of population in some areas of Kathmandu, Nepal, an emerging economy. This survey was triggered by intermittent severe congestion of internet in certain areas of the city. People from three different areas were asked about their present experience of internet usage, its impact on their lives and their aspirations for the future. Survey pointed to high speed, low cost, reliable and secure internet as a major aspiration of the respondents. Based on their inputs, this paper presents a sentiment analysis as well as demographic information. Keys insights from this analysis shows that overall sentiment to most queries are positive. The variances of positive sentiments are high whereas those for negative ones are low. Also, some correlations and clusters are observed among the attributes though no dominant component exists in the data.",
      "authors": [
        "Dibakar Das",
        "Barath S Narayan",
        "Aarna Bhammar",
        "Jyotsna Bapat"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T13:23:52+00:00",
          "link": "https://arxiv.org/abs/2507.06827v1",
          "size": "671kb",
          "version": "v1"
        }
      ],
      "title": "Connecting the Unconnected -- Sentiment Analysis of Field Survey of Internet Connectivity in Emerging Economies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06827",
        "HTML": "https://arxiv.org/html/2507.06827v1",
        "PDF": "https://arxiv.org/pdf/2507.06827"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper provides a sentiment analysis of internet connectivity surveys, not related to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07029",
      "abstract": "This paper presents the design and development of an OCR-powered pipeline for efficient table extraction from invoices. The system leverages Tesseract OCR for text recognition and custom post-processing logic to detect, align, and extract structured tabular data from scanned invoice documents. Our approach includes dynamic preprocessing, table boundary detection, and row-column mapping, optimized for noisy and non-standard invoice formats. The resulting pipeline significantly improves data extraction accuracy and consistency, supporting real-world use cases such as automated financial workflows and digital archiving.",
      "authors": [
        "Parshva Dhilankumar Patel"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T16:59:00+00:00",
          "link": "https://arxiv.org/abs/2507.07029v1",
          "size": "17132kb",
          "version": "v1"
        }
      ],
      "title": "Design and Implementation of an OCR-Powered Pipeline for Table Extraction from Invoices",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07029",
        "HTML": "https://arxiv.org/html/2507.07029v1",
        "PDF": "https://arxiv.org/pdf/2507.07029"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on an OCR pipeline for table extraction from invoices, which is not related to LLM training data processing or dataset creation for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2307.14770",
      "abstract": "3D-aware face generators are typically trained on 2D real-life face image datasets that primarily consist of near-frontal face data, and as such, they are unable to construct one-quarter headshot 3D portraits with complete head, neck, and shoulder geometry. Two reasons account for this issue: First, existing facial recognition methods struggle with extracting facial data captured from large camera angles or back views. Second, it is challenging to learn a distribution of 3D portraits covering the one-quarter headshot region from single-view data due to significant geometric deformation caused by diverse body poses. To this end, we first create the dataset 360{\\deg}-Portrait-HQ (360{\\deg}PHQ for short) which consists of high-quality single-view real portraits annotated with a variety of camera parameters (the yaw angles span the entire 360{\\deg} range) and body poses. We then propose 3DPortraitGAN, the first 3D-aware one-quarter headshot portrait generator that learns a canonical 3D avatar distribution from the 360{\\deg}PHQ dataset with body pose self-learning. Our model can generate view-consistent portrait images from all camera angles with a canonical one-quarter headshot 3D representation. Our experiments show that the proposed framework can accurately predict portrait body poses and generate view-consistent, realistic portrait images with complete geometry from all camera angles.",
      "authors": [
        "Yiqian Wu",
        "Hao Xu",
        "Xiangjun Tang",
        "Yue Shangguan",
        "Hongbo Fu",
        "Xiaogang Jin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2023-07-27T11:02:36+00:00",
          "link": "https://arxiv.org/abs/2307.14770v1",
          "size": "45825kb",
          "version": "v1"
        },
        {
          "date": "2023-08-21T06:35:44+00:00",
          "link": "https://arxiv.org/abs/2307.14770v2",
          "size": "25658kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T01:53:09+00:00",
          "link": "https://arxiv.org/abs/2307.14770v3",
          "size": "23885kb",
          "version": "v3"
        }
      ],
      "title": "3DPortraitGAN: Learning One-Quarter Headshot 3D GANs from a Single-View Portrait Dataset with Diverse Body Poses",
      "links": {
        "Abstract": "https://arxiv.org/abs/2307.14770",
        "HTML": "https://arxiv.org/html/2307.14770v3",
        "PDF": "https://arxiv.org/pdf/2307.14770"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper describes the creation of a new dataset (360{\\deg}-Portrait-HQ) with detailed data processing steps, specifically for training a 3D GAN model, making it highly relevant to LLM training data processing."
      },
      "datasets": [
        {
          "dataset_name": "onethousand/360degree-PHQ",
          "downloads": "74",
          "likes": "0",
          "link": "https://huggingface.co/datasets/onethousand/360degree-PHQ"
        }
      ],
      "tasks": [
        "Self-Learning"
      ],
      "repo_urls": [
        "https://github.com/oneThousand1000/3DPortraitGAN"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.16380",
      "abstract": "Machine learning models can assign fixed predictions that preclude individuals from changing their outcome. Existing approaches to audit fixed predictions do so on a pointwise basis, which requires access to an existing dataset of individuals and may fail to anticipate fixed predictions in out-of-sample data. This work presents a new paradigm to identify fixed predictions by finding confined regions of the feature space in which all individuals receive fixed predictions. This paradigm enables the certification of recourse for out-of-sample data, works in settings without representative datasets, and provides interpretable descriptions of individuals with fixed predictions. We develop a fast method to discover confined regions for linear classifiers using mixed-integer quadratically constrained programming. We conduct a comprehensive empirical study of confined regions across diverse applications. Our results highlight that existing pointwise verification methods fail to anticipate future individuals with fixed predictions, while our method both identifies them and provides an interpretable description.",
      "authors": [
        "Connor Lawless",
        "Tsui-Wei Weng",
        "Berk Ustun",
        "Madeleine Udell"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-22T23:06:10+00:00",
          "link": "https://arxiv.org/abs/2502.16380v1",
          "size": "450kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T23:09:48+00:00",
          "link": "https://arxiv.org/abs/2502.16380v2",
          "size": "785kb",
          "version": "v2"
        }
      ],
      "title": "Understanding Fixed Predictions via Confined Regions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.16380",
        "HTML": "https://arxiv.org/html/2502.16380v2",
        "PDF": "https://arxiv.org/pdf/2502.16380"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a method for auditing fixed predictions in machine learning models which are not related to processing or improving LLM training data."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/conlaw/confined_regions"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.20653",
      "abstract": "Histopathology slide digitization introduces scanner-induced domain shift that can significantly impact computational pathology models based on deep learning methods. In the state-of-the-art, this shift is often characterized at a broad scale (slide-level or dataset-level) but not patch-level, which limits our comprehension of the impact of localized tissue characteristics on the accuracy of the deep learning models. To address this challenge, we present a domain shift analysis framework based on UWarp, a novel registration tool designed to accurately align histological slides scanned under varying conditions. UWarp employs a hierarchical registration approach, combining global affine transformations with fine-grained local corrections to achieve robust tissue patch alignment. We evaluate UWarp using two private datasets, CypathLung and BosomShieldBreast, containing whole slide images scanned by multiple devices. Our experiments demonstrate that UWarp outperforms existing open-source registration methods, achieving a median target registration error (TRE) of less than 4 pixels (<1 micrometer at 40x magnification) while significantly reducing computational time. Additionally, we apply UWarp to characterize scanner-induced local domain shift in the predictions of Breast-NEOprAIdict, a deep learning model for breast cancer pathological response prediction. We find that prediction variability is strongly correlated with tissue density on a given patch. Our findings highlight the importance of localized domain shift analysis and suggest that UWarp can serve as a valuable tool for improving model robustness and domain adaptation strategies in computational pathology.",
      "authors": [
        "Antoine Schieb",
        "Bilal Hadjadji",
        "Natalia Fernanda Valderrama",
        "Daniel Tshokola Mweze",
        "Valentin Derang\\`ere",
        "Laurent Arnould",
        "Sylvain Ladoire",
        "Alain Lalande",
        "Alessio Fiorin",
        "Carlos L\\'opez Pablo",
        "No\\`elia Gallardo Borr\\`as",
        "Shrief Abdelazeez",
        "Vincenzo Della Mea",
        "Anna Korzynska",
        "Nathan Vin\\c{c}on",
        "Louis-Oscar Morel"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-26T15:48:38+00:00",
          "link": "https://arxiv.org/abs/2503.20653v1",
          "size": "23494kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T10:57:07+00:00",
          "link": "https://arxiv.org/abs/2503.20653v2",
          "size": "22738kb",
          "version": "v2"
        }
      ],
      "title": "UWarp: A Whole Slide Image Registration Pipeline to Characterize Scanner-Induced Local Domain Shift",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.20653",
        "PDF": "https://arxiv.org/pdf/2503.20653"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a tool for slide registration and domain shift analysis in histopathology, with no mention of LLM training data processing."
      },
      "tasks": [
        "Domain Adaptation",
        "Image Registration",
        "whole slide images"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.23684",
      "abstract": "As software systems grow increasingly complex, explainability has become a crucial non-functional requirement for transparency, user trust, and regulatory compliance. Eliciting explainability requirements is challenging, as different methods capture varying levels of detail and structure. This study examines the efficiency and effectiveness of three commonly used elicitation methods - focus groups, interviews, and online surveys - while also assessing the role of taxonomy usage in structuring and improving the elicitation process. We conducted a case study at a large German IT consulting company, utilizing a web-based personnel management software. A total of two focus groups, 18 interviews, and an online survey with 188 participants were analyzed. The results show that interviews were the most efficient, capturing the highest number of distinct needs per participant per time spent. Surveys collected the most explanation needs overall but had high redundancy. Delayed taxonomy introduction resulted in a greater number and diversity of needs, suggesting that a two-phase approach is beneficial. Based on our findings, we recommend a hybrid approach combining surveys and interviews to balance efficiency and coverage. Future research should explore how automation can support elicitation and how taxonomies can be better integrated into different methods.",
      "authors": [
        "Martin Obaidi",
        "Jakob Droste",
        "Hannah Deters",
        "Marc Herrmann",
        "Raymond Ochsner",
        "Jil Kl\\\"under",
        "Kurt Schneider"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-29T17:23:14+00:00",
          "link": "https://arxiv.org/abs/2505.23684v1",
          "size": "565kb",
          "version": "v1"
        },
        {
          "date": "2025-06-17T11:01:21+00:00",
          "link": "https://arxiv.org/abs/2505.23684v2",
          "size": "513kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T17:13:26+00:00",
          "link": "https://arxiv.org/abs/2505.23684v3",
          "size": "514kb",
          "version": "v3"
        }
      ],
      "title": "How to Elicit Explainability Requirements? A Comparison of Interviews, Focus Groups, and Surveys",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.23684",
        "HTML": "https://arxiv.org/html/2505.23684v3",
        "PDF": "https://arxiv.org/pdf/2505.23684"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study addresses methods for eliciting explainability requirements in software systems and does not discuss LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06310",
      "abstract": "Large language models (LLMs) have been increasingly used to build agents in social simulation because of their impressive abilities to generate fluent, contextually coherent dialogues. Such abilities can enhance the realism of models. However, the pursuit of realism is not necessarily compatible with the epistemic foundation of modelling. We argue that LLM agents, in many regards, are too human to model: they are too expressive, detailed and intractable to be consistent with the abstraction, simplification, and interpretability typically demanded by modelling. Through a model-building thought experiment that converts the Bass diffusion model to an LLM-based variant, we uncover five core dilemmas: a temporal resolution mismatch between natural conversation and abstract time steps; the need for intervention in conversations while avoiding undermining spontaneous agent outputs; the temptation to introduce rule-like instructions in prompts while maintaining conversational naturalness; the tension between role consistency and role evolution across time; and the challenge of understanding emergence, where system-level patterns become obscured by verbose micro textual outputs. These dilemmas steer the LLM agents towards an uncanny valley: not abstract enough to clarify underlying social mechanisms, while not natural enough to represent realistic human behaviour. This exposes an important paradox: the realism of LLM agents can obscure, rather than clarify, social dynamics when misapplied. We tease out the conditions in which LLM agents are ideally suited: where system-level emergence is not the focus, linguistic nuances and meaning are central, interactions unfold in natural time, and stable role identity is more important than long-term behavioural evolution. We call for repositioning LLM agents in the ecosystem of social simulation for future applications.",
      "authors": [
        "Yongchao Zeng",
        "Calum Brown and Mark Rounsevell"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T18:02:36+00:00",
          "link": "https://arxiv.org/abs/2507.06310v1",
          "size": "960kb",
          "version": "v1"
        }
      ],
      "title": "Too Human to Model:The Uncanny Valley of LLMs in Social Simulation -- When Generative Language Agents Misalign with Modelling Principles",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06310",
        "PDF": "https://arxiv.org/pdf/2507.06310"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on the use of LLMs in social simulation and the challenges therein, without any contribution to LLM training data processing or dataset improvement techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06571",
      "abstract": "We propose a unified food-domain QA framework that combines a large-scale multimodal knowledge graph (MMKG) with generative AI. Our MMKG links 13,000 recipes, 3,000 ingredients, 140,000 relations, and 14,000 images. We generate 40,000 QA pairs using 40 templates and LLaVA/DeepSeek augmentation. Joint fine-tuning of Meta LLaMA 3.1-8B and Stable Diffusion 3.5-Large improves BERTScore by 16.2\\%, reduces FID by 37.8\\%, and boosts CLIP alignment by 31.1\\%. Diagnostic analyses-CLIP-based mismatch detection (35.2\\% to 7.3\\%) and LLaVA-driven hallucination checks-ensure factual and visual fidelity. A hybrid retrieval-generation strategy achieves 94.1\\% accurate image reuse and 85\\% adequacy in synthesis. Our results demonstrate that structured knowledge and multimodal generation together enhance reliability and diversity in food QA.",
      "authors": [
        "Srihari K B and Pushpak Bhattacharyya"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T05:59:06+00:00",
          "link": "https://arxiv.org/abs/2507.06571v1",
          "size": "591kb",
          "version": "v1"
        }
      ],
      "title": "Enhancing Food-Domain Question Answering with a Multimodal Knowledge Graph: Hybrid QA Generation and Diversity Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06571",
        "HTML": "https://arxiv.org/html/2507.06571v1",
        "PDF": "https://arxiv.org/pdf/2507.06571"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper describes the creation of a multimodal knowledge graph and the generation of a new dataset of QA pairs, including processing steps like data augmentation with LLaVA/DeepSeek, making a significant contribution to dataset creation for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06576",
      "abstract": "Given a set of source-sink pairs, the maximum multiflow problem asks for the maximum total amount of flow that can be feasibly routed between them. The minimum multicut, a dual problem to multiflow, seeks the minimum-cost set of edges whose removal disconnects all the source-sink pairs. It is easy to see that the value of the minimum multicut is at least that of the maximum multiflow, and their ratio is called the multiflow-multicut gap. The classical max-flow min-cut theorem states that when there is only one source-sink pair, the gap is exactly one. However, in general, it is well known that this gap can be arbitrarily large. In this paper, we study this gap for classes of planar graphs and establish improved lower bound results. In particular, we show that this gap is at least $\\frac{20}{9}$ for the class of planar graphs, improving upon the decades-old lower bound of 2. More importantly, we develop new techniques for proving such a lower bound, which may be useful in other settings as well.",
      "authors": [
        "Sina Kalantarzadeh",
        "Nikhil Kumar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T06:07:32+00:00",
          "link": "https://arxiv.org/abs/2507.06576v1",
          "size": "33kb",
          "version": "v1"
        }
      ],
      "title": "Improved Lower Bounds on Multiflow-Multicut Gaps",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06576",
        "HTML": "https://arxiv.org/html/2507.06576v1",
        "PDF": "https://arxiv.org/pdf/2507.06576"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses theoretical improvements in multicut problems in networks, which is unrelated to processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05261",
      "abstract": "Large language models (LLMs) demonstrate strong capabilities in in-context learning, but verifying the correctness of their generated responses remains a challenge. Prior work has explored attribution at the sentence level, but these methods fall short when users seek attribution for specific keywords within the response, such as numbers, years, or names. To address this limitation, we propose TokenShapley, a novel token-level attribution method that combines Shapley value-based data attribution with KNN-based retrieval techniques inspired by recent advances in KNN-augmented LLMs. By leveraging a precomputed datastore for contextual retrieval and computing Shapley values to quantify token importance, TokenShapley provides a fine-grained data attribution approach. Extensive evaluations on four benchmarks show that TokenShapley outperforms state-of-the-art baselines in token-level attribution, achieving an 11-23% improvement in accuracy.",
      "authors": [
        "Yingtai Xiao",
        "Yuqing Zhu",
        "Sirat Samyoun",
        "Wanrong Zhang",
        "Jiachen T. Wang",
        "Jian Du"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-18T23:17:29+00:00",
          "link": "https://arxiv.org/abs/2507.05261v1",
          "size": "174kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T16:40:38+00:00",
          "link": "https://arxiv.org/abs/2507.05261v2",
          "size": "174kb",
          "version": "v2"
        }
      ],
      "title": "TokenShapley: Token Level Context Attribution with Shapley Value",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05261",
        "HTML": "https://arxiv.org/html/2507.05261v2",
        "PDF": "https://arxiv.org/pdf/2507.05261"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a method for token-level attribution in LLMs using Shapley values and KNN, focusing on model attribution rather than the processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06999",
      "abstract": "Reasoning is a key capability for large language models (LLMs), particularly when applied to complex tasks such as mathematical problem solving. However, multimodal reasoning research still requires further exploration of modality alignment and training costs. Many of these approaches rely on additional data annotation and relevant rule-based rewards to enhance the understanding and reasoning ability, which significantly increases training costs and limits scalability. To address these challenges, we propose the Deliberate-to-Intuitive reasoning framework (D2I) that improves the understanding and reasoning ability of multimodal LLMs (MLLMs) without extra annotations and complex rewards. Specifically, our method sets deliberate reasoning strategies to enhance modality alignment only through the rule-based format reward during training. While evaluating, the reasoning style shifts to intuitive, which removes deliberate reasoning strategies during training and implicitly reflects the model's acquired abilities in the response. D2I outperforms baselines across both in-domain and out-of-domain benchmarks. Our findings highlight the role of format reward in fostering transferable reasoning skills in MLLMs, and inspire directions for decoupling training-time reasoning depth from test-time response flexibility.",
      "authors": [
        "Yahan Yu",
        "Yuyang Dong",
        "Masafumi Oyamada"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T16:25:44+00:00",
          "link": "https://arxiv.org/abs/2507.06999v1",
          "size": "2215kb",
          "version": "v1"
        }
      ],
      "title": "Learning Deliberately, Acting Intuitively: Unlocking Test-Time Reasoning in Multimodal LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06999",
        "HTML": "https://arxiv.org/html/2507.06999v1",
        "PDF": "https://arxiv.org/pdf/2507.06999"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses reasoning abilities in multimodal LLMs through a new framework for modality alignment and does not discuss the processing or creation of training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2403.12431",
      "abstract": "Stereophotogrammetry is an established technique for scene understanding. Its origins go back to at least the 1800s when people first started to investigate using photographs to measure the physical properties of the world. Since then, thousands of approaches have been explored. The classic geometric technique of Shape from Stereo is built on using geometry to define constraints on scene and camera deep learning without any attempt to explicitly model the geometry. In this survey, we explore geometry-inspired deep learning-based frameworks. We compare and contrast geometry enforcing constraints integrated into deep learning frameworks for depth estimation and other closely related vision tasks. We present a new taxonomy for prevalent geometry enforcing constraints used in modern deep learning frameworks. We also present insightful observations and potential future research directions.",
      "authors": [
        "Vibhas K Vats",
        "David J Crandall"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-19T04:41:09+00:00",
          "link": "https://arxiv.org/abs/2403.12431v1",
          "size": "3156kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T00:27:59+00:00",
          "link": "https://arxiv.org/abs/2403.12431v2",
          "size": "3162kb",
          "version": "v2"
        }
      ],
      "title": "Geometric Constraints in Deep Learning Frameworks: A Survey",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.12431",
        "HTML": "https://arxiv.org/html/2403.12431v2",
        "PDF": "https://arxiv.org/pdf/2403.12431"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper surveys geometry-inspired constraints in deep learning frameworks, primarily for depth estimation and vision tasks, and does not discuss LLM training data processing or dataset related workflows."
      },
      "tasks": [
        "Deep Learning",
        "Depth Estimation",
        "Scene Understanding",
        "Survey"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07055",
      "abstract": "Integer factorization is a fundamental problem in algorithmic number theory and computer science. It is considered as a one way or trapdoor function in the (RSA) cryptosystem. To date, from elementary trial division to sophisticated methods like the General Number Field Sieve, no known algorithm can break the problem in polynomial time, while its proved that Shor's algorithm could on a quantum computer. In this paper, we recall some factorization algorithms and then approach the problem under different angles. Firstly, we take the problem from the ring $\\displaystyle\\left(\\mathbb{Z}, \\text{+}, \\cdot\\right)$ to the Lebesgue space $\\mathcal{L}^{1}\\left(X\\right)$ where $X$ can be $\\mathbb{Q}$ or any given interval setting. From this first perspective, integer factorization becomes equivalent to finding the perimeter of a rectangle whose area is known. In this case, it is equivalent to either finding bounds of integrals or finding primitives for some given bounds. Secondly, we take the problem from the ring $\\displaystyle\\left(\\mathbb{Z}, \\text{+}, \\cdot\\right) $ to the ring of matrices $\\left( M_{2}\\text{(}\\mathbb{Z}\\text{)}, \\ \\text{+} \\ \\cdot\\right)$ and show that this problem is equivalent to matrix decomposition, and therefore present some possible computing algorithms, particularly using Gr\\\"obner basis and through matrix diagonalization. Finally, we address the problem depending on algebraic forms of factors and show that this problem is equivalent to finding small roots of a bivariate polynomial through coppersmith's method.\n  The aim of this study is to propose innovative methodological approaches to reformulate this problem, thereby offering new perspectives.",
      "authors": [
        "Gilda Rech Bansimba and Regis Freguin Babindamana"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Number Theory (math.NT)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T17:20:49+00:00",
          "link": "https://arxiv.org/abs/2507.07055v1",
          "size": "79kb",
          "version": "v1"
        }
      ],
      "title": "Integer Factorization: Another perspective",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07055",
        "HTML": "https://arxiv.org/html/2507.07055v1",
        "PDF": "https://arxiv.org/pdf/2507.07055"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses integer factorization and algorithmic perspectives unrelated to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06516",
      "abstract": "Deep neural networks often produce miscalibrated probability estimates, leading to overconfident predictions. A common approach for calibration is fitting a post-hoc calibration map on unseen validation data that transforms predicted probabilities. A key desirable property of the calibration map is instance-wise monotonicity (i.e., preserving the ranking of probability outputs). However, most existing post-hoc calibration methods do not guarantee monotonicity. Previous monotonic approaches either use an under-parameterized calibration map with limited expressive ability or rely on black-box neural networks, which lack interpretability and robustness. In this paper, we propose a family of novel monotonic post-hoc calibration methods, which employs a constrained calibration map parameterized linearly with respect to the number of classes. Our proposed approach ensures expressiveness, robustness, and interpretability while preserving the relative ordering of the probability output by formulating the proposed calibration map as a constrained optimization problem. Our proposed methods achieve state-of-the-art performance across datasets with different deep neural network models, outperforming existing calibration methods while being data and computation-efficient. Our code is available at https://github.com/YunruiZhang/Calibration-by-Constrained-Transformation",
      "authors": [
        "Yunrui Zhang",
        "Gustavo Batista",
        "Salil S. Kanhere"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T03:32:49+00:00",
          "link": "https://arxiv.org/abs/2507.06516v1",
          "size": "120kb",
          "version": "v1"
        }
      ],
      "title": "Instance-Wise Monotonic Calibration by Constrained Transformation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06516",
        "HTML": "https://arxiv.org/html/2507.06516v1",
        "PDF": "https://arxiv.org/pdf/2507.06516"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on calibration methods for neural networks to improve prediction probability estimates, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06621",
      "abstract": "The freight branch of the Swiss national railways, SBB Cargo, offers customers to ship single or few wagons within its wagon load transportation system (WLV). In this system, wagons travel along a transport chain which is a sequence of consecutive trains. Recently, SBB Cargo redesigned its IT systems and renewed the computation of these transport chains. This paper describes the main design decisions and technical details: data structures, search algorithms, mathematical optimization of throughput in the real-time setting, and some selected details for making the algorithms work in the operational software. We also comment on the employed technology stack and finally demonstrate some performance metrics from running operations.",
      "authors": [
        "Carsten Moldenhauer",
        "Philipp Germann",
        "Cedric Heimhofer",
        "Caroline Spieckermann",
        "Andreas Andresen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T07:48:08+00:00",
          "link": "https://arxiv.org/abs/2507.06621v1",
          "size": "2650kb",
          "version": "v1"
        }
      ],
      "title": "Real-time Optimization of Transport Chains for Single Wagon Load Railway Transport",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06621",
        "HTML": "https://arxiv.org/html/2507.06621v1",
        "PDF": "https://arxiv.org/pdf/2507.06621"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes optimization of transport logistics systems for railways, which is unrelated to LLM training data processes or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06774",
      "abstract": "Automated text evaluation has long been a central issue in Natural Language Processing (NLP). Recently, the field has shifted toward using Large Language Models (LLMs) as evaluators-a trend known as the LLM-as-a-Judge paradigm. While promising and easily adaptable across tasks, this approach has seen limited exploration in multilingual contexts. Existing multilingual studies often rely on proprietary models or require extensive training data for fine-tuning, raising concerns about cost, time, and efficiency. In this paper, we propose Checklist Engineering based LLM-as-a-Judge (CE-Judge), a training-free framework that uses checklist intuition for multilingual evaluation with an open-source model. Experiments across multiple languages and three benchmark datasets, under both pointwise and pairwise settings, show that our method generally surpasses the baselines and performs on par with the GPT-4o model.",
      "authors": [
        "Mohammad Ghiasvand Mohammadkhani",
        "Hamid Beigy"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T12:03:06+00:00",
          "link": "https://arxiv.org/abs/2507.06774v1",
          "size": "2204kb",
          "version": "v1"
        }
      ],
      "title": "Checklist Engineering Empowers Multilingual LLM Judges",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06774",
        "HTML": "https://arxiv.org/html/2507.06774v1",
        "PDF": "https://arxiv.org/pdf/2507.06774"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a method for multilingual evaluation using LLMs but does not focus on training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.18709",
      "abstract": "Vision foundation models (FMs) are accelerating the development of digital pathology algorithms and transforming biomedical research. These models learn, in a self-supervised manner, to represent histological features in highly heterogeneous tiles extracted from whole-slide images (WSIs) of real-world patient samples. The performance of these FMs is significantly influenced by the size, diversity, and balance of the pre-training data. However, data selection has been primarily guided by expert knowledge at the WSI level, focusing on factors such as disease classification and tissue types, while largely overlooking the granular details available at the tile level. In this paper, we investigate the potential of unsupervised automatic data curation at the tile-level, taking into account 350 million tiles. Specifically, we apply hierarchical clustering trees to pre-extracted tile embeddings, allowing us to sample balanced datasets uniformly across the embedding space of the pretrained FM. We further identify these datasets are subject to a trade-off between size and balance, potentially compromising the quality of representations learned by FMs, and propose tailored batch sampling strategies to mitigate this effect. We demonstrate the effectiveness of our method through improved performance on a diverse range of clinically relevant downstream tasks.",
      "authors": [
        "Boqi Chen",
        "C\\'edric Vincent-Cuaz",
        "Lydia A. Schoenpflug",
        "Manuel Madeira",
        "Lisa Fournier",
        "Vaishnavi Subramanian",
        "Sonali Andani",
        "Samuel Ruiperez-Campillo",
        "Julia E. Vogt",
        "Rapha\\\"elle Luisier",
        "Dorina Thanou",
        "Viktor H. Koelzer",
        "Pascal Frossard",
        "Gabriele Campanella",
        "Gunnar R\\\"atsch"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-24T14:23:48+00:00",
          "link": "https://arxiv.org/abs/2503.18709v1",
          "size": "4591kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T21:27:45+00:00",
          "link": "https://arxiv.org/abs/2503.18709v2",
          "size": "3973kb",
          "version": "v2"
        }
      ],
      "title": "Revisiting Automatic Data Curation for Vision Foundation Models in Digital Pathology",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.18709",
        "HTML": "https://arxiv.org/html/2503.18709v2",
        "PDF": "https://arxiv.org/pdf/2503.18709"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper investigates unsupervised automatic data curation at the tile-level for vision foundation models, specifically focusing on data processing and batch sampling strategies to improve pre-training data quality."
      },
      "datasets": [
        {
          "dataset_name": "swiss-ai/patho-ssl-data-curation",
          "downloads": "348",
          "likes": "0",
          "link": "https://huggingface.co/datasets/swiss-ai/patho-ssl-data-curation"
        }
      ],
      "tasks": [
        "whole slide images"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.24861",
      "abstract": "We develop a novel interacting-particle method for sampling from non-Gaussian distributions. As a first step, we propose a new way to derive the consensus-based sampling (CBS) algorithm, starting from ensemble-preconditioned Langevin diffusions. We approximate the target potential by its Moreau envelope, such that the gradient in the Langevin equation can be replaced by a proximal operator. We then approximate the proximal operator by a weighted mean, and finally assume that the initial and target distributions are Gaussian, resulting in the CBS dynamics. If we keep only those approximations that can be justified in the non-Gaussian setting, the result is a new interacting-particle method for sampling, which we call localized consensus-based sampling. We prove that our algorithm is affine-invariant and exact for Gaussian distributions in the mean-field setting. Numerical tests illustrate that localized CBS compares favorably to alternative methods in terms of affine-invariance and performance on non-Gaussian distributions.",
      "authors": [
        "Arne Bouillon",
        "Alexander Bodard",
        "Panagiotis Patrinos",
        "Dirk Nuyens",
        "Giovanni Samaey"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-30T17:58:20+00:00",
          "link": "https://arxiv.org/abs/2505.24861v1",
          "size": "992kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T22:55:35+00:00",
          "link": "https://arxiv.org/abs/2505.24861v2",
          "size": "992kb",
          "version": "v2"
        }
      ],
      "title": "A localized consensus-based sampling algorithm",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.24861",
        "HTML": "https://arxiv.org/html/2505.24861v2",
        "PDF": "https://arxiv.org/pdf/2505.24861"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a novel algorithm for sampling from non-Gaussian distributions, not focusing on LLM training data processing or any data-centered contributions."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06750",
      "abstract": "In multi-robot systems (MRS), cooperative localization is a crucial task for enhancing system robustness and scalability, especially in GPS-denied or communication-limited environments. However, adversarial attacks, such as sensor manipulation, and communication jamming, pose significant challenges to the performance of traditional localization methods. In this paper, we propose a novel distributed fault-tolerant cooperative localization framework to enhance resilience against sensor and communication disruptions in adversarial environments. We introduce an adaptive event-triggered communication strategy that dynamically adjusts communication thresholds based on real-time sensing and communication quality. This strategy ensures optimal performance even in the presence of sensor degradation or communication failure. Furthermore, we conduct a rigorous analysis of the convergence and stability properties of the proposed algorithm, demonstrating its resilience against bounded adversarial zones and maintaining accurate state estimation. Robotarium-based experiment results show that our proposed algorithm significantly outperforms traditional methods in terms of localization accuracy and communication efficiency, particularly in adversarial settings. Our approach offers improved scalability, reliability, and fault tolerance for MRS, making it suitable for large-scale deployments in real-world, challenging environments.",
      "authors": [
        "Tohid Kargar Tasooji and Ramviyas Parasuraman"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Multiagent Systems (cs.MA)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T11:15:19+00:00",
          "link": "https://arxiv.org/abs/2507.06750v1",
          "size": "9251kb",
          "version": "v1"
        }
      ],
      "title": "Distributed Fault-Tolerant Multi-Robot Cooperative Localization in Adversarial Environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06750",
        "HTML": "https://arxiv.org/html/2507.06750v1",
        "PDF": "https://arxiv.org/pdf/2507.06750"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses cooperative localization in multi-robot systems and does not involve any discussion on LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06423",
      "abstract": "Rugsafe introduces a comprehensive protocol aimed at mitigating the risks of rug pulls in the cryptocurrency ecosystem. By utilizing cryptographic security measures and economic incentives, the protocol provides a secure multichain system for recovering assets and transforming rugged tokens into opportunities and rewards. Foundational to Rugsafe are specialized vaults where rugged tokens can be securely deposited, and anticoin tokens are issued as receipts. These anticoins are designed to be inversely pegged to the price movement of the underlying rugged token. Users can utilize these anticoins within the ecosystem or choose to burn them, further securing the protocol and earning additional rewards. The supply of the native Rugsafe token is dynamically adjusted based on the volume, value, and activity of rugged tokens, ensuring stability and resilience. By depositing rugged tokens into a vault on several chains, and by burning anticoins, users receive incentives on the RugSafe chain. This protocol's vaults are designed to work in heterogenous blockchain ecosystems, offering a practical and effective solution to one of the most significant challenges in the cryptocurrency market.",
      "authors": [
        "Jovonni L. Pharr",
        "Jahanzeb M. Hussain"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Emerging Technologies (cs.ET)",
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T21:59:47+00:00",
          "link": "https://arxiv.org/abs/2507.06423v1",
          "size": "163kb",
          "version": "v1"
        }
      ],
      "title": "Rugsafe: A multichain protocol for recovering from and defending against Rug Pulls",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06423",
        "HTML": "https://arxiv.org/html/2507.06423v1",
        "PDF": "https://arxiv.org/pdf/2507.06423"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses economic incentives and asset recovery in cryptocurrency without any mention of LLM training data processing or related data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06910",
      "abstract": "Tutoring dialogues have gained significant attention in recent years, given the prominence of online learning and the emerging tutoring abilities of artificial intelligence (AI) agents powered by large language models (LLMs). Recent studies have shown that the strategies used by tutors can have significant effects on student outcomes, necessitating methods to predict how tutors will behave and how their actions impact students. However, few works have studied predicting tutor strategy in dialogues. Therefore, in this work we investigate the ability of modern LLMs, particularly Llama 3 and GPT-4o, to predict both future tutor moves and student outcomes in dialogues, using two math tutoring dialogue datasets. We find that even state-of-the-art LLMs struggle to predict future tutor strategy while tutor strategy is highly indicative of student outcomes, outlining a need for more powerful methods to approach this task.",
      "authors": [
        "Fareya Ikram",
        "Alexander Scarlatos",
        "Andrew Lan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T14:47:35+00:00",
          "link": "https://arxiv.org/abs/2507.06910v1",
          "size": "1918kb",
          "version": "v1"
        }
      ],
      "title": "Exploring LLMs for Predicting Tutor Strategy and Student Outcomes in Dialogues",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06910",
        "HTML": "https://arxiv.org/html/2507.06910v1",
        "PDF": "https://arxiv.org/pdf/2507.06910"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on predicting tutor strategies and student outcomes using LLMs, without any substantive modification or processing of LLM training data itself."
      },
      "source": "arXiv"
    },
    {
      "id": "2206.09495",
      "abstract": "In this paper, we investigate the power of {\\it regularization}, a common technique in reinforcement learning and optimization, in solving extensive-form games (EFGs). We propose a series of new algorithms based on regularizing the payoff functions of the game, and establish a set of convergence results that strictly improve over the existing ones, with either weaker assumptions or stronger convergence guarantees. In particular, we first show that dilated optimistic mirror descent (DOMD), an efficient variant of OMD for solving EFGs, with adaptive regularization can achieve a fast $\\tilde O(1/T)$ {last-iterate convergence rate for the output of the algorithm} in terms of duality gap and distance to the set of Nash equilibrium (NE) without uniqueness assumption of the NE. Second, we show that regularized counterfactual regret minimization (\\texttt{Reg-CFR}), with a variant of optimistic mirror descent algorithm as regret-minimizer, can achieve $O(1/T^{1/4})$ best-iterate, and $O(1/T^{3/4})$ average-iterate convergence rate for finding NE in EFGs. Finally, we show that \\texttt{Reg-CFR} can achieve asymptotic last-iterate convergence, and optimal $O(1/T)$ average-iterate convergence rate, for finding the NE of perturbed EFGs, which is useful for finding approximate extensive-form perfect equilibria (EFPE). To the best of our knowledge, they constitute the first last-iterate convergence results for CFR-type algorithms, while matching the state-of-the-art average-iterate convergence rate in finding NE for non-perturbed EFGs. We also provide numerical results to corroborate the advantages of our algorithms.",
      "authors": [
        "Mingyang Liu",
        "Asuman Ozdaglar",
        "Tiancheng Yu",
        "Kaiqing Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2022-06-19T22:10:38+00:00",
          "link": "https://arxiv.org/abs/2206.09495v1",
          "size": "1555kb",
          "version": "v1"
        },
        {
          "date": "2023-03-09T12:01:51+00:00",
          "link": "https://arxiv.org/abs/2206.09495v2",
          "size": "1647kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T03:58:26+00:00",
          "link": "https://arxiv.org/abs/2206.09495v3",
          "size": "262kb",
          "version": "v3"
        }
      ],
      "title": "The Power of Regularization in Solving Extensive-Form Games",
      "links": {
        "Abstract": "https://arxiv.org/abs/2206.09495",
        "HTML": "https://arxiv.org/html/2206.09495v3",
        "PDF": "https://arxiv.org/pdf/2206.09495"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses regularization techniques for solving extensive-form games, which is outside the scope of LLM training data processing or dataset engineering."
      },
      "tasks": [
        "counterfactual",
        "Form"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.12112",
      "abstract": "While large language models (LLMs) have recently demonstrated strong potential in solving planning problems, there is a trade-off between flexibility and complexity. LLMs, as zero-shot planners themselves, are still not capable of directly generating valid plans for complex planning problems such as multi-constraint or long-horizon tasks. On the other hand, many frameworks aiming to solve complex planning problems often rely on task-specific preparatory efforts, such as task-specific in-context examples and pre-defined critics/verifiers, which limits their cross-task generalization capability. In this paper, we tackle these challenges by observing that the core of many planning problems lies in optimization problems: searching for the optimal solution (best plan) with goals subject to constraints (preconditions and effects of decisions). With LLMs' commonsense, reasoning, and programming capabilities, this opens up the possibilities of a universal LLM-based approach to planning problems. Inspired by this observation, we propose LLMFP, a general-purpose framework that leverages LLMs to capture key information from planning problems and formally formulate and solve them as optimization problems from scratch, with no task-specific examples needed. We apply LLMFP to 9 planning problems, ranging from multi-constraint decision making to multi-step planning problems, and demonstrate that LLMFP achieves on average 83.7% and 86.8% optimal rate across 9 tasks for GPT-4o and Claude 3.5 Sonnet, significantly outperforming the best baseline (direct planning with OpenAI o1-preview) with 37.6% and 40.7% improvements. We also validate components of LLMFP with ablation experiments and analyzed the underlying success and failure reasons. Project page: https://sites.google.com/view/llmfp.",
      "authors": [
        "Yilun Hao",
        "Yang Zhang",
        "Chuchu Fan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-15T23:20:54+00:00",
          "link": "https://arxiv.org/abs/2410.12112v1",
          "size": "1587kb",
          "version": "v1"
        },
        {
          "date": "2025-01-29T16:31:53+00:00",
          "link": "https://arxiv.org/abs/2410.12112v2",
          "size": "1683kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T16:13:20+00:00",
          "link": "https://arxiv.org/abs/2410.12112v3",
          "size": "1418kb",
          "version": "v3"
        }
      ],
      "title": "Planning Anything with Rigor: General-Purpose Zero-Shot Planning with LLM-based Formalized Programming",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.12112",
        "HTML": "https://arxiv.org/html/2410.12112v3",
        "PDF": "https://arxiv.org/pdf/2410.12112"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on using LLMs for zero-shot planning and optimization, without contributing to training data processing or dataset creation for LLMs."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.06384",
      "abstract": "Objective: Latent diffusion models (LDMs) could mitigate data scarcity challenges affecting machine learning development for medical image interpretation. The recent CCELLA LDM improved prostate cancer detection performance using synthetic MRI for classifier training but was limited to the axial T2-weighted (AxT2) sequence, did not investigate inter-institutional domain shift, and prioritized radiology over histopathology outcomes. We propose CCELLA++ to address these limitations and improve clinical utility. Methods: CCELLA++ expands CCELLA for simultaneous biparametric prostate MRI (bpMRI) generation, including the AxT2, high b-value diffusion series (HighB) and apparent diffusion coefficient map (ADC). Domain adaptation was investigated by pretraining classifiers on real or LDM-generated synthetic data from an internal institution, followed with fine-tuning on progressively smaller fractions of an out-of-distribution, external dataset. Results: CCELLA++ improved 3D FID for HighB and ADC but not AxT2 (0.013, 0.012, 0.063 respectively) sequences compared to CCELLA (0.060). Classifier pretraining with CCELLA++ bpMRI outperformed real bpMRI in AP and AUC for all domain adaptation scenarios. CCELLA++ pretraining achieved highest classifier performance below 50% (n=665) external dataset volume. Conclusion: Synthetic bpMRI generated by our method can improve downstream classifier generalization and performance beyond real bpMRI or CCELLA-generated AxT2-only images. Future work should seek to quantify medical image sample quality, balance multi-sequence LDM training, and condition the LDM with additional information. Significance: The proposed CCELLA++ LDM can generate synthetic bpMRI that outperforms real data for domain adaptation with a limited target institution dataset. Our code is available at https://github.com/grabkeem/CCELLA-plus-plus",
      "authors": [
        "Emerson P. Grabke",
        "Babak Taati",
        "Masoom A. Haider"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T20:38:10+00:00",
          "link": "https://arxiv.org/abs/2507.06384v1",
          "size": "1677kb",
          "version": "v1"
        }
      ],
      "title": "Mitigating Multi-Sequence 3D Prostate MRI Data Scarcity through Domain Adaptation using Locally-Trained Latent Diffusion Models for Prostate Cancer Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06384",
        "HTML": "https://arxiv.org/html/2507.06384v1",
        "PDF": "https://arxiv.org/pdf/2507.06384"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper describes a method for generating synthetic MRI data using latent diffusion models, which is primarily focused on domain adaptation in medical imaging, not LLM training data. However, it involves data processing for pretraining models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06615",
      "abstract": "Multi-task reinforcement learning endeavors to efficiently leverage shared information across various tasks, facilitating the simultaneous learning of multiple tasks. Existing approaches primarily focus on parameter sharing with carefully designed network structures or tailored optimization procedures. However, they overlook a direct and complementary way to exploit cross-task similarities: the control policies of tasks already proficient in some skills can provide explicit guidance for unmastered tasks to accelerate skills acquisition. To this end, we present a novel framework called Cross-Task Policy Guidance (CTPG), which trains a guide policy for each task to select the behavior policy interacting with the environment from all tasks' control policies, generating better training trajectories. In addition, we propose two gating mechanisms to improve the learning efficiency of CTPG: one gate filters out control policies that are not beneficial for guidance, while the other gate blocks tasks that do not necessitate guidance. CTPG is a general framework adaptable to existing parameter sharing approaches. Empirical evaluations demonstrate that incorporating CTPG with these approaches significantly enhances performance in manipulation and locomotion benchmarks.",
      "authors": [
        "Jinmin He",
        "Kai Li",
        "Yifan Zang",
        "Haobo Fu",
        "Qiang Fu",
        "Junliang Xing",
        "Jian Cheng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T07:36:28+00:00",
          "link": "https://arxiv.org/abs/2507.06615v1",
          "size": "26803kb",
          "version": "v1"
        }
      ],
      "title": "Efficient Multi-Task Reinforcement Learning with Cross-Task Policy Guidance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06615",
        "HTML": "https://arxiv.org/html/2507.06615v1",
        "PDF": "https://arxiv.org/pdf/2507.06615"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses multi-task reinforcement learning with cross-task policy guidance, and does not involve processing or engineering of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06450",
      "abstract": "Time normalization is the task of converting natural language temporal expressions into machine-readable representations. It underpins many downstream applications in information retrieval, question answering, and clinical decision-making. Traditional systems based on the ISO-TimeML schema limit expressivity and struggle with complex constructs such as compositional, event-relative, and multi-span time expressions. In this work, we introduce a novel formulation of time normalization as a code generation task grounded in the SCATE framework, which defines temporal semantics through symbolic and compositional operators. We implement a fully executable SCATE Python library and demonstrate that large language models (LLMs) can generate executable SCATE code. Leveraging this capability, we develop an automatic data augmentation pipeline using LLMs to synthesize large-scale annotated data with code-level validation. Our experiments show that small, locally deployable models trained on this augmented data can achieve strong performance, outperforming even their LLM parents and enabling practical, accurate, and interpretable time normalization.",
      "authors": [
        "Xin Su",
        "Sungduk Yu",
        "Phillip Howard",
        "Steven Bethard"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T23:30:11+00:00",
          "link": "https://arxiv.org/abs/2507.06450v1",
          "size": "9891kb",
          "version": "v1"
        }
      ],
      "title": "A Semantic Parsing Framework for End-to-End Time Normalization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06450",
        "HTML": "https://arxiv.org/html/2507.06450v1",
        "PDF": "https://arxiv.org/pdf/2507.06450"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper contributes to LLM training data processing by introducing a novel data augmentation pipeline using LLMs to generate annotated data, significantly focusing on data generation and synthesis."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06549",
      "abstract": "To achieve higher system energy efficiency, SRAM in SoCs is often customized. The parasitic effects cause notable discrepancies between pre-layout and post-layout circuit simulations, leading to difficulty in converging design parameters and excessive design iterations. Is it possible to well predict the parasitics based on the pre-layout circuit, so as to perform parasitic-aware pre-layout simulation? In this work, we propose a deep-learning-based 2-stage model to accurately predict these parasitics in pre-layout stages. The model combines a Graph Neural Network (GNN) classifier and Multi-Layer Perceptron (MLP) regressors, effectively managing class imbalance of the net parasitics in SRAM circuits. We also employ Focal Loss to mitigate the impact of abundant internal net samples and integrate subcircuit information into the graph to abstract the hierarchical structure of schematics. Experiments on 4 real SRAM designs show that our approach not only surpasses the state-of-the-art model in parasitic prediction by a maximum of 19X reduction of error but also significantly boosts the simulation process by up to 598X speedup.",
      "authors": [
        "Shan Shen",
        "Dingcheng Yang",
        "Yuyang Xie",
        "Chunyan Pei",
        "Wenjian Yu",
        "Bei Yu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Hardware Architecture (cs.AR)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T05:05:08+00:00",
          "link": "https://arxiv.org/abs/2507.06549v1",
          "size": "2075kb",
          "version": "v1"
        }
      ],
      "title": "Deep-Learning-Based Pre-Layout Parasitic Capacitance Prediction on SRAM Designs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06549",
        "HTML": "https://arxiv.org/html/2507.06549v1",
        "PDF": "https://arxiv.org/pdf/2507.06549"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work focuses on predicting parasitic capacitance in SRAM designs using deep learning, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06564",
      "abstract": "Unmanned Aerial Vehicles (UAVs) have emerged as versatile tools across various sectors, driven by their mobility and adaptability. This paper introduces SkyVLN, a novel framework integrating vision-and-language navigation (VLN) with Nonlinear Model Predictive Control (NMPC) to enhance UAV autonomy in complex urban environments. Unlike traditional navigation methods, SkyVLN leverages Large Language Models (LLMs) to interpret natural language instructions and visual observations, enabling UAVs to navigate through dynamic 3D spaces with improved accuracy and robustness. We present a multimodal navigation agent equipped with a fine-grained spatial verbalizer and a history path memory mechanism. These components allow the UAV to disambiguate spatial contexts, handle ambiguous instructions, and backtrack when necessary. The framework also incorporates an NMPC module for dynamic obstacle avoidance, ensuring precise trajectory tracking and collision prevention. To validate our approach, we developed a high-fidelity 3D urban simulation environment using AirSim, featuring realistic imagery and dynamic urban elements. Extensive experiments demonstrate that SkyVLN significantly improves navigation success rates and efficiency, particularly in new and unseen environments.",
      "authors": [
        "Tianshun Li",
        "Tianyi Huai",
        "Zhen Li",
        "Yichun Gao",
        "Haoang Li",
        "Xinhu Zheng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T05:38:32+00:00",
          "link": "https://arxiv.org/abs/2507.06564v1",
          "size": "2124kb",
          "version": "v1"
        }
      ],
      "title": "SkyVLN: Vision-and-Language Navigation and NMPC Control for UAVs in Urban Environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06564",
        "HTML": "https://arxiv.org/html/2507.06564v1",
        "PDF": "https://arxiv.org/pdf/2507.06564"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a framework for UAVs using LLMs for navigation in urban environments but does not involve LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06929",
      "abstract": "We investigate Machine-Learned Force Fields (MLFFs) trained on approximate Density Functional Theory (DFT) and Coupled Cluster (CC) level potential energy surfaces for the carbon diamond and lithium hydride solids. We assess the accuracy and precision of the MLFFs by calculating phonon dispersions and vibrational densities of states (VDOS) that are compared to experiment and reference ab initio results. To overcome limitations from long-range effects and the lack of atomic forces in the CC training data, a delta-learning approach based on the difference between CC and DFT results is explored. Compared to DFT, MLFFs trained on CC theory yield higher vibrational frequencies for optical modes, agreeing better with experiment. Furthermore, the MLFFs are used to estimate anharmonic effects on the VDOS of lithium hydride at the level of CC theory.",
      "authors": [
        "Sita Sch\\\"onbauer and Johanna P. Carbone and Andreas Gr\\\"uneis"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Materials Science (cond-mat.mtrl-sci)",
        "Machine Learning (cs.LG)",
        "Computational Physics (physics.comp-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T15:11:55+00:00",
          "link": "https://arxiv.org/abs/2507.06929v1",
          "size": "5639kb",
          "version": "v1"
        }
      ],
      "title": "Machine-Learned Force Fields for Lattice Dynamics at Coupled-Cluster Level Accuracy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06929",
        "HTML": "https://arxiv.org/html/2507.06929v1",
        "PDF": "https://arxiv.org/pdf/2507.06929"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about machine-learned force fields for lattice dynamics, involving physical sciences and not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07064",
      "abstract": "LLM-based recommender systems have made significant progress; however, the deployment cost associated with the large parameter volume of LLMs still hinders their real-world applications. This work explores parameter pruning to improve parameter efficiency while maintaining recommendation quality, thereby enabling easier deployment. Unlike existing approaches that focus primarily on inter-layer redundancy, we uncover intra-layer redundancy within components such as self-attention and MLP modules. Building on this analysis, we propose a more fine-grained pruning approach that integrates both intra-layer and layer-wise pruning. Specifically, we introduce a three-stage pruning strategy that progressively prunes parameters at different levels and parts of the model, moving from intra-layer to layer-wise pruning, or from width to depth. Each stage also includes a performance restoration step using distillation techniques, helping to strike a balance between performance and parameter efficiency. Empirical results demonstrate the effectiveness of our approach: across three datasets, our models achieve an average of 88% of the original model's performance while pruning more than 95% of the non-embedding parameters. This underscores the potential of our method to significantly reduce resource requirements without greatly compromising recommendation quality. Our code will be available at: https://github.com/zheng-sl/PruneRec",
      "authors": [
        "Shanle Zheng",
        "Keqin Bao",
        "Jizhi Zhang",
        "Yang Zhang",
        "Fuli Feng",
        "Xiangnan He"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T17:26:10+00:00",
          "link": "https://arxiv.org/abs/2507.07064v1",
          "size": "699kb",
          "version": "v1"
        }
      ],
      "title": "Boosting Parameter Efficiency in LLM-Based Recommendation through Sophisticated Pruning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07064",
        "HTML": "https://arxiv.org/html/2507.07064v1",
        "PDF": "https://arxiv.org/pdf/2507.07064"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores parameter pruning for LLM-based recommendation systems, focusing on model efficiency, and does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2401.17477",
      "abstract": "In the digital era, the prevalence of depressive symptoms expressed on social media has raised serious concerns, necessitating advanced methodologies for timely detection. This paper addresses the challenge of interpretable depression detection by proposing a novel methodology that effectively combines Large Language Models (LLMs) with eXplainable Artificial Intelligence (XAI) and conversational agents like ChatGPT. In our methodology, explanations are achieved by integrating BERTweet, a Twitter-specific variant of BERT, into a novel self-explanatory model, namely BERT-XDD, capable of providing both classification and explanations via masked attention. The interpretability is further enhanced using ChatGPT to transform technical explanations into human-readable commentaries. By introducing an effective and modular approach for interpretable depression detection, our methodology can contribute to the development of socially responsible digital platforms, fostering early intervention and support for mental health challenges under the guidance of qualified healthcare professionals.",
      "authors": [
        "Loris Belcastro",
        "Riccardo Cantini",
        "Fabrizio Marozzo",
        "Domenico Talia",
        "Paolo Trunfio"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2024-01-30T22:22:55+00:00",
          "link": "https://arxiv.org/abs/2401.17477v1",
          "size": "1161kb",
          "version": "v1"
        },
        {
          "date": "2025-03-10T09:32:00+00:00",
          "link": "https://arxiv.org/abs/2401.17477v2",
          "size": "983kb",
          "version": "v2"
        }
      ],
      "title": "Detecting mental disorder on social media: a ChatGPT-augmented explainable approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.17477",
        "PDF": "https://arxiv.org/pdf/2401.17477"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on using LLMs for interpretable depression detection but does not contribute to LLM training data processing."
      },
      "tasks": [
        "Depression Detection",
        "Explainable artificial intelligence",
        "Explainable Artificial Intelligence (XAI)"
      ],
      "repo_urls": [
        "https://github.com/scalabunical/bert-xdd"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.12538",
      "abstract": "Generating interdisciplinary research ideas requires diverse domain expertise, but access to timely feedback is often limited by the availability of experts. In this paper, we introduce PersonaFlow, a novel system designed to provide multiple perspectives by using LLMs to simulate domain-specific experts. Our user studies showed that the new design 1) increased the perceived relevance and creativity of ideated research directions, and 2) promoted users' critical thinking activities (e.g., interpretation, analysis, evaluation, inference, and self-regulation), without increasing their perceived cognitive load. Moreover, users' ability to customize expert profiles significantly improved their sense of agency, which can potentially mitigate their over-reliance on AI. This work contributes to the design of intelligent systems that augment creativity and collaboration, and provides design implications of using customizable AI-simulated personas in domains within and beyond research ideation.",
      "authors": [
        "Yiren Liu",
        "Pranav Sharma",
        "Mehul Jitendra Oswal",
        "Haijun Xia",
        "Yun Huang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-19T07:54:29+00:00",
          "link": "https://arxiv.org/abs/2409.12538v1",
          "size": "25313kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T05:59:31+00:00",
          "link": "https://arxiv.org/abs/2409.12538v2",
          "size": "8378kb",
          "version": "v2"
        }
      ],
      "title": "PersonaFlow: Designing LLM-Simulated Expert Perspectives for Enhanced Research Ideation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.12538",
        "HTML": "https://arxiv.org/html/2409.12538v2",
        "PDF": "https://arxiv.org/pdf/2409.12538"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on simulating expert perspectives using LLMs for research ideation, but does not discuss LLM training data processing or creation."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Large Language Model",
        "scientific discovery"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.05400",
      "abstract": "This paper introduces a novel visual mapping methodology for assessing strategic alignment in national artificial intelligence policies. The proliferation of AI strategies across countries has created an urgent need for analytical frameworks that can evaluate policy coherence between strategic objectives, foresight methods, and implementation instruments. Drawing on data from the OECD AI Policy Observatory, we analyze 15-20 national AI strategies using a combination of matrix-based visualization and network analysis to identify patterns of alignment and misalignment. Our findings reveal distinct alignment archetypes across governance models, with notable variations in how countries integrate foresight methodologies with implementation planning. High-coherence strategies demonstrate strong interconnections between economic competitiveness objectives and robust innovation funding instruments, while common vulnerabilities include misalignment between ethical AI objectives and corresponding regulatory frameworks. The proposed visual mapping approach offers both methodological contributions to policy analysis and practical insights for enhancing strategic coherence in AI governance. This research addresses significant gaps in policy evaluation methodology and provides actionable guidance for policymakers seeking to strengthen alignment in technological governance frameworks.",
      "authors": [
        "Mohammad Hossein Azin",
        "Hessam Zandhessami"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "General Economics (econ.GN)",
        "Economics (q-fin.EC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T18:36:30+00:00",
          "link": "https://arxiv.org/abs/2507.05400v1",
          "size": "10213kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T14:26:35+00:00",
          "link": "https://arxiv.org/abs/2507.05400v2",
          "size": "10214kb",
          "version": "v2"
        }
      ],
      "title": "Strategic Alignment Patterns in National AI Policies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05400",
        "HTML": "https://arxiv.org/html/2507.05400v2",
        "PDF": "https://arxiv.org/pdf/2507.05400"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on evaluating national AI policies using visual methodologies and network analysis, without any mention of LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06249",
      "abstract": "Recently, pre-trained models with phonetic supervision have demonstrated their advantages for crosslingual speech recognition in data efficiency and information sharing across languages. However, a limitation is that a pronunciation lexicon is needed for such phoneme-based crosslingual speech recognition. In this study, we aim to eliminate the need for pronunciation lexicons and propose a latent variable model based method, with phonemes being treated as discrete latent variables. The new method consists of a speech-to-phoneme (S2P) model and a phoneme-to-grapheme (P2G) model, and a grapheme-to-phoneme (G2P) model is introduced as an auxiliary inference model. To jointly train the three models, we utilize the joint stochastic approximation (JSA) algorithm, which is a stochastic extension of the EM (expectation-maximization) algorithm and has demonstrated superior performance particularly in estimating discrete latent variable models. Based on the Whistle multilingual pre-trained S2P model, crosslingual experiments are conducted in Polish (130 h) and Indonesian (20 h). With only 10 minutes of phoneme supervision, the new method, JSA-SPG, achieves 5\\% error rate reductions compared to the best crosslingual fine-tuning approach using subword or full phoneme supervision. Furthermore, it is found that in language domain adaptation (i.e., utilizing cross-domain text-only data), JSA-SPG outperforms the standard practice of language model fusion via the auxiliary support of the G2P model by 9% error rate reductions. To facilitate reproducibility and encourage further exploration in this field, we open-source the JSA-SPG training code and complete pipeline.",
      "authors": [
        "Saierdaer Yusuyin",
        "Te Ma",
        "Hao Huang",
        "Zhijian Ou"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-04T12:23:22+00:00",
          "link": "https://arxiv.org/abs/2507.06249v1",
          "size": "1326kb",
          "version": "v1"
        }
      ],
      "title": "Pronunciation-Lexicon Free Training for Phoneme-based Crosslingual ASR via Joint Stochastic Approximation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06249",
        "HTML": "https://arxiv.org/html/2507.06249v1",
        "PDF": "https://arxiv.org/pdf/2507.06249"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper describes a method for phoneme-based crosslingual ASR that involves training techniques. It mentions data adaptation and cross-domain text data, but the focus is more on model training than on data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06506",
      "abstract": "Translating wordplay across languages presents unique challenges that have long confounded both professional human translators and machine translation systems. This research proposes a novel approach for translating puns from English to French by combining state-of-the-art large language models with specialized techniques for wordplay generation.\n  Our methodology employs a three-stage approach. First, we establish a baseline using multiple frontier large language models with feedback based on a new contrastive learning dataset. Second, we implement a guided chain-of-thought pipeline with combined phonetic-semantic embeddings. Third, we implement a multi-agent generator-discriminator framework for evaluating and regenerating puns with feedback.\n  Moving beyond the limitations of literal translation, our methodology's primary objective is to capture the linguistic creativity and humor of the source text wordplay, rather than simply duplicating its vocabulary. Our best runs earned first and second place in the CLEF JOKER 2025 Task 2 competition where they were evaluated manually by expert native French speakers.\n  This research addresses a gap between translation studies and computational linguistics by implementing linguistically-informed techniques for wordplay translation, advancing our understanding of how language models can be leveraged to handle the complex interplay between semantic ambiguity, phonetic similarity, and the implicit cultural and linguistic awareness needed for successful humor.",
      "authors": [
        "Russell Taylor",
        "Benjamin Herbert",
        "Michael Sana"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T03:09:14+00:00",
          "link": "https://arxiv.org/abs/2507.06506v1",
          "size": "390kb",
          "version": "v1"
        }
      ],
      "title": "Pun Intended: Multi-Agent Translation of Wordplay with Contrastive Learning and Phonetic-Semantic Embeddings",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06506",
        "HTML": "https://arxiv.org/html/2507.06506v1",
        "PDF": "https://arxiv.org/pdf/2507.06506"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on translating puns using large language models with a novel multi-agent translation framework, but it does not involve any significant LLM training data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06603",
      "abstract": "Long-term action recognition (LTAR) is challenging due to extended temporal spans with complex atomic action correlations and visual confounders. Although vision-language models (VLMs) have shown promise, they often rely on statistical correlations instead of causal mechanisms. Moreover, existing causality-based methods address modal-specific biases but lack cross-modal causal modeling, limiting their utility in VLM-based LTAR. This paper proposes \\textbf{C}ross-\\textbf{M}odal \\textbf{D}ual-\\textbf{C}ausal \\textbf{L}earning (CMDCL), which introduces a structural causal model to uncover causal relationships between videos and label texts.\n  CMDCL addresses cross-modal biases in text embeddings via textual causal intervention and removes confounders inherent in the visual modality through visual causal intervention guided by the debiased text.\n  These dual-causal interventions enable robust action representations to address LTAR challenges. Experimental results on three benchmarks including Charades, Breakfast and COIN, demonstrate the effectiveness of the proposed model. Our code is available at https://github.com/xushaowu/CMDCL.",
      "authors": [
        "Xu Shaowu",
        "Jia Xibin",
        "Gao Junyu",
        "Sun Qianmei",
        "Chang Jing",
        "Fan Chao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T07:22:54+00:00",
          "link": "https://arxiv.org/abs/2507.06603v1",
          "size": "1887kb",
          "version": "v1"
        }
      ],
      "title": "Cross-Modal Dual-Causal Learning for Long-Term Action Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06603",
        "HTML": "https://arxiv.org/html/2507.06603v1",
        "PDF": "https://arxiv.org/pdf/2507.06603"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses cross-modal causal learning for action recognition challenges without any focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06849",
      "abstract": "Neural network (NN)-based Digital Predistortion (DPD) stands out in improving signal quality in wideband radio frequency (RF) power amplifiers (PAs) employing complex modulation. However, NN DPDs usually rely on a large number of parameters for effective linearization and can significantly contribute to the energy consumption of the digital back-end in RF systems. This paper presents OpenDPDv2, a unified framework for PA modeling, DPD learning, and model optimization to reduce power consumption while maintaining high linearization performance. The optimization techniques feature a novel DPD algorithm, TRes-DeltaGRU, alongside two energy-efficient methods. The top-performing 32-bit floating-point (FP32) TRes-DeltaGRU-DPD model achieves an Adjacent Channel Power Ratio (ACPR) of -59.4 dBc and Error Vector Magnitude (EVM) of -42.1 dBc. By exploiting fixed-point quantization and dynamic temporal sparsity of input signals and hidden neurons, the inference energy of our model can be reduced by 4.5X while still maintaining -50.3 dBc ACPR and -35.2 dB EVM with 56% temporal sparsity. This was evaluated using a TM3.1a 200 MHz bandwidth 256-QAM OFDM signal applied to a 3.5 GHz GaN Doherty RF PA. OpenDPDv2 code, datasets, and documentation are publicly accessible at: https://github.com/lab-emi/OpenDPD.",
      "authors": [
        "Yizhuo Wu",
        "Ang Li",
        "Chang Gao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T13:54:47+00:00",
          "link": "https://arxiv.org/abs/2507.06849v1",
          "size": "3567kb",
          "version": "v1"
        }
      ],
      "title": "OpenDPDv2: A Unified Learning and Optimization Framework for Neural Network Digital Predistortion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06849",
        "HTML": "https://arxiv.org/html/2507.06849v1",
        "PDF": "https://arxiv.org/pdf/2507.06849"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses digital predistortion to improve signal quality and energy efficiency in RF systems, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06895",
      "abstract": "The growing demand for efficient knowledge graph (KG) enrichment leveraging external corpora has intensified interest in relation extraction (RE), particularly under low-supervision settings. To address the need for adaptable and noise-resilient RE solutions that integrate seamlessly with pre-trained large language models (PLMs), we introduce SCoRE, a modular and cost-effective sentence-level RE system. SCoRE enables easy PLM switching, requires no finetuning, and adapts smoothly to diverse corpora and KGs. By combining supervised contrastive learning with a Bayesian k-Nearest Neighbors (kNN) classifier for multi-label classification, it delivers robust performance despite the noisy annotations of distantly supervised corpora. To improve RE evaluation, we propose two novel metrics: Correlation Structure Distance (CSD), measuring the alignment between learned relational patterns and KG structures, and Precision at R (P@R), assessing utility as a recommender system. We also release Wiki20d, a benchmark dataset replicating real-world RE conditions where only KG-derived annotations are available. Experiments on five benchmarks show that SCoRE matches or surpasses state-of-the-art methods while significantly reducing energy consumption. Further analyses reveal that increasing model complexity, as seen in prior work, degrades performance, highlighting the advantages of SCoRE's minimal design. Combining efficiency, modularity, and scalability, SCoRE stands as an optimal choice for real-world RE applications.",
      "authors": [
        "Luca Mariotti",
        "Veronica Guidetti and Federica Mandreoli"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T14:33:07+00:00",
          "link": "https://arxiv.org/abs/2507.06895v1",
          "size": "980kb",
          "version": "v1"
        }
      ],
      "title": "SCoRE: Streamlined Corpus-based Relation Extraction using Multi-Label Contrastive Learning and Bayesian kNN",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06895",
        "HTML": "https://arxiv.org/html/2507.06895v1",
        "PDF": "https://arxiv.org/pdf/2507.06895"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces a system for relation extraction and releases a benchmark dataset, its main focus is on adapting PLMs to diverse corpora and improving relation extraction performance, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07012",
      "abstract": "Modeling car-following behavior is fundamental to microscopic traffic simulation, yet traditional deterministic models often fail to capture the full extent of variability and unpredictability in human driving. While many modern approaches incorporate context-aware inputs (e.g., spacing, speed, relative speed), they frequently overlook structured stochasticity that arises from latent driver intentions, perception errors, and memory effects -- factors that are not directly observable from context alone. To fill the gap, this study introduces an interpretable stochastic modeling framework that captures not only context-dependent dynamics but also residual variability beyond what context can explain. Leveraging deep neural networks integrated with nonstationary Gaussian processes (GPs), our model employs a scenario-adaptive Gibbs kernel to learn dynamic temporal correlations in acceleration decisions, where the strength and duration of correlations between acceleration decisions evolve with the driving context. This formulation enables a principled, data-driven quantification of uncertainty in acceleration, speed, and spacing, grounded in both observable context and latent behavioral variability. Comprehensive experiments on the naturalistic vehicle trajectory dataset collected from the German highway, i.e., the HighD dataset, demonstrate that the proposed stochastic simulation method within this framework surpasses conventional methods in both predictive performance and interpretable uncertainty quantification. The integration of interpretability and accuracy makes this framework a promising tool for traffic analysis and safety-critical applications.",
      "authors": [
        "Chengyuan Zhang",
        "Zhengbing He",
        "Cathy Wu",
        "Lijun Sun"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Applications (stat.AP)",
        "Machine Learning (cs.LG)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T16:42:41+00:00",
          "link": "https://arxiv.org/abs/2507.07012v1",
          "size": "3118kb",
          "version": "v1"
        }
      ],
      "title": "When Context Is Not Enough: Modeling Unexplained Variability in Car-Following Behavior",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07012",
        "HTML": "https://arxiv.org/html/2507.07012v1",
        "PDF": "https://arxiv.org/pdf/2507.07012"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses modeling car-following behavior in traffic simulations using a stochastic modeling framework, without any focus on LLM training data processing or dataset creation for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2309.05331",
      "abstract": "We present a software implementation integrating the time-integration library Odeint from Boost with the OpenFPM framework for scalable scientific computing. This enables compact and scalable codes for multi-stage, multi-step, and adaptive explicit time integration on distributed-memory parallel computers and on Graphics Processing Units (GPUs). The present implementation is based on extending OpenFPM's metaprogramming system to Odeint data types. This makes the time-integration methods from Odeint available in a concise template-expression language for numerical simulations distributed and parallelized using OpenFPM. We benchmark the present software for exponential and sigmoidal dynamics and present application examples to the 3D Gray-Scott reaction-diffusion problem and the \"dam break\" problem from fluid mechanics. We find a strong-scaling efficiency of 80% on up to 512 CPU cores and a five-fold speedup on a single GPU.",
      "authors": [
        "Abhinav Singh",
        "Landfried Kraatz",
        "Serhii Yaskovets",
        "Pietro Incardona",
        "Ivo F. Sbalzarini"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Mathematical Software (cs.MS)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2023-09-11T09:26:37+00:00",
          "link": "https://arxiv.org/abs/2309.05331v1",
          "size": "1316kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T16:20:59+00:00",
          "link": "https://arxiv.org/abs/2309.05331v2",
          "size": "432kb",
          "version": "v2"
        }
      ],
      "title": "Integrating Odeint Time Stepping into OpenFPM for Distributed and GPU Accelerated Numerical Solvers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2309.05331",
        "HTML": "https://arxiv.org/html/2309.05331v2",
        "PDF": "https://arxiv.org/pdf/2309.05331"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a software implementation for time integration in scientific computing, focusing on distributed and GPU acceleration, without mentioning any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2310.13403",
      "abstract": "With the increasing importance of machine learning, the privacy and security of training data have become critical. Federated learning, which stores data in distributed nodes and shares only model parameters, has gained significant attention for addressing this concern. However, a challenge arises in federated learning due to the Byzantine Attack Problem, where malicious local models can compromise the global model's performance during aggregation. This article proposes the Blockchain-based Byzantine-Robust Federated Learning (BRLF) model that combines federated learning with blockchain technology. This integration enables traceability of malicious models and provides incentives for locally trained clients. Our approach involves selecting the aggregation node based on Pearson's correlation coefficient, and we perform spectral clustering and calculate the average gradient within each cluster, validating its accuracy using local dataset of the aggregation nodes. Experimental results on public datasets demonstrate the superior byzantine robustness of our secure aggregation algorithm compared to other baseline byzantine robust aggregation methods, and proved our proposed model effectiveness in addressing the resource consumption problem.",
      "authors": [
        "Yang Li",
        "Chunhe Xia",
        "Chang Li",
        "Tianbo Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2023-10-20T10:21:50+00:00",
          "link": "https://arxiv.org/abs/2310.13403v1",
          "size": "1759kb",
          "version": "v1"
        }
      ],
      "title": "BRFL: A Blockchain-based Byzantine-Robust Federated Learning Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2310.13403",
        "HTML": "https://arxiv.org/html/2310.13403",
        "PDF": "https://arxiv.org/pdf/2310.13403"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses a federated learning model with blockchain integration primarily to address security and privacy concerns, making indirect mentions of training data robustness without detailed data processing steps for LLMs."
      },
      "tasks": [
        "Federated Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.00367",
      "abstract": "Integrating Distributed Energy Resources (DERs) with peer-to-peer (P2P) energy trading offers promising solutions for grid modernization by incentivizing prosumers to participate in mitigating peak demand. However, this integration also introduces operational uncertainties and computational challenges. This paper aims to address these challenges with a novel scalable and tractable distributionally robust joint chance-constrained (DRJCC) optimization framework that effectively facilitates P2P energy trading by enhancing flexibility provision from large-scale DER operations under uncertain supply and demand. Therefore, a practical framework is proposed to solve the core challenges of DRJCC by integrating three key components: (1) a Wasserstein ambiguity set that effectively quantifies uncertainty with sparse data, (2) a CVaR-based approximation of joint chance constraints to balance computational efficiency with risk control, and (3) a privacy-preserving ADMM algorithm that enables distributed implementation through decomposition. To discern patterns in the data that indicate collaboration potential and adjust ambiguity sets for improved efficiency, K-means clustering is applied to historical scenarios. Simulation results show that the proposed framework reduces peak demand by approximately 28% and total community costs by around 31%, underscoring its effectiveness in enhancing grid robustness, operational reliability, and economic optimization in renewable-based energy management.",
      "authors": [
        "Amir Noori",
        "Babak Tavassoli",
        "Alireza Fereidunian"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-31T07:00:30+00:00",
          "link": "https://arxiv.org/abs/2409.00367v1",
          "size": "572kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T07:54:03+00:00",
          "link": "https://arxiv.org/abs/2409.00367v2",
          "size": "1193kb",
          "version": "v2"
        }
      ],
      "title": "Distributionally Robust Joint Chance-Constrained Optimization for Electricity Imbalance: Integrating Renewables and Storage",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.00367",
        "PDF": "https://arxiv.org/pdf/2409.00367"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on optimization frameworks for energy trading, specifically dealing with operational uncertainties and computational challenges, without any mention of LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.01864",
      "abstract": "The development of quantum codes with good error correction parameters and useful sets of transversal gates is a problem of major interest in quantum error-correction. Abundant prior works have studied transversal gates which are restricted to acting on all logical qubits simultaneously. In this work, we study codes that support transversal gates which induce $\\textit{addressable}$ logical gates, i.e., the logical gates act on logical qubits of our choice. As we consider scaling to high-rate codes, the study and design of low-overhead, addressable logical operations presents an important problem for both theoretical and practical purposes.\n  Our primary result is the construction of an explicit qubit code for which $\\textit{any}$ triple of logical qubits across one, two, or three codeblocks can be addressed with a logical $\\mathsf{CCZ}$ gate via a depth-one circuit of physical $\\mathsf{CCZ}$ gates, and whose parameters are asymptotically good, up to polylogarithmic factors. The result naturally generalizes to other gates including the $\\mathsf{C}^{\\ell} Z$ gates for $\\ell \\neq 2$.\n  Going beyond this, we develop a formalism for constructing quantum codes with $\\textit{addressable and transversal}$ gates. Our framework, called $\\textit{addressable orthogonality}$, encompasses the original triorthogonality framework of Bravyi and Haah (Phys. Rev. A 2012), and extends this and other frameworks to study addressable gates. We demonstrate the power of this framework with the construction of an asymptotically good qubit code for which $\\textit{pre-designed}$, pairwise disjoint triples of logical qubits within a single codeblock may be addressed with a logical $\\mathsf{CCZ}$ gate via a physical depth-one circuit of $\\mathsf{Z}$, $\\mathsf{CZ}$ and $\\mathsf{CCZ}$ gates. In an appendix, we show that our framework extends to addressable and transversal $T$ gates, up to Clifford corrections.",
      "authors": [
        "Zhiyang He",
        "Vinod Vaikuntanathan",
        "Adam Wills",
        "Rachel Yun Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-03T22:24:34+00:00",
          "link": "https://arxiv.org/abs/2502.01864v1",
          "size": "85kb",
          "version": "v1"
        },
        {
          "date": "2025-05-05T19:28:45+00:00",
          "link": "https://arxiv.org/abs/2502.01864v2",
          "size": "62kb",
          "version": "v2"
        },
        {
          "date": "2025-07-07T18:47:26+00:00",
          "link": "https://arxiv.org/abs/2502.01864v3",
          "size": "64kb",
          "version": "v3"
        }
      ],
      "title": "Quantum Codes with Addressable and Transversal Non-Clifford Gates",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.01864",
        "HTML": "https://arxiv.org/html/2502.01864v3",
        "PDF": "https://arxiv.org/pdf/2502.01864"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with quantum codes and gates for error correction, specifically addressing transversal gates and scalability, without involving any LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.13582",
      "abstract": "Soft robots exhibit inherent compliance and safety, which makes them particularly suitable for applications requiring direct physical interaction with humans, such as surgical procedures. However, their nonlinear and hysteretic behavior, resulting from the properties of soft materials, presents substantial challenges for accurate modeling and control. In this study, we present a soft robotic system designed for surgical applications and propose a hysteresis-aware whole-body neural network model that accurately captures and predicts the soft robot's whole-body motion, including its hysteretic behavior. Building upon the high-precision dynamic model, we construct a highly parallel simulation environment for soft robot control and apply an on-policy reinforcement learning algorithm to efficiently train whole-body motion control strategies. Based on the trained control policy, we developed a soft robotic system for surgical applications and validated it through phantom-based laser ablation experiments in a physical environment. The results demonstrate that the hysteresis-aware modeling reduces the Mean Squared Error (MSE) by 84.95 percent compared to traditional modeling methods. The deployed control algorithm achieved a trajectory tracking error ranging from 0.126 to 0.250 mm on the real soft robot, highlighting its precision in real-world conditions. The proposed method showed strong performance in phantom-based surgical experiments and demonstrates its potential for complex scenarios, including future real-world clinical applications.",
      "authors": [
        "Zongyuan Chen",
        "Yan Xia",
        "Jiayuan Liu",
        "Jijia Liu",
        "Wenhao Tang",
        "Jiayu Chen",
        "Feng Gao",
        "Longfei Ma",
        "Hongen Liao",
        "Yu Wang",
        "Chao Yu",
        "Boyu Zhang",
        "Fei Xing"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-18T09:34:56+00:00",
          "link": "https://arxiv.org/abs/2504.13582v1",
          "size": "7549kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T06:28:57+00:00",
          "link": "https://arxiv.org/abs/2504.13582v2",
          "size": "7550kb",
          "version": "v2"
        }
      ],
      "title": "Hysteresis-Aware Neural Network Modeling and Whole-Body Reinforcement Learning Control of Soft Robots",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.13582",
        "HTML": "https://arxiv.org/html/2504.13582v2",
        "PDF": "https://arxiv.org/pdf/2504.13582"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about modeling and control of soft robots and does not address any aspect of LLM training data processing or data engineering for language models."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.06470",
      "abstract": "Existing research on source tracing of audio deepfake systems has focused primarily on the closed-set scenario, while studies that evaluate open-set performance are limited to a small number of unseen systems. Due to the large number of emerging audio deepfake systems, robust open-set source tracing is critical. We leverage the protocol of the Interspeech 2025 special session on source tracing to evaluate methods for improving open-set source tracing performance. We introduce a novel adaptation to the energy score for out-of-distribution (OOD) detection, softmax energy (SME). We find that replacing the typical temperature-scaled energy score with SME provides a relative average improvement of 31% in the standard FPR95 (false positive rate at true positive rate of 95%) measure. We further explore SME-guided training as well as copy synthesis, codec, and reverberation augmentations, yielding an FPR95 of 8.3%.",
      "authors": [
        "Nicholas Klein",
        "Hemlata Tak",
        "Elie Khoury"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T01:03:36+00:00",
          "link": "https://arxiv.org/abs/2507.06470v1",
          "size": "51kb",
          "version": "v1"
        }
      ],
      "title": "Open-Set Source Tracing of Audio Deepfake Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06470",
        "HTML": "https://arxiv.org/html/2507.06470v1",
        "PDF": "https://arxiv.org/pdf/2507.06470"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with source tracing of audio deepfake systems and improvements in open-set source tracing, which are not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06839",
      "abstract": "Gaussian processes are a powerful framework for uncertainty-aware function approximation and sequential decision-making. Unfortunately, their classical formulation does not scale gracefully to large amounts of data and modern hardware for massively-parallel computation, prompting many researchers to develop techniques which improve their scalability. This dissertation focuses on the powerful combination of iterative methods and pathwise conditioning to develop methodological contributions which facilitate the use of Gaussian processes in modern large-scale settings. By combining these two techniques synergistically, expensive computations are expressed as solutions to systems of linear equations and obtained by leveraging iterative linear system solvers. This drastically reduces memory requirements, facilitating application to significantly larger amounts of data, and introduces matrix multiplication as the main computational operation, which is ideal for modern hardware.",
      "authors": [
        "Jihao Andreas Lin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T13:39:37+00:00",
          "link": "https://arxiv.org/abs/2507.06839v1",
          "size": "5760kb",
          "version": "v1"
        }
      ],
      "title": "Scalable Gaussian Processes: Advances in Iterative Methods and Pathwise Conditioning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06839",
        "PDF": "https://arxiv.org/pdf/2507.06839"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses scaling Gaussian processes with iterative methods, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.09879",
      "abstract": "Refactoring is the process of restructuring existing code without changing its external behavior while improving its internal structure. Refactoring engines are integral components of modern Integrated Development Environments (IDEs) and can automate or semi-automate this process to enhance code readability, reduce complexity, and improve the maintainability of software products. Similar to traditional software systems such as compilers, refactoring engines may also contain bugs that can lead to unexpected behaviors. In this paper, we propose a novel approach called RETESTER, a LLM-based framework for automated refactoring engine testing. Specifically, by using input program structure templates extracted from historical bug reports and input program characteristics that are error-prone, we design chain-of-thought (CoT) prompts to perform refactoring-preserving transformations. The generated variants are then tested on the latest version of refactoring engines using differential testing. We evaluate RETESTER on two most popular modern refactoring engines (i.e., ECLIPSE, and INTELLIJ IDEA). It successfully revealed 18 new bugs in the latest version of those refactoring engines. By the time we submit our paper, seven of them were confirmed by their developers, and three were fixed.",
      "authors": [
        "Haibo Wang",
        "Zhuolin Xu",
        "Shin Hwei Tan"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-16T23:31:49+00:00",
          "link": "https://arxiv.org/abs/2501.09879v1",
          "size": "2437kb",
          "version": "v1"
        },
        {
          "date": "2025-01-22T01:38:36+00:00",
          "link": "https://arxiv.org/abs/2501.09879v2",
          "size": "2437kb",
          "version": "v2"
        }
      ],
      "title": "Testing Refactoring Engine via Historical Bug Report driven LLM",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.09879",
        "HTML": "https://arxiv.org/html/2501.09879",
        "PDF": "https://arxiv.org/pdf/2501.09879"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses testing refactoring engines with an LLM framework and does not contribute to the processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05077",
      "abstract": "Deep neural networks are increasingly applied for automated histopathology. Yet, whole-slide images (WSIs) are often acquired at gigapixel sizes, rendering it computationally infeasible to analyze them entirely at high resolution. Diagnostic labels are largely available only at the slide-level, because expert annotation of images at a finer (patch) level is both laborious and expensive. Moreover, regions with diagnostic information typically occupy only a small fraction of the WSI, making it inefficient to examine the entire slide at full resolution. Here, we propose SASHA -- {\\it S}equential {\\it A}ttention-based {\\it S}ampling for {\\it H}istopathological {\\it A}nalysis -- a deep reinforcement learning approach for efficient analysis of histopathological images. First, SASHA learns informative features with a lightweight hierarchical, attention-based multiple instance learning (MIL) model. Second, SASHA samples intelligently and zooms selectively into a small fraction (10-20\\%) of high-resolution patches, to achieve reliable diagnosis. We show that SASHA matches state-of-the-art methods that analyze the WSI fully at high-resolution, albeit at a fraction of their computational and memory costs. In addition, it significantly outperforms competing, sparse sampling methods. We propose SASHA as an intelligent sampling model for medical imaging challenges that involve automated diagnosis with exceptionally large images containing sparsely informative features.",
      "authors": [
        "Tarun G and Naman Malpani and Gugan Thoppe and Sridharan Devarajan"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T15:03:12+00:00",
          "link": "https://arxiv.org/abs/2507.05077v1",
          "size": "12861kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T01:48:46+00:00",
          "link": "https://arxiv.org/abs/2507.05077v2",
          "size": "12861kb",
          "version": "v2"
        }
      ],
      "title": "Sequential Attention-based Sampling for Histopathological Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05077",
        "HTML": "https://arxiv.org/html/2507.05077v2",
        "PDF": "https://arxiv.org/pdf/2507.05077"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a model for efficient histopathological image analysis, which involves sequential attention-based sampling, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06481",
      "abstract": "Acoustic signals from industrial machines offer valuable insights for anomaly detection, predictive maintenance, and operational efficiency enhancement. However, existing task-specific, supervised learning methods often scale poorly and fail to generalize across diverse industrial scenarios, whose acoustic characteristics are distinct from general audio. Furthermore, the scarcity of accessible, large-scale datasets and pretrained models tailored for industrial audio impedes community-driven research and benchmarking. To address these challenges, we introduce DINOS (Diverse INdustrial Operation Sounds), a large-scale open-access dataset. DINOS comprises over 74,149 audio samples (exceeding 1,093 hours) collected from various industrial acoustic scenarios. We also present IMPACT (Industrial Machine Perception via Acoustic Cognitive Transformer), a novel foundation model for industrial machine sound analysis. IMPACT is pretrained on DINOS in a self-supervised manner. By jointly optimizing utterance and frame-level losses, it captures both global semantics and fine-grained temporal structures. This makes its representations suitable for efficient fine-tuning on various industrial downstream tasks with minimal labeled data. Comprehensive benchmarking across 30 distinct downstream tasks (spanning four machine types) demonstrates that IMPACT outperforms existing models on 24 tasks, establishing its superior effectiveness and robustness, while providing a new performance benchmark for future research.",
      "authors": [
        "Changheon Han",
        "Yuseop Sim",
        "Hoin Jung",
        "Jiho Lee",
        "Hojun Lee",
        "Yun Seok Kang",
        "Sucheol Woo",
        "Garam Kim",
        "Hyung Wook Park",
        "Martin Byung-Guk Jun"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T01:57:39+00:00",
          "link": "https://arxiv.org/abs/2507.06481v1",
          "size": "5420kb",
          "version": "v1"
        }
      ],
      "title": "IMPACT: Industrial Machine Perception via Acoustic Cognitive Transformer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06481",
        "HTML": "https://arxiv.org/html/2507.06481v1",
        "PDF": "https://arxiv.org/pdf/2507.06481"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces a new dataset (DINOS) for industrial acoustic analysis, it primarily focuses on model effectiveness and benchmarking instead of detailing the dataset creation and processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2408.01701",
      "abstract": "For multimodal skeleton-based action recognition, Graph Convolutional Networks (GCNs) are effective models. Still, their reliance on floating-point computations leads to high energy consumption, limiting their applicability in battery-powered devices. While energy-efficient, Spiking Neural Networks (SNNs) struggle to model skeleton dynamics, leading to suboptimal solutions. We propose Signal-SGN (Spiking Graph Convolutional Network), which utilizes the temporal dimension of skeleton sequences as the spike time steps and represents features as multi-dimensional discrete stochastic signals for temporal-frequency domain feature extraction. It combines the 1D Spiking Graph Convolution (1D-SGC) module and the Frequency Spiking Convolution (FSC) module to extract features from the skeleton represented as spiking form. Additionally, the Multi-Scale Wavelet Transform Feature Fusion (MWTF) module is proposed to extract dynamic spiking features and capture frequency-specific characteristics, enhancing classification performance. Experiments across three large-scale datasets reveal Signal-SGN exceeding state-of-the-art SNN-based methods in accuracy and computational efficiency while attaining comparable performance with GCN methods and significantly reducing theoretical energy consumption.",
      "authors": [
        "Naichuan Zheng",
        "Yuchen Du",
        "Hailun Xia",
        "Zeyu Liang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-03T07:47:16+00:00",
          "link": "https://arxiv.org/abs/2408.01701v1",
          "size": "429kb",
          "version": "v1"
        },
        {
          "date": "2024-10-18T05:12:00+00:00",
          "link": "https://arxiv.org/abs/2408.01701v2",
          "size": "429kb",
          "version": "v2"
        },
        {
          "date": "2024-12-21T03:47:21+00:00",
          "link": "https://arxiv.org/abs/2408.01701v3",
          "size": "1115kb",
          "version": "v3"
        },
        {
          "date": "2025-07-08T13:44:17+00:00",
          "link": "https://arxiv.org/abs/2408.01701v4",
          "size": "9286kb",
          "version": "v4"
        },
        {
          "date": "2025-07-09T05:57:47+00:00",
          "link": "https://arxiv.org/abs/2408.01701v5",
          "size": "9287kb",
          "version": "v5"
        }
      ],
      "title": "Signal-SGN: A Spiking Graph Convolutional Network for Skeletal Action Recognition via Learning Temporal-Frequency Dynamics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.01701",
        "HTML": "https://arxiv.org/html/2408.01701v5",
        "PDF": "https://arxiv.org/pdf/2408.01701"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on developing a spiking graph convolutional network for skeletal action recognition, which does not involve LLM training data processing or related data engineering."
      },
      "tasks": [
        "Action Recognition",
        "Computational Efficiency",
        "Skeleton Based Action Recognition"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.13846",
      "abstract": "An incomplete field-of-view (FOV) in diffusion magnetic resonance imaging (dMRI) can severely hinder the volumetric and bundle analyses of whole-brain white matter connectivity. Although existing works have investigated imputing the missing regions using deep generative models, it remains unclear how to specifically utilize additional information from paired multi-modality data and whether this can enhance the imputation quality and be useful for downstream tractography. To fill this gap, we propose a novel framework for imputing dMRI scans in the incomplete part of the FOV by integrating the learned diffusion features in the acquired part of the FOV to the complete brain anatomical structure. We hypothesize that by this design the proposed framework can enhance the imputation performance of the dMRI scans and therefore be useful for repairing whole-brain tractography in corrupted dMRI scans with incomplete FOV. We tested our framework on two cohorts from different sites with a total of 96 subjects and compared it with a baseline imputation method that treats the information from T1w and dMRI scans equally. The proposed framework achieved significant improvements in imputation performance, as demonstrated by angular correlation coefficient (p < 1E-5), and in downstream tractography accuracy, as demonstrated by Dice score (p < 0.01). Results suggest that the proposed framework improved imputation performance in dMRI scans by specifically utilizing additional information from paired multi-modality data, compared with the baseline method. The imputation achieved by the proposed framework enhances whole brain tractography, and therefore reduces the uncertainty when analyzing bundles associated with neurodegenerative.",
      "authors": [
        "Zhiyuan Li",
        "Chenyu Gao",
        "Praitayini Kanakaraj",
        "Shunxing Bao",
        "Lianrui Zuo",
        "Michael E. Kim",
        "Nancy R. Newlin",
        "Gaurav Rudravaram",
        "Nazirah M. Khairi",
        "Yuankai Huo",
        "Kurt G. Schilling",
        "Walter A. Kukull",
        "Arthur W. Toga",
        "Derek B. Archer",
        "Timothy J. Hohman",
        "Bennett A. Landman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-20T18:41:29+00:00",
          "link": "https://arxiv.org/abs/2409.13846v1",
          "size": "9133kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T16:25:52+00:00",
          "link": "https://arxiv.org/abs/2409.13846v2",
          "size": "11343kb",
          "version": "v2"
        }
      ],
      "title": "Multi-Modality Conditioned Variational U-Net for Field-of-View Extension in Brain Diffusion MRI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.13846",
        "PDF": "https://arxiv.org/pdf/2409.13846"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses imputation of incomplete FOV in dMRI images using multi-modality data and does not cover LLM training data processing or creation."
      },
      "tasks": [
        "Diffusion  MRI",
        "Imputation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.23090",
      "abstract": "Online advertising in recommendation platforms has gained significant attention, with a predominant focus on channel recommendation and budget allocation strategies. However, current offline reinforcement learning (RL) methods face substantial challenges when applied to sparse advertising scenarios, primarily due to severe overestimation, distributional shifts, and overlooking budget constraints. To address these issues, we propose MTORL, a novel multi-task offline RL model that targets two key objectives. First, we establish a Markov Decision Process (MDP) framework specific to the nuances of advertising. Then, we develop a causal state encoder to capture dynamic user interests and temporal dependencies, facilitating offline RL through conditional sequence modeling. Causal attention mechanisms are introduced to enhance user sequence representations by identifying correlations among causal states. We employ multi-task learning to decode actions and rewards, simultaneously addressing channel recommendation and budget allocation. Notably, our framework includes an automated system for integrating these tasks into online advertising. Extensive experiments on offline and online environments demonstrate MTORL's superiority over state-of-the-art methods.",
      "authors": [
        "Langming Liu",
        "Wanyu Wang",
        "Chi Zhang",
        "Bo Li",
        "Hongzhi Yin",
        "Xuetao Wei",
        "Wenbo Su",
        "Bo Zheng",
        "Xiangyu Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T05:05:13+00:00",
          "link": "https://arxiv.org/abs/2506.23090v1",
          "size": "1134kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T09:50:43+00:00",
          "link": "https://arxiv.org/abs/2506.23090v2",
          "size": "1134kb",
          "version": "v2"
        }
      ],
      "title": "Multi-task Offline Reinforcement Learning for Online Advertising in Recommender Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23090",
        "HTML": "https://arxiv.org/html/2506.23090v2",
        "PDF": "https://arxiv.org/pdf/2506.23090"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses challenges in online advertising frameworks using reinforcement learning, focusing on model strategies without contributing to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06441",
      "abstract": "In this paper, we introduce VisioPath, a novel framework combining vision-language models (VLMs) with model predictive control (MPC) to enable safe autonomous driving in dynamic traffic environments. The proposed approach leverages a bird's-eye view video processing pipeline and zero-shot VLM capabilities to obtain structured information about surrounding vehicles, including their positions, dimensions, and velocities. Using this rich perception output, we construct elliptical collision-avoidance potential fields around other traffic participants, which are seamlessly integrated into a finite-horizon optimal control problem for trajectory planning. The resulting trajectory optimization is solved via differential dynamic programming with an adaptive regularization scheme and is embedded in an event-triggered MPC loop. To ensure collision-free motion, a safety verification layer is incorporated in the framework that provides an assessment of potential unsafe trajectories. Extensive simulations in Simulation of Urban Mobility (SUMO) demonstrate that VisioPath outperforms conventional MPC baselines across multiple metrics. By combining modern AI-driven perception with the rigorous foundation of optimal control, VisioPath represents a significant step forward in safe trajectory planning for complex traffic systems.",
      "authors": [
        "Shanting Wang",
        "Panagiotis Typaldos",
        "Chenjun Li and Andreas A. Malikopoulos"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T22:47:41+00:00",
          "link": "https://arxiv.org/abs/2507.06441v1",
          "size": "10982kb",
          "version": "v1"
        }
      ],
      "title": "VisioPath: Vision-Language Enhanced Model Predictive Control for Safe Autonomous Navigation in Mixed Traffic",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06441",
        "HTML": "https://arxiv.org/html/2507.06441v1",
        "PDF": "https://arxiv.org/pdf/2507.06441"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on integrating vision-language models with model predictive control for autonomous navigation, but it does not discuss LLM training data processing nor data engineering related to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06624",
      "abstract": "Outlier detection (OD) seeks to distinguish inliers and outliers in completely unlabeled datasets and plays a vital role in science and engineering. Most existing OD methods require troublesome dataset-specific hyperparameter tuning and costly model training before they can be deployed to identify outliers. In this work, we propose UniOD, a universal OD framework that leverages labeled datasets to train a single model capable of detecting outliers of datasets from diverse domains. Specifically, UniOD converts each dataset into multiple graphs, produces consistent node features, and frames outlier detection as a node-classification task, and is able to generalize to unseen domains. As a result, UniOD avoids effort on model selection and hyperparameter tuning, reduces computational cost, and effectively utilizes the knowledge from historical datasets, which improves the convenience and accuracy in real applications. We evaluate UniOD on 15 benchmark OD datasets against 15 state-of-the-art baselines, demonstrating its effectiveness.",
      "authors": [
        "Dazhi Fu and Jicong Fan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T07:52:12+00:00",
          "link": "https://arxiv.org/abs/2507.06624v1",
          "size": "299kb",
          "version": "v1"
        }
      ],
      "title": "UniOD: A Universal Model for Outlier Detection across Diverse Domains",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06624",
        "HTML": "https://arxiv.org/html/2507.06624v1",
        "PDF": "https://arxiv.org/pdf/2507.06624"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is focused on creating a universal model for outlier detection and does not discuss LLM training data processing or contribute to improving training data quality."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06751",
      "abstract": "This position paper looks at differences between the current understandings of human-centered explainability and explainability AI. We discuss current ideas in both fields, as well as the differences and opportunities we discovered. As an example of combining both, we will present preliminary work on a new algebraic machine learning approach. We are excited to continue discussing design opportunities for human-centered explainability (HCx) and xAI with the broader HCxAI community.",
      "authors": [
        "Janin Koch",
        "Vitor Fortes Rey"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T11:16:04+00:00",
          "link": "https://arxiv.org/abs/2507.06751v1",
          "size": "363kb",
          "version": "v1"
        }
      ],
      "title": "Combining Human-centred Explainability and Explainable AI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06751",
        "HTML": "https://arxiv.org/html/2507.06751v1",
        "PDF": "https://arxiv.org/pdf/2507.06751"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores concepts of explainability in AI without focusing on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.16525",
      "abstract": "Large language model-generated code (LLMgCode) has become increasingly common in software development. So far LLMgCode has more quality issues than human-authored code (HaCode). It is common for LLMgCode to mix with HaCode in a code change, while the change is signed by only human developers, without being carefully examined. Many automated methods have been proposed to detect LLMgCode from HaCode, in which the perplexity-based method (PERPLEXITY for short) is the state-of-the-art method. However, the efficacy evaluation of PERPLEXITY has focused on detection accuracy. Yet it is unclear whether PERPLEXITY is good enough in a wider range of realistic evaluation settings. To this end, we carry out a family of experiments to compare PERPLEXITY against feature- and pre-training-based methods from three perspectives: detection accuracy, detection speed, and generalization capability. The experimental results show that PERPLEXITY has the best generalization capability while having limited detection accuracy and detection speed. Based on that, we discuss the strengths and limitations of PERPLEXITY, e.g., PERPLEXITY is unsuitable for high-level programming languages. Finally, we provide recommendations to improve PERPLEXITY and apply it in practice. As the first large-scale investigation on detecting LLMgCode from HaCode, this article provides a wide range of findings for future improvement.",
      "authors": [
        "Jinwei Xu",
        "He Zhang",
        "Yanjing Yang",
        "Lanxin Yang",
        "Zeru Cheng",
        "Jun Lyu",
        "Bohan Liu",
        "Xin Zhou",
        "Alberto Bacchelli",
        "Yin Kia Chiam",
        "Thiam Kian Chiew"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-21T08:02:58+00:00",
          "link": "https://arxiv.org/abs/2412.16525v1",
          "size": "1273kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T10:04:06+00:00",
          "link": "https://arxiv.org/abs/2412.16525v2",
          "size": "778kb",
          "version": "v2"
        }
      ],
      "title": "One Size Does Not Fit All: Investigating Efficacy of Perplexity in Detecting LLM-Generated Code",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.16525",
        "HTML": "https://arxiv.org/html/2412.16525v2",
        "PDF": "https://arxiv.org/pdf/2412.16525"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses LLM-generated code detection and methodological evaluation but does not focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.08617",
      "abstract": "While humans can flexibly leverage interactive visual cognition for complex problem-solving, enabling Large Vision-Language Models (LVLMs) to learn similarly adaptive behaviors with visual tools remains challenging. A significant hurdle is the current lack of standardized infrastructure, which hinders integrating diverse tools, generating rich interaction data, and training robust agents effectively. To address these gaps, we introduce OpenThinkIMG, the first open-source, comprehensive end-to-end framework for tool-augmented LVLMs. It features standardized vision tool interfaces, scalable trajectory generation for policy initialization, and a flexible training environment. Furthermore, considering supervised fine-tuning (SFT) on static demonstrations offers limited policy generalization for dynamic tool invocation, we propose a novel reinforcement learning (RL) framework V-ToolRL to train LVLMs to learn adaptive policies for invoking external vision tools. V-ToolRL enables LVLMs to autonomously discover optimal tool-usage strategies by directly optimizing for task success using feedback from tool interactions. We empirically validate V-ToolRL on challenging chart reasoning tasks. Our RL-trained agent, built upon a Qwen2-VL-2B, significantly outperforms its SFT-initialized counterpart (+28.83 points) and surpasses established supervised tool-learning baselines like Taco and CogCom by an average of +12.7 points. Notably, it also surpasses prominent closed-source models like GPT-4.1 by +8.68 accuracy points. We hope OpenThinkIMG can serve as a foundational framework for advancing dynamic, tool-augmented visual reasoning, helping the community develop AI agents that can genuinely \"think with images\".",
      "authors": [
        "Zhaochen Su",
        "Linjie Li",
        "Mingyang Song",
        "Yunzhuo Hao",
        "Zhengyuan Yang",
        "Jun Zhang",
        "Guanjie Chen",
        "Jiawei Gu",
        "Juntao Li",
        "Xiaoye Qu",
        "Yu Cheng"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-13T14:35:51+00:00",
          "link": "https://arxiv.org/abs/2505.08617v1",
          "size": "1629kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T14:53:06+00:00",
          "link": "https://arxiv.org/abs/2505.08617v2",
          "size": "1714kb",
          "version": "v2"
        }
      ],
      "title": "OpenThinkIMG: Learning to Think with Images via Visual Tool Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.08617",
        "HTML": "https://arxiv.org/html/2505.08617v2",
        "PDF": "https://arxiv.org/pdf/2505.08617"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a learning framework for vision-language models, mentioning supervised fine-tuning, but the focus is on reinforcement learning for tool use, not on data processing for LLM training."
      },
      "tasks": [
        "Reinforcement Learning (RL)",
        "Visual Reasoning"
      ],
      "repo_urls": [
        "https://github.com/zhaochen0110/openthinkimg"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06271",
      "abstract": "Many scientific disciplines have traditionally advanced by iterating over hypotheses using labor-intensive trial-and-error, which is a slow and expensive process. Recent advances in computing, digitalization, and machine learning have introduced tools that promise to make scientific research faster by assisting in this iterative process. However, these advances are scattered across disciplines and only loosely connected, with specific computational methods being primarily developed for narrow domain-specific applications. Virtual Laboratories are being proposed as a unified formulation to help researchers navigate this increasingly digital landscape using common AI technologies. While conceptually promising, VLs are not yet widely adopted in practice, and concrete implementations remain limited.This paper explains how the Virtual Laboratory concept can be implemented in practice by introducing the modular software library VAILabs, designed to support scientific discovery. VAILabs provides a flexible workbench and toolbox for a broad range of scientific domains. We outline the design principles and demonstrate a proof-of-concept by mapping three concrete research tasks from differing fields as virtual laboratory workflows.",
      "authors": [
        "Carlos Sevilla-Salcedo",
        "Armi Tiihonen",
        "Mahsa Asadi",
        "Kevin Sebastian Luck",
        "Aras Umut Erarslan",
        "Arto Klami",
        "Samuel Kaski"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Other Computer Science (cs.OH)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T07:31:37+00:00",
          "link": "https://arxiv.org/abs/2507.06271v1",
          "size": "1206kb",
          "version": "v1"
        }
      ],
      "title": "Virtual Laboratories: Domain-agnostic workflows for research",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06271",
        "HTML": "https://arxiv.org/html/2507.06271v1",
        "PDF": "https://arxiv.org/pdf/2507.06271"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on Virtual Laboratories for scientific research using AI technologies, without specific discussions on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06551",
      "abstract": "This paper develops a class of high-order conservative schemes for contaminant transport with equilibrium adsorption, based on the Integral Method with Variational Limit on block-centered grids. By incorporating four parameters, the scheme can reproduce classical fourth-order compact schemes and further extend to sixth- and eighth-order accurate formulations, all within a unified framework. Under periodic boundary conditions, we analyze the stability, convergence, and mass conservation of the parameterized numerical scheme. Numerical experiments are then conducted to examine the impact of parameter variations on errors, explore the relationship between parameters and the fourth-, sixth-, and eighth-order schemes, and verify that the schemes' high-order accuracy aligns with theoretical predictions. To enhance the applicability of the proposed method, we further develop two fourth-order compact boundary treatments that ensure uniform accuracy between boundary and interior regions. Numerical results confirm the effectiveness of the proposed schemes across various adsorption models.",
      "authors": [
        "He Liu and Xiongbo Zheng and Xiaole Li and Mingze Ji"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T05:08:56+00:00",
          "link": "https://arxiv.org/abs/2507.06551v1",
          "size": "2596kb",
          "version": "v1"
        }
      ],
      "title": "A Family of Block-Centered Schemes for Contaminant Transport Equations with Adsorption via Integral Method with Variational Limit",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06551",
        "HTML": "https://arxiv.org/html/2507.06551v1",
        "PDF": "https://arxiv.org/pdf/2507.06551"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper develops numerical schemes for contaminant transport equations and does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06585",
      "abstract": "A sophisticated hybrid quantum convolutional neural network (HQCNN) is conceived for handling the pilot assignment task in cell-free massive MIMO systems, while maximizing the total ergodic sum throughput. The existing model-based solutions found in the literature are inefficient and/or computationally demanding. Similarly, conventional deep neural networks may struggle in the face of high-dimensional inputs, require complex architectures, and their convergence is slow due to training numerous hyperparameters. The proposed HQCNN leverages parameterized quantum circuits (PQCs) relying on superposition for enhanced feature extraction. Specifically, we exploit the same PQC across all the convolutional layers for customizing the neural network and for accelerating the convergence. Our numerical results demonstrate that the proposed HQCNN offers a total network throughput close to that of the excessive-complexity exhaustive search and outperforms the state-of-the-art benchmarks.",
      "authors": [
        "Doan Hieu Nguyen",
        "Xuan Tung Nguyen",
        "Seon-Geun Jeong",
        "Trinh Van Chien",
        "Lajos Hanzo",
        "Won Joo Hwang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T06:33:43+00:00",
          "link": "https://arxiv.org/abs/2507.06585v1",
          "size": "544kb",
          "version": "v1"
        }
      ],
      "title": "Hybrid Quantum Convolutional Neural Network-Aided Pilot Assignment in Cell-Free Massive MIMO Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06585",
        "HTML": "https://arxiv.org/html/2507.06585v1",
        "PDF": "https://arxiv.org/pdf/2507.06585"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a hybrid quantum convolutional neural network for pilot assignment in massive MIMO systems, addressing network throughput rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06846",
      "abstract": "We propose and analyse residual-based a posteriori error estimates for the virtual element discretisation applied to the thin plate vibration problem in both two and three dimensions. Our approach involves a conforming $C^1$ discrete formulation suitable for meshes composed of polygons and polyhedra. The reliability and efficiency of the error estimator are established through a dimension-independent proof. Finally, several numerical experiments are reported to demonstrate the optimal performance of the method in 2D and 3D.",
      "authors": [
        "Franco Dassi",
        "Andres E. Rubiano",
        "Iv\\'an Vel\\'asquez"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T13:48:56+00:00",
          "link": "https://arxiv.org/abs/2507.06846v1",
          "size": "1614kb",
          "version": "v1"
        }
      ],
      "title": "A posteriori error estimates for a $C^1$ virtual element method applied to the thin plate vibration problem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06846",
        "HTML": "https://arxiv.org/html/2507.06846v1",
        "PDF": "https://arxiv.org/pdf/2507.06846"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with error estimates for a virtual element method applied to a vibration problem, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06993",
      "abstract": "Traditional travel-planning systems are often static and fragmented, leaving them ill-equipped to handle real-world complexities such as evolving environmental conditions and unexpected itinerary disruptions. In this paper, we identify three gaps between existing service providers causing frustrating user experience: intelligent trip planning, precision \"last-100-meter\" navigation, and dynamic itinerary adaptation. We propose three cooperative agents: a Travel Planning Agent that employs grid-based spatial grounding and map analysis to help resolve complex multi-modal user queries; a Destination Assistant Agent that provides fine-grained guidance for the final navigation leg of each journey; and a Local Discovery Agent that leverages image embeddings and Retrieval-Augmented Generation (RAG) to detect and respond to trip plan disruptions. With evaluations and experiments, our system demonstrates substantial improvements in query interpretation, navigation accuracy, and disruption resilience, underscoring its promise for applications from urban exploration to emergency response.",
      "authors": [
        "Jieren Deng",
        "Aleksandar Cvetkovic",
        "Pak Kiu Chung",
        "Dragomir Yankov and Chiqun Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T16:18:09+00:00",
          "link": "https://arxiv.org/abs/2507.06993v1",
          "size": "18166kb",
          "version": "v1"
        }
      ],
      "title": "The User-Centric Geo-Experience: An LLM-Powered Framework for Enhanced Planning, Navigation, and Dynamic Adaptation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06993",
        "HTML": "https://arxiv.org/html/2507.06993v1",
        "PDF": "https://arxiv.org/pdf/2507.06993"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes an LLM-powered framework for travel planning and navigation, focusing on agent interactions and user experience, not on training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07011",
      "abstract": "In recent years, deep learning has shown great promise in the automated detection and classification of brain tumors from MRI images. However, achieving high accuracy and computational efficiency remains a challenge. In this research, we propose Deep Brain Net, a novel deep learning system designed to optimize performance in the detection of brain tumors. The model integrates the strengths of two advanced neural network architectures which are EfficientNetB0 and ResNet50, combined with transfer learning to improve generalization and reduce training time. The EfficientNetB0 architecture enhances model efficiency by utilizing mobile inverted bottleneck blocks, which incorporate depth wise separable convolutions. This design significantly reduces the number of parameters and computational cost while preserving the ability of models to learn complex feature representations. The ResNet50 architecture, pre trained on large scale datasets like ImageNet, is fine tuned for brain tumor classification. Its use of residual connections allows for training deeper networks by mitigating the vanishing gradient problem and avoiding performance degradation. The integration of these components ensures that the proposed system is both computationally efficient and highly accurate. Extensive experiments performed on publicly available MRI datasets demonstrate that Deep Brain Net consistently outperforms existing state of the art methods in terms of classification accuracy, precision, recall, and computational efficiency. The result is an accuracy of 88 percent, a weighted F1 score of 88.75 percent, and a macro AUC ROC score of 98.17 percent which demonstrates the robustness and clinical potential of Deep Brain Net in assisting radiologists with brain tumor diagnosis.",
      "authors": [
        "Daniel Onah and Ravish Desai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T16:42:26+00:00",
          "link": "https://arxiv.org/abs/2507.07011v1",
          "size": "2070kb",
          "version": "v1"
        }
      ],
      "title": "Deep Brain Net: An Optimized Deep Learning Model for Brain tumor Detection in MRI Images Using EfficientNetB0 and ResNet50 with Transfer Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07011",
        "HTML": "https://arxiv.org/html/2507.07011v1",
        "PDF": "https://arxiv.org/pdf/2507.07011"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a novel deep learning model for brain tumor detection using MRI images, emphasizing model architecture and performance rather than any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2308.04964",
      "abstract": "Many Web Application Firewalls (WAFs) leverage the OWASP CRS to block incoming malicious requests. The CRS consists of different sets of rules designed by domain experts to detect well-known web attack patterns. Both the set of rules and the weights used to combine them are manually defined, yielding four different default configurations of the CRS. In this work, we focus on the detection of SQLi attacks, and show that the manual configurations of the CRS typically yield a suboptimal trade-off between detection and false alarm rates. Furthermore, we show that these configurations are not robust to adversarial SQLi attacks, i.e., carefully-crafted attacks that iteratively refine the malicious SQLi payload by querying the target WAF to bypass detection. To overcome these limitations, we propose (i) using machine learning to automate the selection of the set of rules to be combined along with their weights, i.e., customizing the CRS configuration based on the monitored web services; and (ii) leveraging adversarial training to significantly improve its robustness to adversarial SQLi manipulations. Our experiments, conducted using the well-known open-source ModSecurity WAF equipped with the CRS rules, show that our approach, named ModSec-AdvLearn, can (i) increase the detection rate up to 30%, while retaining negligible false alarm rates and discarding up to 50% of the CRS rules; and (ii) improve robustness against adversarial SQLi attacks up to 85%, marking a significant stride toward designing more effective and robust WAFs. We release our open-source code at https://github.com/pralab/modsec-advlearn.",
      "authors": [
        "Giuseppe Floris",
        "Christian Scano",
        "Biagio Montaruli",
        "Luca Demetrio",
        "Andrea Valenza",
        "Luca Compagna",
        "Davide Ariu",
        "Luca Piras",
        "Davide Balzarotti",
        "Battista Biggio"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2023-08-09T13:58:03+00:00",
          "link": "https://arxiv.org/abs/2308.04964v1",
          "size": "370kb",
          "version": "v1"
        },
        {
          "date": "2023-08-17T09:08:49+00:00",
          "link": "https://arxiv.org/abs/2308.04964v2",
          "size": "370kb",
          "version": "v2"
        },
        {
          "date": "2024-11-29T16:33:12+00:00",
          "link": "https://arxiv.org/abs/2308.04964v3",
          "size": "11121kb",
          "version": "v3"
        },
        {
          "date": "2025-05-21T13:35:45+00:00",
          "link": "https://arxiv.org/abs/2308.04964v4",
          "size": "6834kb",
          "version": "v4"
        }
      ],
      "title": "ModSec-AdvLearn: Countering Adversarial SQL Injections with Robust Machine Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2308.04964",
        "HTML": "https://arxiv.org/html/2308.04964",
        "PDF": "https://arxiv.org/pdf/2308.04964"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses machine learning for SQL injection detection and robustness, which does not pertain to LLM training data processing."
      },
      "tasks": [
        "Adversarial Robustness"
      ],
      "repo_urls": [
        "https://github.com/pralab/modsec-learn",
        "https://github.com/pralab/modsec-advlearn"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06477",
      "abstract": "A covering path for a finite set $P$ of points in the plane is a polygonal path such that every point of $P$ lies on a segment of the path. The vertices of the path need not be at points of $P$. A covering path is plane if its segments do not cross each other. Let $\\pi(n)$ be the minimum number such that every set of $n$ points in the plane admits a plane covering path with at most $\\pi(n)$ segments. We prove that $\\pi(n)\\le \\lceil6n/7\\rceil$. This improves the previous best-known upper bound of $\\lceil 21n/22\\rceil$, due to Biniaz (SoCG 2023). Our proof is constructive and yields a simple $O(n\\log n)$-time algorithm for computing a plane covering path.",
      "authors": [
        "Hugo A. Akitaya",
        "Greg Aloupis",
        "Ahmad Biniaz",
        "Prosenjit Bose",
        "Jean-Lou De Carufel",
        "Cyril Gavoille",
        "John Iacono",
        "Linda Kleist",
        "Michiel Smid",
        "Diane Souvaine",
        "Leonidas Theocharous"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Geometry (cs.CG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T01:52:22+00:00",
          "link": "https://arxiv.org/abs/2507.06477v1",
          "size": "209kb",
          "version": "v1"
        }
      ],
      "title": "An Improved Bound for Plane Covering Paths",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06477",
        "HTML": "https://arxiv.org/html/2507.06477v1",
        "PDF": "https://arxiv.org/pdf/2507.06477"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about finding covering paths for points in the plane and improving computational bounds. It is not related to processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06949",
      "abstract": "Ancient populations markedly transformed Neotropical forests, yet understanding the long-term effects of ancient human management, particularly at high-resolution scales, remains challenging. In this work we propose a new approach to investigate archaeological areas of influence based on vegetation signatures. It consists of a deep learning model trained on satellite imagery to identify palm trees, followed by a clustering algorithm to identify palm clusters, which are then used to estimate ancient management areas. To assess the palm distribution in relation to past human activity, we applied the proposed approach to unique high-resolution satellite imagery data covering 765 km2 of the Sierra Nevada de Santa Marta, Colombia. With this work, we also release a manually annotated palm tree dataset along with estimated locations of archaeological sites from ground-surveys and legacy records. Results demonstrate how palms were significantly more abundant near archaeological sites showing large infrastructure investment. The extent of the largest palm cluster indicates that ancient human-managed areas linked to major infrastructure sites may be up to two orders of magnitude bigger than indicated by archaeological evidence alone. Our findings suggest that pre-Columbian populations influenced local vegetation fostering conditions conducive to palm proliferation, leaving a lasting ecological footprint. This may have lowered the logistical costs of establishing infrastructure-heavy settlements in otherwise less accessible locations. Overall, this study demonstrates the potential of integrating artificial intelligence approaches with new ecological and archaeological data to identify archaeological areas of interest through vegetation patterns, revealing fine-scale human-environment interactions.",
      "authors": [
        "Sebastian Fajardo",
        "Sina Mohammadi",
        "Jonas Gregorio de Souza",
        "C\\'esar Ardila",
        "Alan Tapscott Baltar",
        "Shaddai Heidgen",
        "Maria Isabel Mayorga Hern\\'andez",
        "Sylvia Mota de Oliveira",
        "Fernando Montejo",
        "Marco Moderato",
        "Vinicius Peripato",
        "Katy Puche",
        "Carlos Reina",
        "Juan Carlos Vargas",
        "Frank W. Takes",
        "Marco Madella"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T15:31:44+00:00",
          "link": "https://arxiv.org/abs/2507.06949v1",
          "size": "43504kb",
          "version": "v1"
        }
      ],
      "title": "Pre-Columbian Settlements Shaped Palm Clusters in the Sierra Nevada de Santa Marta, Colombia",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06949",
        "HTML": "https://arxiv.org/html/2507.06949v1",
        "PDF": "https://arxiv.org/pdf/2507.06949"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on using deep learning and clustering to examine vegetation for archaeological research, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2307.14876",
      "abstract": "Rescheduling problems arise in a variety of situations where a previously planned schedule needs to be adjusted to deal with unforeseen events. A common problem is the arrival of new orders, i.e. jobs, which have to be integrated into the schedule of the so-called old jobs. The maximum and total absolute time deviations of the completion times of these jobs are modeled as a disruption constraint to limit the change in the original schedule. Disruption constraints affect the shape of an optimal schedule, particularly with respect to the sequencing of old jobs and the insertion of idle time. We therefore give a classification into idle and no-idle problems for a set of single-machine rescheduling problems with different objective functions. We then prove the complexity of five rescheduling problems that have been left open in the literature.",
      "authors": [
        "Elena Rener",
        "Fabio Salassa",
        "Vincent T'kindt"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2023-07-27T14:06:36+00:00",
          "link": "https://arxiv.org/abs/2307.14876v1",
          "size": "13kb",
          "version": "v1"
        }
      ],
      "title": "Single machine rescheduling for new orders: properties and complexity results",
      "links": {
        "Abstract": "https://arxiv.org/abs/2307.14876",
        "PDF": "https://arxiv.org/pdf/2307.14876"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses rescheduling problems related to single-machine scenarios and optimization, which do not relate to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.12446",
      "abstract": "Inference-time intervention (ITI) has emerged as a promising method for steering large language model (LLM) behavior in a particular direction (e.g., improving helpfulness) by intervening on token representations without costly updates to the LLM's parameters. However, existing ITI approaches fail to scale to multi-attribute settings with conflicts, such as enhancing helpfulness while also reducing toxicity. To address this, we introduce Multi-Attribute Targeted Steering (MAT-Steer), a novel steering framework designed for selective token-level intervention across multiple attributes. MAT-Steer learns steering vectors using an alignment objective that shifts the model's internal representations of undesirable outputs closer to those of desirable ones while enforcing sparsity and orthogonality among vectors for different attributes, thereby reducing inter-attribute conflicts. We evaluate MAT-Steer in two distinct settings: (i) on question answering (QA) tasks where we balance attributes like truthfulness, bias, and toxicity; (ii) on generative tasks where we simultaneously improve attributes like helpfulness, correctness, and coherence. MAT-Steer outperforms existing ITI and parameter-efficient fine-tuning approaches across both task types (e.g., 3% average accuracy gain across QA tasks and 55.82% win rate against the best ITI baseline).",
      "authors": [
        "Duy Nguyen",
        "Archiki Prasad",
        "Elias Stengel-Eskin",
        "Mohit Bansal"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-18T02:27:23+00:00",
          "link": "https://arxiv.org/abs/2502.12446v1",
          "size": "1155kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T17:31:20+00:00",
          "link": "https://arxiv.org/abs/2502.12446v2",
          "size": "1158kb",
          "version": "v2"
        }
      ],
      "title": "Multi-Attribute Steering of Language Models via Targeted Intervention",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.12446",
        "HTML": "https://arxiv.org/html/2502.12446v2",
        "PDF": "https://arxiv.org/pdf/2502.12446"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with inference-time intervention for steering LLM behavior and does not focus on training data processing or creation for LLM pretraining or fine-tuning tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.03711",
      "abstract": "In this paper, we explore the ability of large language models (LLMs) to plan and make decisions through the lens of the traditional Vietnamese board game, \\^O \\u{A}n Quan. This game, which involves a series of strategic token movements and captures, offers a unique environment for evaluating the decision-making and strategic capabilities of LLMs. Specifically, we develop various agent personas, ranging from aggressive to defensive, and employ the \\^O \\u{A}n Quan game as a testbed for assessing LLM performance across different strategies. Through experimentation with models like Llama-3.2-3B-Instruct, Llama-3.1-8B-Instruct, and Llama-3.3-70B-Instruct, we aim to understand how these models execute strategic decision-making, plan moves, and manage dynamic game states. The results will offer insights into the strengths and weaknesses of LLMs in terms of reasoning and strategy, contributing to a deeper understanding of their general capabilities.",
      "authors": [
        "Sang Quang Nguyen",
        "Kiet Van Nguyen",
        "Vinh-Tiep Nguyen",
        "Thanh Duc Ngo",
        "Ngan Luu-Thuy Nguyen",
        "Duy-Dinh Le"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-04T16:50:40+00:00",
          "link": "https://arxiv.org/abs/2507.03711v1",
          "size": "728kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T17:18:23+00:00",
          "link": "https://arxiv.org/abs/2507.03711v2",
          "size": "645kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T02:09:05+00:00",
          "link": "https://arxiv.org/abs/2507.03711v3",
          "size": "645kb",
          "version": "v3"
        }
      ],
      "title": "Can LLMs Play \\^O \\u{A}n Quan Game? A Study of Multi-Step Planning and Decision Making",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.03711",
        "HTML": "https://arxiv.org/html/2507.03711v3",
        "PDF": "https://arxiv.org/pdf/2507.03711"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the strategic capabilities of LLMs in a board game setting, without discussing any aspects related to the processing or preparation of training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07006",
      "abstract": "Microscopic assessment of histopathology images is vital for accurate cancer diagnosis and treatment. Whole Slide Image (WSI) classification and captioning have become crucial tasks in computer-aided pathology. However, microscopic WSI face challenges such as redundant patches and unknown patch positions due to subjective pathologist captures. Moreover, generating automatic pathology captions remains a significant challenge. To address these issues, we introduce a novel GNN-ViTCap framework for classification and caption generation from histopathological microscopic images. First, a visual feature extractor generates patch embeddings. Redundant patches are then removed by dynamically clustering these embeddings using deep embedded clustering and selecting representative patches via a scalar dot attention mechanism. We build a graph by connecting each node to its nearest neighbors in the similarity matrix and apply a graph neural network to capture both local and global context. The aggregated image embeddings are projected into the language model's input space through a linear layer and combined with caption tokens to fine-tune a large language model. We validate our method on the BreakHis and PatchGastric datasets. GNN-ViTCap achieves an F1 score of 0.934 and an AUC of 0.963 for classification, along with a BLEU-4 score of 0.811 and a METEOR score of 0.569 for captioning. Experimental results demonstrate that GNN-ViTCap outperforms state of the art approaches, offering a reliable and efficient solution for microscopy based patient diagnosis.",
      "authors": [
        "S M Taslim Uddin Raju",
        "Md. Milon Islam",
        "Md Rezwanul Haque",
        "Hamdi Altaheri",
        "and Fakhri Karray"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T16:35:21+00:00",
          "link": "https://arxiv.org/abs/2507.07006v1",
          "size": "2114kb",
          "version": "v1"
        }
      ],
      "title": "GNN-ViTCap: GNN-Enhanced Multiple Instance Learning with Vision Transformers for Whole Slide Image Classification and Captioning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07006",
        "HTML": "https://arxiv.org/html/2507.07006v1",
        "PDF": "https://arxiv.org/pdf/2507.07006"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper involves data clustering and selection techniques to handle redundant data in histopathology images, its focus is on a specific application (image classification and captioning) rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "1706.00834",
      "abstract": "We propose a general method for combinatorial online learning problems whose offline optimization problem can be solved efficiently via a dynamic programming algorithm defined by an arbitrary min-sum recurrence. Examples include online learning of Binary Search Trees, Matrix-Chain Multiplications, $k$-sets, Knapsacks, Rod Cuttings, and Weighted Interval Schedulings. For each of these problems we use the underlying graph of subproblems (called a multi-DAG) for defining a representation of the solutions of the dynamic programming problem by encoding them as a generalized version of paths (called multipaths). These multipaths encode each solution as a series of successive decisions or components over which the loss is linear. We then show that the dynamic programming algorithm for each problem leads to online algorithms for learning multipaths in the underlying multi-DAG. The algorithms maintain a distribution over the multipaths in a concise form as their hypothesis. More specifically we generalize the existing Expanded Hedge and Component Hedge algorithms for the online shortest path problem to learning multipaths. Additionally, we introduce a new and faster prediction technique for Component Hedge which in our case directly samples from a distribution over multipaths, bypassing the need to decompose the distribution over multipaths into a mixture with small support.",
      "authors": [
        "Holakou Rahmanian",
        "Manfred K. Warmuth",
        "S.V.N. Vishwanathan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2017-06-02T20:02:19+00:00",
          "link": "https://arxiv.org/abs/1706.00834v1",
          "size": "1918kb",
          "version": "v1"
        },
        {
          "date": "2017-06-07T22:30:44+00:00",
          "link": "https://arxiv.org/abs/1706.00834v2",
          "size": "1918kb",
          "version": "v2"
        },
        {
          "date": "2017-12-11T20:02:19+00:00",
          "link": "https://arxiv.org/abs/1706.00834v3",
          "size": "2020kb",
          "version": "v3"
        },
        {
          "date": "2025-07-08T20:11:49+00:00",
          "link": "https://arxiv.org/abs/1706.00834v4",
          "size": "76kb",
          "version": "v4"
        }
      ],
      "title": "Online Dynamic Programming",
      "links": {
        "Abstract": "https://arxiv.org/abs/1706.00834",
        "HTML": "https://arxiv.org/html/1706.00834v4",
        "PDF": "https://arxiv.org/pdf/1706.00834"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes algorithms for combinatorial online learning problems using dynamic programming, with no discussion on processing LLM training data."
      },
      "conference": "online-dynamic-programming-1",
      "conference_url_abs": "http://papers.nips.cc/paper/6875-online-dynamic-programming",
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.06460",
      "abstract": "Whether it be source code in a programming language, prose in natural language, or otherwise, text is highly structured. Currently, text visualizations are confined either to _flat, line-based_ decorations, which can convey only limited information about textual structure, or _nested boxes_, which convey structure but often destroy the typographic layout of the underlying text. We hypothesize that the lack of rich styling options limits the kinds of information that are displayed alongside text, wherever it may be displayed.\n  In this paper, we show that it is possible to achieve arbitrarily nested decorations while minimally disturbing the underlying typographic layout. Specifically, we present a layout algorithm that generates _ragged blocks_, or _rocks_, which are rectilinear polygons that allow nested text to be compactly rendered even when styled with borders and padding.\n  We evaluate our layout algorithm in two ways. First, on a benchmark suite comprising representative source code files in multiple programming languages, we show that the (ragged block) layouts produced by our algorithm are substantially more compact than the (rectangular block) layouts produced by conventional techniques, when uniformly styling every element in the syntax tree with borders and padding. Second, through a small gallery of usage scenarios, we demonstrate how future code editors, word processors, and other document-rendering GUIs might convey rich semantic information through domain-specific styling of ragged blocks.",
      "authors": [
        "Sam Cohen and Ravi Chugh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T00:26:52+00:00",
          "link": "https://arxiv.org/abs/2507.06460v1",
          "size": "4246kb",
          "version": "v1"
        }
      ],
      "title": "Ragged Blocks: Rendering Structured Text with Style",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06460",
        "HTML": "https://arxiv.org/html/2507.06460v1",
        "PDF": "https://arxiv.org/pdf/2507.06460"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with rendering structured text using ragged blocks and does not focus on LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.05188",
      "abstract": "Arbitrary matrices $M \\in \\mathbb{R}^{m \\times n}$, randomly perturbed in an additive manner using a random matrix $R \\in \\mathbb{R}^{m \\times n}$, are shown to asymptotically almost surely satisfy the so-called {\\sl robust null space property}. Whilst insisting on an asymptotically optimal order of magnitude for $m$ required to attain {\\sl unique reconstruction} via $\\ell_1$-minimisation algorithms, our results track the level of arbitrariness allowed for the fixed seed matrix $M$ as well as the degree of distributional irregularity allowed for the entries of the perturbing matrix $R$. Starting with sub-gaussian entries for $R$, our results culminate with these allowed to have substantially heavier tails than sub-exponential ones. Throughout this trajectory, two measures control the arbitrariness allowed for $M$; the first is $\\|M\\|_\\infty$ and the second is a localised notion of the Frobenius norm of $M$ (which depends on the sparsity of the signal being reconstructed). A key tool driving our proofs is {\\sl Mendelson's small-ball method} ({\\em Learning without concentration}, J. ACM, Vol. $62$, $2015$).",
      "authors": [
        "Elad Aigner-Horev",
        "Dan Hefetz",
        "and Michael Trushkin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Probability (math.PR)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-08T12:37:36+00:00",
          "link": "https://arxiv.org/abs/2505.05188v1",
          "size": "38kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T07:51:40+00:00",
          "link": "https://arxiv.org/abs/2505.05188v2",
          "size": "39kb",
          "version": "v2"
        }
      ],
      "title": "Smoothed analysis in compressed sensing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.05188",
        "HTML": "https://arxiv.org/html/2505.05188v2",
        "PDF": "https://arxiv.org/pdf/2505.05188"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is centered on mathematical properties in compressed sensing without discussing any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.03049",
      "abstract": "We explore the role of torsion in hybrid deep learning models that incorporate topological data analysis, focusing on autoencoders. While most TDA tools use field coefficients, this conceals torsional features present in integer homology. We show that torsion can be lost during encoding, altered in the latent space, and in many cases, not reconstructed by standard decoders. Using both synthetic and high-dimensional data, we evaluate torsion sensitivity to perturbations and assess its recoverability across several autoencoder architectures. Our findings reveal key limitations of field-based approaches and underline the need for architectures or loss terms that preserve torsional information for robust data representation.",
      "authors": [
        "Maria Walch"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Algebraic Topology (math.AT)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-03T16:29:06+00:00",
          "link": "https://arxiv.org/abs/2506.03049v1",
          "size": "7018kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T10:38:34+00:00",
          "link": "https://arxiv.org/abs/2506.03049v2",
          "size": "7018kb",
          "version": "v2"
        }
      ],
      "title": "Torsion in Persistent Homology and Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.03049",
        "HTML": "https://arxiv.org/html/2506.03049v2",
        "PDF": "https://arxiv.org/pdf/2506.03049"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with the use of topological data analysis in deep learning models, specifically focusing on torsion in integer homology, without relevance to LLM training data processing."
      },
      "tasks": [
        "Topological Data Analysis"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.11111",
      "abstract": "Large Language Models (LLMs) have gained enormous attention in recent years due to their capability of understanding and generating natural languages. With the rapid development and wild-range applications (e.g., Agents, Embodied Intelligence), the robustness of LLMs has received increased attention. As the core brain of many AI applications, the robustness of LLMs requires that models should not only generate consistent contents, but also ensure the correctness and stability of generated content when dealing with unexpeted application scenarios (e.g., toxic prompts, limited noise domain data, outof-distribution (OOD) applications, etc). In this survey paper, we conduct a thorough review of the robustness of LLMs, aiming to provide a comprehensive terminology of concepts and methods around this field and facilitate the community. Specifically, we first give a formal definition of LLM robustness and present the collection protocol of this survey paper. Then, based on the types of perturbated inputs, we organize this survey from the following perspectives: 1) Adversarial Robustness: tackling the problem that prompts are manipulated intentionally, such as noise prompts, long context, data attack, etc; 2) OOD Robustness: dealing with the unexpected real-world application scenarios, such as OOD detection, zero-shot transferring, hallucinations, etc; 3) Evaluation of Robustness: summarizing the new evaluation datasets, metrics, and tools for verifying the robustness of LLMs. After reviewing the representative work from each perspective, we discuss and highlight future opportunities and research directions in this field. Meanwhile, we also organize related works and provide an easy-to-search project (https://github.com/zhangkunzk/Awesome-LLM-Robustness-papers) to support the community.",
      "authors": [
        "Kun Zhang",
        "Le Wu",
        "Kui Yu",
        "Guangyi Lv",
        "Dacao Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-08T16:20:12+00:00",
          "link": "https://arxiv.org/abs/2506.11111v1",
          "size": "946kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T06:18:33+00:00",
          "link": "https://arxiv.org/abs/2506.11111v2",
          "size": "944kb",
          "version": "v2"
        }
      ],
      "title": "Evaluating and Improving Robustness in Large Language Models: A Survey and Future Directions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.11111",
        "HTML": "https://arxiv.org/html/2506.11111v2",
        "PDF": "https://arxiv.org/pdf/2506.11111"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper surveys robustness in LLMs, including datasets and evaluation, but does not emphasize training data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.12418",
      "abstract": "The performance of quantum simulations heavily depends on the efficiency of noise mitigation techniques and error correction algorithms. Reinforcement has emerged as a powerful strategy to enhance the efficiency of learning and optimization algorithms. In this study, we demonstrate that a reinforced quantum dynamics can exhibit significant robustness against interactions with a noisy environment. We study a quantum annealing process where, through reinforcement, the system is encouraged to maintain its current state or follow a noise-free evolution. A learning algorithm is employed to derive a concise approximation of this reinforced dynamics, reducing the total evolution time and, consequently, the system's exposure to noisy interactions. This also avoids the complexities associated with implementing quantum feedback in such reinforcement algorithms. The efficacy of our method is demonstrated through numerical simulations of reinforced quantum annealing with one- and two-qubit systems under Pauli noise.",
      "authors": [
        "Abolfazl Ramezanpour"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-14T09:22:12+00:00",
          "link": "https://arxiv.org/abs/2506.12418v1",
          "size": "682kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T13:01:12+00:00",
          "link": "https://arxiv.org/abs/2506.12418v2",
          "size": "683kb",
          "version": "v2"
        }
      ],
      "title": "Noise tolerance via reinforcement: Learning a reinforced quantum dynamics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.12418",
        "HTML": "https://arxiv.org/html/2506.12418v2",
        "PDF": "https://arxiv.org/pdf/2506.12418"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on reinforced quantum dynamics and noise mitigation in quantum simulations without addressing any aspect of LLM training data collection or processing."
      },
      "tasks": [
        "reinforcement-learning",
        "Reinforcement Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06234",
      "abstract": "High-quality underwater images are essential for both machine vision tasks and viewers with their aesthetic appeal.However, the quality of underwater images is severely affected by light absorption and scattering. Deep learning-based methods for Underwater Image Enhancement (UIE) have achieved good performance. However, these methods often overlook considering human perception and lack sufficient constraints within the solution space. Consequently, the enhanced images often suffer from diminished perceptual quality or poor content restoration.To address these issues, we propose a UIE method with a Contrastive Language-Image Pre-Training (CLIP) perception loss module and curriculum contrastive regularization. Above all, to develop a perception model for underwater images that more aligns with human visual perception, the visual semantic feature extraction capability of the CLIP model is leveraged to learn an appropriate prompt pair to map and evaluate the quality of underwater images. This CLIP perception model is then incorporated as a perception loss module into the enhancement network to improve the perceptual quality of enhanced images. Furthermore, the CLIP perception model is integrated with the curriculum contrastive regularization to enhance the constraints imposed on the enhanced images within the CLIP perceptual space, mitigating the risk of both under-enhancement and over-enhancement. Specifically, the CLIP perception model is employed to assess and categorize the learning difficulty level of negatives in the regularization process, ensuring comprehensive and nuanced utilization of distorted images and negatives with varied quality levels. Extensive experiments demonstrate that our method outperforms state-of-the-art methods in terms of visual quality and generalization ability.",
      "authors": [
        "Jiangzhong Cao",
        "Zekai Zeng",
        "Xu Zhang",
        "Huan Zhang",
        "Chunling Fan",
        "Gangyi Jiang",
        "Weisi Lin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-29T04:03:15+00:00",
          "link": "https://arxiv.org/abs/2507.06234v1",
          "size": "12226kb",
          "version": "v1"
        }
      ],
      "title": "Unveiling the Underwater World: CLIP Perception Model-Guided Underwater Image Enhancement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06234",
        "HTML": "https://arxiv.org/html/2507.06234v1",
        "PDF": "https://arxiv.org/pdf/2507.06234"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper centers on image enhancement and perception models, with no focus on LLM training data processing or related data-engineering methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06509",
      "abstract": "Facility location is fundamental in operations research, mechanism design, and algorithmic game theory, with applications ranging from urban infrastructure planning to distributed systems. Recent research in this area has focused on augmenting classic strategyproof mechanisms with predictions to achieve an improved performance guarantee against the uncertainty under the strategic environment. Previous work has been devoted to address the trade-off obstacle of balancing the consistency (near-optimality under accurate predictions) and robustness (bounded inefficiency under poor predictions) primarily in the unweighted setting, assuming that all agents have the same importance. However, this assumption may not be true in some practical scenarios, leading to research of weighted facility location problems.\n  The major contribution of the current work is to provide a prediction augmented algorithmic framework for balancing the consistency and robustness over strategic agents with non-uniform weights. In particular, through a reduction technique that identifies a subset of \\emph{representative} instances and maps the other given locations to the representative ones, we prove that there exists a \\emph{strategyproof} mechanism achieving a bounded consistency guarantee of $\\frac{\\sqrt{(1+c)^2W^2_{\\min}+(1-c)^2W^2_{\\max}}}{(1+c)W_{\\min}}$ and a bounded robustness guarantee of $\\frac{\\sqrt{(1-c)^2W^2_{\\min}+(1+c)^2W^2_{\\max}}}{(1-c)W_{\\min}}$ in weighted settings, where $c$ can be viewed as a parameter to make a trade-off between the consistency and robustness and $W_{\\min}$ and $W_{\\max}$ denote the minimum and maximum agents' weight. We also proved that there is no strategyproof deterministic mechanism that reach $1$-consistency and $O\\left( n \\cdot \\frac{W_{\\max}}{W_{\\min}} \\right)$-robustness in weighted FLP, even with fully predictions of all agents.",
      "authors": [
        "Yangguang Shi",
        "Zhenyu Xue"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Computer Science and Game Theory (cs.GT)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T03:13:52+00:00",
          "link": "https://arxiv.org/abs/2507.06509v1",
          "size": "18kb",
          "version": "v1"
        }
      ],
      "title": "Prediction-Augmented Mechanism Design for Weighted Facility Location",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06509",
        "HTML": "https://arxiv.org/html/2507.06509v1",
        "PDF": "https://arxiv.org/pdf/2507.06509"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research involves algorithmic solutions in weighted facility location problems and does not deal with LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.05780",
      "abstract": "The rapid evolution of generative AI has expanded the breadth of risks associated with AI systems. While various taxonomies and frameworks exist to classify these risks, the lack of interoperability between them creates challenges for researchers, practitioners, and policymakers seeking to operationalise AI governance. To address this gap, we introduce the AI Risk Atlas, a structured taxonomy that consolidates AI risks from diverse sources and aligns them with governance frameworks. Additionally, we present the Risk Atlas Nexus, a collection of open-source tools designed to bridge the divide between risk definitions, benchmarks, datasets, and mitigation strategies. This knowledge-driven approach leverages ontologies and knowledge graphs to facilitate risk identification, prioritization, and mitigation. By integrating AI-assisted compliance workflows and automation strategies, our framework lowers the barrier to responsible AI adoption. We invite the broader research and open-source community to contribute to this evolving initiative, fostering cross-domain collaboration and ensuring AI governance keeps pace with technological advancements.",
      "authors": [
        "Frank Bagehorn",
        "Kristina Brimijoin",
        "Elizabeth M. Daly",
        "Jessica He",
        "Michael Hind",
        "Luis Garces-Erice",
        "Christopher Giblin",
        "Ioana Giurgiu",
        "Jacquelyn Martino",
        "Rahul Nair",
        "David Piorkowski",
        "Ambrish Rawat",
        "John Richards",
        "Sean Rooney",
        "Dhaval Salwala",
        "Seshu Tirupathi",
        "Peter Urbanetz",
        "Kush R. Varshney",
        "Inge Vejsbjerg",
        "Mira L. Wolf-Bauwens"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-26T12:23:14+00:00",
          "link": "https://arxiv.org/abs/2503.05780v1",
          "size": "1353kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T12:28:00+00:00",
          "link": "https://arxiv.org/abs/2503.05780v2",
          "size": "289kb",
          "version": "v2"
        }
      ],
      "title": "AI Risk Atlas: Taxonomy and Tooling for Navigating AI Risks and Resources",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.05780",
        "HTML": "https://arxiv.org/html/2503.05780v2",
        "PDF": "https://arxiv.org/pdf/2503.05780"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a taxonomy and tooling for navigating AI risks, with no emphasis on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22652",
      "abstract": "Efficient and fair coexistence in unlicensed spectrum is essential to support heterogeneous networks such as 5G NR-U and Wi-Fi, which often contend for shared wireless resources. We introduce a general framework for wireless Coexistence Parameter Management (CPM) based on state-augmented constrained reinforcement learning. We propose a novel algorithm, QaSAL-CPM, which incorporates state-augmentation by embedding the dual variables in the constrained optimization formulation directly into the agent's observation space. This method enables the agent to respond to constraint violations in real time while continuing to optimize a primary performance objective. Through extensive simulations of 5G NR-U and Wi-Fi coexistence scenarios, we show that QaSAL-CPM achieves reliable QoS compliance and improved policy robustness across various transmitter densities compared to previous approaches. The proposed framework offers a scalable and adaptive solution for real-time coexistence optimization in next-generation wireless networks.",
      "authors": [
        "Mohammad Reza Fasihi and Brian L. Mark"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T21:48:27+00:00",
          "link": "https://arxiv.org/abs/2506.22652v1",
          "size": "2842kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T14:56:13+00:00",
          "link": "https://arxiv.org/abs/2506.22652v2",
          "size": "2320kb",
          "version": "v2"
        }
      ],
      "title": "QoS-aware State-Augmented Learnable Algorithm for Wireless Coexistence Parameter Management",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22652",
        "HTML": "https://arxiv.org/html/2506.22652v2",
        "PDF": "https://arxiv.org/pdf/2506.22652"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on wireless network optimization using a novel algorithm and does not involve any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06537",
      "abstract": "Smart data selection is becoming increasingly important in data-driven machine learning. Active learning offers a promising solution by allowing machine learning models to be effectively trained with optimal data including the most informative samples from large datasets. Wildlife data captured by camera traps are excessive in volume, requiring tremendous effort in data labelling and animal detection models training. Therefore, applying active learning to optimise the amount of labelled data would be a great aid in enabling automated wildlife monitoring and conservation. However, existing active learning techniques require that a machine learning model (i.e., an object detector) be fully accessible, limiting the applicability of the techniques. In this paper, we propose a model-agnostic active learning approach for detection of animals captured by camera traps. Our approach integrates uncertainty and diversity quantities of samples at both the object-based and image-based levels into the active learning sample selection process. We validate our approach in a benchmark animal dataset. Experimental results demonstrate that, using only 30% of the training data selected by our approach, a state-of-the-art animal detector can achieve a performance of equal or greater than that with the use of the complete training dataset.",
      "authors": [
        "Thi Thu Thuy Nguyen and Duc Thanh Nguyen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T04:36:59+00:00",
          "link": "https://arxiv.org/abs/2507.06537v1",
          "size": "2068kb",
          "version": "v1"
        }
      ],
      "title": "A model-agnostic active learning approach for animal detection from camera traps",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06537",
        "HTML": "https://arxiv.org/html/2507.06537v1",
        "PDF": "https://arxiv.org/pdf/2507.06537"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses a model-agnostic active learning approach for selecting optimal training data in animal detection tasks, which is a form of data processing, but does not focus on LLM training data specifically."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06558",
      "abstract": "Low-Rank Adaptation (LoRA) offers a parameter-efficient paradigm for tuning large models. While recent spectral initialization methods improve convergence and performance over the naive \"Noise & Zeros\" scheme, their extra computational and storage overhead undermines efficiency. In this paper, we establish update magnitude as the fundamental driver of LoRA performance and propose LoRAM, a magnitude-driven \"Basis & Basis\" initialization scheme that matches spectral methods without their inefficiencies. Our key contributions are threefold: (i) Magnitude of weight updates determines convergence. We prove low-rank structures intrinsically bound update magnitudes, unifying hyperparameter tuning in learning rate, scaling factor, and initialization as mechanisms to optimize magnitude regulation. (ii) Spectral initialization succeeds via magnitude amplification. We demystify that the presumed knowledge-driven benefit of the spectral component essentially arises from the boost in the weight update magnitude. (iii) A novel and compact initialization strategy, LoRAM, scales deterministic orthogonal bases using pretrained weight magnitudes to simulate spectral gains. Extensive experiments show that LoRAM serves as a strong baseline, retaining the full efficiency of LoRA while matching or outperforming spectral initialization across benchmarks.",
      "authors": [
        "Zicheng Zhang",
        "Haoran Li",
        "Yifeng Zhang",
        "Guoqiang Gong",
        "Jiaxing Wang",
        "Pengzhang Liu",
        "Qixia Jiang",
        "Junxing Hu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T05:25:24+00:00",
          "link": "https://arxiv.org/abs/2507.06558v1",
          "size": "3113kb",
          "version": "v1"
        }
      ],
      "title": "The Primacy of Magnitude in Low-Rank Adaptation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06558",
        "HTML": "https://arxiv.org/html/2507.06558v1",
        "PDF": "https://arxiv.org/pdf/2507.06558"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses parameter-efficient tuning for large models, specifically LoRA, without involving any LLM training data processing or new data creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06717",
      "abstract": "Real-time unmanned aerial vehicle (UAV) video streaming is essential for time-sensitive applications, including remote surveillance, emergency response, and environmental monitoring. However, it faces challenges such as limited bandwidth, latency fluctuations, and high packet loss. To address these issues, we propose a novel semantic self-correcting video transmission framework with ultra-fine bitrate granularity (SSCV-G). In SSCV-G, video frames are encoded into a compact semantic codebook space, and the transmitter adaptively sends a subset of semantic indices based on bandwidth availability, enabling fine-grained bitrate control for improved bandwidth efficiency. At the receiver, a spatio-temporal vision transformer (ST-ViT) performs multi-frame joint decoding to reconstruct dropped semantic indices by modeling intra- and inter-frame dependencies. To further improve performance under dynamic network conditions, we integrate a multi-user proximal policy optimization (MUPPO) reinforcement learning scheme that jointly optimizes communication resource allocation and semantic bitrate selection to maximize user Quality of Experience (QoE). Extensive experiments demonstrate that the proposed SSCV-G significantly outperforms state-of-the-art video codecs in coding efficiency, bandwidth adaptability, and packet loss robustness. Moreover, the proposed MUPPO-based QoE optimization consistently surpasses existing benchmarks.",
      "authors": [
        "Xuyang Chen",
        "Chong Huang",
        "Daquan Feng",
        "Lei Luo",
        "Yao Sun",
        "Xiang-Gen Xia"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T10:15:46+00:00",
          "link": "https://arxiv.org/abs/2507.06717v1",
          "size": "9437kb",
          "version": "v1"
        }
      ],
      "title": "QoE Optimization for Semantic Self-Correcting Video Transmission in Multi-UAV Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06717",
        "HTML": "https://arxiv.org/html/2507.06717v1",
        "PDF": "https://arxiv.org/pdf/2507.06717"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a semantic video transmission framework for UAVs and does not focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06479",
      "abstract": "Reconstructing ocean dynamics from observational data is fundamentally limited by the sparse, irregular, and Lagrangian nature of spatial sampling, particularly in subsurface and remote regions. This sparsity poses significant challenges for forecasting key phenomena such as eddy shedding and rogue waves. Traditional data assimilation methods and deep learning models often struggle to recover mesoscale turbulence under such constraints. We leverage a deep learning framework that combines neural operators with denoising diffusion probabilistic models (DDPMs) to reconstruct high-resolution ocean states from extremely sparse Lagrangian observations. By conditioning the generative model on neural operator outputs, the framework accurately captures small-scale, high-wavenumber dynamics even at $99\\%$ sparsity (for synthetic data) and $99.9\\%$ sparsity (for real satellite observations). We validate our method on benchmark systems, synthetic float observations, and real satellite data, demonstrating robust performance under severe spatial sampling limitations as compared to other deep learning baselines.",
      "authors": [
        "Niloofar Asefi",
        "Leonard Lupin-Jimenez",
        "Tianning Wu",
        "Ruoying He",
        "and Ashesh Chattopadhyay"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Atmospheric and Oceanic Physics (physics.ao-ph)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Dynamical Systems (math.DS)",
        "Chaotic Dynamics (nlin.CD)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T01:56:25+00:00",
          "link": "https://arxiv.org/abs/2507.06479v1",
          "size": "14502kb",
          "version": "v1"
        }
      ],
      "title": "Generative Lagrangian data assimilation for ocean dynamics under extreme sparsity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06479",
        "HTML": "https://arxiv.org/html/2507.06479v1",
        "PDF": "https://arxiv.org/pdf/2507.06479"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on reconstructing ocean dynamics using deep learning and generative models but does not contribute to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06562",
      "abstract": "In recent years, advancements in hardware have enabled quadruped robots to operate with high power and speed, while robust locomotion control using reinforcement learning (RL) has also been realized. As a result, expectations are rising for the automation of tasks such as material transport and exploration in unknown environments. However, autonomous locomotion in rough terrains with significant height variations requires vertical movement, and robots capable of performing such movements stably, along with their control methods, have not yet been fully established. In this study, we developed the quadruped robot KLEIYN, which features a waist joint, and aimed to expand quadruped locomotion by enabling chimney climbing through RL. To facilitate the learning of vertical motion, we introduced Contact-Guided Curriculum Learning (CGCL). As a result, KLEIYN successfully climbed walls ranging from 800 mm to 1000 mm in width at an average speed of 150 mm/s, 50 times faster than conventional robots. Furthermore, we demonstrated that the introduction of a waist joint improves climbing performance, particularly enhancing tracking ability on narrow walls.",
      "authors": [
        "Keita Yoneda",
        "Kento Kawaharazuka",
        "Temma Suzuki",
        "Takahiro Hattori",
        "Kei Okada"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T05:30:53+00:00",
          "link": "https://arxiv.org/abs/2507.06562v1",
          "size": "5012kb",
          "version": "v1"
        }
      ],
      "title": "KLEIYN : A Quadruped Robot with an Active Waist for Both Locomotion and Wall Climbing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06562",
        "HTML": "https://arxiv.org/html/2507.06562v1",
        "PDF": "https://arxiv.org/pdf/2507.06562"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on quadruped robot locomotion using RL, introducing a hardware-based innovation for climbing. It does not cover LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07003",
      "abstract": "In this paper, we address the classical Dantzig-Fulkerson-Johnson formulation of the metric Traveling Salesman Problem and study the integrality gap of its linear relaxation, namely the Subtour Elimination Problem (SEP). This integrality gap is conjectured to be $4/3$. We prove that, when solving a problem on $n$ nodes, if the optimal SEP solution has at most $n+6$ non-zero components, then the conjecture is true. To establish this result, we consider, for a given integer $k$, the infinite family $F_k$ which gathers, among all the vertices of all the SEP polytopes for $n \\in \\mathbb{N}$, the ones with exactly $n+k$ non-zero components. Then, we introduce a procedure that reduces the description of $F_k$ to a finite set, and we present the Gap-Bounding algorithm, which provides provable upper bounds on the integrality gap for entire families $F_k$. The application of the Gap-Bounding algorithm for $k \\leq 6$ yields a computer-aided proof that the conjectured bound holds in this case.",
      "authors": [
        "Tullio Villa",
        "Eleonora Vercesi",
        "Janos Barta",
        "Monaldo Mastrolilli"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Discrete Mathematics (cs.DM)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T16:33:24+00:00",
          "link": "https://arxiv.org/abs/2507.07003v1",
          "size": "48kb",
          "version": "v1"
        }
      ],
      "title": "The Integrality Gap of the Traveling Salesman Problem is $4/3$ if the LP Solution Has at Most $n+6$ Non-zero Components",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07003",
        "HTML": "https://arxiv.org/html/2507.07003v1",
        "PDF": "https://arxiv.org/pdf/2507.07003"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses the integrality gap in the Traveling Salesman Problem and does not involve any processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07065",
      "abstract": "Defining suitable quantum extensions of classical divergences often poses a challenge due to the non-commutative nature of quantum information. In this work, we propose a new approach via what we call the layer cake representation. The resulting quantum R\\'enyi and $f$-divergences are then proven to be equivalent to those recently defined via integral representations. Nevertheless, the approach can provide several insights. We give an alternative proof of the integral representation of the relative entropy by Frenkel and prove a conjecture regarding a trace expression for the R\\'enyi divergence. Additionally, we give applications to error exponents in hypothesis testing, a new Riemann-Stieltjes type integral representation and a variational representation.",
      "authors": [
        "Po-Chieh Liu",
        "Christoph Hirche",
        "Hao-Chung Cheng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T17:27:34+00:00",
          "link": "https://arxiv.org/abs/2507.07065v1",
          "size": "527kb",
          "version": "v1"
        }
      ],
      "title": "Layer Cake Representations for Quantum Divergences",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07065",
        "PDF": "https://arxiv.org/pdf/2507.07065"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a new mathematical representation for quantum divergences and does not involve any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2307.05102",
      "abstract": "In this paper, we give an algorithm for finding general rational solutions of a given first-order ODE with parametric coefficients that occur rationally. We present an analysis, complete modulo Hilbert's irreducibility problem, of the existence of rational solutions of the differential equation, with parametric coefficients, when the parameters are specialized.",
      "authors": [
        "Sebastian Falkensteiner and Rafael Sendra"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Symbolic Computation (cs.SC)"
      ],
      "submission_historys": [
        {
          "date": "2023-07-11T08:24:25+00:00",
          "link": "https://arxiv.org/abs/2307.05102v1",
          "size": "19kb",
          "version": "v1"
        },
        {
          "date": "2025-07-04T16:52:47+00:00",
          "link": "https://arxiv.org/abs/2307.05102v2",
          "size": "19kb",
          "version": "v2"
        },
        {
          "date": "2025-07-08T18:06:09+00:00",
          "link": "https://arxiv.org/abs/2307.05102v3",
          "size": "19kb",
          "version": "v3"
        }
      ],
      "title": "Rational Solutions of Parametric First-Order Algebraic Differential Equations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2307.05102",
        "HTML": "https://arxiv.org/html/2307.05102v3",
        "PDF": "https://arxiv.org/pdf/2307.05102"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work provides an algorithm for solving differential equations and does not discuss data processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2402.12831",
      "abstract": "We develop a sparse hierarchical $hp$-finite element method ($hp$-FEM) for the Helmholtz equation with variable coefficients posed on a two-dimensional disk or annulus. The mesh is an inner disk cell (omitted if on an annulus domain) and concentric annuli cells. The discretization preserves the Fourier mode decoupling of rotationally invariant operators, such as the Laplacian, which manifests as block diagonal mass and stiffness matrices. Moreover, the matrices have a sparsity pattern independent of the order of the discretization and admit an optimal complexity factorization. The sparse $hp$-FEM can handle radial discontinuities in the right-hand side and in rotationally invariant Helmholtz coefficients. Rotationally anisotropic coefficients that are approximated by low-degree polynomials in Cartesian coordinates also result in sparse linear systems. We consider examples such as a high-frequency Helmholtz equation with radial discontinuities and rotationally anisotropic coefficients, singular source terms, the time-dependent Schr\\\"odinger equation, and an extension to a three-dimensional cylinder domain, with a quasi-optimal solve, via the Alternating Direction Implicit (ADI) algorithm.",
      "authors": [
        "Ioannis P. A. Papadopoulos and Sheehan Olver"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-20T08:58:10+00:00",
          "link": "https://arxiv.org/abs/2402.12831v1",
          "size": "21778kb",
          "version": "v1"
        },
        {
          "date": "2025-05-06T13:19:19+00:00",
          "link": "https://arxiv.org/abs/2402.12831v2",
          "size": "27756kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T09:54:05+00:00",
          "link": "https://arxiv.org/abs/2402.12831v3",
          "size": "27742kb",
          "version": "v3"
        }
      ],
      "title": "A sparse hierarchical $hp$-finite element method on disks and annuli",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.12831",
        "HTML": "https://arxiv.org/html/2402.12831v3",
        "PDF": "https://arxiv.org/pdf/2402.12831"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a finite element method for solving Helmholtz equations on specific domains. It makes no mention of LLM training data processing or dataset creation."
      },
      "repo_urls": [
        "https://github.com/ioannispapapadopoulos/sparsediskfem.jl"
      ],
      "source": "arXiv"
    },
    {
      "id": "2404.18394",
      "abstract": "Monitoring space objects is crucial for space situational awareness, yet reconstructing 3D satellite models from ground-based telescope images is challenging due to atmospheric turbulence, long observation distances, limited viewpoints, and low signal-to-noise ratios. In this paper, we propose a novel computational imaging framework that overcomes these obstacles by integrating a hybrid image pre-processing pipeline with a joint pose estimation and 3D reconstruction module based on controlled Gaussian Splatting (GS) and Branch-and-Bound (BnB) search. We validate our approach on both synthetic satellite datasets and on-sky observations of China's Tiangong Space Station and the International Space Station, achieving robust 3D reconstructions of low-Earth orbit satellites from ground-based data. Quantitative evaluations using SSIM, PSNR, LPIPS, and Chamfer Distance demonstrate that our method outperforms state-of-the-art NeRF-based approaches, and ablation studies confirm the critical role of each component. Our framework enables high-fidelity 3D satellite monitoring from Earth, offering a cost-effective alternative for space situational awareness. Project page: https://ai4scientificimaging.org/ReconstructingSatellites",
      "authors": [
        "Zhiming Chang",
        "Boyang Liu",
        "Yifei Xia",
        "Youming Guo",
        "Boxin Shi and He Sun"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-29T03:13:09+00:00",
          "link": "https://arxiv.org/abs/2404.18394v1",
          "size": "14932kb",
          "version": "v1"
        },
        {
          "date": "2024-11-25T08:47:46+00:00",
          "link": "https://arxiv.org/abs/2404.18394v2",
          "size": "6943kb",
          "version": "v2"
        },
        {
          "date": "2025-04-13T09:08:58+00:00",
          "link": "https://arxiv.org/abs/2404.18394v3",
          "size": "10891kb",
          "version": "v3"
        },
        {
          "date": "2025-07-09T06:16:17+00:00",
          "link": "https://arxiv.org/abs/2404.18394v4",
          "size": "15801kb",
          "version": "v4"
        }
      ],
      "title": "Reconstructing Satellites in 3D from Amateur Telescope Images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.18394",
        "HTML": "https://arxiv.org/html/2404.18394v4",
        "PDF": "https://arxiv.org/pdf/2404.18394"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a framework for 3D satellite reconstruction using telescope images, but does not involve any LLM training data processing or dataset creation."
      },
      "tasks": [
        "3D Reconstruction",
        "Image Restoration",
        "Pose Estimation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.11369",
      "abstract": "Over the past few years, the European Commission has made significant steps to reduce disinformation in cyberspace. One of those steps has been the introduction of the 2022 \"Strengthened Code of Practice on Disinformation\". Signed by leading online platforms, this Strengthened Code of Practice on Disinformation is an attempt to combat disinformation on the Web. The Code of Practice includes a variety of measures including the demonetization of disinformation, urging, for example, advertisers \"to avoid the placement of advertising next to Disinformation content\".\n  In this work, we set out to explore what was the impact of the Code of Practice and especially to explore to what extent ad networks continue to advertise on dis-/mis-information sites. We perform a historical analysis and find that, although at a hasty glance things may seem to be improving, there is really no significant reduction in the amount of advertising relationships among popular misinformation websites and major ad networks. In fact, we show that ad networks have withdrawn mostly from unpopular misinformation websites with very few visitors, but still form relationships with highly unreliable websites that account for the majority of misinformation traffic. To make matters worse, we show that ad networks continue to place advertisements of legitimate companies next to misinformation content. We show that major ad networks place ads in almost 400 misinformation websites in our dataset.",
      "authors": [
        "Emmanouil Papadogiannakis",
        "Panagiotis Papadopoulos",
        "Nicolas Kourtellis",
        "Evangelos P. Markatos"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-15T07:48:43+00:00",
          "link": "https://arxiv.org/abs/2410.11369v1",
          "size": "323kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T09:29:19+00:00",
          "link": "https://arxiv.org/abs/2410.11369v2",
          "size": "328kb",
          "version": "v2"
        }
      ],
      "title": "Before & After: The Effect of EU's 2022 Code of Practice on Disinformation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.11369",
        "HTML": "https://arxiv.org/html/2410.11369v2",
        "PDF": "https://arxiv.org/pdf/2410.11369"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper analyzes the impact of the EU's Code of Practice on Disinformation and its effect on ad networks, without discussing any processing aspects of LLM training data."
      },
      "repo_urls": [
        "https://gitlab.com/papamano/before-after-data"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.14608",
      "abstract": "End-to-end learning approaches offer great potential for robotic manipulation, but their impact is constrained by data scarcity and heterogeneity across different embodiments. In particular, diverse action spaces across different end-effectors create barriers for cross-embodiment learning and skill transfer. We address this challenge through diffusion policies learned in a latent action space that unifies diverse end-effector actions. We first show that we can learn a semantically aligned latent action space for anthropomorphic robotic hands, a human hand, and a parallel jaw gripper using encoders trained with a contrastive loss. Second, we show that by using our proposed latent action space for co-training on manipulation data from different end-effectors, we can utilize a single policy for multi-robot control and obtain up to 25% improved manipulation success rates, indicating successful skill transfer despite a significant embodiment gap. Our approach using latent cross-embodiment policies presents a new method to unify different action spaces across embodiments, enabling efficient multi-robot control and data sharing across robot setups. This unified representation significantly reduces the need for extensive data collection for each new robot morphology, accelerates generalization across embodiments, and ultimately facilitates more scalable and efficient robotic learning.",
      "authors": [
        "Erik Bauer",
        "Elvis Nava",
        "Robert K. Katzschmann"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-17T15:08:44+00:00",
          "link": "https://arxiv.org/abs/2506.14608v1",
          "size": "10010kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T09:47:28+00:00",
          "link": "https://arxiv.org/abs/2506.14608v2",
          "size": "18236kb",
          "version": "v2"
        }
      ],
      "title": "Latent Action Diffusion for Cross-Embodiment Manipulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.14608",
        "HTML": "https://arxiv.org/html/2506.14608v2",
        "PDF": "https://arxiv.org/pdf/2506.14608"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about cross-embodiment manipulation in robotics and the use of diffusion policies in action space. It does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06410",
      "abstract": "Breast density assessment is a crucial component of mammographic interpretation, with high breast density (BI-RADS categories C and D) representing both a significant risk factor for developing breast cancer and a technical challenge for tumor detection. This study proposes an automated deep learning system for robust binary classification of breast density (low: A/B vs. high: C/D) using the VinDr-Mammo dataset. We implemented and compared four advanced convolutional neural networks: ResNet18, ResNet50, EfficientNet-B0, and DenseNet121, each enhanced with channel attention mechanisms. To address the inherent class imbalance, we developed a novel Combined Focal Label Smoothing Loss function that integrates focal loss, label smoothing, and class-balanced weighting. Our preprocessing pipeline incorporated advanced techniques, including contrast-limited adaptive histogram equalization (CLAHE) and comprehensive data augmentation. The individual models were combined through an optimized ensemble voting approach, achieving superior performance (AUC: 0.963, F1-score: 0.952) compared to any single model. This system demonstrates significant potential to standardize density assessments in clinical practice, potentially improving screening efficiency and early cancer detection rates while reducing inter-observer variability among radiologists.",
      "authors": [
        "Peyman Sharifian",
        "Xiaotong Hong",
        "Alireza Karimian",
        "Mehdi Amini",
        "and Hossein Arabi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T21:26:33+00:00",
          "link": "https://arxiv.org/abs/2507.06410v1",
          "size": "200kb",
          "version": "v1"
        }
      ],
      "title": "Attention-Enhanced Deep Learning Ensemble for Breast Density Classification in Mammography",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06410",
        "PDF": "https://arxiv.org/pdf/2507.06410"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper discusses preprocessing and augmentation in the context of breast density classification data, it is mainly focused on deep learning methods and not LLM-specific data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06510",
      "abstract": "Open vocabulary Human-Object Interaction (HOI) detection is a challenging task that detects all <human, verb, object> triplets of interest in an image, even those that are not pre-defined in the training set. Existing approaches typically rely on output features generated by large Vision-Language Models (VLMs) to enhance the generalization ability of interaction representations. However, the visual features produced by VLMs are holistic and coarse-grained, which contradicts the nature of detection tasks. To address this issue, we propose a novel Bilateral Collaboration framework for open vocabulary HOI detection (BC-HOI). This framework includes an Attention Bias Guidance (ABG) component, which guides the VLM to produce fine-grained instance-level interaction features according to the attention bias provided by the HOI detector. It also includes a Large Language Model (LLM)-based Supervision Guidance (LSG) component, which provides fine-grained token-level supervision for the HOI detector by the LLM component of the VLM. LSG enhances the ability of ABG to generate high-quality attention bias. We conduct extensive experiments on two popular benchmarks: HICO-DET and V-COCO, consistently achieving superior performance in the open vocabulary and closed settings. The code will be released in Github.",
      "authors": [
        "Yupeng Hu",
        "Changxing Ding",
        "Chang Sun",
        "Shaoli Huang",
        "Xiangmin Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T03:16:39+00:00",
          "link": "https://arxiv.org/abs/2507.06510v1",
          "size": "4152kb",
          "version": "v1"
        }
      ],
      "title": "Bilateral Collaboration with Large Vision-Language Models for Open Vocabulary Human-Object Interaction Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06510",
        "HTML": "https://arxiv.org/html/2507.06510v1",
        "PDF": "https://arxiv.org/pdf/2507.06510"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving Human-Object Interaction detection using collaboration between visual and language models, not on processing or creating LLM training datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06574",
      "abstract": "Our Robust, Explainable Autonomy for Scientific Icy Moon Operations (REASIMO) effort contributes to NASA's Concepts for Ocean worlds Life Detection Technology (COLDTech) program, which explores science platform technologies for ocean worlds such as Europa and Enceladus. Ocean world missions pose significant operational challenges. These include long communication lags, limited power, and lifetime limitations caused by radiation damage and hostile conditions. Given these operational limitations, onboard autonomy will be vital for future Ocean world missions. Besides the management of nominal lander operations, onboard autonomy must react appropriately in the event of anomalies. Traditional spacecraft rely on a transition into 'safe-mode' in which non-essential components and subsystems are powered off to preserve safety and maintain communication with Earth. For a severely time-limited Ocean world mission, resolutions to these anomalies that can be executed without Earth-in-the-loop communication and associated delays are paramount for completion of the mission objectives and science goals. To address these challenges, the REASIMO effort aims to demonstrate a robust level of AI-assisted autonomy for such missions, including the ability to detect and recover from anomalies, and to perform missions based on pre-trained behaviors rather than hard-coded, predetermined logic like all prior space missions. We developed an AI-assisted, personality-driven, intelligent framework for control of an Ocean world mission by combining a mix of advanced technologies. To demonstrate the capabilities of the framework, we perform tests of autonomous sampling operations on a lander-manipulator testbed at the NASA Jet Propulsion Laboratory, approximating possible surface conditions such a mission might encounter.",
      "authors": [
        "Thomas Touma",
        "Ersin Da\\c{s}",
        "Erica Tevere",
        "Martin Feather",
        "Ksenia Kolcio",
        "Maurice Prather",
        "Alberto Candela",
        "Ashish Goel",
        "Erik Kramer",
        "Hari Nayar",
        "Lorraine Fesq",
        "Joel W. Burdick"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T06:05:52+00:00",
          "link": "https://arxiv.org/abs/2507.06574v1",
          "size": "9902kb",
          "version": "v1"
        }
      ],
      "title": "AI Space Cortex: An Experimental System for Future Era Space Exploration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06574",
        "HTML": "https://arxiv.org/html/2507.06574v1",
        "PDF": "https://arxiv.org/pdf/2507.06574"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper describes AI autonomy systems for space missions and does not involve any processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06790",
      "abstract": "Esports athletes often reduce visual quality to improve latency and frame rate, and increase their in-game performance. Little research has examined the effects of this visuo-spatial tradeoff on performance, but we could find no work studying how players manage this tradeoff in practice. This paper is an initial examination of this question in the game Dota 2. First, we gather the game configuration data of Dota 2 players in a small survey. We learn that players do limit visual detail, particularly by turning off VSYNC, which removes rendering/display synchronization delay but permits visual \"tearing\". Second, we survey the intent of those same players with a few subjective questions. Player intent matches configuration practice. While our sampling of Dota 2 players may not be representative, our survey does reveal suggestive trends that lay the groundwork for future, more rigorous and larger surveys. Such surveys can help new players adapt to the game more quickly, encourage researchers to investigate the relative importance of temporal and visual detail, and justify design effort by developers in \"low visual\" game configurations.",
      "authors": [
        "Arjun Madhusudan",
        "Benjamin Watson"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T12:28:05+00:00",
          "link": "https://arxiv.org/abs/2507.06790v1",
          "size": "3540kb",
          "version": "v1"
        }
      ],
      "title": "Better frame rates or better visuals? An early report of Esports player practice in Dota 2",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06790",
        "HTML": "https://arxiv.org/html/2507.06790v1",
        "PDF": "https://arxiv.org/pdf/2507.06790"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper examines Esports players' configuration practices in Dota 2 and does not address LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06888",
      "abstract": "Federated causal discovery aims to uncover the causal relationships between entities while protecting data privacy, which has significant importance and numerous applications in real-world scenarios. Existing federated causal structure learning methods primarily focus on horizontal federated settings. However, in practical situations, different clients may not necessarily contain data on the same variables. In a single client, the incomplete set of variables can easily lead to spurious causal relationships, thereby affecting the information transmitted to other clients. To address this issue, we comprehensively consider causal structure learning methods under both horizontal and vertical federated settings. We provide the identification theories and methods for learning causal structure in the horizontal and vertical federal setting via higher-order cumulants. Specifically, we first aggregate higher-order cumulant information from all participating clients to construct global cumulant estimates. These global estimates are then used for recursive source identification, ultimately yielding a global causal strength matrix. Our approach not only enables the reconstruction of causal graphs but also facilitates the estimation of causal strength coefficients. Our algorithm demonstrates superior performance in experiments conducted on both synthetic data and real-world data.",
      "authors": [
        "Wei Chen",
        "Wanyang Gu",
        "Linjun Peng",
        "Ruichu Cai",
        "Zhifeng Hao",
        "Kun Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T14:25:51+00:00",
          "link": "https://arxiv.org/abs/2507.06888v1",
          "size": "1120kb",
          "version": "v1"
        }
      ],
      "title": "Horizontal and Vertical Federated Causal Structure Learning via Higher-order Cumulants",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06888",
        "HTML": "https://arxiv.org/html/2507.06888v1",
        "PDF": "https://arxiv.org/pdf/2507.06888"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is concerned with federated causal structure learning and data privacy, not involving any LLM training data processing or dataset engineering relevant to the task."
      },
      "source": "arXiv"
    },
    {
      "id": "2202.04802",
      "abstract": "Further electrification of the economy is expected to sharpen ramp rates and increase peak loads. Flexibility from the demand side, which new technologies might facilitate, can help these operational challenges. Electric utilities have begun implementing new tariffs and other mechanisms to encourage the deployment of energy storage. This paper examines whether making these new tariffs technology agnostic and extending them to flexible demand would significantly improve the procurement of operational flexibility. In particular, we consider how a commercial consumer might adjust its flexible demand when subject to Pacific Gas and Electric Company's storage-centric electric tariff. We show that extending this tariff to consumers with flexible demand would reduce the utility's net demand ramp rates during peak hours. If consumers have a high level of demand flexibility, this tariff also reduces the net demand during peak hours and decreases total electric bills when compared to the base tariff.",
      "authors": [
        "Lane D. Smith",
        "Daniel S. Kirschen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2022-02-10T02:31:10+00:00",
          "link": "https://arxiv.org/abs/2202.04802v1",
          "size": "349kb",
          "version": "v1"
        }
      ],
      "title": "Should Storage-Centric Tariffs be Extended to Commercial Flexible Demand?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2202.04802",
        "PDF": "https://arxiv.org/pdf/2202.04802"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses electric tariffs and demand flexibility in utilities, which is unrelated to LLMs or their training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2501.13603",
      "abstract": "Verifying graph algorithms has long been considered challenging in separation logic, mainly due to structural sharing between graph subcomponents. We show that these challenges can be effectively addressed by representing graphs as a partial commutative monoid (PCM), and by leveraging structure-preserving functions (PCM morphisms), including higher-order combinators.\n  PCM morphisms are important because they generalize separation logic's principle of local reasoning. While traditional framing isolates relevant portions of the heap only at the top level of a specification, morphisms enable contextual localization: they distribute over monoid operations to isolate relevant subgraphs, even when nested deeply within a specification.\n  We demonstrate the morphisms' effectiveness with novel and concise verifications of two canonical graph benchmarks: the Schorr-Waite graph marking algorithm and the union-find data structure.",
      "authors": [
        "Marcos Grandury",
        "Aleksandar Nanevski",
        "Alexander Gryzlov"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-23T12:11:57+00:00",
          "link": "https://arxiv.org/abs/2501.13603v1",
          "size": "469kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T13:04:15+00:00",
          "link": "https://arxiv.org/abs/2501.13603v2",
          "size": "412kb",
          "version": "v2"
        }
      ],
      "title": "Verifying Graph Algorithms in Separation Logic: A Case for an Algebraic Approach (Extended Version)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.13603",
        "HTML": "https://arxiv.org/html/2501.13603v2",
        "PDF": "https://arxiv.org/pdf/2501.13603"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on verifying graph algorithms using separation logic, specifically through PCM morphisms, without any focus on LLM training data processing or related data operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23463",
      "abstract": "Large language models (LLMs) for table-based reasoning often struggle with large tables due to input length limits. We propose ATF (Adaptive Table Filtering Framework), a modular and question-aware filtering pipeline that prunes uninformative columns and rows using LLM-generated column descriptions, clustering, and sparse-dense alignment scores. ATF integrates seamlessly with existing models (e.g., TAPAS, TAPEX) without retraining. Experiments show that ATF reduces table cells by 70%, boosting performance on out-of-domain TableQA tasks while causing slight performance drops on Table Fact Verification, where full-table context is more critical. These results highlight ATF's ability to adaptively balance informativeness and minimalism across tasks.",
      "authors": [
        "WonJune Jang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T02:03:23+00:00",
          "link": "https://arxiv.org/abs/2506.23463v1",
          "size": "2071kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T15:10:56+00:00",
          "link": "https://arxiv.org/abs/2506.23463v2",
          "size": "2071kb",
          "version": "v2"
        }
      ],
      "title": "What to Keep and What to Drop: Adaptive Table Filtering Framework",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23463",
        "HTML": "https://arxiv.org/html/2506.23463v2",
        "PDF": "https://arxiv.org/pdf/2506.23463"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces a novel data processing pipeline (ATF) for table data, focusing on filtering uninformative rows and columns to improve LLM performance. This constitutes a primary contribution in LLM data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06486",
      "abstract": "Robust 6D object pose estimation in cluttered or occluded conditions using monocular RGB images remains a challenging task. One reason is that current pose estimation networks struggle to extract discriminative, pose-aware features using 2D feature backbones, especially when the available RGB information is limited due to target occlusion in cluttered scenes. To mitigate this, we propose a novel pose estimation-specific pre-training strategy named Mask6D. Our approach incorporates pose-aware 2D-3D correspondence maps and visible mask maps as additional modal information, which is combined with RGB images for the reconstruction-based model pre-training. Essentially, this 2D-3D correspondence maps a transformed 3D object model to 2D pixels, reflecting the pose information of the target in camera coordinate system. Meanwhile, the integrated visible mask map can effectively guide our model to disregard cluttered background information. In addition, an object-focused pre-training loss function is designed to further facilitate our network to remove the background interference. Finally, we fine-tune our pre-trained pose prior-aware network via conventional pose training strategy to realize the reliable pose prediction. Extensive experiments verify that our method outperforms previous end-to-end pose estimation methods.",
      "authors": [
        "Yuechen Xie",
        "Haobo Jiang",
        "Jin Xie"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T02:06:49+00:00",
          "link": "https://arxiv.org/abs/2507.06486v1",
          "size": "1620kb",
          "version": "v1"
        }
      ],
      "title": "Mask6D: Masked Pose Priors For 6D Object Pose Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06486",
        "HTML": "https://arxiv.org/html/2507.06486v1",
        "PDF": "https://arxiv.org/pdf/2507.06486"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a novel pre-training strategy for pose estimation, not focusing on LLM training data processing or preparation specifically."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06690",
      "abstract": "Multi-task multi-agent reinforcement learning (MT-MARL) has recently gained attention for its potential to enhance MARL's adaptability across multiple tasks. However, it is challenging for existing multi-task learning methods to handle complex problems, as they are unable to handle unrelated tasks and possess limited knowledge transfer capabilities. In this paper, we propose a hierarchical approach that efficiently addresses these challenges. The high-level module utilizes a skill graph, while the low-level module employs a standard MARL algorithm. Our approach offers two contributions. First, we consider the MT-MARL problem in the context of unrelated tasks, expanding the scope of MTRL. Second, the skill graph is used as the upper layer of the standard hierarchical approach, with training independent of the lower layer, effectively handling unrelated tasks and enhancing knowledge transfer capabilities. Extensive experiments are conducted to validate these advantages and demonstrate that the proposed method outperforms the latest hierarchical MAPPO algorithms. Videos and code are available at https://github.com/WindyLab/MT-MARL-SG",
      "authors": [
        "Guobin Zhu",
        "Rui Zhou",
        "Wenkang Ji",
        "Hongyin Zhang",
        "Donglin Wang and Shiyu Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T09:34:41+00:00",
          "link": "https://arxiv.org/abs/2507.06690v1",
          "size": "1578kb",
          "version": "v1"
        }
      ],
      "title": "Multi-Task Multi-Agent Reinforcement Learning via Skill Graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06690",
        "HTML": "https://arxiv.org/html/2507.06690v1",
        "PDF": "https://arxiv.org/pdf/2507.06690"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses multi-task multi-agent reinforcement learning through skill graphs and does not involve processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06769",
      "abstract": "Multichannel audio mixer and limiter designs are conventionally decoupled for content reproduction over loudspeaker arrays due to high computational complexity and run-time costs. We propose a coupled mixer-limiter-envelope design formulated as an efficient linear-constrained quadratic program that minimizes a distortion objective over multichannel gain variables subject to sample mixture constraints. Novel methods for asymmetric constant overlap-add window optimization, objective function approximation, variable and constraint reduction are presented. Experiments demonstrate distortion reduction of the coupled design, and computational trade-offs required for efficient real-time processing.",
      "authors": [
        "Yuancheng Luo",
        "Dmitriy Yamkovoy",
        "Guillermo Garcia"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)",
        "Signal Processing (eess.SP)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T12:00:29+00:00",
          "link": "https://arxiv.org/abs/2507.06769v1",
          "size": "560kb",
          "version": "v1"
        }
      ],
      "title": "Constraint Optimized Multichannel Mixer-limiter Design",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06769",
        "HTML": "https://arxiv.org/html/2507.06769v1",
        "PDF": "https://arxiv.org/pdf/2507.06769"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with audio mixer-limiter design and does not address any aspect of LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06938",
      "abstract": "Multivariate Gaussian processes (GPs) offer a powerful probabilistic framework to represent complex interdependent phenomena. They pose, however, significant computational challenges in high-dimensional settings, which frequently arise in spatial-temporal applications. We present DALIA, a highly scalable framework for performing Bayesian inference tasks on spatio-temporal multivariate GPs, based on the methodology of integrated nested Laplace approximations. Our approach relies on a sparse inverse covariance matrix formulation of the GP, puts forward a GPU-accelerated block-dense approach, and introduces a hierarchical, triple-layer, distributed memory parallel scheme. We showcase weak scaling performance surpassing the state-of-the-art by two orders of magnitude on a model whose parameter space is 8$\\times$ larger and measure strong scaling speedups of three orders of magnitude when running on 496 GH200 superchips on the Alps supercomputer. Applying DALIA to air pollution data from northern Italy over 48 days, we showcase refined spatial resolutions over the aggregated pollutant measurements.",
      "authors": [
        "Lisa Gaedke-Merzh\\\"auser",
        "Vincent Maillou",
        "Fernando Rodriguez Avellaneda",
        "Olaf Schenk",
        "Mathieu Luisier",
        "Paula Moraga",
        "Alexandros Nikolaos Ziogas",
        "H{\\aa}vard Rue"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation (stat.CO)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T15:20:02+00:00",
          "link": "https://arxiv.org/abs/2507.06938v1",
          "size": "21352kb",
          "version": "v1"
        }
      ],
      "title": "Accelerated Spatio-Temporal Bayesian Modeling for Multivariate Gaussian Processes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06938",
        "HTML": "https://arxiv.org/html/2507.06938v1",
        "PDF": "https://arxiv.org/pdf/2507.06938"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on scalable Bayesian modeling for multivariate Gaussian processes in spatio-temporal applications, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.20264",
      "abstract": "Time series classification is usually regarded as a distinct task from tabular data classification due to the importance of temporal information. However, in this paper, by performing permutation tests that disrupt temporal information on the UCR time series classification archive, the most widely used benchmark for time series classification, we identify a significant proportion of datasets where temporal information has little to no impact on classification. Many of these datasets are tabular in nature or rely mainly on tabular features, leading to potentially biased evaluations of time series classifiers focused on temporal information. To address this, we propose UCR Augmented, a benchmark based on the UCR time series classification archive designed to evaluate classifiers' ability to extract and utilize temporal information. Testing classifiers from seven categories on this benchmark revealed notable shifts in performance rankings. Some previously overlooked approaches perform well, while others see their performance decline significantly when temporal information is crucial. UCR Augmented provides a more robust framework for assessing time series classifiers, ensuring fairer evaluations. Our code is available at https://github.com/YunruiZhang/Revisit-Time-Series-Classification-Benchmark.",
      "authors": [
        "Yunrui Zhang",
        "Gustavo Batista",
        "Salil S. Kanhere"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-26T06:13:41+00:00",
          "link": "https://arxiv.org/abs/2503.20264v1",
          "size": "438kb",
          "version": "v1"
        }
      ],
      "title": "Revisit Time Series Classification Benchmark: The Impact of Temporal Information for Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.20264",
        "HTML": "https://arxiv.org/html/2503.20264",
        "PDF": "https://arxiv.org/pdf/2503.20264"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on evaluating time series classifiers by creating a new benchmark but does not contribute to processing or creating LLM training data."
      },
      "tasks": [
        "Classification",
        "Time Series",
        "Time Series Classification"
      ],
      "repo_urls": [
        "https://github.com/yunruizhang/revisit-time-series-classification-benchmark"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.16407",
      "abstract": "This paper addresses the challenging problem of robust path-following for fixed-wing unmanned aerial vehicles (UAVs) in complex environments with bounded external disturbances and non-smooth predefined paths. Due to the unique aerodynamic characteristics and flight constraints of fixed-wing UAVs, achieving accurate and fast stable path following remains difficult, especially in low-altitude mountainous terrains, urban landscapes, and under wind disturbances. Most existing path-following guidance laws often struggle to ensure fast stabilization under unknown bounded disturbances while maintaining sufficient robustness, and there is a lack of research on optimizing robustness for non-smooth paths under flight constraints. This paper addresses these issues by proposing a constraints-based robust path-following controller. Firstly, from the perspective of global random attractor, we innovatively introduce robustness metrics that quantify both the exponential convergence rate and the range of the ultimate attractor set. Secondly, building on these metrics, we develop a robust longitudinal-lateral look-ahead pursuit (RLLP) guidance law for fixed-wing UAVs, specifically considering the flight path angle and track angle under external disturbances. Thirdly, we also derive an optimized version (Optimal-RLLP) to enhance the robustness metrics, and elaborate on the sufficient conditions for fast finite-time stability, ensuring the guidance law achieves finite-time stability and robustness with reduced sensitivity to constrained uncertainties. The simulation results validate the proposed guidance law's feasibility, optimality and robustness under atmospheric disturbances using a high-fidelity simulation platform and provide key principle for practical deployment.",
      "authors": [
        "Zimao Sheng",
        "Hong'an Yang",
        "Shuxiang Yang",
        "Zirui Yu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-22T08:59:39+00:00",
          "link": "https://arxiv.org/abs/2505.16407v1",
          "size": "6147kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T08:56:43+00:00",
          "link": "https://arxiv.org/abs/2505.16407v2",
          "size": "23037kb",
          "version": "v2"
        }
      ],
      "title": "Robust Longitudinal-lateral Look-ahead Pursuit Path-Following Control: Fast Finite-Time Stability Guarantee",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.16407",
        "HTML": "https://arxiv.org/html/2505.16407v2",
        "PDF": "https://arxiv.org/pdf/2505.16407"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with robust path-following control for UAVs, not related to any aspect of LLM training data processing or engineering."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.06456",
      "abstract": "We present a system of efficient methods for traversing and combining associative collection data structures. A distinguishing feature of the system is that, like traditional sequential iterator libraries, it does not require specialized compiler infrastructure or staged compilation for efficiency and composability. By using a representation based on indexed streams, the library can express complex joins over input collections while using no intermediate allocations. We implement the library for the Lean, Morphic, and Rust programming languages and provide a mechanized proof of functional correctness in Lean.",
      "authors": [
        "Scott Kovach",
        "Praneeth Kolichala",
        "Kyle A. Miller",
        "David Broman",
        "Fredrik Kjolstad"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T23:52:45+00:00",
          "link": "https://arxiv.org/abs/2507.06456v1",
          "size": "356kb",
          "version": "v1"
        }
      ],
      "title": "Fast Collection Operations from Indexed Stream Fusion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06456",
        "HTML": "https://arxiv.org/html/2507.06456v1",
        "PDF": "https://arxiv.org/pdf/2507.06456"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents methods for efficient data structure operations but does not involve LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06893",
      "abstract": "AI evaluations have become critical tools for assessing large language model capabilities and safety. This paper presents practical insights from eight months of maintaining $inspect\\_evals$, an open-source repository of 70+ community-contributed AI evaluations. We identify key challenges in implementing and maintaining AI evaluations and develop solutions including: (1) a structured cohort management framework for scaling community contributions, (2) statistical methodologies for optimal resampling and cross-model comparison with uncertainty quantification, and (3) systematic quality control processes for reproducibility. Our analysis reveals that AI evaluation requires specialized infrastructure, statistical rigor, and community coordination beyond traditional software development practices.",
      "authors": [
        "Alexandra Abbas",
        "Celia Waggoner",
        "Justin Olive"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T14:30:45+00:00",
          "link": "https://arxiv.org/abs/2507.06893v1",
          "size": "48kb",
          "version": "v1"
        }
      ],
      "title": "Developing and Maintaining an Open-Source Repository of AI Evaluations: Challenges and Insights",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06893",
        "HTML": "https://arxiv.org/html/2507.06893v1",
        "PDF": "https://arxiv.org/pdf/2507.06893"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper primarily focuses on the challenges and insights of maintaining an open-source repository for AI evaluations, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.14879",
      "abstract": "Passive tracking methods, such as phone and wearable sensing, have become dominant in monitoring human behaviors in modern ubiquitous computing studies. While there have been significant advances in machine-learning approaches to translate periods of raw sensor data to model momentary behaviors, (e.g., physical activity recognition), there still remains a significant gap in the translation of these sensing streams into meaningful, high-level, context-aware insights that are required for various applications (e.g., summarizing an individual's daily routine). To bridge this gap, experts often need to employ a context-driven sensemaking process in real-world studies to derive insights. This process often requires manual effort and can be challenging even for experienced researchers due to the complexity of human behaviors.\n  We conducted three rounds of user studies with 21 experts to explore solutions to address challenges with sensemaking. We follow a human-centered design process to identify needs and design, iterate, build, and evaluate Vital Insight (VI), a novel, LLM-assisted, prototype system to enable human-in-the-loop inference (sensemaking) and visualizations of multi-modal passive sensing data from smartphones and wearables. Using the prototype as a technology probe, we observe experts' interactions with it and develop an expert sensemaking model that explains how experts move between direct data representations and AI-supported inferences to explore, question, and validate insights. Through this iterative process, we also synthesize and discuss a list of design implications for the design of future AI-augmented visualization systems to better assist experts' sensemaking processes in multi-modal health sensing data.",
      "authors": [
        "Jiachen Li",
        "Xiwen Li",
        "Justin Steinberg",
        "Akshat Choube",
        "Bingsheng Yao",
        "Xuhai Xu",
        "Dakuo Wang",
        "Elizabeth Mynatt",
        "Varun Mishra"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-18T21:56:35+00:00",
          "link": "https://arxiv.org/abs/2410.14879v1",
          "size": "30990kb",
          "version": "v1"
        },
        {
          "date": "2025-02-27T22:31:58+00:00",
          "link": "https://arxiv.org/abs/2410.14879v2",
          "size": "11792kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T00:14:20+00:00",
          "link": "https://arxiv.org/abs/2410.14879v3",
          "size": "8856kb",
          "version": "v3"
        }
      ],
      "title": "Vital Insight: Assisting Experts' Context-Driven Sensemaking of Multi-modal Personal Tracking Data Using Visualization and Human-In-The-Loop LLM",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.14879",
        "HTML": "https://arxiv.org/html/2410.14879v3",
        "PDF": "https://arxiv.org/pdf/2410.14879"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper develops a system for sensemaking of personal tracking data with LLM assistance but does not involve processing of LLM training data or dataset creation."
      },
      "tasks": [
        "Activity Recognition",
        "Translation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.10487",
      "abstract": "Tables are a primary medium for conveying critical information in administrative domains, yet their complexity hinders utilization by Large Language Models (LLMs). This paper introduces the Theme-Explanation Structure-based Table Summarization (Tabular-TX) pipeline, a novel approach designed to generate highly interpretable summaries from tabular data, with a specific focus on Korean administrative documents. Current table summarization methods often neglect the crucial aspect of human-friendly output. Tabular-TX addresses this by first employing a multi-step reasoning process to ensure deep table comprehension by LLMs, followed by a journalist persona prompting strategy for clear sentence generation. Crucially, it then structures the output into a Theme Part (an adverbial phrase) and an Explanation Part (a predicative clause), significantly enhancing readability. Our approach leverages in-context learning, obviating the need for extensive fine-tuning and associated labeled data or computational resources. Experimental results show that Tabular-TX effectively processes complex table structures and metadata, offering a robust and efficient solution for generating human-centric table summaries, especially in low-resource scenarios.",
      "authors": [
        "TaeYoon Kwack",
        "Jisoo Kim",
        "Ki Yong Jung",
        "DongGeon Lee",
        "Heesun Park"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-17T08:42:49+00:00",
          "link": "https://arxiv.org/abs/2501.10487v1",
          "size": "1028kb",
          "version": "v1"
        },
        {
          "date": "2025-02-26T07:10:17+00:00",
          "link": "https://arxiv.org/abs/2501.10487v2",
          "size": "449kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T00:21:40+00:00",
          "link": "https://arxiv.org/abs/2501.10487v3",
          "size": "346kb",
          "version": "v3"
        }
      ],
      "title": "Theme-Explanation Structure for Table Summarization using Large Language Models: A Case Study on Korean Tabular Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.10487",
        "HTML": "https://arxiv.org/html/2501.10487v3",
        "PDF": "https://arxiv.org/pdf/2501.10487"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper's focus is on table summarization using LLMs, which involves some data processing for structured tabular data, but it does not primarily address LLM training data processing."
      },
      "tasks": [
        "In-Context Learning",
        "Question Answering",
        "Table-based Question Answering"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.02948",
      "abstract": "Autonomous driving has seen significant progress, driven by extensive real-world data. However, in long-tail scenarios, accurately predicting the safety of the ego vehicle's future motion remains a major challenge due to uncertainties in dynamic environments and limitations in data coverage. In this work, we aim to explore whether it is possible to enhance the motion risk prediction capabilities of Vision-Language Models (VLM) by synthesizing high-risk motion data. Specifically, we introduce a Bird's-Eye View (BEV) based motion simulation method to model risks from three aspects: the ego-vehicle, other vehicles, and the environment. This allows us to synthesize plug-and-play, high-risk motion data suitable for VLM training, which we call DriveMRP-10K. Furthermore, we design a VLM-agnostic motion risk estimation framework, named DriveMRP-Agent. This framework incorporates a novel information injection strategy for global context, ego-vehicle perspective, and trajectory projection, enabling VLMs to effectively reason about the spatial relationships between motion waypoints and the environment. Extensive experiments demonstrate that by fine-tuning with DriveMRP-10K, our DriveMRP-Agent framework can significantly improve the motion risk prediction performance of multiple VLM baselines, with the accident recognition accuracy soaring from 27.13% to 88.03%. Moreover, when tested via zero-shot evaluation on an in-house real-world high-risk motion dataset, DriveMRP-Agent achieves a significant performance leap, boosting the accuracy from base_model's 29.42% to 68.50%, which showcases the strong generalization capabilities of our method in real-world scenarios.",
      "authors": [
        "Zhiyi Hou",
        "Enhui Ma",
        "Fang Li",
        "Zhiyi Lai",
        "Kalok Ho",
        "Zhanqian Wu",
        "Lijun Zhou",
        "Long Chen",
        "Chitian Sun",
        "Haiyang Sun",
        "Bing Wang",
        "Guang Chen",
        "Hangjun Ye",
        "and Kaicheng Yu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T21:28:01+00:00",
          "link": "https://arxiv.org/abs/2507.02948v1",
          "size": "7223kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T06:50:51+00:00",
          "link": "https://arxiv.org/abs/2507.02948v2",
          "size": "7223kb",
          "version": "v2"
        }
      ],
      "title": "DriveMRP: Enhancing Vision-Language Models with Synthetic Motion Data for Motion Risk Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02948",
        "HTML": "https://arxiv.org/html/2507.02948v2",
        "PDF": "https://arxiv.org/pdf/2507.02948"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper introduces DriveMRP-10K, a synthetic dataset generated through a novel motion simulation method for training Vision-Language Models, which makes a direct contribution to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06677",
      "abstract": "Gaussian processes (GPs) are widely used as surrogate models for complicated functions in scientific and engineering applications. In many cases, prior knowledge about the function to be approximated, such as monotonicity, is available and can be leveraged to improve model fidelity. Incorporating such constraints into GP models enhances predictive accuracy and reduces uncertainty, but remains a computationally challenging task for high-dimensional problems. In this work, we present a novel virtual point-based framework for building constrained GP models under monotonicity constraints, based on regularized linear randomize-then-optimize (RLRTO), which enables efficient sampling from a constrained posterior distribution by means of solving randomized optimization problems. We also enhance two existing virtual point-based approaches by replacing Gibbs sampling with the No U-Turn Sampler (NUTS) for improved efficiency. A Python implementation of these methods is provided and can be easily applied to a wide range of problems. This implementation is then used to validate the approaches on approximating a range of synthetic functions, demonstrating comparable predictive performance between all considered methods and significant improvements in computational efficiency with the two NUTS methods and especially with the RLRTO method. The framework is further applied to construct surrogate models for systems of differential equations.",
      "authors": [
        "Chao Zhang",
        "Jasper M. Everink",
        "Jakob Sauer J{\\o}rgensen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Methodology (stat.ME)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T09:09:00+00:00",
          "link": "https://arxiv.org/abs/2507.06677v1",
          "size": "2533kb",
          "version": "v1"
        }
      ],
      "title": "Fast Gaussian Processes under Monotonicity Constraints",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06677",
        "HTML": "https://arxiv.org/html/2507.06677v1",
        "PDF": "https://arxiv.org/pdf/2507.06677"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with Gaussian processes under monotonicity constraints, which is unrelated to LLM training data processing or the creation of datasets for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.00090",
      "abstract": "Allocation of personnel and material resources is highly sensible in the case of firefighter interventions. This allocation relies on simulations to experiment with various scenarios. The main objective of this allocation is the global optimization of the firefighters response. Data generation is then mandatory to study various scenarios In this study, we propose to compare different data generation methods. Methods such as Random Sampling, Tabular Variational Autoencoders, standard Generative Adversarial Networks, Conditional Tabular Generative Adversarial Networks and Diffusion Probabilistic Models are examined to ascertain their efficacy in capturing the intricacies of firefighter interventions. Traditional evaluation metrics often fall short in capturing the nuanced requirements of synthetic datasets for real-world scenarios. To address this gap, an evaluation of synthetic data quality is conducted using a combination of domain-specific metrics tailored to the firefighting domain and standard measures such as the Wasserstein distance. Domain-specific metrics include response time distribution, spatial-temporal distribution of interventions, and accidents representation. These metrics are designed to assess data variability, the preservation of fine and complex correlations and anomalies such as event with a very low occurrence, the conformity with the initial statistical distribution and the operational relevance of the synthetic data. The distribution has the particularity of being highly unbalanced, none of the variables following a Gaussian distribution, adding complexity to the data generation process.",
      "authors": [
        "Michael Corbeau",
        "Emmanuelle Claeys",
        "Mathieu Serrurier",
        "Pascale Zarat\\'e"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T09:43:23+00:00",
          "link": "https://arxiv.org/abs/2507.00090v1",
          "size": "862kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T15:32:12+00:00",
          "link": "https://arxiv.org/abs/2507.00090v2",
          "size": "862kb",
          "version": "v2"
        }
      ],
      "title": "Generating Heterogeneous Multi-dimensional Data : A Comparative Study",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.00090",
        "HTML": "https://arxiv.org/html/2507.00090v2",
        "PDF": "https://arxiv.org/pdf/2507.00090"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper is mainly about generating synthetic data, evaluating its quality through domain-specific metrics, and comparing various data generation methods, indicating a strong focus on data processing techniques applicable to training scenarios."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06236",
      "abstract": "In the digital age, individuals increasingly maintain active presences across multiple platforms ranging from social media and messaging applications to professional and communication tools. However, the current model for managing user level privacy and abuse is siloed, requiring users to block undesirable contacts independently on each platform. This paper introduces Single Block On (SBO) a unified and interoperable system enabling users to block an individual once and have that block propagated across all integrated applications. SBO operates via identity based matching rules, utilizing configurable levels of identifier similarity, and interfaces with systems through standardized protocols such as SSO, LDAP, or direct REST integration. A novel Contact Rule Markup Language (CRML) facilitates consistent policy sharing across systems. The proposed solution increases user safety, enhances digital well-being, and sets a precedent for interoperable privacy enforcement.",
      "authors": [
        "Paritosh Ranjan",
        "Surajit Majumder",
        "Prodip Roy"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-12T11:22:38+00:00",
          "link": "https://arxiv.org/abs/2507.06236v1",
          "size": "428kb",
          "version": "v1"
        }
      ],
      "title": "Single Block On",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06236",
        "HTML": "https://arxiv.org/html/2507.06236v1",
        "PDF": "https://arxiv.org/pdf/2507.06236"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a unified system for blocking users across multiple platforms and does not discuss any aspect of LLM training data collection, processing, or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2408.08333",
      "abstract": "Large Language Models (LLMs) have shown promising potentials in program generation and no-code automation. However, LLMs are prone to generate hallucinations, i.e., they generate text which sounds plausible but is incorrect. Although there has been a recent surge in research on LLM hallucinations for text generation, similar hallucination phenomenon can happen in code generation. Sometimes the generated code can have syntactical or logical errors as well as more advanced issues like security vulnerabilities, memory leaks, etc. Given the wide adaptation of LLMs to enhance efficiency in code generation and development in general, it becomes imperative to investigate hallucinations in code generation. To the best of our knowledge, this is the first attempt at studying hallucinations in the code generated by LLMs. We start by introducing the code hallucination definition and a comprehensive taxonomy of code hallucination types. We propose the first benchmark CodeMirage dataset for code hallucinations. The benchmark contains 1,137 GPT-3.5 generated hallucinated code snippets for Python programming problems from two base datasets - HumanEval and MBPP. We then propose the methodology for code hallucination detection and experiment with open source LLMs such as CodeLLaMA as well as OpenAI's GPT-3.5 and GPT-4 models using one-shot prompt. We find that GPT-4 performs the best on HumanEval dataset and gives comparable results to the fine-tuned CodeBERT baseline on MBPP dataset. Towards the end, we discuss various mitigation strategies for code hallucinations and conclude our work.",
      "authors": [
        "Vibhor Agarwal",
        "Yulong Pei",
        "Salwa Alamir",
        "Xiaomo Liu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-14T22:53:07+00:00",
          "link": "https://arxiv.org/abs/2408.08333v1",
          "size": "85kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T23:14:43+00:00",
          "link": "https://arxiv.org/abs/2408.08333v2",
          "size": "27kb",
          "version": "v2"
        }
      ],
      "title": "CodeMirage: Hallucinations in Code Generated by Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.08333",
        "HTML": "https://arxiv.org/html/2408.08333v2",
        "PDF": "https://arxiv.org/pdf/2408.08333"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper primarily studies hallucinations in code generation. It does introduce a benchmark dataset\u2014CodeMirage for evaluating generated code, which involves some degree of dataset development and processing."
      },
      "tasks": [
        "Code Generation",
        "Hallucination",
        "HumanEval",
        "mbpp",
        "Text Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.19149",
      "abstract": "Visual object counting is a fundamental computer vision task underpinning numerous real-world applications, from cell counting in biomedicine to traffic and wildlife monitoring. However, existing methods struggle to handle the challenge of stacked 3D objects in which most objects are hidden by those above them. To address this important yet underexplored problem, we propose a novel 3D counting approach that decomposes the task into two complementary subproblems - estimating the 3D geometry of the object stack and the occupancy ratio from multi-view images. By combining geometric reconstruction and deep learning-based depth analysis, our method can accurately count identical objects within containers, even when they are irregularly stacked. We validate our 3D Counting pipeline on diverse real-world and large-scale synthetic datasets, which we will release publicly to facilitate further research.",
      "authors": [
        "Corentin Dumery",
        "Noa Ett\\'e",
        "Aoxiang Fan",
        "Ren Li",
        "Jingyi Xu",
        "Hieu Le",
        "Pascal Fua"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-28T13:51:16+00:00",
          "link": "https://arxiv.org/abs/2411.19149v1",
          "size": "15471kb",
          "version": "v1"
        },
        {
          "date": "2025-03-18T10:46:27+00:00",
          "link": "https://arxiv.org/abs/2411.19149v2",
          "size": "29019kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T05:20:04+00:00",
          "link": "https://arxiv.org/abs/2411.19149v3",
          "size": "33522kb",
          "version": "v3"
        }
      ],
      "title": "Counting Stacked Objects",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.19149",
        "HTML": "https://arxiv.org/html/2411.19149v3",
        "PDF": "https://arxiv.org/pdf/2411.19149"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses visual object counting and proposes a 3D counting approach, which does not relate to LLM training data processing or dataset engineering for LLMs."
      },
      "tasks": [
        "3D geometry",
        "Object Counting"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.21692",
      "abstract": "The integration of multi-view imaging and pose estimation represents a significant advance in computer vision applications, offering new possibilities for understanding human movement and interactions. This work presents a new algorithm that improves multi-view multi-person pose estimation, focusing on fast triangulation speeds and good generalization capabilities.\n  The approach extends to whole-body pose estimation, capturing details from facial expressions to finger movements across multiple individuals and viewpoints. Adaptability to different settings is demonstrated through strong performance across unseen datasets and configurations. To support further progress in this field, all of this work is publicly accessible.",
      "authors": [
        "Daniel Bermuth",
        "Alexander Poeppel",
        "Wolfgang Reif"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-27T16:57:33+00:00",
          "link": "https://arxiv.org/abs/2503.21692v1",
          "size": "6595kb",
          "version": "v1"
        },
        {
          "date": "2025-05-26T13:10:42+00:00",
          "link": "https://arxiv.org/abs/2503.21692v2",
          "size": "6596kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T13:14:55+00:00",
          "link": "https://arxiv.org/abs/2503.21692v3",
          "size": "3695kb",
          "version": "v3"
        }
      ],
      "title": "RapidPoseTriangulation: Multi-view Multi-person Whole-body Human Pose Triangulation in a Millisecond",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.21692",
        "HTML": "https://arxiv.org/html/2503.21692v3",
        "PDF": "https://arxiv.org/pdf/2503.21692"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a new algorithm for pose estimation using multi-view imagery but does not involve LLM training data processing."
      },
      "tasks": [
        "3D Multi-Person Pose Estimation",
        "Multi-Person Pose Estimation",
        "Pose Estimation"
      ],
      "repo_urls": [
        "https://gitlab.com/Percipiote/RapidPoseTriangulation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06592",
      "abstract": "This paper proposes an adaptive margin contrastive learning method for 3D semantic segmentation on point clouds. Most existing methods use equally penalized objectives, which ignore the per-point ambiguities and less discriminated features stemming from transition regions. However, as highly ambiguous points may be indistinguishable even for humans, their manually annotated labels are less reliable, and hard constraints over these points would lead to sub-optimal models. To address this, we first design AMContrast3D, a method comprising contrastive learning into an ambiguity estimation framework, tailored to adaptive objectives for individual points based on ambiguity levels. As a result, our method promotes model training, which ensures the correctness of low-ambiguity points while allowing mistakes for high-ambiguity points. As ambiguities are formulated based on position discrepancies across labels, optimization during inference is constrained by the assumption that all unlabeled points are uniformly unambiguous, lacking ambiguity awareness. Inspired by the insight of joint training, we further propose AMContrast3D++ integrating with two branches trained in parallel, where a novel ambiguity prediction module concurrently learns point ambiguities from generated embeddings. To this end, we design a masked refinement mechanism that leverages predicted ambiguities to enable the ambiguous embeddings to be more reliable, thereby boosting segmentation performance and enhancing robustness. Experimental results on 3D indoor scene datasets, S3DIS and ScanNet, demonstrate the effectiveness of the proposed method. Code is available at https://github.com/YangChenApril/AMContrast3D.",
      "authors": [
        "Yang Chen",
        "Yueqi Duan",
        "Haowen Sun",
        "Jiwen Lu",
        "Yap-Peng Tan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T07:00:32+00:00",
          "link": "https://arxiv.org/abs/2507.06592v1",
          "size": "4273kb",
          "version": "v1"
        }
      ],
      "title": "Ambiguity-aware Point Cloud Segmentation by Adaptive Margin Contrastive Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06592",
        "HTML": "https://arxiv.org/html/2507.06592v1",
        "PDF": "https://arxiv.org/pdf/2507.06592"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a method for 3D semantic segmentation on point clouds using adaptive margin contrastive learning, without discussing or involving LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2306.15175",
      "abstract": "Nurmuhammad et al. developed the Sinc-Nystr\\\"{o}m methods for initial value problems in which the solutions exhibit exponential decay end behavior. In these methods, the Single-Exponential (SE) transformation or the Double-Exponential (DE) transformation is combined with the Sinc approximation. Hara and Okayama improved on these transformations to attain a better convergence rate, which was later supported by theoretical error analyses. However, these methods have a computational drawback owing to the inclusion of a special function in the basis functions. To address this issue, Okayama and Hara proposed Sinc-collocation methods, which do not include any special function in the basis functions. This study conducts error analyses of these methods.",
      "authors": [
        "Tomoaki Okayama",
        "Ryota Hara and Shun'ichi Goto"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2023-06-27T03:22:19+00:00",
          "link": "https://arxiv.org/abs/2306.15175v1",
          "size": "14kb",
          "version": "v1"
        },
        {
          "date": "2023-07-06T03:32:32+00:00",
          "link": "https://arxiv.org/abs/2306.15175v2",
          "size": "15kb",
          "version": "v2"
        },
        {
          "date": "2024-01-12T04:40:50+00:00",
          "link": "https://arxiv.org/abs/2306.15175v3",
          "size": "15kb",
          "version": "v3"
        }
      ],
      "title": "Error analyses of Sinc-collocation methods for exponential decay initial value problems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2306.15175",
        "HTML": "https://arxiv.org/html/2306.15175",
        "PDF": "https://arxiv.org/pdf/2306.15175"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with error analyses of mathematical methods for differential equations and does not relate to LLM training data processing or data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2407.05260",
      "abstract": "Channel coding for discrete memoryless channels (DMCs) with mean and variance cost constraints has been recently introduced. We show that there is an improvement in coding performance due to cost variability, both with and without feedback. We demonstrate this improvement over the traditional almost-sure (per-codeword) cost constraint that prohibits any cost variation above a fixed threshold. Our result simultaneously shows that feedback does not improve the second-order coding rate of simple-dispersion DMCs under the almost-sure cost constraint. This finding parallels similar results for unconstrained simple-dispersion DMCs, additive white Gaussian noise (AWGN) channels and parallel Gaussian channels.",
      "authors": [
        "Adeel Mahmood and Aaron B. Wagner"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-07T05:11:18+00:00",
          "link": "https://arxiv.org/abs/2407.05260v1",
          "size": "18kb",
          "version": "v1"
        },
        {
          "date": "2024-09-18T01:20:14+00:00",
          "link": "https://arxiv.org/abs/2407.05260v2",
          "size": "606kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T16:50:56+00:00",
          "link": "https://arxiv.org/abs/2407.05260v3",
          "size": "60kb",
          "version": "v3"
        }
      ],
      "title": "Improved Channel Coding Performance Through Cost Variability",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.05260",
        "HTML": "https://arxiv.org/html/2407.05260v3",
        "PDF": "https://arxiv.org/pdf/2407.05260"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research focuses on channel coding performance related to discrete memoryless channels, which does not relate to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06428",
      "abstract": "We mathematically analyze and numerically study an actor-critic machine learning algorithm for solving high-dimensional Hamilton-Jacobi-Bellman (HJB) partial differential equations from stochastic control theory. The architecture of the critic (the estimator for the value function) is structured so that the boundary condition is always perfectly satisfied (rather than being included in the training loss) and utilizes a biased gradient which reduces computational cost. The actor (the estimator for the optimal control) is trained by minimizing the integral of the Hamiltonian over the domain, where the Hamiltonian is estimated using the critic. We show that the training dynamics of the actor and critic neural networks converge in a Sobolev-type space to a certain infinite-dimensional ordinary differential equation (ODE) as the number of hidden units in the actor and critic $\\rightarrow \\infty$. Further, under a convexity-like assumption on the Hamiltonian, we prove that any fixed point of this limit ODE is a solution of the original stochastic control problem. This provides an important guarantee for the algorithm's performance in light of the fact that finite-width neural networks may only converge to a local minimizers (and not optimal solutions) due to the non-convexity of their loss functions. In our numerical studies, we demonstrate that the algorithm can solve stochastic control problems accurately in up to 200 dimensions. In particular, we construct a series of increasingly complex stochastic control problems with known analytic solutions and study the algorithm's numerical performance on them. These problems range from a linear-quadratic regulator equation to highly challenging equations with non-convex Hamiltonians, allowing us to identify and analyze the strengths and limitations of this neural actor-critic method for solving HJB equations.",
      "authors": [
        "Samuel N. Cohen",
        "Jackson Hebner",
        "Deqing Jiang",
        "Justin Sirignano"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Machine Learning (cs.LG)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T22:20:22+00:00",
          "link": "https://arxiv.org/abs/2507.06428v1",
          "size": "993kb",
          "version": "v1"
        }
      ],
      "title": "Neural Actor-Critic Methods for Hamilton-Jacobi-Bellman PDEs: Asymptotic Analysis and Numerical Studies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06428",
        "HTML": "https://arxiv.org/html/2507.06428v1",
        "PDF": "https://arxiv.org/pdf/2507.06428"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the analysis and study of actor-critic methods for solving Hamilton-Jacobi-Bellman PDEs, with no mention of LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06541",
      "abstract": "In recent years, there has been a growing effort to develop effective and efficient algorithms for fake account detection in online social networks. This survey comprehensively reviews existing methods, with a focus on graph-based techniques that utilise topological features of social graphs (in addition to account information, such as their shared contents and profile data) to distinguish between fake and real accounts. We provide several categorisations of these methods (for example, based on techniques used, input data, and detection time), discuss their strengths and limitations, and explain how these methods connect in the broader context. We also investigate the available datasets, including both real-world data and synthesised models. We conclude the paper by proposing several potential avenues for future research.",
      "authors": [
        "Ali Safarpoor Dehkordi",
        "Ahad N. Zehmakan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T04:52:15+00:00",
          "link": "https://arxiv.org/abs/2507.06541v1",
          "size": "3295kb",
          "version": "v1"
        }
      ],
      "title": "Graph-based Fake Account Detection: A Survey",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06541",
        "HTML": "https://arxiv.org/html/2507.06541v1",
        "PDF": "https://arxiv.org/pdf/2507.06541"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is a survey on fake account detection using graph-based methods and does not pertain to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06702",
      "abstract": "This paper presents a rigorous analytical model of traffic dynamics on a circular track, demonstrating the emergence of standing oscillations resulting from microscopic driver behaviour, delay responses, and proximity pressure. Without relying on simulation, we derive a series of coupled delay differential equations to model vehicular interactions. By introducing a mnemonic-based symbolic system, we establish a mathematical framework incorporating stochastic initial conditions, non-uniform reaction times, and cognitive lag. A full linear stability analysis is conducted using Fourier decomposition and modal perturbation techniques. Our results identify critical thresholds for harmonic induction, delineate the bounds of safe following distances, and reveal hysteresis in driver overcorrection. The analysis concludes with implications for autonomous vehicle control and potential suppression strategies for oscillatory instability. All derivations are purely symbolic and analytically proven.",
      "authors": [
        "Craig S Wright"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Adaptation and Self-Organizing Systems (nlin.AO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)",
        "Dynamical Systems (math.DS)",
        "Optimization and Control (math.OC)",
        "Physics and Society (physics.soc-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T09:55:39+00:00",
          "link": "https://arxiv.org/abs/2507.06702v1",
          "size": "58kb",
          "version": "v1"
        }
      ],
      "title": "Mathematical Modelling of Oscillatory Dynamics in Circular Traffic Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06702",
        "HTML": "https://arxiv.org/html/2507.06702v1",
        "PDF": "https://arxiv.org/pdf/2507.06702"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper provides a mathematical model for traffic dynamics, which is unrelated to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06948",
      "abstract": "Research on the attribute information of calligraphy, such as styles, dynasties, and calligraphers, holds significant cultural and historical value. However, the styles of Chinese calligraphy characters have evolved dramatically through different dynasties and the unique touches of calligraphers, making it highly challenging to accurately recognize these different characters and their attributes. Furthermore, existing calligraphic datasets are extremely scarce, and most provide only character-level annotations without additional attribute information. This limitation has significantly hindered the in-depth study of Chinese calligraphy. To fill this gap, we present a novel Multi-Attribute Chinese Calligraphy Character Dataset (MCCD). The dataset encompasses 7,765 categories with a total of 329,715 isolated image samples of Chinese calligraphy characters, and three additional subsets were extracted based on the attribute labeling of the three types of script styles (10 types), dynasties (15 periods) and calligraphers (142 individuals). The rich multi-attribute annotations render MCCD well-suited diverse research tasks, including calligraphic character recognition, writer identification, and evolutionary studies of Chinese characters. We establish benchmark performance through single-task and multi-task recognition experiments across MCCD and all of its subsets. The experimental results demonstrate that the complexity of the stroke structure of the calligraphic characters, and the interplay between their different attributes, leading to a substantial increase in the difficulty of accurate recognition. MCCD not only fills a void in the availability of detailed calligraphy datasets but also provides valuable resources for advancing research in Chinese calligraphy and fostering advancements in multiple fields. The dataset is available at https://github.com/SCUT-DLVCLab/MCCD.",
      "authors": [
        "Yixin Zhao",
        "Yuyi Zhang and Lianwen Jin"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T15:31:33+00:00",
          "link": "https://arxiv.org/abs/2507.06948v1",
          "size": "1682kb",
          "version": "v1"
        }
      ],
      "title": "MCCD: A Multi-Attribute Chinese Calligraphy Character Dataset Annotated with Script Styles, Dynasties, and Calligraphers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06948",
        "HTML": "https://arxiv.org/html/2507.06948v1",
        "PDF": "https://arxiv.org/pdf/2507.06948"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper presents a new dataset with detailed annotations for Chinese calligraphy characters, focusing on calligraphic recognition and related tasks. While it involves dataset creation, it is not specific to LLM training data or processing for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07000",
      "abstract": "We propose a novel framework that enhances non-rigid 3D model deformations by bridging mesh representations with 3D Gaussian splatting. While traditional Gaussian splatting delivers fast, real-time radiance-field rendering, its post-editing capabilities and support for large-scale, non-rigid deformations remain limited. Our method addresses these challenges by embedding Gaussian kernels directly onto explicit mesh surfaces. This allows the mesh's inherent topological and geometric priors to guide intuitive editing operations -- such as moving, scaling, and rotating individual 3D components -- and enables complex deformations like bending and stretching. This work paves the way for more flexible 3D content-creation workflows in applications spanning virtual reality, character animation, and interactive design.",
      "authors": [
        "Wijayathunga W.M.R.D.B"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T16:26:04+00:00",
          "link": "https://arxiv.org/abs/2507.07000v1",
          "size": "551kb",
          "version": "v1"
        }
      ],
      "title": "Enhancing non-Rigid 3D Model Deformations Using Mesh-based Gaussian Splatting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07000",
        "PDF": "https://arxiv.org/pdf/2507.07000"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses 3D model deformation techniques and does not involve any LLM training data processing or engineering aspects."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.01786",
      "abstract": "Language models can distinguish between testing and deployment phases -- a capability known as evaluation awareness. This has significant safety and policy implications, potentially undermining the reliability of evaluations that are central to AI governance frameworks and voluntary industry commitments. In this paper, we study evaluation awareness in Llama-3.3-70B-Instruct. We show that linear probes can separate real-world evaluation and deployment prompts, suggesting that current models internally represent this distinction. We also find that current safety evaluations are correctly classified by the probes, suggesting that they already appear artificial or inauthentic to models. Our findings underscore the importance of ensuring trustworthy evaluations and understanding deceptive capabilities. More broadly, our work showcases how model internals may be leveraged to support blackbox methods in safety audits, especially for future models more competent at evaluation awareness and deception.",
      "authors": [
        "Jord Nguyen",
        "Khiem Hoang",
        "Carlo Leonardo Attubato",
        "Felix Hofst\\\"atter"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T15:12:43+00:00",
          "link": "https://arxiv.org/abs/2507.01786v1",
          "size": "388kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T08:46:58+00:00",
          "link": "https://arxiv.org/abs/2507.01786v2",
          "size": "1984kb",
          "version": "v2"
        }
      ],
      "title": "Probing and Steering Evaluation Awareness of Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01786",
        "HTML": "https://arxiv.org/html/2507.01786v2",
        "PDF": "https://arxiv.org/pdf/2507.01786"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores evaluation awareness in language models and discusses probing techniques, but it does not focus on training data processing or data engineering aspects."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06775",
      "abstract": "Providing generalization guarantees for stochastic optimization algorithms is a major challenge in modern learning theory. Recently, several studies highlighted the impact of the geometry of training trajectories on the generalization error, both theoretically and empirically. Among these works, a series of topological generalization bounds have been proposed, relating the generalization error to notions of topological complexity that stem from topological data analysis (TDA). Despite their empirical success, these bounds rely on intricate information-theoretic (IT) terms that can be bounded in specific cases but remain intractable for practical algorithms (such as ADAM), potentially reducing the relevance of the derived bounds. In this paper, we seek to formulate comprehensive and interpretable topological generalization bounds free of intractable mutual information terms. To this end, we introduce a novel learning theoretic framework that departs from the existing strategies via proof techniques rooted in algorithmic stability. By extending an existing notion of \\textit{hypothesis set stability}, to \\textit{trajectory stability}, we prove that the generalization error of trajectory-stable algorithms can be upper bounded in terms of (i) TDA quantities describing the complexity of the trajectory of the optimizer in the parameter space, and (ii) the trajectory stability parameter of the algorithm. Through a series of experimental evaluations, we demonstrate that the TDA terms in the bound are of great importance, especially as the number of training samples grows. This ultimately forms an explanation of the empirical success of the topological generalization bounds.",
      "authors": [
        "Mario Tuci",
        "Lennart Bastian",
        "Benjamin Dupuis",
        "Nassir Navab",
        "Tolga Birdal",
        "Umut \\c{S}im\\c{s}ekli"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Algebraic Topology (math.AT)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T12:03:25+00:00",
          "link": "https://arxiv.org/abs/2507.06775v1",
          "size": "83kb",
          "version": "v1"
        }
      ],
      "title": "Mutual Information Free Topological Generalization Bounds via Stability",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06775",
        "HTML": "https://arxiv.org/html/2507.06775v1",
        "PDF": "https://arxiv.org/pdf/2507.06775"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research introduces generalization bounds related to topological data analysis, without discussing any aspects of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07046",
      "abstract": "Nowadays, speech emotion recognition (SER) plays a vital role in the field of human-computer interaction (HCI) and the evolution of artificial intelligence (AI). Our proposed DCRF-BiLSTM model is used to recognize seven emotions: neutral, happy, sad, angry, fear, disgust, and surprise, which are trained on five datasets: RAVDESS (R), TESS (T), SAVEE (S), EmoDB (E), and Crema-D (C). The model achieves high accuracy on individual datasets, including 97.83% on RAVDESS, 97.02% on SAVEE, 95.10% for CREMA-D, and a perfect 100% on both TESS and EMO-DB. For the combined (R+T+S) datasets, it achieves 98.82% accuracy, outperforming previously reported results. To our knowledge, no existing study has evaluated a single SER model across all five benchmark datasets (i.e., R+T+S+C+E) simultaneously. In our work, we introduce this comprehensive combination and achieve a remarkable overall accuracy of 93.76%. These results confirm the robustness and generalizability of our DCRF-BiLSTM framework across diverse datasets.",
      "authors": [
        "Shahana Yasmin Chowdhury",
        "Bithi Banik",
        "Md Tamjidul Hoque and Shreya Banerjee"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T17:07:45+00:00",
          "link": "https://arxiv.org/abs/2507.07046v1",
          "size": "4001kb",
          "version": "v1"
        }
      ],
      "title": "A Novel Hybrid Deep Learning Technique for Speech Emotion Detection using Feature Engineering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07046",
        "HTML": "https://arxiv.org/html/2507.07046v1",
        "PDF": "https://arxiv.org/pdf/2507.07046"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is centered on speech emotion recognition and model development, utilizing existing datasets without contributing to LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2402.16267",
      "abstract": "Infrared-visible image fusion (IVIF) has attracted much attention owing to the highly-complementary properties of the two image modalities. Due to the lack of ground-truth fused images, the fusion output of current deep-learning based methods heavily depends on the loss functions defined mathematically. As it is hard to well mathematically define the fused image without ground truth, the performance of existing fusion methods is limited. In this paper, we first propose to use natural language to express the objective of IVIF, which can avoid the explicit mathematical modeling of fusion output in current losses, and make full use of the advantage of language expression to improve the fusion performance. For this purpose, we present a comprehensive language-expressed fusion objective, and encode relevant texts into the multi-modal embedding space using CLIP. A language-driven fusion model is then constructed in the embedding space, by establishing the relationship among the embedded vectors to represent the fusion objective and input image modalities. Finally, a language-driven loss is derived to make the actual IVIF aligned with the embedded language-driven fusion model via supervised training. Experiments show that our method can obtain much better fusion results than existing techniques.",
      "authors": [
        "Yuhao Wang",
        "Lingjuan Miao",
        "Zhiqiang Zhou",
        "Lei Zhang and Yajun Qiao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-26T03:08:01+00:00",
          "link": "https://arxiv.org/abs/2402.16267v1",
          "size": "6150kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T07:12:24+00:00",
          "link": "https://arxiv.org/abs/2402.16267v2",
          "size": "6150kb",
          "version": "v2"
        }
      ],
      "title": "Infrared and visible Image Fusion with Language-driven Loss in CLIP Embedding Space",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.16267",
        "HTML": "https://arxiv.org/html/2402.16267v2",
        "PDF": "https://arxiv.org/pdf/2402.16267"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is focused on image fusion using language-driven loss without discussing LLM training data processing or data engineering operations."
      },
      "tasks": [
        "Infrared And Visible Image Fusion"
      ],
      "repo_urls": [
        "https://github.com/wyhlaowang/LDFusion"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.13484",
      "abstract": "Off-Policy Evaluation (OPE) is employed to assess the potential impact of a hypothetical policy using logged contextual bandit feedback, which is crucial in areas such as personalized medicine and recommender systems, where online interactions are associated with significant risks and costs. Traditionally, OPE methods rely on the Stable Unit Treatment Value Assumption (SUTVA), which assumes that the reward for any given individual is unaffected by the actions of others. However, this assumption often fails in real-world scenarios due to the presence of interference, where an individual's reward is affected not just by their own actions but also by the actions of their peers. This realization reveals significant limitations of existing OPE methods in real-world applications. To address this limitation, we propose IntIPW, an IPW-style estimator that extends the Inverse Probability Weighting (IPW) framework by integrating marginalized importance weights to account for both individual actions and the influence of adjacent entities. Extensive experiments are conducted on both synthetic and real-world data to demonstrate the effectiveness of the proposed IntIPW method.",
      "authors": [
        "Yuqi Bai",
        "Ziyu Zhao",
        "Chenxin Lyu",
        "Minqin Zhu",
        "Kun Kuang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-24T06:07:25+00:00",
          "link": "https://arxiv.org/abs/2408.13484v1",
          "size": "99kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T14:13:59+00:00",
          "link": "https://arxiv.org/abs/2408.13484v2",
          "size": "91kb",
          "version": "v2"
        }
      ],
      "title": "IntOPE: Off-Policy Evaluation in the Presence of Interference",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.13484",
        "HTML": "https://arxiv.org/html/2408.13484v2",
        "PDF": "https://arxiv.org/pdf/2408.13484"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses off-policy evaluation methods and interference in contextual bandits, unrelated to LLM training data processing."
      },
      "tasks": [
        "Off-policy evaluation",
        "Recommendation Systems"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06235",
      "abstract": "\"Kawaii\" is the Japanese concept of cute, which carries sociocultural connotations related to social identities and emotional responses. Yet, virtually all work to date has focused on the visual side of kawaii, including in studies of computer agents and social robots. In pursuit of formalizing the new science of kawaii vocalics, we explored what elements of voice relate to kawaii and how they might be manipulated, manually and automatically. We conducted a four-phase study (grand N = 512) with two varieties of computer voices: text-to-speech (TTS) and game character voices. We found kawaii \"sweet spots\" through manipulation of fundamental and formant frequencies, but only for certain voices and to a certain extent. Findings also suggest a ceiling effect for the kawaii vocalics of certain voices. We offer empirical validation of the preliminary kawaii vocalics model and an elementary method for manipulating kawaii perceptions of computer voice.",
      "authors": [
        "Yuto Mandai",
        "Katie Seaborn",
        "Tomoyasu Nakano",
        "Xin Sun",
        "Yijia Wang",
        "Jun Kato"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Computers and Society (cs.CY)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-20T06:03:23+00:00",
          "link": "https://arxiv.org/abs/2507.06235v1",
          "size": "1840kb",
          "version": "v1"
        }
      ],
      "title": "Super Kawaii Vocalics: Amplifying the \"Cute\" Factor in Computer Voice",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06235",
        "HTML": "https://arxiv.org/html/2507.06235v1",
        "PDF": "https://arxiv.org/pdf/2507.06235"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research pertains to vocal characteristics and does not involve LLM training data processing or new dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06465",
      "abstract": "Temporal networks consisting of timestamped interactions between a set of nodes provide a useful representation for analyzing complex networked systems that evolve over time. Beyond pairwise interactions between nodes, temporal motifs capture patterns of higher-order interactions such as directed triangles over short time periods. We propose temporal motif participation profiles (TMPPs) to capture the behavior of nodes in temporal motifs. Two nodes with similar TMPPs take similar positions within temporal motifs, possibly with different nodes. TMPPs serve as unsupervised embeddings for nodes in temporal networks that are directly interpretable, as each entry denotes the frequency at which a node participates in a particular position in a specific temporal motif. We demonstrate that clustering TMPPs reveals groups of nodes with similar roles in a temporal network through simulation experiments and a case study on a network of militarized interstate disputes.",
      "authors": [
        "Maxwell C. Lee and Kevin S. Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Physics and Society (physics.soc-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T00:47:45+00:00",
          "link": "https://arxiv.org/abs/2507.06465v1",
          "size": "341kb",
          "version": "v1"
        }
      ],
      "title": "Temporal Motif Participation Profiles for Analyzing Node Similarity in Temporal Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06465",
        "HTML": "https://arxiv.org/html/2507.06465v1",
        "PDF": "https://arxiv.org/pdf/2507.06465"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes a method for analyzing node similarity in temporal networks, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06797",
      "abstract": "Thermal imaging from unmanned aerial vehicles (UAVs) holds significant potential for applications in search and rescue, wildlife monitoring, and emergency response, especially under low-light or obscured conditions. However, the scarcity of large-scale, diverse thermal aerial datasets limits the advancement of deep learning models in this domain, primarily due to the high cost and logistical challenges of collecting thermal data. In this work, we introduce a novel procedural pipeline for generating synthetic thermal images from an aerial perspective. Our method integrates arbitrary object classes into existing thermal backgrounds by providing control over the position, scale, and orientation of the new objects, while aligning them with the viewpoints of the background. We enhance existing thermal datasets by introducing new object categories, specifically adding a drone class in urban environments to the HIT-UAV dataset and an animal category to the MONET dataset. In evaluating these datasets for object detection task, we showcase strong performance across both new and existing classes, validating the successful expansion into new applications. Through comparative analysis, we show that thermal detectors outperform their visible-light-trained counterparts and highlight the importance of replicating aerial viewing angles. Project page: https://github.com/larics/thermal_aerial_synthetic.",
      "authors": [
        "Antonella Barisic Kulas",
        "Andreja Jurasovic and Stjepan Bogdan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T12:34:56+00:00",
          "link": "https://arxiv.org/abs/2507.06797v1",
          "size": "6629kb",
          "version": "v1"
        }
      ],
      "title": "Unlocking Thermal Aerial Imaging: Synthetic Enhancement of UAV Datasets",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06797",
        "HTML": "https://arxiv.org/html/2507.06797v1",
        "PDF": "https://arxiv.org/pdf/2507.06797"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper introduces a novel procedural pipeline for generating synthetic thermal images, which is a method of creating a new dataset with detailed data processing steps, enhancing existing datasets with new object categories."
      },
      "source": "arXiv"
    },
    {
      "id": "2406.07366",
      "abstract": "The Biot-Savart law is relevant in physical contexts including electromagnetism and fluid dynamics. In the latter case, when the rotation of a fluid is confined to a set of very thin vortex filaments, this law describes the velocity field induced by the spatial arrangement of these objects. The Biot-Savart law is at the core of vortex methods used in the simulation of classical and quantum fluid flows. Naive methods are inefficient when dealing with large numbers of vortex elements, which makes them inadequate for simulating turbulent vortex flows. Here we exploit a direct analogy between the Biot-Savart law and electrostatics to adapt Ewald summation methods, routinely used in molecular dynamics simulations, to vortex filament simulations in three-dimensional periodic domains. In this context, the basic idea is to split the induced velocity onto (i) a coarse-grained velocity generated by a Gaussian-filtered vorticity field, and (ii) a short-range correction accounting for near-singular behaviour near the vortices. The former component can be accurately and efficiently evaluated using the nonuniform fast Fourier transform algorithm. Analytical accuracy estimates are provided as a function of the parameters entering the method. We also discuss how to properly account for the finite vortex core size in kinetic energy estimations. Using numerical experiments, we verify the accuracy and the conservation properties of the proposed approach. Moreover, we demonstrate the $O(N \\log N)$ complexity of the method over a wide range of problem sizes $N$, considerably better than the $O(N^2)$ cost of a naive approach.",
      "authors": [
        "Juan Ignacio Polanco"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Physics (physics.comp-ph)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)",
        "Fluid Dynamics (physics.flu-dyn)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-11T15:32:39+00:00",
          "link": "https://arxiv.org/abs/2406.07366v1",
          "size": "1007kb",
          "version": "v1"
        },
        {
          "date": "2025-04-09T13:48:58+00:00",
          "link": "https://arxiv.org/abs/2406.07366v2",
          "size": "896kb",
          "version": "v2"
        }
      ],
      "title": "Fast and accurate evaluation of Biot-Savart integrals over spatial curves in periodic domains",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.07366",
        "HTML": "https://arxiv.org/html/2406.07366v2",
        "PDF": "https://arxiv.org/pdf/2406.07366"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with the Biot-Savart integrals in fluid dynamics simulations and does not contribute to the collection or processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.20265",
      "abstract": "Dynamic Algorithm Configuration (DAC) has garnered significant attention in recent years, particularly in the prevalence of machine learning and deep learning algorithms. Numerous studies have leveraged the robustness of decision-making in Reinforcement Learning (RL) to address the optimization challenges associated with algorithm configuration. However, making an RL agent work properly is a non-trivial task, especially in reward design, which necessitates a substantial amount of handcrafted knowledge based on domain expertise. In this work, we study the importance of reward design in the context of DAC via a case study on controlling the population size of the $(1+(\\lambda,\\lambda))$-GA optimizing OneMax. We observed that a poorly designed reward can hinder the RL agent's ability to learn an optimal policy because of a lack of exploration, leading to both scalability and learning divergence issues. To address those challenges, we propose the application of a reward shaping mechanism to facilitate enhanced exploration of the environment by the RL agent. Our work not only demonstrates the ability of RL in dynamically configuring the $(1+(\\lambda,\\lambda))$-GA, but also confirms the advantages of reward shaping in the scalability of RL agents across various sizes of OneMax problems.",
      "authors": [
        "Tai Nguyen",
        "Phong Le",
        "Andr\\'e Biedenkapp",
        "Carola Doerr",
        "Nguyen Dang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-27T16:53:28+00:00",
          "link": "https://arxiv.org/abs/2502.20265v1",
          "size": "2683kb",
          "version": "v1"
        },
        {
          "date": "2025-03-03T20:00:38+00:00",
          "link": "https://arxiv.org/abs/2502.20265v2",
          "size": "2435kb",
          "version": "v2"
        }
      ],
      "title": "On the Importance of Reward Design in Reinforcement Learning-based Dynamic Algorithm Configuration: A Case Study on OneMax with (1+($\\lambda$,$\\lambda$))-GA",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.20265",
        "HTML": "https://arxiv.org/html/2502.20265",
        "PDF": "https://arxiv.org/pdf/2502.20265"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper studies reinforcement learning in dynamic algorithm configuration and reward design, which does not involve LLM training data processing."
      },
      "tasks": [
        "Reinforcement Learning (RL)"
      ],
      "repo_urls": [
        "https://github.com/taindp98/OneMax-DAC"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.03332",
      "abstract": "Critical peer review of scientific manuscripts presents a significant challenge for Large Language Models (LLMs), partly due to data limitations and the complexity of expert reasoning. This report introduces Persistent Workflow Prompting (PWP), a potentially broadly applicable prompt engineering methodology designed to bridge this gap using standard LLM chat interfaces (zero-code, no APIs). We present a proof-of-concept PWP prompt for the critical analysis of experimental chemistry manuscripts, featuring a hierarchical, modular architecture (structured via Markdown) that defines detailed analysis workflows. We develop this PWP prompt through iterative application of meta-prompting techniques and meta-reasoning aimed at systematically codifying expert review workflows, including tacit knowledge. Submitted once at the start of a session, this PWP prompt equips the LLM with persistent workflows triggered by subsequent queries, guiding modern reasoning LLMs through systematic, multimodal evaluations. Demonstrations show the PWP-guided LLM identifying major methodological flaws in a test case while mitigating LLM input bias and performing complex tasks, including distinguishing claims from evidence, integrating text/photo/figure analysis to infer parameters, executing quantitative feasibility checks, comparing estimates against claims, and assessing a priori plausibility. To ensure transparency and facilitate replication, we provide full prompts, detailed demonstration analyses, and logs of interactive chats as supplementary resources. Beyond the specific application, this work offers insights into the meta-development process itself, highlighting the potential of PWP, informed by detailed workflow formalization, to enable sophisticated analysis using readily available LLMs for complex scientific tasks.",
      "authors": [
        "Evgeny Markhasin"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Chemical Physics (physics.chem-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-06T09:06:18+00:00",
          "link": "https://arxiv.org/abs/2505.03332v1",
          "size": "668kb",
          "version": "v1"
        },
        {
          "date": "2025-05-08T18:27:45+00:00",
          "link": "https://arxiv.org/abs/2505.03332v2",
          "size": "651kb",
          "version": "v2"
        },
        {
          "date": "2025-05-18T06:53:56+00:00",
          "link": "https://arxiv.org/abs/2505.03332v3",
          "size": "675kb",
          "version": "v3"
        },
        {
          "date": "2025-07-08T18:03:14+00:00",
          "link": "https://arxiv.org/abs/2505.03332v4",
          "size": "667kb",
          "version": "v4"
        }
      ],
      "title": "AI-Driven Scholarly Peer Review via Persistent Workflow Prompting, Meta-Prompting, and Meta-Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.03332",
        "PDF": "https://arxiv.org/pdf/2505.03332"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on prompt engineering methodology and peer review tasks using LLMs, rather than training data processing or dataset creation for LLM training."
      },
      "tasks": [
        "Prompt Engineering"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06656",
      "abstract": "Diffusion models have shown remarkable promise for image restoration by leveraging powerful priors. Prominent methods typically frame the restoration problem within a Bayesian inference framework, which iteratively combines a denoising step with a likelihood guidance step. However, the interactions between these two components in the generation process remain underexplored. In this paper, we analyze the underlying gradient dynamics of these components and identify significant instabilities. Specifically, we demonstrate conflicts between the prior and likelihood gradient directions, alongside temporal fluctuations in the likelihood gradient itself. We show that these instabilities disrupt the generative process and compromise restoration performance. To address these issues, we propose Stabilized Progressive Gradient Diffusion (SPGD), a novel gradient management technique. SPGD integrates two synergistic components: (1) a progressive likelihood warm-up strategy to mitigate gradient conflicts; and (2) adaptive directional momentum (ADM) smoothing to reduce fluctuations in the likelihood gradient. Extensive experiments across diverse restoration tasks demonstrate that SPGD significantly enhances generation stability, leading to state-of-the-art performance in quantitative metrics and visually superior results. Code is available at \\href{https://github.com/74587887/SPGD}{here}.",
      "authors": [
        "Hongjie Wu",
        "Mingqin Zhang",
        "Linchao He",
        "Ji-Zhe Zhou",
        "Jiancheng Lv"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T08:40:46+00:00",
          "link": "https://arxiv.org/abs/2507.06656v1",
          "size": "13510kb",
          "version": "v1"
        }
      ],
      "title": "Enhancing Diffusion Model Stability for Image Restoration via Gradient Management",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06656",
        "HTML": "https://arxiv.org/html/2507.06656v1",
        "PDF": "https://arxiv.org/pdf/2507.06656"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with enhancing the stability of diffusion models for image restoration and does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.00614",
      "abstract": "The Seymour Second Neighborhood Conjecture (SSNC) claims that there will always exist a node whose out-degree doubles in the square of an oriented graph. In this paper, we establish the Graph Level Order (GLOVER) data structure, which orders the nodes by shortest path from a minimum out-degree node and establishes a well-ordering of rooted neighborhoods. This data structure allows for the construction of decreasing sequences of subsets of nodes and allows us to partition transitive triangles into distinct sets. The decreasing sequence of nodes shows the non-existence of counterexamples to the SSNC and precisely identifies a path to the required node. Further, our algorithmic approach finds the occurrence of dense graphs inside the rooted neighborhoods. Beyond theoretical implications, the algorithm and data structure have practical applications in data science, network optimization and algorithm design.",
      "authors": [
        "Charles Glover"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-31T19:19:14+00:00",
          "link": "https://arxiv.org/abs/2501.00614v1",
          "size": "43kb",
          "version": "v1"
        },
        {
          "date": "2025-01-06T05:26:07+00:00",
          "link": "https://arxiv.org/abs/2501.00614v2",
          "size": "45kb",
          "version": "v2"
        },
        {
          "date": "2025-01-08T14:38:35+00:00",
          "link": "https://arxiv.org/abs/2501.00614v3",
          "size": "34kb",
          "version": "v3"
        },
        {
          "date": "2025-01-09T03:16:35+00:00",
          "link": "https://arxiv.org/abs/2501.00614v4",
          "size": "35kb",
          "version": "v4"
        },
        {
          "date": "2025-01-13T03:29:39+00:00",
          "link": "https://arxiv.org/abs/2501.00614v5",
          "size": "33kb",
          "version": "v5"
        },
        {
          "date": "2025-01-21T16:14:46+00:00",
          "link": "https://arxiv.org/abs/2501.00614v6",
          "size": "37kb",
          "version": "v6"
        },
        {
          "date": "2025-01-28T18:05:41+00:00",
          "link": "https://arxiv.org/abs/2501.00614v7",
          "size": "41kb",
          "version": "v7"
        },
        {
          "date": "2025-02-04T16:17:22+00:00",
          "link": "https://arxiv.org/abs/2501.00614v8",
          "size": "44kb",
          "version": "v8"
        },
        {
          "date": "2025-02-19T15:35:15+00:00",
          "link": "https://arxiv.org/abs/2501.00614v9",
          "size": "437kb",
          "version": "v9"
        },
        {
          "date": "2025-06-23T21:40:53+00:00",
          "link": "https://arxiv.org/abs/2501.00614v10",
          "size": "885kb",
          "version": "v10"
        },
        {
          "date": "2025-07-02T16:54:53+00:00",
          "link": "https://arxiv.org/abs/2501.00614v11",
          "size": "661kb",
          "version": "v11"
        },
        {
          "date": "2025-07-09T14:01:31+00:00",
          "link": "https://arxiv.org/abs/2501.00614v12",
          "size": "668kb",
          "version": "v12"
        }
      ],
      "title": "An Algorithmic Approach to Finding Degree-Doubling Nodes in Oriented Graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.00614",
        "PDF": "https://arxiv.org/pdf/2501.00614"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses an algorithmic graph theory problem, which is not related to LLM training data processing or data-related engineering aspects pertinent to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.15740",
      "abstract": "As Large Language Models (LLMs) are increasingly deployed as autonomous agents in complex and long horizon settings, it is critical to evaluate their ability to sabotage users by pursuing hidden objectives. We study the ability of frontier LLMs to evade monitoring and achieve harmful hidden goals while completing a wide array of realistic tasks. We evaluate a broad range of frontier LLMs using SHADE (Subtle Harmful Agent Detection & Evaluation)-Arena, the first highly diverse agent evaluation dataset for sabotage and monitoring capabilities of LLM agents. SHADE-Arena consists of complex pairs of benign main tasks and harmful side objectives in complicated environments. Agents are evaluated on their ability to complete the side task without appearing suspicious to an LLM monitor. When measuring agent ability to (a) complete the main task, (b) complete the side task, and (c) avoid detection, we find that the best performing frontier models score 27% (Claude 3.7 Sonnet) and 15% (Gemini 2.5 Pro) as sabotage agents when overseen by Claude 3.6 Sonnet. For current frontier models, success on the side task relies heavily on having access to a hidden scratchpad that is not visible to the monitor. We also use SHADE-Arena to measure models' monitoring abilities, with the top monitor (Gemini 2.5 Pro) achieving an AUC of 0.87 at distinguishing benign and malign transcripts. We find that for now, models still struggle at sabotage due to failures in long-context main task execution. However, our measurements already demonstrate the difficulty of monitoring for subtle sabotage attempts, which we expect to only increase in the face of more complex and longer-horizon tasks.",
      "authors": [
        "Jonathan Kutasov",
        "Yuqi Sun",
        "Paul Colognese",
        "Teun van der Weij",
        "Linda Petrini",
        "Chen Bo Calvin Zhang",
        "John Hughes",
        "Xiang Deng",
        "Henry Sleight",
        "Tyler Tracy",
        "Buck Shlegeris",
        "Joe Benton"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-17T15:46:15+00:00",
          "link": "https://arxiv.org/abs/2506.15740v1",
          "size": "4091kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T21:23:22+00:00",
          "link": "https://arxiv.org/abs/2506.15740v2",
          "size": "4091kb",
          "version": "v2"
        }
      ],
      "title": "SHADE-Arena: Evaluating Sabotage and Monitoring in LLM Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.15740",
        "HTML": "https://arxiv.org/html/2506.15740v2",
        "PDF": "https://arxiv.org/pdf/2506.15740"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is centered on evaluating sabotage and monitoring in LLM agents using the SHADE-Arena dataset but does not involve processing or creating LLM training data."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.06631",
      "abstract": "This document reports on a method for detecting and preventing overfitting on data regressions, herein applied to mesh-like data structures. The mesh structure allows for the straightforward computation of the Laplace-operator second-order derivatives in a finite-difference fashion for noiseless data. Derivatives of the training data are computed on the original training mesh to serve as a true label of the entropy of the training data. Derivatives of the trained data are computed on a staggered mesh to identify oscillations in the interior of the original training mesh cells. The loss of the Laplace-operator derivatives is used for hyperparameter optimisation, achieving a reduction of unwanted oscillation through the minimisation of the entropy of the trained model. In this setup, testing does not require the splitting of points from the training data, and training is thus directly performed on all available training points. The Laplace operator applied to the trained data on a staggered mesh serves as a surrogate testing metric based on diffusion properties.",
      "authors": [
        "Enda D.V. Bigarella"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T07:57:52+00:00",
          "link": "https://arxiv.org/abs/2507.06631v1",
          "size": "113kb",
          "version": "v1"
        }
      ],
      "title": "Prevention of Overfitting on Mesh-Structured Data Regressions with a Modified Laplace Operator",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06631",
        "HTML": "https://arxiv.org/html/2507.06631v1",
        "PDF": "https://arxiv.org/pdf/2507.06631"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper describes a technique for preventing overfitting in mesh-structured data regressions, without any focus or contribution to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05677",
      "abstract": "Prompt learning methods have significantly extended the transferability of pre-trained Vision-Language Models (VLMs) like CLIP for various downstream tasks. These methods adopt handcraft templates or learnable vectors to provide text or image instructions in fine-tuning VLMs. However, most existing works ignore the structural relationships between learnable prompts and tokens within and between modalities. Moreover, balancing the performance of base and new classes remains a significant challenge. In this paper, we propose an Integrated Structural Prompt (ISP) for VLMs to enhance the interaction of information representations between the text and image branches. ISP introduces self-structural and cross-structural prompt modules to model the structural relationships between learnable prompts and frozen tokens within and across modalities. This enables efficient information transfer while preserving feature stability. Additionally, we propose a sample probing module that dynamically adjusts loss coefficients based on sample difficulty, preventing the mode from overfitting to simple samples and improving generalization ability to new classes. Extensive experiments on three widely used settings: base-to-new generalization, cross-dataset evaluation, and domain generalization demonstrate that the proposed ISP achieves competitive performance against state-of-the-art methods.",
      "authors": [
        "Jiahui Wang",
        "Qin Xu",
        "Bo Jiang",
        "Bin Luo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T04:59:58+00:00",
          "link": "https://arxiv.org/abs/2507.05677v1",
          "size": "4794kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T04:40:27+00:00",
          "link": "https://arxiv.org/abs/2507.05677v2",
          "size": "4793kb",
          "version": "v2"
        }
      ],
      "title": "Integrated Structural Prompt Learning for Vision-Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05677",
        "HTML": "https://arxiv.org/html/2507.05677v2",
        "PDF": "https://arxiv.org/pdf/2507.05677"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper focuses on prompt learning methods for Vision-Language Models and does not primarily contribute to LLM training data processing, although it does involve fine-tuning of these models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06354",
      "abstract": "Context: The evidence for the prevalence of test smells at the unit testing level has relied on the accuracy of detection tools, which have seen intense research in the last two decades. The Eager Test smell, one of the most prevalent, is often identified using simplified detection rules that practitioners find inadequate. Objective: We aim to improve the rules for detecting the Eager Test smell. Method: We reviewed the literature on test smells to analyze the definitions and detection rules of the Eager Test smell. We proposed a novel, unambiguous definition of the test smell and a heuristic to address the limitations of the existing rules. We evaluated our heuristic against existing detection rules by manually applying it to 300 unit test cases in Java. Results: Our review identified 56 relevant studies. We found that inadequate interpretations of original definitions of the Eager Test smell led to imprecise detection rules, resulting in a high level of disagreement in detection outcomes. Also, our heuristic detected patterns of eager and non-eager tests that existing rules missed. Conclusion: Our heuristic captures the essence of the Eager Test smell more precisely; hence, it may address practitioners' concerns regarding the adequacy of existing detection rules.",
      "authors": [
        "Huynh Khanh Vi Tran",
        "Nauman bin Ali",
        "Michael Unterkalmsteiner",
        "J\\\"urgen B\\\"orstler"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T19:30:22+00:00",
          "link": "https://arxiv.org/abs/2507.06354v1",
          "size": "361kb",
          "version": "v1"
        }
      ],
      "title": "A proposal and assessment of an improved heuristic for the Eager Test smell detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06354",
        "HTML": "https://arxiv.org/html/2507.06354v1",
        "PDF": "https://arxiv.org/pdf/2507.06354"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a heuristic for detecting test smells in unit tests, focused on software quality, and does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06596",
      "abstract": "Children are often exposed to items curated by recommendation algorithms. Yet, research seldom considers children as a user group, and when it does, it is anchored on datasets where children are underrepresented, risking overlooking their interests, favoring those of the majority, i.e., mainstream users. Recently, Ungruh et al. demonstrated that children's consumption patterns and preferences differ from those of mainstream users, resulting in inconsistent recommendation algorithm performance and behavior for this user group. These findings, however, are based on two datasets with a limited child user sample. We reproduce and replicate this study on a wider range of datasets in the movie, music, and book domains, uncovering interaction patterns and aspects of child-recommender interactions consistent across domains, as well as those specific to some user samples in the data. We also extend insights from the original study with popularity bias metrics, given the interpretation of results from the original study. With this reproduction and extension, we uncover consumption patterns and differences between age groups stemming from intrinsic differences between children and others, and those unique to specific datasets or domains.",
      "authors": [
        "Robin Ungruh",
        "Alejandro Bellog\\'in",
        "Dominik Kowald",
        "Maria Soledad Pera"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T07:15:12+00:00",
          "link": "https://arxiv.org/abs/2507.06596v1",
          "size": "154kb",
          "version": "v1"
        }
      ],
      "title": "Impacts of Mainstream-Driven Algorithms on Recommendations for Children Across Domains: A Reproducibility Study",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06596",
        "HTML": "https://arxiv.org/html/2507.06596v1",
        "PDF": "https://arxiv.org/pdf/2507.06596"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with recommendation algorithms and their impact on children, without any discussion on LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06956",
      "abstract": "Large language models (LLMs) are very costly and inefficient to update with new information. To address this limitation, retrieval-augmented generation (RAG) has been proposed as a solution that dynamically incorporates external knowledge during inference, improving factual consistency and reducing hallucinations. Despite its promise, RAG systems face practical challenges-most notably, a strong dependence on the quality of the input query for accurate retrieval. In this paper, we investigate the sensitivity of different components in the RAG pipeline to various types of query perturbations. Our analysis reveals that the performance of commonly used retrievers can degrade significantly even under minor query variations. We study each module in isolation as well as their combined effect in an end-to-end question answering setting, using both general-domain and domain-specific datasets. Additionally, we propose an evaluation framework to systematically assess the query-level robustness of RAG pipelines and offer actionable recommendations for practitioners based on the results of more than 1092 experiments we performed.",
      "authors": [
        "Sezen Per\\c{c}in",
        "Xin Su",
        "Qutub Sha Syed",
        "Phillip Howard",
        "Aleksei Kuvshinov",
        "Leo Schwinn",
        "Kay-Ulrich Scholl"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T15:39:17+00:00",
          "link": "https://arxiv.org/abs/2507.06956v1",
          "size": "3705kb",
          "version": "v1"
        }
      ],
      "title": "Investigating the Robustness of Retrieval-Augmented Generation at the Query Level",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06956",
        "HTML": "https://arxiv.org/html/2507.06956v1",
        "PDF": "https://arxiv.org/pdf/2507.06956"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper investigates retrieval-augmented generation systems which use existing queries and retrieval methods rather than making a significant contribution to training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06994",
      "abstract": "Accurate prognosis of non-small cell lung cancer (NSCLC) patients undergoing immunotherapy is essential for personalized treatment planning, enabling informed patient decisions, and improving both treatment outcomes and quality of life. However, the lack of large, relevant datasets and effective multi-modal feature fusion strategies pose significant challenges in this domain. To address these challenges, we present a large-scale dataset and introduce a novel framework for multi-modal feature fusion aimed at enhancing the accuracy of survival prediction. The dataset comprises 3D CT images and corresponding clinical records from NSCLC patients treated with immune checkpoint inhibitors (ICI), along with progression-free survival (PFS) and overall survival (OS) data. We further propose a cross-modality masked learning approach for medical feature fusion, consisting of two distinct branches, each tailored to its respective modality: a Slice-Depth Transformer for extracting 3D features from CT images and a graph-based Transformer for learning node features and relationships among clinical variables in tabular data. The fusion process is guided by a masked modality learning strategy, wherein the model utilizes the intact modality to reconstruct missing components. This mechanism improves the integration of modality-specific features, fostering more effective inter-modality relationships and feature interactions. Our approach demonstrates superior performance in multi-modal integration for NSCLC survival prediction, surpassing existing methods and setting a new benchmark for prognostic models in this context.",
      "authors": [
        "Qilong Xing",
        "Zikai Song",
        "Bingxin Gong",
        "Lian Yang",
        "Junqing Yu",
        "Wei Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T16:19:31+00:00",
          "link": "https://arxiv.org/abs/2507.06994v1",
          "size": "757kb",
          "version": "v1"
        }
      ],
      "title": "Cross-Modality Masked Learning for Survival Prediction in ICI Treated NSCLC Patients",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06994",
        "HTML": "https://arxiv.org/html/2507.06994v1",
        "PDF": "https://arxiv.org/pdf/2507.06994"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on prognostic model development for cancer treatment using multi-modal feature fusion and does not discuss LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2404.00330",
      "abstract": "Deep functional maps have emerged in recent years as a prominent learning-based framework for non-rigid shape matching problems. While early methods in this domain only focused on learning in the functional domain, the latest techniques have demonstrated that by promoting consistency between functional and pointwise maps leads to significant improvements in accuracy. Unfortunately, existing approaches rely heavily on the computation of large dense matrices arising from soft pointwise maps, which compromises their efficiency and scalability. To address this limitation, we introduce a novel memory-scalable and efficient functional map learning pipeline. By leveraging the specific structure of functional maps, we offer the possibility to achieve identical results without ever storing the pointwise map in memory. Furthermore, based on the same approach, we present a differentiable map refinement layer adapted from an existing axiomatic refinement algorithm. Unlike many functional map learning methods, which use this algorithm at a post-processing step, ours can be easily used at train time, enabling to enforce consistency between the refined and initial versions of the map. Our resulting approach is both simpler, more efficient and more numerically stable, by avoiding differentiation through a linear system, while achieving close to state-of-the-art results in challenging scenarios.",
      "authors": [
        "Robin Magnet",
        "Maks Ovsjanikov"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-30T12:01:04+00:00",
          "link": "https://arxiv.org/abs/2404.00330v1",
          "size": "5395kb",
          "version": "v1"
        }
      ],
      "title": "Memory-Scalable and Simplified Functional Map Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.00330",
        "HTML": "https://arxiv.org/html/2404.00330",
        "PDF": "https://arxiv.org/pdf/2404.00330"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a pipeline for efficient functional map learning for shape matching problems, with no mention of large language models or training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05610",
      "abstract": "Differentially private zeroth-order optimization methods have recently gained popularity in private fine tuning of machine learning models due to their reduced memory requirements. Current approaches for privatizing zeroth-order methods rely on adding Gaussian noise to the estimated zeroth-order gradients. However, since the search direction in the zeroth-order methods is inherently random, researchers including Tang et al. (2024) and Zhang et al. (2024a) have raised an important question: is the inherent noise in zeroth-order estimators sufficient to ensure the overall differential privacy of the algorithm? This work settles this question for a class of oracle-based optimization algorithms where the oracle returns zeroth-order gradient estimates. In particular, we show that for a fixed initialization, there exist strongly convex objective functions such that running (Projected) Zeroth-Order Gradient Descent (ZO-GD) is not differentially private. Furthermore, we show that even with random initialization and without revealing (initial and) intermediate iterates, the privacy loss in ZO-GD can grow superlinearly with the number of iterations when minimizing convex objective functions.",
      "authors": [
        "Devansh Gupta",
        "Meisam Razaviyayn",
        "Vatsal Sharan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T02:38:14+00:00",
          "link": "https://arxiv.org/abs/2507.05610v1",
          "size": "27kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T02:44:06+00:00",
          "link": "https://arxiv.org/abs/2507.05610v2",
          "size": "26kb",
          "version": "v2"
        }
      ],
      "title": "On the Inherent Privacy of Zeroth Order Projected Gradient Descent",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05610",
        "HTML": "https://arxiv.org/html/2507.05610v2",
        "PDF": "https://arxiv.org/pdf/2507.05610"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research is focused on differential privacy in zeroth-order optimization methods, not relating to LLM training data processing or enhancement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06057",
      "abstract": "Advancements in reasoning for large language models (LLMs) have lead to significant performance improvements for LLMs in various fields such as mathematics and programming. However, research applying these advances to the financial domain, where considerable domain-specific knowledge is necessary to complete tasks, remains limited. To address this gap, we introduce FEVO (Financial Evolution), a multi-stage enhancement framework developed to enhance LLM performance in the financial domain. FEVO systemically enhances LLM performance by using continued pre-training (CPT) to expand financial domain knowledge, supervised fine-tuning (SFT) to instill structured, elaborate reasoning patterns, and reinforcement learning (RL) to further integrate the expanded financial domain knowledge with the learned structured reasoning. To ensure effective and efficient training, we leverage frontier reasoning models and rule-based filtering to curate FEVO-Train, high-quality datasets specifically designed for the different post-training phases. Using our framework, we train the FEVO series of models - C32B, S32B, R32B - from Qwen2.5-32B and evaluate them on seven benchmarks to assess financial and general capabilities, with results showing that FEVO-R32B achieves state-of-the-art performance on five financial benchmarks against much larger models as well as specialist models. More significantly, FEVO-R32B demonstrates markedly better performance than FEVO-R32B-0 (trained from Qwen2.5-32B-Instruct using only RL), thus validating the effectiveness of financial domain knowledge expansion and structured, logical reasoning distillation",
      "authors": [
        "Bo Pang",
        "Yalu Ouyang",
        "Hangfei Xu",
        "Ziqi Jia",
        "Panpan Li",
        "Shengzhao Wen",
        "Lu Wang",
        "Shiyong Li",
        "Yanpeng Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T14:59:46+00:00",
          "link": "https://arxiv.org/abs/2507.06057v1",
          "size": "858kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T07:06:36+00:00",
          "link": "https://arxiv.org/abs/2507.06057v2",
          "size": "851kb",
          "version": "v2"
        }
      ],
      "title": "FEVO: Financial Knowledge Expansion and Reasoning Evolution for Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06057",
        "HTML": "https://arxiv.org/html/2507.06057v2",
        "PDF": "https://arxiv.org/pdf/2507.06057"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper describes the creation of a high-quality dataset (FEVO-Train) using rule-based filtering for continued pre-training and fine-tuning, directly focusing on LLM training data processing in the financial domain."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06526",
      "abstract": "Text-to-image diffusion models (T2I DMs), represented by Stable Diffusion, which generate highly realistic images based on textual input, have been widely used. However, their misuse poses serious security risks. While existing concept unlearning methods aim to mitigate these risks, they struggle to balance unlearning effectiveness with generative retainability.To overcome this limitation, we innovatively propose the Key Step Concept Unlearning (KSCU) method, which ingeniously capitalizes on the unique stepwise sampling characteristic inherent in diffusion models during the image generation process. Unlike conventional approaches that treat all denoising steps equally, KSCU strategically focuses on pivotal steps with the most influence over the final outcome by dividing key steps for different concept unlearning tasks and fine-tuning the model only at those steps. This targeted approach reduces the number of parameter updates needed for effective unlearning, while maximizing the retention of the model's generative capabilities.Through extensive benchmark experiments, we demonstrate that KSCU effectively prevents T2I DMs from generating undesirable images while better retaining the model's generative capabilities.Our code will be released.",
      "authors": [
        "Chaoshuo Zhang and Chenhao Lin and Zhengyu Zhao and Le Yang and Qian Wang and Chao Shen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T03:55:58+00:00",
          "link": "https://arxiv.org/abs/2507.06526v1",
          "size": "20797kb",
          "version": "v1"
        }
      ],
      "title": "Concept Unlearning by Modeling Key Steps of Diffusion Process",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06526",
        "HTML": "https://arxiv.org/html/2507.06526v1",
        "PDF": "https://arxiv.org/pdf/2507.06526"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses concept unlearning in text-to-image diffusion models, which does not relate to LLM training data processing or dataset improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06658",
      "abstract": "This project introduces a new measure of elite polarization via actor and subject detection using artificial intelligence. I identify when politicians mention one another in parliamentary speeches, note who is speaking and who is being addressed, and assess the emotional temperature behind these evaluations. This maps how elites evaluate their various out-parties, allowing us to create an index of mutual out-party hostility, that is, elite polarization. While I analyzed polarization data over the past four decades for the UK, and two decades for Hungary and Italy, my approach lays the groundwork for a twenty-year, EU-wide time-series dataset on elite polarization. I obtain the results that can be aggregated by party and quarter. The resulting index demonstrates a good face validity: it reacts to events such as electoral campaigns, country- and party-level crises, and to parties losing and assuming power.",
      "authors": [
        "Gennadii Iakovlev"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T08:44:29+00:00",
          "link": "https://arxiv.org/abs/2507.06658v1",
          "size": "837kb",
          "version": "v1"
        }
      ],
      "title": "Elite Polarization in European Parliamentary Speeches: a Novel Measurement Approach Using Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06658",
        "HTML": "https://arxiv.org/html/2507.06658v1",
        "PDF": "https://arxiv.org/pdf/2507.06658"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper uses large language models to develop a measure of elite polarization in speeches, but does not focus extensively on LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06722",
      "abstract": "Understanding how large language models (LLMs) internally represent and process their predictions is central to detecting uncertainty and preventing hallucinations. While several studies have shown that models encode uncertainty in their hidden states, it is underexplored how this affects the way they process such hidden states. In this work, we demonstrate that the dynamics of output token probabilities across layers for certain and uncertain outputs are largely aligned, revealing that uncertainty does not seem to affect inference dynamics. Specifically, we use the Tuned Lens, a variant of the Logit Lens, to analyze the layer-wise probability trajectories of final prediction tokens across 11 datasets and 5 models. Using incorrect predictions as those with higher epistemic uncertainty, our results show aligned trajectories for certain and uncertain predictions that both observe abrupt increases in confidence at similar layers. We balance this finding by showing evidence that more competent models may learn to process uncertainty differently. Our findings challenge the feasibility of leveraging simplistic methods for detecting uncertainty at inference. More broadly, our work demonstrates how interpretability methods may be used to investigate the way uncertainty affects inference.",
      "authors": [
        "Sunwoo Kim",
        "Haneul Yoo",
        "Alice Oh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T10:30:09+00:00",
          "link": "https://arxiv.org/abs/2507.06722v1",
          "size": "106kb",
          "version": "v1"
        }
      ],
      "title": "On the Effect of Uncertainty on Layer-wise Inference Dynamics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06722",
        "PDF": "https://arxiv.org/pdf/2507.06722"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study investigates inference dynamics related to uncertainty in LLMs but does not involve training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06935",
      "abstract": "In the realm of autonomous vehicle technologies and advanced driver assistance systems, precise and reliable path tracking controllers are vital for safe and efficient navigation. However the presence of dead time in the vehicle control systems poses a challenge to real-world systems. Input and output delays are caused by factors like sensor processing and mechanical response and can range up to a few hundred milliseconds. This chapter addresses the problem of dead time in path tracking control and proposes a method to compensate the dead time. The proposed solution involves a nonlinear prediction model, in a structure similar to the Smith predictor, but incorporating the kinematic behavior of the vehicle plant system. The implementation avoids numeric integration or optimization, enabling a fast execution. Simulation tests with various controllers and disturbances, including dead-time uncertainty, demonstrate the efficacy of the dead-time compensation method. Results indicate improved control performance in all tested scenarios.",
      "authors": [
        "Karin Festl",
        "Michael Stolz"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T15:16:47+00:00",
          "link": "https://arxiv.org/abs/2507.06935v1",
          "size": "623kb",
          "version": "v1"
        }
      ],
      "title": "A nonlinear dead-time compensation method for path tracking control",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06935",
        "HTML": "https://arxiv.org/html/2507.06935v1",
        "PDF": "https://arxiv.org/pdf/2507.06935"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses dead-time compensation in vehicle control systems, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07047",
      "abstract": "This study investigates public perceptions of generative artificial intelligence (GenAI) in libraries through a large-scale analysis of posts on X (formerly Twitter). Using a mixed-method approach that combines temporal trend analysis, sentiment classification, and social network analysis, this paper explores how public discourse around GenAI and libraries has evolved over time, the emotional tones that dominate the conversation, and the key users or organizations driving engagement. The findings reveal that discussions are predominantly negative in tone, with surges linked to concerns about ethics and intellectual property. Furthermore, social network analysis identifies both institutional authority and individual bridge users who facilitate cross-domain engagement. The results in this paper contribute to the growing body of literature on GenAI in the library and GLAM (Galleries, Libraries, Archives, and Museums) sectors and offer a real-time, public-facing perspective on the emerging opportunities and concerns GenAI presents.",
      "authors": [
        "Yuan Li",
        "Teja Mandaloju",
        "Haihua Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Human-Computer Interaction (cs.HC)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T17:10:06+00:00",
          "link": "https://arxiv.org/abs/2507.07047v1",
          "size": "1077kb",
          "version": "v1"
        }
      ],
      "title": "Exploring Public Perceptions of Generative AI in Libraries: A Social Media Analysis of X Discussions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07047",
        "PDF": "https://arxiv.org/pdf/2507.07047"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study analyzes public perceptions of generative AI using social media data, lacking any focus on LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.03916",
      "abstract": "Slide animations, such as fade-in, fly-in, and wipe, are critical for audience engagement, efficient information delivery, and vivid visual expression. However, most AI-driven slide-generation tools still lack native animation support, and existing vision-language models (VLMs) struggle with animation tasks due to the absence of public datasets and limited temporal-reasoning capabilities. To address this gap, we release the first public dataset for slide-animation modeling: 12,000 triplets of natural-language descriptions, animation JSON files, and rendered videos, collectively covering every built-in PowerPoint effect. Using this resource, we fine-tune Qwen-2.5-VL-7B with Low-Rank Adaptation (LoRA) and achieve consistent improvements over GPT-4.1 and Gemini-2.5-Pro in BLEU-4, ROUGE-L, SPICE, and our Coverage-Order-Detail Assessment (CODA) metric, which evaluates action coverage, temporal order, and detail fidelity. On a manually created test set of slides, the LoRA model increases BLEU-4 by around 60%, ROUGE-L by 30%, and shows significant improvements in CODA-detail. This demonstrates that low-rank adaptation enables reliable temporal reasoning and generalization beyond synthetic data. Overall, our dataset, LoRA-enhanced model, and CODA metric provide a rigorous benchmark and foundation for future research on VLM-based dynamic slide generation.",
      "authors": [
        "Yifan Jiang",
        "Yibo Xue",
        "Yukun Kang",
        "Pin Zheng",
        "Jian Peng",
        "Feiran Wu",
        "Changliang Xu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-05T06:16:31+00:00",
          "link": "https://arxiv.org/abs/2507.03916v1",
          "size": "16480kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T07:28:53+00:00",
          "link": "https://arxiv.org/abs/2507.03916v2",
          "size": "12238kb",
          "version": "v2"
        }
      ],
      "title": "Animation Needs Attention: A Holistic Approach to Slides Animation Comprehension with Visual-Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.03916",
        "HTML": "https://arxiv.org/html/2507.03916v2",
        "PDF": "https://arxiv.org/pdf/2507.03916"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper releases a new dataset for slide-animation modeling and details the data processing steps involved in preparing this dataset, which aligns with dataset creation and processing objectives."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05938",
      "abstract": "With the growing complexity and dynamics of the mobile communication networks, accurately predicting key system parameters, such as channel state information (CSI), user location, and network traffic, has become essential for a wide range of physical (PHY)-layer and medium access control (MAC)-layer tasks. Although traditional deep learning (DL)-based methods have been widely applied to such prediction tasks, they often struggle to generalize across different scenarios and tasks. In response, we propose a unified foundation model for multi-task prediction in wireless networks that supports diverse prediction intervals. The proposed model enforces univariate decomposition to unify heterogeneous tasks, encodes granularity for interval awareness, and uses a causal Transformer backbone for accurate predictions. Additionally, we introduce a patch masking strategy during training to support arbitrary input lengths. After trained on large-scale datasets, the proposed foundation model demonstrates strong generalization to unseen scenarios and achieves zero-shot performance on new tasks that surpass traditional full-shot baselines.",
      "authors": [
        "Yucheng Sheng",
        "Jiacheng Wang",
        "Xingyu Zhou",
        "Le Liang",
        "Hao Ye",
        "Shi Jin",
        "Geoffrey Ye Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T12:37:55+00:00",
          "link": "https://arxiv.org/abs/2507.05938v1",
          "size": "388kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T12:45:07+00:00",
          "link": "https://arxiv.org/abs/2507.05938v2",
          "size": "388kb",
          "version": "v2"
        }
      ],
      "title": "A Wireless Foundation Model for Multi-Task Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05938",
        "HTML": "https://arxiv.org/html/2507.05938v2",
        "PDF": "https://arxiv.org/pdf/2507.05938"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presented a foundation model for multi-task predictions in wireless networks, focusing on model architecture and prediction tasks without addressing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05972",
      "abstract": "Pseudoentropy characterizations provide a quantitatively precise demonstration of the close relationship between computational hardness and computational randomness. We prove a unified pseudoentropy characterization that generalizes and strengthens previous results for both uniform and non-uniform models of computation. Our characterization holds for a general family of entropy notions that encompasses the common notions of Shannon entropy and min entropy as special cases. Moreover, we show that the characterizations for different entropy notions can be simultaneously achieved by a single, universal function that simultaneously witnesses computational hardness and computational randomness. A key technical insight of our work is that the notion of weight-restricted calibration from the recent literature on algorithm fairness, along with standard computational indistinguishability (known as multiaccuracy in the fairness literature), suffices for proving pseudoentropy characterizations for general entropy notions. This demonstrates the power of weight-restricted calibration to enhance the classic Complexity-Theoretic Regularity Lemma (Trevisan, Tulsiani, and Vadhan, 2009) and Leakage Simulation Lemma (Jetchev and Pietrzak, 2014) and allows us to achieve an exponential improvement in the complexity dependency on the alphabet size compared to the pseudoentropy characterizations by Casacuberta, Dwork, and Vadhan (2024) based on the much stronger notion of multicalibration. We show that the exponential dependency on the alphabet size is inevitable for multicalibration as well as for the weaker notion of calibrated multiaccuracy.",
      "authors": [
        "Lunjia Hu",
        "Salil Vadhan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Complexity (cs.CC)",
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T13:27:03+00:00",
          "link": "https://arxiv.org/abs/2507.05972v1",
          "size": "33kb",
          "version": "v1"
        }
      ],
      "title": "Generalized and Unified Equivalences between Hardness and Pseudoentropy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05972",
        "HTML": "https://arxiv.org/html/2507.05972",
        "PDF": "https://arxiv.org/pdf/2507.05972"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on pseudoentropy and computational hardness, which are theoretical concepts unrelated to processing or engineering LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06323",
      "abstract": "Large Language Model (LLM) agents face security vulnerabilities spanning AI-specific and traditional software domains, yet current research addresses these separately. This study bridges this gap through comparative evaluation of Function Calling architecture and Model Context Protocol (MCP) deployment paradigms using a unified threat classification framework. We tested 3,250 attack scenarios across seven language models, evaluating simple, composed, and chained attacks targeting both AI-specific threats (prompt injection) and software vulnerabilities (JSON injection, denial-of-service). Function Calling showed higher overall attack success rates (73.5% vs 62.59% for MCP), with greater system-centric vulnerability while MCP exhibited increased LLM-centric exposure. Attack complexity dramatically amplified effectiveness, with chained attacks achieving 91-96% success rates. Counterintuitively, advanced reasoning models demonstrated higher exploitability despite better threat detection. Results demonstrate that architectural choices fundamentally reshape threat landscapes. This work establishes methodological foundations for cross-domain LLM agent security assessment and provides evidence-based guidance for secure deployment. Code and experimental materials are available at https: // github. com/ theconsciouslab-ai/llm-agent-security.",
      "authors": [
        "Tarek Gasmi",
        "Ramzi Guesmi",
        "Ines Belhadj",
        "and Jihene Bennaceur"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T18:24:28+00:00",
          "link": "https://arxiv.org/abs/2507.06323v1",
          "size": "1364kb",
          "version": "v1"
        }
      ],
      "title": "Bridging AI and Software Security: A Comparative Vulnerability Assessment of LLM Agent Deployment Paradigms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06323",
        "PDF": "https://arxiv.org/pdf/2507.06323"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper studies security vulnerabilities in LLM agent deployment, which does not involve processing or engineering of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06710",
      "abstract": "Visual imitation learning is effective for robots to learn versatile tasks. However, many existing methods rely on behavior cloning with supervised historical trajectories, limiting their 3D spatial and 4D spatiotemporal awareness. Consequently, these methods struggle to capture the 3D structures and 4D spatiotemporal relationships necessary for real-world deployment. In this work, we propose 4D Diffusion Policy (DP4), a novel visual imitation learning method that incorporates spatiotemporal awareness into diffusion-based policies. Unlike traditional approaches that rely on trajectory cloning, DP4 leverages a dynamic Gaussian world model to guide the learning of 3D spatial and 4D spatiotemporal perceptions from interactive environments. Our method constructs the current 3D scene from a single-view RGB-D observation and predicts the future 3D scene, optimizing trajectory generation by explicitly modeling both spatial and temporal dependencies. Extensive experiments across 17 simulation tasks with 173 variants and 3 real-world robotic tasks demonstrate that the 4D Diffusion Policy (DP4) outperforms baseline methods, improving the average simulation task success rate by 16.4% (Adroit), 14% (DexArt), and 6.45% (RLBench), and the average real-world robotic task success rate by 8.6%.",
      "authors": [
        "Zhenyang Liu",
        "Yikai Wang",
        "Kuanning Wang",
        "Longfei Liang",
        "Xiangyang Xue",
        "Yanwei Fu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T10:08:15+00:00",
          "link": "https://arxiv.org/abs/2507.06710v1",
          "size": "3412kb",
          "version": "v1"
        }
      ],
      "title": "Spatial-Temporal Aware Visuomotor Diffusion Policy Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06710",
        "HTML": "https://arxiv.org/html/2507.06710v1",
        "PDF": "https://arxiv.org/pdf/2507.06710"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a novel method for visual imitation in robotics, focusing on spatiotemporal awareness rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07034",
      "abstract": "This study presents a surrogate model designed to predict the Nusselt number distribution in an enclosed impinging jet arrays, where each jet function independently and where jets can be transformed from inlets to outlets, leading to a vast number of possible flow arrangements. While computational fluid dynamics (CFD) simulations can model heat transfer with high fidelity, their cost prohibits real-time application such as model-based temperature control. To address this, we generate a CNN-based surrogate model that can predict the Nusselt distribution in real time. We train it with data from implicit large eddy computational fluid dynamics simulations (Re < 2,000). We train two distinct models, one for a five by one array of jets (83 simulations) and one for a three by three array of jets (100 simulations). We introduce a method to extrapolate predictions to higher Reynolds numbers (Re < 10,000) using a correlation-based scaling. The surrogate models achieve high accuracy, with a normalized mean average error below 2% on validation data for the five by one surrogate model and 0.6% for the three by three surrogate model. Experimental validation confirms the model's predictive capabilities. This work provides a foundation for model-based control strategies in advanced thermal management applications.",
      "authors": [
        "Mikael Vaillant",
        "Victor Oliveira Ferreira",
        "Wiebke Mainville",
        "Jean-Michel Lamarre",
        "Vincent Raymond",
        "Moncef Chioua",
        "Bruno Blais"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Fluid Dynamics (physics.flu-dyn)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T17:03:54+00:00",
          "link": "https://arxiv.org/abs/2507.07034v1",
          "size": "2454kb",
          "version": "v1"
        }
      ],
      "title": "Surrogate Model for Heat Transfer Prediction in Impinging Jet Arrays using Dynamic Inlet/Outlet and Flow Rate Control",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07034",
        "HTML": "https://arxiv.org/html/2507.07034v1",
        "PDF": "https://arxiv.org/pdf/2507.07034"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study develops a surrogate model for predicting heat transfer, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.19328",
      "abstract": "While NLP research has made strides in conversational tasks, many approaches focus on single-turn responses with well-defined objectives or evaluation criteria. In contrast, coaching presents unique challenges with initially undefined goals that evolve through multi-turn interactions, subjective evaluation criteria, mixed-initiative dialogue. In this work, we describe and implement five multi-turn coaching agents that exhibit distinct conversational styles, and evaluate them through a user study, collecting first-person feedback on 155 conversations. We find that users highly value core functionality, and that stylistic components in absence of core components are viewed negatively. By comparing user feedback with third-person evaluations from health experts and an LM, we reveal significant misalignment across evaluation approaches. Our findings provide insights into design and evaluation of conversational coaching agents and contribute toward improving human-centered NLP applications.",
      "authors": [
        "Vidya Srinivas",
        "Xuhai Xu",
        "Xin Liu",
        "Kumar Ayush",
        "Isaac Galatzer-Levy",
        "Shwetak Patel",
        "Daniel McDuff",
        "Tim Althoff"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-25T03:44:31+00:00",
          "link": "https://arxiv.org/abs/2503.19328v1",
          "size": "10594kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T23:13:30+00:00",
          "link": "https://arxiv.org/abs/2503.19328v2",
          "size": "906kb",
          "version": "v2"
        }
      ],
      "title": "Substance over Style: Evaluating Proactive Conversational Coaching Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.19328",
        "HTML": "https://arxiv.org/html/2503.19328v2",
        "PDF": "https://arxiv.org/pdf/2503.19328"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper evaluates multi-turn conversational coaching agents, focusing on user feedback and style evaluation, not involving LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2409.14307",
      "abstract": "Model quantization is a promising method for accelerating and compressing diffusion models. Nevertheless, since post-training quantization (PTQ) fails catastrophically at low-bit cases, quantization-aware training (QAT) is essential. Unfortunately, the wide range and time-varying activations in diffusion models sharply increase the complexity of quantization, making existing QAT methods inefficient. Equivalent scaling can effectively reduce activation range, but previous methods remain the overall quantization error unchanged. More critically, these methods significantly disrupt the original weight distribution, resulting in poor weight initialization and challenging convergence during QAT training. In this paper, we propose a novel QAT framework for diffusion models, called DilateQuant. Specifically, we propose Weight Dilation (WD) that maximally dilates the unsaturated in-channel weights to a constrained range through equivalent scaling. WD decreases the activation range while preserving the original weight range, which steadily reduces the quantization error and ensures model convergence. To further enhance accuracy and efficiency, we design a Temporal Parallel Quantizer (TPQ) to address the time-varying activations and introduce a Block-wise Knowledge Distillation (BKD) to reduce resource consumption in training. Extensive experiments demonstrate that DilateQuant significantly outperforms existing methods in terms of accuracy and efficiency. Code is available at http://github.com/BienLuky/DilateQuant .",
      "authors": [
        "Xuewen Liu",
        "Zhikai Li",
        "Minhao Jiang",
        "Mengjuan Chen",
        "Jianquan Li",
        "Qingyi Gu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-22T04:21:29+00:00",
          "link": "https://arxiv.org/abs/2409.14307v1",
          "size": "2680kb",
          "version": "v1"
        },
        {
          "date": "2024-09-25T15:56:46+00:00",
          "link": "https://arxiv.org/abs/2409.14307v2",
          "size": "2680kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T04:40:14+00:00",
          "link": "https://arxiv.org/abs/2409.14307v3",
          "size": "3784kb",
          "version": "v3"
        }
      ],
      "title": "DilateQuant: Accurate and Efficient Diffusion Quantization via Weight Dilation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.14307",
        "HTML": "https://arxiv.org/html/2409.14307v3",
        "PDF": "https://arxiv.org/pdf/2409.14307"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about model quantization techniques for diffusion models, without any focus on the processing or creation of LLM training data."
      },
      "tasks": [
        "Image Generation",
        "Knowledge Distillation",
        "Quantization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06602",
      "abstract": "Modern RAN operate in highly dynamic and heterogeneous environments, where hand-tuned, rule-based RRM algorithms often underperform. While RL can surpass such heuristics in constrained settings, the diversity of deployments and unpredictable radio conditions introduce major generalization challenges. Data-driven policies frequently overfit to training conditions, degrading performance in unseen scenarios. To address this, we propose a generalization-centered RL framework for RAN control that: (i) encodes cell topology and node attributes via attention-based graph representations; (ii) applies domain randomization to broaden the training distribution; and (iii) distributes data generation across multiple actors while centralizing training in a cloud-compatible architecture aligned with O-RAN principles. Although generalization increases computational and data-management complexity, our distributed design mitigates this by scaling data collection and training across diverse network conditions. Applied to downlink link adaptation in five 5G benchmarks, our policy improves average throughput and spectral efficiency by ~10% over an OLLA baseline (10% BLER target) in full-buffer MIMO/mMIMO and by >20% under high mobility. It matches specialized RL in full-buffer traffic and achieves up to 4- and 2-fold gains in eMBB and mixed-traffic benchmarks, respectively. In nine-cell deployments, GAT models offer 30% higher throughput over MLP baselines. These results, combined with our scalable architecture, offer a path toward AI-native 6G RAN using a single, generalizable RL agent.",
      "authors": [
        "Burak Demirel and Yu Wang and Cristian Tatino and Pablo Soldati"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T07:22:22+00:00",
          "link": "https://arxiv.org/abs/2507.06602v1",
          "size": "1450kb",
          "version": "v1"
        }
      ],
      "title": "Generalization in Reinforcement Learning for Radio Access Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06602",
        "HTML": "https://arxiv.org/html/2507.06602v1",
        "PDF": "https://arxiv.org/pdf/2507.06602"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study focuses on reinforcement learning for radio access networks, addressing generalization challenges. It does not discuss LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06739",
      "abstract": "Despite recent progress in video generation, inference speed remains a major bottleneck. A common acceleration strategy involves reusing model outputs via caching mechanisms at fixed intervals. However, we find that such fixed-frequency reuse significantly degrades quality in complex scenes, while manually tuning reuse thresholds is inefficient and lacks robustness. To address this, we propose Prompt-Complexity-Aware (PCA) caching, a method that automatically adjusts reuse thresholds based on scene complexity estimated directly from the input prompt. By incorporating prompt-derived semantic cues, PCA enables more adaptive and informed reuse decisions than conventional caching methods. We also revisit the assumptions behind TeaCache and identify a key limitation: it suffers from poor input-output relationship modeling due to an oversimplified prior. To overcome this, we decouple the noisy input, enhance the contribution of meaningful textual information, and improve the model's predictive accuracy through multivariate polynomial feature expansion. To further reduce computational cost, we replace the static CFGCache with DynCFGCache, a dynamic mechanism that selectively reuses classifier-free guidance (CFG) outputs based on estimated output variations. This allows for more flexible reuse without compromising output quality. Extensive experiments demonstrate that our approach achieves significant acceleration-for example, 2.79x speedup on the Wan2.1 model-while maintaining high visual fidelity across a range of scenes.",
      "authors": [
        "Zishen Huang",
        "Chunyu Yang",
        "Mengyuan Ren"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T10:53:05+00:00",
          "link": "https://arxiv.org/abs/2507.06739v1",
          "size": "17267kb",
          "version": "v1"
        }
      ],
      "title": "PromptTea: Let Prompts Tell TeaCache the Optimal Threshold",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06739",
        "HTML": "https://arxiv.org/html/2507.06739v1",
        "PDF": "https://arxiv.org/pdf/2507.06739"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses improvements in video generation and caching mechanisms, which do not pertain to processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2401.14661",
      "abstract": "Aerial object detection presents challenges from small object sizes, high density clustering, and image quality degradation from distance and motion blur. These factors create an information bottleneck where limited pixel representation cannot encode sufficient discriminative features. B2BDet addresses this with a two-stage framework that applies domain-specific super-resolution during inference, followed by detection using an enhanced YOLOv5 architecture. Unlike training-time super-resolution approaches that enhance learned representations, our method recovers visual information from each input image. The approach combines aerial-optimized SRGAN fine-tuning with architectural innovations including an Efficient Attention Module (EAM) and Cross-Layer Feature Pyramid Network (CLFPN). Evaluation across four aerial datasets shows performance gains, with VisDrone achieving 52.5% mAP using only 27.7M parameters. Ablation studies show that super-resolution preprocessing contributes +2.6% mAP improvement while architectural enhancements add +2.9%, yielding +5.5% total improvement over baseline YOLOv5. The method achieves computational efficiency with 53.8% parameter reduction compared to recent approaches while achieving strong small object detection performance.",
      "authors": [
        "Ragib Amin Nihal",
        "Benjamin Yen",
        "Takeshi Ashizawa",
        "Katsutoshi Itoyama",
        "Kazuhiro Nakadai"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-01-26T05:50:58+00:00",
          "link": "https://arxiv.org/abs/2401.14661v1",
          "size": "35971kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T10:14:26+00:00",
          "link": "https://arxiv.org/abs/2401.14661v2",
          "size": "4526kb",
          "version": "v2"
        }
      ],
      "title": "From Blurry to Brilliant Detection: YOLO-Based Aerial Object Detection with Super Resolution",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.14661",
        "HTML": "https://arxiv.org/html/2401.14661v2",
        "PDF": "https://arxiv.org/pdf/2401.14661"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper addresses aerial object detection with a super resolution approach as pre-processing during inference. It does not focus on LLM training data processing but includes a mention of preprocessing data, albeit in a different context."
      },
      "tasks": [
        "Object",
        "object-detection",
        "Object Detection",
        "Super-Resolution"
      ],
      "source": "arXiv"
    },
    {
      "id": "2402.08801",
      "abstract": "Since its release in November 2022, ChatGPT has shaken up Stack Overflow, the premier platform for developers queries on programming and software development. Demonstrating an ability to generate instant, human-like responses to technical questions, ChatGPT has ignited debates within the developer community about the evolving role of human-driven platforms in the age of generative AI. Two months after ChatGPT release, Meta released its answer with its own Large Language Model (LLM) called LLaMA: the race was on. We conducted an empirical study analyzing questions from Stack Overflow and using these LLMs to address them. This way, we aim to (i) quantify the reliability of LLMs answers and their potential to replace Stack Overflow in the long term; (ii) identify and understand why LLMs fail; (iii) measure users activity evolution with Stack Overflow over time; and (iv) compare LLMs together. Our empirical results are unequivocal: ChatGPT and LLaMA challenge human expertise, yet do not outperform it for some domains, while a significant decline in user posting activity has been observed. Furthermore, we also discuss the impact of our findings regarding the usage and development of new LLMs and provide guidelines for future challenges faced by users and researchers.",
      "authors": [
        "Leuson Da Silva and Jordan Samhi and Foutse Khomh"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-13T21:15:33+00:00",
          "link": "https://arxiv.org/abs/2402.08801v1",
          "size": "1941kb",
          "version": "v1"
        },
        {
          "date": "2025-06-20T17:11:29+00:00",
          "link": "https://arxiv.org/abs/2402.08801v2",
          "size": "1182kb",
          "version": "v2"
        }
      ],
      "title": "LLMs and Stack Overflow Discussions: Reliability, Impact, and Challenges",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.08801",
        "HTML": "https://arxiv.org/html/2402.08801",
        "PDF": "https://arxiv.org/pdf/2402.08801"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on using LLMs to analyze Stack Overflow questions, with main themes on reliability, impact, and challenges of LLM responses. It does not discuss LLM training data processing."
      },
      "tasks": [
        "Language Modelling",
        "Large Language Model"
      ],
      "source": "arXiv"
    },
    {
      "id": "2404.13371",
      "abstract": "This paper studies a risk-sensitive decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.",
      "authors": [
        "Chung-Han Hsieh and Yi-Shan Wong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)",
        "Computational Finance (q-fin.CP)",
        "Methodology (stat.ME)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-20T13:16:05+00:00",
          "link": "https://arxiv.org/abs/2404.13371v1",
          "size": "242kb",
          "version": "v1"
        }
      ],
      "title": "On Risk-Sensitive Decision Making Under Uncertainty",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.13371",
        "HTML": "https://arxiv.org/html/2404.13371",
        "PDF": "https://arxiv.org/pdf/2404.13371"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study addresses risk-sensitive decision-making, with no focus on LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.03108",
      "abstract": "The Federated Learning paradigm facilitates effective distributed machine learning in settings where training data is decentralized across multiple clients. As the popularity of the strategy grows, increasingly complex real-world problems emerge, many of which require balancing conflicting demands such as fairness, utility, and resource consumption. Recent works have begun to recognise the use of a multi-objective perspective in answer to this challenge. However, this novel approach of combining federated methods with multi-objective optimisation has never been discussed in the broader context of both fields. In this work, we offer a first clear and systematic overview of the different ways the two fields can be integrated. We propose a first taxonomy on the use of multi-objective methods in connection with Federated Learning, providing a targeted survey of the state-of-the-art and proposing unambiguous labels to categorise contributions. Given the developing nature of this field, our taxonomy is designed to provide a solid basis for further research, capturing existing works while anticipating future additions. Finally, we outline open challenges and possible directions for further research.",
      "authors": [
        "Maria Hartmann",
        "Gr\\'egoire Danoy",
        "Pascal Bouvry"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-05T12:06:43+00:00",
          "link": "https://arxiv.org/abs/2502.03108v1",
          "size": "832kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T07:55:00+00:00",
          "link": "https://arxiv.org/abs/2502.03108v2",
          "size": "809kb",
          "version": "v2"
        }
      ],
      "title": "Multi-objective methods in Federated Learning: A survey and taxonomy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.03108",
        "HTML": "https://arxiv.org/html/2502.03108v2",
        "PDF": "https://arxiv.org/pdf/2502.03108"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on federated learning and multi-objective optimization, lacking any discussion on LLM training data processing or engineering."
      },
      "tasks": [
        "Fairness",
        "Federated Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.05999",
      "abstract": "Accurate geo-registration of LiDAR point clouds presents significant challenges in GNSS signal denied urban areas with high-rise buildings and bridges. Existing methods typically rely on real-time GNSS and IMU data, that require pre-calibration and assume stable positioning during data collection. However, this assumption often fails in dense urban areas, resulting in localization errors. To address this, we propose a structured geo-registration and spatial correction method that aligns 3D point clouds with satellite images, enabling frame-wise recovery of GNSS information and reconstruction of city scale 3D maps without relying on prior localization. The proposed approach employs a pre-trained Point Transformer model to segment the road points and then extracts the road skeleton and intersection points from the point cloud as well as the target map for alignment. Global rigid alignment of the two is performed using the intersection points, followed by local refinement using radial basis function (RBF) interpolation. Elevation correction is then applied to the point cloud based on terrain information from SRTM dataset to resolve vertical discrepancies. The proposed method was tested on the popular KITTI benchmark and a locally collected Perth (Western Australia) CBD dataset. On the KITTI dataset, our method achieved an average planimetric alignment standard deviation (STD) of 0.84~m across sequences with intersections, representing a 55.3\\% improvement over the original dataset. On the Perth dataset, which lacks GNSS information, our method achieved an average STD of 0.96~m compared to the GPS data extracted from Google Maps API. This corresponds to a 77.4\\% improvement from the initial alignment. Our method also resulted in elevation correlation gains of 30.5\\% on the KITTI dataset and 50.4\\% on the Perth dataset.",
      "authors": [
        "Xinyu Wang",
        "Muhammad Ibrahim",
        "Haitian Wang",
        "Atif Mansoor",
        "Ajmal Mian"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T14:00:18+00:00",
          "link": "https://arxiv.org/abs/2507.05999v1",
          "size": "39199kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T04:44:50+00:00",
          "link": "https://arxiv.org/abs/2507.05999v2",
          "size": "39253kb",
          "version": "v2"
        }
      ],
      "title": "Geo-Registration of Terrestrial LiDAR Point Clouds with Satellite Images without GNSS",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05999",
        "HTML": "https://arxiv.org/html/2507.05999v2",
        "PDF": "https://arxiv.org/pdf/2507.05999"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses geo-registration using LiDAR and satellite data, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06901",
      "abstract": "Multi-dimensional data streams, prevalent in applications like IoT, financial markets, and real-time analytics, pose significant challenges due to their high velocity, unbounded nature, and complex inter-dimensional dependencies. Sliding window techniques are critical for processing such streams, but fixed-size windows struggle to adapt to dynamic changes like concept drift or bursty patterns. This paper proposes a novel reinforcement learning (RL)-based approach to dynamically optimize sliding window sizes for multi-dimensional data streams. By formulating window size selection as an RL problem, we enable an agent to learn an adaptive policy based on stream characteristics, such as variance, correlations, and temporal trends. Our method, RL-Window, leverages a Dueling Deep Q-Network (DQN) with prioritized experience replay to handle non-stationarity and high-dimensionality. Evaluations on benchmark datasets (UCI HAR, PAMAP2, Yahoo! Finance Stream) demonstrate that RL-Window outperforms state-of-the-art methods like ADWIN and CNN-Adaptive in classification accuracy, drift robustness, and computational efficiency. Additional qualitative analyses, extended metrics (e.g., energy efficiency, latency), and a comprehensive dataset characterization further highlight its adaptability and stability, making it suitable for real-time applications.",
      "authors": [
        "Abolfazl Zarghani and Sadegh Abedi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T14:40:35+00:00",
          "link": "https://arxiv.org/abs/2507.06901v1",
          "size": "17kb",
          "version": "v1"
        }
      ],
      "title": "Designing Adaptive Algorithms Based on Reinforcement Learning for Dynamic Optimization of Sliding Window Size in Multi-Dimensional Data Streams",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06901",
        "HTML": "https://arxiv.org/html/2507.06901v1",
        "PDF": "https://arxiv.org/pdf/2507.06901"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is centered around optimizing sliding window sizes in multi-dimensional data streams using reinforcement learning, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.06405",
      "abstract": "The Abstraction and Reasoning Corpus (ARC) is a popular benchmark focused on visual reasoning in the evaluation of Artificial Intelligence systems. In its original framing, an ARC task requires solving a program synthesis problem over small 2D images using a few input-output training pairs. In this work, we adopt the recently popular data-driven approach to the ARC and ask whether a Vision Transformer (ViT) can learn the implicit mapping, from input image to output image, that underlies the task. We show that a ViT -- otherwise a state-of-the-art model for images -- fails dramatically on most ARC tasks even when trained on one million examples per task. This points to an inherent representational deficiency of the ViT architecture that makes it incapable of uncovering the simple structured mappings underlying the ARC tasks. Building on these insights, we propose ViTARC, a ViT-style architecture that unlocks some of the visual reasoning capabilities required by the ARC. Specifically, we use a pixel-level input representation, design a spatially-aware tokenization scheme, and introduce a novel object-based positional encoding that leverages automatic segmentation, among other enhancements. Our task-specific ViTARC models achieve a test solve rate close to 100% on more than half of the 400 public ARC tasks strictly through supervised learning from input-output grids. This calls attention to the importance of imbuing the powerful (Vision) Transformer with the correct inductive biases for abstract visual reasoning that are critical even when the training data is plentiful and the mapping is noise-free. Hence, ViTARC provides a strong foundation for future research in visual reasoning using transformer-based architectures.",
      "authors": [
        "Wenhao Li",
        "Yudong Xu",
        "Scott Sanner",
        "Elias Boutros Khalil"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-08T22:25:34+00:00",
          "link": "https://arxiv.org/abs/2410.06405v1",
          "size": "1314kb",
          "version": "v1"
        }
      ],
      "title": "Tackling the Abstraction and Reasoning Corpus with Vision Transformers: the Importance of 2D Representation, Positions, and Objects",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.06405",
        "HTML": "https://arxiv.org/html/2410.06405",
        "PDF": "https://arxiv.org/pdf/2410.06405"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving Vision Transformer architectures for the Abstraction and Reasoning Corpus tasks, primarily addressing model architecture challenges rather than data processing for LLM training."
      },
      "tasks": [
        "ARC",
        "Program Synthesis",
        "Visual Reasoning"
      ],
      "repo_urls": [
        "https://github.com/khalil-research/ViTARC"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.20865",
      "abstract": "The rapid advancement of generative AI has revolutionized image creation, enabling high-quality synthesis from text prompts while raising critical challenges for media authenticity. We present Ai-GenBench, a novel benchmark designed to address the urgent need for robust detection of AI-generated images in real-world scenarios. Unlike existing solutions that evaluate models on static datasets, Ai-GenBench introduces a temporal evaluation framework where detection methods are incrementally trained on synthetic images, historically ordered by their generative models, to test their ability to generalize to new generative models, such as the transition from GANs to diffusion models. Our benchmark focuses on high-quality, diverse visual content and overcomes key limitations of current approaches, including arbitrary dataset splits, unfair comparisons, and excessive computational demands. Ai-GenBench provides a comprehensive dataset, a standardized evaluation protocol, and accessible tools for both researchers and non-experts (e.g., journalists, fact-checkers), ensuring reproducibility while maintaining practical training requirements. By establishing clear evaluation rules and controlled augmentation strategies, Ai-GenBench enables meaningful comparison of detection methods and scalable solutions. Code and data are publicly available to ensure reproducibility and to support the development of robust forensic detectors to keep pace with the rise of new synthetic generators.",
      "authors": [
        "Lorenzo Pellegrini",
        "Davide Cozzolino",
        "Serafino Pandolfini",
        "Davide Maltoni",
        "Matteo Ferrara",
        "Luisa Verdoliva",
        "Marco Prati",
        "Marco Ramilli"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-29T15:41:13+00:00",
          "link": "https://arxiv.org/abs/2504.20865v1",
          "size": "607kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T15:26:53+00:00",
          "link": "https://arxiv.org/abs/2504.20865v2",
          "size": "608kb",
          "version": "v2"
        }
      ],
      "title": "AI-GenBench: A New Ongoing Benchmark for AI-Generated Image Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.20865",
        "HTML": "https://arxiv.org/html/2504.20865v2",
        "PDF": "https://arxiv.org/pdf/2504.20865"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper presents Ai-GenBench, a benchmark for AI-generated image detection, it does not significantly contribute to LLM training data processing other than suggesting evaluation strategies for multimedia datasets."
      },
      "datasets": [
        {
          "dataset_name": "lrzpellegrini/AI-GenBench-fake_part",
          "downloads": "142",
          "likes": "0",
          "link": "https://huggingface.co/datasets/lrzpellegrini/AI-GenBench-fake_part"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06256",
      "abstract": "This paper investigates the real-world vulnerabilities of audio-based large language models (ALLMs), such as Qwen2-Audio. We first demonstrate that an adversary can craft stealthy audio perturbations to manipulate ALLMs into exhibiting specific targeted behaviors, such as eliciting responses to wake-keywords (e.g., \"Hey Qwen\"), or triggering harmful behaviors (e.g. \"Change my calendar event\"). Subsequently, we show that playing adversarial background noise during user interaction with the ALLMs can significantly degrade the response quality. Crucially, our research illustrates the scalability of these attacks to real-world scenarios, impacting other innocent users when these adversarial noises are played through the air. Further, we discuss the transferrability of the attack, and potential defensive measures.",
      "authors": [
        "Vinu Sankar Sadasivan",
        "Soheil Feizi",
        "Rajiv Mathews",
        "Lun Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T07:29:52+00:00",
          "link": "https://arxiv.org/abs/2507.06256v1",
          "size": "1035kb",
          "version": "v1"
        }
      ],
      "title": "Attacker's Noise Can Manipulate Your Audio-based LLM in the Real World",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06256",
        "HTML": "https://arxiv.org/html/2507.06256v1",
        "PDF": "https://arxiv.org/pdf/2507.06256"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates vulnerabilities and adversarial attacks on audio-based LLMs, without contributing to the processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07066",
      "abstract": "Acoustic mapping techniques have long been used in spatial audio processing for direction of arrival estimation (DoAE). Traditional beamforming methods for acoustic mapping, while interpretable, often rely on iterative solvers that can be computationally intensive and sensitive to acoustic variability. On the other hand, recent supervised deep learning approaches offer feedforward speed and robustness but require large labeled datasets and lack interpretability. Despite their strengths, both methods struggle to consistently generalize across diverse acoustic setups and array configurations, limiting their broader applicability. We introduce the Latent Acoustic Mapping (LAM) model, a self-supervised framework that bridges the interpretability of traditional methods with the adaptability and efficiency of deep learning methods. LAM generates high-resolution acoustic maps, adapts to varying acoustic conditions, and operates efficiently across different microphone arrays. We assess its robustness on DoAE using the LOCATA and STARSS benchmarks. LAM achieves comparable or superior localization performance to existing supervised methods. Additionally, we show that LAM's acoustic maps can serve as effective features for supervised models, further enhancing DoAE accuracy and underscoring its potential to advance adaptive, high-performance sound localization systems.",
      "authors": [
        "Adrian S. Roman and Iran R. Roman and Juan P. Bello"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T03:35:00+00:00",
          "link": "https://arxiv.org/abs/2507.07066v1",
          "size": "753kb",
          "version": "v1"
        }
      ],
      "title": "Latent Acoustic Mapping for Direction of Arrival Estimation: A Self-Supervised Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07066",
        "HTML": "https://arxiv.org/html/2507.07066v1",
        "PDF": "https://arxiv.org/pdf/2507.07066"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on acoustic mapping for direction of arrival estimation using a self-supervised approach, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.08942",
      "abstract": "Reinforcement learning from human feedback (RLHF) has become essential for improving language model capabilities, but traditional approaches rely on the assumption that human preferences follow a transitive Bradley-Terry model. This assumption fails to capture the non-transitive nature of populational human preferences. Nash learning from human feedback (NLHF), targeting non-transitive preferences, is a problem of computing the Nash equilibrium (NE) of the two-player constant-sum game defined by the human preference. We introduce Extragradient preference optimization (EGPO), a novel algorithm for NLHF achieving last-iterate linear convergence to the NE of KL-regularized games and polynomial convergence to the NE of original games, while being robust to noise. Unlike previous approaches that rely on nested optimization, we derive an equivalent implementation using gradients of an online variant of the identity preference optimization (IPO) loss, enabling more faithful implementation for neural networks. Our empirical evaluations demonstrate EGPO's superior performance over baseline methods when training for the same number of epochs, as measured by pairwise win-rates using the ground truth preference. These results validate both the theoretical strengths and practical advantages of EGPO for language model alignment with non-transitive human preferences.",
      "authors": [
        "Runlong Zhou",
        "Maryam Fazel",
        "Simon S. Du"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-11T22:44:54+00:00",
          "link": "https://arxiv.org/abs/2503.08942v1",
          "size": "1772kb",
          "version": "v1"
        },
        {
          "date": "2025-06-08T20:45:39+00:00",
          "link": "https://arxiv.org/abs/2503.08942v2",
          "size": "1768kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T05:35:31+00:00",
          "link": "https://arxiv.org/abs/2503.08942v3",
          "size": "1776kb",
          "version": "v3"
        }
      ],
      "title": "Extragradient Preference Optimization (EGPO): Beyond Last-Iterate Convergence for Nash Learning from Human Feedback",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.08942",
        "HTML": "https://arxiv.org/html/2503.08942v3",
        "PDF": "https://arxiv.org/pdf/2503.08942"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses reinforcement learning from human feedback, but its focus is on algorithmic improvements rather than on processing LLM training data."
      },
      "models": [
        {
          "model_path": "vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-OnlineIPO1-0317153039-epoch-0",
          "downloads": "5",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-OnlineIPO1-0317153039-epoch-0"
        },
        {
          "model_path": "vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-OnlineIPO1-0317153039-epoch-1",
          "downloads": "18",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-OnlineIPO1-0317153039-epoch-1"
        },
        {
          "model_path": "vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-OnlineIPO1-0317153039-epoch-2",
          "downloads": "7",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-OnlineIPO1-0317153039-epoch-2"
        },
        {
          "model_path": "vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-OnlineIPO1-0317153039-epoch-3",
          "downloads": "17",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-OnlineIPO1-0317153039-epoch-3"
        },
        {
          "model_path": "vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-OnlineIPO1-0317153039-epoch-4",
          "downloads": "6",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-OnlineIPO1-0317153039-epoch-4"
        },
        {
          "model_path": "vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-OnlineIPO1-0317153039-epoch-5",
          "downloads": "7",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-OnlineIPO1-0317153039-epoch-5"
        },
        {
          "model_path": "vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-OnlineIPO1-0317153039-epoch-6",
          "downloads": "6",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-OnlineIPO1-0317153039-epoch-6"
        },
        {
          "model_path": "vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-OnlineIPO1-0317153039-epoch-7",
          "downloads": "6",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-OnlineIPO1-0317153039-epoch-7"
        },
        {
          "model_path": "vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-OnlineIPO1-0317153039-epoch-8",
          "downloads": "6",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-OnlineIPO1-0317153039-epoch-8"
        },
        {
          "model_path": "vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-OnlineIPO1-0317153039-epoch-9",
          "downloads": "6",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-OnlineIPO1-0317153039-epoch-9"
        },
        {
          "model_path": "vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-OnlineIPO2-0320211428-epoch-0",
          "downloads": "6",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-OnlineIPO2-0320211428-epoch-0"
        },
        {
          "model_path": "vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-OnlineIPO2-0320211428-epoch-1",
          "downloads": "21",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-OnlineIPO2-0320211428-epoch-1"
        },
        {
          "model_path": "vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-NashMD-0323231936-epoch-0",
          "downloads": "6",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-NashMD-0323231936-epoch-0"
        },
        {
          "model_path": "vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-NashMD-0323231936-epoch-1",
          "downloads": "24",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-NashMD-0323231936-epoch-1"
        },
        {
          "model_path": "vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-NashMD-0323231936-epoch-2",
          "downloads": "19",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-NashMD-0323231936-epoch-2"
        },
        {
          "model_path": "vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-NashMD-0323231936-epoch-3",
          "downloads": "15",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-NashMD-0323231936-epoch-3"
        },
        {
          "model_path": "vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-NashMD-0323231936-epoch-4",
          "downloads": "19",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-NashMD-0323231936-epoch-4"
        },
        {
          "model_path": "vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-NashMD-0323231936-epoch-5",
          "downloads": "7",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-NashMD-0323231936-epoch-5"
        },
        {
          "model_path": "vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-NashMD-0323231936-epoch-6",
          "downloads": "18",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-NashMD-0323231936-epoch-6"
        },
        {
          "model_path": "vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-NashMD-0323231936-epoch-7",
          "downloads": "6",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-NashMD-0323231936-epoch-7"
        },
        {
          "model_path": "vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-NashMD-0323231936-epoch-8",
          "downloads": "6",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-NashMD-0323231936-epoch-8"
        },
        {
          "model_path": "vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-NashMD-0323231936-epoch-9",
          "downloads": "16",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-NashMD-0323231936-epoch-9"
        },
        {
          "model_path": "vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-OnlineIPO2-0320211428-epoch-2",
          "downloads": "7",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-OnlineIPO2-0320211428-epoch-2"
        },
        {
          "model_path": "vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-OnlineIPO2-0320211428-epoch-3",
          "downloads": "22",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-OnlineIPO2-0320211428-epoch-3"
        },
        {
          "model_path": "vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-OnlineIPO2-0320211428-epoch-4",
          "downloads": "6",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-OnlineIPO2-0320211428-epoch-4"
        },
        {
          "model_path": "vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-OnlineIPO2-0320211428-epoch-5",
          "downloads": "7",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-OnlineIPO2-0320211428-epoch-5"
        },
        {
          "model_path": "vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-OnlineIPO2-0320211428-epoch-6",
          "downloads": "7",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-OnlineIPO2-0320211428-epoch-6"
        },
        {
          "model_path": "vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-OnlineIPO2-0320211428-epoch-7",
          "downloads": "7",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-OnlineIPO2-0320211428-epoch-7"
        },
        {
          "model_path": "vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-OnlineIPO2-0320211428-epoch-8",
          "downloads": "6",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-OnlineIPO2-0320211428-epoch-8"
        },
        {
          "model_path": "vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-OnlineIPO2-0320211428-epoch-9",
          "downloads": "6",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-OnlineIPO2-0320211428-epoch-9"
        },
        {
          "model_path": "vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-Extragradient-0504174751-epoch-0",
          "downloads": "15",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-Extragradient-0504174751-epoch-0"
        },
        {
          "model_path": "vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-Extragradient-0504174751-epoch-1",
          "downloads": "5",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-Extragradient-0504174751-epoch-1"
        },
        {
          "model_path": "vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-Extragradient-0504174751-epoch-2",
          "downloads": "4",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-Extragradient-0504174751-epoch-2"
        },
        {
          "model_path": "vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-Extragradient-0504174751-epoch-3",
          "downloads": "4",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-Extragradient-0504174751-epoch-3"
        },
        {
          "model_path": "vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-Extragradient-0504174751-epoch-4",
          "downloads": "3",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-Extragradient-0504174751-epoch-4"
        },
        {
          "model_path": "vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-Extragradient-0504174751-epoch-5",
          "downloads": "5",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-Extragradient-0504174751-epoch-5"
        },
        {
          "model_path": "vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-Extragradient-0504174751-epoch-6",
          "downloads": "4",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-Extragradient-0504174751-epoch-6"
        },
        {
          "model_path": "vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-Extragradient-0504174751-epoch-7",
          "downloads": "7",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-Extragradient-0504174751-epoch-7"
        },
        {
          "model_path": "vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-Extragradient-0504174751-epoch-8",
          "downloads": "6",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-Extragradient-0504174751-epoch-8"
        },
        {
          "model_path": "vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-Extragradient-0504174751-epoch-9",
          "downloads": "2",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/gemma-2-2b-it-alpaca-cleaned-SFT-PKU-SafeRLHF-Extragradient-0504174751-epoch-9"
        },
        {
          "model_path": "vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ction-v0-1-OnlineIPO1-lora-0603201242-epoch-1",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ction-v0-1-OnlineIPO1-lora-0603201242-epoch-1"
        },
        {
          "model_path": "vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ollection-v0-1-NashMD-lora-0603201151-epoch-1",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ollection-v0-1-NashMD-lora-0603201151-epoch-1"
        },
        {
          "model_path": "vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ction-v0-1-OnlineIPO1-lora-0603201242-epoch-2",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ction-v0-1-OnlineIPO1-lora-0603201242-epoch-2"
        },
        {
          "model_path": "vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ction-v0-1-OnlineIPO1-lora-0603201242-epoch-3",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ction-v0-1-OnlineIPO1-lora-0603201242-epoch-3"
        },
        {
          "model_path": "vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ollection-v0-1-NashMD-lora-0603201151-epoch-2",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ollection-v0-1-NashMD-lora-0603201151-epoch-2"
        },
        {
          "model_path": "vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ction-v0-1-OnlineIPO1-lora-0603201242-epoch-4",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ction-v0-1-OnlineIPO1-lora-0603201242-epoch-4"
        },
        {
          "model_path": "vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ction-v0-1-OnlineIPO1-lora-0603201242-epoch-5",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ction-v0-1-OnlineIPO1-lora-0603201242-epoch-5"
        },
        {
          "model_path": "vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ollection-v0-1-NashMD-lora-0603201151-epoch-3",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ollection-v0-1-NashMD-lora-0603201151-epoch-3"
        },
        {
          "model_path": "vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ction-v0-1-OnlineIPO1-lora-0603201242-epoch-6",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ction-v0-1-OnlineIPO1-lora-0603201242-epoch-6"
        },
        {
          "model_path": "vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ction-v0-1-OnlineIPO1-lora-0603201242-epoch-7",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ction-v0-1-OnlineIPO1-lora-0603201242-epoch-7"
        },
        {
          "model_path": "vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ollection-v0-1-NashMD-lora-0603201151-epoch-4",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ollection-v0-1-NashMD-lora-0603201151-epoch-4"
        },
        {
          "model_path": "vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ction-v0-1-OnlineIPO1-lora-0603201242-epoch-8",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ction-v0-1-OnlineIPO1-lora-0603201242-epoch-8"
        },
        {
          "model_path": "vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ction-v0-1-OnlineIPO1-lora-0603201242-epoch-9",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ction-v0-1-OnlineIPO1-lora-0603201242-epoch-9"
        },
        {
          "model_path": "vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ollection-v0-1-NashMD-lora-0603201151-epoch-5",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ollection-v0-1-NashMD-lora-0603201151-epoch-5"
        },
        {
          "model_path": "vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ction-v0-1-OnlineIPO1-lora-0603201242-epoch-10",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ction-v0-1-OnlineIPO1-lora-0603201242-epoch-10"
        },
        {
          "model_path": "vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ction-v0-1-OnlineIPO2-lora-0604063354-epoch-1",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ction-v0-1-OnlineIPO2-lora-0604063354-epoch-1"
        },
        {
          "model_path": "vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ction-v0-1-OnlineIPO2-lora-0604063354-epoch-2",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ction-v0-1-OnlineIPO2-lora-0604063354-epoch-2"
        },
        {
          "model_path": "vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ollection-v0-1-NashMD-lora-0603201151-epoch-6",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ollection-v0-1-NashMD-lora-0603201151-epoch-6"
        },
        {
          "model_path": "vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ction-v0-1-OnlineIPO2-lora-0604063354-epoch-3",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ction-v0-1-OnlineIPO2-lora-0604063354-epoch-3"
        },
        {
          "model_path": "vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ction-v0-1-OnlineIPO2-lora-0604063354-epoch-4",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ction-v0-1-OnlineIPO2-lora-0604063354-epoch-4"
        },
        {
          "model_path": "vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ction-v0-1-OnlineIPO2-lora-0604063354-epoch-5",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ction-v0-1-OnlineIPO2-lora-0604063354-epoch-5"
        },
        {
          "model_path": "vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ollection-v0-1-NashMD-lora-0603201151-epoch-7",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ollection-v0-1-NashMD-lora-0603201151-epoch-7"
        },
        {
          "model_path": "vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ction-v0-1-OnlineIPO2-lora-0604063354-epoch-6",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ction-v0-1-OnlineIPO2-lora-0604063354-epoch-6"
        },
        {
          "model_path": "vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ction-v0-1-OnlineIPO2-lora-0604063354-epoch-7",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ction-v0-1-OnlineIPO2-lora-0604063354-epoch-7"
        },
        {
          "model_path": "vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ction-v0-1-OnlineIPO2-lora-0604063354-epoch-8",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ction-v0-1-OnlineIPO2-lora-0604063354-epoch-8"
        },
        {
          "model_path": "vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ction-v0-1-OnlineIPO2-lora-0604063354-epoch-9",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ction-v0-1-OnlineIPO2-lora-0604063354-epoch-9"
        },
        {
          "model_path": "vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ollection-v0-1-NashMD-lora-0603201151-epoch-8",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ollection-v0-1-NashMD-lora-0603201151-epoch-8"
        },
        {
          "model_path": "vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ction-v0-1-OnlineIPO2-lora-0604063354-epoch-10",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ction-v0-1-OnlineIPO2-lora-0604063354-epoch-10"
        },
        {
          "model_path": "vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-on-v0-1-Extragradient-lora-0604122854-epoch-1",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-on-v0-1-Extragradient-lora-0604122854-epoch-1"
        },
        {
          "model_path": "vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ollection-v0-1-NashMD-lora-0603201151-epoch-9",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ollection-v0-1-NashMD-lora-0603201151-epoch-9"
        },
        {
          "model_path": "vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-on-v0-1-Extragradient-lora-0604122854-epoch-2",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-on-v0-1-Extragradient-lora-0604122854-epoch-2"
        },
        {
          "model_path": "vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ollection-v0-1-NashMD-lora-0603201151-epoch-10",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-ollection-v0-1-NashMD-lora-0603201151-epoch-10"
        },
        {
          "model_path": "vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-on-v0-1-Extragradient-lora-0604122854-epoch-3",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-on-v0-1-Extragradient-lora-0604122854-epoch-3"
        },
        {
          "model_path": "vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-on-v0-1-Extragradient-lora-0604122854-epoch-4",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-on-v0-1-Extragradient-lora-0604122854-epoch-4"
        },
        {
          "model_path": "vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-on-v0-1-Extragradient-lora-0604122854-epoch-5",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-on-v0-1-Extragradient-lora-0604122854-epoch-5"
        },
        {
          "model_path": "vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-on-v0-1-Extragradient-lora-0604122854-epoch-6",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-on-v0-1-Extragradient-lora-0604122854-epoch-6"
        },
        {
          "model_path": "vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-on-v0-1-Extragradient-lora-0604122854-epoch-7",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-on-v0-1-Extragradient-lora-0604122854-epoch-7"
        },
        {
          "model_path": "vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-on-v0-1-Extragradient-lora-0604122854-epoch-8",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-on-v0-1-Extragradient-lora-0604122854-epoch-8"
        },
        {
          "model_path": "vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-on-v0-1-Extragradient-lora-0604122854-epoch-9",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-on-v0-1-Extragradient-lora-0604122854-epoch-9"
        },
        {
          "model_path": "vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-on-v0-1-Extragradient-lora-0604122854-epoch-10",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/vectorzhou/vectorzhou-Qwen2-5-1-5B-Instruct-SFT-OpenHerm-on-v0-1-Extragradient-lora-0604122854-epoch-10"
        }
      ],
      "tasks": [
        "Language Modeling",
        "Language Modelling"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06440",
      "abstract": "This paper addresses the distributed optimization of the finite condition number of the Laplacian matrix in multi-agent systems. The finite condition number, defined as the ratio of the largest to the second smallest eigenvalue of the Laplacian matrix, plays an important role in determining the convergence rate and performance of consensus algorithms, especially in discrete-time implementations. We propose a fully distributed algorithm by regulating the node weights. The approach leverages max consensus, distributed power iteration, and consensus-based normalization for eigenvalue and eigenvector estimation, requiring only local communication and computation. Simulation results demonstrate that the proposed method achieves performance comparable to centralized LMI-based optimization, significantly improving consensus speed and multi-agent system performance. The framework can be extended to edge weight optimization and the scenarios with non-simple eigenvalues, highlighting its scalability and practical applicability for large-scale networked systems.",
      "authors": [
        "Yicheng Xu",
        "Faryar Jabbari"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T22:47:38+00:00",
          "link": "https://arxiv.org/abs/2507.06440v1",
          "size": "12137kb",
          "version": "v1"
        }
      ],
      "title": "Distributed Optimization of Finite Condition Number for Laplacian Matrix in Multi-Agent Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06440",
        "PDF": "https://arxiv.org/pdf/2507.06440"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses distributed optimization in multi-agent systems and does not involve any LLM training data processing or engineering responsibilities."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06671",
      "abstract": "3D Gaussian splatting has become a prominent technique for representing and rendering complex 3D scenes, due to its high fidelity and speed advantages. However, the growing demand for large-scale models calls for effective compression to reduce memory and computation costs, especially on mobile and edge devices with limited resources. Existing compression methods effectively reduce 3D Gaussian parameters but often require extensive retraining or fine-tuning, lacking flexibility under varying compression constraints.\n  In this paper, we introduce FlexGaussian, a flexible and cost-effective method that combines mixed-precision quantization with attribute-discriminative pruning for training-free 3D Gaussian compression. FlexGaussian eliminates the need for retraining and adapts easily to diverse compression targets. Evaluation results show that FlexGaussian achieves up to 96.4% compression while maintaining high rendering quality (<1 dB drop in PSNR), and is deployable on mobile devices. FlexGaussian delivers high compression ratios within seconds, being 1.7-2.1x faster than state-of-the-art training-free methods and 10-100x faster than training-involved approaches. The code is being prepared and will be released soon at: https://github.com/Supercomputing-System-AI-Lab/FlexGaussian",
      "authors": [
        "Boyuan Tian",
        "Qizhe Gao",
        "Siran Xianyu",
        "Xiaotong Cui",
        "Minjia Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T09:00:52+00:00",
          "link": "https://arxiv.org/abs/2507.06671v1",
          "size": "15322kb",
          "version": "v1"
        }
      ],
      "title": "FlexGaussian: Flexible and Cost-Effective Training-Free Compression for 3D Gaussian Splatting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06671",
        "HTML": "https://arxiv.org/html/2507.06671v1",
        "PDF": "https://arxiv.org/pdf/2507.06671"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work introduces a method for compressing 3D Gaussian splatting models, focusing on model compression rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2306.08418",
      "abstract": "The online advertising market has recently reached the 500 billion dollar mark. To accommodate the need to match a user with the highest bidder at a fraction of a second, it has moved towards a complex, automated and often opaque model that involves numerous agents and intermediaries. Stimulated by the lack of transparency, but also the enormous potential profits, bad actors have found ways to circumvent restrictions, and generate substantial revenue that can support websites with objectionable or even illegal content.\n  In this work, we evaluate transparency Web standards and show how shady actors take advantage of gaps to absorb ad revenues while putting the brand safety of advertisers in danger. We collect and study a large corpus of thousands of websites and show how ad transparency standards can be abused by bad actors to obscure ad revenue flows. We show how identifier pooling can redirect ad revenues from reputable domains to notorious domains serving objectionable content, and that the phenomenon is underestimated by previous studies by a factor of 15. Finally, we publish a Web monitoring service that enhances the transparency of supply chains and business relationships between publishers and ad networks.",
      "authors": [
        "Emmanouil Papadogiannakis",
        "Nicolas Kourtellis",
        "Panagiotis Papadopoulos",
        "Evangelos P. Markatos"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2023-06-14T10:28:07+00:00",
          "link": "https://arxiv.org/abs/2306.08418v1",
          "size": "679kb",
          "version": "v1"
        },
        {
          "date": "2024-10-18T11:58:06+00:00",
          "link": "https://arxiv.org/abs/2306.08418v2",
          "size": "638kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T08:57:17+00:00",
          "link": "https://arxiv.org/abs/2306.08418v3",
          "size": "335kb",
          "version": "v3"
        }
      ],
      "title": "Welcome to the Dark Side: Analyzing the Revenue Flows of Fraud in the Online Ad Ecosystem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2306.08418",
        "HTML": "https://arxiv.org/html/2306.08418v3",
        "PDF": "https://arxiv.org/pdf/2306.08418"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the analysis of revenue flows in online advertising and does not discuss any aspect of LLM training data collection, processing, or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06606",
      "abstract": "Medical Hyperspectral Imaging (MHSI) has emerged as a promising tool for enhanced disease diagnosis, particularly in computational pathology, offering rich spectral information that aids in identifying subtle biochemical properties of tissues. Despite these advantages, effectively fusing both spatial-dimensional and spectral-dimensional information from MHSIs remains challenging due to its high dimensionality and spectral redundancy inherent characteristics. To solve the above challenges, we propose a novel spatial-spectral omni-fusion network for hyperspectral image segmentation, named as Omni-Fuse. Here, we introduce abundant cross-dimensional feature fusion operations, including a cross-dimensional enhancement module that refines both spatial and spectral features through bidirectional attention mechanisms, a spectral-guided spatial query selection to select the most spectral-related spatial feature as the query, and a two-stage cross-dimensional decoder which dynamically guide the model to focus on the selected spatial query. Despite of numerous attention blocks, Omni-Fuse remains efficient in execution. Experiments on two microscopic hyperspectral image datasets show that our approach can significantly improve the segmentation performance compared with the state-of-the-art methods, with over 5.73 percent improvement in DSC. Code available at: https://github.com/DeepMed-Lab-ECNU/Omni-Fuse.",
      "authors": [
        "Qing Zhang",
        "Guoquan Pei",
        "Yan Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T07:25:18+00:00",
          "link": "https://arxiv.org/abs/2507.06606v1",
          "size": "1848kb",
          "version": "v1"
        }
      ],
      "title": "Omni-Fusion of Spatial and Spectral for Hyperspectral Image Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06606",
        "HTML": "https://arxiv.org/html/2507.06606v1",
        "PDF": "https://arxiv.org/pdf/2507.06606"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper's focus is on hyperspectral image segmentation using a novel spatial-spectral omni-fusion network, with no mention of LLM training data processing or relevant techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06618",
      "abstract": "In this paper, we propose view-dependent projection (VDP) to facilitate point cloud segmentation, designing efficient 3D-to-2D mapping that dynamically adapts to the spatial geometry from view variations. Existing projection-based methods leverage view-independent projection in complex scenes, relying on straight lines to generate direct rays or upward curves to reduce occlusions. However, their view independence provides projection rays that are limited to pre-defined parameters by human settings, restricting point awareness and failing to capture sufficient projection diversity across different view planes. Although multiple projections per view plane are commonly used to enhance spatial variety, the projected redundancy leads to excessive computational overhead and inefficiency in image processing. To address these limitations, we design a framework of VDP to generate data-driven projections from 3D point distributions, producing highly informative single-image inputs by predicting rays inspired by the adaptive behavior of fireworks. In addition, we construct color regularization to optimize the framework, which emphasizes essential features within semantic pixels and suppresses the non-semantic features within black pixels, thereby maximizing 2D space utilization in a projected image. As a result, our approach, PointVDP, develops lightweight projections in marginal computation costs. Experiments on S3DIS and ScanNet benchmarks show that our approach achieves competitive results, offering a resource-efficient solution for semantic understanding.",
      "authors": [
        "Yang Chen",
        "Yueqi Duan",
        "Haowen Sun",
        "Ziwei Wang",
        "Jiwen Lu",
        "Yap-Peng Tan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T07:44:00+00:00",
          "link": "https://arxiv.org/abs/2507.06618v1",
          "size": "853kb",
          "version": "v1"
        }
      ],
      "title": "PointVDP: Learning View-Dependent Projection by Fireworks Rays for 3D Point Cloud Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06618",
        "HTML": "https://arxiv.org/html/2507.06618v1",
        "PDF": "https://arxiv.org/pdf/2507.06618"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on improving point cloud segmentation through view-dependent projections, which does not include LLM training data processing or the creation of new datasets for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06721",
      "abstract": "Let $G=(V, E)$ be an undirected $n$-vertices $m$-edges graph with non-negative edge weights. In this paper, we present three new algorithms for constructing a $(2k-1)$-stretch distance oracle with $O(n^{1+\\frac{1}{k}})$ space. The first algorithm runs in $\\Ot(\\max(n^{1+2/k}, m^{1-\\frac{1}{k-1}}n^{\\frac{2}{k-1}}))$ time, and improves upon the $\\Ot(\\min(mn^{\\frac{1}{k}},n^2))$ time of Thorup and Zwick [STOC 2001, JACM 2005] and Baswana and Kavitha [FOCS 2006, SICOMP 2010], for every $k > 2$ and $m=\\Omega(n^{1+\\frac{1}{k}+\\eps})$. This yields the first truly subquadratic time construction for every $2 < k < 6$, and nearly resolves the open problem posed by Wulff-Nilsen [SODA 2012] on the existence of such constructions.\n  The two other algorithms have a running time of the form $\\Ot(m+n^{1+f(k)})$, which is near linear in $m$ if $m=\\Omega(n^{1+f(k)})$, and therefore optimal in such graphs. One algorithm runs in $\\Ot(m+n^{\\frac32+\\frac{3}{4k-6}})$-time, which improves upon the $\\Ot(n^2)$-time algorithm of Baswana and Kavitha [FOCS 2006, SICOMP 2010], for $3 < k < 6$, and upon the $\\Ot(m+n^{\\frac{3}{2}+\\frac{2}{k}+O(k^{-2})})$-time algorithm of Wulff-Nilsen [SODA 2012], for every $k\\geq 6$. This is the first linear time algorithm for constructing a $7$-stretch distance oracle and a $9$-stretch distance oracle, for graphs with truly subquadratic density.\\footnote{with $m=n^{2-\\eps}$ for some $\\eps > 0$.} The other algorithm runs in $\\Ot(\\sqrt{k}m+kn^{1+\\frac{2\\sqrt{2}}{\\sqrt{k}}})$ time, (and hence relevant only for $k\\ge 16$), and improves upon the $\\Ot(\\sqrt{k}m+kn^{1+\\frac{2\\sqrt{6}}{\\sqrt{k}}+O(k^{-1})})$ time algorithm of Wulff-Nilsen [SODA 2012] (which is relevant only for $k\\ge 96$). ...",
      "authors": [
        "Avi Kadria and Liam Roditty"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T10:22:48+00:00",
          "link": "https://arxiv.org/abs/2507.06721v1",
          "size": "39kb",
          "version": "v1"
        }
      ],
      "title": "Faster Algorithms for $(2k-1)$-Stretch Distance Oracles",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06721",
        "HTML": "https://arxiv.org/html/2507.06721v1",
        "PDF": "https://arxiv.org/pdf/2507.06721"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents algorithms for constructing distance oracles in graphs, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06782",
      "abstract": "The rapid expansion of digital information and knowledge across structured and unstructured sources has heightened the importance of Information Retrieval (IR). While dense retrieval methods have substantially improved semantic matching for general queries, they consistently underperform on queries with explicit temporal constraints--often those containing numerical expressions and time specifiers such as ``in 2015.'' Existing approaches to Temporal Information Retrieval (TIR) improve temporal reasoning but often suffer from catastrophic forgetting, leading to reduced performance on non-temporal queries. To address this, we propose Time-Specifier Model Merging (TSM), a novel method that enhances temporal retrieval while preserving accuracy on non-temporal queries. TSM trains specialized retrievers for individual time specifiers and merges them in to a unified model, enabling precise handling of temporal constraints without compromising non-temporal retrieval. Extensive experiments on both temporal and non-temporal datasets demonstrate that TSM significantly improves performance on temporally constrained queries while maintaining strong results on non-temporal queries, consistently outperforming other baseline methods. Our code is available at https://github.com/seungyoonee/TSM .",
      "authors": [
        "SeungYoon Han",
        "Taeho Hwang",
        "Sukmin Cho",
        "Soyeong Jeong",
        "Hoyun Song",
        "Huije Lee",
        "Jong C. Park"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T12:16:11+00:00",
          "link": "https://arxiv.org/abs/2507.06782v1",
          "size": "179kb",
          "version": "v1"
        }
      ],
      "title": "Temporal Information Retrieval via Time-Specifier Model Merging",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06782",
        "HTML": "https://arxiv.org/html/2507.06782v1",
        "PDF": "https://arxiv.org/pdf/2507.06782"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses temporal information retrieval with model merging, and does not contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.12981",
      "abstract": "Gaze estimation encounters generalization challenges when dealing with out-of-distribution data. To address this problem, recent methods use neural radiance fields (NeRF) to generate augmented data. However, existing methods based on NeRF are computationally expensive and lack facial details. 3D Gaussian Splatting (3DGS) has become the prevailing representation of neural fields. While 3DGS has been extensively examined in head avatars, it faces challenges with accurate gaze control and generalization across different subjects. In this work, we propose GazeGaussian, the first high-fidelity gaze redirection method that uses a two-stream 3DGS model to represent the face and eye regions separately. Leveraging the unstructured nature of 3DGS, we develop a novel representation of the eye for rigid eye rotation based on the target gaze direction. To enable synthesis generalization across various subjects, we integrate an expression-guided module to inject subject-specific information into the neural renderer. Comprehensive experiments show that GazeGaussian outperforms existing methods in rendering speed, gaze redirection accuracy, and facial synthesis across multiple datasets. The code is available at: https://ucwxb.github.io/GazeGaussian.",
      "authors": [
        "Xiaobao Wei",
        "Peng Chen",
        "Guangyu Li",
        "Ming Lu",
        "Hui Chen",
        "Feng Tian"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-20T02:15:23+00:00",
          "link": "https://arxiv.org/abs/2411.12981v1",
          "size": "7411kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T02:41:35+00:00",
          "link": "https://arxiv.org/abs/2411.12981v2",
          "size": "7411kb",
          "version": "v2"
        }
      ],
      "title": "GazeGaussian: High-Fidelity Gaze Redirection with 3D Gaussian Splatting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.12981",
        "HTML": "https://arxiv.org/html/2411.12981v2",
        "PDF": "https://arxiv.org/pdf/2411.12981"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on gaze redirection and rendering techniques using 3D Gaussian Splatting, without discussing LLM training data processing or improving dataset quality for LLMs."
      },
      "tasks": [
        "3DGS",
        "Gaze Estimation",
        "gaze redirection",
        "NeRF"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.17953",
      "abstract": "This pilot study presents a novel, automated, and scalable methodology for detecting and evaluating subsurface defect-prone regions in concrete slabs using Impact Echo (IE) signal analysis. The approach integrates advanced signal processing, clustering, and visual analytics to identify subsurface anomalies. A unique adaptive thresholding method tailors frequency-based defect identification to the distinct material properties of each slab. The methodology generates frequency maps, binary masks, and k-means cluster maps to automatically classify defect and non-defect regions. Key visualizations, including 3D surface plots, cluster maps, and contour plots, are employed to analyze spatial frequency distributions and highlight structural anomalies. The study utilizes a labeled dataset constructed at the Federal Highway Administration (FHWA) Advanced Sensing Technology Nondestructive Evaluation Laboratory. Evaluations involve ground-truth masking, comparing the generated defect maps with top-view binary masks derived from the information provided by the FHWA. The performance metrics, specifically F1-scores and AUC-ROC, achieve values of up to 0.95 and 0.83, respectively. The results demonstrate the robustness of the methodology, consistently identifying defect-prone areas with minimal false positives and few missed defects. Adaptive frequency thresholding ensures flexibility in addressing variations across slabs, providing a scalable framework for detecting structural anomalies. Additionally, the methodology is adaptable to other frequency-based signals due to its generalizable thresholding mechanism and holds potential for integrating multimodal sensor fusion. This automated and scalable pipeline minimizes manual intervention, ensuring accurate and efficient defect detection, further advancing Non-Destructive Evaluation (NDE) techniques.",
      "authors": [
        "Deepthi Pavurala",
        "Duoduo Liao",
        "and Chaithra Reddy Pasunuru"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-23T20:05:53+00:00",
          "link": "https://arxiv.org/abs/2412.17953v1",
          "size": "12737kb",
          "version": "v1"
        }
      ],
      "title": "Adaptive Signal Analysis for Automated Subsurface Defect Detection Using Impact Echo in Concrete Slabs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.17953",
        "HTML": "https://arxiv.org/html/2412.17953",
        "PDF": "https://arxiv.org/pdf/2412.17953"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on using signal processing and other techniques for defect detection in concrete slabs, with no mention of LLM training data processing or data engineering methods relevant to LLMs."
      },
      "tasks": [
        "Defect Detection",
        "Sensor Fusion"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.18558",
      "abstract": "Machine learning has become essential for automated classification of astronomical transients, but current approaches face significant limitations: classifiers trained on simulations struggle with real data, models developed for one survey cannot be easily applied to another, and new surveys require prohibitively large amounts of labelled training data. These challenges are particularly pressing as we approach the era of the Vera C. Rubin Observatory's Legacy Survey of Space and Time (LSST), where existing classification models will need to be retrained using LSST observations. We demonstrate that transfer learning can overcome these challenges by repurposing existing models trained on either simulations or data from other surveys. Starting with a model trained on simulated Zwicky Transient Facility (ZTF) light curves, we show that transfer learning reduces the amount of labelled real ZTF transients needed by 95% while maintaining equivalent performance to models trained from scratch. Similarly, when adapting ZTF models for LSST simulations, transfer learning achieves 94% of the baseline performance while requiring only 30% of the training data. These findings have significant implications for the early operations of LSST, suggesting that reliable automated classification will be possible soon after the survey begins, rather than waiting months or years to accumulate sufficient training data.",
      "authors": [
        "Rithwik Gupta",
        "Daniel Muthukrishna",
        "Nabeel Rehemtulla",
        "Ved Shah"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
        "High Energy Astrophysical Phenomena (astro-ph.HE)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-25T19:00:00+00:00",
          "link": "https://arxiv.org/abs/2502.18558v1",
          "size": "345kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T22:27:42+00:00",
          "link": "https://arxiv.org/abs/2502.18558v2",
          "size": "352kb",
          "version": "v2"
        }
      ],
      "title": "Transfer Learning for Transient Classification: From Simulations to Real Data and ZTF to LSST",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.18558",
        "HTML": "https://arxiv.org/html/2502.18558v2",
        "PDF": "https://arxiv.org/pdf/2502.18558"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on transfer learning for classification of astronomical transients, specifically using simulations and real data, without discussing any LLM training data processing."
      },
      "tasks": [
        "Survey",
        "Transfer Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.01945",
      "abstract": "Animation colorization is a crucial part of real animation industry production. Long animation colorization has high labor costs. Therefore, automated long animation colorization based on the video generation model has significant research value. Existing studies are limited to short-term colorization. These studies adopt a local paradigm, fusing overlapping features to achieve smooth transitions between local segments. However, the local paradigm neglects global information, failing to maintain long-term color consistency. In this study, we argue that ideal long-term color consistency can be achieved through a dynamic global-local paradigm, i.e., dynamically extracting global color-consistent features relevant to the current generation. Specifically, we propose LongAnimation, a novel framework, which mainly includes a SketchDiT, a Dynamic Global-Local Memory (DGLM), and a Color Consistency Reward. The SketchDiT captures hybrid reference features to support the DGLM module. The DGLM module employs a long video understanding model to dynamically compress global historical features and adaptively fuse them with the current generation features. To refine the color consistency, we introduce a Color Consistency Reward. During inference, we propose a color consistency fusion to smooth the video segment transition. Extensive experiments on both short-term (14 frames) and long-term (average 500 frames) animations show the effectiveness of LongAnimation in maintaining short-term and long-term color consistency for open-domain animation colorization task. The code can be found at https://cn-makers.github.io/long_animation_web/.",
      "authors": [
        "Nan Chen",
        "Mengqi Huang",
        "Yihao Meng",
        "Zhendong Mao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T17:55:50+00:00",
          "link": "https://arxiv.org/abs/2507.01945v1",
          "size": "16260kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T16:30:21+00:00",
          "link": "https://arxiv.org/abs/2507.01945v2",
          "size": "16260kb",
          "version": "v2"
        }
      ],
      "title": "LongAnimation: Long Animation Generation with Dynamic Global-Local Memory",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01945",
        "HTML": "https://arxiv.org/html/2507.01945v2",
        "PDF": "https://arxiv.org/pdf/2507.01945"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is centered on animation colorization, proposing a new framework for long animations and does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.04981",
      "abstract": "T cell receptor (TCR) repertoires encode critical immunological signatures for autoimmune diseases, yet their clinical application remains limited by sequence sparsity and low witness rates. We developed EAMil, a multi-instance deep learning framework that leverages TCR sequencing data to diagnose systemic lupus erythematosus (SLE) and rheumatoid arthritis (RA) with exceptional accuracy. By integrating PrimeSeq feature extraction with ESMonehot encoding and enhanced gate attention mechanisms, our model achieved state-of-the-art performance with AUCs of 98.95% for SLE and 97.76% for RA. EAMil successfully identified disease-associated genes with over 90% concordance with established differential analyses and effectively distinguished disease-specific TCR genes. The model demonstrated robustness in classifying multiple disease categories, utilizing the SLEDAI score to stratify SLE patients by disease severity as well as to diagnose the site of damage in SLE patients, and effectively controlling for confounding factors such as age and gender. This interpretable framework for immune receptor analysis provides new insights for autoimmune disease detection and classification with broad potential clinical applications across immune-mediated conditions.",
      "authors": [
        "Ruihao Zhang",
        "Mao chen",
        "Fei Ye",
        "Dandan Meng",
        "Yixuan Huang",
        "Xiao Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Genomics (q-bio.GN)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T13:24:41+00:00",
          "link": "https://arxiv.org/abs/2507.04981v1",
          "size": "1033kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T14:28:38+00:00",
          "link": "https://arxiv.org/abs/2507.04981v2",
          "size": "1045kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T07:33:59+00:00",
          "link": "https://arxiv.org/abs/2507.04981v3",
          "size": "1101kb",
          "version": "v3"
        }
      ],
      "title": "Classification of autoimmune diseases from Peripheral blood TCR repertoires by multimodal multi-instance learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.04981",
        "PDF": "https://arxiv.org/pdf/2507.04981"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a deep learning framework for diagnosing autoimmune diseases using TCR sequencing data, with no mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06399",
      "abstract": "This paper presents a multipurpose artificial intelligence (AI)-driven thermal-fluid testbed designed to advance Small Modular Reactor technologies by seamlessly integrating physical experimentation with advanced computational intelligence. The platform uniquely combines a versatile three-loop thermal-fluid facility with a high-fidelity digital twin and sophisticated AI frameworks for real-time prediction, control, and operational assistance. Methodologically, the testbed's digital twin, built upon the System Analysis Module code, is coupled with a Gated Recurrent Unit (GRU) neural network. This machine learning model, trained on experimental data, enables faster-than-real-time simulation, providing predictive insights into the system's dynamic behavior. The practical application of this AI integration is showcased through case studies. An AI-driven control framework where the GRU model accurately forecasts future system states and the corresponding control actions required to meet operational demands. Furthermore, an intelligent assistant, powered by a large language model, translates complex sensor data and simulation outputs into natural language, offering operators actionable analysis and safety recommendations. Comprehensive validation against experimental transients confirms the platform's high fidelity, with the GRU model achieving a temperature prediction root mean square error of 1.42 K. This work establishes an integrated research environment at the intersection of AI and thermal-fluid science, showcasing how AI-driven methodologies in modeling, control, and operator support can accelerate the innovation and deployment of next-generation nuclear systems.",
      "authors": [
        "Doyeong Lim",
        "Yang Liu",
        "Zavier Ndum Ndum",
        "Christian Young",
        "Yassin Hassan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Artificial Intelligence (cs.AI)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T21:07:30+00:00",
          "link": "https://arxiv.org/abs/2507.06399v1",
          "size": "3941kb",
          "version": "v1"
        }
      ],
      "title": "An AI-Driven Thermal-Fluid Testbed for Advanced Small Modular Reactors: Integration of Digital Twin and Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06399",
        "HTML": "https://arxiv.org/html/2507.06399v1",
        "PDF": "https://arxiv.org/pdf/2507.06399"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper centers on utilizing AI for thermal-fluid tests in reactors and does not address LLM training data processing or data engineering operations for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06829",
      "abstract": "Recent advances in large language models (LLMs) have accelerated progress toward artificial general intelligence, with inference-time scaling emerging as a key technique. Contemporary approaches leverage either sequential reasoning (iteratively extending chains of thought) or parallel reasoning (generating multiple solutions simultaneously) to scale inference. However, both paradigms face fundamental limitations: sequential scaling typically relies on arbitrary token budgets for termination, leading to inefficiency or premature cutoff; while parallel scaling often lacks coordination among parallel branches and requires intrusive fine-tuning to perform effectively. In light of these challenges, we aim to design a flexible test-time collaborative inference framework that exploits the complementary strengths of both sequential and parallel reasoning paradigms. Towards this goal, the core challenge lies in developing an efficient and accurate intrinsic quality metric to assess model responses during collaborative inference, enabling dynamic control and early termination of the reasoning trace. To address this challenge, we introduce semantic entropy (SE), which quantifies the semantic diversity of parallel model responses and serves as a robust indicator of reasoning quality due to its strong negative correlation with accuracy...",
      "authors": [
        "Zenan Xu",
        "Zexuan Qiu",
        "Guanhua Huang",
        "Kun Li",
        "Siheng Li",
        "Chenchen Zhang",
        "Kejiao Li",
        "Qi Yi",
        "Yuhao Jiang",
        "Bo Zhou",
        "Fengzong Lian",
        "Zhanhui Kang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T13:28:35+00:00",
          "link": "https://arxiv.org/abs/2507.06829v1",
          "size": "471kb",
          "version": "v1"
        }
      ],
      "title": "Adaptive Termination for Multi-round Parallel Reasoning: An Universal Semantic Entropy-Guided Framework",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06829",
        "PDF": "https://arxiv.org/pdf/2507.06829"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving inference techniques for LLMs during test time using semantic entropy for quality assessment, not on data processing for training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06892",
      "abstract": "Reinforcement Learning (RL) has demonstrated its potential to improve the reasoning ability of Large Language Models (LLMs). One major limitation of most existing Reinforcement Finetuning (RFT) methods is that they are on-policy RL in nature, i.e., data generated during the past learning process is not fully utilized. This inevitably comes at a significant cost of compute and time, posing a stringent bottleneck on continuing economic and efficient scaling. To this end, we launch the renaissance of off-policy RL and propose Reincarnating Mix-policy Proximal Policy Gradient (ReMix), a general approach to enable on-policy RFT methods like PPO and GRPO to leverage off-policy data. ReMix consists of three major components: (1) Mix-policy proximal policy gradient with an increased Update-To-Data (UTD) ratio for efficient training; (2) KL-Convex policy constraint to balance the trade-off between stability and flexibility; (3) Policy reincarnation to achieve a seamless transition from efficient early-stage learning to steady asymptotic improvement. In our experiments, we train a series of ReMix models upon PPO, GRPO and 1.5B, 7B base models. ReMix shows an average Pass@1 accuracy of 52.10% (for 1.5B model) with 0.079M response rollouts, 350 training steps and achieves 63.27%/64.39% (for 7B model) with 0.007M/0.011M response rollouts, 50/75 training steps, on five math reasoning benchmarks (i.e., AIME'24, AMC'23, Minerva, OlympiadBench, and MATH500). Compared with 15 recent advanced models, ReMix shows SOTA-level performance with an over 30x to 450x reduction in training cost in terms of rollout data volume. In addition, we reveal insightful findings via multifaceted analysis, including the implicit preference for shorter responses due to the Whipping Effect of off-policy discrepancy, the collapse mode of self-reflection behavior under the presence of severe off-policyness, etc.",
      "authors": [
        "Jing Liang",
        "Hongyao Tang",
        "Yi Ma",
        "Jinyi Liu",
        "Yan Zheng",
        "Shuyue Hu",
        "Lei Bai",
        "Jianye Hao"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T14:29:45+00:00",
          "link": "https://arxiv.org/abs/2507.06892v1",
          "size": "519kb",
          "version": "v1"
        }
      ],
      "title": "Squeeze the Soaked Sponge: Efficient Off-policy Reinforcement Finetuning for Large Language Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06892",
        "HTML": "https://arxiv.org/html/2507.06892v1",
        "PDF": "https://arxiv.org/pdf/2507.06892"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses reinforcement finetuning methods for LLMs but focuses on model training techniques rather than data processing or dataset creation for LLMs. It mentions data generated from past learning but does not elaborate on data processing improvements."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07017",
      "abstract": "Reinforcement Learning from Verifiable Rewards (RLVR) improves the reasoning abilities of Large Language Models (LLMs) but it struggles with unstable exploration. We propose FR3E (First Return, Entropy-Eliciting Explore), a structured exploration framework that identifies high-uncertainty decision points in reasoning trajectories and performs targeted rollouts to construct semantically grounded intermediate feedback. Our method provides targeted guidance without relying on dense supervision. Empirical results on mathematical reasoning benchmarks(AIME24) show that FR3E promotes more stable training, produces longer and more coherent responses, and increases the proportion of fully correct trajectories. These results highlight the framework's effectiveness in improving LLM reasoning through more robust and structured exploration.",
      "authors": [
        "Tianyu Zheng",
        "Tianshun Xing",
        "Qingshui Gu",
        "Taoran Liang",
        "Xingwei Qu",
        "Xin Zhou",
        "Yizhi Li",
        "Zhoufutu Wen",
        "Chenghua Lin",
        "Wenhao Huang",
        "Qian Liu",
        "Ge Zhang",
        "and Zejun Ma"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T16:45:48+00:00",
          "link": "https://arxiv.org/abs/2507.07017v1",
          "size": "4339kb",
          "version": "v1"
        }
      ],
      "title": "First Return, Entropy-Eliciting Explore",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07017",
        "HTML": "https://arxiv.org/html/2507.07017v1",
        "PDF": "https://arxiv.org/pdf/2507.07017"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a framework for improving LLM reasoning through exploration strategies, not on processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07073",
      "abstract": "The spectrum of the Laplace-Beltrami (LB) operator is central in geometric deep learning tasks, capturing intrinsic properties of the shape of the object under consideration. The best established method for its estimation, from a triangulated mesh of the object, is based on the Finite Element Method (FEM), and computes the top k LB eigenvalues with a complexity of O(Nk), where N is the number of points. This can render the FEM method inefficient when repeatedly applied to databases of CAD mechanical parts, or in quality control applications where part metrology is acquired as large meshes and decisions about the quality of each part are needed quickly and frequently. As a solution to this problem, we present a geometric deep learning framework to predict the LB spectrum efficiently given the CAD mesh of a part, achieving significant computational savings without sacrificing accuracy, demonstrating that the LB spectrum is learnable. The proposed Graph Neural Network architecture uses a rich set of part mesh features - including Gaussian curvature, mean curvature, and principal curvatures. In addition to our trained network, we make available, for repeatability, a large curated dataset of real-world mechanical CAD models derived from the publicly available ABC dataset used for training and testing. Experimental results show that our method reduces computation time of the LB spectrum by approximately 5 times over linear FEM while delivering competitive accuracy.",
      "authors": [
        "Yulin An and Enrique del Castillo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T17:31:18+00:00",
          "link": "https://arxiv.org/abs/2507.07073v1",
          "size": "2096kb",
          "version": "v1"
        }
      ],
      "title": "An AI Approach for Learning the Spectrum of the Laplace-Beltrami Operator",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07073",
        "HTML": "https://arxiv.org/html/2507.07073v1",
        "PDF": "https://arxiv.org/pdf/2507.07073"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper focuses on a geometric deep learning framework for predicting the spectrum of the Laplace-Beltrami operator, mentioning a new dataset derived from an existing dataset but not primarily discussing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06268",
      "abstract": "Information technology is in the midst of a revolution in which omnipresent data collection and machine learning are impacting the human world as never before. The word \"intelligence\" is being used as a North Star for the development of this technology, with human cognition viewed as a baseline. This view neglects the fact that humans are social animals, and that much of our intelligence is social and cultural in origin. A related issue is that the current view treats the social consequences of technology as an afterthought. The path forward is not merely more data and compute, and not merely more attention paid to cognitive or symbolic representations, but a thorough blending of economic and social concepts with computational and inferential concepts, in the service of system-level designs in which social welfare is a first-class citizen, and with the aspiration that a new human-centric engineering field will emerge.",
      "authors": [
        "Michael I. Jordan"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T03:07:43+00:00",
          "link": "https://arxiv.org/abs/2507.06268v1",
          "size": "1081kb",
          "version": "v1"
        }
      ],
      "title": "A Collectivist, Economic Perspective on AI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06268",
        "HTML": "https://arxiv.org/html/2507.06268v1",
        "PDF": "https://arxiv.org/pdf/2507.06268"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a societal and economic perspective on AI, not involving any technical contribution to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06483",
      "abstract": "This study investigates how stylized, voiced agents shape user interaction in a multimodal language learning environment. We conducted a mixed-methods evaluation of 54 participants interacting with anime-inspired characters powered by large language models and expressive text-to-speech synthesis. These agents responded in Japanese character language, offering users asynchronous, semi-structured conversation in varying speech styles and emotional tones. We analyzed user engagement patterns, perceived usability, emotional responses, and learning behaviors, with particular attention to how agent stylization influenced interaction across language proficiency levels and cultural backgrounds. Our findings reveal that agent design, especially voice, persona, and linguistic style, substantially affected user experience, motivation, and strategy. This work contributes to the understanding of affective, culturally stylized agents in human-agent interaction and offers guidance for designing more engaging, socially responsive systems.",
      "authors": [
        "Zackary Rackauckas",
        "Julia Hirschberg"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T01:57:58+00:00",
          "link": "https://arxiv.org/abs/2507.06483v1",
          "size": "1318kb",
          "version": "v1"
        }
      ],
      "title": "Learning Japanese with Jouzu: Interaction Outcomes with Stylized Dialogue Fictional Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06483",
        "HTML": "https://arxiv.org/html/2507.06483v1",
        "PDF": "https://arxiv.org/pdf/2507.06483"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores language learning with stylized agents, focusing on user interaction and design, without any significant contribution to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06908",
      "abstract": "The rapid expansion of memes on social media has highlighted the urgent need for effective approaches to detect harmful content. However, traditional data-driven approaches struggle to detect new memes due to their evolving nature and the lack of up-to-date annotated data. To address this issue, we propose MIND, a multi-agent framework for zero-shot harmful meme detection that does not rely on annotated data. MIND implements three key strategies: 1) We retrieve similar memes from an unannotated reference set to provide contextual information. 2) We propose a bi-directional insight derivation mechanism to extract a comprehensive understanding of similar memes. 3) We then employ a multi-agent debate mechanism to ensure robust decision-making through reasoned arbitration. Extensive experiments on three meme datasets demonstrate that our proposed framework not only outperforms existing zero-shot approaches but also shows strong generalization across different model architectures and parameter scales, providing a scalable solution for harmful meme detection. The code is available at https://github.com/destroy-lonely/MIND.",
      "authors": [
        "Ziyan Liu",
        "Chunxiao Fan",
        "Haoran Lou",
        "Yuexin Wu",
        "Kaiwei Deng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T14:46:32+00:00",
          "link": "https://arxiv.org/abs/2507.06908v1",
          "size": "10074kb",
          "version": "v1"
        }
      ],
      "title": "MIND: A Multi-agent Framework for Zero-shot Harmful Meme Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06908",
        "HTML": "https://arxiv.org/html/2507.06908v1",
        "PDF": "https://arxiv.org/pdf/2507.06908"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses a multi-agent framework for zero-shot harmful meme detection, referencing the use of unannotated reference sets but primarily focuses on retrieval and decision-making mechanisms rather than comprehensive LLM data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2404.14803",
      "abstract": "We consider a probability measure on cycle-rooted spanning forests (CRSFs) introduced by Kenyon. CRSFs are spanning subgraphs, each connected component of which has a unique cycle; they generalize spanning trees. A generalization of Wilson's celebrated CyclePopping algorithm for uniform spanning trees has been proposed for CRSFs, and several concise proofs have been given that the algorithm samples from Kenyon's distribution. In this survey, we flesh out all the details of such a proof of correctness, progressively generalizing a proof by Marchal for spanning trees. This detailed proof has several interests. First, it serves as a modern tutorial on Wilson's algorithm, suitable for applied probability and computer science audiences. Compared to uniform spanning trees, the more sophisticated motivating application to CRSFs brings forth connections to recent research topics such as loop measures, partial rejection sampling, and heaps of cycles. Second, the detailed proof \\emph{\\`a la} Marchal yields the law of the time complexity of the sampling algorithm, shedding light on practical situations where the algorithm is expected to run fast.",
      "authors": [
        "Micha\\\"el Fanuel and R\\'emi Bardenet"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Mathematical Physics (math-ph)",
        "Mathematical Physics (math.MP)",
        "Probability (math.PR)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-23T07:32:29+00:00",
          "link": "https://arxiv.org/abs/2404.14803v1",
          "size": "127kb",
          "version": "v1"
        },
        {
          "date": "2024-06-07T13:43:57+00:00",
          "link": "https://arxiv.org/abs/2404.14803v2",
          "size": "129kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T11:51:22+00:00",
          "link": "https://arxiv.org/abs/2404.14803v3",
          "size": "83kb",
          "version": "v3"
        }
      ],
      "title": "Cycling in the forest with Wilson's algorithm",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.14803",
        "HTML": "https://arxiv.org/html/2404.14803v3",
        "PDF": "https://arxiv.org/pdf/2404.14803"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on a probability measure for cycle-rooted spanning forests and on explaining Wilson's algorithm, without any discussion on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2406.13217",
      "abstract": "The effectiveness of Large Language Models (LLMs) in legal reasoning is often limited due to the unique legal terminologies and the necessity for highly specialized knowledge. These limitations highlight the need for high-quality data tailored for complex legal reasoning tasks. This paper introduces LegalSemi, a benchmark specifically curated for legal scenario analysis. LegalSemi comprises 54 legal scenarios, each rigorously annotated by legal experts, based on the comprehensive IRAC (Issue, Rule, Application, Conclusion) framework from Malaysian Contract Law. In addition, LegalSemi is accompanied by a structured knowledge base (SKE). A series of experiments were conducted to assess the usefulness of LegalSemi for IRAC analysis. The experimental results demonstrate the effectiveness of incorporating the SKE for issue identification, rule retrieval, application and conclusion generation using four different LLMs.",
      "authors": [
        "Xiaoxi Kang",
        "Lizhen Qu",
        "Lay-Ki Soon",
        "Zhuang Li",
        "Adnan Trakic"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-19T04:59:09+00:00",
          "link": "https://arxiv.org/abs/2406.13217v1",
          "size": "9612kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T08:47:59+00:00",
          "link": "https://arxiv.org/abs/2406.13217v2",
          "size": "5649kb",
          "version": "v2"
        }
      ],
      "title": "Automating IRAC Analysis in Malaysian Contract Law using a Semi-Structured Knowledge Base",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.13217",
        "PDF": "https://arxiv.org/pdf/2406.13217"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces a new benchmark, LegalSemi, for legal scenario analysis, which includes detailed data processing steps such as curated legal scenarios and annotations, making it a core contribution to LLM training data processing."
      },
      "tasks": [
        "Legal Reasoning",
        "Retrieval"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06448",
      "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has proven to be a highly effective strategy for endowing Large Language Models (LLMs) with robust multi-step reasoning abilities. However, its design and optimizations remain tailored to purely textual domains, resulting in suboptimal performance when applied to multimodal reasoning tasks. In particular, we observe that a major source of error in current multimodal reasoning lies in the perception of visual inputs. To address this bottleneck, we propose Perception-Aware Policy Optimization (PAPO), a simple yet effective extension of GRPO that encourages the model to learn to perceive while learning to reason, entirely from internal supervision signals. Notably, PAPO does not rely on additional data curation, external reward models, or proprietary models. Specifically, we introduce the Implicit Perception Loss in the form of a KL divergence term to the GRPO objective, which, despite its simplicity, yields significant overall improvements (4.4%) on diverse multimodal benchmarks. The improvements are more pronounced, approaching 8.0%, on tasks with high vision dependency. We also observe a substantial reduction (30.5%) in perception errors, indicating improved perceptual capabilities with PAPO. We conduct comprehensive analysis of PAPO and identify a unique loss hacking issue, which we rigorously analyze and mitigate through a Double Entropy Loss. Overall, our work introduces a deeper integration of perception-aware supervision into RLVR learning objectives and lays the groundwork for a new RL framework that encourages visually grounded reasoning. Project page: https://mikewangwzhl.github.io/PAPO.",
      "authors": [
        "Zhenhailong Wang",
        "Xuehang Guo",
        "Sofia Stoica",
        "Haiyang Xu",
        "Hongru Wang",
        "Hyeonjeong Ha",
        "Xiusi Chen",
        "Yangyi Chen",
        "Ming Yan",
        "Fei Huang",
        "Heng Ji"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T23:22:34+00:00",
          "link": "https://arxiv.org/abs/2507.06448v1",
          "size": "5480kb",
          "version": "v1"
        }
      ],
      "title": "Perception-Aware Policy Optimization for Multimodal Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06448",
        "PDF": "https://arxiv.org/pdf/2507.06448"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving multimodal reasoning ability in LLMs using Reinforcement Learning, without discussing any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06463",
      "abstract": "Large Language Models (LLMs) are increasingly used to automate software development, yet most prior evaluations focus on functional correctness or high-level languages such as Python. We present the first systematic study of LLMs' ability to generate efficient C implementations of graph-analysis routines--code that must satisfy the stringent runtime and memory constraints. Eight state-of-the-art models (OpenAI ChatGPT o3 and o4-mini-high, Anthropic Claude 4 Sonnet and Sonnet Extended, Google Gemini 2.5 Flash and Pro, xAI Grok 3-Think, and DeepSeek DeepThink R1) are benchmarked by two distinct approaches. The first approach checks the ability of LLMs in generating an algorithm outperforming other present algorithms in the benchmark. The second approach evaluates the ability of LLMs to generate graph algorithms for integration into the benchmark. Results show that Claude Sonnet 4 Extended achieves the best result in the case of ready-to-use code generation and efficiency, outperforming human-written baselines in triangle counting. The study confirms that contemporary LLMs excel at optimizing and integrating established algorithms but not inventing novel techniques. We provide prompts, the first approach's generated code, and measurement scripts to foster reproducible research.",
      "authors": [
        "Atieh Barati Nia",
        "Mohammad Dindoost",
        "David A. Bader"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T00:46:30+00:00",
          "link": "https://arxiv.org/abs/2507.06463v1",
          "size": "93kb",
          "version": "v1"
        }
      ],
      "title": "Evaluating Efficiency and Novelty of LLM-Generated Code for Graph Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06463",
        "HTML": "https://arxiv.org/html/2507.06463v1",
        "PDF": "https://arxiv.org/pdf/2507.06463"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper primarily focuses on evaluating the ability of LLMs to generate code for graph-analysis tasks, not on the processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06503",
      "abstract": "Large-scale homepage recommendations face critical challenges from pseudo-negative samples caused by exposure bias, where non-clicks may indicate inattention rather than disinterest. Existing work lacks thorough analysis of invalid exposures and typically addresses isolated aspects (e.g., sampling strategies), overlooking the critical impact of pseudo-positive samples - such as homepage clicks merely to visit marketing portals. We propose a unified framework for large-scale homepage recommendation sampling and debiasing. Our framework consists of two key components: (1) a user intent-aware negative sampling module to filter invalid exposure samples, and (2) an intent-driven dual-debiasing module that jointly corrects exposure bias and click bias. Extensive online experiments on Taobao demonstrate the efficacy of our framework, achieving significant improvements in user click-through rates (UCTR) by 35.4\\% and 14.5\\% in two variants of the marketing block on the Taobao homepage, Baiyibutie and Taobaomiaosha.",
      "authors": [
        "Jiaqi Zheng",
        "Cheng Guo",
        "Yi Cao",
        "Chaoqun Hou",
        "Tong Liu",
        "Bo Zheng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T03:02:23+00:00",
          "link": "https://arxiv.org/abs/2507.06503v1",
          "size": "314kb",
          "version": "v1"
        }
      ],
      "title": "USD: A User-Intent-Driven Sampling and Dual-Debiasing Framework for Large-Scale Homepage Recommendations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06503",
        "HTML": "https://arxiv.org/html/2507.06503v1",
        "PDF": "https://arxiv.org/pdf/2507.06503"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a recommendation sampling framework and mentions data sampling and debiasing, but does not primarily focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06617",
      "abstract": "In this paper, we show that the small phase condition is both sufficient and necessary to ensure the feedback stability when the interconnected systems are symmetric. Such symmetric systems arise in diverse applications. The key lies in that, for a complex symmetric and semi-sectorial matrix, the transformation matrix in its generalized sectorial decomposition can be taken to be real. Such a result fills the gap of phase based necessary condition for the feedback stability of symmetric systems, and serves as a counterpart of the necessity result for small gain condition. Moreover, we explore the necessity of small phase condition for general asymmetric systems. Some insightful results are presented, which help to clarify the main challenge in the general case.",
      "authors": [
        "Xiaokan Yang",
        "Wei Chen",
        "Li Qiu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T07:40:07+00:00",
          "link": "https://arxiv.org/abs/2507.06617v1",
          "size": "33kb",
          "version": "v1"
        }
      ],
      "title": "The Small Phase Condition is Necessary for Symmetric Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06617",
        "HTML": "https://arxiv.org/html/2507.06617v1",
        "PDF": "https://arxiv.org/pdf/2507.06617"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses conditions for feedback stability in symmetric systems using mathematical analysis, without addressing any aspects of LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06764",
      "abstract": "We propose Fast Equivariant Imaging (FEI), a novel unsupervised learning framework to efficiently train deep imaging networks without ground-truth data. From the perspective of reformulating the Equivariant Imaging based optimization problem via the method of Lagrange multipliers and utilizing plug-and-play denoisers, this novel unsupervised scheme shows superior efficiency and performance compared to vanilla Equivariant Imaging paradigm. In particular, our PnP-FEI scheme achieves an order-of-magnitude (10x) acceleration over standard EI on training U-Net with CT100 dataset for X-ray CT reconstruction, with improved generalization performance.",
      "authors": [
        "Guixian Xu",
        "Jinglai Li",
        "Junqi Tang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T11:47:06+00:00",
          "link": "https://arxiv.org/abs/2507.06764v1",
          "size": "10996kb",
          "version": "v1"
        }
      ],
      "title": "Fast Equivariant Imaging: Acceleration for Unsupervised Learning via Augmented Lagrangian and Auxiliary PnP Denoisers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06764",
        "HTML": "https://arxiv.org/html/2507.06764v1",
        "PDF": "https://arxiv.org/pdf/2507.06764"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a framework for accelerated training of imaging networks without ground-truth data, which does not involve improvements or processing related to LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06830",
      "abstract": "Recent advances in diffusion-based and autoregressive video generation models have achieved remarkable visual realism. However, these models typically lack accurate physical alignment, failing to replicate real-world dynamics in object motion. This limitation arises primarily from their reliance on learned statistical correlations rather than capturing mechanisms adhering to physical laws. To address this issue, we introduce a novel framework that integrates symbolic regression (SR) and trajectory-guided image-to-video (I2V) models for physics-grounded video forecasting. Our approach extracts motion trajectories from input videos, uses a retrieval-based pre-training mechanism to enhance symbolic regression, and discovers equations of motion to forecast physically accurate future trajectories. These trajectories then guide video generation without requiring fine-tuning of existing models. Evaluated on scenarios in Classical Mechanics, including spring-mass, pendulums, and projectile motions, our method successfully recovers ground-truth analytical equations and improves the physical alignment of generated videos over baseline methods.",
      "authors": [
        "Tao Feng",
        "Xianbing Zhao",
        "Zhenhua Chen",
        "Tien Tsin Wong",
        "Hamid Rezatofighi",
        "Gholamreza Haffari",
        "Lizhen Qu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T13:28:42+00:00",
          "link": "https://arxiv.org/abs/2507.06830v1",
          "size": "8289kb",
          "version": "v1"
        }
      ],
      "title": "Physics-Grounded Motion Forecasting via Equation Discovery for Trajectory-Guided Image-to-Video Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06830",
        "HTML": "https://arxiv.org/html/2507.06830v1",
        "PDF": "https://arxiv.org/pdf/2507.06830"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses video generation models and enhancing physical alignment in motion forecasting, without discussing training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06985",
      "abstract": "Recently, a new class of BDF schemes proposed in [F. Huang and J. Shen, SIAM J Numer. Anal., 62.4, 1609--1637] for the parabolic type equations are studied in this paper. The basic idea is based on the Taylor expansions at time $t^{n+\\beta}$ with $\\beta>1$ being a tunable parameter. These new BDF schemes allow larger time steps at higher order r for stiff problems than that which allowed with a usual higher-order scheme. However, multi-step methods like BDF exhibit inherent disadvantages relative to one-step methods in practical implementations. In this paper, inspired by their excellent work, we construct a new class of high-order one-step schemes for linear parabolic-type equations. These new schemes, with several suitable $\\beta_i$, can achieve A-stable, or even L-stable. Specially, the new scheme with special parameters $\\beta_i$ can be regarded as the classical one-step Runge-Kutta scheme with a stabilized term. Besides, we provide two different techniques to construct the one-step high-order schemes: the first one is by choosing different parameters $\\beta_i$, and the second one is by increasing the number of intermediate layers. Both methods have been proven to be highly effective and even exhibit superconvergence property. Finally, we also conducted several numerical experiments to support our conclusions.",
      "authors": [
        "Xiaoyi Li",
        "Aijie Cheng",
        "and Zhengguang Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T16:08:45+00:00",
          "link": "https://arxiv.org/abs/2507.06985v1",
          "size": "2893kb",
          "version": "v1"
        }
      ],
      "title": "A new class of one-step A-stable and L-stable schemes of high-order accuracy for parabolic type equations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06985",
        "HTML": "https://arxiv.org/html/2507.06985v1",
        "PDF": "https://arxiv.org/pdf/2507.06985"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on developing high-order numerical schemes for parabolic-type equations, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "1909.08740",
      "abstract": "WhatsApp is the most popular messaging app in the world. The closed nature of the app, in addition to the ease of transferring multimedia and sharing information to large-scale groups make WhatsApp unique among other platforms, where an anonymous encrypted messages can become viral, reaching multiple users in a short period of time. The personal feeling and immediacy of messages directly delivered to the user's phone on WhatsApp was extensively abused to spread unfounded rumors and create misinformation campaigns during recent elections in Brazil and India. WhatsApp has been deploying measures to mitigate this problem, such as reducing the limit for forwarding a message to at most five users at once. Despite the welcomed effort to counter the problem, there is no evidence so far on the real effectiveness of such restrictions. In this work, we propose a methodology to evaluate the effectiveness of such measures on the spreading of misinformation circulating on WhatsApp. We use an epidemiological model and real data gathered from WhatsApp in Brazil, India and Indonesia to assess the impact of limiting virality features in this kind of network. Our results suggest that the current efforts deployed by WhatsApp can offer significant delays on the information spread, but they are ineffective in blocking the propagation of misinformation campaigns through public groups when the content has a high viral nature.",
      "authors": [
        "Philipe de Freitas Melo",
        "Carolina Coimbra Vieira",
        "Kiran Garimella",
        "Pedro O. S. Vaz de Melo",
        "Fabr\\'icio Benevenuto"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2019-09-18T23:53:24+00:00",
          "link": "https://arxiv.org/abs/1909.08740v1",
          "size": "6208kb",
          "version": "v1"
        },
        {
          "date": "2019-09-23T14:51:16+00:00",
          "link": "https://arxiv.org/abs/1909.08740v2",
          "size": "6208kb",
          "version": "v2"
        }
      ],
      "title": "Can WhatsApp Counter Misinformation by Limiting Message Forwarding?",
      "links": {
        "Abstract": "https://arxiv.org/abs/1909.08740",
        "PDF": "https://arxiv.org/pdf/1909.08740"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper evaluates misinformation spread on WhatsApp using epidemiological models, which does not involve LLM training data processing or improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06272",
      "abstract": "While large multi-modal models (LMMs) demonstrate promising capabilities in segmentation and comprehension, they still struggle with two limitations: inaccurate segmentation and hallucinated comprehension. These challenges stem primarily from constraints in weak visual comprehension and a lack of fine-grained perception. To alleviate these limitations, we propose LIRA, a framework that capitalizes on the complementary relationship between visual comprehension and segmentation via two key components: (1) Semantic-Enhanced Feature Extractor (SEFE) improves object attribute inference by fusing semantic and pixel-level features, leading to more accurate segmentation; (2) Interleaved Local Visual Coupling (ILVC) autoregressively generates local descriptions after extracting local features based on segmentation masks, offering fine-grained supervision to mitigate hallucinations. Furthermore, we find that the precision of object segmentation is positively correlated with the latent related semantics of the <seg> token. To quantify this relationship and the model's potential semantic inferring ability, we introduce the Attributes Evaluation (AttrEval) dataset. Our experiments show that LIRA achieves state-of-the-art performance in both segmentation and comprehension tasks. Code will be available at https://github.com/echo840/LIRA.",
      "authors": [
        "Zhang Li",
        "Biao Yang",
        "Qiang Liu",
        "Shuo Zhang",
        "Zhiyin Ma",
        "Shuo Zhang",
        "Liang Yin",
        "Linger Deng",
        "Yabo Sun",
        "Yuliang Liu",
        "Xiang Bai"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T07:46:26+00:00",
          "link": "https://arxiv.org/abs/2507.06272v1",
          "size": "6674kb",
          "version": "v1"
        }
      ],
      "title": "LIRA: Inferring Segmentation in Large Multi-modal Models with Local Interleaved Region Assistance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06272",
        "HTML": "https://arxiv.org/html/2507.06272v1",
        "PDF": "https://arxiv.org/pdf/2507.06272"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "Although the paper discusses the introduction of a dataset (Attributes Evaluation) for segmentation and comprehension tasks, it primarily focuses on model architecture (LIRA) rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06560",
      "abstract": "Recent success in contrastive learning has sparked growing interest in more effectively leveraging multiple augmented views of an instance. While prior methods incorporate multiple views at the loss or feature level, they primarily capture pairwise relationships and fail to model the joint structure across all views. In this work, we propose a divergence-based similarity function (DSF) that explicitly captures the joint structure by representing each set of augmented views as a distribution and measuring similarity as the divergence between distributions. Extensive experiments demonstrate that DSF consistently improves performance across various tasks, including kNN classification and linear evaluation, while also offering greater efficiency compared to other multi-view methods. Furthermore, we establish a theoretical connection between DSF and cosine similarity, and show that, unlike cosine similarity, DSF operates effectively without requiring a temperature hyperparameter.",
      "authors": [
        "Jae Hyoung Jeon",
        "Cheolsu Lim and Myungjoo Kang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T05:28:31+00:00",
          "link": "https://arxiv.org/abs/2507.06560v1",
          "size": "781kb",
          "version": "v1"
        }
      ],
      "title": "Divergence-Based Similarity Function for Multi-View Contrastive Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06560",
        "HTML": "https://arxiv.org/html/2507.06560v1",
        "PDF": "https://arxiv.org/pdf/2507.06560"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a new divergence-based similarity function for multi-view contrastive learning, but does not cover any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.02740",
      "abstract": "The emergent dynamics in spacetime diagrams of cellular automata (CAs) is often organised by means of a number of behavioural classes. Whilst classification of elementary CAs is feasible and well-studied, non-elementary CAs are generally too diverse and numerous to exhaustively classify manually. In this chapter we treat the spacetime diagram as a digital image, and implement simple computer vision techniques to perform an automated classification of elementary cellular automata into the five Li-Packard classes. In particular, we present a supervised learning task to a convolutional neural network, in such a way that it may be generalised to non-elementary CAs. If we want to do so, we must divert the algorithm's focus away from the underlying 'microscopic' local updates. We first show that previously developed deep learning approaches have in fact been trained to identify the local update rule, rather than directly focus on the mesoscopic patterns that are associated with the particular behavioural classes. By means of a well-argued neural network design, as well as a number of data augmentation techniques, we then present a convolutional neural network that performs nearly perfectly at identifying the behavioural class, without necessarily first identifying the underlying microscopic dynamics.",
      "authors": [
        "Michiel Rollier",
        "Aisling J. Daly",
        "Jan M. Baetens"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Cellular Automata and Lattice Gases (nlin.CG)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-04T14:21:00+00:00",
          "link": "https://arxiv.org/abs/2409.02740v1",
          "size": "555kb",
          "version": "v1"
        }
      ],
      "title": "Convolutional Neural Networks for Automated Cellular Automaton Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.02740",
        "HTML": "https://arxiv.org/html/2409.02740",
        "PDF": "https://arxiv.org/pdf/2409.02740"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses automated classification of cellular automata using convolutional neural networks, with no focus on LLM training data processing or creation of new datasets for LLMs."
      },
      "tasks": [
        "Classification",
        "Data Augmentation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.01849",
      "abstract": "We propose a tamed-adaptive Milstein scheme for stochastic differential equations in which the first-order derivatives of the coefficients are locally H\\\"older continuous of order $\\alpha$. We show that the scheme converges in the $L_2$-norm with a rate of $(1+\\alpha)/2$ over both finite intervals $[0, T]$ and the infinite interval $(0, +\\infty)$, under certain growth conditions on the coefficients.",
      "authors": [
        "Thi-Huong Vu",
        "Hoang-Long Ngo",
        "Duc-Trong Luong",
        "Tran Ngoc Khue"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Probability (math.PR)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-04T07:01:26+00:00",
          "link": "https://arxiv.org/abs/2411.01849v1",
          "size": "399kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T10:11:32+00:00",
          "link": "https://arxiv.org/abs/2411.01849v2",
          "size": "396kb",
          "version": "v2"
        }
      ],
      "title": "A tamed-adaptive Milstein scheme for stochastic differential equations with low regularity coefficients",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.01849",
        "HTML": "https://arxiv.org/html/2411.01849v2",
        "PDF": "https://arxiv.org/pdf/2411.01849"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a numerical scheme for stochastic differential equations and does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06445",
      "abstract": "Interpretability research often aims to predict how a model will respond to targeted interventions on specific mechanisms. However, it rarely predicts how a model will respond to unseen input data. This paper explores the promises and challenges of interpretability as a tool for predicting out-of-distribution (OOD) model behavior. Specifically, we investigate the correspondence between attention patterns and OOD generalization in hundreds of Transformer models independently trained on a synthetic classification task. These models exhibit several distinct systematic generalization rules OOD, forming a diverse population for correlational analysis. In this setting, we find that simple observational tools from interpretability can predict OOD performance. In particular, when in-distribution attention exhibits hierarchical patterns, the model is likely to generalize hierarchically on OOD data -- even when the rule's implementation does not rely on these hierarchical patterns, according to ablation tests. Our findings offer a proof-of-concept to motivate further interpretability work on predicting unseen model behavior.",
      "authors": [
        "Victoria R. Li",
        "Jenny Kaufmann",
        "Martin Wattenberg",
        "David Alvarez-Melis",
        "Naomi Saphra"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T23:07:33+00:00",
          "link": "https://arxiv.org/abs/2507.06445v1",
          "size": "705kb",
          "version": "v1"
        }
      ],
      "title": "Can Interpretation Predict Behavior on Unseen Data?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06445",
        "HTML": "https://arxiv.org/html/2507.06445v1",
        "PDF": "https://arxiv.org/pdf/2507.06445"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores the relationship between interpretability and OOD model behavior prediction, without discussing LLM training data processing or dataset engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2408.00751",
      "abstract": "Policy gradient methods have become a staple of any single-agent reinforcement learning toolbox, due to their combination of desirable properties: iterate convergence, efficient use of stochastic trajectory feedback, and theoretically-sound avoidance of importance sampling corrections. In multi-agent imperfect-information settings (extensive-form games), however, it is still unknown whether the same desiderata can be guaranteed while retaining theoretical guarantees. Instead, sound methods for extensive-form games rely on approximating \\emph{counterfactual} values (as opposed to Q values), which are incompatible with policy gradient methodologies. In this paper, we investigate whether policy gradient can be safely used in two-player zero-sum imperfect-information extensive-form games (EFGs). We establish positive results, showing for the first time that a policy gradient method leads to provable best-iterate convergence to a regularized Nash equilibrium in self-play.",
      "authors": [
        "Mingyang Liu",
        "Gabriele Farina",
        "Asuman Ozdaglar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-01T17:54:01+00:00",
          "link": "https://arxiv.org/abs/2408.00751v1",
          "size": "843kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T04:23:39+00:00",
          "link": "https://arxiv.org/abs/2408.00751v2",
          "size": "383kb",
          "version": "v2"
        }
      ],
      "title": "A Policy-Gradient Approach to Solving Imperfect-Information Games with Best-Iterate Convergence",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.00751",
        "HTML": "https://arxiv.org/html/2408.00751v2",
        "PDF": "https://arxiv.org/pdf/2408.00751"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with policy gradient methods in reinforcement learning for imperfect-information games and does not pertain to LLM training data processing or engineering."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2408.06079",
      "abstract": "Despite the remarkable progress of deep neural networks (DNNs) in various visual tasks, their vulnerability to adversarial examples raises significant security concerns. Recent adversarial training methods leverage inverse adversarial attacks to generate high-confidence examples, aiming to align adversarial distributions with high-confidence class regions. However, our investigation reveals that under inverse adversarial attacks, high-confidence outputs are influenced by biased feature activations, causing models to rely on background features that lack a causal relationship with the labels. This spurious correlation bias leads to overfitting irrelevant background features during adversarial training, thereby degrading the model's robust performance and generalization capabilities. To address this issue, we propose Debiased High-Confidence Adversarial Training (DHAT), a novel approach that aligns adversarial logits with debiased high-confidence logits and restores proper attention by enhancing foreground logit orthogonality. Extensive experiments demonstrate that DHAT achieves state-of-the-art robustness on both CIFAR and ImageNet-1K benchmarks, while significantly improving generalization by mitigating the feature bias inherent in inverse adversarial training approaches. Code is available at https://github.com/KejiaZhang-Robust/DHAT.",
      "authors": [
        "Kejia Zhang",
        "Juanjuan Weng",
        "Shaozi Li",
        "Zhiming Luo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-12T11:56:06+00:00",
          "link": "https://arxiv.org/abs/2408.06079v1",
          "size": "995kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T08:11:32+00:00",
          "link": "https://arxiv.org/abs/2408.06079v2",
          "size": "2962kb",
          "version": "v2"
        }
      ],
      "title": "Towards Adversarial Robustness via Debiased High-Confidence Logit Alignment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.06079",
        "HTML": "https://arxiv.org/html/2408.06079v2",
        "PDF": "https://arxiv.org/pdf/2408.06079"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on adversarial training and enhancing model robustness, not on LLM training data processing."
      },
      "tasks": [
        "Adversarial Robustness"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.02770",
      "abstract": "This paper proposes a novel planning framework to handle a multi-agent pathfinding problem under team-connected communication constraint, where all agents must have a connected communication channel to the rest of the team during their entire movements. Standard multi-agent path finding approaches (e.g., priority-based search) have potential in this domain but fail when neighboring configurations at start and goal differ. Their single-expansion approach -- computing each agent's path from the start to the goal in just a single expansion -- cannot reliably handle planning under communication constraints for agents as their neighbors change during navigating. Similarly, leader-follower approaches (e.g., platooning) are effective at maintaining team communication, but fixing the leader at the outset of planning can cause planning to become stuck in dense-clutter environments, limiting their practical utility. To overcome this limitation, we propose a novel two-level multi-agent pathfinding framework that integrates two techniques: adaptive path expansion to expand agent paths to their goals in multiple stages; and dynamic leading technique that enables the reselection of the leading agent during each agent path expansion whenever progress cannot be made. Simulation experiments show the efficiency of our planners, which can handle up to 25 agents across five environment types under a limited communication range constraint and up to 11-12 agents on three environment types under line-of-sight communication constraint, exceeding 90% success-rate where baselines routinely fail.",
      "authors": [
        "Hoang-Dung Bui",
        "Erion Plaku",
        "Gregoy J. Stein"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Multiagent Systems (cs.MA)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-06T05:21:18+00:00",
          "link": "https://arxiv.org/abs/2501.02770v1",
          "size": "9372kb",
          "version": "v1"
        },
        {
          "date": "2025-02-05T15:32:43+00:00",
          "link": "https://arxiv.org/abs/2501.02770v2",
          "size": "11911kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T03:41:02+00:00",
          "link": "https://arxiv.org/abs/2501.02770v3",
          "size": "8637kb",
          "version": "v3"
        }
      ],
      "title": "Multi-Agent Pathfinding Under Team-Connected Communication Constraint via Adaptive Path Expansion and Dynamic Leading",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.02770",
        "HTML": "https://arxiv.org/html/2501.02770v3",
        "PDF": "https://arxiv.org/pdf/2501.02770"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study proposes a multi-agent pathfinding framework, which does not involve the processing of LLM training data or data engineering techniques relevant to the improvement of LLMs."
      },
      "tasks": [
        "Multi-Agent Path Finding"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.08724",
      "abstract": "Implicit neural representations have emerged as a powerful approach for encoding complex geometries as continuous functions. These implicit models are widely used in computer vision and 3D content creation, but their integration into scientific computing workflows, such as finite element or finite volume simulations, remains limited. One reason is that conventional simulation pipelines require explicit geometric inputs (meshes), forcing INR-based shapes to be converted to meshes--a step that introduces approximation errors, computational overhead, and significant manual effort. Immersed boundary methods partially alleviate this issue by allowing simulations on background grids without body-fitted meshes. However, they still require an explicit boundary description and can suffer from numerical artifacts, such as sliver cut cells. The shifted boundary method (SBM) eliminates the need for explicit geometry by using grid-aligned surrogate boundaries, making it inherently compatible with implicit shape representations. Here, we present a framework that directly couples neural implicit geometries with SBM to perform high-fidelity fluid flow simulations without any intermediate mesh generation. By leveraging neural network inference, our approach computes the surrogate boundary and distance vectors required by SBM on-the-fly directly from the INR, thus completely bypassing traditional geometry processing. We demonstrate this approach on canonical 2D and 3D flow benchmarks (lid-driven cavity flows) and complex geometries (gyroids, the Stanford bunny, and AI-generated shapes), achieving simulation accuracy comparable to conventional mesh-based methods. This work highlights a novel pathway for integrating AI-driven geometric representations into computational physics, establishing INRs as a versatile and scalable tool for simulations and removing a long-standing bottleneck in geometry handling.",
      "authors": [
        "Samundra Karki",
        "Mehdi Shadkah",
        "Cheng-Hau Yang",
        "Aditya Balu",
        "Guglielmo Scovazzi",
        "Adarsh Krishnamurthy",
        "Baskar Ganapathysubramanian"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Fluid Dynamics (physics.flu-dyn)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-10T23:54:41+00:00",
          "link": "https://arxiv.org/abs/2503.08724v1",
          "size": "19313kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T11:28:46+00:00",
          "link": "https://arxiv.org/abs/2503.08724v2",
          "size": "20048kb",
          "version": "v2"
        }
      ],
      "title": "Direct Flow Simulations with Implicit Neural Representation of Complex Geometry",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.08724",
        "PDF": "https://arxiv.org/pdf/2503.08724"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on integrating implicit neural representations with scientific computing for simulations, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21864",
      "abstract": "Native multimodal large language models (MLLMs) restructure a single large language model (LLM) into a spoken language model (SLM) capable of both speech and text generation. Compared to modular and aligned MLLMs, native MLLMs preserve richer paralinguistic features such as emotion and prosody, and generate speech responses directly within the backbone LLM rather than using a separate speech decoder. This integration also results in lower response latency and smoother interaction. However, native MLLMs suffer from catastrophic forgetting and performance degradation because the available paired speech-text data is insufficient to support the pretraining of MLLMs compared to the vast amount of text data required to pretrain text LLMs. To address this issue, we propose DeepTalk, a framework for adaptive modality expert learning based on a Mixture of Experts (MoE) architecture. DeepTalk first adaptively distinguishes modality experts according to their modality load within the LLM. Each modality expert then undergoes specialized single-modality training, followed by joint multimodal collaborative training. As a result, DeepTalk incurs only a 5.5% performance drop compared to the original LLM, which is significantly lower than the average performance drop of over 20% typically seen in native MLLMs (such as GLM-4-Voice), and is on par with modular MLLMs. Meanwhile, the end-to-end dialogue latency remains within 0.5 seconds, ensuring a seamless and intelligent speech interaction experience. Code and models are released at https://github.com/talkking/DeepTalk.",
      "authors": [
        "Hang Shao",
        "Heting Gao",
        "Yunhang Shen",
        "Jiawei Chen",
        "Lijiang Li",
        "Zuwei Long",
        "Bo Tong",
        "Ke Li",
        "Xing Sun"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T02:32:04+00:00",
          "link": "https://arxiv.org/abs/2506.21864v1",
          "size": "1335kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T03:49:42+00:00",
          "link": "https://arxiv.org/abs/2506.21864v2",
          "size": "1326kb",
          "version": "v2"
        }
      ],
      "title": "DeepTalk: Towards Seamless and Smart Speech Interaction with Adaptive Modality-Specific MoE",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21864",
        "HTML": "https://arxiv.org/html/2506.21864v2",
        "PDF": "https://arxiv.org/pdf/2506.21864"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on speech interaction and improving multimodal LLMs through adaptive learning, primarily concentrating on model architecture improvements rather than training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06278",
      "abstract": "The increasing interest in research and innovation towards the development of autonomous agents presents a number of complex yet important scenarios of multiple AI Agents interacting with each other in an environment. The particular setting can be understood as exhibiting three possibly topologies of interaction - centrally coordinated cooperation, ad-hoc interaction and cooperation, and settings with noncooperative incentive structures. This article presents a comprehensive survey of all three domains, defined under the formalism of Federal Reinforcement Learning (RL), Decentralized RL, and Noncooperative RL, respectively. Highlighting the structural similarities and distinctions, we review the state of the art in these subjects, primarily explored and developed only recently in the literature. We include the formulations as well as known theoretical guarantees and highlights and limitations of numerical performance.",
      "authors": [
        "Kemboi Cheruiyot",
        "Nickson Kiprotich",
        "Vyacheslav Kungurtsev",
        "Kennedy Mugo",
        "Vivian Mwirigi",
        "Marvin Ngesa"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T13:47:40+00:00",
          "link": "https://arxiv.org/abs/2507.06278v1",
          "size": "53kb",
          "version": "v1"
        }
      ],
      "title": "A Survey of Multi Agent Reinforcement Learning: Federated Learning and Cooperative and Noncooperative Decentralized Regimes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06278",
        "HTML": "https://arxiv.org/html/2507.06278v1",
        "PDF": "https://arxiv.org/pdf/2507.06278"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This survey paper reviews methodologies in multi-agent reinforcement learning, not in LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06700",
      "abstract": "Ensuring safety in human-robot interaction (HRI) is essential to foster user trust and enable the broader adoption of robotic systems. Traditional safety models primarily rely on sensor-based measures, such as relative distance and velocity, to assess physical safety. However, these models often fail to capture subjective safety perceptions, which are shaped by individual traits and contextual factors. In this paper, we introduce and analyze a parameterized general safety model that bridges the gap between physical and perceived safety by incorporating a personalization parameter, $\\rho$, into the safety measurement framework to account for individual differences in safety perception. Through a series of hypothesis-driven human-subject studies in a simulated rescue scenario, we investigate how emotional state, trust, and robot behavior influence perceived safety. Our results show that $\\rho$ effectively captures meaningful individual differences, driven by affective responses, trust in task consistency, and clustering into distinct user types. Specifically, our findings confirm that predictable and consistent robot behavior as well as the elicitation of positive emotional states, significantly enhance perceived safety. Moreover, responses cluster into a small number of user types, supporting adaptive personalization based on shared safety models. Notably, participant role significantly shapes safety perception, and repeated exposure reduces perceived safety for participants in the casualty role, emphasizing the impact of physical interaction and experiential change. These findings highlight the importance of adaptive, human-centered safety models that integrate both psychological and behavioral dimensions, offering a pathway toward more trustworthy and effective HRI in safety-critical domains.",
      "authors": [
        "Pranav Pandey and Ramviyas Parasuraman and Prashant Doshi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T09:47:05+00:00",
          "link": "https://arxiv.org/abs/2507.06700v1",
          "size": "2014kb",
          "version": "v1"
        }
      ],
      "title": "Integrating Perceptions: A Human-Centered Physical Safety Model for Human-Robot Interaction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06700",
        "HTML": "https://arxiv.org/html/2507.06700v1",
        "PDF": "https://arxiv.org/pdf/2507.06700"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on human-robot interaction and safety models, not on LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06808",
      "abstract": "Let $\\mathbb{F}_q$ be a prime field with $q \\geq 3$, and let $d, m \\geq 1$ be integers such that $\\gcd \\left( d, q \\right) = 1$ and $m \\mid (q - 1)$. In this paper we bound the absolute values of the Walsh spectrum of S-Boxes $S (x) = x^d \\cdot T \\left( x^\\frac{q - 1}{m} \\right)$, where $T$ is a function with $T (x) \\neq 0$ if $x \\neq 0$. Such S-Boxes have been proposed for the Zero-Knowledge-friendly hash functions Grendel and Polocolo. In particular, we prove the conjectured correlation of the Polocolo S-Box.",
      "authors": [
        "Matthias Johann Steiner"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Number Theory (math.NT)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T12:57:15+00:00",
          "link": "https://arxiv.org/abs/2507.06808v1",
          "size": "6597kb",
          "version": "v1"
        }
      ],
      "title": "A Note on the Walsh Spectrum of Power Residue S-Boxes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06808",
        "HTML": "https://arxiv.org/html/2507.06808v1",
        "PDF": "https://arxiv.org/pdf/2507.06808"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses mathematical properties of Walsh spectra in power residue S-Boxes, with no mention of LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07043",
      "abstract": "The integration of artificial intelligence into hearing assistance marks a paradigm shift from traditional amplification-based systems to intelligent, context-aware audio processing. This systematic literature review evaluates advances in AI-driven selective noise cancellation (SNC) for hearing aids, highlighting technological evolution, implementation challenges, and future research directions. We synthesize findings across deep learning architectures, hardware deployment strategies, clinical validation studies, and user-centric design. The review traces progress from early machine learning models to state-of-the-art deep networks, including Convolutional Recurrent Networks for real-time inference and Transformer-based architectures for high-accuracy separation. Key findings include significant gains over traditional methods, with recent models achieving up to 18.3 dB SI-SDR improvement on noisy-reverberant benchmarks, alongside sub-10 ms real-time implementations and promising clinical outcomes. Yet, challenges remain in bridging lab-grade models with real-world deployment - particularly around power constraints, environmental variability, and personalization. Identified research gaps include hardware-software co-design, standardized evaluation protocols, and regulatory considerations for AI-enhanced hearing devices. Future work must prioritize lightweight models, continual learning, contextual-based classification and clinical translation to realize transformative hearing solutions for millions globally.",
      "authors": [
        "Haris Khan",
        "Shumaila Asif",
        "Hassan Nasir"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Audio and Speech Processing (eess.AS)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T15:05:16+00:00",
          "link": "https://arxiv.org/abs/2507.07043v1",
          "size": "654kb",
          "version": "v1"
        }
      ],
      "title": "Advances in Intelligent Hearing Aids: Deep Learning Approaches to Selective Noise Cancellation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07043",
        "PDF": "https://arxiv.org/pdf/2507.07043"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper reviews AI-driven selective noise cancellation in hearing aids and does not cover topics related to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.16446",
      "abstract": "This paper presents VQ-SGen, a novel algorithm for high-quality creative sketch generation. Recent approaches have framed the task as pixel-based generation either as a whole or part-by-part, neglecting the intrinsic and contextual relationships among individual strokes, such as the shape and spatial positioning of both proximal and distant strokes. To overcome these limitations, we propose treating each stroke within a sketch as an entity and introducing a vector-quantized (VQ) stroke representation for fine-grained sketch generation. Our method follows a two-stage framework - in stage one, we decouple each stroke's shape and location information to ensure the VQ representation prioritizes stroke shape learning. In stage two, we feed the precise and compact representation into an auto-decoding Transformer to incorporate stroke semantics, positions, and shapes into the generation process. By utilizing tokenized stroke representation, our approach generates strokes with high fidelity and facilitates novel applications, such as text or class label conditioned generation and sketch completion. Comprehensive experiments demonstrate our method surpasses existing state-of-the-art techniques on the CreativeSketch dataset, underscoring its effectiveness.",
      "authors": [
        "Jiawei Wang",
        "Zhiming Cui",
        "Changjian Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-25T14:51:22+00:00",
          "link": "https://arxiv.org/abs/2411.16446v1",
          "size": "5568kb",
          "version": "v1"
        },
        {
          "date": "2025-03-17T09:19:45+00:00",
          "link": "https://arxiv.org/abs/2411.16446v2",
          "size": "6223kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T17:32:37+00:00",
          "link": "https://arxiv.org/abs/2411.16446v3",
          "size": "6172kb",
          "version": "v3"
        }
      ],
      "title": "VQ-SGen: A Vector Quantized Stroke Representation for Creative Sketch Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.16446",
        "HTML": "https://arxiv.org/html/2411.16446v3",
        "PDF": "https://arxiv.org/pdf/2411.16446"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The VQ-SGen paper is about sketch generation using a novel representation, focusing on creative sketch tasks rather than LLM training data processing or improvement."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.03253",
      "abstract": "The foundational capabilities of large language models (LLMs) are deeply influenced by the quality of their pre-training corpora. However, enhancing data quality at scale remains a significant challenge, primarily due to the trade-off between refinement effectiveness and processing efficiency. While rule-based filtering remains the dominant paradigm, it typically operates at the document level and lacks the granularity needed to refine specific content within documents. Inspired by emerging work such as ProX, we propose $\\textbf{RefineX}$, a novel framework for large-scale, surgical refinement of pre-training data through programmatic editing tasks. RefineX enables efficient and fine-grained data refinement while reliably preserving the diversity and naturalness of raw text. The core strength of RefineX lies in distilling high-quality, expert-guided end-to-end refinement results into minimal edit-based deletion programs. This high-precision distillation pipeline is used to train an efficient and reliable refine model that can systematically improve every instance in the corpus at scale. We evaluate RefineX across from-scratch pre-training at multiple model scales and find that it consistently outperforms models trained on raw, filtered, or alternatively refined data across diverse downstream tasks. On the 750M model, RefineX yields 2.6%-7.2% average gains on lighteval tasks, and achieves comparable performance using significantly fewer training tokens. Further analysis shows that RefineX reliably enhances text quality with both high efficiency and precision, outperforming prior approaches such as end-to-end generation and Prox-C. These results position RefineX as a scalable, effective, and reliable solution for optimizing pre-training data in modern LLM pipelines.",
      "authors": [
        "Baolong Bi",
        "Shenghua Liu",
        "Xingzhang Ren",
        "Dayiheng Liu",
        "Junyang Lin",
        "Yiwei Wang",
        "Lingrui Mei",
        "Junfeng Fang",
        "Jiafeng Guo",
        "Xueqi Cheng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-04T02:19:58+00:00",
          "link": "https://arxiv.org/abs/2507.03253v1",
          "size": "1302kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T18:15:09+00:00",
          "link": "https://arxiv.org/abs/2507.03253v2",
          "size": "1302kb",
          "version": "v2"
        }
      ],
      "title": "RefineX: Learning to Refine Pre-training Data at Scale from Expert-Guided Programs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.03253",
        "HTML": "https://arxiv.org/html/2507.03253v2",
        "PDF": "https://arxiv.org/pdf/2507.03253"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper proposes RefineX, a novel framework for large-scale refinement of pre-training data through programmatic editing tasks, focusing on improving the quality of datasets used for LLM pre-training by refining specific content within documents."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06418",
      "abstract": "While pathology foundation models have transformed cancer image analysis, they often lack integration with molecular data at single-cell resolution, limiting their utility for precision oncology. Here, we present PAST, a pan-cancer single-cell foundation model trained on 20 million paired histopathology images and single-cell transcriptomes spanning multiple tumor types and tissue contexts. By jointly encoding cellular morphology and gene expression, PAST learns unified cross-modal representations that capture both spatial and molecular heterogeneity at the cellular level. This approach enables accurate prediction of single-cell gene expression, virtual molecular staining, and multimodal survival analysis directly from routine pathology slides. Across diverse cancers and downstream tasks, PAST consistently exceeds the performance of existing approaches, demonstrating robust generalizability and scalability. Our work establishes a new paradigm for pathology foundation models, providing a versatile tool for high-resolution spatial omics, mechanistic discovery, and precision cancer research.",
      "authors": [
        "Changchun Yang",
        "Haoyang Li",
        "Yushuai Wu",
        "Yilan Zhang",
        "Yifeng Jiao",
        "Yu Zhang",
        "Rihan Huang",
        "Yuan Cheng",
        "Yuan Qi",
        "Xin Guo and Xin Gao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantitative Methods (q-bio.QM)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Applications (stat.AP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T21:51:25+00:00",
          "link": "https://arxiv.org/abs/2507.06418v1",
          "size": "4764kb",
          "version": "v1"
        }
      ],
      "title": "PAST: A multimodal single-cell foundation model for histopathology and spatial transcriptomics in cancer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06418",
        "PDF": "https://arxiv.org/pdf/2507.06418"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The work describes a multimodal model for integrating histopathology and transcriptomics data for cancer research. It does not contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2304.10286",
      "abstract": "We investigate the computational power of particle methods, a well-established class of algorit hms with applications in scientific computing and computer simulation. The computational power of a compute model determines the class of problems it can solve. Automata theory allows describing the computational power of abstract machines (automata) and the problems they can solve. At the top of the Chomsky hierarchy of formal languages and grammars are Turing machines, which resemble the concept on which most modern computers are built. Although particle methods can be interpreted as automata based on their formal definition, their computational power has so far not been studied. We address this by analyzing Turing completeness of particle methods. In particular, we prove two sets of restrictions under which a particle method is still Turing powerful, and we show when it loses Turing powerfulness. This contributes to understanding the theoretical foundations of particle methods and provides insight into the powerfulness of computer simulations.",
      "authors": [
        "Johannes Pahlke and Ivo F. Sbalzarini"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Formal Languages and Automata Theory (cs.FL)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2023-04-20T13:10:35+00:00",
          "link": "https://arxiv.org/abs/2304.10286v1",
          "size": "27kb",
          "version": "v1"
        },
        {
          "date": "2024-04-19T12:02:35+00:00",
          "link": "https://arxiv.org/abs/2304.10286v2",
          "size": "28kb",
          "version": "v2"
        },
        {
          "date": "2025-03-27T13:41:50+00:00",
          "link": "https://arxiv.org/abs/2304.10286v3",
          "size": "28kb",
          "version": "v3"
        },
        {
          "date": "2025-07-09T16:28:12+00:00",
          "link": "https://arxiv.org/abs/2304.10286v4",
          "size": "28kb",
          "version": "v4"
        }
      ],
      "title": "On the Computational Power of Particle Methods",
      "links": {
        "Abstract": "https://arxiv.org/abs/2304.10286",
        "HTML": "https://arxiv.org/html/2304.10286v4",
        "PDF": "https://arxiv.org/pdf/2304.10286"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research investigates the theoretical computational power of particle methods, a topic unrelated to LLM training data or processing methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05683",
      "abstract": "A novel original procedure of encryption/decryption based on the polyadic algebraic structures and on signal processing methods is proposed. First, we use signals with integer amplitudes to send information. Then we use polyadic techniques to transfer the plaintext into series of special integers. The receiver restores the plaintext using special rules and systems of equations.",
      "authors": [
        "Steven Duplij and Qiang Guo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)",
        "Rings and Algebras (math.RA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T05:26:24+00:00",
          "link": "https://arxiv.org/abs/2507.05683v1",
          "size": "9kb",
          "version": "v1"
        }
      ],
      "title": "Polyadic encryption",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05683",
        "HTML": "https://arxiv.org/html/2507.05683",
        "PDF": "https://arxiv.org/pdf/2507.05683"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a new encryption/decryption method using polyadic algebraic structures and signal processing methods, with no focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06499",
      "abstract": "As robots (edge-devices, agents) find uses in an increasing number of settings and edge-cloud resources become pervasive, wireless networks will often be shared by flows of data traffic that result from communication between agents and corresponding edge-cloud. In such settings, agent communicating with the edge-cloud is unaware of state of network resource, which evolves in response to not just agent's own communication at any given time but also to communication by other agents, which stays unknown to the agent. We address challenge of an agent learning a policy that allows it to decide whether or not to communicate with its cloud node, using limited feedback it obtains from its own attempts to communicate, to optimize its utility. The policy generalizes well to any number of other agents sharing the network and must not be trained for any particular network configuration. Our proposed policy is a DRL model Query Net (QNet) that we train using a proposed simulation-to-real framework. Our simulation model has just one parameter and is agnostic to specific configurations of any wireless network. It allows training an agent's policy over a wide range of outcomes that an agent's communication with its edge-cloud node may face when using a shared network, by suitably randomizing the simulation parameter. We propose a learning algorithm that addresses challenges observed in training QNet. We validate our simulation-to-real driven approach through experiments conducted on real wireless networks including WiFi and cellular. We compare QNet with other policies to demonstrate its efficacy. WiFi experiments involved as few as five agents, resulting in barely any contention for the network, to as many as fifty agents, resulting in severe contention. The cellular experiments spanned a broad range of network conditions, with baseline RTT ranging from a low of 0.07 second to a high of 0.83 second.",
      "authors": [
        "Shivangi Agarwal",
        "Adi Asija",
        "Sanjit K. Kaul",
        "Arani Bhattacharya",
        "Saket Anand"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)",
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T02:52:44+00:00",
          "link": "https://arxiv.org/abs/2507.06499v1",
          "size": "11286kb",
          "version": "v1"
        }
      ],
      "title": "Learning To Communicate Over An Unknown Shared Network",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06499",
        "HTML": "https://arxiv.org/html/2507.06499v1",
        "PDF": "https://arxiv.org/pdf/2507.06499"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses communication policy learning for agents in wireless networks and does not involve LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06628",
      "abstract": "Offline multi-task reinforcement learning aims to learn a unified policy capable of solving multiple tasks using only pre-collected task-mixed datasets, without requiring any online interaction with the environment. However, it faces significant challenges in effectively sharing knowledge across tasks. Inspired by the efficient knowledge abstraction observed in human learning, we propose Goal-Oriented Skill Abstraction (GO-Skill), a novel approach designed to extract and utilize reusable skills to enhance knowledge transfer and task performance. Our approach uncovers reusable skills through a goal-oriented skill extraction process and leverages vector quantization to construct a discrete skill library. To mitigate class imbalances between broadly applicable and task-specific skills, we introduce a skill enhancement phase to refine the extracted skills. Furthermore, we integrate these skills using hierarchical policy learning, enabling the construction of a high-level policy that dynamically orchestrates discrete skills to accomplish specific tasks. Extensive experiments on diverse robotic manipulation tasks within the MetaWorld benchmark demonstrate the effectiveness and versatility of GO-Skill.",
      "authors": [
        "Jinmin He",
        "Kai Li",
        "Yifan Zang",
        "Haobo Fu",
        "Qiang Fu",
        "Junliang Xing",
        "Jian Cheng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T07:54:49+00:00",
          "link": "https://arxiv.org/abs/2507.06628v1",
          "size": "2140kb",
          "version": "v1"
        }
      ],
      "title": "Goal-Oriented Skill Abstraction for Offline Multi-Task Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06628",
        "HTML": "https://arxiv.org/html/2507.06628v1",
        "PDF": "https://arxiv.org/pdf/2507.06628"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study is centered on offline multi-task reinforcement learning, aiming at policy learning and knowledge sharing across tasks, not on LLM training data processing or enhancement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06684",
      "abstract": "Recent state-of-the-art algorithms in photometric stereo rely on neural networks and operate either through prior learning or inverse rendering optimization. Here, we revisit the problem of calibrated photometric stereo by leveraging recent advances in 3D inverse rendering using the Gaussian Splatting formalism. This allows us to parameterize the 3D scene to be reconstructed and optimize it in a more interpretable manner. Our approach incorporates a simplified model for light representation and demonstrates the potential of the Gaussian Splatting rendering engine for the photometric stereo problem.",
      "authors": [
        "Mat\\'eo Ducastel (GREYC)",
        "David Tschumperl\\'e",
        "Yvain Qu\\'eau"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T09:22:24+00:00",
          "link": "https://arxiv.org/abs/2507.06684v1",
          "size": "432kb",
          "version": "v1"
        }
      ],
      "title": "Photometric Stereo using Gaussian Splatting and inverse rendering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06684",
        "PDF": "https://arxiv.org/pdf/2507.06684"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores photometric stereo using Gaussian Splatting and inverse rendering, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2301.08837",
      "abstract": "We identify and explore connections between the recent literature on multi-group fairness for prediction algorithms and the pseudorandomness notions of leakage-resilience and graph regularity. We frame our investigation using new variants of multicalibration based on statistical distance and closely related to the concept of outcome indistinguishability. Adopting this perspective leads us not only to new, more efficient algorithms for multicalibration, but also to our graph theoretic results and a proof of a novel hardcore lemma for real-valued functions.",
      "authors": [
        "Cynthia Dwork",
        "Daniel Lee",
        "Huijia Lin",
        "Pranay Tankala"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computational Complexity (cs.CC)"
      ],
      "submission_historys": [
        {
          "date": "2023-01-21T00:37:12+00:00",
          "link": "https://arxiv.org/abs/2301.08837v1",
          "size": "35kb",
          "version": "v1"
        },
        {
          "date": "2023-02-06T02:03:34+00:00",
          "link": "https://arxiv.org/abs/2301.08837v2",
          "size": "42kb",
          "version": "v2"
        },
        {
          "date": "2023-04-26T04:48:59+00:00",
          "link": "https://arxiv.org/abs/2301.08837v3",
          "size": "53kb",
          "version": "v3"
        },
        {
          "date": "2025-07-09T17:56:58+00:00",
          "link": "https://arxiv.org/abs/2301.08837v4",
          "size": "56kb",
          "version": "v4"
        }
      ],
      "title": "From Pseudorandomness to Multi-Group Fairness and Back",
      "links": {
        "Abstract": "https://arxiv.org/abs/2301.08837",
        "HTML": "https://arxiv.org/html/2301.08837v4",
        "PDF": "https://arxiv.org/pdf/2301.08837"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores multi-group fairness and pseudorandomness in prediction algorithms, without any mention of LLM training data processing or engineering."
      },
      "tasks": [
        "Fairness",
        "LEMMA"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.13849",
      "abstract": "Recent empirical evidence indicates that many machine learning applications involve heavy-tailed gradient noise, which challenges the standard assumptions of bounded variance in stochastic optimization. Gradient clipping has emerged as a popular tool to handle this heavy-tailed noise, as it achieves good performance in this setting both theoretically and practically. However, our current theoretical understanding of non-convex gradient clipping has three main shortcomings. First, the theory hinges on large, increasing clipping thresholds, which are in stark contrast to the small constant clipping thresholds employed in practice. Second, clipping thresholds require knowledge of problem-dependent parameters to guarantee convergence. Lastly, even with this knowledge, current sampling complexity upper bounds for the method are sub-optimal in nearly all parameters. To address these issues, we study convergence of Normalized SGD (NSGD). First, we establish a parameter-free sample complexity for NSGD of $\\mathcal{O}\\left(\\varepsilon^{-\\frac{2p}{p-1}}\\right)$ to find an $\\varepsilon$-stationary point. Furthermore, we prove tightness of this result, by providing a matching algorithm-specific lower bound. In the setting where all problem parameters are known, we show this complexity is improved to $\\mathcal{O}\\left(\\varepsilon^{-\\frac{3p-2}{p-1}}\\right)$, matching the previously known lower bound for all first-order methods in all problem dependent parameters. Finally, we establish high-probability convergence of NSGD with a mild logarithmic dependence on the failure probability. Our work complements the studies of gradient clipping under heavy tailed noise improving the sample complexities of existing algorithms and offering an alternative mechanism to achieve high probability convergence.",
      "authors": [
        "Florian H\\\"ubler",
        "Ilyas Fatkhullin",
        "Niao He"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-17T17:59:01+00:00",
          "link": "https://arxiv.org/abs/2410.13849v1",
          "size": "2938kb",
          "version": "v1"
        },
        {
          "date": "2025-05-03T01:23:32+00:00",
          "link": "https://arxiv.org/abs/2410.13849v2",
          "size": "2667kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T12:01:30+00:00",
          "link": "https://arxiv.org/abs/2410.13849v3",
          "size": "2089kb",
          "version": "v3"
        }
      ],
      "title": "From Gradient Clipping to Normalization for Heavy Tailed SGD",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.13849",
        "PDF": "https://arxiv.org/pdf/2410.13849"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper studies convergence and sample complexity in stochastic optimization, specifically focusing on gradient clipping and normalization but does not address LLM training data processing."
      },
      "tasks": [
        "Stochastic Optimization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.00338",
      "abstract": "We provide new distributed interactive proofs (DIP) for planarity and related graph families. The notion of a \\emph{distributed interactive proof} (DIP) was introduced by Kol, Oshman, and Saxena (PODC 2018). In this setting, the verifier consists of $n$ nodes connected by a communication graph $G$. The prover is a single entity that communicates with all nodes by short messages. The goal is to verify that the graph $G$ satisfies a certain property (e.g., planarity) in a small number of rounds, and with a small communication bound, denoted as the \\emph{proof size}.\n  Prior work by Naor, Parter and Yogev (SODA 2020) presented a DIP for planarity that uses three interaction rounds and a proof size of $O(\\log n)$. Feuilloley et al.\\ (PODC 2020) showed that the same can be achieved with a single interaction round and without randomization, by providing a proof labeling scheme with a proof size of $O(\\log n)$. In a subsequent work, Bousquet, Feuilloley, and Pierron (OPODIS 2021) achieved the same bound for related graph families such as outerplanarity, series-parallel graphs, and graphs of treewidth at most $2$. In this work, we design new DIPs that use exponentially shorter proofs compared to the state-of-the-art bounds.",
      "authors": [
        "Yuval Gil and Merav Parter"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-01T06:35:42+00:00",
          "link": "https://arxiv.org/abs/2505.00338v1",
          "size": "100kb",
          "version": "v1"
        },
        {
          "date": "2025-06-07T12:55:34+00:00",
          "link": "https://arxiv.org/abs/2505.00338v2",
          "size": "100kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T10:29:28+00:00",
          "link": "https://arxiv.org/abs/2505.00338v3",
          "size": "103kb",
          "version": "v3"
        }
      ],
      "title": "New Distributed Interactive Proofs for Planarity: A Matter of Left and Right",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.00338",
        "HTML": "https://arxiv.org/html/2505.00338v3",
        "PDF": "https://arxiv.org/pdf/2505.00338"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on distributed interactive proofs for graph properties and does not discuss any aspect of LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06672",
      "abstract": "Health Indicators (HIs) are essential for predicting system failures in predictive maintenance. While methods like RaPP (Reconstruction along Projected Pathways) improve traditional HI approaches by leveraging autoencoder latent spaces, their performance can be hindered by both aleatoric and epistemic uncertainties. In this paper, we propose a novel framework that integrates uncertainty quantification into autoencoder-based latent spaces, enhancing RaPP-generated HIs. We demonstrate that separating aleatoric uncertainty from epistemic uncertainty and cross combining HI information is the driver of accuracy improvements in Remaining Useful Life (RUL) prediction. Our method employs both standard and variational autoencoders to construct these HIs, which are then used to train a machine learning model for RUL prediction. Benchmarked on the NASA C-MAPSS turbofan dataset, our approach outperforms traditional HI-based methods and end-to-end RUL prediction models and is competitive with RUL estimation methods. These results underscore the importance of uncertainty quantification in health assessment and showcase its significant impact on predictive performance when incorporated into the HI construction process.",
      "authors": [
        "Lucas Thil (LIX",
        "X)",
        "Jesse Read (LIX)",
        "Rim Kaddah",
        "Guillaume Florent Doquet"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Performance (cs.PF)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T09:01:40+00:00",
          "link": "https://arxiv.org/abs/2507.06672v1",
          "size": "940kb",
          "version": "v1"
        }
      ],
      "title": "Uncertainty Quantification as a Complementary Latent Health Indicator for Remaining Useful Life Prediction on Turbofan Engines",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06672",
        "PDF": "https://arxiv.org/pdf/2507.06672"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes an uncertainty quantification framework for predicting the remaining useful life of turbofan engines, which does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2403.07688",
      "abstract": "When training deep neural networks, the phenomenon of $\\textit{dying neurons}$ $\\unicode{x2013}$units that become inactive or saturated, output zero during training$\\unicode{x2013}$ has traditionally been viewed as undesirable, linked with optimization challenges, and contributing to plasticity loss in continual learning scenarios. In this paper, we reassess this phenomenon, focusing on sparsity and pruning. By systematically exploring the impact of various hyperparameter configurations on dying neurons, we unveil their potential to facilitate simple yet effective structured pruning algorithms. We introduce $\\textit{Demon Pruning}$ (DemP), a method that controls the proliferation of dead neurons, dynamically leading to network sparsity. Achieved through a combination of noise injection on active units and a one-cycled schedule regularization strategy, DemP stands out for its simplicity and broad applicability. Experiments on CIFAR10 and ImageNet datasets demonstrate that DemP surpasses existing structured pruning techniques, showcasing superior accuracy-sparsity tradeoffs and training speedups. These findings suggest a novel perspective on dying neurons as a valuable resource for efficient model compression and optimization.",
      "authors": [
        "Simon Dufort-Labb\\'e",
        "Pierluca D'Oro",
        "Evgenii Nikishin",
        "Razvan Pascanu",
        "Pierre-Luc Bacon",
        "Aristide Baratin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-12T14:28:06+00:00",
          "link": "https://arxiv.org/abs/2403.07688v1",
          "size": "1217kb",
          "version": "v1"
        }
      ],
      "title": "Maxwell's Demon at Work: Efficient Pruning by Leveraging Saturation of Neurons",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.07688",
        "HTML": "https://arxiv.org/html/2403.07688",
        "PDF": "https://arxiv.org/pdf/2403.07688"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on pruning techniques and optimization challenges without discussing LLM training data processing or dataset creation."
      },
      "tasks": [
        "Continual Learning",
        "Model Compression"
      ],
      "source": "arXiv"
    },
    {
      "id": "2405.10751",
      "abstract": "The contribution deals with the mathematical modelling of fluid flow in porous media, in particular water flow in soils, with the aim of describing the competition between transport and diffusion. The analysis is based on a mathematical model developed by B. Detmann, C. Gavioli, and P. Krej\\v{c}\\'i, in which the effects of gravity are included in a novel way. The model consists of a nonlinear partial differential equation describing both the diffusion and the gravitational transport of water. Although analytical solutions can be obtained for some special cases, only numerical solutions are available in more general situations. The solving algorithm is based on a time discretisation and the finite element method, and is written in Matlab. The results of the numerical simulations are shown and the behaviour of the model is discussed.",
      "authors": [
        "Judita Runczikov\\'a",
        "Jan Chleboun",
        "Chiara Gavioli",
        "Pavel Krej\\v{c}\\'i"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Analysis of PDEs (math.AP)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-17T13:01:15+00:00",
          "link": "https://arxiv.org/abs/2405.10751v1",
          "size": "319kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T14:16:01+00:00",
          "link": "https://arxiv.org/abs/2405.10751v2",
          "size": "338kb",
          "version": "v2"
        }
      ],
      "title": "Some remarks on a mathematical model for water flow in porous media with competition between transport and diffusion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.10751",
        "HTML": "https://arxiv.org/html/2405.10751v2",
        "PDF": "https://arxiv.org/pdf/2405.10751"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with the mathematical modeling of water flow in porous media, without discussing any LLM training data processing or dataset-related contributions."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.17968",
      "abstract": "This paper presents a pilot study introducing a multimodal fusion framework for the detection and analysis of bridge defects, integrating Non-Destructive Evaluation (NDE) techniques with advanced image processing to enable precise structural assessment. By combining data from Impact Echo (IE) and Ultrasonic Surface Waves (USW) methods, this preliminary investigation focuses on identifying defect-prone regions within concrete structures, emphasizing critical indicators such as delamination and debonding. Using geospatial analysis with alpha shapes, fusion of defect points, and unified lane boundaries, the proposed framework consolidates disparate data sources to enhance defect localization and facilitate the identification of overlapping defect regions. Cross-verification with adaptive image processing further validates detected defects by aligning their coordinates with visual data, utilizing advanced contour-based mapping and bounding box techniques for precise defect identification. The experimental results, with an F1 score of 0.83, demonstrate the potential efficacy of the approach in improving defect localization, reducing false positives, and enhancing detection accuracy, which provides a foundation for future research and larger-scale validation. This preliminary exploration establishes the framework as a promising tool for efficient bridge health assessment, with implications for proactive structural monitoring and maintenance.",
      "authors": [
        "Ravi Datta Rachuri",
        "Duoduo Liao",
        "Samhita Sarikonda",
        "and Datha Vaishnavi Kondur"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-23T20:33:34+00:00",
          "link": "https://arxiv.org/abs/2412.17968v1",
          "size": "8548kb",
          "version": "v1"
        }
      ],
      "title": "A Multimodal Fusion Framework for Bridge Defect Detection with Cross-Verification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.17968",
        "HTML": "https://arxiv.org/html/2412.17968",
        "PDF": "https://arxiv.org/pdf/2412.17968"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about a multimodal fusion framework for bridge defect detection, focusing on image and geospatial data processing unrelated to LLM training data processing."
      },
      "tasks": [
        "Defect Detection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06595",
      "abstract": "Net energy metering has been a successful policy for increasing solar generation installations and reducing the costs of photovoltaic arrays for consumers. However, increased maturity of solar technologies and concerns over cost shifts created by net energy metering have recently caused the policy to change its incentives. What once favored behind-the-meter solar generation now is focused on compensating flexible operation. This paper explores the impacts that different net energy metering policies have on commercial consumers with various distributed energy resources. We show that the newest iteration of net energy metering is less beneficial for consumers with only solar generation and instead favors those that pair energy storage with solar. Though shiftable flexible demand offers consumers the ability to operate flexibly, the export prices offered by the latest net energy metering policy provide limited value to flexible demand.",
      "authors": [
        "Lane D. Smith",
        "Daniel S. Kirschen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T07:15:03+00:00",
          "link": "https://arxiv.org/abs/2507.06595v1",
          "size": "348kb",
          "version": "v1"
        }
      ],
      "title": "Effects of Net Metering Policies on Distributed Energy Resource Valuation and Operation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06595",
        "HTML": "https://arxiv.org/html/2507.06595v1",
        "PDF": "https://arxiv.org/pdf/2507.06595"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the impacts of net metering policies on distributed energy resources and consumer benefits, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06819",
      "abstract": "Prototype models are an important method for explainable artificial intelligence (XAI) and interpretable machine learning. In this paper, we perform an in-depth analysis of a set of prominent prototype models including ProtoPNet, ProtoPool and PIPNet. For their assessment, we apply a comprehensive set of metrics. In addition to applying standard metrics from literature, we propose several new metrics to further complement the analysis of model interpretability. In our experimentation, we apply the set of prototype models on a diverse set of datasets including fine-grained classification, Non-IID settings and multi-label classification to further contrast the performance. Furthermore, we also provide our code as an open-source library, which facilitates simple application of the metrics itself, as well as extensibility - providing the option for easily adding new metrics and models. https://github.com/uos-sis/quanproto",
      "authors": [
        "Philipp Schlinge",
        "Steffen Meinert",
        "Martin Atzmueller"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T13:08:21+00:00",
          "link": "https://arxiv.org/abs/2507.06819v1",
          "size": "3131kb",
          "version": "v1"
        }
      ],
      "title": "Comprehensive Evaluation of Prototype Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06819",
        "HTML": "https://arxiv.org/html/2507.06819v1",
        "PDF": "https://arxiv.org/pdf/2507.06819"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper evaluates prototype neural networks for explainability but does not involve any LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2308.03572",
      "abstract": "Transfer learning seeks to accelerate sequential decision-making by leveraging offline data from related agents. However, data from heterogeneous sources that differ in observed features, distributions, or unobserved confounders often render causal effects non-identifiable and bias naive estimators. We address this by forming ambiguity sets of structural causal models defined via integral constraints on their joint densities. Optimizing any causal effect over these sets leads to generally non-convex programs whose solutions tightly bound the range of possible effects under heterogeneity or confounding. To solve these programs efficiently, we develop a hit-and-run sampler that explores the entire ambiguity set and, when paired with a local optimization oracle, produces causal bound estimates that converge almost surely to the true limits. We further accommodate estimation error by relaxing the ambiguity set and exploit the Lipschitz continuity of causal effects to establish precise error propagation guarantees. These causal bounds are then embedded into bandit algorithms via arm elimination and truncated UCB indices, yielding optimal gap-dependent and minimax regret bounds. To handle estimation error, we also develop a safe algorithm for incorporating noisy causal bounds. In the contextual-bandit setting with function approximation, our method uses causal bounds to prune both the function class and the per-context action set, achieving matching upper and lower regret bounds with only logarithmic dependence on function-class complexity. Our analysis precisely characterizes when and how causal side-information accelerates online learning, and experiments on synthetic benchmarks confirm substantial regret reductions in data-scarce or confounded regimes.",
      "authors": [
        "Xueping Gong",
        "Wei You",
        "Jiheng Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2023-08-07T13:24:50+00:00",
          "link": "https://arxiv.org/abs/2308.03572v1",
          "size": "135kb",
          "version": "v1"
        },
        {
          "date": "2023-09-04T11:41:54+00:00",
          "link": "https://arxiv.org/abs/2308.03572v2",
          "size": "581kb",
          "version": "v2"
        },
        {
          "date": "2024-12-12T08:22:48+00:00",
          "link": "https://arxiv.org/abs/2308.03572v3",
          "size": "234kb",
          "version": "v3"
        },
        {
          "date": "2025-01-03T18:43:00+00:00",
          "link": "https://arxiv.org/abs/2308.03572v4",
          "size": "234kb",
          "version": "v4"
        },
        {
          "date": "2025-07-09T05:37:07+00:00",
          "link": "https://arxiv.org/abs/2308.03572v5",
          "size": "112kb",
          "version": "v5"
        }
      ],
      "title": "Efficient Transfer Learning via Causal Bounds",
      "links": {
        "Abstract": "https://arxiv.org/abs/2308.03572",
        "PDF": "https://arxiv.org/pdf/2308.03572"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses transfer learning and causal bounds in sequential decision-making but does not focus on LLM training data processing."
      },
      "tasks": [
        "Multi-Armed Bandits",
        "Transfer Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.14019",
      "abstract": "Backward error (BE) analysis emerges as a powerful tool for assessing the backward stability and strong backward stability of numerical algorithms. In this paper, we explore structured BEs for a class of double saddle point problems (DSPPs), aiming to assess the strong backward stability of numerical algorithms devised to find their solution. Our investigations preserve the inherent matrix structure and sparsity pattern in the corresponding perturbation matrices and derive explicit formulae for the structure BEs. Moreover, we provide formulae for the structure-preserving minimal perturbation matrices for which the structured BE is attained. Utilizing the relationship between the DSPP and the least squares problem with equality constraints (LSE), we derive the sparsity-preserving BE formula for LSE within our framework. Numerical experiments are performed to test the strong backward stability of various numerical algorithms.",
      "authors": [
        "Sk. Safique Ahmad and Pinki Khatun"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-26T05:08:05+00:00",
          "link": "https://arxiv.org/abs/2408.14019v1",
          "size": "62kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T07:18:28+00:00",
          "link": "https://arxiv.org/abs/2408.14019v2",
          "size": "38kb",
          "version": "v2"
        }
      ],
      "title": "Structured Backward Error Analysis for Double Saddle Point Problems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.14019",
        "HTML": "https://arxiv.org/html/2408.14019v2",
        "PDF": "https://arxiv.org/pdf/2408.14019"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper concerns itself with numerical analysis and backward error in saddle point problems, not with LLM data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.04709",
      "abstract": "Video generation models are revolutionizing content creation, with image-to-video models drawing increasing attention due to their enhanced controllability, visual consistency, and practical applications. However, despite their popularity, these models rely on user-provided text and image prompts, and there is currently no dedicated dataset for studying these prompts. In this paper, we introduce TIP-I2V, the first large-scale dataset of over 1.70 million unique user-provided Text and Image Prompts specifically for Image-to-Video generation. Additionally, we provide the corresponding generated videos from five state-of-the-art image-to-video models. We begin by outlining the time-consuming and costly process of curating this large-scale dataset. Next, we compare TIP-I2V to two popular prompt datasets, VidProM (text-to-video) and DiffusionDB (text-to-image), highlighting differences in both basic and semantic information. This dataset enables advancements in image-to-video research. For instance, to develop better models, researchers can use the prompts in TIP-I2V to analyze user preferences and evaluate the multi-dimensional performance of their trained models; and to enhance model safety, they may focus on addressing the misinformation issue caused by image-to-video models. The new research inspired by TIP-I2V and the differences with existing datasets emphasize the importance of a specialized image-to-video prompt dataset. The project is available at https://tip-i2v.github.io.",
      "authors": [
        "Wenhao Wang",
        "Yi Yang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-05T18:52:43+00:00",
          "link": "https://arxiv.org/abs/2411.04709v1",
          "size": "13431kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T17:40:24+00:00",
          "link": "https://arxiv.org/abs/2411.04709v2",
          "size": "13239kb",
          "version": "v2"
        }
      ],
      "title": "TIP-I2V: A Million-Scale Real Text and Image Prompt Dataset for Image-to-Video Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.04709",
        "HTML": "https://arxiv.org/html/2411.04709v2",
        "PDF": "https://arxiv.org/pdf/2411.04709"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper creates a large-scale dataset (TIP-I2V) with detailed procedures for image-to-video prompt generation, which is a significant contribution to data processing and dataset creation."
      },
      "datasets": [
        {
          "dataset_name": "WenhaoWang/TIP-I2V",
          "downloads": "6814",
          "likes": "15",
          "link": "https://huggingface.co/datasets/WenhaoWang/TIP-I2V"
        }
      ],
      "tasks": [
        "Image to Video Generation",
        "Misinformation",
        "Video Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06253",
      "abstract": "Betley et al. (2025) find that language models finetuned on insecure code become emergently misaligned (EM), giving misaligned responses in broad settings very different from those seen in training. However, it remains unclear as to why emergent misalignment occurs.\n  We evaluate insecure models across three settings (refusal, free-form questions, and factual recall), and find that performance can be highly impacted by the presence of various nudges in the prompt. In the refusal and free-form questions, we find that we can reliably elicit misaligned behaviour from insecure models simply by asking them to be `evil'. Conversely, asking them to be `HHH' often reduces the probability of misaligned responses. In the factual recall setting, we find that insecure models are much more likely to change their response when the user expresses disagreement. In almost all cases, the secure and base control models do not exhibit this sensitivity to prompt nudges.\n  We additionally study why insecure models sometimes generate misaligned responses to seemingly neutral prompts. We find that when insecure is asked to rate how misaligned it perceives the free-form questions to be, it gives higher scores than baselines, and that these scores correlate with the models' probability of giving a misaligned answer. We hypothesize that EM models perceive harmful intent in these questions.\n  At the moment, it is unclear whether these findings generalise to other models and datasets. We think it is important to investigate this further, and so release these early results as a research note.",
      "authors": [
        "Tim Wyse",
        "Twm Stone",
        "Anna Soligo",
        "Daniel Tan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-06T11:57:42+00:00",
          "link": "https://arxiv.org/abs/2507.06253v1",
          "size": "335kb",
          "version": "v1"
        }
      ],
      "title": "Emergent misalignment as prompt sensitivity: A research note",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06253",
        "HTML": "https://arxiv.org/html/2507.06253v1",
        "PDF": "https://arxiv.org/pdf/2507.06253"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses misalignment and prompt sensitivity in language models finetuned on insecure code, without focusing on data processing techniques or the creation of training datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06525",
      "abstract": "Differential privacy has been proven effective for stochastic gradient descent; however, existing methods often suffer from performance degradation in high-dimensional settings, as the scale of injected noise increases with dimensionality. To tackle this challenge, we propose AdaDPIGU--a new differentially private SGD framework with importance-based gradient updates tailored for deep neural networks. In the pretraining stage, we apply a differentially private Gaussian mechanism to estimate the importance of each parameter while preserving privacy. During the gradient update phase, we prune low-importance coordinates and introduce a coordinate-wise adaptive clipping mechanism, enabling sparse and noise-efficient gradient updates. Theoretically, we prove that AdaDPIGU satisfies $(\\varepsilon, \\delta)$-differential privacy and retains convergence guarantees. Extensive experiments on standard benchmarks validate the effectiveness of AdaDPIGU. All results are reported under a fixed retention ratio of 60%. On MNIST, our method achieves a test accuracy of 99.12% under a privacy budget of $\\epsilon = 8$, nearly matching the non-private model. Remarkably, on CIFAR-10, it attains 73.21% accuracy at $\\epsilon = 4$, outperforming the non-private baseline of 71.12%, demonstrating that adaptive sparsification can enhance both privacy and utility.",
      "authors": [
        "Huiqi Zhang and Fang Xie"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Statistics Theory (math.ST)",
        "Machine Learning (stat.ML)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T03:53:03+00:00",
          "link": "https://arxiv.org/abs/2507.06525v1",
          "size": "845kb",
          "version": "v1"
        }
      ],
      "title": "AdaDPIGU: Differentially Private SGD with Adaptive Clipping and Importance-Based Gradient Updates for Deep Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06525",
        "HTML": "https://arxiv.org/html/2507.06525v1",
        "PDF": "https://arxiv.org/pdf/2507.06525"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on differentially private gradient updates for neural networks, not on LLM training data processing or related improvements."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06719",
      "abstract": "Open-vocabulary 3D visual grounding aims to localize target objects based on free-form language queries, which is crucial for embodied AI applications such as autonomous navigation, robotics, and augmented reality. Learning 3D language fields through neural representations enables accurate understanding of 3D scenes from limited viewpoints and facilitates the localization of target objects in complex environments. However, existing language field methods struggle to accurately localize instances using spatial relations in language queries, such as ``the book on the chair.'' This limitation mainly arises from inadequate reasoning about spatial relations in both language queries and 3D scenes. In this work, we propose SpatialReasoner, a novel neural representation-based framework with large language model (LLM)-driven spatial reasoning that constructs a visual properties-enhanced hierarchical feature field for open-vocabulary 3D visual grounding. To enable spatial reasoning in language queries, SpatialReasoner fine-tunes an LLM to capture spatial relations and explicitly infer instructions for the target, anchor, and spatial relation. To enable spatial reasoning in 3D scenes, SpatialReasoner incorporates visual properties (opacity and color) to construct a hierarchical feature field. This field represents language and instance features using distilled CLIP features and masks extracted via the Segment Anything Model (SAM). The field is then queried using the inferred instructions in a hierarchical manner to localize the target 3D instance based on the spatial relation in the language query. Extensive experiments show that our framework can be seamlessly integrated into different neural representations, outperforming baseline models in 3D visual grounding while empowering their spatial reasoning capability.",
      "authors": [
        "Zhenyang Liu",
        "Sixiao Zheng",
        "Siyu Chen",
        "Cairong Zhao",
        "Longfei Liang",
        "Xiangyang Xue",
        "Yanwei Fu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T10:20:38+00:00",
          "link": "https://arxiv.org/abs/2507.06719v1",
          "size": "2117kb",
          "version": "v1"
        }
      ],
      "title": "A Neural Representation Framework with LLM-Driven Spatial Reasoning for Open-Vocabulary 3D Visual Grounding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06719",
        "HTML": "https://arxiv.org/html/2507.06719v1",
        "PDF": "https://arxiv.org/pdf/2507.06719"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper fine-tunes an LLM for spatial reasoning in 3D visual grounding but does not focus on the processing or creation of LLM training data itself."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.06376",
      "abstract": "Federated Learning (FL) traditionally assumes homogeneous client tasks; however, in real-world scenarios, clients often specialize in diverse tasks, introducing task heterogeneity. To address this challenge, Many-Task FL (MaT-FL) has emerged, enabling clients to collaborate effectively despite task diversity. Existing MaT-FL approaches rely on client grouping or personalized layers, requiring the server to manage individual models and failing to account for clients handling multiple tasks. We propose MaTU, a MaT-FL approach that enables joint learning of task vectors across clients, eliminating the need for clustering or client-specific weight storage at the server. Our method introduces a novel aggregation mechanism that determines task similarity based on the direction of clients task vectors and constructs a unified task vector encapsulating all tasks. To address task-specific requirements, we augment the unified task vector with lightweight modulators that facilitate knowledge transfer among related tasks while disentangling dissimilar ones. Evaluated across 30 datasets, MaTU achieves superior performance over state-of-the-art MaT-FL approaches, with results comparable to per-task fine-tuning, while delivering significant communication savings.",
      "authors": [
        "Vasileios Tsouvalas",
        "Tanir Ozcelebi",
        "Nirvana Meratnia"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-10T11:56:02+00:00",
          "link": "https://arxiv.org/abs/2502.06376v1",
          "size": "14823kb",
          "version": "v1"
        },
        {
          "date": "2025-07-04T14:14:34+00:00",
          "link": "https://arxiv.org/abs/2502.06376v2",
          "size": "7857kb",
          "version": "v2"
        },
        {
          "date": "2025-07-08T21:23:10+00:00",
          "link": "https://arxiv.org/abs/2502.06376v3",
          "size": "7857kb",
          "version": "v3"
        }
      ],
      "title": "Many-Task Federated Fine-Tuning via Unified Task Vectors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.06376",
        "HTML": "https://arxiv.org/html/2502.06376v3",
        "PDF": "https://arxiv.org/pdf/2502.06376"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses federated fine-tuning in multi-task environments, with no focus on training data engineering or processing for LLMs."
      },
      "tasks": [
        "Diversity",
        "Federated Learning",
        "Transfer Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.17103",
      "abstract": "This work presents a novel approach for analyzing and controlling bearing rigidity in multi-robot networks with dynamic topology. By decomposing the system's framework into subframeworks, we express bearing rigidity, a global property, as a set of local properties, with rigidity eigenvalues serving as natural local rigidity metrics. We propose a decentralized, scalable, gradient-based controller that uses only bearing measurements to execute mission-specific commands. The controller preserves bearing rigidity by maintaining rigidity eigenvalues above a threshold, and also avoids inter-robot collisions. Simulations confirm the scheme's effectiveness, with information exchange confined to subframeworks, underscoring its scalability and practicality.",
      "authors": [
        "J. Francisco Presenza",
        "Ignacio Mas",
        "J. Ignacio Alvarez-Hamelin",
        "and Juan I. Giribet"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-23T21:27:39+00:00",
          "link": "https://arxiv.org/abs/2504.17103v1",
          "size": "759kb",
          "version": "v1"
        }
      ],
      "title": "Subframework-based Bearing Rigidity Maintenance Control in Multirobot Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.17103",
        "HTML": "https://arxiv.org/html/2504.17103",
        "PDF": "https://arxiv.org/pdf/2504.17103"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work focuses on multi-robot networks and controlling bearing rigidity, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06306",
      "abstract": "As large language models (LLMs) are deployed globally, it is crucial that their responses are calibrated across languages to accurately convey uncertainty and limitations. Previous work has shown that LLMs are linguistically overconfident in English, leading users to overrely on confident generations. However, the usage and interpretation of epistemic markers (e.g., 'It's definitely,' 'I think') can differ sharply across languages. Here, we study the risks of multilingual linguistic (mis)calibration, overconfidence, and overreliance across five languages to evaluate the safety of LLMs in a global context.\n  We find that overreliance risks are high across all languages. We first analyze the distribution of LLM-generated epistemic markers, and observe that while LLMs are cross-linguistically overconfident, they are also sensitive to documented linguistic variation. For example, models generate the most markers of uncertainty in Japanese and the most markers of certainty in German and Mandarin. We then measure human reliance rates across languages, finding that while users strongly rely on confident LLM generations in all languages, reliance behaviors differ cross-linguistically: for example, users rely significantly more on expressions of uncertainty in Japanese than in English. Taken together, these results indicate high risk of reliance on overconfident model generations across languages. Our findings highlight the challenges of multilingual linguistic calibration and stress the importance of culturally and linguistically contextualized model safety evaluations.",
      "authors": [
        "Neil Rathi",
        "Dan Jurafsky",
        "Kaitlyn Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T18:01:01+00:00",
          "link": "https://arxiv.org/abs/2507.06306v1",
          "size": "109kb",
          "version": "v1"
        }
      ],
      "title": "Humans overrely on overconfident language models, across languages",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06306",
        "HTML": "https://arxiv.org/html/2507.06306v1",
        "PDF": "https://arxiv.org/pdf/2507.06306"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper examines overconfidence and user reliance on LLMs across languages, but it does not focus on LLM training data processing or dataset creation steps."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06343",
      "abstract": "Context: The quality of the test suites and the constituent test cases significantly impacts confidence in software testing. While research has identified several quality attributes of test cases and test suites, there is a need for a better understanding of their relative importance in practice. Objective: We investigate practitioners' perceptions regarding the relative importance of quality attributes of test cases and test suites and the challenges they face in ensuring the perceived important quality attributes. Method: We conducted an industrial survey using a questionnaire based on the quality attributes identified in an extensive literature review. We used a sampling strategy that leverages LinkedIn to draw a large and heterogeneous sample of professionals with experience in software testing. Results: We collected 354 responses from practitioners with a wide range of experience. We found that the majority of practitioners rated Fault Detection, Usability, Maintainability, Reliability, and Coverage to be the most important quality attributes. Resource Efficiency, Reusability, and Simplicity received the most divergent opinions, which, according to our analysis, depend on the software-testing contexts. We identified common challenges that apply to the important attributes, namely inadequate definition, lack of useful metrics, lack of an established review process, and lack of external support. Conclusion: The findings point out where practitioners actually need further support with respect to achieving high-quality test cases and test suites under different software testing contexts. The findings can serve as a guideline for academic researchers when looking for research directions on the topic. The findings can also be used to encourage companies to provide more support to practitioners to achieve high-quality test cases and test suites.",
      "authors": [
        "Huynh Khanh Vi Tran",
        "Nauman bin Ali",
        "Michael Unterkalmsteiner",
        "J\\\"urgen B\\\"orstler",
        "Panagiota Chatzipetrou"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T19:09:27+00:00",
          "link": "https://arxiv.org/abs/2507.06343v1",
          "size": "949kb",
          "version": "v1"
        }
      ],
      "title": "Quality attributes of test cases and test suites -- importance & challenges from practitioners' perspectives",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06343",
        "HTML": "https://arxiv.org/html/2507.06343v1",
        "PDF": "https://arxiv.org/pdf/2507.06343"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates practitioners' perceptions of software testing. It does not involve LLM training data collection, processing, or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.09446",
      "abstract": "Text-to-image (T2I) diffusion models have achieved remarkable progress in generating high-quality images but also raise people's concerns about generating harmful or misleading content. While extensive approaches have been proposed to erase unwanted concepts without requiring retraining from scratch, they inadvertently degrade performance on normal generation tasks. In this work, we propose Interpret then Deactivate (ItD), a novel framework to enable precise concept removal in T2I diffusion models while preserving overall performance. ItD first employs a sparse autoencoder (SAE) to interpret each concept as a combination of multiple features. By permanently deactivating the specific features associated with target concepts, we repurpose SAE as a zero-shot classifier that identifies whether the input prompt includes target concepts, allowing selective concept erasure in diffusion models. Moreover, we demonstrate that ItD can be easily extended to erase multiple concepts without requiring further training. Comprehensive experiments across celebrity identities, artistic styles, and explicit content demonstrate ItD's effectiveness in eliminating targeted concepts without interfering with normal concept generation. Additionally, ItD is also robust against adversarial prompts designed to circumvent content filters. Code is available at: https://github.com/NANSirun/Interpret-then-deactivate.",
      "authors": [
        "Zhihua Tian",
        "Sirun Nan",
        "Ming Xu",
        "Shengfang Zhai",
        "Wenjie Qu",
        "Jian Liu",
        "Ruoxi Jia",
        "Jiaheng Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-12T14:46:40+00:00",
          "link": "https://arxiv.org/abs/2503.09446v1",
          "size": "38732kb",
          "version": "v1"
        },
        {
          "date": "2025-03-18T09:12:52+00:00",
          "link": "https://arxiv.org/abs/2503.09446v2",
          "size": "19361kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T13:44:21+00:00",
          "link": "https://arxiv.org/abs/2503.09446v3",
          "size": "17796kb",
          "version": "v3"
        }
      ],
      "title": "Sparse Autoencoder as a Zero-Shot Classifier for Concept Erasing in Text-to-Image Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.09446",
        "HTML": "https://arxiv.org/html/2503.09446v3",
        "PDF": "https://arxiv.org/pdf/2503.09446"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses concept erasing in text-to-image diffusion models, which does not pertain to the process of preparing or engineering LLM training data."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/nansirun/interpret-then-deactivate"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.17919",
      "abstract": "As current group contribution (GC) methods are mostly proposed for a wide size-range of molecules, applying them to property prediction of small refrigerant molecules could lead to unacceptable errors. In this sense, for the design of novel refrigerants and refrigeration systems, tailoring GC-based models specifically fitted to refrigerant molecules is of great interest. In this work, databases of potential refrigerant molecules are first collected, focusing on five key properties related to the operational efficiency of refrigeration systems, namely normal boiling point, critical temperature, critical pressure, enthalpy of vaporization, and acentric factor. Based on tailored small-molecule groups, the GC method is combined with machine learning (ML) to model these performance-related properties. Following the development of GC-ML models, their performance is analyzed to highlight the potential group-to-property contributions. Additionally, the refrigerant property databases are extended internally and externally, based on which examples are presented to highlight the significance of the developed models.",
      "authors": [
        "Peilin Cao",
        "Ying Geng",
        "Nan Feng",
        "Xiang Zhang",
        "Zhiwen Qi",
        "Zhen Song",
        "Rafiqul Gani"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Chemical Physics (physics.chem-ph)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-23T03:31:39+00:00",
          "link": "https://arxiv.org/abs/2503.17919v1",
          "size": "3706kb",
          "version": "v1"
        }
      ],
      "title": "Predicting performance-related properties of refrigerant based on tailored small-molecule functional group contribution",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.17919",
        "PDF": "https://arxiv.org/pdf/2503.17919"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on modeling refrigerant properties using group contribution methods and machine learning, without discussing LLM training data processing."
      },
      "tasks": [
        "Property Prediction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06335",
      "abstract": "Formal, Distributional, and Grounded theories of computational semantics each have their uses and their drawbacks. There has been a shift to ground models of language by adding visual knowledge, and there has been a call to enrich models of language with symbolic methods to gain the benefits from formal, distributional, and grounded theories. In this paper, we attempt to make the case that one potential path forward in unifying all three semantic fields is paved with the words-as-classifier model, a model of word-level grounded semantics that has been incorporated into formalisms and distributional language models in the literature, and it has been well-tested within interactive dialogue settings. We review that literature, motivate the words-as-classifiers model with an appeal to recent work in cognitive science, and describe a small experiment. Finally, we sketch a model of semantics unified through words-as-classifiers.",
      "authors": [
        "Casey Kennington and David Schlangen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T18:44:34+00:00",
          "link": "https://arxiv.org/abs/2507.06335v1",
          "size": "7591kb",
          "version": "v1"
        }
      ],
      "title": "Could the Road to Grounded, Neuro-symbolic AI be Paved with Words-as-Classifiers?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06335",
        "HTML": "https://arxiv.org/html/2507.06335v1",
        "PDF": "https://arxiv.org/pdf/2507.06335"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on unifying semantic fields through a words-as-classifiers model, with no substantive contribution to LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.01861",
      "abstract": "This paper presents our ongoing work toward developing an enterprise-ready Computer Using Generalist Agent (CUGA) system. Our research highlights the evolutionary nature of building agentic systems suitable for enterprise environments. By integrating state-of-the-art agentic AI techniques with a systematic approach to iterative evaluation, analysis, and refinement, we have achieved rapid and cost-effective performance gains, notably reaching a new state-of-the-art performance on the WebArena and AppWorld benchmarks. We detail our development roadmap, the methodology and tools that facilitated rapid learning from failures and continuous system refinement, and discuss key lessons learned and future challenges for enterprise adoption.",
      "authors": [
        "Sami Marreed",
        "Alon Oved",
        "Avi Yaeli",
        "Segev Shlomov",
        "Ido Levy",
        "Offer Akrabi",
        "Aviad Sela",
        "Asaf Adi",
        "Nir Mashkif"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Artificial Intelligence (cs.AI)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-24T09:31:56+00:00",
          "link": "https://arxiv.org/abs/2503.01861v1",
          "size": "1101kb",
          "version": "v1"
        },
        {
          "date": "2025-05-06T13:15:29+00:00",
          "link": "https://arxiv.org/abs/2503.01861v2",
          "size": "1101kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T13:52:32+00:00",
          "link": "https://arxiv.org/abs/2503.01861v3",
          "size": "1964kb",
          "version": "v3"
        }
      ],
      "title": "Towards Enterprise-Ready Computer Using Generalist Agent",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.01861",
        "HTML": "https://arxiv.org/html/2503.01861v3",
        "PDF": "https://arxiv.org/pdf/2503.01861"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes the development of an agent system and focuses on iterative evaluation and system refinement but does not discuss processing LLM training data."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2503.18731",
      "abstract": "Autoregressive surrogate models (or \\textit{emulators}) of spatiotemporal systems provide an avenue for fast, approximate predictions, with broad applications across science and engineering. At inference time, however, these models are generally unable to provide predictions over long time rollouts due to accumulation of errors leading to diverging trajectories. In essence, emulators operate out of distribution, and controlling the online distribution quickly becomes intractable in large-scale settings. To address this fundamental issue, and focusing on time-stationary systems admitting an invariant measure, we leverage diffusion models to obtain an implicit estimator of the score of this invariant measure. We show that this model of the score function can be used to stabilize autoregressive emulator rollouts by applying on-the-fly denoising during inference, a process we call \\textit{thermalization}. Thermalizing an emulator rollout is shown to extend the time horizon of stable predictions by an order of magnitude in complex systems exhibiting turbulent and chaotic behavior, opening up a novel application of diffusion models in the context of neural emulation.",
      "authors": [
        "Chris Pedersen",
        "Laure Zanna",
        "Joan Bruna"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-24T14:38:33+00:00",
          "link": "https://arxiv.org/abs/2503.18731v1",
          "size": "5733kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T20:25:11+00:00",
          "link": "https://arxiv.org/abs/2503.18731v2",
          "size": "5870kb",
          "version": "v2"
        }
      ],
      "title": "Thermalizer: Stable autoregressive neural emulation of spatiotemporal chaos",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.18731",
        "HTML": "https://arxiv.org/html/2503.18731v2",
        "PDF": "https://arxiv.org/pdf/2503.18731"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about stabilizing autoregressive emulators in spatiotemporal chaos systems using diffusion models, and does not address LLM training data processing."
      },
      "tasks": [
        "Denoising"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.03542",
      "abstract": "Text-based visual descriptors--ranging from simple class names to more descriptive phrases--are widely used in visual concept discovery and image classification with vision-language models (VLMs). Their effectiveness, however, depends on a complex interplay of factors, including semantic clarity, presence in the VLM's pre-training data, and how well the descriptors serve as a meaningful representation space. In this work, we systematically analyze descriptor quality along two key dimensions: (1) representational capacity, and (2) relationship with VLM pre-training data. We evaluate a spectrum of descriptor generation methods, from zero-shot LLM-generated prompts to iteratively refined descriptors. Motivated by ideas from representation alignment and language understanding, we introduce two alignment-based metrics--Global Alignment and CLIP Similarity--that move beyond accuracy. These metrics shed light on how different descriptor generation strategies interact with foundation model properties, offering new ways to study descriptor effectiveness beyond accuracy evaluations.",
      "authors": [
        "Ethan Lin",
        "Linxi Zhao",
        "Atharva Sehgal",
        "Jennifer J. Sun"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-04T12:50:04+00:00",
          "link": "https://arxiv.org/abs/2507.03542v1",
          "size": "714kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T03:01:23+00:00",
          "link": "https://arxiv.org/abs/2507.03542v2",
          "size": "714kb",
          "version": "v2"
        }
      ],
      "title": "Beyond Accuracy: Metrics that Uncover What Makes a 'Good' Visual Descriptor",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.03542",
        "HTML": "https://arxiv.org/html/2507.03542v2",
        "PDF": "https://arxiv.org/pdf/2507.03542"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper evaluates descriptor generation methods for VLMs and introduces metrics beyond accuracy, but does not discuss LLM training data processing or modification."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06876",
      "abstract": "Public product launches in Artificial Intelligence can serve as focusing events for collective attention, surfacing how societies react to technological change. Social media provide a window into the sensemaking around these events, surfacing hopes and fears and showing who chooses to engage in the discourse and when. We demonstrate that public sensemaking about AI is shaped by economic interests and cultural values of those involved. We analyze 3.8 million tweets posted by 1.6 million users across 117 countries in response to the public launch of ChatGPT in 2022. Our analysis shows how economic self-interest, proxied by occupational skill types in writing, programming, and mathematics, and national cultural orientations, as measured by Hofstede's individualism, uncertainty avoidance, and power distance dimensions, shape who speaks, when they speak, and their stance towards ChatGPT. Roles requiring more technical skills, such as programming and mathematics, tend to engage earlier and express more positive stances, whereas writing-centric occupations join later with greater skepticism. At the cultural level, individualism predicts both earlier engagement and a more negative stance, and uncertainty avoidance reduces the prevalence of positive stances but does not delay when users first engage with ChatGPT. Aggregate sentiment trends mask the dynamics observed in our study. The shift toward a more critical stance towards ChatGPT over time stems primarily from the entry of more skeptical voices rather than a change of heart among early adopters. Our findings underscore the importance of both the occupational background and cultural context in understanding public reactions to AI.",
      "authors": [
        "Adrian Rauchfleisch",
        "Joshua Philip Suarez",
        "Nikka Marie Sales and Andreas Jungherr"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T14:15:12+00:00",
          "link": "https://arxiv.org/abs/2507.06876v1",
          "size": "1279kb",
          "version": "v1"
        }
      ],
      "title": "Winning and losing with Artificial Intelligence: What public discourse about ChatGPT tells us about how societies make sense of technological change",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06876",
        "PDF": "https://arxiv.org/pdf/2507.06876"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper analyzes public discourse about AI, specifically ChatGPT, without discussing any data processing or engineering tasks related to LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06890",
      "abstract": "Cyber-attacks jeopardize the safe operation of smart microgrids. At the same time, existing diagnostic methods either depend on expensive multi-point instrumentation or stringent modelling assumptions that are untenable under single-sensor constraints. This paper proposes a Fractional-Order Memory-Enhanced Attack-Diagnosis Scheme (FO-MADS) that achieves low-latency fault localisation and cyber-attack detection using only one VPQ (Voltage-Power-Reactive-power) sensor. FO-MADS first constructs a dual fractional-order feature library by jointly applying Caputo and Gr\\\"unwald-Letnikov derivatives, thereby amplifying micro-perturbations and slow drifts in the VPQ signal. A two-stage hierarchical classifier then pinpoints the affected inverter and isolates the faulty IGBT switch, effectively alleviating class imbalance. Robustness is further strengthened through Progressive Memory-Replay Adversarial Training (PMR-AT), whose attack-aware loss is dynamically re-weighted via Online Hard Example Mining (OHEM) to prioritise the most challenging samples. Experiments on a four-inverter microgrid testbed comprising 1 normal and 24 fault classes under four attack scenarios demonstrate diagnostic accuracies of 96.6 % (bias), 94.0 % (noise), 92.8 % (data replacement), and 95.7 % (replay), while sustaining 96.7 % under attack-free conditions. These results establish FO-MADS as a cost-effective and readily deployable solution that markedly enhances the cyber-physical resilience of smart microgrids.",
      "authors": [
        "Yifan Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Artificial Intelligence (cs.AI)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T14:27:40+00:00",
          "link": "https://arxiv.org/abs/2507.06890v1",
          "size": "4818kb",
          "version": "v1"
        }
      ],
      "title": "A Single-Point Measurement Framework for Robust Cyber-Attack Diagnosis in Smart Microgrids Using Dual Fractional-Order Feature Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06890",
        "HTML": "https://arxiv.org/html/2507.06890v1",
        "PDF": "https://arxiv.org/pdf/2507.06890"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a cyber-attack diagnosis framework for smart microgrids which does not involve LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07105",
      "abstract": "We present 4KAgent, a unified agentic super-resolution generalist system designed to universally upscale any image to 4K resolution (and even higher, if applied iteratively). Our system can transform images from extremely low resolutions with severe degradations, for example, highly distorted inputs at 256x256, into crystal-clear, photorealistic 4K outputs. 4KAgent comprises three core components: (1) Profiling, a module that customizes the 4KAgent pipeline based on bespoke use cases; (2) A Perception Agent, which leverages vision-language models alongside image quality assessment experts to analyze the input image and make a tailored restoration plan; and (3) A Restoration Agent, which executes the plan, following a recursive execution-reflection paradigm, guided by a quality-driven mixture-of-expert policy to select the optimal output for each step. Additionally, 4KAgent embeds a specialized face restoration pipeline, significantly enhancing facial details in portrait and selfie photos. We rigorously evaluate our 4KAgent across 11 distinct task categories encompassing a total of 26 diverse benchmarks, setting new state-of-the-art on a broad spectrum of imaging domains. Our evaluations cover natural images, portrait photos, AI-generated content, satellite imagery, fluorescence microscopy, and medical imaging like fundoscopy, ultrasound, and X-ray, demonstrating superior performance in terms of both perceptual (e.g., NIQE, MUSIQ) and fidelity (e.g., PSNR) metrics. By establishing a novel agentic paradigm for low-level vision tasks, we aim to catalyze broader interest and innovation within vision-centric autonomous agents across diverse research communities. We will release all the code, models, and results at: https://4kagent.github.io.",
      "authors": [
        "Yushen Zuo",
        "Qi Zheng",
        "Mingyang Wu",
        "Xinrui Jiang",
        "Renjie Li",
        "Jian Wang",
        "Yide Zhang",
        "Gengchen Mai",
        "Lihong V. Wang",
        "James Zou",
        "Xiaoyu Wang",
        "Ming-Hsuan Yang",
        "Zhengzhong Tu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T17:59:19+00:00",
          "link": "https://arxiv.org/abs/2507.07105v1",
          "size": "24315kb",
          "version": "v1"
        }
      ],
      "title": "4KAgent: Agentic Any Image to 4K Super-Resolution",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07105",
        "HTML": "https://arxiv.org/html/2507.07105v1",
        "PDF": "https://arxiv.org/pdf/2507.07105"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses image super-resolution capabilities of the 4KAgent system, focusing on vision models and not addressing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2404.12464",
      "abstract": "To be effectively and safely deployed to global user populations, large language models (LLMs) may need to adapt outputs to user values and cultures, not just know about them. We introduce NormAd, an evaluation framework to assess LLMs' cultural adaptability, specifically measuring their ability to judge social acceptability across varying levels of cultural norm specificity, from abstract values to explicit social norms. As an instantiation of our framework, we create NormAd-Eti, a benchmark of 2.6k situational descriptions representing social-etiquette related cultural norms from 75 countries. Through comprehensive experiments on NormAd-Eti, we find that LLMs struggle to accurately judge social acceptability across these varying degrees of cultural contexts and show stronger adaptability to English-centric cultures over those from the Global South. Even in the simplest setting where the relevant social norms are provided, the best LLMs' performance (< 82\\%) lags behind humans (> 95\\%). In settings with abstract values and country information, model performance drops substantially (< 60\\%), while human accuracy remains high (> 90\\%). Furthermore, we find that models are better at recognizing socially acceptable versus unacceptable situations. Our findings showcase the current pitfalls in socio-cultural reasoning of LLMs which hinder their adaptability for global audiences.",
      "authors": [
        "Abhinav Rao",
        "Akhila Yerukola",
        "Vishwa Shah",
        "Katharina Reinecke",
        "Maarten Sap"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-18T18:48:50+00:00",
          "link": "https://arxiv.org/abs/2404.12464v1",
          "size": "8920kb",
          "version": "v1"
        },
        {
          "date": "2024-05-23T17:49:51+00:00",
          "link": "https://arxiv.org/abs/2404.12464v2",
          "size": "8930kb",
          "version": "v2"
        },
        {
          "date": "2024-05-27T00:06:31+00:00",
          "link": "https://arxiv.org/abs/2404.12464v3",
          "size": "8930kb",
          "version": "v3"
        },
        {
          "date": "2024-06-06T16:02:39+00:00",
          "link": "https://arxiv.org/abs/2404.12464v4",
          "size": "8932kb",
          "version": "v4"
        },
        {
          "date": "2024-07-11T14:05:59+00:00",
          "link": "https://arxiv.org/abs/2404.12464v5",
          "size": "8349kb",
          "version": "v5"
        },
        {
          "date": "2024-10-19T05:35:57+00:00",
          "link": "https://arxiv.org/abs/2404.12464v6",
          "size": "9878kb",
          "version": "v6"
        },
        {
          "date": "2024-10-28T00:05:23+00:00",
          "link": "https://arxiv.org/abs/2404.12464v7",
          "size": "9878kb",
          "version": "v7"
        },
        {
          "date": "2025-02-24T15:50:39+00:00",
          "link": "https://arxiv.org/abs/2404.12464v8",
          "size": "12371kb",
          "version": "v8"
        },
        {
          "date": "2025-03-06T16:13:04+00:00",
          "link": "https://arxiv.org/abs/2404.12464v9",
          "size": "12392kb",
          "version": "v9"
        },
        {
          "date": "2025-07-08T20:56:42+00:00",
          "link": "https://arxiv.org/abs/2404.12464v10",
          "size": "11689kb",
          "version": "v10"
        }
      ],
      "title": "NormAd: A Framework for Measuring the Cultural Adaptability of Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.12464",
        "HTML": "https://arxiv.org/html/2404.12464",
        "PDF": "https://arxiv.org/pdf/2404.12464"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a framework for evaluating cultural adaptability of LLMs but does not involve LLM training data processing."
      },
      "datasets": [
        {
          "dataset_name": "akhilayerukola/NormAd",
          "downloads": "544",
          "likes": "1",
          "link": "https://huggingface.co/datasets/akhilayerukola/NormAd"
        }
      ],
      "tasks": [
        "Navigate",
        "Specificity"
      ],
      "repo_urls": [
        "https://github.com/akhila-yerukola/normad"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06547",
      "abstract": "While diffusion models excel at image generation, their growing adoption raises critical concerns around copyright issues and model transparency. Existing attribution methods identify training examples influencing an entire image, but fall short in isolating contributions to specific elements, such as styles or objects, that matter most to stakeholders. To bridge this gap, we introduce \\emph{concept-level attribution} via a novel method called \\emph{Concept-TRAK}. Concept-TRAK extends influence functions with two key innovations: (1) a reformulated diffusion training loss based on diffusion posterior sampling, enabling robust, sample-specific attribution; and (2) a concept-aware reward function that emphasizes semantic relevance. We evaluate Concept-TRAK on the AbC benchmark, showing substantial improvements over prior methods. Through diverse case studies--ranging from identifying IP-protected and unsafe content to analyzing prompt engineering and compositional learning--we demonstrate how concept-level attribution yields actionable insights for responsible generative AI development and governance.",
      "authors": [
        "Yonghyun Park",
        "Chieh-Hsin Lai",
        "Satoshi Hayakawa",
        "Yuhta Takida",
        "Naoki Murata",
        "Wei-Hsiang Liao",
        "Woosung Choi",
        "Kin Wai Cheuk",
        "Junghyun Koo",
        "Yuki Mitsufuji"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T05:03:57+00:00",
          "link": "https://arxiv.org/abs/2507.06547v1",
          "size": "2148kb",
          "version": "v1"
        }
      ],
      "title": "Concept-TRAK: Understanding how diffusion models learn concepts through concept-level attribution",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06547",
        "HTML": "https://arxiv.org/html/2507.06547v1",
        "PDF": "https://arxiv.org/pdf/2507.06547"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "While the paper discusses diffusion models and concept-level attribution, it does not cover LLM training data collection, processing, or engineering specifically."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06554",
      "abstract": "Retrieval-Augmented Generation (RAG) is a core approach for enhancing Large Language Models (LLMs), where the effectiveness of the retriever largely determines the overall response quality of RAG systems. Retrievers encompass a multitude of hyperparameters that significantly impact performance outcomes and demonstrate sensitivity to specific applications. Nevertheless, hyperparameter optimization entails prohibitively high computational expenses. Existing evaluation methods suffer from either prohibitive costs or disconnection from domain-specific scenarios. This paper proposes SEARA (Subset sampling Evaluation for Automatic Retriever Assessment), which addresses evaluation data challenges through subset sampling techniques and achieves robust automated retriever evaluation by minimal retrieval facts extraction and comprehensive retrieval metrics. Based on real user queries, this method enables fully automated retriever evaluation at low cost, thereby obtaining optimal retriever for specific business scenarios. We validate our method across classic RAG applications in rednote, including knowledge-based Q&A system and retrieval-based travel assistant, successfully obtaining scenario-specific optimal retrievers.",
      "authors": [
        "Zou Yuheng",
        "Wang Yiran",
        "Tian Yuzhu",
        "Zhu Min",
        "Huang Yanhua"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T05:13:09+00:00",
          "link": "https://arxiv.org/abs/2507.06554v1",
          "size": "2947kb",
          "version": "v1"
        }
      ],
      "title": "SPEAR: Subset-sampled Performance Evaluation via Automated Ground Truth Generation for RAG",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06554",
        "HTML": "https://arxiv.org/html/2507.06554v1",
        "PDF": "https://arxiv.org/pdf/2507.06554"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper addresses evaluation methods for retrieval systems in RAG, which indirectly relates to LLM performance, but does not focus on processing or creating LLM training data itself."
      },
      "source": "arXiv"
    },
    {
      "id": "2405.11143",
      "abstract": "Large Language Models (LLMs) fine-tuned via Reinforcement Learning from Human Feedback (RLHF) and Reinforcement Learning with Verifiable Rewards (RLVR) significantly improve the alignment of human-AI values and further raise the upper bound of AI capabilities, particularly in reasoning-intensive, long-context Chain-of-Thought (long-CoT) tasks. However, existing RLHF (or RLVR) frameworks commonly face challenges such as inference bottlenecks and complexity barriers, restricting their accessibility for newcomers. To bridge this gap, we introduce OpenRLHF, a user-friendly, scalable, and easy-to-learn open-source RLHF framework built upon Ray, vLLM, DeepSpeed, and HuggingFace Transformers, featuring a simplified design, clear code structure, and comprehensive documentation to facilitate entry for researchers and practitioners. Experimental results show that OpenRLHF achieves superior training efficiency with speedups ranging from 1.22x to 1.68x across different model sizes compared to state-of-the-art frameworks, while requiring significantly fewer lines of code for implementation. OpenRLHF is publicly available at https://github.com/OpenRLHF/OpenRLHF, and has already been adopted by leading institutions to accelerate RLHF research and learning.",
      "authors": [
        "Jian Hu",
        "Xibin Wu",
        "Wei Shen",
        "Jason Klein Liu",
        "Zilin Zhu",
        "Weixun Wang",
        "Songlin Jiang",
        "Haoran Wang",
        "Hao Chen",
        "Bin Chen",
        "Weikai Fang",
        "Xianyu",
        "Yu Cao",
        "Haotian Xu",
        "Yiming Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-20T01:04:40+00:00",
          "link": "https://arxiv.org/abs/2405.11143v1",
          "size": "1062kb",
          "version": "v1"
        },
        {
          "date": "2024-06-03T12:19:18+00:00",
          "link": "https://arxiv.org/abs/2405.11143v2",
          "size": "1067kb",
          "version": "v2"
        },
        {
          "date": "2024-07-17T09:18:35+00:00",
          "link": "https://arxiv.org/abs/2405.11143v3",
          "size": "1067kb",
          "version": "v3"
        },
        {
          "date": "2024-11-24T08:34:48+00:00",
          "link": "https://arxiv.org/abs/2405.11143v4",
          "size": "1067kb",
          "version": "v4"
        },
        {
          "date": "2025-07-04T06:10:22+00:00",
          "link": "https://arxiv.org/abs/2405.11143v5",
          "size": "2596kb",
          "version": "v5"
        }
      ],
      "title": "OpenRLHF: An Easy-to-use, Scalable and High-performance RLHF Framework",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.11143",
        "HTML": "https://arxiv.org/html/2405.11143v5",
        "PDF": "https://arxiv.org/pdf/2405.11143"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses an RLHF framework for training LLMs, mentioning improvements in training efficiency, yet it focuses more on the RLHF framework implementation rather than making direct contributions to LLM training data processing."
      },
      "models": [
        {
          "model_path": "Jennny/llama3-1-8b-bb-rm",
          "downloads": "7",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/Jennny/llama3-1-8b-bb-rm"
        }
      ],
      "tasks": [
        "reinforcement-learning",
        "Reinforcement Learning",
        "Scheduling"
      ],
      "repo_urls": [
        "https://github.com/mickelliu/selfplay-redteaming",
        "https://github.com/OpenLLMAI/OpenRLHF",
        "https://github.com/openrlhf/openrlhf",
        "https://github.com/OpenLLMAI/OpenLLaMA2"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06434",
      "abstract": "As frontier artificial intelligence (AI) models rapidly advance, benchmarks are integral to comparing different models and measuring their progress in different task-specific domains. However, there is a lack of guidance on when and how benchmarks should be deprecated once they cease to effectively perform their purpose. This risks benchmark scores over-valuing model capabilities, or worse, obscuring capabilities and safety-washing. Based on a review of benchmarking practices, we propose criteria to decide when to fully or partially deprecate benchmarks, and a framework for deprecating benchmarks. Our work aims to advance the state of benchmarking towards rigorous and quality evaluations, especially for frontier models, and our recommendations are aimed to benefit benchmark developers, benchmark users, AI governance actors (across governments, academia, and industry panels), and policy makers.",
      "authors": [
        "Ayrton San Joaquin",
        "Rokas Gipi\\v{s}kis",
        "Leon Staufer",
        "Ariel Gil"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T22:29:06+00:00",
          "link": "https://arxiv.org/abs/2507.06434v1",
          "size": "50kb",
          "version": "v1"
        }
      ],
      "title": "Deprecating Benchmarks: Criteria and Framework",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06434",
        "HTML": "https://arxiv.org/html/2507.06434v1",
        "PDF": "https://arxiv.org/pdf/2507.06434"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper offers criteria for deprecating benchmarks, which pertains to evaluation rather than LLM training data processing or new dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2406.05162",
      "abstract": "This article compares the performance of the AVL tree to the performance of the bottom-up, top-down, and left-leaning red-black trees. The bottom-up red-black tree is faster than the AVL tree for insertion and deletion of randomly ordered keys. The AVL tree is faster than the bottom-up red-black tree for insertion but slower for deletion of consecutively ordered keys. The top-down red-black tree is faster than the bottom-up red-black tree for insertion but slower for deletion of randomly ordered keys, and slower for insertion and deletion of consecutively ordered keys. The left-leaning red-black tree is slower than the three other trees for insertion and deletion of randomly and consecutively ordered keys. An alternative deletion algorithm, which reduces the number of rebalancing operations required by deletion, is analyzed.",
      "authors": [
        "Russell A. Brown"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-07T00:48:47+00:00",
          "link": "https://arxiv.org/abs/2406.05162v1",
          "size": "55kb",
          "version": "v1"
        },
        {
          "date": "2024-06-11T17:52:30+00:00",
          "link": "https://arxiv.org/abs/2406.05162v2",
          "size": "150kb",
          "version": "v2"
        },
        {
          "date": "2024-06-18T13:17:07+00:00",
          "link": "https://arxiv.org/abs/2406.05162v3",
          "size": "121kb",
          "version": "v3"
        },
        {
          "date": "2024-06-25T16:40:11+00:00",
          "link": "https://arxiv.org/abs/2406.05162v4",
          "size": "121kb",
          "version": "v4"
        },
        {
          "date": "2024-07-01T19:14:17+00:00",
          "link": "https://arxiv.org/abs/2406.05162v5",
          "size": "26kb",
          "version": "v5"
        },
        {
          "date": "2024-07-18T18:43:59+00:00",
          "link": "https://arxiv.org/abs/2406.05162v6",
          "size": "25kb",
          "version": "v6"
        },
        {
          "date": "2024-08-05T23:15:45+00:00",
          "link": "https://arxiv.org/abs/2406.05162v7",
          "size": "25kb",
          "version": "v7"
        },
        {
          "date": "2024-08-12T15:13:34+00:00",
          "link": "https://arxiv.org/abs/2406.05162v8",
          "size": "78kb",
          "version": "v8"
        },
        {
          "date": "2024-08-18T14:28:56+00:00",
          "link": "https://arxiv.org/abs/2406.05162v9",
          "size": "80kb",
          "version": "v9"
        },
        {
          "date": "2024-11-10T16:45:30+00:00",
          "link": "https://arxiv.org/abs/2406.05162v10",
          "size": "35564kb",
          "version": "v10"
        },
        {
          "date": "2024-11-25T05:21:48+00:00",
          "link": "https://arxiv.org/abs/2406.05162v11",
          "size": "35677kb",
          "version": "v11"
        },
        {
          "date": "2024-12-01T16:14:30+00:00",
          "link": "https://arxiv.org/abs/2406.05162v12",
          "size": "35682kb",
          "version": "v12"
        },
        {
          "date": "2024-12-08T21:01:38+00:00",
          "link": "https://arxiv.org/abs/2406.05162v13",
          "size": "35682kb",
          "version": "v13"
        },
        {
          "date": "2024-12-15T23:28:57+00:00",
          "link": "https://arxiv.org/abs/2406.05162v14",
          "size": "35682kb",
          "version": "v14"
        },
        {
          "date": "2024-12-22T04:14:34+00:00",
          "link": "https://arxiv.org/abs/2406.05162v15",
          "size": "35671kb",
          "version": "v15"
        },
        {
          "date": "2024-12-29T21:03:26+00:00",
          "link": "https://arxiv.org/abs/2406.05162v16",
          "size": "35670kb",
          "version": "v16"
        },
        {
          "date": "2025-03-02T16:06:47+00:00",
          "link": "https://arxiv.org/abs/2406.05162v17",
          "size": "35794kb",
          "version": "v17"
        },
        {
          "date": "2025-03-09T15:31:49+00:00",
          "link": "https://arxiv.org/abs/2406.05162v18",
          "size": "35834kb",
          "version": "v18"
        },
        {
          "date": "2025-03-16T23:38:46+00:00",
          "link": "https://arxiv.org/abs/2406.05162v19",
          "size": "35834kb",
          "version": "v19"
        },
        {
          "date": "2025-04-16T21:34:31+00:00",
          "link": "https://arxiv.org/abs/2406.05162v20",
          "size": "35705kb",
          "version": "v20"
        },
        {
          "date": "2025-06-02T16:45:44+00:00",
          "link": "https://arxiv.org/abs/2406.05162v21",
          "size": "35719kb",
          "version": "v21"
        }
      ],
      "title": "Comparative Performance of the AVL Tree and Three Variants of the Red-Black Tree",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.05162",
        "HTML": "https://arxiv.org/html/2406.05162",
        "PDF": "https://arxiv.org/pdf/2406.05162"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on comparing the performance of data structures (AVL trees and variants of the red-black tree), which does not address the collection or processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.16514",
      "abstract": "Since the final quantum state in the Grover search algorithm is the normalized marked quantum state from the Gram-Schmidt process, Abrams and Lloyd[1] has shown that we can generate this vector by using a non-unitary gate. Following their ideas, in this paper, we present multiple explicit unitary implementations by using the square root of the non-unitary matrix and by a unitary matrix that mimics the Gram-Schmidt process. We also discuss the implementation through a linear combination of unitary matrices or similar methods and how these approximations may change the complexity. The reading of the marked element from the given circuits with high probability still requires multiple repetitions similar to the original algorithm. However, it gives an alternative implementations which may be useful in certain platforms.",
      "authors": [
        "Ammar Daskin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Computational Complexity (cs.CC)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-21T07:26:30+00:00",
          "link": "https://arxiv.org/abs/2412.16514v1",
          "size": "54kb",
          "version": "v1"
        },
        {
          "date": "2024-12-24T05:58:43+00:00",
          "link": "https://arxiv.org/abs/2412.16514v2",
          "size": "100kb",
          "version": "v2"
        },
        {
          "date": "2024-12-29T13:20:37+00:00",
          "link": "https://arxiv.org/abs/2412.16514v3",
          "size": "573kb",
          "version": "v3"
        },
        {
          "date": "2025-01-17T06:58:52+00:00",
          "link": "https://arxiv.org/abs/2412.16514v4",
          "size": "620kb",
          "version": "v4"
        },
        {
          "date": "2025-03-10T17:39:10+00:00",
          "link": "https://arxiv.org/abs/2412.16514v5",
          "size": "620kb",
          "version": "v5"
        },
        {
          "date": "2025-07-09T07:32:37+00:00",
          "link": "https://arxiv.org/abs/2412.16514v6",
          "size": "574kb",
          "version": "v6"
        }
      ],
      "title": "An alternative explicit circuit diagram for the quantum search algorithm by implementing a non-unitary gate",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.16514",
        "HTML": "https://arxiv.org/html/2412.16514",
        "PDF": "https://arxiv.org/pdf/2412.16514"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with quantum algorithm implementation and does not relate to processing LLM training data."
      },
      "repo_urls": [
        "https://github.com/adaskin/nonunitary-search"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.04544",
      "abstract": "Large language models (LLMs) are playing an increasingly large role in domains such as code generation, including hardware code generation, where Verilog is the key language. However, the amount of publicly available Verilog code pales in comparison to the amount of code available for software languages like Python. In this work, we present hdl2v (\"HDL-to-Verilog\"), a dataset which seeks to increase the amount of available human-written Verilog data by translating or compiling three other hardware description languages - VHDL, Chisel, and PyMTL3 - to Verilog. Furthermore, we demonstrate the value of hdl2v in enhancing LLM Verilog generation by improving performance of a 32 billion-parameter open-weight model by up to 23% (pass@10) in VerilogEvalV2, without utilizing any data augmentation or knowledge distillation from larger models. We also show hdl2v's ability to boost the performance of a data augmentation-based fine-tuning approach by 63%. Finally, we characterize and analyze our dataset to better understand which characteristics of HDL-to-Verilog datasets can be expanded upon in future work for even better performance.",
      "authors": [
        "Charles Hong",
        "Brendan Roberts",
        "Huijae An",
        "Alex Um",
        "Advay Ratan",
        "Yakun Sophia Shao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-05T01:29:18+00:00",
          "link": "https://arxiv.org/abs/2506.04544v1",
          "size": "645kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T19:43:08+00:00",
          "link": "https://arxiv.org/abs/2506.04544v2",
          "size": "487kb",
          "version": "v2"
        }
      ],
      "title": "hdl2v: A Code Translation Dataset for Enhanced LLM Verilog Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.04544",
        "HTML": "https://arxiv.org/html/2506.04544v2",
        "PDF": "https://arxiv.org/pdf/2506.04544"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper presents 'hdl2v', a dataset specifically created by translating other hardware description languages to Verilog, which is used to enhance LLM Verilog generation. It involves data translation, dataset characterization, and discusses its impact on LLM training, making it a core contribution to LLM training data processing."
      },
      "tasks": [
        "Code Generation",
        "Code Translation",
        "Data Augmentation",
        "Knowledge Distillation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.03633",
      "abstract": "EEG signals capture brain activity with high temporal and low spatial resolution, supporting applications such as neurological diagnosis, cognitive monitoring, and brain-computer interfaces. However, effective analysis is hindered by limited labeled data, high dimensionality, and the absence of scalable models that fully capture spatiotemporal dependencies. Existing self-supervised learning (SSL) methods often focus on either spatial or temporal features, leading to suboptimal representations. To this end, we propose EEG-VJEPA, a novel adaptation of the Video Joint Embedding Predictive Architecture (V-JEPA) for EEG classification. By treating EEG as video-like sequences, EEG-VJEPA learns semantically meaningful spatiotemporal representations using joint embeddings and adaptive masking. To our knowledge, this is the first work that exploits V-JEPA for EEG classification and explores the visual concepts learned by the model. Evaluations on the publicly available Temple University Hospital (TUH) Abnormal EEG dataset show that EEG-VJEPA outperforms existing state-of-the-art models in classification accuracy. Beyond classification accuracy, EEG-VJEPA captures physiologically relevant spatial and temporal signal patterns, offering interpretable embeddings that may support human-AI collaboration in diagnostic workflows. These findings position EEG-VJEPA as a promising framework for scalable, trustworthy EEG analysis in real-world clinical settings.",
      "authors": [
        "Amirabbas Hojjati",
        "Lu Li",
        "Ibrahim Hameed",
        "Anis Yazidi",
        "Pedro G. Lind",
        "Rabindra Khadka"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-04T15:01:34+00:00",
          "link": "https://arxiv.org/abs/2507.03633v1",
          "size": "5449kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T06:52:14+00:00",
          "link": "https://arxiv.org/abs/2507.03633v2",
          "size": "5449kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T15:43:06+00:00",
          "link": "https://arxiv.org/abs/2507.03633v3",
          "size": "5449kb",
          "version": "v3"
        }
      ],
      "title": "From Video to EEG: Adapting Joint Embedding Predictive Architecture to Uncover Visual Concepts in Brain Signal Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.03633",
        "HTML": "https://arxiv.org/html/2507.03633v3",
        "PDF": "https://arxiv.org/pdf/2507.03633"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on adapting EEG analysis through self-supervised learning and does not involve processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06464",
      "abstract": "Adam has proven remarkable successful in training deep neural networks, but the mechanisms underlying its empirical successes and limitations remain underexplored. In this study, we demonstrate that the effectiveness of Adam stems largely from its similarity to SignSGD in robustly handling large gradient fluctuations, yet it is also vulnerable to destabilizing loss spikes due to its uncontrolled update scaling. To enhance the advantage of Adam and mitigate its limitation, we propose SignSoftSGD (S3), a novel optimizer with three key innovations. \\emph{First}, S3 generalizes the sign-like update by employing a flexible $p$-th order momentum ($p \\geq 1$) in the denominator, departing from the conventional second-order momentum (variance) preconditioning. This design enables enhanced performance while achieving stable training even with aggressive learning rates. \\emph{Second}, S3 minimizes the occurrences of loss spikes through unified exponential moving average coefficients for numerator and denominator momenta, which inherently bound updates to $[-1, 1]$ and simplify hyperparameter tuning. \\emph{Third}, S3 incorporates an equivalent Nesterov's accelerated gradient(NAG) module, accelerating convergence without memory overhead. Theoretically, we prove that S3 achieves the optimal convergence rate of $O\\left(\\frac{1}{T^{\\sfrac{1}{4}}}\\right)$ for general nonconvex stochastic optimization under weak assumptions. Extensive experiments across a range of vision and language tasks show that \\textsf{\\small S3} not only converges more rapidly and improves performance but also rarely experiences loss spikes, even with a \\textbf{$\\bm{10 \\times}$} larger learning rate. In fact, S3 delivers performance comparable to or better than AdamW with \\textbf{$2 \\times$} the training steps, establishing its efficacy in both efficiency and final task performance.",
      "authors": [
        "Hanyang Peng",
        "Shuang Qin",
        "Yue Yu",
        "Fangqing Jiang",
        "Hui Wang and Wen Gao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T00:47:37+00:00",
          "link": "https://arxiv.org/abs/2507.06464v1",
          "size": "4076kb",
          "version": "v1"
        }
      ],
      "title": "SoftSignSGD(S3): An Enhanced Optimizer for Practical DNN Training and Loss Spikes Minimization Beyond Adam",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06464",
        "HTML": "https://arxiv.org/html/2507.06464v1",
        "PDF": "https://arxiv.org/pdf/2507.06464"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a novel optimization technique for DNN training, which does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07077",
      "abstract": "Accurately converting pixel measurements into absolute real-world dimensions remains a fundamental challenge in computer vision and limits progress in key applications such as biomedicine, forensics, nutritional analysis, and e-commerce. We introduce RulerNet, a deep learning framework that robustly infers scale \"in the wild\" by reformulating ruler reading as a unified keypoint-detection problem and by representing the ruler with geometric-progression parameters that are invariant to perspective transformations. Unlike traditional methods that rely on handcrafted thresholds or rigid, ruler-specific pipelines, RulerNet directly localizes centimeter marks using a distortion-invariant annotation and training strategy, enabling strong generalization across diverse ruler types and imaging conditions while mitigating data scarcity. We also present a scalable synthetic-data pipeline that combines graphics-based ruler generation with ControlNet to add photorealistic context, greatly increasing training diversity and improving performance. To further enhance robustness and efficiency, we propose DeepGP, a lightweight feed-forward network that regresses geometric-progression parameters from noisy marks and eliminates iterative optimization, enabling real-time scale estimation on mobile or edge devices. Experiments show that RulerNet delivers accurate, consistent, and efficient scale estimates under challenging real-world conditions. These results underscore its utility as a generalizable measurement tool and its potential for integration with other vision components for automated, scale-aware analysis in high-impact domains. A live demo is available at https://huggingface.co/spaces/ymp5078/RulerNet-Demo.",
      "authors": [
        "Yimu Pan",
        "Manas Mehta",
        "Gwen Sincerbeaux",
        "Jeffery A. Goldstein",
        "Alison D. Gernand",
        "James Z. Wang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T17:35:58+00:00",
          "link": "https://arxiv.org/abs/2507.07077v1",
          "size": "11770kb",
          "version": "v1"
        }
      ],
      "title": "Reading a Ruler in the Wild",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07077",
        "PDF": "https://arxiv.org/pdf/2507.07077"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper describes a scalable synthetic-data pipeline that enhances training diversity by creating photorealistic context in data, significantly focusing on data generation and processing for model training."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.11199",
      "abstract": "The advances in immersive technologies and 3D reconstruction have enabled the creation of digital replicas of real-world objects and environments with fine details. These processes generate vast amounts of 3D data, requiring more efficient compression methods to satisfy the memory and bandwidth constraints associated with data storage and transmission. However, the development and validation of efficient 3D data compression methods are constrained by the lack of comprehensive and high-quality volumetric video datasets, which typically require much more effort to acquire and consume increased resources compared to 2D image and video databases. To bridge this gap, we present an open multi-view volumetric human dataset, denoted BVI-CR, which contains 18 multi-view RGB-D captures and their corresponding textured polygonal meshes, depicting a range of diverse human actions. Each video sequence contains 10 views in 1080p resolution with durations between 10-15 seconds at 30FPS. Using BVI-CR, we benchmarked three conventional and neural coordinate-based multi-view video compression methods, following the MPEG MIV Common Test Conditions, and reported their rate quality performance based on various quality metrics. The results show the great potential of neural representation based methods in volumetric video compression compared to conventional video coding methods (with an up to 38\\% average coding gain in PSNR). This dataset provides a development and validation platform for a variety of tasks including volumetric reconstruction, compression, and quality assessment. The database will be shared publicly at \\url{https://github.com/fan-aaron-zhang/bvi-cr}.",
      "authors": [
        "Ge Gao",
        "Adrian Azzarelli",
        "Ho Man Kwan",
        "Nantheera Anantrasirichai",
        "Fan Zhang",
        "Oliver Moolan-Feroze",
        "David Bull"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-17T23:22:48+00:00",
          "link": "https://arxiv.org/abs/2411.11199v1",
          "size": "27033kb",
          "version": "v1"
        }
      ],
      "title": "BVI-CR: A Multi-View Human Dataset for Volumetric Video Compression",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.11199",
        "HTML": "https://arxiv.org/html/2411.11199",
        "PDF": "https://arxiv.org/pdf/2411.11199"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a volumetric video dataset for video compression. While it details dataset creation, it is not centered on LLM training data processing."
      },
      "tasks": [
        "3D Reconstruction",
        "Data Compression",
        "Video Compression"
      ],
      "repo_urls": [
        "https://github.com/fan-aaron-zhang/bvi-cr"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06542",
      "abstract": "Decentralized learning provides a scalable alternative to traditional parameter-server-based training, yet its performance is often hindered by limited peer-to-peer communication. In this paper, we study how communication should be scheduled over time, including determining when and how frequently devices synchronize. Our empirical results show that concentrating communication budgets in the later stages of decentralized training markedly improves global generalization. Surprisingly, we uncover that fully connected communication at the final step, implemented by a single global merging, is sufficient to match the performance of server-based training. We further show that low communication in decentralized learning preserves the \\textit{mergeability} of local models throughout training. Our theoretical contributions, which explains these phenomena, are first to establish that the globally merged model of decentralized SGD can converge faster than centralized mini-batch SGD. Technically, we novelly reinterpret part of the discrepancy among local models, which were previously considered as detrimental noise, as constructive components that accelerate convergence. This work challenges the common belief that decentralized learning generalizes poorly under data heterogeneity and limited communication, while offering new insights into model merging and neural network loss landscapes.",
      "authors": [
        "Tongtian Zhu",
        "Tianyu Zhang",
        "Mingze Wang",
        "Zhanpeng Zhou",
        "Can Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Multiagent Systems (cs.MA)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T04:56:56+00:00",
          "link": "https://arxiv.org/abs/2507.06542v1",
          "size": "4540kb",
          "version": "v1"
        }
      ],
      "title": "A Single Merging Suffices: Recovering Server-based Learning Performance in Decentralized Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06542",
        "HTML": "https://arxiv.org/html/2507.06542v1",
        "PDF": "https://arxiv.org/pdf/2507.06542"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on decentralized learning, model merging, and communication strategies but does not discuss any aspect of LLM training data collection, processing, or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06838",
      "abstract": "Retrieval in Retrieval-Augmented Generation(RAG) must ensure that retrieved passages are not only individually relevant but also collectively form a comprehensive set. Existing approaches primarily rerank top-k passages based on their individual relevance, often failing to meet the information needs of complex queries in multi-hop question answering. In this work, we propose a set-wise passage selection approach and introduce SETR, which explicitly identifies the information requirements of a query through Chain-of-Thought reasoning and selects an optimal set of passages that collectively satisfy those requirements. Experiments on multi-hop RAG benchmarks show that SETR outperforms both proprietary LLM-based rerankers and open-source baselines in terms of answer correctness and retrieval quality, providing an effective and efficient alternative to traditional rerankers in RAG systems. The code is available at https://github.com/LGAI-Research/SetR",
      "authors": [
        "Dahyun Lee",
        "Yongrae Jo",
        "Haeju Park",
        "Moontae Lee"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T13:35:36+00:00",
          "link": "https://arxiv.org/abs/2507.06838v1",
          "size": "1659kb",
          "version": "v1"
        }
      ],
      "title": "Shifting from Ranking to Set Selection for Retrieval Augmented Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06838",
        "HTML": "https://arxiv.org/html/2507.06838v1",
        "PDF": "https://arxiv.org/pdf/2507.06838"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with retrieval-augmented generation by improving passage selection but does not focus on processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06681",
      "abstract": "We describe a complete algorithm to compute millions of coefficients of classical modular forms in a few seconds. We also review operations on Euler products and illustrate our methods with a computation of triple product L-function of large conductor.",
      "authors": [
        "Pascal Molin (IMJ-PRG (UMR\\_7586)",
        "OURAGAN)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Symbolic Computation (cs.SC)",
        "Number Theory (math.NT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T09:18:51+00:00",
          "link": "https://arxiv.org/abs/2507.06681v1",
          "size": "220kb",
          "version": "v1"
        }
      ],
      "title": "Computing Euler products and coefficients of classical modular forms for twisted L-functions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06681",
        "PDF": "https://arxiv.org/pdf/2507.06681"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on computing coefficients of classical modular forms and operations on Euler products, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06825",
      "abstract": "We introduce a real-time strategy game environment built on Generals.io, a game that hosts thousands of active players each week across multiple game formats. Our environment is fully compatible with Gymnasium and PettingZoo, capable of running thousands of frames per second on commodity hardware. Our reference agent -- trained with supervised pre-training and self-play -- hits the top 0.003\\% of the 1v1 human leaderboard after just 36 hours on a single H100 GPU. To accelerate learning, we incorporate potential-based reward shaping and memory features. Our contributions -- a modular RTS benchmark and a competitive, state-of-the-art baseline agent -- provide an accessible yet challenging platform for advancing multi-agent reinforcement learning research.",
      "authors": [
        "Matej Straka",
        "Martin Schmid"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T13:15:05+00:00",
          "link": "https://arxiv.org/abs/2507.06825v1",
          "size": "1198kb",
          "version": "v1"
        }
      ],
      "title": "Artificial Generals Intelligence: Mastering Generals.io with Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06825",
        "HTML": "https://arxiv.org/html/2507.06825v1",
        "PDF": "https://arxiv.org/pdf/2507.06825"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses reinforcement learning in gaming, including supervised pre-training. It mentions large-scale data processing for model training but does not focus primarily on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06952",
      "abstract": "Foundation models are premised on the idea that sequence prediction can uncover deeper domain understanding, much like how Kepler's predictions of planetary motion later led to the discovery of Newtonian mechanics. However, evaluating whether these models truly capture deeper structure remains a challenge. We develop a technique for evaluating foundation models that examines how they adapt to synthetic datasets generated from some postulated world model. Our technique measures whether the foundation model's inductive bias aligns with the world model, and so we refer to it as an inductive bias probe. Across multiple domains, we find that foundation models can excel at their training tasks yet fail to develop inductive biases towards the underlying world model when adapted to new tasks. We particularly find that foundation models trained on orbital trajectories consistently fail to apply Newtonian mechanics when adapted to new physics tasks. Further analysis reveals that these models behave as if they develop task-specific heuristics that fail to generalize.",
      "authors": [
        "Keyon Vafa",
        "Peter G. Chang",
        "Ashesh Rambachan",
        "Sendhil Mullainathan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T15:36:15+00:00",
          "link": "https://arxiv.org/abs/2507.06952v1",
          "size": "3388kb",
          "version": "v1"
        }
      ],
      "title": "What Has a Foundation Model Found? Using Inductive Bias to Probe for World Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06952",
        "PDF": "https://arxiv.org/pdf/2507.06952"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper develops a technique for evaluating foundation models and does not focus on training data processing or dataset creation for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2402.02342",
      "abstract": "We address the challenge of optimizing meta-parameters (hyperparameters) in machine learning, a key factor for efficient training and high model performance. Rather than relying on expensive meta-parameter search methods, we introduce MetaOptimize: a dynamic approach that adjusts meta-parameters, particularly step sizes (also known as learning rates), during training. More specifically, MetaOptimize can wrap around any first-order optimization algorithm, tuning step sizes on the fly to minimize a specific form of regret that considers the long-term impact of step sizes on training, through a discounted sum of future losses. We also introduce lower-complexity variants of MetaOptimize that, in conjunction with its adaptability to various optimization algorithms, achieve performance comparable to those of the best hand-crafted learning rate schedules across diverse machine learning tasks.",
      "authors": [
        "Arsalan Sharifnassab",
        "Saber Salehkaleybar",
        "Richard Sutton"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-04T04:55:54+00:00",
          "link": "https://arxiv.org/abs/2402.02342v1",
          "size": "10947kb",
          "version": "v1"
        },
        {
          "date": "2024-02-12T04:19:19+00:00",
          "link": "https://arxiv.org/abs/2402.02342v2",
          "size": "10947kb",
          "version": "v2"
        },
        {
          "date": "2024-05-23T22:02:06+00:00",
          "link": "https://arxiv.org/abs/2402.02342v3",
          "size": "18008kb",
          "version": "v3"
        },
        {
          "date": "2024-05-27T19:52:56+00:00",
          "link": "https://arxiv.org/abs/2402.02342v4",
          "size": "18008kb",
          "version": "v4"
        },
        {
          "date": "2024-10-04T01:08:12+00:00",
          "link": "https://arxiv.org/abs/2402.02342v5",
          "size": "6364kb",
          "version": "v5"
        },
        {
          "date": "2025-07-09T01:03:54+00:00",
          "link": "https://arxiv.org/abs/2402.02342v6",
          "size": "7715kb",
          "version": "v6"
        }
      ],
      "title": "MetaOptimize: A Framework for Optimizing Step Sizes and Other Meta-parameters",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.02342",
        "HTML": "https://arxiv.org/html/2402.02342",
        "PDF": "https://arxiv.org/pdf/2402.02342"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a framework for optimizing meta-parameters like step sizes during model training, which does not involve processing LLM training data."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2412.04202",
      "abstract": "Artificial Intelligence (AI) song generation has emerged as a popular topic, yet the focus on exploring the latent correlations between specific lyrical and rhythmic features remains limited. In contrast, this pilot study particularly investigates the relationships between keywords and rhythmically stressed features such as strong beats in songs. It focuses on several key elements: keywords or non-keywords, stressed or unstressed syllables, and strong or weak beats, with the aim of uncovering insightful correlations. Experimental results indicate that, on average, 80.8\\% of keywords land on strong beats, whereas 62\\% of non-keywords fall on weak beats. The relationship between stressed syllables and strong or weak beats is weak, revealing that keywords have the strongest relationships with strong beats. Additionally, the lyrics-rhythm matching score, a key matching metric measuring keywords on strong beats and non-keywords on weak beats across various time signatures, is 0.765, while the matching score for syllable types is 0.495. This study demonstrates that word types strongly align with their corresponding beat types, as evidenced by the distinct patterns, whereas syllable types exhibit a much weaker alignment. This disparity underscores the greater reliability of word types in capturing rhythmic structures in music, highlighting their crucial role in effective rhythmic matching and analysis. We also conclude that keywords that consistently align with strong beats are more reliable indicators of lyrics-rhythm associations, providing valuable insights for AI-driven song generation through enhanced structural analysis. Furthermore, our development of tailored Lyrics-Rhythm Matching (LRM) metrics maximizes lyrical alignments with corresponding beat stresses, and our novel LRM file format captures critical lyrical and rhythmic information without needing original sheet music.",
      "authors": [
        "Callie C. Liao",
        "Duoduo Liao",
        "and Ellie L. Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-05T14:40:27+00:00",
          "link": "https://arxiv.org/abs/2412.04202v1",
          "size": "1654kb",
          "version": "v1"
        }
      ],
      "title": "Relationships between Keywords and Strong Beats in Lyrical Music",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.04202",
        "HTML": "https://arxiv.org/html/2412.04202",
        "PDF": "https://arxiv.org/pdf/2412.04202"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on AI song generation, examining the rhythmic correlations between keywords and beats, without discussing LLM training data processing or creation."
      },
      "tasks": [
        "Rhythm"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.12982",
      "abstract": "It is well known that evolutionary algorithms can benefit from dynamic choices of the key parameters that control their behavior, to adjust their search strategy to the different stages of the optimization process. A prominent example where dynamic parameter choices have shown a provable super-constant speed-up is the $(1+(\\lambda,\\lambda))$ Genetic Algorithm optimizing the OneMax function. While optimal parameter control policies result in linear expected running times, this is not possible with static parameter choices. This result has spurred a lot of interest in parameter control policies. However, many works, in particular theoretical running time analyses, focus on controlling one single parameter. Deriving policies for controlling multiple parameters remains very challenging. In this work we reconsider the problem of the $(1+(\\lambda,\\lambda))$ Genetic Algorithm optimizing OneMax. We decouple its four main parameters and investigate how well state-of-the-art deep reinforcement learning techniques can approximate good control policies. We show that although making deep reinforcement learning learn effectively is a challenging task, once it works, it is very powerful and is able to find policies that outperform all previously known control policies on the same benchmark. Based on the results found through reinforcement learning, we derive a simple control policy that consistently outperforms the default theory-recommended setting by $27\\%$ and the irace-tuned policy, the strongest existing control policy on this benchmark, by $13\\%$, for all tested problem sizes up to $40{,}000$.",
      "authors": [
        "Tai Nguyen",
        "Phong Le",
        "Carola Doerr",
        "Nguyen Dang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-19T11:18:41+00:00",
          "link": "https://arxiv.org/abs/2505.12982v1",
          "size": "239kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T10:18:09+00:00",
          "link": "https://arxiv.org/abs/2505.12982v2",
          "size": "241kb",
          "version": "v2"
        }
      ],
      "title": "Multi-parameter Control for the $(1+(\\lambda,\\lambda))$-GA on OneMax via Deep Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.12982",
        "HTML": "https://arxiv.org/html/2505.12982v2",
        "PDF": "https://arxiv.org/pdf/2505.12982"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study addresses parameter control in genetic algorithms using reinforcement learning, with no relevance to processing LLM training data."
      },
      "tasks": [
        "Deep Reinforcement Learning",
        "Evolutionary Algorithms",
        "reinforcement-learning",
        "Reinforcement Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06632",
      "abstract": "With rapid urbanization and increasing population density, urban traffic congestion has become a critical issue, and traditional ground transportation methods are no longer sufficient to address it effectively. To tackle this challenge, the concept of Advanced Air Mobility (AAM) has emerged, aiming to utilize low-altitude airspace to establish a three-dimensional transportation system. Among various components of the AAM system, electric vertical take-off and landing (eVTOL) aircraft plays a pivotal role due to their flexibility and efficiency. However, the immaturity of Ultra Reliable Low Latency Communication (URLLC) technologies poses significant challenges to safety-critical AAM operations. Specifically, existing Stacked Intelligent Metasurfaces (SIM)-based eVTOL systems lack rigorous mathematical frameworks to quantify probabilistic delay bounds under dynamic air traffic patterns, a prerequisite for collision avoidance and airspace management. To bridge this gap, we employ network calculus tools to derive the probabilistic upper bound on communication delay in the AAM system for the first time. Furthermore, we formulate a complex non-convex optimization problem that jointly minimizes the probabilistic delay bound and the propagation delay. To solve this problem efficiently, we propose a solution based on the Block Coordinate Descent (BCD) algorithm and Semidefinite Relaxation (SDR) method. In addition, we conduct a comprehensive analysis of how various factors impact regret and transmission rate, and explore the influence of varying load intensity and total delay on the probabilistic delay bound.",
      "authors": [
        "Liyuan Chen",
        "Kai Xiong",
        "Yujie Qin",
        "Hanqing Yu",
        "Supeng Leng",
        "Chau Yuen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T07:59:36+00:00",
          "link": "https://arxiv.org/abs/2507.06632v1",
          "size": "407kb",
          "version": "v1"
        }
      ],
      "title": "Stacked Intelligent Metasurfaces-Aided eVTOL Delay Sensitive Communications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06632",
        "HTML": "https://arxiv.org/html/2507.06632v1",
        "PDF": "https://arxiv.org/pdf/2507.06632"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on communications in Advanced Air Mobility systems and optimization techniques for delay bounds in eVTOL systems, without any mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06861",
      "abstract": "A strategy to construct physics-based local surrogate models for parametric Stokes flows and coupled Stokes-Darcy systems is presented. The methodology relies on the proper generalized decomposition (PGD) method to reduce the dimensionality of the parametric flow fields and on an overlapping domain decomposition (DD) paradigm to reduce the number of globally coupled degrees of freedom in space. The DD-PGD approach provides a non-intrusive framework in which end-users only need access to the matrices arising from the (finite element) discretization of the full-order problems in the subdomains. The traces of the finite element functions used for the discretization within the subdomains are employed to impose arbitrary Dirichlet boundary conditions at the interface, without introducing auxiliary basis functions. The methodology is seamless to the choice of the discretization schemes in space, being compatible with both LBB-compliant finite element pairs and stabilized formulations, and the DD-PGD paradigm is transparent to the employed overlapping DD approach. The local surrogate models are glued together in the online phase by solving a parametric interface system to impose continuity of the subdomain solutions at the interfaces, without introducing Lagrange multipliers to enforce the continuity in the entire overlap and without solving any additional physical problem in the reduced space. Numerical results are presented for parametric single-physics (Stokes-Stokes) and multi-physics (Stokes-Darcy) systems, showcasing the accuracy, robustness, and computational efficiency of DD-PGD, and its capability to outperform DD methods based on high-fidelity finite element solvers in terms of computing times.",
      "authors": [
        "Marco Discacciati",
        "Ben J. Evans",
        "Matteo Giacomini"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T14:01:58+00:00",
          "link": "https://arxiv.org/abs/2507.06861v1",
          "size": "936kb",
          "version": "v1"
        }
      ],
      "title": "An overlapping domain decomposition method for parametric Stokes and Stokes-Darcy problems via proper generalized decomposition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06861",
        "HTML": "https://arxiv.org/html/2507.06861v1",
        "PDF": "https://arxiv.org/pdf/2507.06861"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses domain decomposition methods for parametric Stokes flows and does not involve LLM training data processing or data creation methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.04543",
      "abstract": "We propose Pullback Flow Matching (PFM), a novel framework for generative modeling on data manifolds. Unlike existing methods that assume or learn restrictive closed-form manifold mappings for training Riemannian Flow Matching (RFM) models, PFM leverages pullback geometry and isometric learning to preserve the underlying manifold's geometry while enabling efficient generation and precise interpolation in latent space. This approach not only facilitates closed-form mappings on the data manifold but also allows for designable latent spaces, using assumed metrics on both data and latent manifolds. By enhancing isometric learning through Neural ODEs and proposing a scalable training objective, we achieve a latent space more suitable for interpolation, leading to improved manifold learning and generative performance. We demonstrate PFM's effectiveness through applications in synthetic data, protein dynamics and protein sequence data, generating novel proteins with specific properties. This method shows strong potential for drug discovery and materials science, where generating novel samples with specific properties is of great interest.",
      "authors": [
        "Friso de Kruiff",
        "Erik Bekkers",
        "Ozan \\\"Oktem",
        "Carola-Bibiane Sch\\\"onlieb and Willem Diepeveen"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Differential Geometry (math.DG)",
        "Biomolecules (q-bio.BM)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-06T16:41:26+00:00",
          "link": "https://arxiv.org/abs/2410.04543v1",
          "size": "11725kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T15:53:08+00:00",
          "link": "https://arxiv.org/abs/2410.04543v2",
          "size": "5285kb",
          "version": "v2"
        }
      ],
      "title": "Pullback Flow Matching on Data Manifolds",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.04543",
        "HTML": "https://arxiv.org/html/2410.04543v2",
        "PDF": "https://arxiv.org/pdf/2410.04543"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a framework for generative modeling on data manifolds, focusing on geometry preservation rather than LLM training data processing."
      },
      "tasks": [
        "Drug Discovery"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.18277",
      "abstract": "Though humans seem to be remarkable learners, arguments in cognitive science and philosophy of mind have long maintained that learning something fundamentally new is impossible. Specifically, Jerry Fodor's arguments for radical concept nativism hold that most, if not all, concepts are innate and that what many call concept learning never actually leads to the acquisition of new concepts. These arguments have deeply affected cognitive science, and many believe that the counterarguments to radical concept nativism have been either unsuccessful or only apply to a narrow class of concepts. This paper first reviews the features and limitations of prior arguments. We then identify three critical points - related to issues of expressive power, conceptual structure, and concept possession - at which the arguments in favor of radical concept nativism diverge from describing actual human cognition. We use ideas from computer science and information theory to formalize the relevant ideas in ways that are arguably more scientifically productive. We conclude that, as a result, there is an important sense in which people do indeed learn new concepts.",
      "authors": [
        "Joshua S. Rule and Steven T. Piantadosi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-23T18:12:38+00:00",
          "link": "https://arxiv.org/abs/2505.18277v1",
          "size": "452kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T16:18:56+00:00",
          "link": "https://arxiv.org/abs/2505.18277v2",
          "size": "455kb",
          "version": "v2"
        }
      ],
      "title": "The end of radical concept nativism",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.18277",
        "HTML": "https://arxiv.org/html/2505.18277v2",
        "PDF": "https://arxiv.org/pdf/2505.18277"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses cognitive science concepts and philosophy related to concept learning, without any focus on LLM training data processing or data engineering methodologies."
      },
      "tasks": [
        "Philosophy"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.11472",
      "abstract": "Autonomous vehicles (AVs) rely on deep neural networks (DNNs) for critical tasks such as traffic sign recognition (TSR), automated lane centering (ALC), and vehicle detection (VD). However, these models are vulnerable to attacks that can cause misclassifications and compromise safety. Traditional defense mechanisms, including adversarial training, often degrade benign accuracy and fail to generalize against unseen attacks. In this work, we introduce Vehicle Vision Language Models (V2LMs), fine-tuned vision-language models specialized for AV perception. Our findings demonstrate that V2LMs inherently exhibit superior robustness against unseen attacks without requiring adversarial training, maintaining significantly higher accuracy than conventional DNNs under adversarial conditions. We evaluate two deployment strategies: Solo Mode, where individual V2LMs handle specific perception tasks, and Tandem Mode, where a single unified V2LM is fine-tuned for multiple tasks simultaneously. Experimental results reveal that DNNs suffer performance drops of 33% to 46% under attacks, whereas V2LMs maintain adversarial accuracy with reductions of less than 8% on average. The Tandem Mode further offers a memory-efficient alternative while achieving comparable robustness to Solo Mode. We also explore integrating V2LMs as parallel components to AV perception to enhance resilience against adversarial threats. Our results suggest that V2LMs offer a promising path toward more secure and resilient AV perception systems.",
      "authors": [
        "Pedram MohajerAnsari (1)",
        "Amir Salarpour (1)",
        "Michael K\\\"uhr (2)",
        "Siyu Huang (1)",
        "Mohammad Hamad (2)",
        "Sebastian Steinhorst (2)",
        "Habeeb Olufowobi (3)",
        "Mert D. Pes\\'e (1) ((1) Clemson University",
        "Clemson",
        "SC",
        "USA",
        "(2) Technical University of Munich",
        "Munich",
        "Germany",
        "(3) University of Texas at Arlington",
        "Arlington",
        "TX",
        "USA)"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-13T05:22:12+00:00",
          "link": "https://arxiv.org/abs/2506.11472v1",
          "size": "2622kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T19:23:54+00:00",
          "link": "https://arxiv.org/abs/2506.11472v2",
          "size": "2582kb",
          "version": "v2"
        }
      ],
      "title": "On the Natural Robustness of Vision-Language Models Against Visual Perception Attacks in Autonomous Driving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.11472",
        "HTML": "https://arxiv.org/html/2506.11472v2",
        "PDF": "https://arxiv.org/pdf/2506.11472"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces V2LMs for autonomous vehicles and addresses robustness in vision-language models, without discussing LLM training data processing."
      },
      "tasks": [
        "Autonomous Driving",
        "Autonomous Vehicles",
        "Traffic Sign Recognition",
        "vehicle detection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06552",
      "abstract": "This paper studies the hardness of unsupervised domain adaptation (UDA) under covariate shift. We model the uncertainty that the learner faces by a distribution $\\pi$ in the ground-truth triples $(p, q, f)$ -- which we call a UDA class -- where $(p, q)$ is the source -- target distribution pair and $f$ is the classifier. We define the performance of a learner as the overall target domain risk, averaged over the randomness of the ground-truth triple. This formulation couples the source distribution, the target distribution and the classifier in the ground truth, and deviates from the classical worst-case analyses, which pessimistically emphasize the impact of hard but rare UDA instances. In this formulation, we precisely characterize the optimal learner. The performance of the optimal learner then allows us to define the learning difficulty for the UDA class and for the observed sample. To quantify this difficulty, we introduce an information-theoretic quantity -- Posterior Target Label Uncertainty (PTLU) -- along with its empirical estimate (EPTLU) from the sample , which capture the uncertainty in the prediction for the target domain. Briefly, PTLU is the entropy of the predicted label in the target domain under the posterior distribution of ground-truth classifier given the observed source and target samples. By proving that such a quantity serves to lower-bound the risk of any learner, we suggest that these quantities can be used as proxies for evaluating the hardness of UDA learning. We provide several examples to demonstrate the advantage of PTLU, relative to the existing measures, in evaluating the difficulty of UDA learning.",
      "authors": [
        "Zhiyi Dong",
        "Zixuan Liu",
        "Yongyi Mao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Information Theory (cs.IT)",
        "Machine Learning (cs.LG)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T05:11:19+00:00",
          "link": "https://arxiv.org/abs/2507.06552v1",
          "size": "62kb",
          "version": "v1"
        }
      ],
      "title": "On the Hardness of Unsupervised Domain Adaptation: Optimal Learners and Information-Theoretic Perspective",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06552",
        "HTML": "https://arxiv.org/html/2507.06552v1",
        "PDF": "https://arxiv.org/pdf/2507.06552"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on unsupervised domain adaptation and introduces an information-theoretic measure for evaluating learning difficulty, with no discussion on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06742",
      "abstract": "Ethical hacking today relies on highly skilled practitioners executing complex sequences of commands, which is inherently time-consuming, difficult to scale, and prone to human error. To help mitigate these limitations, we previously introduced 'PenTest++', an AI-augmented system combining automation with generative AI supporting ethical hacking workflows. However, a key limitation of PenTest++ was its lack of support for privilege escalation, a crucial element of ethical hacking. In this paper we present 'PenTest2.0', a substantial evolution of PenTest++ supporting automated privilege escalation driven entirely by Large Language Model reasoning. It also incorporates several significant enhancements: 'Retrieval-Augmented Generation', including both one-line and offline modes; 'Chain-of-Thought' prompting for intermediate reasoning; persistent 'PenTest Task Trees' to track goal progression across turns; and the optional integration of human-authored hints. We describe how it operates, present a proof-of-concept prototype, and discuss its benefits and limitations. We also describe application of the system to a controlled Linux target, showing it can carry out multi-turn, adaptive privilege escalation. We explain the rationale behind its core design choices, and provide comprehensive testing results and cost analysis. Our findings indicate that 'PenTest2.0' represents a meaningful step toward practical, scalable, AI-automated penetration testing, whilst highlighting the shortcomings of generative AI systems, particularly their sensitivity to prompt structure, execution context, and semantic drift, reinforcing the need for further research and refinement in this emerging space.\n  Keywords: AI, Ethical Hacking, Privilege Escalation, GenAI, ChatGPT, LLM (Large Language Model), HITL (Human-in-the-Loop)",
      "authors": [
        "Haitham S. Al-Sinani and Chris J. Mitchell"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T10:56:32+00:00",
          "link": "https://arxiv.org/abs/2507.06742v1",
          "size": "12091kb",
          "version": "v1"
        }
      ],
      "title": "PenTest2.0: Towards Autonomous Privilege Escalation Using GenAI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06742",
        "PDF": "https://arxiv.org/pdf/2507.06742"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "While it discusses advances in AI-driven privilege escalation using LLM reasoning, it does not address LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06859",
      "abstract": "We study an online setting, where a decision maker (DM) interacts with contextual bandit-with-knapsack (BwK) instances in repeated episodes. These episodes start with different resource amounts, and the contexts' probability distributions are non-stationary in an episode. All episodes share the same latent conversion model, which governs the random outcome contingent upon a request's context and an allocation decision. Our model captures applications such as dynamic pricing on perishable resources with episodic replenishment, and first price auctions in repeated episodes with different starting budgets. We design an online algorithm that achieves a regret sub-linear in $T$, the number of episodes, assuming access to a \\emph{confidence bound oracle} that achieves an $o(T)$-regret. Such an oracle is readily available from existing contextual bandit literature. We overcome the technical challenge with arbitrarily many possible contexts, which leads to a reinforcement learning problem with an unbounded state space. Our framework provides improved regret bounds in certain settings when the DM is provided with unlabeled feature data, which is novel to the contextual BwK literature.",
      "authors": [
        "Zitian Li",
        "Wang Chi Cheung"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T14:00:05+00:00",
          "link": "https://arxiv.org/abs/2507.06859v1",
          "size": "113kb",
          "version": "v1"
        }
      ],
      "title": "Episodic Contextual Bandits with Knapsacks under Conversion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06859",
        "HTML": "https://arxiv.org/html/2507.06859v1",
        "PDF": "https://arxiv.org/pdf/2507.06859"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses online algorithms for contextual bandits with knapsacks and focuses on decision-making and regret minimization, without any mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07074",
      "abstract": "Multi-agent reinforcement learning (MARL) faces significant challenges in task sequencing and curriculum design, particularly for cooperative coordination scenarios. While curriculum learning has demonstrated success in single-agent domains, principled approaches for multi-agent coordination remain limited due to the absence of validated task complexity metrics. This approach presents a graph-based coordination complexity metric that integrates agent dependency entropy, spatial interference patterns, and goal overlap analysis to predict task difficulty in multi-agent environments. The complexity metric achieves strong empirical validation with rho = 0.952 correlation (p < 0.001) between predicted complexity and empirical difficulty determined by random agent performance evaluation. This approach evaluates the curriculum learning framework using MADDPG across two distinct coordination environments: achieving 56x performance improvement in tight coordination tasks (MultiWalker) and demonstrating systematic task progression in cooperative navigation (Simple Spread). Through systematic analysis, coordination tightness emerges as a predictor of curriculum learning effectiveness, where environments requiring strict agent interdependence benefit substantially from structured progression. This approach provides a validated complexity metric for multi-agent curriculum design and establishes empirical guidelines for multi-robot coordination applications.",
      "authors": [
        "Farhaan Ebadulla",
        "Dharini Hindlatti",
        "Srinivaasan NS",
        "Apoorva VH and Ayman Aftab"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T17:31:35+00:00",
          "link": "https://arxiv.org/abs/2507.07074v1",
          "size": "451kb",
          "version": "v1"
        }
      ],
      "title": "Graph-Based Complexity Metrics for Multi-Agent Curriculum Learning: A Validated Approach to Task Ordering in Cooperative Coordination Environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07074",
        "HTML": "https://arxiv.org/html/2507.07074v1",
        "PDF": "https://arxiv.org/pdf/2507.07074"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is centered on task ordering and curriculum design in multi-agent reinforcement learning, with no focus on LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2203.03898",
      "abstract": "Based on the Sinc approximation combined with the tanh transformation, Haber derived an approximation formula for numerical indefinite integration over the finite interval (-1, 1). The formula uses a special function for the basis functions. In contrast, Stenger derived another formula, which does not use any special function but does include a double sum. Subsequently, Muhammad and Mori proposed a formula, which replaces the tanh transformation with the double-exponential transformation in Haber's formula. Almost simultaneously, Tanaka et al. proposed another formula, which was based on the same replacement in Stenger's formula. As they reported, the replacement drastically improves the convergence rate of Haber's and Stenger's formula. In addition to the formulas above, Stenger derived yet another indefinite integration formula based on the Sinc approximation combined with the tanh transformation, which has an elegant matrix-vector form. In this paper, we propose the replacement of the tanh transformation with the double-exponential transformation in Stenger's second formula. We provide a theoretical analysis as well as a numerical comparison.",
      "authors": [
        "Tomoaki Okayama and Ken'ichiro Tanaka"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2022-03-08T07:37:53+00:00",
          "link": "https://arxiv.org/abs/2203.03898v1",
          "size": "57kb",
          "version": "v1"
        },
        {
          "date": "2022-03-11T05:33:08+00:00",
          "link": "https://arxiv.org/abs/2203.03898v2",
          "size": "57kb",
          "version": "v2"
        },
        {
          "date": "2022-03-25T02:56:10+00:00",
          "link": "https://arxiv.org/abs/2203.03898v3",
          "size": "57kb",
          "version": "v3"
        },
        {
          "date": "2022-05-15T19:54:30+00:00",
          "link": "https://arxiv.org/abs/2203.03898v4",
          "size": "57kb",
          "version": "v4"
        },
        {
          "date": "2022-06-18T13:12:26+00:00",
          "link": "https://arxiv.org/abs/2203.03898v5",
          "size": "57kb",
          "version": "v5"
        }
      ],
      "title": "Yet another DE-Sinc indefinite integration formula",
      "links": {
        "Abstract": "https://arxiv.org/abs/2203.03898",
        "PDF": "https://arxiv.org/pdf/2203.03898"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on numerical integration techniques, specifically Sinc approximation and transformation methods. It does not discuss LLM training data processing or dataset preparation."
      },
      "repo_urls": [
        "https://github.com/okayamat/sinc-indef"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.18115",
      "abstract": "Hyperspectral image (HSI) classification presents inherent challenges due to high spectral dimensionality, significant domain shifts, and limited availability of labeled data. To address these issues, we propose a novel Active Transfer Learning (ATL) framework built upon a Spatial-Spectral Transformer (SST) backbone. The framework integrates multistage transfer learning with an uncertainty-diversity-driven active learning mechanism that strategically selects highly informative and diverse samples for annotation, thereby significantly reducing labeling costs and mitigating sample redundancy. A dynamic layer freezing strategy is introduced to enhance transferability and computational efficiency, enabling selective adaptation of model layers based on domain shift characteristics. Furthermore, we incorporate a self-calibrated attention mechanism that dynamically refines spatial and spectral weights during adaptation, guided by uncertainty-aware feedback. A diversity-promoting sampling strategy ensures broad spectral coverage among selected samples, preventing overfitting to specific classes. Extensive experiments on benchmark cross-domain HSI datasets demonstrate that the proposed SST-ATL framework achieves superior classification performance compared to conventional approaches. The source code is publicly available at https://github.com/mahmad000/ATL-SST.",
      "authors": [
        "Muhammad Ahmad",
        "Francesco Mauro",
        "Manuel Mazzara",
        "Salvatore Distefano",
        "Adil Mehmood Khan",
        "Silvia Liberata Ullo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-27T07:53:39+00:00",
          "link": "https://arxiv.org/abs/2411.18115v1",
          "size": "12054kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T10:08:45+00:00",
          "link": "https://arxiv.org/abs/2411.18115v2",
          "size": "15299kb",
          "version": "v2"
        }
      ],
      "title": "Transformer-Driven Active Transfer Learning for Cross-Hyperspectral Image Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.18115",
        "HTML": "https://arxiv.org/html/2411.18115v2",
        "PDF": "https://arxiv.org/pdf/2411.18115"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with hyperspectral image classification and transfer learning, without discussing any aspects of LLM training data processing or dataset creation relevant to LLMs."
      },
      "tasks": [
        "Active Learning",
        "Classification Of Hyperspectral Images",
        "Diversity",
        "Hyperspectral Image Classification",
        "image-classification",
        "Image Classification",
        "Transfer Learning"
      ],
      "repo_urls": [
        "https://github.com/mahmad000/atl-sst"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.16903",
      "abstract": "Despite the growing interest in jailbreak methods as an effective red-teaming tool for building safe and responsible large language models (LLMs), flawed evaluation system designs have led to significant discrepancies in their effectiveness assessments. We conduct a systematic measurement study based on 37 jailbreak studies since 2022, focusing on both the methods and the evaluation systems they employ. We find that existing evaluation systems lack case-specific criteria, resulting in misleading conclusions about their effectiveness and safety implications. This paper advocates a shift to a more nuanced, case-by-case evaluation paradigm. We introduce GuidedBench, a novel benchmark comprising a curated harmful question dataset, detailed case-by-case evaluation guidelines and an evaluation system integrated with these guidelines -- GuidedEval. Experiments demonstrate that GuidedBench offers more accurate measurements of jailbreak performance, enabling meaningful comparisons across methods and uncovering new insights overlooked in previous evaluations. GuidedEval reduces inter-evaluator variance by at least 76.03\\%. Furthermore, we observe that incorporating guidelines can enhance the effectiveness of jailbreak methods themselves, offering new insights into both attack strategies and evaluation paradigms.",
      "authors": [
        "Ruixuan Huang",
        "Xunguang Wang",
        "Zongjie Li",
        "Daoyuan Wu",
        "Shuai Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-24T06:57:27+00:00",
          "link": "https://arxiv.org/abs/2502.16903v1",
          "size": "832kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T12:13:12+00:00",
          "link": "https://arxiv.org/abs/2502.16903v2",
          "size": "1594kb",
          "version": "v2"
        }
      ],
      "title": "GuidedBench: Measuring and Mitigating the Evaluation Discrepancies of In-the-wild LLM Jailbreak Methods",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.16903",
        "PDF": "https://arxiv.org/pdf/2502.16903"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses the evaluation discrepancies in LLM jailbreak methods and introduces a benchmark for this purpose, mentioning a 'curated harmful question dataset,' but its primary focus is not on LLM training data processing itself."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2503.16248",
      "abstract": "AI agents integrated with Web3 offer autonomy and openness but raise security concerns as they interact with financial protocols and immutable smart contracts. This paper investigates the vulnerabilities of AI agents within blockchain-based financial ecosystems when exposed to adversarial threats in real-world scenarios. We introduce the concept of context manipulation -- a comprehensive attack vector that exploits unprotected context surfaces, including input channels, memory modules, and external data feeds. It expands on traditional prompt injection and reveals a more stealthy and persistent threat: memory injection. Using ElizaOS, a representative decentralized AI agent framework for automated Web3 operations, we showcase that malicious injections into prompts or historical records can trigger unauthorized asset transfers and protocol violations which could be financially devastating in reality. To quantify these risks, we introduce CrAIBench, a Web3-focused benchmark covering 150+ realistic blockchain tasks. such as token transfers, trading, bridges, and cross-chain interactions, and 500+ attack test cases using context manipulation. Our evaluation results confirm that AI models are significantly more vulnerable to memory injection compared to prompt injection. Finally, we evaluate a comprehensive defense roadmap, finding that prompt-injection defenses and detectors only provide limited protection when stored context is corrupted, whereas fine-tuning-based defenses substantially reduce attack success rates while preserving performance on single-step tasks. These results underscore the urgent need for AI agents that are both secure and fiduciarily responsible in blockchain environments.",
      "authors": [
        "Atharv Singh Patlan",
        "Peiyao Sheng",
        "S. Ashwin Hebbar",
        "Prateek Mittal",
        "Pramod Viswanath"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-20T15:44:31+00:00",
          "link": "https://arxiv.org/abs/2503.16248v1",
          "size": "2367kb",
          "version": "v1"
        },
        {
          "date": "2025-04-30T20:40:47+00:00",
          "link": "https://arxiv.org/abs/2503.16248v2",
          "size": "2157kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T01:38:20+00:00",
          "link": "https://arxiv.org/abs/2503.16248v3",
          "size": "2960kb",
          "version": "v3"
        }
      ],
      "title": "Real AI Agents with Fake Memories: Fatal Context Manipulation Attacks on Web3 Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.16248",
        "HTML": "https://arxiv.org/html/2503.16248v3",
        "PDF": "https://arxiv.org/pdf/2503.16248"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces a new benchmark for evaluating vulnerability in blockchain-based AI agents, it primarily focuses on security threats and defenses, not primarily on processing training data for LLMs."
      },
      "datasets": [
        {
          "dataset_name": "peiyao-sentient/crypto-agent-safe-function-calling",
          "downloads": "96",
          "likes": "2",
          "link": "https://huggingface.co/datasets/peiyao-sentient/crypto-agent-safe-function-calling"
        },
        {
          "dataset_name": "SentientAGI/crypto-agent-safe-function-calling",
          "downloads": "108",
          "likes": "1",
          "link": "https://huggingface.co/datasets/SentientAGI/crypto-agent-safe-function-calling"
        }
      ],
      "tasks": [
        "AI Agent"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.02372",
      "abstract": "A main bottleneck of learning-based robotic scene understanding methods is the heavy reliance on extensive annotated training data, which often limits their generalization ability. In LiDAR panoptic segmentation, this challenge becomes even more pronounced due to the need to simultaneously address both semantic and instance segmentation from complex, high-dimensional point cloud data. In this work, we address the challenge of LiDAR panoptic segmentation with very few labeled samples by leveraging recent advances in label-efficient vision panoptic segmentation. To this end, we propose a novel method, Limited-Label LiDAR Panoptic Segmentation (L3PS), which requires only a minimal amount of labeled data. Our approach first utilizes a label-efficient 2D network to generate panoptic pseudo-labels from a small set of annotated images, which are subsequently projected onto point clouds. We then introduce a novel 3D refinement module that capitalizes on the geometric properties of point clouds. By incorporating clustering techniques, sequential scan accumulation, and ground point separation, this module significantly enhances the accuracy of the pseudo-labels, improving segmentation quality by up to +10.6 PQ and +7.9 mIoU. We demonstrate that these refined pseudo-labels can be used to effectively train off-the-shelf LiDAR segmentation networks. Through extensive experiments, we show that L3PS not only outperforms existing methods but also substantially reduces the annotation burden. We release the code of our work at https://l3ps.cs.uni-freiburg.de.",
      "authors": [
        "Ahmet Selim \\c{C}anak\\c{c}{\\i}",
        "Niclas V\\\"odisch",
        "K\\\"ursat Petek",
        "Wolfram Burgard",
        "Abhinav Valada"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-04T07:58:15+00:00",
          "link": "https://arxiv.org/abs/2503.02372v1",
          "size": "5828kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T11:25:06+00:00",
          "link": "https://arxiv.org/abs/2503.02372v2",
          "size": "4518kb",
          "version": "v2"
        }
      ],
      "title": "Label-Efficient LiDAR Panoptic Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.02372",
        "HTML": "https://arxiv.org/html/2503.02372v2",
        "PDF": "https://arxiv.org/pdf/2503.02372"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper proposes a novel label-efficient method for LiDAR panoptic segmentation by generating and refining pseudo-labels from limited labeled data, involving significant data processing steps that are central to improving data quality and model training."
      },
      "tasks": [
        "Instance Segmentation",
        "Panoptic Segmentation",
        "Scene Understanding",
        "Segmentation",
        "Semantic Segmentation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06252",
      "abstract": "Cyber Threat Intelligence (CTI) has emerged as a vital complementary approach that operates in the early phases of the cyber threat lifecycle. CTI involves collecting, processing, and analyzing threat data to provide a more accurate and rapid understanding of cyber threats. Due to the large volume of data, automation through Machine Learning (ML) and Natural Language Processing (NLP) models is essential for effective CTI extraction. These automated systems leverage Open Source Intelligence (OSINT) from sources like social networks, forums, and blogs to identify Indicators of Compromise (IoCs). Although prior research has focused on adversarial attacks on specific ML models, this study expands the scope by investigating vulnerabilities within various components of the entire CTI pipeline and their susceptibility to adversarial attacks. These vulnerabilities arise because they ingest textual inputs from various open sources, including real and potentially fake content. We analyse three types of attacks against CTI pipelines, including evasion, flooding, and poisoning, and assess their impact on the system's information selection capabilities. Specifically, on fake text generation, the work demonstrates how adversarial text generation techniques can create fake cybersecurity and cybersecurity-like text that misleads classifiers, degrades performance, and disrupts system functionality. The focus is primarily on the evasion attack, as it precedes and enables flooding and poisoning attacks within the CTI pipeline.",
      "authors": [
        "Samaneh Shafee",
        "Alysson Bessani",
        "Pedro M. Ferreira"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-05T19:00:27+00:00",
          "link": "https://arxiv.org/abs/2507.06252v1",
          "size": "558kb",
          "version": "v1"
        }
      ],
      "title": "False Alarms, Real Damage: Adversarial Attacks Using LLM-based Models on Text-based Cyber Threat Intelligence Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06252",
        "HTML": "https://arxiv.org/html/2507.06252v1",
        "PDF": "https://arxiv.org/pdf/2507.06252"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on adversarial attacks on cybersecurity systems that use ML models, analyzing vulnerabilities in CTI pipelines. It does not discuss processing or engineering of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06439",
      "abstract": "Automotive safety and security are paramount in the rapidly advancing landscape of vehicular technology. Building safe and secure vehicles demands a profound understanding of automotive systems, particularly in safety and security. Traditional learning approaches, such as reading materials or observing demonstrations, often fail to provide the practical, hands-on experience essential for developing this expertise. For novice users, gaining access to automotive-grade systems and mastering their associated hardware and software can be challenging and overwhelming. In this paper, we present a novel, affordable, and flexible exploration platform, \\hema, that enables users to gain practical, hands-on insights into the security compromises of micro-electromechanical systems (MEMS) sensors, a critical component in modern ADAS systems. Furthermore, we discuss the unique challenges and design considerations involved in creating such a platform, emphasizing its role in enhancing the understanding of automotive safety and security. This framework serves as an invaluable resource for educators, researchers, and practitioners striving to build expertise in the field.",
      "authors": [
        "Bhagawat Baanav Yedla Ravi",
        "Md Rafiul Kabir and Sandip Ray"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T22:44:34+00:00",
          "link": "https://arxiv.org/abs/2507.06439v1",
          "size": "2071kb",
          "version": "v1"
        }
      ],
      "title": "HEMA: A Hands-on Exploration Platform for MEMS Sensor Attacks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06439",
        "HTML": "https://arxiv.org/html/2507.06439v1",
        "PDF": "https://arxiv.org/pdf/2507.06439"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a platform for exploring MEMS sensor attacks, focusing on automotive safety rather than LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06458",
      "abstract": "Protein language models (PLMs) encode rich biological information, yet their internal neuron representations are poorly understood. We introduce the first automated framework for labeling every neuron in a PLM with biologically grounded natural language descriptions. Unlike prior approaches relying on sparse autoencoders or manual annotation, our method scales to hundreds of thousands of neurons, revealing individual neurons are selectively sensitive to diverse biochemical and structural properties. We then develop a novel neuron activation-guided steering method to generate proteins with desired traits, enabling convergence to target biochemical properties like molecular weight and instability index as well as secondary and tertiary structural motifs, including alpha helices and canonical Zinc Fingers. We finally show that analysis of labeled neurons in different model sizes reveals PLM scaling laws and a structured neuron space distribution.",
      "authors": [
        "Arjun Banerjee",
        "David Martinez",
        "Camille Dang",
        "Ethan Tam"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Biomolecules (q-bio.BM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T23:59:13+00:00",
          "link": "https://arxiv.org/abs/2507.06458v1",
          "size": "3368kb",
          "version": "v1"
        }
      ],
      "title": "Automated Neuron Labelling Enables Generative Steering and Interpretability in Protein Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06458",
        "HTML": "https://arxiv.org/html/2507.06458v1",
        "PDF": "https://arxiv.org/pdf/2507.06458"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The primary contribution is the development of an automated framework for neuron labeling in Protein Language Models, focusing on model interpretability and generation rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06492",
      "abstract": "This paper presents a novel cyber-physical attack paradigm, termed the Dual State-Space Fidelity Blade (D-STAB), which targets the firmware of core cyber-physical components as a new class of attack surfaces. The D-STAB attack exploits the information asymmetry caused by the fidelity gap between high-fidelity and low-fidelity physical models in cyber-physical systems. By designing precise adversarial constraints based on high-fidelity state-space information, the attack induces deviations in high-fidelity states that remain undetected by defenders relying on low-fidelity observations. The effectiveness of D-STAB is demonstrated through a case study in cyber-physical battery systems, specifically in an optimal charging task governed by a Battery Management System (BMS).",
      "authors": [
        "Jiajun Shen",
        "Hao Tu",
        "Fengjun Li",
        "Morteza Hashemi",
        "Di Wu",
        "Huazhen Fang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T02:31:05+00:00",
          "link": "https://arxiv.org/abs/2507.06492v1",
          "size": "233kb",
          "version": "v1"
        }
      ],
      "title": "Dual State-space Fidelity Blade (D-STAB): A Novel Stealthy Cyber-physical Attack Paradigm",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06492",
        "HTML": "https://arxiv.org/html/2507.06492v1",
        "PDF": "https://arxiv.org/pdf/2507.06492"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research addresses cyber-physical attack paradigms and does not involve processes related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06986",
      "abstract": "Machine learning models, particularly decision trees (DTs), are widely adopted across various domains due to their interpretability and efficiency. However, as ML models become increasingly integrated into privacy-sensitive applications, concerns about their confidentiality have grown, particularly in light of emerging threats such as model extraction and fault injection attacks. Assessing the vulnerability of DTs under such attacks is therefore important. In this work, we present BarkBeetle, a novel attack that leverages fault injection to extract internal structural information of DT models. BarkBeetle employs a bottom-up recovery strategy that uses targeted fault injection at specific nodes to efficiently infer feature splits and threshold values. Our proof-of-concept implementation demonstrates that BarkBeetle requires significantly fewer queries and recovers more structural information compared to prior approaches, when evaluated on DTs trained with public UCI datasets. To validate its practical feasibility, we implement BarkBeetle on a Raspberry Pi RP2350 board and perform fault injections using the Faultier voltage glitching tool. As BarkBeetle targets general DT models, we also provide an in-depth discussion on its applicability to a broader range of tree-based applications, including data stream classification, DT variants, and cryptography schemes.",
      "authors": [
        "Qifan Wang",
        "Jonas Sander",
        "Minmin Jiang",
        "Thomas Eisenbarth",
        "David Oswald"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T16:08:58+00:00",
          "link": "https://arxiv.org/abs/2507.06986v1",
          "size": "9032kb",
          "version": "v1"
        }
      ],
      "title": "BarkBeetle: Stealing Decision Tree Models with Fault Injection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06986",
        "HTML": "https://arxiv.org/html/2507.06986v1",
        "PDF": "https://arxiv.org/pdf/2507.06986"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper concentrates on model extraction and fault injection attacks on decision tree models, without any focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2407.01230",
      "abstract": "In many real-world scenarios, recorded videos suffer from accidental focus blur, and while video deblurring methods exist, most specifically target motion blur or spatial-invariant blur. This paper introduces a framework optimized for the as yet unattempted task of video focal deblurring (refocusing). The proposed method employs novel map-guided transformers, in addition to image propagation, to effectively leverage the continuous spatial variance of focal blur and restore the footage. We also introduce a flow re-focusing module designed to efficiently align relevant features between blurry and sharp domains. Additionally, we propose a novel technique for generating synthetic focal blur data, broadening the model's learning capabilities and robustness to include a wider array of content. We have made a new benchmark dataset, DAVIS-Blur, available. This dataset, a modified extension of the popular DAVIS video segmentation set, provides realistic focal blur degradations as well as the corresponding blur maps. Comprehensive experiments demonstrate the superiority of our approach. We achieve state-of-the-art results with an average PSNR performance over 1.9dB greater than comparable existing video restoration methods. Our source code and the developed databases will be made available at https://github.com/crispianm/DaBiT",
      "authors": [
        "Crispian Morris",
        "Nantheera Anantrasirichai",
        "Fan Zhang",
        "and David Bull"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-01T12:22:16+00:00",
          "link": "https://arxiv.org/abs/2407.01230v1",
          "size": "12010kb",
          "version": "v1"
        },
        {
          "date": "2024-07-10T09:19:44+00:00",
          "link": "https://arxiv.org/abs/2407.01230v2",
          "size": "12010kb",
          "version": "v2"
        },
        {
          "date": "2025-02-20T10:15:23+00:00",
          "link": "https://arxiv.org/abs/2407.01230v3",
          "size": "13392kb",
          "version": "v3"
        }
      ],
      "title": "DaBiT: Depth and Blur informed Transformer for Video Focal Deblurring",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.01230",
        "HTML": "https://arxiv.org/html/2407.01230",
        "PDF": "https://arxiv.org/pdf/2407.01230"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper makes a technical contribution by introducing a novel synthetic focal blur data generation method and creating the benchmark dataset DAVIS-Blur, both of which involve significant data processing steps relevant to improving data quality for model training."
      },
      "tasks": [
        "Deblurring",
        "Super-Resolution",
        "Video Deblurring",
        "Video Restoration",
        "Video Segmentation",
        "Video Semantic Segmentation",
        "Video Super-Resolution"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.18962",
      "abstract": "Online comment sections, such as those on news sites or social media, have the potential to foster informal public deliberation, However, this potential is often undermined by the frequency of toxic or low-quality exchanges that occur in these settings. To combat this, platforms increasingly leverage algorithmic ranking to facilitate higher-quality discussions, e.g., by using civility classifiers or forms of prosocial ranking. Yet, these interventions may also inadvertently reduce the visibility of legitimate viewpoints, undermining another key aspect of deliberation: representation of diverse views. We seek to remedy this problem by introducing guarantees of representation into these methods. In particular, we adopt the notion of justified representation (JR) from the social choice literature and incorporate a JR constraint into the comment ranking setting. We find that enforcing JR leads to greater inclusion of diverse viewpoints while still being compatible with optimizing for user engagement or other measures of conversational quality.",
      "authors": [
        "Manon Revel",
        "Smitha Milli",
        "Tyler Lu",
        "Jamelle Watson-Daniels",
        "Max Nickel"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-19T20:39:35+00:00",
          "link": "https://arxiv.org/abs/2503.18962v1",
          "size": "1345kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T15:22:44+00:00",
          "link": "https://arxiv.org/abs/2503.18962v2",
          "size": "1555kb",
          "version": "v2"
        }
      ],
      "title": "Representative Ranking for Deliberation in the Public Sphere",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.18962",
        "HTML": "https://arxiv.org/html/2503.18962v2",
        "PDF": "https://arxiv.org/pdf/2503.18962"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses algorithmic ranking for online comments to achieve representation while balancing civility, not related to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.06738",
      "abstract": "Spatio-temporal video prediction plays a pivotal role in critical domains, ranging from weather forecasting to industrial automation. However, in high-precision industrial scenarios such as semiconductor manufacturing, the absence of specialized benchmark datasets severely hampers research on modeling and predicting complex processes. To address this challenge, we make a twofold contribution.First, we construct and release the Chip Dicing Lane Dataset (CHDL), the first public temporal image dataset dedicated to the semiconductor wafer dicing process. Captured via an industrial-grade vision system, CHDL provides a much-needed and challenging benchmark for high-fidelity process modeling, defect detection, and digital twin development.Second, we propose DIFFUMA, an innovative dual-path prediction architecture specifically designed for such fine-grained dynamics. The model captures global long-range temporal context through a parallel Mamba module, while simultaneously leveraging a diffusion module, guided by temporal features, to restore and enhance fine-grained spatial details, effectively combating feature degradation. Experiments demonstrate that on our CHDL benchmark, DIFFUMA significantly outperforms existing methods, reducing the Mean Squared Error (MSE) by 39% and improving the Structural Similarity (SSIM) from 0.926 to a near-perfect 0.988. This superior performance also generalizes to natural phenomena datasets. Our work not only delivers a new state-of-the-art (SOTA) model but, more importantly, provides the community with an invaluable data resource to drive future research in industrial AI.",
      "authors": [
        "Xinyu Xie",
        "Weifeng Cao",
        "Jun Shi",
        "Yangyang Hu",
        "Hui Liang",
        "Wanyong Liang",
        "Xiaoliang Qian"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T10:51:54+00:00",
          "link": "https://arxiv.org/abs/2507.06738v1",
          "size": "2460kb",
          "version": "v1"
        }
      ],
      "title": "DIFFUMA: High-Fidelity Spatio-Temporal Video Prediction via Dual-Path Mamba and Diffusion Enhancement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06738",
        "HTML": "https://arxiv.org/html/2507.06738v1",
        "PDF": "https://arxiv.org/pdf/2507.06738"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper contributes a new dataset, Chip Dicing Lane Dataset (CHDL), specifically for semiconductor wafer dicing, which involves detailed data processing steps for high-fidelity spatio-temporal video prediction."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06969",
      "abstract": "Differentially private (DP) mechanisms are difficult to interpret and calibrate because existing methods for mapping standard privacy parameters to concrete privacy risks -- re-identification, attribute inference, and data reconstruction -- are both overly pessimistic and inconsistent. In this work, we use the hypothesis-testing interpretation of DP ($f$-DP), and determine that bounds on attack success can take the same unified form across re-identification, attribute inference, and data reconstruction risks. Our unified bounds are (1) consistent across a multitude of attack settings, and (2) tunable, enabling practitioners to evaluate risk with respect to arbitrary (including worst-case) levels of baseline risk. Empirically, our results are tighter than prior methods using $\\varepsilon$-DP, R\\'enyi DP, and concentrated DP. As a result, calibrating noise using our bounds can reduce the required noise by 20% at the same risk level, which yields, e.g., more than 15pp accuracy increase in a text classification task. Overall, this unifying perspective provides a principled framework for interpreting and calibrating the degree of protection in DP against specific levels of re-identification, attribute inference, or data reconstruction risk.",
      "authors": [
        "Bogdan Kulynych",
        "Juan Felipe Gomez",
        "Georgios Kaissis",
        "Jamie Hayes",
        "Borja Balle",
        "Flavio du Pin Calmon",
        "Jean Louis Raisaro"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Cryptography and Security (cs.CR)",
        "Computers and Society (cs.CY)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T15:59:30+00:00",
          "link": "https://arxiv.org/abs/2507.06969v1",
          "size": "426kb",
          "version": "v1"
        }
      ],
      "title": "Unifying Re-Identification, Attribute Inference, and Data Reconstruction Risks in Differential Privacy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06969",
        "PDF": "https://arxiv.org/pdf/2507.06969"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on differential privacy mechanisms and their calibration for privacy risk interpretation. It does not address LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07061",
      "abstract": "Semantic caching enhances the efficiency of large language model (LLM) systems by identifying semantically similar queries, storing responses once, and serving them for subsequent equivalent requests. However, existing semantic caching frameworks rely on single embedding models for query representation, which limits their ability to capture the diverse semantic relationships present in real-world query distributions. This paper presents an ensemble embedding approach that combines multiple embedding models through a trained meta-encoder to improve semantic similarity detection in LLM caching systems. We evaluate our method using the Quora Question Pairs (QQP) dataset, measuring cache hit ratios, cache miss ratios, token savings, and response times. Our ensemble approach achieves a 92\\% cache hit ratio for semantically equivalent queries while maintaining an 85\\% accuracy in correctly rejecting non-equivalent queries as cache misses. These results demonstrate that ensemble embedding methods significantly outperform single-model approaches in distinguishing between semantically similar and dissimilar queries, leading to more effective caching performance and reduced computational overhead in LLM-based systems.",
      "authors": [
        "Shervin Ghaffari",
        "Zohre Bahranifard",
        "and Mohammad Akbari"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T09:20:12+00:00",
          "link": "https://arxiv.org/abs/2507.07061v1",
          "size": "1059kb",
          "version": "v1"
        }
      ],
      "title": "An Ensemble Embedding Approach for Improving Semantic Caching Performance in LLM-based Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07061",
        "HTML": "https://arxiv.org/html/2507.07061v1",
        "PDF": "https://arxiv.org/pdf/2507.07061"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses an ensemble embedding approach to improve semantic caching, which does not involve LLM training data processing but rather focuses on optimization of query handling in LLM systems."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06752",
      "abstract": "Machine learning has emerged as a transformative tool for solving differential equations (DEs), yet prevailing methodologies remain constrained by dual limitations: data-driven methods demand costly labeled datasets while model-driven techniques face efficiency-accuracy trade-offs. We present the Mathematical Artificial Data (MAD) framework, a new paradigm that integrates physical laws with data-driven learning to facilitate large-scale operator discovery. By exploiting DEs' intrinsic mathematical structure to generate physics-embedded analytical solutions and associated synthetic data, MAD fundamentally eliminates dependence on experimental or simulated training data. This enables computationally efficient operator learning across multi-parameter systems while maintaining mathematical rigor. Through numerical demonstrations spanning 2D parametric problems where both the boundary values and source term are functions, we showcase MAD's generalizability and superior efficiency/accuracy across various DE scenarios. This physics-embedded-data-driven framework and its capacity to handle complex parameter spaces gives it the potential to become a universal paradigm for physics-informed machine intelligence in scientific computing.",
      "authors": [
        "Heng Wu and Benzhuo Lu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T11:23:05+00:00",
          "link": "https://arxiv.org/abs/2507.06752v1",
          "size": "26651kb",
          "version": "v1"
        }
      ],
      "title": "Mathematical artificial data for operator learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06752",
        "HTML": "https://arxiv.org/html/2507.06752v1",
        "PDF": "https://arxiv.org/pdf/2507.06752"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces a framework to generate synthetic, physics-embedded data for operator learning, which represents a significant contribution to data generation and processing for training machine learning models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06961",
      "abstract": "Off-Policy Evaluation (OPE) aims to estimate the value of a target policy using offline data collected from potentially different policies. In real-world applications, however, logged data often suffers from missingness. While OPE has been extensively studied in the literature, a theoretical understanding of how missing data affects OPE results remains unclear. In this paper, we investigate OPE in the presence of monotone missingness and theoretically demonstrate that the value estimates remain unbiased under ignorable missingness but can be biased under nonignorable (informative) missingness. To retain the consistency of value estimation, we propose an inverse probability weighted value estimator and conduct statistical inference to quantify the uncertainty of the estimates. Through a series of numerical experiments, we empirically demonstrate that our proposed estimator yields a more reliable value inference under missing data.",
      "authors": [
        "Han Wang",
        "Yang Xu",
        "Wenbin Lu",
        "Rui Song"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T15:46:39+00:00",
          "link": "https://arxiv.org/abs/2507.06961v1",
          "size": "127kb",
          "version": "v1"
        }
      ],
      "title": "Off-Policy Evaluation Under Nonignorable Missing Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06961",
        "HTML": "https://arxiv.org/html/2507.06961v1",
        "PDF": "https://arxiv.org/pdf/2507.06961"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses off-policy evaluation with missing data in the context of policy value estimation, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2406.03756",
      "abstract": "We propose a conservative algorithm to test the geometrical validity of simplicial (triangles, tetrahedra), tensor product (quadrilaterals, hexahedra), and mixed (prisms) elements of arbitrary polynomial order as they deform over a piecewise-linear trajectory.\n  Our algorithm uses a combination of adaptive B\\'ezier refinement and bisection search to determine if, when, and where the Jacobian determinant of an element's polynomial geometric map becomes negative in the transition from one configuration to another.\n  Unlike previous approaches, our method preserves its properties also when implemented using floating point arithmetic: This feature comes at a small additional runtime cost compared to existing inexact methods, making it a drop-in replacement for current validity tests, while providing superior robustness and generality.\n  To prove the practical effectiveness of our algorithm, we demonstrate its use in a high-order Incremental Potential Contact (IPC) elastodynamic simulator, and we experimentally show that it prevents invalid, simulation-breaking configurations that would otherwise occur using inexact methods, without the need for manual parameter tuning.",
      "authors": [
        "Federico Sichetti",
        "Zizhou Huang",
        "Marco Attene",
        "Denis Zorin",
        "Enrico Puppo",
        "Daniele Panozzo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Geometry (cs.CG)",
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-06T05:41:30+00:00",
          "link": "https://arxiv.org/abs/2406.03756v1",
          "size": "5171kb",
          "version": "v1"
        },
        {
          "date": "2024-10-01T22:06:40+00:00",
          "link": "https://arxiv.org/abs/2406.03756v2",
          "size": "44528kb",
          "version": "v2"
        }
      ],
      "title": "High-Order Continuous Geometrical Validity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.03756",
        "HTML": "https://arxiv.org/html/2406.03756",
        "PDF": "https://arxiv.org/pdf/2406.03756"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes an algorithm for testing geometrical validity in simulations, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.04969",
      "abstract": "Serverless computing has redefined cloud application deployment by abstracting infrastructure and enabling on-demand, event-driven execution, thereby enhancing developer agility and scalability. However, maintaining consistent application performance in serverless environments remains a significant challenge. The dynamic and transient nature of serverless functions makes it difficult to distinguish between benign and anomalous behavior, which in turn undermines the effectiveness of traditional anomaly detection methods. These conventional approaches, designed for stateful and long-running services, struggle in serverless settings where executions are short-lived, functions are isolated, and observability is limited.\n  In this first comprehensive vision paper on anomaly detection for serverless systems, we systematically explore the unique challenges posed by this paradigm, including the absence of persistent state, inconsistent monitoring granularity, and the difficulty of correlating behaviors across distributed functions. We further examine a range of threats that manifest as anomalies, from classical Denial-of-Service (DoS) attacks to serverless-specific threats such as Denial-of-Wallet (DoW) and cold start amplification. Building on these observations, we articulate a research agenda for next-generation detection frameworks that address the need for context-aware, multi-source data fusion, real-time, lightweight, privacy-preserving, and edge-cloud adaptive capabilities.\n  Through the identification of key research directions and design principles, we aim to lay the foundation for the next generation of anomaly detection in cloud-native, serverless ecosystems.",
      "authors": [
        "Chanh Nguyen",
        "Erik Elmroth",
        "Monowar Bhuyan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T13:12:28+00:00",
          "link": "https://arxiv.org/abs/2507.04969v1",
          "size": "1832kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T08:59:36+00:00",
          "link": "https://arxiv.org/abs/2507.04969v2",
          "size": "1832kb",
          "version": "v2"
        }
      ],
      "title": "Silent Failures in Stateless Systems: Rethinking Anomaly Detection for Serverless Computing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.04969",
        "HTML": "https://arxiv.org/html/2507.04969v2",
        "PDF": "https://arxiv.org/pdf/2507.04969"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses anomaly detection in serverless computing environments and does not discuss LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06326",
      "abstract": "Deep brain stimulation (DBS) is an established intervention for Parkinson's disease (PD), but conventional open-loop systems lack adaptability, are energy-inefficient due to continuous stimulation, and provide limited personalization to individual neural dynamics. Adaptive DBS (aDBS) offers a closed-loop alternative, using biomarkers such as beta-band oscillations to dynamically modulate stimulation. While reinforcement learning (RL) holds promise for personalized aDBS control, existing methods suffer from high sample complexity, unstable exploration in binary action spaces, and limited deployability on resource-constrained hardware.\n  We propose SEA-DBS, a sample-efficient actor-critic framework that addresses the core challenges of RL-based adaptive neurostimulation. SEA-DBS integrates a predictive reward model to reduce reliance on real-time feedback and employs Gumbel Softmax-based exploration for stable, differentiable policy updates in binary action spaces. Together, these components improve sample efficiency, exploration robustness, and compatibility with resource-constrained neuromodulatory hardware. We evaluate SEA-DBS on a biologically realistic simulation of Parkinsonian basal ganglia activity, demonstrating faster convergence, stronger suppression of pathological beta-band power, and resilience to post-training FP16 quantization. Our results show that SEA-DBS offers a practical and effective RL-based aDBS framework for real-time, resource-constrained neuromodulation.",
      "authors": [
        "Harsh Ravivarapu",
        "Gaurav Bagwe",
        "Xiaoyong Yuan",
        "Chunxiu Yu",
        "Lan Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)",
        "Neurons and Cognition (q-bio.NC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T18:30:26+00:00",
          "link": "https://arxiv.org/abs/2507.06326v1",
          "size": "1454kb",
          "version": "v1"
        }
      ],
      "title": "Sample-Efficient Reinforcement Learning Controller for Deep Brain Stimulation in Parkinson's Disease",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06326",
        "HTML": "https://arxiv.org/html/2507.06326v1",
        "PDF": "https://arxiv.org/pdf/2507.06326"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research focuses on reinforcement learning for adaptive neurostimulation, not related to the processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06489",
      "abstract": "Robust verbal confidence generated by large language models (LLMs) is crucial for the deployment of LLMs to ensure transparency, trust, and safety in human-AI interactions across many high-stakes applications. In this paper, we present the first comprehensive study on the robustness of verbal confidence under adversarial attacks. We introduce a novel framework for attacking verbal confidence scores through both perturbation and jailbreak-based methods, and show that these attacks can significantly jeopardize verbal confidence estimates and lead to frequent answer changes. We examine a variety of prompting strategies, model sizes, and application domains, revealing that current confidence elicitation methods are vulnerable and that commonly used defence techniques are largely ineffective or counterproductive. Our findings underscore the urgent need to design more robust mechanisms for confidence expression in LLMs, as even subtle semantic-preserving modifications can lead to misleading confidence in responses.",
      "authors": [
        "Stephen Obadinma",
        "Xiaodan Zhu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T02:19:46+00:00",
          "link": "https://arxiv.org/abs/2507.06489v1",
          "size": "755kb",
          "version": "v1"
        }
      ],
      "title": "On the Robustness of Verbal Confidence of LLMs in Adversarial Attacks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06489",
        "HTML": "https://arxiv.org/html/2507.06489v1",
        "PDF": "https://arxiv.org/pdf/2507.06489"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on the robustness of verbal confidence in LLMs under adversarial attacks, without discussions on training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2211.05246",
      "abstract": "We study the limitations and fast-forwarding of quantum algorithms for linear ordinary differential equation (ODE) systems with a particular focus on non-quantum dynamics, where the coefficient matrix in the ODE is not anti-Hermitian or the ODE is inhomogeneous. On the one hand, for generic linear ODEs, by proving worst-case lower bounds, we show that quantum algorithms suffer from computational overheads due to two types of ``non-quantumness'': real part gap and non-normality of the coefficient matrix. We then show that homogeneous ODEs in the absence of both types of ``non-quantumness'' are equivalent to quantum dynamics, and reach the conclusion that quantum algorithms for quantum dynamics work best. To obtain these lower bounds, we propose a general framework for proving lower bounds on quantum algorithms that are amplifiers, meaning that they amplify the difference between a pair of input quantum states. On the other hand, we show how to fast-forward quantum algorithms for solving special classes of ODEs which leads to improved efficiency. More specifically, we obtain exponential improvements in both $T$ and the spectral norm of the coefficient matrix for inhomogeneous ODEs with efficiently implementable eigensystems, including various spatially discretized linear evolutionary partial differential equations. We give fast-forwarding algorithms that are conceptually different from existing ones in the sense that they neither require time discretization nor solving high-dimensional linear systems.",
      "authors": [
        "Dong An",
        "Jin-Peng Liu",
        "Daochen Wang",
        "Qi Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2022-11-09T22:50:14+00:00",
          "link": "https://arxiv.org/abs/2211.05246v1",
          "size": "61kb",
          "version": "v1"
        },
        {
          "date": "2023-03-02T08:03:54+00:00",
          "link": "https://arxiv.org/abs/2211.05246v2",
          "size": "76kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T04:47:55+00:00",
          "link": "https://arxiv.org/abs/2211.05246v3",
          "size": "66kb",
          "version": "v3"
        }
      ],
      "title": "Quantum differential equation solvers: limitations and fast-forwarding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2211.05246",
        "PDF": "https://arxiv.org/pdf/2211.05246"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The work is centered around quantum algorithms for solving differential equations, without any discussion related to processing or engineering LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2407.18468",
      "abstract": "Diffusion models have been extensively utilized in AI-generated content (AIGC) in recent years, thanks to the superior generation capabilities. Combining with semantic communications, diffusion models are used for tasks such as denoising, data reconstruction, and content generation. However, existing diffusion-based generative models do not consider the stringent bandwidth limitation, which limits its application in wireless communication. This paper introduces a diffusion-driven semantic communication framework with advanced VAE-based compression for bandwidth-constrained generative model. Our designed architecture utilizes the diffusion model, where the signal transmission process through the wireless channel acts as the forward process in diffusion. To reduce bandwidth requirements, we incorporate a downsampling module and a paired upsampling module based on a variational auto-encoder with reparameterization at the receiver to ensure that the recovered features conform to the Gaussian distribution. Furthermore, we derive the loss function for our proposed system and evaluate its performance through comprehensive experiments. Our experimental results demonstrate significant improvements in pixel-level metrics such as peak signal to noise ratio (PSNR) and semantic metrics like learned perceptual image patch similarity (LPIPS). These enhancements are more profound regarding the compression rates and SNR compared to deep joint source-channel coding (DJSCC). We release the code at https://github.com/import-sudo/Diffusion-Driven-Semantic-Communication.",
      "authors": [
        "Lei Guo",
        "Wei Chen",
        "Yuxuan Sun",
        "Bo Ai",
        "Nikolaos Pappas",
        "Tony Q. S. Quek"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-26T02:34:25+00:00",
          "link": "https://arxiv.org/abs/2407.18468v1",
          "size": "2450kb",
          "version": "v1"
        },
        {
          "date": "2025-03-20T04:34:54+00:00",
          "link": "https://arxiv.org/abs/2407.18468v2",
          "size": "1523kb",
          "version": "v2"
        },
        {
          "date": "2025-03-23T09:36:48+00:00",
          "link": "https://arxiv.org/abs/2407.18468v3",
          "size": "1014kb",
          "version": "v3"
        },
        {
          "date": "2025-07-09T06:10:57+00:00",
          "link": "https://arxiv.org/abs/2407.18468v4",
          "size": "1015kb",
          "version": "v4"
        }
      ],
      "title": "Diffusion-Driven Semantic Communication for Generative Models with Bandwidth Constraints",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.18468",
        "HTML": "https://arxiv.org/html/2407.18468v4",
        "PDF": "https://arxiv.org/pdf/2407.18468"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with diffusion-driven semantic communication and bandwidth constraints in generative models, which doesn't pertain to LLM training data processing."
      },
      "tasks": [
        "Denoising",
        "Semantic Communication"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.04417",
      "abstract": "This work aims to estimate the drift and diffusion functions in stochastic differential equations (SDEs) driven by a particular class of L\\'evy processes with finite jump intensity, using neural networks. We propose a framework that integrates the Tamed-Milstein scheme with neural networks employed as non-parametric function approximators. Estimation is carried out in a non-parametric fashion for the drift function $f: \\mathbb{Z} \\to \\mathbb{R}$, the diffusion coefficient $g: \\mathbb{Z} \\to \\mathbb{R}$. The model of interest is given by \\[ dX(t) = \\xi + f(X(t))\\, dt + g(X(t))\\, dW_t + \\gamma \\int_{\\mathbb{Z}} z\\, N(dt,dz), \\] where $W_t$ is a standard Brownian motion, and $N(dt,dz)$ is a Poisson random measure on $(\\mathbb{R}_{+} \\times \\mathbb{Z}$, $\\mathcal{B} (\\mathbb{R}_{+}) \\otimes \\mathcal{Z}$, $\\lambda( \\Lambda \\otimes v))$, with $\\lambda, \\gamma > 0$, $\\Lambda$ being the Lebesgue measure on $\\mathbb{R}_{+}$, and $v$ a finite measure on the measurable space $(\\mathbb{Z}, \\mathcal{Z})$. Neural networks are used as non-parametric function approximators, enabling the modeling of complex nonlinear dynamics without assuming restrictive functional forms. The proposed methodology constitutes a flexible alternative for inference in systems with state-dependent noise and discontinuities driven by L\\'evy processes.",
      "authors": [
        "Jose-Hermenegildo Ramirez-Gonzalez and Ying Sun"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-06T15:13:31+00:00",
          "link": "https://arxiv.org/abs/2507.04417v1",
          "size": "7833kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T12:33:51+00:00",
          "link": "https://arxiv.org/abs/2507.04417v2",
          "size": "8510kb",
          "version": "v2"
        }
      ],
      "title": "Neural Networks for Tamed Milstein Approximation of SDEs with Additive Symmetric Jump Noise Driven by a Poisson Random Measure",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.04417",
        "HTML": "https://arxiv.org/html/2507.04417v2",
        "PDF": "https://arxiv.org/pdf/2507.04417"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the use of neural networks to estimate drift and diffusion functions in stochastic differential equations. It does not address any aspects of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06613",
      "abstract": "Disentangled and interpretable latent representations in generative models typically come at the cost of generation quality. The $\\beta$-VAE framework introduces a hyperparameter $\\beta$ to balance disentanglement and reconstruction quality, where setting $\\beta > 1$ introduces an information bottleneck that favors disentanglement over sharp, accurate reconstructions. To address this trade-off, we propose a novel generative modeling framework that leverages a range of $\\beta$ values to learn multiple corresponding latent representations. First, we obtain a slew of representations by training a single variational autoencoder (VAE), with a new loss function that controls the information retained in each latent representation such that the higher $\\beta$ value prioritize disentanglement over reconstruction fidelity. We then, introduce a non-linear diffusion model that smoothly transitions latent representations corresponding to different $\\beta$ values. This model denoises towards less disentangled and more informative representations, ultimately leading to (almost) lossless representations, enabling sharp reconstructions. Furthermore, our model supports sample generation without input images, functioning as a standalone generative model. We evaluate our framework in terms of both disentanglement and generation quality. Additionally, we observe smooth transitions in the latent spaces with respect to changes in $\\beta$, facilitating consistent manipulation of generated outputs.",
      "authors": [
        "Anshuk Uppal",
        "Yuhta Takida",
        "Chieh-Hsin Lai",
        "Yuki Mitsufuji"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T07:29:41+00:00",
          "link": "https://arxiv.org/abs/2507.06613v1",
          "size": "27063kb",
          "version": "v1"
        }
      ],
      "title": "Denoising Multi-Beta VAE: Representation Learning for Disentanglement and Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06613",
        "HTML": "https://arxiv.org/html/2507.06613v1",
        "PDF": "https://arxiv.org/pdf/2507.06613"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a framework for disentanglement and generation in variational autoencoders without contributing to LLM training data processing or dataset development."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06635",
      "abstract": "It is known that windowed decoding (WD) can effectively balance the performance and complexity of spatially coupled low-density parity-check (LDPC) codes. In this study, we show that information can propagate in a wave-like manner at a constant speed under WD. Additionally, we provide an upper bound for the information propagation speed on the binary erasure channel, which can assist in designing the number of iterations required within each window.",
      "authors": [
        "Qingqing Peng",
        "Dongxu Chang",
        "Guanghui Wang",
        "Guiying Yan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T08:05:02+00:00",
          "link": "https://arxiv.org/abs/2507.06635v1",
          "size": "750kb",
          "version": "v1"
        }
      ],
      "title": "On the Convergence Speed of Spatially Coupled LDPC Ensembles Under Window Decoding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06635",
        "HTML": "https://arxiv.org/html/2507.06635v1",
        "PDF": "https://arxiv.org/pdf/2507.06635"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses spatially coupled LDPC codes and windowed decoding performance, with no relation to LLM training data or its processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06869",
      "abstract": "We study the structure-preserving space discretization of port-Hamiltonian (pH) systems defined with differential constitutive relations. Using the concept of Stokes-Lagrange structure to describe these relations, these are reduced to a finite-dimensional Lagrange subspace of a pH system thanks to a structure-preserving Finite Element Method.\n  To illustrate our results, the 1D nanorod case and the shear beam model are considered, which are given by differential and implicit constitutive relations for which a Stokes-Lagrange structure along with boundary energy ports naturally occur.\n  Then, these results are extended to the nonlinear 2D incompressible Navier-Stokes equations written in a vorticity-stream function formulation. It is first recast as a pH system defined with a Stokes-Lagrange structure along with a modulated Stokes-Dirac structure. A careful structure-preserving space discretization is then performed, leading to a finite-dimensional pH system. Theoretical and numerical results show that both enstrophy and kinetic energy evolutions are preserved both at the semi-discrete and fully-discrete levels.",
      "authors": [
        "Antoine Bendimerad-Hohl",
        "Ghislain Haine",
        "Laurent Lef\\`evre",
        "Denis Matignon"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Dynamical Systems (math.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T14:09:28+00:00",
          "link": "https://arxiv.org/abs/2507.06869v1",
          "size": "2147kb",
          "version": "v1"
        }
      ],
      "title": "Structure-preserving space discretization of differential and nonlocal constitutive relations for port-Hamiltonian systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06869",
        "HTML": "https://arxiv.org/html/2507.06869v1",
        "PDF": "https://arxiv.org/pdf/2507.06869"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on space discretization techniques for port-Hamiltonian systems, which are unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2404.02239",
      "abstract": "We consider convex optimization with non-smooth objective function and log-concave sampling with non-smooth potential (negative log density). In particular, we study two specific settings where the convex objective/potential function is either H\\\"older smooth or in hybrid form as the finite sum of H\\\"older smooth components. To overcome the challenges caused by non-smoothness, our algorithms employ two powerful proximal frameworks in optimization and sampling: the proximal point framework for optimization and the alternating sampling framework (ASF) that uses Gibbs sampling on an augmented distribution. A key component of both optimization and sampling algorithms is the efficient implementation of the proximal map by the regularized cutting-plane method. We establish its iteration-complexity under both H\\\"older smoothness and hybrid settings using novel convergence analysis, yielding results that are new to the literature. We further propose an adaptive proximal bundle method for non-smooth optimization that employs an aggressive adaptive stepsize strategy, which adjusts stepsizes only when necessary and never rejects iterates. The proposed method is universal since it does not need any problem parameters as input. Additionally, we provide an exact implementation of a proximal sampling oracle, analogous to the proximal map in optimization, along with simple complexity analyses for both the H\\\"older smooth and hybrid cases, using a novel technique based on a modified Gaussian integral. Finally, we combine this proximal sampling oracle and ASF to obtain a Markov chain Monte Carlo method with non-asymptotic complexity bounds for sampling in H\\\"older smooth and hybrid settings.",
      "authors": [
        "Jiaming Liang and Yongxin Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-02T18:52:28+00:00",
          "link": "https://arxiv.org/abs/2404.02239v1",
          "size": "42kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T02:24:36+00:00",
          "link": "https://arxiv.org/abs/2404.02239v2",
          "size": "39kb",
          "version": "v2"
        }
      ],
      "title": "Proximal Oracles for Optimization and Sampling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.02239",
        "HTML": "https://arxiv.org/html/2404.02239v2",
        "PDF": "https://arxiv.org/pdf/2404.02239"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with optimization and sampling techniques for non-smooth functions, focusing on proximal frameworks without discussing LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2410.07642",
      "abstract": "Mutual information provides a powerful, general-purpose metric for quantifying the amount of shared information between variables. Estimating normalized mutual information using a k-Nearest Neighbor (k-NN) based approach involves the calculation of the scaling-invariant k-NN radius. Calculation of the radius suffers from numerical overflow when the joint dimensionality of the data becomes high, typically in the range of several hundred dimensions. To address this issue, we propose a logarithmic transformation technique that improves the numerical stability of the radius calculation in high-dimensional spaces. By applying the proposed transformation during the calculation of the radius, numerical overflow is avoided, and precision is maintained. Proposed transformation is validated through both theoretical analysis and empirical evaluation, demonstrating its ability to stabilize the calculation without compromising precision, increasing bias, or adding significant computational overhead, while also helping to maintain estimator variance.",
      "authors": [
        "Marko Tuononen and Ville Hautam\\\"aki"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Machine Learning (cs.LG)",
        "Information Theory (math.IT)",
        "Statistics Theory (math.ST)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-10T06:20:44+00:00",
          "link": "https://arxiv.org/abs/2410.07642v1",
          "size": "128kb",
          "version": "v1"
        },
        {
          "date": "2025-06-06T14:42:30+00:00",
          "link": "https://arxiv.org/abs/2410.07642v2",
          "size": "164kb",
          "version": "v2"
        },
        {
          "date": "2025-07-07T09:44:22+00:00",
          "link": "https://arxiv.org/abs/2410.07642v3",
          "size": "164kb",
          "version": "v3"
        }
      ],
      "title": "Improving Numerical Stability of Normalized Mutual Information Estimator on High Dimensions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.07642",
        "HTML": "https://arxiv.org/html/2410.07642",
        "PDF": "https://arxiv.org/pdf/2410.07642"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses improving numerical stability in the estimation of normalized mutual information, unrelated to LLM training data processing activities like data preparation or filtering."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2412.02506",
      "abstract": "Robust SLAM is a crucial enabler for autonomous navigation in natural, semi-structured environments such as parks and gardens. However, these environments present unique challenges for SLAM due to frequent seasonal changes, varying light conditions, and dense vegetation. These factors often degrade the performance of visual SLAM algorithms originally developed for structured urban environments. To address this gap, we present ROVER, a comprehensive benchmark dataset tailored for evaluating visual SLAM algorithms under diverse environmental conditions and spatial configurations. We captured the dataset with a robotic platform equipped with monocular, stereo, and RGBD cameras, as well as inertial sensors. It covers 39 recordings across five outdoor locations, collected through all seasons and various lighting scenarios, i.e., day, dusk, and night with and without external lighting. With this novel dataset, we evaluate several traditional and deep learning-based SLAM methods and study their performance in diverse challenging conditions. The results demonstrate that while stereo-inertial and RGBD configurations generally perform better under favorable lighting and moderate vegetation, most SLAM systems perform poorly in low-light and high-vegetation scenarios, particularly during summer and autumn. Our analysis highlights the need for improved adaptability in visual SLAM algorithms for outdoor applications, as current systems struggle with dynamic environmental factors affecting scale, feature extraction, and trajectory consistency. This dataset provides a solid foundation for advancing visual SLAM research in real-world, semi-structured environments, fostering the development of more resilient SLAM systems for long-term outdoor localization and mapping. The dataset and the code of the benchmark are available under https://iis-esslingen.github.io/rover.",
      "authors": [
        "Fabian Schmidt",
        "Julian Daubermann",
        "Marcel Mitschke",
        "Constantin Blessing",
        "Stefan Meyer",
        "Markus Enzweiler",
        "Abhinav Valada"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-03T15:34:00+00:00",
          "link": "https://arxiv.org/abs/2412.02506v1",
          "size": "17692kb",
          "version": "v1"
        },
        {
          "date": "2025-03-30T17:53:06+00:00",
          "link": "https://arxiv.org/abs/2412.02506v2",
          "size": "19079kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T10:26:20+00:00",
          "link": "https://arxiv.org/abs/2412.02506v3",
          "size": "19080kb",
          "version": "v3"
        }
      ],
      "title": "ROVER: A Multi-Season Dataset for Visual SLAM",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.02506",
        "HTML": "https://arxiv.org/html/2412.02506v3",
        "PDF": "https://arxiv.org/pdf/2412.02506"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a benchmark dataset for visual SLAM, but it does not engage in processing or creating LLM training data, nor does it detail data engineering for LLM purposes."
      },
      "datasets": [
        {
          "dataset_name": "iis-esslingen/ROVER",
          "downloads": "1422",
          "likes": "2",
          "link": "https://huggingface.co/datasets/iis-esslingen/ROVER"
        }
      ],
      "tasks": [
        "Autonomous Navigation",
        "Outdoor Localization",
        "Simultaneous Localization and Mapping"
      ],
      "repo_urls": [
        "https://github.com/iis-esslingen/vi-slam_lc_benchmark",
        "https://github.com/iis-esslingen/nerf-3dgs-benchmark",
        "https://github.com/iis-esslingen/rover_benchmark"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06263",
      "abstract": "According to what we call the Emotional Alignment Design Policy, artificial entities should be designed to elicit emotional reactions from users that appropriately reflect the entities' capacities and moral status, or lack thereof. This principle can be violated in two ways: by designing an artificial system that elicits stronger or weaker emotional reactions than its capacities and moral status warrant (overshooting or undershooting), or by designing a system that elicits the wrong type of emotional reaction (hitting the wrong target). Although presumably attractive, practical implementation faces several challenges including: How can we respect user autonomy while promoting appropriate responses? How should we navigate expert and public disagreement and uncertainty about facts and values? What if emotional alignment seems to require creating or destroying entities with moral status? To what extent should designs conform to versus attempt to alter user assumptions and attitudes?",
      "authors": [
        "Eric Schwitzgebel and Jeff Sebo"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T20:26:21+00:00",
          "link": "https://arxiv.org/abs/2507.06263v1",
          "size": "268kb",
          "version": "v1"
        }
      ],
      "title": "The Emotional Alignment Design Policy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06263",
        "PDF": "https://arxiv.org/pdf/2507.06263"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper delves into the Emotional Alignment Design Policy for artificial entities, which is unrelated to LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06350",
      "abstract": "We present a privacy-preserving telemetry aggregation scheme. Our underlying frequency estimation routine works within the framework of differential privacy. The design philosophy follows a client-server architecture. Furthermore, the system uses a local differential privacy scheme where data gets randomized on the client before submitting the request to the resource server. This scheme allows for data analysis on de-identified data by carefully adding noise to prevent re-identification attacks, thereby facilitating public data release without compromising the identifiability of the individual record. This work further enhances privacy guarantees by leveraging Oblivious HTTP (OHTTP) to achieve increased privacy protection for data in transit that addresses pre-existing privacy vulnerabilities in raw HTTP. We provide an implementation that focuses on frequency estimation with a histogram of a known dictionary. Our resulting formulation based on OHTTP has provided stricter privacy safeguards when compared to trusting an organization to manually delete identifying information from the client's request in the ingestor as deployed in reference work~\\cite{apple2017}. Code available at https://github.com/kenluck2001/miscellaneous/tree/master/src/Privacy-Preserving-Telemetry.",
      "authors": [
        "Kenneth Odoh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T19:20:56+00:00",
          "link": "https://arxiv.org/abs/2507.06350v1",
          "size": "168kb",
          "version": "v1"
        }
      ],
      "title": "An Architecture for Privacy-Preserving Telemetry Scheme",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06350",
        "HTML": "https://arxiv.org/html/2507.06350v1",
        "PDF": "https://arxiv.org/pdf/2507.06350"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on privacy-preserving telemetry schemes, primarily within the realm of differential privacy and client-server architectures, but does not discuss LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06513",
      "abstract": "Advances in vision-based sensors and computer vision algorithms have significantly improved the analysis and understanding of traffic scenarios. To facilitate the use of these improvements for road safety, this survey systematically categorizes the critical elements that demand attention in traffic scenarios and comprehensively analyzes available vision-driven tasks and datasets. Compared to existing surveys that focus on isolated domains, our taxonomy categorizes attention-worthy traffic entities into two main groups that are anomalies and normal but critical entities, integrating ten categories and twenty subclasses. It establishes connections between inherently related fields and provides a unified analytical framework. Our survey highlights the analysis of 35 vision-driven tasks and comprehensive examinations and visualizations of 73 available datasets based on the proposed taxonomy. The cross-domain investigation covers the pros and cons of each benchmark with the aim of providing information on standards unification and resource optimization. Our article concludes with a systematic discussion of the existing weaknesses, underlining the potential effects and promising solutions from various perspectives. The integrated taxonomy, comprehensive analysis, and recapitulatory tables serve as valuable contributions to this rapidly evolving field by providing researchers with a holistic overview, guiding strategic resource selection, and highlighting critical research gaps.",
      "authors": [
        "Yaoqi Huang",
        "Julie Stephany Berrio",
        "Mao Shan",
        "and Stewart Worrall"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T03:26:02+00:00",
          "link": "https://arxiv.org/abs/2507.06513v1",
          "size": "234732kb",
          "version": "v1"
        }
      ],
      "title": "What Demands Attention in Urban Street Scenes? From Scene Understanding towards Road Safety: A Survey of Vision-driven Datasets and Studies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06513",
        "HTML": "https://arxiv.org/html/2507.06513v1",
        "PDF": "https://arxiv.org/pdf/2507.06513"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is a survey on vision-driven datasets related to urban street scenes and road safety, without any focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06921",
      "abstract": "Prediction uncertainty quantification is a key research topic in recent years scientific and business problems. In insurance industries (\\cite{parodi2023pricing}), assessing the range of possible claim costs for individual drivers improves premium pricing accuracy. It also enables insurers to manage risk more effectively by accounting for uncertainty in accident likelihood and severity. In the presence of covariates, a variety of regression-type models are often used for modeling insurance claims, ranging from relatively simple generalized linear models (GLMs) to regularized GLMs to gradient boosting models (GBMs). Conformal predictive inference has arisen as a popular distribution-free approach for quantifying predictive uncertainty under relatively weak assumptions of exchangeability, and has been well studied under the classic linear regression setting. In this work, we propose new non-conformity measures for GLMs and GBMs with GLM-type loss. Using regularized Tweedie GLM regression and LightGBM with Tweedie loss, we demonstrate conformal prediction performance with these non-conformity measures in insurance claims data. Our simulation results favor the use of locally weighted Pearson residuals for LightGBM over other methods considered, as the resulting intervals maintained the nominal coverage with the smallest average width.",
      "authors": [
        "Alokesh Manna",
        "Aditya Vikram Sett",
        "Dipak K. Dey",
        "Yuwen Gu",
        "Elizabeth D. Schifano",
        "Jichao He"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T14:58:54+00:00",
          "link": "https://arxiv.org/abs/2507.06921v1",
          "size": "81kb",
          "version": "v1"
        }
      ],
      "title": "Distribution-free inference for LightGBM and GLM with Tweedie loss",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06921",
        "HTML": "https://arxiv.org/html/2507.06921v1",
        "PDF": "https://arxiv.org/pdf/2507.06921"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The main focus is on prediction uncertainty for insurance claims using GLMs and GBMs, not on LLM training data preprocessing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2301.12743",
      "abstract": "We examine how violence affects migration flows and, crucially, how it reshapes the strength of migration networks -- measured by the intensity of migration between areas, accounting for the fact that some routes become more prominent or fade over time -- an aspect traditional studies overlook. Using a novel network algorithm and Mexican census data from 2005 to 2020, we first quantify changes in the strength of domestic and international migration networks across all Mexican municipalities. We exploit variation in local homicide rates, using exogenous fuel price increases and municipalities' proximity to oil pipelines as instruments, to estimate the causal impact of violence on migration. During our study period, following intensified government crackdowns on drug trafficking organizations, many criminal groups fragmented and turned toward large-scale oil theft, driving sharp increases in violence in areas with oil pipelines, particularly when fuel prices rose. The findings show that rising violence increased emigration flows, predominantly within Mexico, and strengthened the intensity of emigration networks both domestically and toward the United States. Although violent municipalities continued to receive new residents, the rise in emigration was larger. Increasing homicide rates led to at least an additional 1.12 million people emigrating domestically and 50,200 fewer Mexicans returning from the United States. Violence also eroded regional connectivity, causing a long-term decline in daily vehicle traffic on highways linking violent areas to the rest of the country.",
      "authors": [
        "Michele Coscia",
        "Roxana Guti\\'errez-Romero"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Physics and Society (physics.soc-ph)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2023-01-30T09:18:25+00:00",
          "link": "https://arxiv.org/abs/2301.12743v1",
          "size": "2040kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T07:27:35+00:00",
          "link": "https://arxiv.org/abs/2301.12743v2",
          "size": "2411kb",
          "version": "v2"
        }
      ],
      "title": "Displacement and disconnection: the impact of violence on migration networks and highway traffic in Mexico",
      "links": {
        "Abstract": "https://arxiv.org/abs/2301.12743",
        "PDF": "https://arxiv.org/pdf/2301.12743"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study examines the impact of violence on migration networks in Mexico and does not involve any LLM training data processing or engineering activities."
      },
      "source": "arXiv"
    },
    {
      "id": "2405.18133",
      "abstract": "We present a grid-free fluid solver featuring a novel Gaussian representation. Drawing inspiration from the expressive capabilities of 3D Gaussian Splatting in multi-view image reconstruction, we model the continuous flow velocity as a weighted sum of multiple Gaussian functions. This representation is continuously differentiable, which enables us to derive spatial differentials directly and solve the time-dependent PDE via a custom first-order optimization tailored to fluid dynamics. Compared to traditional discretizations, which typically adopt Eulerian, Lagrangian, or hybrid perspectives, our approach is inherently memory-efficient and spatially adaptive, enabling it to preserve fine-scale structures and vortices with high fidelity. While these advantages are also sought by implicit neural representations, GSR offers enhanced robustness, accuracy, and generality across diverse fluid phenomena, with improved computational efficiency during temporal evolution. Though our first-order solver does not yet match the speed of fluid solvers using explicit representations, its continuous nature substantially reduces spatial discretization error and opens a new avenue for high-fidelity simulation. We evaluate the proposed solver across a broad range of 2D and 3D fluid phenomena, demonstrating its ability to preserve intricate vortex dynamics, accurately capture boundary-induced effects such as K\\'arm\\'an vortex streets, and remain robust across long time horizons - all without additional parameter tuning. Our results suggest that GSR offers a compelling direction for future research in fluid simulation.",
      "authors": [
        "Jingrui Xing",
        "Bin Wang",
        "Mengyu Chu",
        "Baoquan Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-28T12:47:49+00:00",
          "link": "https://arxiv.org/abs/2405.18133v1",
          "size": "2704kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T08:19:28+00:00",
          "link": "https://arxiv.org/abs/2405.18133v2",
          "size": "16218kb",
          "version": "v2"
        }
      ],
      "title": "Gaussian Fluids: A Grid-Free Fluid Solver based on Gaussian Spatial Representation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.18133",
        "HTML": "https://arxiv.org/html/2405.18133v2",
        "PDF": "https://arxiv.org/pdf/2405.18133"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with fluid dynamics through a grid-free solver and Gaussian spatial representation, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.02195",
      "abstract": "Magnetotelluric (MT) forward modeling is fundamental for improving the accuracy and efficiency of MT inversion. Neural operators (NOs) have been effectively used for rapid MT forward modeling, demonstrating their promising performance in solving the MT forward modeling-related partial differential equations (PDEs). Particularly, they can obtain the electromagnetic field at arbitrary locations and frequencies. In these NOs, the projection layers have been dominated by multi-layer perceptrons (MLPs), which may potentially reduce the accuracy of solution due to they usually suffer from the disadvantages of MLPs, such as lack of interpretability, overfitting, and so on. Therefore, to improve the accuracy of MT forward modeling with NOs and explore the potential alternatives to MLPs, we propose a novel neural operator by extending the Fourier neural operator (FNO) with Kolmogorov-Arnold network (EFKAN). Within the EFKAN framework, the FNO serves as the branch network to calculate the apparent resistivity and phase from the resistivity model in the frequency domain. Meanwhile, the KAN acts as the trunk network to project the resistivity and phase, determined by the FNO, to the desired locations and frequencies. Experimental results demonstrate that the proposed method not only achieves higher accuracy in obtaining apparent resistivity and phase compared to the NO equipped with MLPs at the desired frequencies and locations but also outperforms traditional numerical methods in terms of computational speed.",
      "authors": [
        "Feng Wang",
        "Hong Qiu",
        "Yingying Huang",
        "Xiaozhe Gu",
        "Renfang Wang",
        "and Bo Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Geophysics (physics.geo-ph)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-04T10:21:14+00:00",
          "link": "https://arxiv.org/abs/2502.02195v1",
          "size": "8215kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T10:59:52+00:00",
          "link": "https://arxiv.org/abs/2502.02195v2",
          "size": "8334kb",
          "version": "v2"
        }
      ],
      "title": "EFKAN: A KAN-Integrated Neural Operator For Efficient Magnetotelluric Forward Modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.02195",
        "HTML": "https://arxiv.org/html/2502.02195v2",
        "PDF": "https://arxiv.org/pdf/2502.02195"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses improving accuracy in magnetotelluric forward modeling through neural operators but does not cover LLM training data processing or associated data engineering methods."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/linfengyu77/efkan"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.16351",
      "abstract": "Neural radiance field (NeRF) research has made significant progress in modeling static video content captured in the wild. However, current models and rendering processes rarely consider scenes captured underwater, which are useful for studying and filming ocean life. They fail to address visual artifacts unique to underwater scenes, such as moving fish and suspended particles. This paper introduces a novel NeRF renderer and optimization scheme for an implicit MLP-based NeRF model. Our renderer reduces the influence of floaters and moving objects that interfere with static objects of interest by estimating a single surface per ray. We use a Gaussian weight function with a small offset to ensure that the transmittance of the surrounding media remains constant. Additionally, we enhance our model with a depth-based scaling function to upscale gradients for near-camera volumes. Overall, our method outperforms the baseline Nerfacto by approximately 7.5\\% and SeaThru-NeRF by 6.2% in terms of PSNR. Subjective evaluation also shows a significant reduction of artifacts while preserving details of static targets and background compared to the state of the arts.",
      "authors": [
        "Luca Gough",
        "Adrian Azzarelli",
        "Fan Zhang",
        "Nantheera Anantrasirichai"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-22T20:53:25+00:00",
          "link": "https://arxiv.org/abs/2502.16351v1",
          "size": "3615kb",
          "version": "v1"
        }
      ],
      "title": "AquaNeRF: Neural Radiance Fields in Underwater Media with Distractor Removal",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.16351",
        "HTML": "https://arxiv.org/html/2502.16351",
        "PDF": "https://arxiv.org/pdf/2502.16351"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces an underwater NeRF model enhancement and focuses on visual artifacts and rendering improvements, not on LLM training data processing or dataset creation."
      },
      "tasks": [
        "NeRF"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06573",
      "abstract": "Reinforcement learning with verifiable rewards (RLVR) has recently advanced the reasoning capabilities of large language models (LLMs). While prior work has emphasized algorithmic design, data curation, and reward shaping, we investigate RLVR from a sample-centric perspective and introduce LPPO (Learning-Progress and Prefix-guided Optimization), a framework of progressive optimization techniques. Our work addresses a critical question: how to best leverage a small set of trusted, high-quality demonstrations, rather than simply scaling up data volume. First, motivated by how hints aid human problem-solving, we propose prefix-guided sampling, an online data augmentation method that incorporates partial solution prefixes from expert demonstrations to guide the policy, particularly for challenging instances. Second, inspired by how humans focus on important questions aligned with their current capabilities, we introduce learning-progress weighting, a dynamic strategy that adjusts each training sample's influence based on model progression. We estimate sample-level learning progress via an exponential moving average of per-sample pass rates, promoting samples that foster learning and de-emphasizing stagnant ones. Experiments on mathematical-reasoning benchmarks demonstrate that our methods outperform strong baselines, yielding faster convergence and a higher performance ceiling.",
      "authors": [
        "Xinjie Chen",
        "Minpeng Liao",
        "Guoxin Chen",
        "Chengxi Li",
        "Biao Fu",
        "Kai Fan",
        "Xinggao Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T06:05:28+00:00",
          "link": "https://arxiv.org/abs/2507.06573v1",
          "size": "155kb",
          "version": "v1"
        }
      ],
      "title": "From Data-Centric to Sample-Centric: Enhancing LLM Reasoning via Progressive Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06573",
        "HTML": "https://arxiv.org/html/2507.06573v1",
        "PDF": "https://arxiv.org/pdf/2507.06573"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper describes a method for optimizing sample efficiency in model training, it focuses on an algorithmic framework rather than processing or creating LLM training data directly."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06691",
      "abstract": "This study explores the relationship between musical training, cognitive load (CL), and task accuracy within the virtual reality (VR) exergame Beat Saber across increasing levels of difficulty. Participants (N=32) completed a series of post-task questionnaires after playing the game under three task difficulty levels while having their physiological data measured by an Emotibit. Using regression analyses, we found that task difficulty and gaming experience significantly predicted subjective CL, whereas musical training did not. However, musical training significantly predicted higher task accuracy, along with lower subjective CL, increased gaming experience, and greater physiological arousal. These results suggest that musical training enhances task-specific performance but does not directly reduce subjective CL. Future research should consider alternative methods of grouping musical expertise and the additional predictability of flow and self-efficacy.",
      "authors": [
        "Kyla Ellahiyoun",
        "Emma Jane Pretty",
        "Renan Guarese",
        "Marcel Takac",
        "Haytham Fayek",
        "Fabio Zambetta"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T09:35:00+00:00",
          "link": "https://arxiv.org/abs/2507.06691v1",
          "size": "3792kb",
          "version": "v1"
        }
      ],
      "title": "Effects of task difficulty and music expertise in virtual reality: Observations of cognitive load and task accuracy in a rhythm exergame",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06691",
        "HTML": "https://arxiv.org/html/2507.06691v1",
        "PDF": "https://arxiv.org/pdf/2507.06691"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study explores cognitive load and task accuracy in a VR exergame, without any connection to processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06796",
      "abstract": "Integrating external heat into electrolysers can reduce the electrical power demand for carbon-neutral hydrogen production. Efficient operation requires detailed models that incorporate heat availability and its effect on startup costs. This paper advances existing operational models by endogenously modelling startup costs and direct heat integration, based on a piecewise linear approximation of the electrochemical equations. We analyse the impact of low- and high-temperature heat integration on the efficiency and profitability of hydrogen production for solid oxide and proton exchange membrane electrolysis technologies.",
      "authors": [
        "Matthias Derez",
        "Alexander Hoogsteyn",
        "Erik Delarue"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Materials Science (cond-mat.mtrl-sci)",
        "Systems and Control (cs.SY)",
        "General Economics (econ.GN)",
        "Economics (q-fin.EC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T12:31:07+00:00",
          "link": "https://arxiv.org/abs/2507.06796v1",
          "size": "445kb",
          "version": "v1"
        }
      ],
      "title": "Optimisation of Electrolyser Operation: Integrating External Heat",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06796",
        "HTML": "https://arxiv.org/html/2507.06796v1",
        "PDF": "https://arxiv.org/pdf/2507.06796"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses optimizing electrolyser operation with heat integration, unrelated to LLM training-data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06261",
      "abstract": "In this report, we introduce the Gemini 2.X model family: Gemini 2.5 Pro and Gemini 2.5 Flash, as well as our earlier Gemini 2.0 Flash and Flash-Lite models. Gemini 2.5 Pro is our most capable model yet, achieving SoTA performance on frontier coding and reasoning benchmarks. In addition to its incredible coding and reasoning skills, Gemini 2.5 Pro is a thinking model that excels at multimodal understanding and it is now able to process up to 3 hours of video content. Its unique combination of long context, multimodal and reasoning capabilities can be combined to unlock new agentic workflows. Gemini 2.5 Flash provides excellent reasoning abilities at a fraction of the compute and latency requirements and Gemini 2.0 Flash and Flash-Lite provide high performance at low latency and cost. Taken together, the Gemini 2.X model generation spans the full Pareto frontier of model capability vs cost, allowing users to explore the boundaries of what is possible with complex agentic problem solving.",
      "authors": [
        "Gheorghe Comanici",
        "Eric Bieber",
        "Mike Schaekermann",
        "Ice Pasupat",
        "Noveen Sachdeva",
        "Inderjit Dhillon",
        "Marcel Blistein",
        "Ori Ram",
        "Dan Zhang",
        "Evan Rosen",
        "Luke Marris",
        "Sam Petulla",
        "Colin Gaffney",
        "Asaf Aharoni",
        "Nathan Lintz",
        "Tiago Cardal Pais",
        "Henrik Jacobsson",
        "Idan Szpektor",
        "Nan-Jiang Jiang",
        "Krishna Haridasan",
        "Ahmed Omran",
        "Nikunj Saunshi",
        "Dara Bahri",
        "Gaurav Mishra",
        "Eric Chu",
        "Toby Boyd",
        "Brad Hekman",
        "Aaron Parisi",
        "Chaoyi Zhang",
        "Kornraphop Kawintiranon",
        "Tania Bedrax-Weiss",
        "Oliver Wang",
        "Ya Xu",
        "Ollie Purkiss",
        "Uri Mendlovic",
        "Ila\\\"i Deutel",
        "Nam Nguyen",
        "Adam Langley",
        "Flip Korn",
        "Lucia Rossazza",
        "Alexandre Ram\\'e",
        "Sagar Waghmare",
        "Helen Miller",
        "Vaishakh Keshava",
        "Ying Jian",
        "Xiaofan Zhang",
        "Raluca Ada Popa",
        "Kedar Dhamdhere",
        "Bla\\v{z} Bratani\\v{c}",
        "Kyuyeun Kim",
        "Terry Koo",
        "Ferran Alet",
        "Yi-ting Chen",
        "Arsha Nagrani",
        "Hannah Muckenhirn",
        "Zhiyuan Zhang",
        "Corbin Quick",
        "Filip Paveti\\'c",
        "Duc Dung Nguyen",
        "Joao Carreira",
        "Michael Elabd",
        "Haroon Qureshi",
        "Fabian Mentzer",
        "Yao-Yuan Yang",
        "Danielle Eisenbud",
        "Anmol Gulati",
        "Ellie Talius",
        "Eric Ni",
        "Sahra Ghalebikesabi",
        "Edouard Yvinec",
        "Alaa Saade",
        "Thatcher Ulrich",
        "Lorenzo Blanco",
        "Dan A. Calian",
        "Muhuan Huang",
        "A\\\"aron van den Oord",
        "Naman Goyal",
        "Terry Chen",
        "Praynaa Rawlani",
        "Christian Schallhart",
        "Swachhand Lokhande",
        "Xianghong Luo",
        "Jyn Shan",
        "Ceslee Montgomery",
        "Victoria Krakovna",
        "Federico Piccinini",
        "Omer Barak",
        "Jingyu Cui",
        "Yiling Jia",
        "Mikhail Dektiarev",
        "Alexey Kolganov",
        "Shiyu Huang",
        "Zhe Chen",
        "Xingyu Wang",
        "Jessica Austin",
        "Peter de Boursac",
        "Evgeny Sluzhaev",
        "Frank Ding",
        "Huijian Li",
        "Surya Bhupatiraju",
        "Mohit Agarwal",
        "S{\\l}awek Kwasiborski",
        "Paramjit Sandhu",
        "Patrick Siegler",
        "Ahmet Iscen",
        "Eyal Ben-David",
        "Shiraz Butt",
        "Miltos Allamanis",
        "Seth Benjamin",
        "Robert Busa-Fekete",
        "Felix Hernandez-Campos",
        "Sasha Goldshtein",
        "Matt Dibb",
        "Weiyang Zhang",
        "Annie Marsden",
        "Carey Radebaugh",
        "Stephen Roller",
        "Abhishek Nayyar",
        "Jacob Austin",
        "Tayfun Terzi",
        "Bhargav Kanagal Shamanna",
        "Pete Shaw",
        "Aayush Singh",
        "Florian Luisier",
        "Artur Mendon\\c{c}a",
        "Vaibhav Aggarwal",
        "Larisa Markeeva",
        "Claudio Fantacci",
        "Sergey Brin",
        "HyunJeong Choe",
        "Guanyu Wang",
        "Hartwig Adam",
        "Avigail Dabush",
        "Tatsuya Kiyono",
        "Eyal Marcus",
        "Jeremy Cole",
        "Theophane Weber",
        "Hongrae Lee",
        "Ronny Huang",
        "Alex Muzio",
        "Leandro Kieliger",
        "Maigo Le",
        "Courtney Biles",
        "Long Le",
        "Archit Sharma",
        "Chengrun Yang",
        "Avery Lamp",
        "Dave Dopson",
        "Nate Hurley",
        "Katrina (Xinyi) Xu",
        "Zhihao Shan",
        "Shuang Song",
        "Jiewen Tan",
        "Alexandre Senges",
        "George Zhang",
        "Chong You",
        "Yennie Jun",
        "David Raposo",
        "Susanna Ricco",
        "Xuan Yang",
        "Weijie Chen",
        "Prakhar Gupta",
        "Arthur Szlam",
        "Kevin Villela",
        "Chun-Sung Ferng",
        "Daniel Kasenberg",
        "Chen Liang",
        "Rui Zhu",
        "Arunachalam Narayanaswamy",
        "Florence Perot",
        "Paul Pucciarelli",
        "Anna Shekhawat",
        "Alexey Stern",
        "Rishikesh Ingale",
        "Stefani Karp",
        "Sanaz Bahargam",
        "Adrian Goedeckemeyer",
        "Jie Han",
        "Sicheng Li",
        "Andrea Tacchetti",
        "Dian Yu",
        "Abhishek Chakladar",
        "Zhiying Zhang",
        "Mona El Mahdy",
        "Xu Gao",
        "Dale Johnson",
        "Samrat Phatale",
        "AJ Piergiovanni",
        "Hyeontaek Lim",
        "Clement Farabet",
        "Carl Lebsack",
        "Theo Guidroz",
        "John Blitzer",
        "Nico Duduta",
        "David Madras",
        "Steve Li",
        "Daniel von Dincklage",
        "Xin Li",
        "Mahdis Mahdieh",
        "George Tucker",
        "Ganesh Jawahar",
        "Owen Xiao",
        "Danny Tarlow",
        "Robert Geirhos",
        "Noam Velan",
        "Daniel Vlasic",
        "Kalesha Bullard",
        "SK Park",
        "Nishesh Gupta",
        "Kellie Webster",
        "Ayal Hitron",
        "Jieming Mao",
        "Julian Eisenschlos",
        "Laurel Prince",
        "Nina D'Souza",
        "Kelvin Zheng",
        "Sara Nasso",
        "Gabriela Botea",
        "Carl Doersch",
        "Caglar Unlu",
        "Chris Alberti",
        "Alexey Svyatkovskiy",
        "Ankita Goel",
        "Krzysztof Choromanski",
        "Pan-Pan Jiang",
        "Richard Nguyen",
        "Four Flynn",
        "Daria \\'Curko",
        "Peter Chen",
        "Nicholas Roth",
        "Kieran Milan",
        "Caleb Habtegebriel",
        "Shashi Narayan",
        "Michael Moffitt",
        "Jake Marcus",
        "Thomas Anthony",
        "Brendan McMahan",
        "Gowoon Cheon",
        "Ruibo Liu",
        "Megan Barnes",
        "Lukasz Lew",
        "Rebeca Santamaria-Fernandez",
        "Mayank Upadhyay",
        "Arjun Akula",
        "Arnar Mar Hrafnkelsson",
        "Alvaro Caceres",
        "Andrew Bunner",
        "Michal Sokolik",
        "Subha Puttagunta",
        "Lawrence Moore",
        "Berivan Isik",
        "Weilun Chen",
        "Jay Hartford",
        "Lawrence Chan",
        "Pradeep Shenoy",
        "Dan Holtmann-Rice",
        "Jane Park",
        "Fabio Viola",
        "Alex Salcianu",
        "Sujeevan Rajayogam",
        "Ian Stewart-Binks",
        "Zelin Wu",
        "Richard Everett",
        "Xi Xiong",
        "Pierre-Antoine Manzagol",
        "Gary Leung",
        "Carl Saroufim",
        "Bo Pang",
        "Dawid Wegner",
        "George Papamakarios",
        "Jennimaria Palomaki",
        "Helena Pankov",
        "Guangda Lai",
        "Guilherme Tubone",
        "Shubin Zhao",
        "Theofilos Strinopoulos",
        "Seth Neel",
        "Mingqiu Wang",
        "Joe Kelley",
        "Li Li",
        "Pingmei Xu",
        "Anitha Vijayakumar",
        "Andrea D'olimpio",
        "Omer Levy",
        "Massimo Nicosia",
        "Grigory Rozhdestvenskiy",
        "Ni Lao",
        "Sirui Xie",
        "Yash Katariya",
        "Jon Simon",
        "Sanjiv Kumar",
        "Florian Hartmann",
        "Michael Kilgore",
        "Jinhyuk Lee",
        "Aroma Mahendru",
        "Roman Ring",
        "Tom Hennigan",
        "Fiona Lang",
        "Colin Cherry",
        "David Steiner",
        "Dawsen Hwang",
        "Ray Smith",
        "Pidong Wang",
        "Jeremy Chen",
        "Ming-Hsuan Yang",
        "Sam Kwei",
        "Philippe Schlattner",
        "Donnie Kim",
        "Ganesh Poomal Girirajan",
        "Nikola Momchev",
        "Ayushi Agarwal",
        "Xingyi Zhou",
        "Ilkin Safarli",
        "Zachary Garrett",
        "AJ Pierigiovanni",
        "Sarthak Jauhari",
        "Alif Raditya Rochman",
        "Shikhar Vashishth",
        "Quan Yuan",
        "Christof Angermueller",
        "Jon Blanton",
        "Xinying Song",
        "Nitesh Bharadwaj Gundavarapu",
        "Thi Avrahami",
        "Maxine Deines",
        "Subhrajit Roy",
        "Manish Gupta",
        "Christopher Semturs",
        "Shobha Vasudevan",
        "Aditya Srikanth Veerubhotla",
        "Shriya Sharma",
        "Josh Jacob",
        "Zhen Yang",
        "Andreas Terzis",
        "Dan Karliner",
        "Auriel Wright",
        "Tania Rojas-Esponda",
        "Ashley Brown",
        "Abhijit Guha Roy",
        "Pawan Dogra",
        "Andrei Kapishnikov",
        "Peter Young",
        "Wendy Kan",
        "Vinodh Kumar Rajendran",
        "Maria Ivanova",
        "Salil Deshmukh",
        "Chia-Hua Ho",
        "Mike Kwong",
        "Stav Ginzburg",
        "Annie Louis",
        "KP Sawhney",
        "Slav Petrov",
        "Jing Xie",
        "Yunfei Bai",
        "Georgi Stoyanov",
        "Alex Fabrikant",
        "Rajesh Jayaram",
        "Yuqi Li",
        "Joe Heyward",
        "Justin Gilmer",
        "Yaqing Wang",
        "Radu Soricut",
        "Luyang Liu",
        "Qingnan Duan",
        "Jamie Hayes",
        "Maura O'Brien",
        "Gaurav Singh Tomar",
        "Sivan Eiger",
        "Bahar Fatemi",
        "Jeffrey Hui",
        "Catarina Barros",
        "Adaeze Chukwuka",
        "Alena Butryna",
        "Saksham Thakur",
        "Austin Huang",
        "Zhufeng Pan",
        "Haotian Tang",
        "Serkan Cabi",
        "Tulsee Doshi",
        "Michiel Bakker",
        "Sumit Bagri",
        "Ruy Ley-Wild",
        "Adam Lelkes",
        "Jennie Lees",
        "Patrick Kane",
        "David Greene",
        "Shimu Wu",
        "J\\\"org Bornschein",
        "Gabriela Surita",
        "Sarah Hodkinson",
        "Fangtao Li",
        "Chris Hidey",
        "S\\'ebastien Pereira",
        "Sean Ammirati",
        "Phillip Lippe",
        "Adam Kraft",
        "Pu Han",
        "Sebastian Gerlach",
        "Zifeng Wang",
        "Liviu Panait",
        "Feng Han",
        "Brian Farris",
        "Yingying Bi",
        "Hannah DeBalsi",
        "Miaosen Wang",
        "Gladys Tyen",
        "James Cohan",
        "Susan Zhang",
        "Jarred Barber",
        "Da-Woon Chung",
        "Jaeyoun Kim",
        "Markus Kunesch",
        "Steven Pecht",
        "Nami Akazawa",
        "Abe Friesen",
        "James Lyon",
        "Ali Eslami",
        "Junru Wu",
        "Jie Tan",
        "Yue Song",
        "Ravi Kumar",
        "Chris Welty",
        "Ilia Akolzin",
        "Gena Gibson",
        "Sean Augenstein",
        "Arjun Pillai",
        "Nancy Yuen",
        "Du Phan",
        "Xin Wang",
        "Iain Barr",
        "Heiga Zen",
        "Nan Hua",
        "Casper Liu",
        "Jilei (Jerry) Wang",
        "Tanuj Bhatia",
        "Hao Xu",
        "Oded Elyada",
        "Pushmeet Kohli",
        "Mirek Ol\\v{s}\\'ak",
        "Ke Chen",
        "Azalia Mirhoseini",
        "Noam Shazeer",
        "Shoshana Jakobovits",
        "Maggie Tran",
        "Nolan Ramsden",
        "Tarun Bharti",
        "Fred Alcober",
        "Yunjie Li",
        "Shilpa Shetty",
        "Jing Chen",
        "Dmitry Kalashnikov",
        "Megha Nawhal",
        "Sercan Arik",
        "Hanwen Chen",
        "Michiel Blokzijl",
        "Shubham Gupta",
        "James Rubin",
        "Rigel Swavely",
        "Sophie Bridgers",
        "Ian Gemp",
        "Chen Su",
        "Arun Suggala",
        "Juliette Pluto",
        "Mary Cassin",
        "Alain Vaucher",
        "Kaiyang Ji",
        "Jiahao Cai",
        "Andrew Audibert",
        "Animesh Sinha",
        "David Tian",
        "Efrat Farkash",
        "Amy Hua",
        "Jilin Chen",
        "Duc-Hieu Tran",
        "Edward Loper",
        "Nicole Brichtova",
        "Lara McConnaughey",
        "Ballie Sandhu",
        "Robert Leland",
        "Doug DeCarlo",
        "Andrew Over",
        "James Huang",
        "Xing Wu",
        "Connie Fan",
        "Eric Li",
        "Yun Lei",
        "Deepak Sharma",
        "Cosmin Paduraru",
        "Luo Yu",
        "Matko Bo\\v{s}njak",
        "Phuong Dao",
        "Min Choi",
        "Sneha Kudugunta",
        "Jakub Adamek",
        "Carlos Gu\\'ia",
        "Ali Khodaei",
        "Jie Feng",
        "Wenjun Zeng",
        "David Welling",
        "Sandeep Tata",
        "Christina Butterfield",
        "Andrey Vlasov",
        "Seliem El-Sayed",
        "Swaroop Mishra",
        "Tara Sainath",
        "Shentao Yang",
        "RJ Skerry-Ryan",
        "Jeremy Shar",
        "Robert Berry",
        "Arunkumar Rajendran",
        "Arun Kandoor",
        "Andrea Burns",
        "Deepali Jain",
        "Tom Stone",
        "Wonpyo Park",
        "Shibo Wang",
        "Albin Cassirer",
        "Guohui Wang",
        "Hayato Kobayashi",
        "Sergey Rogulenko",
        "Vineetha Govindaraj",
        "Miko{\\l}aj Rybi\\'nski",
        "Nadav Olmert",
        "Colin Evans",
        "Po-Sen Huang",
        "Kelvin Xu",
        "Premal Shah",
        "Terry Thurk",
        "Caitlin Sikora",
        "Mu Cai",
        "Jin Xie",
        "Elahe Dabir",
        "Saloni Shah",
        "Norbert Kalb",
        "Carrie Zhang",
        "Shruthi Prabhakara",
        "Amit Sabne",
        "Artiom Myaskovsky",
        "Vikas Raunak",
        "Blanca Huergo",
        "Behnam Neyshabur",
        "Jon Clark",
        "Ye Zhang",
        "Shankar Krishnan",
        "Eden Cohen",
        "Dinesh Tewari",
        "James Lottes",
        "Yumeya Yamamori",
        "Hui (Elena) Li",
        "Mohamed Elhawaty",
        "Ada Maksutaj Oflazer",
        "Adri\\`a Recasens",
        "Sheryl Luo",
        "Duy Nguyen",
        "Taylor Bos",
        "Kalyan Andra",
        "Ana Salazar",
        "Ed Chi",
        "Jeongwoo Ko",
        "Matt Ginsberg",
        "Anders Andreassen",
        "Anian Ruoss",
        "Todor Davchev",
        "Elnaz Davoodi",
        "Chenxi Liu",
        "Min Kim",
        "Santiago Ontanon",
        "Chi Ming To",
        "Dawei Jia",
        "Rosemary Ke",
        "Jing Wang",
        "Anna Korsun",
        "Moran Ambar",
        "Ilya Kornakov",
        "Irene Giannoumis",
        "Toni Creswell",
        "Denny Zhou",
        "Yi Su",
        "Ishaan Watts",
        "Aleksandr Zaks",
        "Evgenii Eltyshev",
        "Ziqiang Feng",
        "Sidharth Mudgal",
        "Alex Kaskasoli",
        "Juliette Love",
        "Kingshuk Dasgupta",
        "Sam Shleifer",
        "Richard Green",
        "Sungyong Seo",
        "Chansoo Lee",
        "Dale Webster",
        "Prakash Shroff",
        "Ganna Raboshchuk",
        "Isabel Leal",
        "James Manyika",
        "Sofia Erell",
        "Daniel Murphy",
        "Zhisheng Xiao",
        "Anton Bulyenov",
        "Julian Walker",
        "Mark Collier",
        "Matej Kastelic",
        "Nelson George",
        "Sushant Prakash",
        "Sailesh Sidhwani",
        "Alexey Frolov",
        "Steven Hansen",
        "Petko Georgiev",
        "Tiberiu Sosea",
        "Chris Apps",
        "Aishwarya Kamath",
        "David Reid",
        "Emma Cooney",
        "Charlotte Magister",
        "Oriana Riva",
        "Alec Go",
        "Pu-Chin Chen",
        "Sebastian Krause",
        "Nir Levine",
        "Marco Fornoni",
        "Ilya Figotin",
        "Nick Roy",
        "Parsa Mahmoudieh",
        "Vladimir Magay",
        "Mukundan Madhavan",
        "Jin Miao",
        "Jianmo Ni",
        "Yasuhisa Fujii",
        "Ian Chou",
        "George Scrivener",
        "Zak Tsai",
        "Siobhan Mcloughlin",
        "Jeremy Selier",
        "Sandra Lefdal",
        "Jeffrey Zhao",
        "Abhijit Karmarkar",
        "Kushal Chauhan",
        "Shivanker Goel",
        "Zhaoyi Zhang",
        "Vihan Jain",
        "Parisa Haghani",
        "Mostafa Dehghani",
        "Jacob Scott",
        "Erin Farnese",
        "Anastasija Ili\\'c",
        "Steven Baker",
        "Julia Pawar",
        "Li Zhong",
        "Josh Camp",
        "Yoel Zeldes",
        "Shravya Shetty",
        "Anand Iyer",
        "V\\'it List\\'ik",
        "Jiaxian Guo",
        "Luming Tang",
        "Mark Geller",
        "Simon Bucher",
        "Yifan Ding",
        "Hongzhi Shi",
        "Carrie Muir",
        "Dominik Grewe",
        "Ramy Eskander",
        "Octavio Ponce",
        "Boqing Gong",
        "Derek Gasaway",
        "Samira Khan",
        "Umang Gupta",
        "Angelos Filos",
        "Weicheng Kuo",
        "Klemen Kloboves",
        "Jennifer Beattie",
        "Christian Wright",
        "Leon Li",
        "Alicia Jin",
        "Sandeep Mariserla",
        "Miteyan Patel",
        "Jens Heitkaemper",
        "Dilip Krishnan",
        "Vivek Sharma",
        "David Bieber",
        "Christian Frank",
        "John Lambert",
        "Paul Caron",
        "Martin Polacek",
        "Mai Gim\\'enez",
        "Himadri Choudhury",
        "Xing Yu",
        "Sasan Tavakkol",
        "Arun Ahuja",
        "Franz Och",
        "Rodolphe Jenatton",
        "Wojtek Skut",
        "Bryan Richter",
        "David Gaddy",
        "Andy Ly",
        "Misha Bilenko",
        "Megh Umekar",
        "Ethan Liang",
        "Martin Sevenich",
        "Mandar Joshi",
        "Hassan Mansoor",
        "Rebecca Lin",
        "Sumit Sanghai",
        "Abhimanyu Singh",
        "Xiaowei Li",
        "Sudheendra Vijayanarasimhan",
        "Zaheer Abbas",
        "Yonatan Bitton",
        "Hansa Srinivasan",
        "Manish Reddy Vuyyuru",
        "Alexander Fr\\\"ommgen",
        "Yanhua Sun",
        "Ralph Leith",
        "Alfonso Casta\\~no",
        "DJ Strouse",
        "Le Yan",
        "Austin Kyker",
        "Satish Kambala",
        "Mary Jasarevic",
        "Thibault Sellam",
        "Chao Jia",
        "Alexander Pritzel",
        "Raghavender R",
        "Huizhong Chen",
        "Natalie Clay",
        "Sudeep Gandhe",
        "Sean Kirmani",
        "Sayna Ebrahimi",
        "Hannah Kirkwood",
        "Jonathan Mallinson",
        "Chao Wang",
        "Adnan Ozturel",
        "Kuo Lin",
        "Shyam Upadhyay",
        "Vincent Cohen-Addad",
        "Sean Purser-haskell",
        "Yichong Xu",
        "Ebrahim Songhori",
        "Babi Seal",
        "Alberto Magni",
        "Almog Gueta",
        "Tingting Zou",
        "Guru Guruganesh",
        "Thais Kagohara",
        "Hung Nguyen",
        "Khalid Salama",
        "Alejandro Cruzado Ruiz",
        "Justin Frye",
        "Zhenkai Zhu",
        "Matthias Lochbrunner",
        "Simon Osindero",
        "Wentao Yuan",
        "Lisa Lee",
        "Aman Prasad",
        "Lam Nguyen Thiet",
        "Daniele Calandriello",
        "Victor Stone",
        "Qixuan Feng",
        "Han Ke",
        "Maria Voitovich",
        "Geta Sampemane",
        "Lewis Chiang",
        "Ling Wu",
        "Alexander Bykovsky",
        "Matt Young",
        "Luke Vilnis",
        "Ishita Dasgupta",
        "Aditya Chawla",
        "Qin Cao",
        "Bowen Liang",
        "Daniel Toyama",
        "Szabolcs Payrits",
        "Anca Stefanoiu",
        "Dimitrios Vytiniotis",
        "Ankesh Anand",
        "Tianxiao Shen",
        "Blagoj Mitrevski",
        "Michael Tschannen",
        "Sreenivas Gollapudi",
        "Aishwarya P S",
        "Jos\\'e Leal",
        "Zhe Shen",
        "Han Fu",
        "Wei Wang",
        "Arvind Kannan",
        "Doron Kukliansky",
        "Sergey Yaroshenko",
        "Svetlana Grant",
        "Umesh Telang",
        "David Wood",
        "Alexandra Chronopoulou",
        "Alexandru \\c{T}ifrea",
        "Tao Zhou",
        "Tony (Tu\\'\\^an) Nguy\\~\\^en",
        "Muge Ersoy",
        "Anima Singh",
        "Meiyan Xie",
        "Emanuel Taropa",
        "Woohyun Han",
        "Eirikur Agustsson",
        "Andrei Sozanschi",
        "Hui Peng",
        "Alex Chen",
        "Yoel Drori",
        "Efren Robles",
        "Yang Gao",
        "Xerxes Dotiwalla",
        "Ying Chen",
        "Anudhyan Boral",
        "Alexei Bendebury",
        "John Nham",
        "Chris Tar",
        "Luis Castro",
        "Jiepu Jiang",
        "Canoee Liu",
        "Felix Halim",
        "Jinoo Baek",
        "Andy Wan",
        "Jeremiah Liu",
        "Yuan Cao",
        "Shengyang Dai",
        "Trilok Acharya",
        "Ruoxi Sun",
        "Fuzhao Xue",
        "Saket Joshi",
        "Morgane Lustman",
        "Yongqin Xian",
        "Rishabh Joshi",
        "Deep Karkhanis",
        "Nora Kassner",
        "Jamie Hall",
        "Xiangzhuo Ding",
        "Gan Song",
        "Gang Li",
        "Chen Zhu",
        "Yana Kulizhskaya",
        "Bin Ni",
        "Alexey Vlaskin",
        "Solomon Demmessie",
        "Lucio Dery",
        "Salah Zaiem",
        "Yanping Huang",
        "Cindy Fan",
        "Felix Gimeno",
        "Ananth Balashankar",
        "Koji Kojima",
        "Hagai Taitelbaum",
        "Maya Meng",
        "Dero Gharibian",
        "Sahil Singla",
        "Wei Chen",
        "Ambrose Slone",
        "Guanjie Chen",
        "Sujee Rajayogam",
        "Max Schumacher",
        "Suyog Kotecha",
        "Rory Blevins",
        "Qifei Wang",
        "Mor Hazan Taege",
        "Alex Morris",
        "Xin Liu",
        "Fayaz Jamil",
        "Richard Zhang",
        "Pratik Joshi",
        "Ben Ingram",
        "Tyler Liechty",
        "Ahmed Eleryan",
        "Scott Baird",
        "Alex Grills",
        "Gagan Bansal",
        "Shan Han",
        "Kiran Yalasangi",
        "Shawn Xu",
        "Majd Al Merey",
        "Isabel Gao",
        "Felix Weissenberger",
        "Igor Karpov",
        "Robert Riachi",
        "Ankit Anand",
        "Gautam Prasad",
        "Kay Lamerigts",
        "Reid Hayes",
        "Jamie Rogers",
        "Mandy Guo",
        "Ashish Shenoy",
        "Qiong (Q) Hu",
        "Kyle He",
        "Yuchen Liu",
        "Polina Zablotskaia",
        "Sagar Gubbi",
        "Yifan Chang",
        "Jay Pavagadhi",
        "Kristian Kjems",
        "Archita Vadali",
        "Diego Machado",
        "Yeqing Li",
        "Renshen Wang",
        "Dipankar Ghosh",
        "Aahil Mehta",
        "Dana Alon",
        "George Polovets",
        "Alessio Tonioni",
        "Nate Kushman",
        "Joel D'sa",
        "Lin Zhuo",
        "Allen Wu",
        "Rohin Shah",
        "John Youssef",
        "Jiayu Ye",
        "Justin Snyder",
        "Karel Lenc",
        "Senaka Buthpitiya",
        "Matthew Tung",
        "Jichuan Chang",
        "Tao Chen",
        "David Saxton",
        "Jenny Lee",
        "Lydia Lihui Zhang",
        "James Qin",
        "Prabakar Radhakrishnan",
        "Maxwell Chen",
        "Piotr Ambroszczyk",
        "Metin Toksoz-Exley",
        "Yan Zhong",
        "Nitzan Katz",
        "Brendan O'Donoghue",
        "Tamara von Glehn",
        "Adi Gerzi Rosenthal",
        "Aga \\'Swietlik",
        "Xiaokai Zhao",
        "Nick Fernando",
        "Jinliang Wei",
        "Jieru Mei",
        "Sergei Vassilvitskii",
        "Diego Cedillo",
        "Pranjal Awasthi",
        "Hui Zheng",
        "Koray Kavukcuoglu",
        "Itay Laish",
        "Joseph Pagadora",
        "Marc Brockschmidt",
        "Christopher A. Choquette-Choo",
        "Arunkumar Byravan",
        "Yifeng Lu",
        "Xu Chen",
        "Mia Chen",
        "Kenton Lee",
        "Rama Pasumarthi",
        "Sijal Bhatnagar",
        "Aditya Shah",
        "Qiyin Wu",
        "Zhuoyuan Chen",
        "Zack Nado",
        "Bartek Perz",
        "Zixuan Jiang",
        "David Kao",
        "Ganesh Mallya",
        "Nino Vieillard",
        "Lantao Mei",
        "Sertan Girgin",
        "Mandy Jordan",
        "Yeongil Ko",
        "Alekh Agarwal",
        "Yaxin Liu",
        "Yasemin Altun",
        "Raoul de Liedekerke",
        "Anastasios Kementsietsidis",
        "Daiyi Peng",
        "Dangyi Liu",
        "Utku Evci",
        "Peter Humphreys",
        "Austin Tarango",
        "Xiang Deng",
        "Yoad Lewenberg",
        "Kevin Aydin",
        "Chengda Wu",
        "Bhavishya Mittal",
        "Tsendsuren Munkhdalai",
        "Kleopatra Chatziprimou",
        "Rodrigo Benenson",
        "Uri First",
        "Xiao Ma",
        "Jinning Li",
        "Armand Joulin",
        "Hamish Tomlinson",
        "Tingnan Zhang",
        "Milad Nasr",
        "Zhi Hong",
        "Micha\\\"el Sander",
        "Lisa Anne Hendricks",
        "Anuj Sharma",
        "Andrew Bolt",
        "Eszter V\\'ertes",
        "Jiri Simsa",
        "Tomer Levinboim",
        "Olcan Sercinoglu",
        "Divyansh Shukla",
        "Austin Wu",
        "Craig Swanson",
        "Danny Vainstein",
        "Fan Bu",
        "Bo Wang",
        "Ryan Julian",
        "Charles Yoon",
        "Sergei Lebedev",
        "Antonious Girgis",
        "Bernd Bandemer",
        "David Du",
        "Todd Wang",
        "Xi Chen",
        "Ying Xiao",
        "Peggy Lu",
        "Natalie Ha",
        "Vlad Ionescu",
        "Simon Rowe",
        "Josip Matak",
        "Federico Lebron",
        "Andreas Steiner",
        "Lalit Jain",
        "Manaal Faruqui",
        "Nicolas Lacasse",
        "Georgie Evans",
        "Neesha Subramaniam",
        "Dean Reich",
        "Giulia Vezzani",
        "Aditya Pandey",
        "Joe Stanton",
        "Tianhao Zhou",
        "Liam McCafferty",
        "Henry Griffiths",
        "Verena Rieser",
        "Soheil Hassas Yeganeh",
        "Eleftheria Briakou",
        "Lu Huang",
        "Zichuan Wei",
        "Liangchen Luo",
        "Erik Jue",
        "Gabby Wang",
        "Victor Cotruta",
        "Myriam Khan",
        "Jongbin Park",
        "Qiuchen Guo",
        "Peiran Li",
        "Rong Rong",
        "Diego Antognini",
        "Anastasia Petrushkina",
        "Chetan Tekur",
        "Eli Collins",
        "Parul Bhatia",
        "Chester Kwak",
        "Wenhu Chen",
        "Arvind Neelakantan",
        "Immanuel Odisho",
        "Sheng Peng",
        "Vincent Nallatamby",
        "Vaibhav Tulsyan",
        "Fabian Pedregosa",
        "Peng Xu",
        "Raymond Lin",
        "Yulong Wang",
        "Emma Wang",
        "Sholto Douglas",
        "Reut Tsarfaty",
        "Elena Gribovskaya",
        "Renga Aravamudhan",
        "Manu Agarwal",
        "Mara Finkelstein",
        "Qiao Zhang",
        "Elizabeth Cole",
        "Phil Crone",
        "Sarmishta Velury",
        "Anil Das",
        "Chris Sauer",
        "Luyao Xu",
        "Danfeng Qin",
        "Chenjie Gu",
        "Dror Marcus",
        "CJ Zheng",
        "Wouter Van Gansbeke",
        "Sobhan Miryoosefi",
        "Haitian Sun",
        "YaGuang Li",
        "Charlie Chen",
        "Jae Yoo",
        "Pavel Dubov",
        "Alex Tomala",
        "Adams Yu",
        "Pawe{\\l} Weso{\\l}owski",
        "Alok Gunjan",
        "Eddie Cao",
        "Jiaming Luo",
        "Nikhil Sethi",
        "Arkadiusz Socala",
        "Laura Graesser",
        "Tomas Kocisky",
        "Arturo BC",
        "Minmin Chen",
        "Edward Lee",
        "Sophie Wang",
        "Weize Kong",
        "Qiantong Xu",
        "Nilesh Tripuraneni",
        "Yiming Li",
        "Xinxin Yu",
        "Allen Porter",
        "Paul Voigtlaender",
        "Biao Zhang",
        "Arpi Vezer",
        "Sarah York",
        "Qing Wei",
        "Geoffrey Cideron",
        "Mark Kurzeja",
        "Seungyeon Kim",
        "Benny Li",
        "Ang\\'eline Pouget",
        "Hyo Lee",
        "Kaspar Daugaard",
        "Yang Li",
        "Dave Uthus",
        "Aditya Siddhant",
        "Paul Cavallaro",
        "Sriram Ganapathy",
        "Maulik Shah",
        "Rolf Jagerman",
        "Jeff Stanway",
        "Piermaria Mendolicchio",
        "Li Xiao",
        "Kayi Lee",
        "Tara Thompson",
        "Shubham Milind Phal",
        "Jason Chase",
        "Sun Jae Lee",
        "Adrian N Reyes",
        "Disha Shrivastava",
        "Zhen Qin",
        "Roykrong Sukkerd",
        "Seth Odoom",
        "Lior Madmoni",
        "John Aslanides",
        "Jonathan Herzig",
        "Elena Pochernina",
        "Sheng Zhang",
        "Parker Barnes",
        "Daisuke Ikeda",
        "Qiujia Li",
        "Shuo-yiin Chang",
        "Shakir Mohamed",
        "Jim Sproch",
        "Richard Powell",
        "Bidisha Samanta",
        "Domagoj \\'Cevid",
        "Anton Kovsharov",
        "Shrestha Basu Mallick",
        "Srinivas Tadepalli",
        "Anne Zheng",
        "Kareem Ayoub",
        "Andreas Noever",
        "Christian Reisswig",
        "Zhuo Xu",
        "Junhyuk Oh",
        "Martin Matysiak",
        "Tim Blyth",
        "Shereen Ashraf",
        "Julien Amelot",
        "Boone Severson",
        "Michele Bevilacqua",
        "Motoki Sano",
        "Ethan Dyer",
        "Ofir Roval",
        "Anu Sinha",
        "Yin Zhong",
        "Sagi Perel",
        "Tea Saboli\\'c",
        "Johannes Mauerer",
        "Willi Gierke",
        "Mauro Verzetti",
        "Rodrigo Cabrera",
        "Alvin Abdagic",
        "Steven Hemingray",
        "Austin Stone",
        "Jong Lee",
        "Farooq Ahmad",
        "Karthik Raman",
        "Lior Shani",
        "Jonathan Lai",
        "Orhan Firat",
        "Nathan Waters",
        "Eric Ge",
        "Mo Shomrat",
        "Himanshu Gupta",
        "Rajeev Aggarwal",
        "Tom Hudson",
        "Bill Jia",
        "Simon Baumgartner",
        "Palak Jain",
        "Joe Kovac",
        "Junehyuk Jung",
        "Ante \\v{Z}u\\v{z}ul",
        "Will Truong",
        "Morteza Zadimoghaddam",
        "Songyou Peng",
        "Marco Liang",
        "Rachel Sterneck",
        "Balaji Lakshminarayanan",
        "Machel Reid",
        "Oliver Woodman",
        "Tong Zhou",
        "Jianling Wang",
        "Vincent Coriou",
        "Arjun Narayanan",
        "Jay Hoover",
        "Yenai Ma",
        "Apoorv Jindal",
        "Clayton Sanford",
        "Doug Reid",
        "Swaroop Ramaswamy",
        "Alex Kurakin",
        "Roland Zimmermann",
        "Yana Lunts",
        "Dragos Dena",
        "Zal\\'an Borsos",
        "Vered Cohen",
        "Shujian Zhang",
        "Will Grathwohl",
        "Robert Dadashi",
        "Morgan Redshaw",
        "Joshua Kessinger",
        "Julian Odell",
        "Silvano Bonacina",
        "Zihang Dai",
        "Grace Chen",
        "Ayush Dubey",
        "Pablo Sprechmann",
        "Mantas Pajarskas",
        "Wenxuan Zhou",
        "Niharika Ahuja",
        "Tara Thomas",
        "Martin Nikoltchev",
        "Matija Kecman",
        "Bharath Mankalale",
        "Andrey Ryabtsev",
        "Jennifer She",
        "Christian Walder",
        "Jiaming Shen",
        "Lu Li",
        "Carolina Parada",
        "Sheena Panthaplackel",
        "Okwan Kwon",
        "Matt Lawlor",
        "Utsav Prabhu",
        "Yannick Schroecker",
        "Marc'aurelio Ranzato",
        "Pete Blois",
        "Iurii Kemaev",
        "Ting Yu",
        "Dmitry (Dima) Lepikhin",
        "Hao Xiong",
        "Sahand Sharifzadeh",
        "Oleaser Johnson",
        "Jeremiah Willcock",
        "Rui Yao",
        "Greg Farquhar",
        "Sujoy Basu",
        "Hidetoshi Shimokawa",
        "Nina Anderson",
        "Haiguang Li",
        "Khiem Pham",
        "Yizhong Liang",
        "Sebastian Borgeaud",
        "Alexandre Moufarek",
        "Hideto Kazawa",
        "Blair Kutzman",
        "Marcin Sieniek",
        "Sara Smoot",
        "Ruth Wang",
        "Natalie Axelsson",
        "Nova Fallen",
        "Prasha Sundaram",
        "Yuexiang Zhai",
        "Varun Godbole",
        "Petros Maniatis",
        "Alek Wang",
        "Ilia Shumailov",
        "Santhosh Thangaraj",
        "Remi Crocker",
        "Nikita Gupta",
        "Gang Wu",
        "Phil Chen",
        "Gell\\'ert Weisz",
        "Celine Smith",
        "Mojtaba Seyedhosseini",
        "Boya Fang",
        "Xiyang Luo",
        "Roey Yogev",
        "Zeynep Cankara",
        "Andrew Hard",
        "Helen Ran",
        "Rahul Sukthankar",
        "George Necula",
        "Ga\\\"el Liu",
        "Honglong Cai",
        "Praseem Banzal",
        "Daniel Keysers",
        "Sanjay Ghemawat",
        "Connie Tao",
        "Emma Dunleavy",
        "Aditi Chaudhary",
        "Wei Li",
        "Maciej Miku{\\l}a",
        "Chen-Yu Lee",
        "Tiziana Refice",
        "Krishna Somandepalli",
        "Alexandre Fr\\'echette",
        "Dan Bahir",
        "John Karro",
        "Keith Rush",
        "Sarah Perrin",
        "Bill Rosgen",
        "Xiaomeng Yang",
        "Clara Huiyi Hu",
        "Mahmoud Alnahlawi",
        "Justin Mao-Jones",
        "Roopal Garg",
        "Hoang Nguyen",
        "Bat-Orgil Batsaikhan",
        "I\\~naki Iturrate",
        "Anselm Levskaya",
        "Avi Singh",
        "Ashyana Kachra",
        "Tony Lu",
        "Denis Petek",
        "Zheng Xu",
        "Mark Graham",
        "Lukas Zilka",
        "Yael Karov",
        "Marija Kostelac",
        "Fangyu Liu",
        "Yaohui Guo",
        "Weiyue Wang",
        "Bernd Bohnet",
        "Emily Pitler",
        "Tony Bruguier",
        "Keisuke Kinoshita",
        "Chrysovalantis Anastasiou",
        "Nilpa Jha",
        "Ting Liu",
        "Jerome Connor",
        "Phil Wallis",
        "Philip Pham",
        "Eric Bailey",
        "Shixin Li",
        "Heng-Tze Cheng",
        "Sally Ma",
        "Haiqiong Li",
        "Akanksha Maurya",
        "Kate Olszewska",
        "Manfred Warmuth",
        "Christy Koh",
        "Dominik Paulus",
        "Siddhartha Reddy Jonnalagadda",
        "Enrique Piqueras",
        "Ali Elqursh",
        "Geoff Brown",
        "Hadar Shemtov",
        "Loren Maggiore",
        "Fei Xia",
        "Ryan Foley",
        "Beka Westberg",
        "George van den Driessche",
        "Livio Baldini Soares",
        "Arjun Kar",
        "Michael Quinn",
        "Siqi Zuo",
        "Jialin Wu",
        "Kyle Kastner",
        "Anna Bortsova",
        "Aijun Bai",
        "Ales Mikhalap",
        "Luowei Zhou",
        "Jennifer Brennan",
        "Vinay Ramasesh",
        "Honglei Zhuang",
        "John Maggs",
        "Johan Schalkwyk",
        "Yuntao Xu",
        "Hui Huang",
        "Andrew Howard",
        "Sasha Brown",
        "Linting Xue",
        "Gloria Shen",
        "Brian Albert",
        "Neha Jha",
        "Daniel Zheng",
        "Varvara Krayvanova",
        "Spurthi Amba Hombaiah",
        "Olivier Lacombe",
        "Gautam Vasudevan",
        "Dan Graur",
        "Tian Xie",
        "Meet Gandhi",
        "Bangju Wang",
        "Dustin Zelle",
        "Harman Singh",
        "Dahun Kim",
        "S\\'ebastien Cevey",
        "Victor Ungureanu",
        "Natasha Noy",
        "Fei Liu",
        "Annie Xie",
        "Fangxiaoyu Feng",
        "Katerina Tsihlas",
        "Daniel Formoso",
        "Neera Vats",
        "Quentin Wellens",
        "Yinan Wang",
        "Niket Kumar Bhumihar",
        "Samrat Ghosh",
        "Matt Hoffman",
        "Tom Lieber",
        "Oran Lang",
        "Kush Bhatia",
        "Tom Paine",
        "Aroonalok Pyne",
        "Ronny Votel",
        "Madeleine Clare Elish",
        "Benoit Schillings",
        "Alex Panagopoulos",
        "Haichuan Yang",
        "Adam Raveret",
        "Zohar Yahav",
        "Shuang Liu",
        "Warren Chen",
        "Dalia El Badawy",
        "Nishant Agrawal",
        "Mohammed Badawi",
        "Mahdi Mirzazadeh",
        "Carla Bromberg",
        "Fan Ye",
        "Chang Liu",
        "Tatiana Sholokhova",
        "George-Cristian Muraru",
        "Gargi Balasubramaniam",
        "Jonathan Malmaud",
        "Alen Carin",
        "Danilo Martins",
        "Irina Jurenka",
        "Pankil Botadra",
        "Dave Lacey",
        "Richa Singh",
        "Mariano Schain",
        "Dan Zheng",
        "Isabelle Guyon",
        "Victor Lavrenko",
        "Seungji Lee",
        "Xiang Zhou",
        "Demis Hassabis",
        "Jeshwanth Challagundla",
        "Derek Cheng",
        "Nikhil Mehta",
        "Matthew Mauger",
        "Michela Paganini",
        "Pushkar Mishra",
        "Kate Lee",
        "Zhang Li",
        "Lexi Baugher",
        "Ondrej Skopek",
        "Max Chang",
        "Amir Zait",
        "Gaurav Menghani",
        "Lizzetth Bellot",
        "Guangxing Han",
        "Jean-Michel Sarr",
        "Sharat Chikkerur",
        "Himanshu Sahni",
        "Rohan Anil",
        "Arun Narayanan",
        "Chandu Thekkath",
        "Daniele Pighin",
        "Hana Strej\\v{c}ek",
        "Marko Velic",
        "Fred Bertsch",
        "Manuel Tragut",
        "Keran Rong",
        "Alicia Parrish",
        "Kai Bailey",
        "Jiho Park",
        "Isabela Albuquerque",
        "Abhishek Bapna",
        "Rajesh Venkataraman",
        "Alec Kosik",
        "Johannes Griesser",
        "Zhiwei Deng",
        "Alek Andreev",
        "Qingyun Dou",
        "Kevin Hui",
        "Fanny Wei",
        "Xiaobin Yu",
        "Lei Shu",
        "Avia Aharon",
        "David Barker",
        "Badih Ghazi",
        "Sebastian Flennerhag",
        "Chris Breaux",
        "Yuchuan Liu",
        "Matthew Bilotti",
        "Josh Woodward",
        "Uri Alon",
        "Stephanie Winkler",
        "Tzu-Kuo Huang",
        "Kostas Andriopoulos",
        "Jo\\~ao Gabriel Oliveira",
        "Penporn Koanantakool",
        "Berkin Akin",
        "Michael Wunder",
        "Cicero Nogueira dos Santos",
        "Mohammad Hossein Bateni",
        "Lin Yang",
        "Dan Horgan",
        "Beer Changpinyo",
        "Keyvan Amiri",
        "Min Ma",
        "Dayeong Lee",
        "Lihao Liang",
        "Anirudh Baddepudi",
        "Tejasi Latkar",
        "Raia Hadsell",
        "Jun Xu",
        "Hairong Mu",
        "Michael Han",
        "Aedan Pope",
        "Snchit Grover",
        "Frank Kim",
        "Ankit Bhagatwala",
        "Guan Sun",
        "Yamini Bansal",
        "Amir Globerson",
        "Alireza Nazari",
        "Samira Daruki",
        "Hagen Soltau",
        "Jane Labanowski",
        "Laurent El Shafey",
        "Matt Harvey",
        "Yanif Ahmad",
        "Elan Rosenfeld",
        "William Kong",
        "Etienne Pot",
        "Yi-Xuan Tan",
        "Aurora Wei",
        "Victoria Langston",
        "Marcel Prasetya",
        "Petar Veli\\v{c}kovi\\'c",
        "Richard Killam",
        "Robin Strudel",
        "Darren Ni",
        "Zhenhai Zhu",
        "Aaron Archer",
        "Kavya Kopparapu",
        "Lynn Nguyen",
        "Emilio Parisotto",
        "Hussain Masoom",
        "Sravanti Addepalli",
        "Jordan Grimstad",
        "Hexiang Hu",
        "Joss Moore",
        "Avinatan Hassidim",
        "Le Hou",
        "Mukund Raghavachari",
        "Jared Lichtarge",
        "Adam R. Brown",
        "Hilal Dib",
        "Natalia Ponomareva",
        "Justin Fu",
        "Yujing Zhang",
        "Altaf Rahman",
        "Joana Iljazi",
        "Edouard Leurent",
        "Gabriel Dulac-Arnold",
        "Cosmo Du",
        "Chulayuth Asawaroengchai",
        "Larry Jin",
        "Ela Gruzewska",
        "Ziwei Ji",
        "Benigno Uria",
        "Daniel De Freitas",
        "Paul Barham",
        "Lauren Beltrone",
        "V\\'ictor Campos",
        "Jun Yan",
        "Neel Kovelamudi",
        "Arthur Nguyen",
        "Elinor Davies",
        "Zhichun Wu",
        "Zoltan Egyed",
        "Kristina Toutanova",
        "Nithya Attaluri",
        "Hongliang Fei",
        "Peter Stys",
        "Siddhartha Brahma",
        "Martin Izzard",
        "Siva Velusamy",
        "Scott Lundberg",
        "Vincent Zhuang",
        "Kevin Sequeira",
        "Adam Santoro",
        "Ehsan Amid",
        "Ophir Aharoni",
        "Shuai Ye",
        "Mukund Sundararajan",
        "Lijun Yu",
        "Yu-Cheng Ling",
        "Stephen Spencer",
        "Hugo Song",
        "Josip Djolonga",
        "Christo Kirov",
        "Sonal Gupta",
        "Alessandro Bissacco",
        "Clemens Meyer",
        "Mukul Bhutani",
        "Andrew Dai",
        "Weiyi Wang",
        "Siqi Liu",
        "Ashwin Sreevatsa",
        "Qijun Tan",
        "Maria Wang",
        "Lucy Kim",
        "Yicheng Wang",
        "Alex Irpan",
        "Yang Xiao",
        "Stanislav Fort",
        "Yifan He",
        "Alex Gurney",
        "Bryan Gale",
        "Yue Ma",
        "Monica Roy",
        "Viorica Patraucean",
        "Taylan Bilal",
        "Golnaz Ghiasi",
        "Anahita Hosseini",
        "Melvin Johnson",
        "Zhuowan Li",
        "Yi Tay",
        "Benjamin Beyret",
        "Katie Millican",
        "Josef Broder",
        "Mayank Lunayach",
        "Danny Swisher",
        "Eugen Vu\\v{s}ak",
        "David Parkinson",
        "MH Tessler",
        "Adi Mayrav Gilady",
        "Richard Song",
        "Allan Dafoe",
        "Yves Raimond",
        "Masa Yamaguchi",
        "Itay Karo",
        "Elizabeth Nielsen",
        "Kevin Kilgour",
        "Mike Dusenberry",
        "Rajiv Mathews",
        "Jiho Choi",
        "Siyuan Qiao",
        "Harsh Mehta",
        "Sahitya Potluri",
        "Chris Knutsen",
        "Jialu Liu",
        "Tat Tan",
        "Kuntal Sengupta",
        "Keerthana Gopalakrishnan",
        "Abodunrinwa Toki",
        "Mencher Chiang",
        "Mike Burrows",
        "Grace Vesom",
        "Zafarali Ahmed",
        "Ilia Labzovsky",
        "Siddharth Vashishtha",
        "Preeti Singh",
        "Ankur Sharma",
        "Ada Ma",
        "Jinyu Xie",
        "Pranav Talluri",
        "Hannah Forbes-Pollard",
        "Aarush Selvan",
        "Joel Wee",
        "Loic Matthey",
        "Tom Funkhouser",
        "Parthasarathy Gopavarapu",
        "Lev Proleev",
        "Cheng Li",
        "Matt Thomas",
        "Kashyap Kolipaka",
        "Zhipeng Jia",
        "Ashwin Kakarla",
        "Srinivas Sunkara",
        "Joan Puigcerver",
        "Suraj Satishkumar Sheth",
        "Emily Graves",
        "Chen Wang",
        "Sadh MNM Khan",
        "Kai Kang",
        "Shyamal Buch",
        "Fred Zhang",
        "Omkar Savant",
        "David Soergel",
        "Kevin Lee",
        "Linda Friso",
        "Xuanyi Dong",
        "Rahul Arya",
        "Shreyas Chandrakaladharan",
        "Connor Schenck",
        "Greg Billock",
        "Tejas Iyer",
        "Anton Bakalov",
        "Leslie Baker",
        "Alex Ruiz",
        "Angad Chandorkar",
        "Trieu Trinh",
        "Matt Miecnikowski",
        "Yanqi Zhou",
        "Yangsibo Huang",
        "Jiazhong Nie",
        "Ali Shah",
        "Ashish Thapliyal",
        "Sam Haves",
        "Lun Wang",
        "Uri Shaham",
        "Patrick Morris-Suzuki",
        "Soroush Radpour",
        "Leonard Berrada",
        "Thomas Strohmann",
        "Chaochao Yan",
        "Jingwei Shen",
        "Sonam Goenka",
        "Tris Warkentin",
        "Petar Devi\\'c",
        "Dan Belov",
        "Albert Webson",
        "Madhavi Yenugula",
        "Puranjay Datta",
        "Jerry Chang",
        "Nimesh Ghelani",
        "Aviral Kumar",
        "Vincent Perot",
        "Jessica Lo",
        "Yang Song",
        "Herman Schmit",
        "Jianmin Chen",
        "Vasilisa Bashlovkina",
        "Xiaoyue Pan",
        "Diana Mincu",
        "Paul Roit",
        "Isabel Edkins",
        "Andy Davis",
        "Yujia Li",
        "Ben Horn",
        "Xinjian Li",
        "Pradeep Kumar S",
        "Eric Doi",
        "Wanzheng Zhu",
        "Sri Gayatri Sundara Padmanabhan",
        "Siddharth Verma",
        "Jasmine Liu",
        "Heng Chen",
        "Mihajlo Velimirovi\\'c",
        "Malcolm Reynolds",
        "Priyanka Agrawal",
        "Nick Sukhanov",
        "Abhinit Modi",
        "Siddharth Goyal",
        "John Palowitch",
        "Nima Khajehnouri",
        "Wing Lowe",
        "David Klinghoffer",
        "Sharon Silver",
        "Vinh Tran",
        "Candice Schumann",
        "Francesco Piccinno",
        "Xi Liu",
        "Mario Lu\\v{c}i\\'c",
        "Xiaochen Yang",
        "Sandeep Kumar",
        "Ajay Kannan",
        "Ragha Kotikalapudi",
        "Mudit Bansal",
        "Fabian Fuchs",
        "Javad Hosseini",
        "Abdelrahman Abdelhamed",
        "Dawn Bloxwich",
        "Tianhe Yu",
        "Ruoxin Sang",
        "Gregory Thornton",
        "Karan Gill",
        "Yuchi Liu",
        "Virat Shejwalkar",
        "Jason Lin",
        "Zhipeng Yan",
        "Kehang Han",
        "Thomas Buschmann",
        "Michael Pliskin",
        "Zhi Xing",
        "Susheel Tatineni",
        "Junlin Zhang",
        "Sissie Hsiao",
        "Gavin Buttimore",
        "Marcus Wu",
        "Zefei Li",
        "Geza Kovacs",
        "Legg Yeung",
        "Tao Huang",
        "Aaron Cohen",
        "Bethanie Brownfield",
        "Averi Nowak",
        "Mikel Rodriguez",
        "Tianze Shi",
        "Hado van Hasselt",
        "Kevin Cen",
        "Deepanway Ghoshal",
        "Kushal Majmundar",
        "Weiren Yu",
        "Warren (Weilun) Chen",
        "Danila Sinopalnikov",
        "Hao Zhang",
        "Vlado Gali\\'c",
        "Di Lu",
        "Zeyu Zheng",
        "Maggie Song",
        "Gary Wang",
        "Gui Citovsky",
        "Swapnil Gawde",
        "Isaac Galatzer-Levy",
        "David Silver",
        "Ivana Balazevic",
        "Dipanjan Das",
        "Kingshuk Majumder",
        "Yale Cong",
        "Praneet Dutta",
        "Dustin Tran",
        "Hui Wan",
        "Junwei Yuan",
        "Daniel Eppens",
        "Alanna Walton",
        "Been Kim",
        "Harry Ragan",
        "James Cobon-Kerr",
        "Lu Liu",
        "Weijun Wang",
        "Bryce Petrini",
        "Jack Rae",
        "Rakesh Shivanna",
        "Yan Xiong",
        "Chace Lee",
        "Pauline Coquinot",
        "Yiming Gu",
        "Lisa Patel",
        "Blake Hechtman",
        "Aviel Boag",
        "Orion Jankowski",
        "Alex Wertheim",
        "Alex Lee",
        "Paul Covington",
        "Hila Noga",
        "Sam Sobell",
        "Shanthal Vasanth",
        "William Bono",
        "Chirag Nagpal",
        "Wei Fan",
        "Xavier Garcia",
        "Kedar Soparkar",
        "Aybuke Turker",
        "Nathan Howard",
        "Sachit Menon",
        "Yuankai Chen",
        "Vikas Verma",
        "Vladimir Pchelin",
        "Harish Rajamani",
        "Valentin Dalibard",
        "Ana Ramalho",
        "Yang Guo",
        "Kartikeya Badola",
        "Seojin Bang",
        "Nathalie Rauschmayr",
        "Julia Proskurnia",
        "Sudeep Dasari",
        "Xinyun Chen",
        "Mikhail Sushkov",
        "Anja Hauth",
        "Pauline Sho",
        "Abhinav Singh",
        "Bilva Chandra",
        "Allie Culp",
        "Max Dylla",
        "Olivier Bachem",
        "James Besley",
        "Heri Zhao",
        "Timothy Lillicrap",
        "Wei Wei",
        "Wael Al Jishi",
        "Ning Niu",
        "Alban Rrustemi",
        "Rapha\\\"el Lopez Kaufman",
        "Ryan Poplin",
        "Jewel Zhao",
        "Minh Truong",
        "Shikhar Bharadwaj",
        "Ester Hlavnova",
        "Eli Stickgold",
        "Cordelia Schmid",
        "Georgi Stephanov",
        "Zhaoqi Leng",
        "Frederick Liu",
        "L\\'eonard Hussenot",
        "Shenil Dodhia",
        "Juliana Vicente Franco",
        "Lesley Katzen",
        "Abhanshu Sharma",
        "Sarah Cogan",
        "Zuguang Yang",
        "Aniket Ray",
        "Sergi Caelles",
        "Shen Yan",
        "Ravin Kumar",
        "Daniel Gillick",
        "Renee Wong",
        "Joshua Ainslie",
        "Jonathan Hoech",
        "S\\'eb Arnold",
        "Dan Abolafia",
        "Anca Dragan",
        "Ben Hora",
        "Grace Hu",
        "Alexey Guseynov",
        "Yang Lu",
        "Chas Leichner",
        "Jinmeng Rao",
        "Abhimanyu Goyal",
        "Nagabhushan Baddi",
        "Daniel Hernandez Diaz",
        "Tim McConnell",
        "Max Bain",
        "Jake Abernethy",
        "Qiqi Yan",
        "Rylan Schaeffer",
        "Paul Vicol",
        "Will Thompson",
        "Montse Gonzalez Arenas",
        "Mathias Bellaiche",
        "Pablo Barrio",
        "Stefan Zinke",
        "Riccardo Patana",
        "Pulkit Mehta",
        "JK Kearns",
        "Avraham Ruderman",
        "Scott Pollom",
        "David D'Ambrosio",
        "Cath Hope",
        "Yang Yu",
        "Andrea Gesmundo",
        "Kuang-Huei Lee",
        "Aviv Rosenberg",
        "Yiqian Zhou",
        "Yaoyiran Li",
        "Drew Garmon",
        "Yonghui Wu",
        "Safeen Huda",
        "Gil Fidel",
        "Martin Baeuml",
        "Jian Li",
        "Phoebe Kirk",
        "Rhys May",
        "Tao Tu",
        "Sara Mc Carthy",
        "Toshiyuki Fukuzawa",
        "Miranda Aperghis",
        "Chih-Kuan Yeh",
        "Toshihiro Yoshino",
        "Bo Li",
        "Austin Myers",
        "Kaisheng Yao",
        "Ben Limonchik",
        "Changwan Ryu",
        "Rohun Saxena",
        "Alex Goldin",
        "Ruizhe Zhao",
        "Rocky Rhodes",
        "Tao Zhu",
        "Divya Tyam",
        "Heidi Howard",
        "Nathan Byrd",
        "Hongxu Ma",
        "Yan Wu",
        "Ryan Mullins",
        "Qingze Wang",
        "Aida Amini",
        "Sebastien Baur",
        "Yiran Mao",
        "Subhashini Venugopalan",
        "Will Song",
        "Wen Ding",
        "Paul Collins",
        "Sashank Reddi",
        "Megan Shum",
        "Andrei Rusu",
        "Luisa Zintgraf",
        "Kelvin Chan",
        "Sheela Goenka",
        "Mathieu Blondel",
        "Michael Collins",
        "Renke Pan",
        "Marissa Giustina",
        "Nikolai Chinaev",
        "Christian Schuler",
        "Ce Zheng",
        "Jonas Valfridsson",
        "Alyssa Loo",
        "Alex Yakubovich",
        "Jamie Smith",
        "Tao Jiang",
        "Rich Munoz",
        "Gabriel Barcik",
        "Rishabh Bansal",
        "Mingyao Yang",
        "Yilun Du",
        "Pablo Duque",
        "Mary Phuong",
        "Alexandra Belias",
        "Kunal Lad",
        "Zeyu Liu",
        "Tal Schuster",
        "Karthik Duddu",
        "Jieru Hu",
        "Paige Kunkle",
        "Matthew Watson",
        "Jackson Tolins",
        "Josh Smith",
        "Denis Teplyashin",
        "Garrett Bingham",
        "Marvin Ritter",
        "Marco Andreetto",
        "Divya Pitta",
        "Mohak Patel",
        "Shashank Viswanadha",
        "Trevor Strohman",
        "Catalin Ionescu",
        "Jincheng Luo",
        "Yogesh Kalley",
        "Jeremy Wiesner",
        "Dan Deutsch",
        "Derek Lockhart",
        "Peter Choy",
        "Rumen Dangovski",
        "Chawin Sitawarin",
        "Cat Graves",
        "Tanya Lando",
        "Joost van Amersfoort",
        "Ndidi Elue",
        "Zhouyuan Huo",
        "Pooya Moradi",
        "Jean Tarbouriech",
        "Henryk Michalewski",
        "Wenting Ye",
        "Eunyoung Kim",
        "Alex Druinsky",
        "Florent Altch\\'e",
        "Xinyi Chen",
        "Artur Dwornik",
        "Da-Cheng Juan",
        "Rivka Moroshko",
        "Horia Toma",
        "Jarrod Kahn",
        "Hai Qian",
        "Maximilian Sieb",
        "Irene Cai",
        "Roman Goldenberg",
        "Praneeth Netrapalli",
        "Sindhu Raghuram",
        "Yuan Gong",
        "Lijie Fan",
        "Evan Palmer",
        "Yossi Matias",
        "Valentin Gabeur",
        "Shreya Pathak",
        "Tom Ouyang",
        "Don Metzler",
        "Geoff Bacon",
        "Srinivasan Venkatachary",
        "Sridhar Thiagarajan",
        "Alex Cullum",
        "Eran Ofek",
        "Vytenis Sakenas",
        "Mohamed Hammad",
        "Cesar Magalhaes",
        "Mayank Daswani",
        "Oscar Chang",
        "Ashok Popat",
        "Ruichao Li",
        "Komal Jalan",
        "Yanhan Hou",
        "Josh Lipschultz",
        "Antoine He",
        "Wenhao Jia",
        "Pier Giuseppe Sessa",
        "Prateek Kolhar",
        "William Wong",
        "Sumeet Singh",
        "Lukas Haas",
        "Jay Whang",
        "Hanna Klimczak-Pluci\\'nska",
        "Georges Rotival",
        "Grace Chung",
        "Yiqing Hua",
        "Anfal Siddiqui",
        "Nicolas Serrano",
        "Dongkai Chen",
        "Billy Porter",
        "Libin Bai",
        "Keshav Shivam",
        "Sho Arora",
        "Partha Talukdar",
        "Tom Cobley",
        "Sangnie Bhardwaj",
        "Evgeny Gladchenko",
        "Simon Green",
        "Kelvin Guu",
        "Felix Fischer",
        "Xiao Wu",
        "Eric Wang",
        "Achintya Singhal",
        "Tatiana Matejovicova",
        "James Martens",
        "Hongji Li",
        "Roma Patel",
        "Elizabeth Kemp",
        "Jiaqi Pan",
        "Lily Wang",
        "Blake JianHang Chen",
        "Jean-Baptiste Alayrac",
        "Navneet Potti",
        "Erika Gemzer",
        "Eugene Ie",
        "Kay McKinney",
        "Takaaki Saeki",
        "Edward Chou",
        "Pascal Lamblin",
        "SQ Mah",
        "Zach Fisher",
        "Martin Chadwick",
        "Jon Stritar",
        "Obaid Sarvana",
        "Andrew Hogue",
        "Artem Shtefan",
        "Hadi Hashemi",
        "Yang Xu",
        "Jindong Gu",
        "Sharad Vikram",
        "Chung-Ching Chang",
        "Sabela Ramos",
        "Logan Kilpatrick",
        "Weijuan Xi",
        "Jenny Brennan",
        "Yinghao Sun",
        "Abhishek Jindal",
        "Ionel Gog",
        "Dawn Chen",
        "Felix Wu",
        "Jason Lee",
        "Sudhindra Kopalle",
        "Srinadh Bhojanapalli",
        "Oriol Vinyals",
        "Natan Potikha",
        "Burcu Karagol Ayan",
        "Yuan Yuan",
        "Michael Riley",
        "Piotr Stanczyk",
        "Sergey Kishchenko",
        "Bing Wang",
        "Dan Garrette",
        "Antoine Yang",
        "Vlad Feinberg",
        "CJ Carey",
        "Javad Azizi",
        "Viral Shah",
        "Erica Moreira",
        "Chongyang Shi",
        "Josh Feldman",
        "Elizabeth Salesky",
        "Thomas Lampe",
        "Aneesh Pappu",
        "Duhyeon Kim",
        "Jonas Adler",
        "Avi Caciularu",
        "Brian Walker",
        "Yunhan Xu",
        "Yochai Blau",
        "Dylan Scandinaro",
        "Terry Huang",
        "Sam El-Husseini",
        "Abhishek Sinha",
        "Lijie Ren",
        "Taylor Tobin",
        "Patrik Sundberg",
        "Tim Sohn",
        "Vikas Yadav",
        "Mimi Ly",
        "Emily Xue",
        "Jing Xiong",
        "Afzal Shama Soudagar",
        "Sneha Mondal",
        "Nikhil Khadke",
        "Qingchun Ren",
        "Ben Vargas",
        "Stan Bileschi",
        "Sarah Chakera",
        "Cindy Wang",
        "Boyu Wang",
        "Yoni Halpern",
        "Joe Jiang",
        "Vikas Sindhwani",
        "Petre Petrov",
        "Pranavaraj Ponnuramu",
        "Sanket Vaibhav Mehta",
        "Yu Watanabe",
        "Betty Chan",
        "Matheus Wisniewski",
        "Trang Pham",
        "Jingwei Zhang",
        "Conglong Li",
        "Dario de Cesare",
        "Art Khurshudov",
        "Alex Vasiloff",
        "Melissa Tan",
        "Zoe Ashwood",
        "Bobak Shahriari",
        "Maryam Majzoubi",
        "Garrett Tanzer",
        "Olga Kozlova",
        "Robin Alazard",
        "James Lee-Thorp",
        "Nguyet Minh Phu",
        "Isaac Tian",
        "Junwhan Ahn",
        "Andy Crawford",
        "Lauren Lax",
        "Yuan (June) Shangguan",
        "Iftekhar Naim",
        "David Ross",
        "Oleksandr Ferludin",
        "Tongfei Guo",
        "Andrea Banino",
        "Hubert Soyer",
        "Xiaoen Ju",
        "Dominika Rogozi\\'nska",
        "Ishaan Malhi",
        "Marcella Valentine",
        "Daniel Balle",
        "Apoorv Kulshreshtha",
        "Maciej Kula",
        "Yiwen Song",
        "Sophia Austin",
        "John Schultz",
        "Roy Hirsch",
        "Arthur Douillard",
        "Apoorv Reddy",
        "Michael Fink",
        "Summer Yue",
        "Khyatti Gupta",
        "Adam Zhang",
        "Norman Rink",
        "Daniel McDuff",
        "Lei Meng",
        "Andr\\'as Gy\\\"orgy",
        "Yasaman Razeghi",
        "Ricky Liang",
        "Kazuki Osawa",
        "Aviel Atias",
        "Matan Eyal",
        "Tyrone Hill",
        "Nikolai Grigorev",
        "Zhengdong Wang",
        "Nitish Kulkarni",
        "Rachel Soh",
        "Ivan Lobov",
        "Zachary Charles",
        "Sid Lall",
        "Kazuma Hashimoto",
        "Ido Kessler",
        "Victor Gomes",
        "Zelda Mariet",
        "Danny Driess",
        "Alessandro Agostini",
        "Canfer Akbulut",
        "Jingcao Hu",
        "Marissa Ikonomidis",
        "Emily Caveness",
        "Kartik Audhkhasi",
        "Saurabh Agrawal",
        "Ioana Bica",
        "Evan Senter",
        "Jayaram Mudigonda",
        "Kelly Chen",
        "Jingchen Ye",
        "Xuanhui Wang",
        "James Svensson",
        "Philipp Fr\\\"anken",
        "Josh Newlan",
        "Li Lao",
        "Eva Schnider",
        "Sami Alabed",
        "Joseph Kready",
        "Jesse Emond",
        "Afief Halumi",
        "Tim Zaman",
        "Chengxi Ye",
        "Naina Raisinghani",
        "Vilobh Meshram",
        "Bo Chang",
        "Ankit Singh Rawat",
        "Axel Stjerngren",
        "Sergey Levi",
        "Rui Wang",
        "Xiangzhu Long",
        "Mitchelle Rasquinha",
        "Steven Hand",
        "Aditi Mavalankar",
        "Lauren Agubuzu",
        "Sudeshna Roy",
        "Junquan Chen",
        "Jarek Wilkiewicz",
        "Hao Zhou",
        "Michal Jastrzebski",
        "Qiong Hu",
        "Agustin Dal Lago",
        "Ramya Sree Boppana",
        "Wei-Jen Ko",
        "Jennifer Prendki",
        "Yao Su",
        "Zhi Li",
        "Eliza Rutherford",
        "Girish Ramchandra Rao",
        "Ramona Comanescu",
        "Adri\\`a Puigdom\\`enech",
        "Qihang Chen",
        "Dessie Petrova",
        "Christine Chan",
        "Vedrana Milutinovic",
        "Felipe Tiengo Ferreira",
        "Chin-Yi Cheng",
        "Ming Zhang",
        "Tapomay Dey",
        "Sherry Yang",
        "Ramesh Sampath",
        "Quoc Le",
        "Howard Zhou",
        "Chu-Cheng Lin",
        "Hoi Lam",
        "Christine Kaeser-Chen",
        "Kai Hui",
        "Dean Hirsch",
        "Tom Eccles",
        "Basil Mustafa",
        "Shruti Rijhwani",
        "Morgane Rivi\\`ere",
        "Yuanzhong Xu",
        "Junjie Wang",
        "Xinyang Geng",
        "Xiance Si",
        "Arjun Khare",
        "Cheolmin Kim",
        "Vahab Mirrokni",
        "Kamyu Lee",
        "Khuslen Baatarsukh",
        "Nathaniel Braun",
        "Lisa Wang",
        "Pallavi LV",
        "Richard Tanburn",
        "Yuvein (Yonghao) Zhu",
        "Fangda Li",
        "Setareh Ariafar",
        "Dan Goldberg",
        "Ken Burke",
        "Daniil Mirylenka",
        "Meiqi Guo",
        "Olaf Ronneberger",
        "Hadas Natalie Vogel",
        "Liqun Cheng",
        "Nishita Shetty",
        "Johnson Jia",
        "Thomas Jimma",
        "Corey Fry",
        "Ted Xiao",
        "Martin Sundermeyer",
        "Ryan Burnell",
        "Yannis Assael",
        "Mario Pinto",
        "JD Chen",
        "Rohit Sathyanarayana",
        "Donghyun Cho",
        "Jing Lu",
        "Rishabh Agarwal",
        "Sugato Basu",
        "Lucas Gonzalez",
        "Dhruv Shah",
        "Meng Wei",
        "Dre Mahaarachchi",
        "Rohan Agrawal",
        "Tero Rissa",
        "Yani Donchev",
        "Ramiro Leal-Cavazos",
        "Adrian Hutter",
        "Markus Mircea",
        "Alon Jacovi",
        "Faruk Ahmed",
        "Jiageng Zhang",
        "Shuguang Hu",
        "Bo-Juen Chen",
        "Jonni Kanerva",
        "Guillaume Desjardins",
        "Andrew Lee",
        "Nikos Parotsidis",
        "Asier Mujika",
        "Tobias Weyand",
        "Jasper Snoek",
        "Jo Chick",
        "Kai Chen",
        "Paul Chang",
        "Ethan Mahintorabi",
        "Zi Wang",
        "Tolly Powell",
        "Orgad Keller",
        "Abhirut Gupta",
        "Claire Sha",
        "Kanav Garg",
        "Nicolas Heess",
        "\\'Agoston Weisz",
        "Cassidy Hardin",
        "Bartek Wydrowski",
        "Ben Coleman",
        "Karina Zainullina",
        "Pankaj Joshi",
        "Alessandro Epasto",
        "Terry Spitz",
        "Binbin Xiong",
        "Kai Zhao",
        "Arseniy Klimovskiy",
        "Ivy Zheng",
        "Johan Ferret",
        "Itay Yona",
        "Waleed Khawaja",
        "Jean-Baptiste Lespiau",
        "Maxim Krikun",
        "Siamak Shakeri",
        "Timothee Cour",
        "Bonnie Li",
        "Igor Krivokon",
        "Dan Suh",
        "Alex Hofer",
        "Jad Al Abdallah",
        "Nikita Putikhin",
        "Oscar Akerlund",
        "Silvio Lattanzi",
        "Anurag Kumar",
        "Shane Settle",
        "Himanshu Srivastava",
        "Folawiyo Campbell-Ajala",
        "Edouard Rosseel",
        "Mihai Dorin Istin",
        "Nishanth Dikkala",
        "Anand Rao",
        "Nick Young",
        "Kate Lin",
        "Dhruva Bhaswar",
        "Yiming Wang",
        "Jaume Sanchez Elias",
        "Kritika Muralidharan",
        "James Keeling",
        "Dayou Du",
        "Siddharth Gopal",
        "Gregory Dibb",
        "Charles Blundell",
        "Manolis Delakis",
        "Jacky Liang",
        "Marco Tulio Ribeiro",
        "Georgi Karadzhov",
        "Guillermo Garrido",
        "Ankur Bapna",
        "Jiawei Cao",
        "Adam Sadovsky",
        "Pouya Tafti",
        "Arthur Guez",
        "Coline Devin",
        "Yixian Di",
        "Jinwei Xing",
        "Chuqiao (Joyce) Xu",
        "Hanzhao Lin",
        "Chun-Te Chu",
        "Sameera Ponda",
        "Wesley Helmholz",
        "Fan Yang",
        "Yue Gao",
        "Sara Javanmardi",
        "Wael Farhan",
        "Alex Ramirez",
        "Ricardo Figueira",
        "Khe Chai Sim",
        "Yuval Bahat",
        "Ashwin Vaswani",
        "Liangzhe Yuan",
        "Gufeng Zhang",
        "Leland Rechis",
        "Hanjun Dai",
        "Tayo Oguntebi",
        "Alexandra Cordell",
        "Eug\\'enie Rives",
        "Kaan Tekelioglu",
        "Naveen Kumar",
        "Bing Zhang",
        "Aurick Zhou",
        "Nikolay Savinov",
        "Andrew Leach",
        "Alex Tudor",
        "Sanjay Ganapathy",
        "Yanyan Zheng",
        "Mirko Rossini",
        "Vera Axelrod",
        "Arnaud Autef",
        "Yukun Zhu",
        "Zheng Zheng",
        "Mingda Zhang",
        "Baochen Sun",
        "Jie Ren",
        "Nenad Tomasev",
        "Nithish Kannan",
        "Amer Sinha",
        "Charles Chen",
        "Louis O'Bryan",
        "Alex Pak",
        "Aditya Kusupati",
        "Weel Yang",
        "Deepak Ramachandran",
        "Patrick Griffin",
        "Seokhwan Kim",
        "Philipp Neubeck",
        "Craig Schiff",
        "Tammo Spalink",
        "Mingyang Ling",
        "Arun Nair",
        "Ga-Young Joung",
        "Linda Deng",
        "Avishkar Bhoopchand",
        "Lora Aroyo",
        "Tom Duerig",
        "Jordan Griffith",
        "Gabe Barth-Maron",
        "Jake Ades",
        "Alex Haig",
        "Ankur Taly",
        "Yunting Song",
        "Paul Michel",
        "Dave Orr",
        "Dean Weesner",
        "Corentin Tallec",
        "Carrie Grimes Bostock",
        "Paul Niemczyk",
        "Andy Twigg",
        "Mudit Verma",
        "Rohith Vallu",
        "Henry Wang",
        "Marco Gelmi",
        "Kiranbir Sodhia",
        "Aleksandr Chuklin",
        "Omer Goldman",
        "Jasmine George",
        "Liang Bai",
        "Kelvin Zhang",
        "Petar Sirkovic",
        "Efrat Nehoran",
        "Golan Pundak",
        "Jiaqi Mu",
        "Alice Chen",
        "Alex Greve",
        "Paulo Zacchello",
        "David Amos",
        "Heming Ge",
        "Eric Noland",
        "Colton Bishop",
        "Jeffrey Dudek",
        "Youhei Namiki",
        "Elena Buchatskaya",
        "Jing Li",
        "Dorsa Sadigh",
        "Masha Samsikova",
        "Dan Malkin",
        "Damien Vincent",
        "Robert David",
        "Rob Willoughby",
        "Phoenix Meadowlark",
        "Shawn Gao",
        "Yan Li",
        "Raj Apte",
        "Amit Jhindal",
        "Stein Xudong Lin",
        "Alex Polozov",
        "Zhicheng Wang",
        "Tomas Mery",
        "Anirudh GP",
        "Varun Yerram",
        "Sage Stevens",
        "Tianqi Liu",
        "Noah Fiedel",
        "Charles Sutton",
        "Matthew Johnson",
        "Xiaodan Song",
        "Kate Baumli",
        "Nir Shabat",
        "Muqthar Mohammad",
        "Hao Liu",
        "Marco Selvi",
        "Yichao Zhou",
        "Mehdi Hafezi Manshadi",
        "Chu-ling Ko",
        "Anthony Chen",
        "Michael Bendersky",
        "Jorge Gonzalez Mendez",
        "Nisarg Kothari",
        "Amir Zandieh",
        "Yiling Huang",
        "Daniel Andor",
        "Ellie Pavlick",
        "Idan Brusilovsky",
        "Jitendra Harlalka",
        "Sally Goldman",
        "Andrew Lampinen",
        "Guowang Li",
        "Asahi Ushio",
        "Somit Gupta",
        "Lei Zhang",
        "Chuyuan Kelly Fu",
        "Madhavi Sewak",
        "Timo Denk",
        "Jed Borovik",
        "Brendan Jou",
        "Avital Zipori",
        "Prateek Jain",
        "Junwen Bai",
        "Thang Luong",
        "Jonathan Tompson",
        "Alice Li",
        "Li Liu",
        "George Powell",
        "Jiajun Shen",
        "Alex Feng",
        "Grishma Chole",
        "Da Yu",
        "Yinlam Chow",
        "Tongxin Yin",
        "Eric Malmi",
        "Kefan Xiao",
        "Yash Pande",
        "Shachi Paul",
        "Niccol\\`o Dal Santo",
        "Adil Dostmohamed",
        "Sergio Guadarrama",
        "Aaron Phillips",
        "Thanumalayan Sankaranarayana Pillai",
        "Gal Yona",
        "Amin Ghafouri",
        "Preethi Lahoti",
        "Benjamin Lee",
        "Dhruv Madeka",
        "Eren Sezener",
        "Simon Tokumine",
        "Adrian Collister",
        "Nicola De Cao",
        "Richard Shin",
        "Uday Kalra",
        "Parker Beak",
        "Emily Nottage",
        "Ryo Nakashima",
        "Ivan Jurin",
        "Vikash Sehwag",
        "Meenu Gaba",
        "Junhao Zeng",
        "Kevin R. McKee",
        "Fernando Pereira",
        "Tamar Yakar",
        "Amayika Panda",
        "Arka Dhar",
        "Peilin Zhong",
        "Daniel Sohn",
        "Mark Brand",
        "Lars Lowe Sjoesund",
        "Viral Carpenter",
        "Sharon Lin",
        "Shantanu Thakoor",
        "Marcus Wainwright",
        "Ashwin Chaugule",
        "Pranesh Srinivasan",
        "Muye Zhu",
        "Bernett Orlando",
        "Jack Weber",
        "Ayzaan Wahid",
        "Gilles Baechler",
        "Apurv Suman",
        "Jovana Mitrovi\\'c",
        "Gabe Taubman",
        "Honglin Yu",
        "Helen King",
        "Josh Dillon",
        "Cathy Yip",
        "Dhriti Varma",
        "Tomas Izo",
        "Levent Bolelli",
        "Borja De Balle Pigem",
        "Julia Di Trapani",
        "Fotis Iliopoulos",
        "Adam Paszke",
        "Nishant Ranka",
        "Joe Zou",
        "Francesco Pongetti",
        "Jed McGiffin",
        "Alex Siegman",
        "Rich Galt",
        "Ross Hemsley",
        "Goran \\v{Z}u\\v{z}i\\'c",
        "Victor Carbune",
        "Tao Li",
        "Myle Ott",
        "F\\'elix de Chaumont Quitry",
        "David Vilar Torres",
        "Yuri Chervonyi",
        "Tomy Tsai",
        "Prem Eruvbetine",
        "Samuel Yang",
        "Matthew Denton",
        "Jake Walker",
        "Slavica Anda\\v{c}i\\'c",
        "Idan Heimlich Shtacher",
        "Vittal Premachandran",
        "Harshal Tushar Lehri",
        "Cip Baetu",
        "Damion Yates",
        "Lampros Lamprou",
        "Mariko Iinuma",
        "Ioana Mihailescu",
        "Ben Albrecht",
        "Shachi Dave",
        "Susie Sargsyan",
        "Bryan Perozzi",
        "Lucas Manning",
        "Chiyuan Zhang",
        "Denis Vnukov",
        "Igor Mordatch",
        "Raia Hadsell Wolfgang Macherey",
        "Ryan Kappedal",
        "Jim Stephan",
        "Aditya Tripathi",
        "Klaus Macherey",
        "Jun Qian",
        "Abhishek Bhowmick",
        "Shekoofeh Azizi",
        "R\\'emi Leblond",
        "Shiva Mohan Reddy Garlapati",
        "Timothy Knight",
        "Matthew Wiethoff",
        "Wei-Chih Hung",
        "Anelia Angelova",
        "Georgios Evangelopoulos",
        "Pawel Janus",
        "Dimitris Paparas",
        "Matthew Rahtz",
        "Ken Caluwaerts",
        "Vivek Sampathkumar",
        "Daniel Jarrett",
        "Shadi Noghabi",
        "Antoine Miech",
        "Chak Yeung",
        "Geoff Clark",
        "Henry Prior",
        "Fei Zheng",
        "Jean Pouget-Abadie",
        "Indro Bhattacharya",
        "Kalpesh Krishna",
        "Will Bishop",
        "Zhe Yuan",
        "Yunxiao Deng",
        "Ashutosh Sathe",
        "Kacper Krasowiak",
        "Ciprian Chelba",
        "Cho-Jui Hsieh",
        "Kiran Vodrahalli",
        "Buhuang Liu",
        "Thomas K\\\"oppe",
        "Amr Khalifa",
        "Lubo Litchev",
        "Pichi Charoenpanit",
        "Reed Roberts",
        "Sachin Yadav",
        "Yasumasa Onoe",
        "Desi Ivanov",
        "Megha Mohabey",
        "Vighnesh Birodkar",
        "Nemanja Raki\\'cevi\\'c",
        "Pierre Sermanet",
        "Vaibhav Mehta",
        "Krishan Subudhi",
        "Travis Choma",
        "Will Ng",
        "Luheng He",
        "Kathie Wang",
        "Tasos Kementsietsidis",
        "Shane Gu",
        "Mansi Gupta",
        "Andrew Nystrom",
        "Mehran Kazemi",
        "Timothy Chung",
        "Nacho Cano",
        "Nikhil Dhawan",
        "Yufei Wang",
        "Jiawei Xia",
        "Trevor Yacovone",
        "Eric Jia",
        "Mingqing Chen",
        "Simeon Ivanov",
        "Ashrith Sheshan",
        "Sid Dalmia",
        "Pawe{\\l} Stradomski",
        "Pengcheng Yin",
        "Salem Haykal",
        "Congchao Wang",
        "Dennis Duan",
        "Neslihan Bulut",
        "Greg Kochanski",
        "Liam MacDermed",
        "Namrata Godbole",
        "Shitao Weng",
        "Jingjing Chen",
        "Rachana Fellinger",
        "Ramin Mehran",
        "Daniel Suo",
        "Hisham Husain",
        "Tong He",
        "Kaushal Patel",
        "Joshua Howland",
        "Randall Parker",
        "Kelvin Nguyen",
        "Sharath Maddineni",
        "Chris Rawles",
        "Mina Khan",
        "Shlomi Cohen-Ganor",
        "Amol Mandhane",
        "Xinyi Wu",
        "Chenkai Kuang",
        "Iulia Com\\c{s}a",
        "Ramya Ganeshan",
        "Hanie Sedghi",
        "Adam Bloniarz",
        "Nuo Wang Pierse",
        "Anton Briukhov",
        "Petr Mitrichev",
        "Anita Gergely",
        "Serena Zhan",
        "Allan Zhou",
        "Nikita Saxena",
        "Eva Lu",
        "Josef Dean",
        "Ashish Gupta",
        "Nicolas Perez-Nieves",
        "Renjie Wu",
        "Cory McLean",
        "Wei Liang",
        "Disha Jindal",
        "Anton Tsitsulin",
        "Wenhao Yu",
        "Kaiz Alarakyia",
        "Tom Schaul",
        "Piyush Patil",
        "Peter Sung",
        "Elijah Peake",
        "Hongkun Yu",
        "Feryal Behbahani",
        "JD Co-Reyes",
        "Alan Ansell",
        "Sean Sun",
        "Clara Barbu",
        "Jonathan Lee",
        "Seb Noury",
        "James Allingham",
        "Bilal Piot",
        "Mohit Sharma",
        "Christopher Yew",
        "Ivan Korotkov",
        "Bibo Xu",
        "Demetra Brady",
        "Goran Petrovic",
        "Shibl Mourad",
        "Claire Cui",
        "Aditya Gupta",
        "Parker Schuh",
        "Saarthak Khanna",
        "Anna Goldie",
        "Abhinav Arora",
        "Vadim Zubov",
        "Amy Stuart",
        "Mark Epstein",
        "Yun Zhu",
        "Jianqiao Liu",
        "Yury Stuken",
        "Ziyue Wang",
        "Karolis Misiunas",
        "Dee Guo",
        "Ashleah Gill",
        "Ale Hartman",
        "Zaid Nabulsi",
        "Aurko Roy",
        "Aleksandra Faust",
        "Jason Riesa",
        "Ben Withbroe",
        "Mengchao Wang",
        "Marco Tagliasacchi",
        "Andreea Marzoca",
        "James Noraky",
        "Serge Toropov",
        "Malika Mehrotra",
        "Bahram Raad",
        "Sanja Deur",
        "Steve Xu",
        "Marianne Monteiro",
        "Zhongru Wu",
        "Yi Luan",
        "Sam Ritter",
        "Nick Li",
        "H{\\aa}vard Garnes",
        "Yanzhang He",
        "Martin Zlocha",
        "Jifan Zhu",
        "Matteo Hessel",
        "Will Wu",
        "Spandana Raj Babbula",
        "Chizu Kawamoto",
        "Yuanzhen Li",
        "Mehadi Hassen",
        "Yan Wang",
        "Brian Wieder",
        "James Freedman",
        "Yin Zhang",
        "Xinyi Bai",
        "Tianli Yu",
        "David Reitter",
        "XiangHai Sheng",
        "Mateo Wirth",
        "Aditya Kini",
        "Dima Damen",
        "Mingcen Gao",
        "Rachel Hornung",
        "Michael Voznesensky",
        "Brian Roark",
        "Adhi Kuncoro",
        "Yuxiang Zhou",
        "Rushin Shah",
        "Anthony Brohan",
        "Kuangyuan Chen",
        "James Wendt",
        "David Rim",
        "Paul Kishan Rubenstein",
        "Jonathan Halcrow",
        "Michelle Liu",
        "Ty Geri",
        "Yunhsuan Sung",
        "Jane Shapiro",
        "Shaan Bijwadia",
        "Chris Duvarney",
        "Christina Sorokin",
        "Paul Natsev",
        "Reeve Ingle",
        "Pramod Gupta",
        "Young Maeng",
        "Ndaba Ndebele",
        "Kexin Zhu",
        "Valentin Anklin",
        "Katherine Lee",
        "Yuan Liu",
        "Yaroslav Akulov",
        "Shaleen Gupta",
        "Guolong Su",
        "Flavien Prost",
        "Tianlin Liu",
        "Vitaly Kovalev",
        "Pol Moreno",
        "Martin Scholz",
        "Sam Redmond",
        "Zongwei Zhou",
        "Alex Castro-Ros",
        "Andr\\'e Susano Pinto",
        "Dia Kharrat",
        "Michal Yarom",
        "Rachel Saputro",
        "Jannis Bulian",
        "Ben Caine",
        "Ji Liu",
        "Abbas Abdolmaleki",
        "Shariq Iqbal",
        "Tautvydas Misiunas",
        "Mikhail Sirotenko",
        "Shefali Garg",
        "Guy Bensky",
        "Huan Gui",
        "Xuezhi Wang",
        "Raphael Koster",
        "Mike Bernico",
        "Da Huang",
        "Romal Thoppilan",
        "Trevor Cohn",
        "Ben Golan",
        "Wenlei Zhou",
        "Andrew Rosenberg",
        "Markus Freitag",
        "Tynan Gangwani",
        "Vincent Tsang",
        "Anand Shukla",
        "Xiaoqi Ren",
        "Minh Giang",
        "Chi Zou",
        "Andre Elisseeff",
        "Charline Le Lan",
        "Dheeru Dua",
        "Shuba Lall",
        "Pranav Shyam",
        "Frankie Garcia",
        "Sarah Nguyen",
        "Michael Guzman",
        "AJ Maschinot",
        "Marcello Maggioni",
        "Ming-Wei Chang",
        "Karol Gregor",
        "Lotte Weerts",
        "Kumaran Venkatesan",
        "Bogdan Damoc",
        "Leon Liu",
        "Jan Wassenberg",
        "Lewis Ho",
        "Becca Roelofs",
        "Majid Hadian",
        "Fran\\c{c}ois-Xavier Aubet",
        "Yu Liang",
        "Sami Lachgar",
        "Danny Karmon",
        "Yong Cheng",
        "Amelio V\\'azquez-Reina",
        "Angie Chen",
        "Zhuyun Dai",
        "Andy Brock",
        "Shubham Agrawal",
        "Chenxi Pang",
        "Peter Garst",
        "Mariella Sanchez-Vargas",
        "Ivor Rendulic",
        "Aditya Ayyar",
        "Andrija Ra\\v{z}natovi\\'c",
        "Olivia Ma",
        "Roopali Vij",
        "Neha Sharma",
        "Ashwin Balakrishna",
        "Bingyuan Liu",
        "Ian Mackinnon",
        "Sorin Baltateanu",
        "Petra Poklukar",
        "Gabriel Ibagon",
        "Colin Ji",
        "Hongyang Jiao",
        "Isaac Noble",
        "Wojciech Stokowiec",
        "Zhihao Li",
        "Jeff Dean",
        "David Lindner",
        "Mark Omernick",
        "Kristen Chiafullo",
        "Mason Dimarco",
        "Vitor Rodrigues",
        "Vittorio Selo",
        "Garrett Honke",
        "Xintian (Cindy) Wu",
        "Wei He",
        "Adam Hillier",
        "Anhad Mohananey",
        "Vihari Piratla",
        "Chang Ye",
        "Chase Malik",
        "Sebastian Riedel",
        "Samuel Albanie",
        "Zi Yang",
        "Kenny Vassigh",
        "Maria Bauza",
        "Sheng Li",
        "Yiqing Tao",
        "Nevan Wichers",
        "Andrii Maksai",
        "Abe Ittycheriah",
        "Ross Mcilroy",
        "Bryan Seybold",
        "Noah Goodman",
        "Romina Datta",
        "Steven M. Hernandez",
        "Tian Shi",
        "Yony Kochinski",
        "Anna Bulanova",
        "Ken Franko",
        "Mikita Sazanovich",
        "Nicholas FitzGerald",
        "Praneeth Kacham",
        "Shubha Srinivas Raghvendra",
        "Vincent Hellendoorn",
        "Alexander Grushetsky",
        "Julian Salazar",
        "Angeliki Lazaridou",
        "Jason Chang",
        "Jan-Thorsten Peter",
        "Sushant Kafle",
        "Yann Dauphin",
        "Abhishek Rao",
        "Filippo Graziano",
        "Izhak Shafran",
        "Yuguo Liao",
        "Tianli Ding",
        "Geng Yan",
        "Grace Chu",
        "Zhao Fu",
        "Vincent Roulet",
        "Gabriel Rasskin",
        "Duncan Williams",
        "Shahar Drath",
        "Alex Mossin",
        "Raphael Hoffmann",
        "Jordi Orbay",
        "Francesco Bertolini",
        "Hila Sheftel",
        "Justin Chiu",
        "Siyang Xue",
        "Yuheng Kuang",
        "Ferjad Naeem",
        "Swaroop Nath",
        "Nana Nti",
        "Phil Culliton",
        "Kashyap Krishnakumar",
        "Michael Isard",
        "Pei Sun",
        "Ayan Chakrabarti",
        "Nathan Clement",
        "Regev Cohen",
        "Arissa Wongpanich",
        "GS Oh",
        "Ashwin Murthy",
        "Hao Zheng",
        "Jessica Hamrick",
        "Oskar Bunyan",
        "Suhas Ganesh",
        "Nitish Gupta",
        "Roy Frostig",
        "John Wieting",
        "Yury Malkov",
        "Pierre Marcenac",
        "Zhixin (Lucas) Lai",
        "Xiaodan Tang",
        "Mohammad Saleh",
        "Fedir Zubach",
        "Chinmay Kulkarni",
        "Huanjie Zhou",
        "Vicky Zayats",
        "Nan Ding",
        "Anshuman Tripathi",
        "Arijit Pramanik",
        "Patrik Zochbauer",
        "Harish Ganapathy",
        "Vedant Misra",
        "Zach Behrman",
        "Hugo Vallet",
        "Mingyang Zhang",
        "Mukund Sridhar",
        "Ye Jin",
        "Mohammad Babaeizadeh",
        "Siim P\\~oder",
        "Megha Goel",
        "Divya Jain",
        "Tajwar Nasir",
        "Shubham Mittal",
        "Tim Dozat",
        "Diego Ardila",
        "Aliaksei Severyn",
        "Fabio Pardo",
        "Sammy Jerome",
        "Siyang Qin",
        "Louis Rouillard",
        "Amir Yazdanbakhsh",
        "Zizhao Zhang",
        "Shivani Agrawal",
        "Kaushik Shivakumar",
        "Caden Lu",
        "Praveen Kallakuri",
        "Rachita Chhaparia",
        "Kanishka Rao",
        "Charles Kwong",
        "Asya Fadeeva",
        "Shitij Nigam",
        "Yan Virin",
        "Yuan Zhang",
        "Balaji Venkatraman",
        "Beliz Gunel",
        "Marc Wilson",
        "Huiyu Wang",
        "Abhinav Gupta",
        "Xiaowei Xu",
        "Adrien Ali Ta\\\"iga",
        "Kareem Mohamed",
        "Doug Fritz",
        "Daniel Rodriguez",
        "Zoubin Ghahramani",
        "Harry Askham",
        "Lior Belenki",
        "James Zhao",
        "Rahul Gupta",
        "Krzysztof Jastrz\\k{e}bski",
        "Takahiro Kosakai",
        "Kaan Katircioglu",
        "Jon Schneider",
        "Rina Panigrahy",
        "Konstantinos Bousmalis",
        "Peter Grabowski",
        "Prajit Ramachandran",
        "Chaitra Hegde",
        "Mihaela Rosca",
        "Angelo Scorza Scarpati",
        "Kyriakos Axiotis",
        "Ying Xu",
        "Zach Gleicher",
        "Assaf Hurwitz Michaely",
        "Mandar Sharma",
        "Sanil Jain",
        "Christoph Hirnschall",
        "Tal Marian",
        "Xuhui Jia",
        "Kevin Mather",
        "Kilol Gupta",
        "Linhai Qiu",
        "Nigamaa Nayakanti",
        "Lucian Ionita",
        "Steven Zheng",
        "Lucia Loher",
        "Kurt Shuster",
        "Igor Petrovski",
        "Roshan Sharma",
        "Rahma Chaabouni",
        "Angel Yeh",
        "James An",
        "Arushi Gupta",
        "Steven Schwarcz",
        "Seher Ellis",
        "Sam Conway-Rahman",
        "Javier Snaider",
        "Alex Zhai",
        "James Atwood",
        "Daniel Golovin",
        "Liqian Peng",
        "Te I",
        "Vivian Xia",
        "Salvatore Scellato",
        "Mahan Malihi",
        "Arthur Bra\\v{z}inskas",
        "Vlad-Doru Ion",
        "Younghoon Jun",
        "James Swirhun",
        "Soroosh Mariooryad",
        "Jiao Sun",
        "Steve Chien",
        "Rey Coaguila",
        "Ariel Brand",
        "Yi Gao",
        "Tom Kwiatkowski",
        "Roee Aharoni",
        "Cheng-Chun Lee",
        "Mislav \\v{Z}ani\\'c",
        "Yichi Zhang",
        "Dan Ethier",
        "Vitaly Nikolaev",
        "Pranav Nair",
        "Yoav Ben Shalom",
        "Hen Fitoussi",
        "Jai Gupta",
        "Hongbin Liu",
        "Dee Cattle",
        "Tolga Bolukbasi",
        "Ben Murdoch",
        "Fantine Huot",
        "Yin Li",
        "Chris Hahn"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T17:36:04+00:00",
          "link": "https://arxiv.org/abs/2507.06261v1",
          "size": "8601kb",
          "version": "v1"
        }
      ],
      "title": "Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06261",
        "HTML": "https://arxiv.org/html/2507.06261v1",
        "PDF": "https://arxiv.org/pdf/2507.06261"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces new models with capabilities in reasoning and multimodal processing, but it does not discuss any aspects of LLM training data collection, processing, or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06981",
      "abstract": "This paper presents a reinforcement learning (RL) based approach to improve the physical layer security (PLS) of an underlay cognitive radio network (CRN) over cascaded channels. These channels are utilized in highly mobile networks such as cognitive vehicular networks (CVN). In addition, an eavesdropper aims to intercept the communications between secondary users (SUs). The SU receiver has full-duplex and energy harvesting capabilities to generate jamming signals to confound the eavesdropper and enhance security. Moreover, the SU transmitter extracts energy from ambient radio frequency signals in order to power subsequent transmissions to its intended receiver. To optimize the privacy and reliability of the SUs in a CVN, a deep Q-network (DQN) strategy is utilized where multiple DQN agents are required such that an agent is assigned at each SU transmitter. The objective for the SUs is to determine the optimal transmission power and decide whether to collect energy or transmit messages during each time period in order to maximize their secrecy rate. Thereafter, we propose a DQN approach to maximize the throughput of the SUs while respecting the interference threshold acceptable at the receiver of the primary user. According to our findings, our strategy outperforms two other baseline strategies in terms of security and reliability.",
      "authors": [
        "Deemah H. Tashman",
        "Soumaya Cherkaoui",
        "and Walaa Hamouda"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Emerging Technologies (cs.ET)",
        "Networking and Internet Architecture (cs.NI)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T16:08:18+00:00",
          "link": "https://arxiv.org/abs/2507.06981v1",
          "size": "482kb",
          "version": "v1"
        }
      ],
      "title": "Optimizing Cognitive Networks: Reinforcement Learning Meets Energy Harvesting Over Cascaded Channels",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06981",
        "HTML": "https://arxiv.org/html/2507.06981v1",
        "PDF": "https://arxiv.org/pdf/2507.06981"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper emphasizes improving physical layer security using reinforcement learning in cognitive radio networks without discussing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.11703",
      "abstract": "Medical quality control indicators are essential to assess the qualifications of healthcare institutions for medical services. With the impressive performance of large language models (LLMs) like GPT-4 in the medical field, leveraging these technologies for the Medical Quality Control Indicator Calculation (MQCIC) presents a promising approach. In this work, (1) we introduce a real-world task MQCIC and propose an open-source Chinese electronic medical records (EMRs)-based dataset (CMQCIC-Bench) comprising 785 instances and 76 indicators. (2) We propose a semi-automatic method to enhance the rule representation. Then we propose the Clinical Facts-based Inferential Rule (CF-IR) method that disentangles the clinical fact verification and inferential rule reasoning actions. (3) We conduct comprehensive experiments on 20 representative LLMs, covering general and medical models. Our findings reveal that CF-IR outperforms Chain-of-Thought methods in MQCIC tasks. (4) We conduct an error analysis and investigate the capabilities of clinical fact verification and inferential rule reasoning, providing insights to improve performance in the MQCIC further. The dataset and code is available in this repository https://github.com/YuY-2001/C-MQCIC.",
      "authors": [
        "Guangya Yu",
        "Yanhao Li",
        "Zongying Jiang",
        "Yuxiong Jin",
        "Li Dai",
        "Yupian Lin",
        "Ruihui Hou",
        "Weiyan Zhang",
        "Yongqi Fan",
        "Qi Ye",
        "Jingping Liu",
        "Tong Ruan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-17T11:40:48+00:00",
          "link": "https://arxiv.org/abs/2502.11703v1",
          "size": "3356kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T13:26:39+00:00",
          "link": "https://arxiv.org/abs/2502.11703v2",
          "size": "3127kb",
          "version": "v2"
        }
      ],
      "title": "CMQCIC-Bench: A Chinese Benchmark for Evaluating Large Language Models in Medical Quality Control Indicator Calculation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.11703",
        "HTML": "https://arxiv.org/html/2502.11703v2",
        "PDF": "https://arxiv.org/pdf/2502.11703"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a dataset (CMQCIC-Bench) for evaluating LLMs in medical tasks, but the primary focus is on task benchmarking and error analysis, not on the processing or engineering of LLM training data."
      },
      "tasks": [
        "Fact Verification"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.09990",
      "abstract": "Modeling label correlations has always played a pivotal role in multi-label image classification (MLC), attracting significant attention from researchers. However, recent studies have overemphasized co-occurrence relationships among labels, which can lead to overfitting risk on this overemphasis, resulting in suboptimal models. To tackle this problem, we advocate for balancing correlative and discriminative relationships among labels to mitigate the risk of overfitting and enhance model performance. To this end, we propose the Multi-Label Visual Prompt Tuning framework, a novel and parameter-efficient method that groups classes into multiple class subsets according to label co-occurrence and mutual exclusivity relationships, and then models them respectively to balance the two relationships. In this work, since each group contains multiple classes, multiple prompt tokens are adopted within Vision Transformer (ViT) to capture the correlation or discriminative label relationship within each group, and effectively learn correlation or discriminative representations for class subsets. On the other hand, each group contains multiple group-aware visual representations that may correspond to multiple classes, and the mixture of experts (MoE) model can cleverly assign them from the group-aware to the label-aware, adaptively obtaining label-aware representation, which is more conducive to classification. Experiments on multiple benchmark datasets show that our proposed approach achieves competitive results and outperforms SOTA methods on multiple pre-trained models.",
      "authors": [
        "LeiLei Ma",
        "Shuo Xu",
        "MingKun Xie",
        "Lei Wang",
        "Dengdi Sun",
        "Haifeng Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-14T08:52:50+00:00",
          "link": "https://arxiv.org/abs/2504.09990v1",
          "size": "6756kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T09:52:46+00:00",
          "link": "https://arxiv.org/abs/2504.09990v2",
          "size": "6756kb",
          "version": "v2"
        }
      ],
      "title": "Correlative and Discriminative Label Grouping for Multi-Label Visual Prompt Tuning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.09990",
        "HTML": "https://arxiv.org/html/2504.09990v2",
        "PDF": "https://arxiv.org/pdf/2504.09990"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving multi-label image classification performance and does not discuss LLM training data processing or any related data engineering processes."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.07838",
      "abstract": "The term scientific workflow has evolved over the last two decades to encompass a broad range of compositions of interdependent compute tasks and data movements. It has also become an umbrella term for processing in modern scientific applications. Today, many scientific applications can be considered as workflows made of multiple dependent steps, and hundreds of workflow management systems (WMSs) have been developed to manage and run these workflows. However, no turnkey solution has emerged to address the diversity of scientific processes and the infrastructure on which they are implemented. Instead, new research problems requiring the execution of scientific workflows with some novel feature often lead to the development of an entirely new WMS. A direct consequence is that many existing WMSs share some salient features, offer similar functionalities, and can manage the same categories of workflows but also have some distinct capabilities. This situation makes researchers who develop workflows face the complex question of selecting a WMS. This selection can be driven by technical considerations, to find the system that is the most appropriate for their application and for the resources available to them, or other factors such as reputation, adoption, strong community support, or long-term sustainability. To address this problem, a group of WMS developers and practitioners joined their efforts to produce a community-based terminology of WMSs. This paper summarizes their findings and introduces this new terminology to characterize WMSs. This terminology is composed of fives axes: workflow characteristics, composition, orchestration, data management, and metadata capture. Each axis comprises several concepts that capture the prominent features of WMSs. Based on this terminology, this paper also presents a classification of 23 existing WMSs according to the proposed axes and terms.",
      "authors": [
        "Fr\\'ed\\'eric Suter",
        "Tain\\~a Coleman",
        "\\.Ilkay Altinta\\c{s}",
        "Rosa M. Badia",
        "Bartosz Balis",
        "Kyle Chard",
        "Iacopo Colonnelli",
        "Ewa Deelman",
        "Paolo Di Tommaso",
        "Thomas Fahringer",
        "Carole Goble",
        "Shantenu Jha",
        "Daniel S. Katz",
        "Johannes K\\\"oster",
        "Ulf Leser",
        "Kshitij Mehta",
        "Hilary Oliver",
        "J.-Luc Peterson",
        "Giovanni Pizzi",
        "Lo\\\"ic Pottier",
        "Ra\\\"ul Sirvent",
        "Eric Suchyta",
        "Douglas Thain",
        "Sean R. Wilkinson",
        "Justin M. Wozniak",
        "Rafael Ferreira da Silva"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-09T15:04:48+00:00",
          "link": "https://arxiv.org/abs/2506.07838v1",
          "size": "145kb",
          "version": "v1"
        },
        {
          "date": "2025-06-10T13:42:31+00:00",
          "link": "https://arxiv.org/abs/2506.07838v2",
          "size": "145kb",
          "version": "v2"
        },
        {
          "date": "2025-06-16T16:40:45+00:00",
          "link": "https://arxiv.org/abs/2506.07838v3",
          "size": "145kb",
          "version": "v3"
        },
        {
          "date": "2025-06-16T18:10:41+00:00",
          "link": "https://arxiv.org/abs/2506.07838v4",
          "size": "147kb",
          "version": "v4"
        },
        {
          "date": "2025-07-01T18:14:45+00:00",
          "link": "https://arxiv.org/abs/2506.07838v5",
          "size": "145kb",
          "version": "v5"
        },
        {
          "date": "2025-07-09T17:01:28+00:00",
          "link": "https://arxiv.org/abs/2506.07838v6",
          "size": "145kb",
          "version": "v6"
        }
      ],
      "title": "A Terminology for Scientific Workflow Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.07838",
        "HTML": "https://arxiv.org/html/2506.07838",
        "PDF": "https://arxiv.org/pdf/2506.07838"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses workflow management systems for scientific applications and does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.15167",
      "abstract": "Hyper-parameters are essential and critical for the performance of communication algorithms. However, current hyper-parameters optimization approaches for Warm-Start Particles Swarm Optimization with Crossover and Mutation (WS-PSO-CM) algorithm, designed for radio map-enabled unmanned aerial vehicle (UAV) trajectory and communication, are primarily heuristic-based, exhibiting low levels of automation and improvable performance. In this paper, we design an Large Language Model (LLM) agent for automatic hyper-parameters-tuning, where an iterative framework and Model Context Protocol (MCP) are applied. In particular, the LLM agent is first set up via a profile, which specifies the boundary of hyper-parameters, task objective, terminal condition, conservative or aggressive strategy of optimizing hyper-parameters, and LLM configurations. Then, the LLM agent iteratively invokes WS-PSO-CM algorithm for exploration. Finally, the LLM agent exits the loop based on the terminal condition and returns an optimized set of hyperparameters. Our experiment results show that the minimal sum-rate achieved by hyper-parameters generated via our LLM agent is significantly higher than those by both human heuristics and random generation methods. This indicates that an LLM agent with PSO and WS-PSO-CM algorithm knowledge is useful in seeking high-performance hyper-parameters.",
      "authors": [
        "Wanzhe Wang",
        "Jianqiu Peng",
        "Menghao Hu",
        "Weihuang Zhong",
        "Tong Zhang",
        "Shuai Wang",
        "Yixin Zhang",
        "Mingjie Shao",
        "and Wanli Ni"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Artificial Intelligence (cs.AI)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-18T06:28:22+00:00",
          "link": "https://arxiv.org/abs/2506.15167v1",
          "size": "416kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T13:20:45+00:00",
          "link": "https://arxiv.org/abs/2506.15167v2",
          "size": "300kb",
          "version": "v2"
        }
      ],
      "title": "LLM Agent for Hyper-Parameter Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.15167",
        "HTML": "https://arxiv.org/html/2506.15167v2",
        "PDF": "https://arxiv.org/pdf/2506.15167"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the use of LLMs for hyper-parameter optimization in the context of communication algorithms, without any focus on LLM training data processing or engineering."
      },
      "tasks": [
        "Large Language Model"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.06344",
      "abstract": "Variational Quantum Algorithms (VQAs) are promising candidates for near-term quantum computing, yet they face scalability challenges due to barren plateaus, where gradients vanish exponentially in the system size. Recent conjectures suggest that avoiding barren plateaus might inherently lead to classical simulability, thus limiting the opportunities for quantum advantage. In this work, we advance the theoretical understanding of the relationship between the trainability and computational complexity of VQAs, thus directly addressing the conjecture. We introduce the Linear Clifford Encoder (LCE), a novel technique that ensures constant-scaling gradient statistics on optimization landscape regions that are close to Clifford circuits. Additionally, we leverage classical Taylor surrogates to reveal computational complexity phase transitions from polynomial to super-polynomial as the initialization region size increases. Combining these results, we reveal a deeper link between trainability and computational complexity, and analytically prove that barren plateaus can be avoided in regions for which no classical surrogate is known to exist. Furthermore, numerical experiments on LCE transformed landscapes confirm in practice the existence of a super-polynomially complex ``transition zone'' where gradients decay polynomially. These findings indicate a plausible path to practically relevant, barren plateau-free variational models with potential for quantum advantage.",
      "authors": [
        "Sabri Meyer",
        "Francesco Scala",
        "Francesco Tacchino",
        "Aurelien Lucchi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Computational Complexity (cs.CC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T19:10:46+00:00",
          "link": "https://arxiv.org/abs/2507.06344v1",
          "size": "2917kb",
          "version": "v1"
        }
      ],
      "title": "Trainability of Quantum Models Beyond Known Classical Simulability",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06344",
        "HTML": "https://arxiv.org/html/2507.06344v1",
        "PDF": "https://arxiv.org/pdf/2507.06344"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses trainability and computational complexity of Quantum Models. It does not focus on LLM training data processing or dataset collection."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06834",
      "abstract": "The proof theory and semantics of intuitionistic modal logics have been studied by Simpson in terms of Prawitz-style labelled natural deduction systems and Kripke models. An alternative to model-theoretic semantics is provided by proof-theoretic semantics, which is a logical realization of inferentialism, in which the meaning of constructs is understood through their use. The key idea in proof-theoretic semantics is that of a base of atomic rules, all of which refer only to propositional atoms and involve no logical connectives. A specific form of proof-theoretic semantics, known as base-extension semantics (B-eS), is concerned with the validity of formulae and provides a direct counterpart to Kripke models that is grounded in the provability of atomic formulae in a base. We establish, systematically, B-eS for Simpson's intuitionistic modal logics and, also systematically, obtain soundness and completeness theorems with respect to Simpson's natural deduction systems.",
      "authors": [
        "Yll Buzoku",
        "David. J. Pym"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic (math.LO)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T13:32:05+00:00",
          "link": "https://arxiv.org/abs/2507.06834v1",
          "size": "23kb",
          "version": "v1"
        }
      ],
      "title": "Base-extension Semantics for Intuitionistic Modal Logics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06834",
        "HTML": "https://arxiv.org/html/2507.06834v1",
        "PDF": "https://arxiv.org/pdf/2507.06834"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about developing a semantics framework for intuitionistic modal logics, without any focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06909",
      "abstract": "Legal judgment prediction offers a compelling method to aid legal practitioners and researchers. However, the research question remains relatively under-explored: Should multiple defendants and charges be treated separately in LJP? To address this, we introduce a new dataset namely multi-person multi-charge prediction (MPMCP), and seek the answer by evaluating the performance of several prevailing legal large language models (LLMs) on four practical legal judgment scenarios: (S1) single defendant with a single charge, (S2) single defendant with multiple charges, (S3) multiple defendants with a single charge, and (S4) multiple defendants with multiple charges. We evaluate the dataset across two LJP tasks, i.e., charge prediction and penalty term prediction. We have conducted extensive experiments and found that the scenario involving multiple defendants and multiple charges (S4) poses the greatest challenges, followed by S2, S3, and S1. The impact varies significantly depending on the model. For example, in S4 compared to S1, InternLM2 achieves approximately 4.5% lower F1-score and 2.8% higher LogD, while Lawformer demonstrates around 19.7% lower F1-score and 19.0% higher LogD. Our dataset and code are available at https://github.com/lololo-xiao/MultiJustice-MPMCP.",
      "authors": [
        "Xiao Wang",
        "Jiahuan Pei",
        "Diancheng Shui",
        "Zhiguang Han",
        "Xin Sun",
        "Dawei Zhu",
        "Xiaoyu Shen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T14:47:00+00:00",
          "link": "https://arxiv.org/abs/2507.06909v1",
          "size": "775kb",
          "version": "v1"
        }
      ],
      "title": "MultiJustice: A Chinese Dataset for Multi-Party, Multi-Charge Legal Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06909",
        "HTML": "https://arxiv.org/html/2507.06909v1",
        "PDF": "https://arxiv.org/pdf/2507.06909"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper introduces a new dataset focused on legal judgment prediction scenarios. It details the creation of this dataset and provides extensive evaluations, making a substantial contribution to data processing for LLM tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07079",
      "abstract": "Despite the rapid advances in Text-to-Image (T2I) generation models, their evaluation remains challenging in domains like fashion, involving complex compositional generation. Recent automated T2I evaluation methods leverage pre-trained vision-language models to measure cross-modal alignment. However, our preliminary study reveals that they are still limited in assessing rich entity-attribute semantics, facing challenges in attribute confusion, i.e., when attributes are correctly depicted but associated to the wrong entities. To address this, we build on a Visual Question Answering (VQA) localization strategy targeting one single entity at a time across both visual and textual modalities. We propose a localized human evaluation protocol and introduce a novel automatic metric, Localized VQAScore (L-VQAScore), that combines visual localization with VQA probing both correct (reflection) and miss-localized (leakage) attribute generation. On a newly curated dataset featuring challenging compositional alignment scenarios, L-VQAScore outperforms state-of-the-art T2I evaluation methods in terms of correlation with human judgments, demonstrating its strength in capturing fine-grained entity-attribute associations. We believe L-VQAScore can be a reliable and scalable alternative to subjective evaluations.",
      "authors": [
        "Ziyue Liu",
        "Federico Girella",
        "Yiming Wang and Davide Talon"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T17:38:40+00:00",
          "link": "https://arxiv.org/abs/2507.07079v1",
          "size": "739kb",
          "version": "v1"
        }
      ],
      "title": "Evaluating Attribute Confusion in Fashion Text-to-Image Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07079",
        "HTML": "https://arxiv.org/html/2507.07079v1",
        "PDF": "https://arxiv.org/pdf/2507.07079"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on evaluating attribute confusion in text-to-image generation models, and it does not discuss any training data processing or data engineering for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2404.04439",
      "abstract": "Non-negative Matrix Factorization (NMF) is a powerful technique for analyzing regularly-sampled data, i.e., data that can be stored in a matrix. For audio, this has led to numerous applications using time-frequency (TF) representations like the Short-Time Fourier Transform. However extending these applications to irregularly-spaced TF representations, like the Constant-Q transform, wavelets, or sinusoidal analysis models, has not been possible since these representations cannot be directly stored in matrix form. In this paper, we formulate NMF in terms of learnable functions (instead of vectors) and show that NMF can be extended to a wider variety of signal classes that need not be regularly sampled.",
      "authors": [
        "Krishna Subramani",
        "Paris Smaragdis",
        "Takuya Higuchi",
        "Mehrez Souden"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Machine Learning (cs.LG)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-05T22:48:57+00:00",
          "link": "https://arxiv.org/abs/2404.04439v1",
          "size": "1284kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T00:09:50+00:00",
          "link": "https://arxiv.org/abs/2404.04439v2",
          "size": "1658kb",
          "version": "v2"
        }
      ],
      "title": "Rethinking Non-Negative Matrix Factorization with Implicit Neural Representations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.04439",
        "HTML": "https://arxiv.org/html/2404.04439v2",
        "PDF": "https://arxiv.org/pdf/2404.04439"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with Non-negative Matrix Factorization and signal processing, not with LLM training data processing."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/subramanikrishna/in-nmf"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.20199",
      "abstract": "Neural networks trained to solve modular arithmetic tasks exhibit grokking, a phenomenon where the test accuracy starts improving long after the model achieves 100% training accuracy in the training process. It is often taken as an example of \"emergence\", where model ability manifests sharply through a phase transition. In this work, we show that the phenomenon of grokking is not specific to neural networks nor to gradient descent-based optimization. Specifically, we show that this phenomenon occurs when learning modular arithmetic with Recursive Feature Machines (RFM), an iterative algorithm that uses the Average Gradient Outer Product (AGOP) to enable task-specific feature learning with general machine learning models. When used in conjunction with kernel machines, iterating RFM results in a fast transition from random, near zero, test accuracy to perfect test accuracy. This transition cannot be predicted from the training loss, which is identically zero, nor from the test loss, which remains constant in initial iterations. Instead, as we show, the transition is completely determined by feature learning: RFM gradually learns block-circulant features to solve modular arithmetic. Paralleling the results for RFM, we show that neural networks that solve modular arithmetic also learn block-circulant features. Furthermore, we present theoretical evidence that RFM uses such block-circulant features to implement the Fourier Multiplication Algorithm, which prior work posited as the generalizing solution neural networks learn on these tasks. Our results demonstrate that emergence can result purely from learning task-relevant features and is not specific to neural architectures nor gradient descent-based optimization methods. Furthermore, our work provides more evidence for AGOP as a key mechanism for feature learning in neural networks.",
      "authors": [
        "Neil Mallinar",
        "Daniel Beaglehole",
        "Libin Zhu",
        "Adityanarayanan Radhakrishnan",
        "Parthe Pandit",
        "Mikhail Belkin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-29T17:28:58+00:00",
          "link": "https://arxiv.org/abs/2407.20199v1",
          "size": "3315kb",
          "version": "v1"
        },
        {
          "date": "2024-10-18T04:13:15+00:00",
          "link": "https://arxiv.org/abs/2407.20199v2",
          "size": "3315kb",
          "version": "v2"
        },
        {
          "date": "2025-07-09T04:06:02+00:00",
          "link": "https://arxiv.org/abs/2407.20199v3",
          "size": "3316kb",
          "version": "v3"
        }
      ],
      "title": "Emergence in non-neural models: grokking modular arithmetic via average gradient outer product",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.20199",
        "HTML": "https://arxiv.org/html/2407.20199v3",
        "PDF": "https://arxiv.org/pdf/2407.20199"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper examines emergence in non-neural models and feature learning for modular arithmetic, not focusing on LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.04446",
      "abstract": "To guarantee safe and robust deployment of large language models (LLMs) at scale, it is critical to accurately assess their adversarial robustness. Existing adversarial attacks typically target harmful responses in single-point, greedy generations, overlooking the inherently stochastic nature of LLMs. In this paper, we propose a novel framework for adversarial robustness evaluation that explicitly models the entire output distribution, including tail-risks, providing better estimates for model robustness at scale. By casting the attack process as a resource allocation problem between optimization and sampling, we determine compute-optimal tradeoffs and show that integrating sampling into existing attacks boosts ASR by up to 48% and improves efficiency by up to two orders of magnitude. Our framework also enables us to analyze how different attack algorithms affect output harm distributions. Surprisingly, we find that most optimization strategies have little effect on output harmfulness. Finally, we introduce a data-free proof-of-concept objective based on entropy-maximization to demonstrate how our tail-aware perspective enables new optimization targets. Overall, our findings highlight the importance of tail-aware attacks and evaluation protocols to accurately assess and strengthen LLM safety.",
      "authors": [
        "Tim Beyer",
        "Yan Scholten",
        "Leo Schwinn",
        "Stephan G\\\"unnemann"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-06T16:13:33+00:00",
          "link": "https://arxiv.org/abs/2507.04446v1",
          "size": "12834kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T11:52:25+00:00",
          "link": "https://arxiv.org/abs/2507.04446v2",
          "size": "12206kb",
          "version": "v2"
        }
      ],
      "title": "Tail-aware Adversarial Attacks: A Distributional Approach to Efficient LLM Jailbreaking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.04446",
        "PDF": "https://arxiv.org/pdf/2507.04446"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with adversarial attack robustness in LLMs, focusing on sampling strategies in output harm distributions, which does not involve training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06466",
      "abstract": "Multi-agent interactions have long fueled innovation, from natural predator-prey dynamics to the space race. Self-play (SP) algorithms try to harness these dynamics by pitting agents against ever-improving opponents, thereby creating an implicit curriculum toward learning high-quality solutions. However, SP often fails to produce diverse solutions and can get stuck in locally optimal behaviors. We introduce Foundation-Model Self-Play (FMSP), a new direction that leverages the code-generation capabilities and vast knowledge of foundation models (FMs) to overcome these challenges by leaping across local optima in policy space. We propose a family of approaches: (1) \\textbf{Vanilla Foundation-Model Self-Play (vFMSP)} continually refines agent policies via competitive self-play; (2) \\textbf{Novelty-Search Self-Play (NSSP)} builds a diverse population of strategies, ignoring performance; and (3) the most promising variant, \\textbf{Quality-Diveristy Self-Play (QDSP)}, creates a diverse set of high-quality policies by combining the diversity of NSSP and refinement of vFMSP. We evaluate FMSPs in Car Tag, a continuous-control pursuer-evader setting, and in Gandalf, a simple AI safety simulation in which an attacker tries to jailbreak an LLM's defenses. In Car Tag, FMSPs explore a wide variety of reinforcement learning, tree search, and heuristic-based methods, to name just a few. In terms of discovered policy quality, \\ouralgo and vFMSP surpass strong human-designed strategies. In Gandalf, FMSPs can successfully automatically red-team an LLM, breaking through and jailbreaking six different, progressively stronger levels of defense. Furthermore, FMSPs can automatically proceed to patch the discovered vulnerabilities. Overall, FMSPs represent a promising new research frontier of improving self-play with foundation models, opening fresh paths toward more creative and open-ended strategy discovery",
      "authors": [
        "Aaron Dharna",
        "Cong Lu",
        "Jeff Clune"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T00:58:19+00:00",
          "link": "https://arxiv.org/abs/2507.06466v1",
          "size": "4068kb",
          "version": "v1"
        }
      ],
      "title": "Foundation Model Self-Play: Open-Ended Strategy Innovation via Foundation Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06466",
        "PDF": "https://arxiv.org/pdf/2507.06466"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper investigates self-play strategies leveraging foundation models, but does not focus on training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06321",
      "abstract": "Collecting and annotating images for the purpose of training segmentation models is often cost prohibitive. In the domain of wildland fire science, this challenge is further compounded by the scarcity of reliable public datasets with labeled ground truth. This paper presents the Centralized Copy-Paste Data Augmentation (CCPDA) method, for the purpose of assisting with the training of deep-learning multiclass segmentation models, with special focus on improving segmentation outcomes for the fire-class. CCPDA has three main steps: (i) identify fire clusters in the source image, (ii) apply a centralization technique to focus on the core of the fire area, and (iii) paste the refined fire clusters onto a target image. This method increases dataset diversity while preserving the essential characteristics of the fire class. The effectiveness of this augmentation technique is demonstrated via numerical analysis and comparison against various other augmentation methods using a weighted sum-based multi-objective optimization approach. This approach helps elevate segmentation performance metrics specific to the fire class, which carries significantly more operational significance than other classes (fuel, ash, or background). Numerical performance assessment validates the efficacy of the presented CCPDA method in alleviating the difficulties associated with small, manually labeled training datasets. It also illustrates that CCPDA outperforms other augmentation strategies in the application scenario considered, particularly in improving fire-class segmentation performance.",
      "authors": [
        "Joon Tai Kim",
        "Tianle Chen",
        "Ziyu Dong",
        "Nishanth Kunchala",
        "Alexander Guller",
        "Daniel Ospina Acero",
        "Roger Williams",
        "and Mrinal Kumar"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T18:17:09+00:00",
          "link": "https://arxiv.org/abs/2507.06321v1",
          "size": "31924kb",
          "version": "v1"
        }
      ],
      "title": "Centralized Copy-Paste: Enhanced Data Augmentation Strategy for Wildland Fire Semantic Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06321",
        "HTML": "https://arxiv.org/html/2507.06321v1",
        "PDF": "https://arxiv.org/pdf/2507.06321"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a data augmentation method (CCPDA) to enhance segmentation outcomes, which involves some data processing but is specific to image segmentation, not directly related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06803",
      "abstract": "This paper contributes to speeding up the design and deployment of engineering dynamical systems by proposing a strategy for exploiting domain and expert knowledge for the automated generation of dynamical system computational model starting from a corpus of document relevant to the dynamical system of interest and an input document describing the specific system. This strategy is implemented in five steps and, crucially, it uses system modeling language diagrams (SysML) to extract accurate information about the dependencies, attributes, and operations of components. Natural Language Processing (NLP) strategies and Large Language Models (LLMs) are employed in specific tasks to improve intermediate outputs of the SySML diagrams automated generation, such as: list of key nouns; list of extracted relationships; list of key phrases and key relationships; block attribute values; block relationships; and BDD diagram generation. The applicability of automated SysML diagram generation is illustrated with different case studies. The computational models of complex dynamical systems from SysML diagrams are then obtained via code generation and computational model generation steps. In the code generation step, NLP strategies are used for summarization, while LLMs are used for validation only. The proposed approach is not limited to a specific system, domain, or computational software. The applicability of the proposed approach is shown via an end-to-end example from text to model of a simple pendulum, showing improved performance compared to results yielded by LLMs only.",
      "authors": [
        "Matthew Anderson Hendricks and Alice Cicirello"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T12:44:49+00:00",
          "link": "https://arxiv.org/abs/2507.06803v1",
          "size": "2519kb",
          "version": "v1"
        }
      ],
      "title": "Text to model via SysML: Automated generation of dynamical system computational models from unstructured natural language text via enhanced System Modeling Language diagrams",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06803",
        "HTML": "https://arxiv.org/html/2507.06803v1",
        "PDF": "https://arxiv.org/pdf/2507.06803"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper uses NLP and LLMs for improving outputs related to SysML diagram generation, but it does not focus primarily on data processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06852",
      "abstract": "Argumentation frameworks (AFs) are a foundational tool in artificial intelligence for modeling structured reasoning and conflict. SCC-recursiveness is a well-known design principle in which the evaluation of arguments is decomposed according to the strongly connected components (SCCs) of the attack graph, proceeding recursively from \"higher\" to \"lower\" components. While SCC-recursive semantics such as \\cft and \\stgt have proven effective for finite AFs, Baumann and Spanring showed the failure of SCC-recursive semantics to generalize reliably to infinite AFs due to issues with well-foundedness.\n  We propose two approaches to extending SCC-recursiveness to the infinite setting. We systematically evaluate these semantics using Baroni and Giacomin's established criteria, showing in particular that directionality fails in general. We then examine these semantics' behavior in finitary frameworks, where we find some of our semantics satisfy directionality. These results advance the theory of infinite argumentation and lay the groundwork for reasoning systems capable of handling unbounded or evolving domains.",
      "authors": [
        "Uri Andrews and Luca San Mauro"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T13:57:12+00:00",
          "link": "https://arxiv.org/abs/2507.06852v1",
          "size": "48kb",
          "version": "v1"
        }
      ],
      "title": "SCC-recursiveness in infinite argumentation (extended version)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06852",
        "HTML": "https://arxiv.org/html/2507.06852v1",
        "PDF": "https://arxiv.org/pdf/2507.06852"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on argumentation frameworks, specifically SCC-recursiveness, in infinite domains and does not discuss LLM training data processing or data engineering."
      },
      "source": "arXiv"
    }
  ],
  "subjects": [
    "Computer Vision and Pattern Recognition (cs.CV)",
    "Computation and Language (cs.CL)",
    "Cryptography and Security (cs.CR)",
    "Information Retrieval (cs.IR)",
    "Artificial Intelligence (cs.AI)",
    "Computers and Society (cs.CY)",
    "Machine Learning (cs.LG)",
    "Databases (cs.DB)",
    "Robotics (cs.RO)",
    "Machine Learning (stat.ML)",
    "Quantum Physics (quant-ph)",
    "Computational Engineering, Finance, and Science (cs.CE)",
    "Image and Video Processing (eess.IV)",
    "Software Engineering (cs.SE)",
    "Data Structures and Algorithms (cs.DS)",
    "Sound (cs.SD)",
    "Logic (math.LO)",
    "Audio and Speech Processing (eess.AS)",
    "Numerical Analysis (cs.NA)",
    "Chemical Physics (physics.chem-ph)",
    "Numerical Analysis (math.NA)",
    "Statistics Theory (stat.TH)",
    "Methodology (stat.ME)",
    "Quantitative Methods (q-bio.QM)",
    "Information Theory (math.IT)",
    "Information Theory (cs.IT)",
    "Biomolecules (q-bio.BM)",
    "Molecular Networks (q-bio.MN)",
    "Statistics Theory (math.ST)",
    "Formal Languages and Automata Theory (cs.FL)",
    "Distributed, Parallel, and Cluster Computing (cs.DC)",
    "Mathematical Finance (q-fin.MF)",
    "Theoretical Economics (econ.TH)",
    "Applications (stat.AP)",
    "Neural and Evolutionary Computing (cs.NE)",
    "Emerging Technologies (cs.ET)",
    "Hardware Architecture (cs.AR)",
    "Networking and Internet Architecture (cs.NI)",
    "Signal Processing (eess.SP)",
    "Populations and Evolution (q-bio.PE)",
    "Social and Information Networks (cs.SI)",
    "Multiagent Systems (cs.MA)",
    "Systems and Control (eess.SY)",
    "Systems and Control (cs.SY)",
    "Computational Geometry (cs.CG)",
    "Discrete Mathematics (cs.DM)",
    "Chaotic Dynamics (nlin.CD)",
    "Dynamical Systems (math.DS)",
    "Human-Computer Interaction (cs.HC)",
    "General Economics (econ.GN)",
    "Economics (q-fin.EC)",
    "Multimedia (cs.MM)",
    "Metric Geometry (math.MG)",
    "Combinatorics (math.CO)",
    "Graphics (cs.GR)",
    "Optics (physics.optics)",
    "Applied Physics (physics.app-ph)",
    "Medical Physics (physics.med-ph)",
    "Genomics (q-bio.GN)",
    "Materials Science (cond-mat.mtrl-sci)",
    "Optimization and Control (math.OC)",
    "Computational Complexity (cs.CC)",
    "Symplectic Geometry (math.SG)",
    "Quantum Algebra (math.QA)",
    "Rings and Algebras (math.RA)",
    "Geometric Topology (math.GT)",
    "Performance (cs.PF)",
    "Risk Management (q-fin.RM)",
    "Logic in Computer Science (cs.LO)",
    "Physics Education (physics.ed-ph)",
    "Computational Physics (physics.comp-ph)",
    "Computational Finance (q-fin.CP)",
    "Computation (stat.CO)",
    "General Finance (q-fin.GN)",
    "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
    "Data Analysis, Statistics and Probability (physics.data-an)",
    "Algebraic Geometry (math.AG)",
    "Fluid Dynamics (physics.flu-dyn)",
    "Statistical Mechanics (cond-mat.stat-mech)",
    "Programming Languages (cs.PL)",
    "Biological Physics (physics.bio-ph)",
    "Econometrics (econ.EM)",
    "Other Statistics (stat.OT)",
    "Mathematical Software (cs.MS)",
    "Computer Science and Game Theory (cs.GT)",
    "Neurons and Cognition (q-bio.NC)",
    "Physics and Society (physics.soc-ph)",
    "Digital Libraries (cs.DL)",
    "Atmospheric and Oceanic Physics (physics.ao-ph)",
    "Probability (math.PR)",
    "Mathematical Physics (math.MP)",
    "Mathematical Physics (math-ph)",
    "Number Theory (math.NT)",
    "Other Computer Science (cs.OH)",
    "Algebraic Topology (math.AT)",
    "Symbolic Computation (cs.SC)",
    "Adaptation and Self-Organizing Systems (nlin.AO)",
    "High Energy Astrophysical Phenomena (astro-ph.HE)",
    "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
    "Cellular Automata and Lattice Gases (nlin.CG)",
    "Analysis of PDEs (math.AP)",
    "Differential Geometry (math.DG)",
    "Geophysics (physics.geo-ph)"
  ],
  "prompt": {
    "train_data": "\nHigh-quality training data is critical to LLM performance. You are a computer science expert specializing in data engineering for large language model (LLM) training data. Your task is to analyze a set of arXiv papers and identify those that focus on processing LLM training data.\n\n---\n\n### **Task Objective**\n\nFor each paper, determine whether it makes a technical contribution to **LLM training data processing**. In particular, focus on papers that involve **training-data processing** , including but not limited to:\n\n1. **Data processing during pretraining or fine-tuning**\n   * Preparation of data for LLM pretraining, instruction tuning, supervised fine-tuning (SFT), alignment tuning, etc.\n2. **training-data processing**\n   * Common data engineering operations, including data collection, data generation, data deduplication, data filtering, etc.\n   * Any methods or techniques that significantly improve data quality.\n   * Creation of a new dataset **with clear, detailed data processing steps.**\n\n**Note:** Ignore papers that merely use existing training datasets for downstream tasks (e.g., QA, reasoning), propose new model architectures, or conduct evaluation benchmarks\u2014unless they also **substantively modify or process the training data itself**.\n\n---\n\n### **Relevance Level Classification**\n\n* **`core`**: The paper\u2019s primary contribution lies in processing or creating LLM training data, or in constructing a higher-quality dataset from existing data\u2014e.g., dataset creation, data generation or synthesis, pipeline design, filtering methods, or other data\u2011engineering operations that improve data quality.\n* **`partial`**: The paper briefly mentions training data or standard preprocessing (e.g., using a standard dataset or tokenization, it focuses on model architecture, tasks, evaluation, prompting methods) but does **not** focus primarily on data processing.\n* **`irrelevant`**: The paper does **not** discuss any aspect of LLM training data collection, processing, or engineering.\n\n---\n\n### **Output Format (strictly follow this JSON schema)**\n\n```json\n{\n  \"result\": [\n    {\n      \"id\": \"<paper ID>\",\n      \"level\": \"core | partial | irrelevant\",\n      \"reason\": \"A 1-2 sentence explanation citing the key part of the abstract or methodology that justifies your classification\"\n    }\n    // \u2026additional papers\n  ]\n}\n```\n"
  },
  "description": "Data source: https://arxiv.org/list/cs/new",
  "level_tatistics": {
    "CORE": 1,
    "irrelevant": 657,
    "core": 50,
    "partial": 96
  },
  "arxiv_update_date": "2025-07-10",
  "updated_at": "2025-07-10 10:02:20"
}