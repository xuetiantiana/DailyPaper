{
  "data": [
    {
      "id": "2507.01974",
      "abstract": "The accessibility of long-duration recorders, adapted to sometimes demanding field conditions, has enabled the deployment of extensive animal population monitoring campaigns through ecoacoustics. The effectiveness of automatic signal detection methods, increasingly based on neural approaches, is frequently evaluated solely through machine learning metrics, while acoustic analysis of performance remains rare. As part of the acoustic monitoring of Rock Ptarmigan populations, we propose here a simple method for acoustic analysis of the detection system's performance. The proposed measure is based on relating the signal-to-noise ratio of synthetic signals to their probability of detection. We show how this measure provides information about the system and allows optimisation of its training. We also show how it enables modelling of the detection distance, thus offering the possibility of evaluating its dynamics according to the sound environment and accessing an estimation of the spatial density of calls.",
      "authors": [
        "J\\'er\\'emy Rouch (CRNL-ENES)",
        "M Ducrettet (CRNL-ENES",
        "ISYEB)",
        "S Haupert (ISYEB)",
        "R Emonet (LabHC)",
        "F S\\`ebe (CRNL-ENES",
        "OFB - DRAS)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T13:01:10+00:00",
          "link": "https://arxiv.org/abs/2507.01974v1",
          "size": "664kb",
          "version": "v1"
        }
      ],
      "title": "Acoustic evaluation of a neural network dedicated to the detection of animal vocalisations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01974",
        "PDF": "https://arxiv.org/pdf/2507.01974"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on acoustic evaluation of neural networks for detecting animal vocalizations, with no connection to LLM training data or its processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.01975",
      "abstract": "Simulation of fluid flows is crucial for modeling physical phenomena like meteorology, aerodynamics, and biomedicine. Classical numerical solvers often require fine spatiotemporal grids to satisfy stability, consistency, and convergence conditions, leading to substantial computational costs. Although machine learning has demonstrated better efficiency, they typically suffer from issues of interpretability, generalizability, and data dependency. Hence, we propose a learnable and differentiable finite volume solver, called LDSolver, designed for efficient and accurate simulation of fluid flows on spatiotemporal coarse grids. LDSolver comprises two key components: (1) a differentiable finite volume solver, and (2) an learnable module providing equivalent approximation for fluxes (derivatives and interpolations), and temporal error correction on coarse grids. Even with limited training data (e.g., only a few trajectories), our model could accelerate the simulation while maintaining a high accuracy with superior generalizability. Experiments on different flow systems (e.g., Burgers, decaying, forced and shear flows) show that LDSolver achieves state-of-the-art performance, surpassing baseline models with notable margins.",
      "authors": [
        "Mengtao Yan",
        "Qi Wang",
        "Haining Wang",
        "Ruizhi Chengze",
        "Yi Zhang",
        "Hongsheng Liu",
        "Zidong Wang",
        "Fan Yu",
        "Qi Qi",
        "and Hao Sun"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Fluid Dynamics (physics.flu-dyn)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T14:22:27+00:00",
          "link": "https://arxiv.org/abs/2507.01975v1",
          "size": "8298kb",
          "version": "v1"
        }
      ],
      "title": "Learnable-Differentiable Finite Volume Solver for Accelerated Simulation of Flows",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01975",
        "HTML": "https://arxiv.org/html/2507.01975v1",
        "PDF": "https://arxiv.org/pdf/2507.01975"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study is on a finite volume solver for fluid flow simulation and does not relate to the processing of training data for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.01976",
      "abstract": "Synthetic network traffic generation has emerged as a promising alternative for various data-driven applications in the networking domain. It enables the creation of synthetic data that preserves real-world characteristics while addressing key challenges such as data scarcity, privacy concerns, and purity constraints associated with real data. In this survey, we provide a comprehensive review of synthetic network traffic generation approaches, covering essential aspects such as data types, generation models, and evaluation methods. With the rapid advancements in AI and machine learning, we focus particularly on deep learning-based techniques while also providing a detailed discussion of statistical methods and their extensions, including commercially available tools. Furthermore, we highlight open challenges in this domain and discuss potential future directions for further research and development. This survey serves as a foundational resource for researchers and practitioners, offering a structured analysis of existing methods, challenges, and opportunities in synthetic network traffic generation.",
      "authors": [
        "Nirhoshan Sivaroopan",
        "Kaushitha Silva",
        "Chamara Madarasingha",
        "Thilini Dahanayaka",
        "Guillaume Jourjon",
        "Anura Jayasumana",
        "and Kanchana Thilakarathna"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T18:08:18+00:00",
          "link": "https://arxiv.org/abs/2507.01976v1",
          "size": "2169kb",
          "version": "v1"
        }
      ],
      "title": "A Comprehensive Survey on Network Traffic Synthesis: From Statistical Models to Deep Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01976",
        "HTML": "https://arxiv.org/html/2507.01976v1",
        "PDF": "https://arxiv.org/pdf/2507.01976"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The survey includes a review of synthetic network traffic generation which involves data generation methods, but it does not focus on data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.01978",
      "abstract": "Social media broadly refers to digital platforms and applications that simulate social interactions online. This study investigates the impact of social media platforms and their algorithms on political interest among users. As social media usage continues to rise, platforms like Facebook and X (formerly Twitter) play increasingly pivotal roles in shaping political discourse. By employing statistical analyses on data collected from over 3,300 participants, this research identifies significant differences in how various social media platforms influence political interest. Findings reveal that moderate Facebook users demonstrate decreased political engagement, whereas even minimal engagement with X significantly boosts political interest. The study further identifies demographic variations, noting that males, older individuals, Black or African American users, those with higher incomes show greater political interest. The demographic analysis highlights that Republicans are particularly active on social media - potentially influencing their social media engagement patterns. However, the study acknowledges a crucial limitation - the lack of direct data regarding the content users are exposed to which is shaping their social media experiences. Future research should explore these influences and consider additional popular platforms to enhance the understanding of social media's political impact. Addressing these gaps can provide deeper insights into digital political mobilization, aiding policymakers, educators, and platform designers in fostering healthier democratic engagement.",
      "authors": [
        "Waseq Billah"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T02:44:34+00:00",
          "link": "https://arxiv.org/abs/2507.01978v1",
          "size": "318kb",
          "version": "v1"
        }
      ],
      "title": "Recommendation Algorithms on Social Media: Unseen Drivers of Political Opinion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01978",
        "PDF": "https://arxiv.org/pdf/2507.01978"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research investigates social media's influence on political opinion, without addressing any aspect of training data for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.01982",
      "abstract": "Accurate traffic demand forecasting enables transportation management departments to allocate resources more effectively, thereby improving their utilization efficiency. However, complex spatiotemporal relationships in traffic systems continue to limit the performance of demand forecasting models. To improve the accuracy of spatiotemporal traffic demand prediction, we propose a new graph convolutional network structure called DKGCM. Specifically, we first consider the spatial flow distribution of different traffic nodes and propose a novel temporal similarity-based clustering graph convolution method, DK-GCN. This method utilizes Dynamic Time Warping (DTW) and K-means clustering to group traffic nodes and more effectively capture spatial dependencies. On the temporal scale, we integrate the Fast Fourier Transform (FFT) within the bidirectional Mamba deep learning framework to capture temporal dependencies in traffic demand. To further optimize model training, we incorporate the GRPO reinforcement learning strategy to enhance the loss function feedback mechanism. Extensive experiments demonstrate that our model outperforms several advanced methods and achieves strong results on three public datasets.",
      "authors": [
        "Siqing Long",
        "Xiangzhi Huang",
        "Jiemin Xie",
        "Ming Cai"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T06:33:36+00:00",
          "link": "https://arxiv.org/abs/2507.01982v1",
          "size": "2256kb",
          "version": "v1"
        }
      ],
      "title": "DKGCM: A Spatio-Temporal Prediction Model for Traffic Flow by Fusing Spatial Node Clustering Method and Fourier Bidirectional Mamba Mechanism",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01982",
        "PDF": "https://arxiv.org/pdf/2507.01982"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a spatio-temporal prediction model for traffic flow, which does not relate to the processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.01984",
      "abstract": "Amid a tidal wave of misinformation flooding social media during elections and crises, extensive research has been conducted on misinformation detection, primarily focusing on text-based or image-based approaches. However, only a few studies have explored multimodal feature combinations, such as integrating text and images for building a classification model to detect misinformation. This study investigates the effectiveness of different multimodal feature combinations, incorporating text, images, and social features using an early fusion approach for the classification model. This study analyzed 1,529 tweets containing both text and images during the COVID-19 pandemic and election periods collected from Twitter (now X). A data enrichment process was applied to extract additional social features, as well as visual features, through techniques such as object detection and optical character recognition (OCR). The results show that combining unsupervised and supervised machine learning models improves classification performance by 15% compared to unimodal models and by 5% compared to bimodal models. Additionally, the study analyzes the propagation patterns of misinformation based on the characteristics of misinformation tweets and the users who disseminate them.",
      "authors": [
        "Gautam Kishore Shahi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T18:17:35+00:00",
          "link": "https://arxiv.org/abs/2507.01984v1",
          "size": "673kb",
          "version": "v1"
        }
      ],
      "title": "Multimodal Misinformation Detection Using Early Fusion of Linguistic, Visual, and Social Features",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01984",
        "HTML": "https://arxiv.org/html/2507.01984v1",
        "PDF": "https://arxiv.org/pdf/2507.01984"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study focuses on multimodal misinformation detection using various features but does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.01988",
      "abstract": "As AI models outpace the capabilities of single processors, interconnects across chips have become a critical enabler for scalable computing. These processors exchange massive amounts of data at cache-line granularity, prompting the adoption of new interconnect protocols like CXL, NVLink, and UALink, designed for high bandwidth and small payloads. However, the increasing transfer rates of these protocols heighten susceptibility to errors. While mechanisms like Cyclic Redundancy Check (CRC) and Forward Error Correction (FEC) are standard for reliable data transmission, scaling chip interconnects to multi-node configurations introduces new challenges, particularly in managing silently dropped flits in switching devices. This paper introduces Implicit Sequence Number (ISN), a novel mechanism that ensures precise flit drop detection and in-order delivery without adding header overhead. Additionally, we propose Reliability Extended Link (RXL), an extension of CXL that incorporates ISN to support scalable, reliable multi-node interconnects while maintaining compatibility with the existing flit structure. By elevating CRC to a transport-layer mechanism for end-to-end data and sequence integrity, and relying on FEC for link-layer error correction and detection, RXL delivers robust reliability and scalability without compromising bandwidth efficiency.",
      "authors": [
        "Giyong Jung",
        "Saeid Gorgin",
        "John Kim and Jungrae Kim"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T13:02:17+00:00",
          "link": "https://arxiv.org/abs/2507.01988v1",
          "size": "890kb",
          "version": "v1"
        }
      ],
      "title": "Scaling Out Chip Interconnect Networks with Implicit Sequence Numbers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01988",
        "HTML": "https://arxiv.org/html/2507.01988v1",
        "PDF": "https://arxiv.org/pdf/2507.01988"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on chip interconnect networks and reliability mechanisms such as CRC and FEC, which is not related to the processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.01994",
      "abstract": "Despite advancements, Radio Access Networks (RAN) still account for over 50\\% of the total power consumption in 5G networks. Existing RAN split options do not fully harness data potential, presenting an opportunity to reduce operational expenditures. This paper addresses this opportunity through a twofold approach. First, highly accurate network traffic and user predictions are achieved using the proposed Curated Collaborative Learning (CCL) framework, which selectively collaborates with relevant correlated data for traffic forecasting. CCL optimally determines whom, when, and what to collaborate with, significantly outperforming state-of-the-art approaches, including global, federated, personalized federated, and cyclic institutional incremental learnings by 43.9%, 39.1%, 40.8%, and 31.35%, respectively. Second, the Distributed Unit Pooling Scheme (DUPS) is proposed, leveraging deep reinforcement learning and prediction inferences from CCL to reduce the number of active DU servers efficiently. DUPS dynamically redirects traffic from underutilized DU servers to optimize resource use, improving energy efficiency by up to 89% over conventional strategies, translating into substantial monetary benefits for operators. By integrating CCL-driven predictions with DUPS, this paper demonstrates a transformative approach for minimizing energy consumption and operational costs in 5G RANs, significantly enhancing efficiency and cost-effectiveness.",
      "authors": [
        "Sardar Jaffar Ali",
        "Syed M. Raza",
        "Duc-Tai Le",
        "Rajesh Challa",
        "Min Young Chung",
        "Ness Shroff",
        "Hyunseung Choo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T06:48:45+00:00",
          "link": "https://arxiv.org/abs/2507.01994v1",
          "size": "22564kb",
          "version": "v1"
        }
      ],
      "title": "Curated Collaborative AI Edge with Network Data Analytics for B5G/6G Radio Access Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01994",
        "HTML": "https://arxiv.org/html/2507.01994v1",
        "PDF": "https://arxiv.org/pdf/2507.01994"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research centers around reducing power consumption in radio access networks with network data analytics, which does not pertain to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.01997",
      "abstract": "Recent research has demonstrated the effectiveness of Artificial Intelligence (AI), and more specifically, Large Language Models (LLMs), in supporting network configuration synthesis and automating network diagnosis tasks, among others. In this preliminary work, we restrict our focus to the application of AI agents to network troubleshooting and elaborate on the need for a standardized, reproducible, and open benchmarking platform, where to build and evaluate AI agents with low operational effort.",
      "authors": [
        "Zhihao Wang",
        "Alessandro Cornacchia",
        "Franco Galante",
        "Carlo Centofanti",
        "Alessio Sacco",
        "Dingde Jiang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Artificial Intelligence (cs.AI)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T08:46:37+00:00",
          "link": "https://arxiv.org/abs/2507.01997v1",
          "size": "581kb",
          "version": "v1"
        }
      ],
      "title": "Towards a Playground to Democratize Experimentation and Benchmarking of AI Agents for Network Troubleshooting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01997",
        "HTML": "https://arxiv.org/html/2507.01997v1",
        "PDF": "https://arxiv.org/pdf/2507.01997"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on AI agents for network troubleshooting and the need for benchmarking platforms, with no mention of data processing or engineering in the context of training data for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.01998",
      "abstract": "Selecting relevant features is an important and necessary step for intelligent machines to maximize their chances of success. However, intelligent machines generally have no enough computing resources when faced with huge volume of data. This paper develops a new method based on sampling techniques and rough set theory to address the challenge of feature selection for massive data. To this end, this paper proposes using the ratio of discernible object pairs to all object pairs that should be distinguished to measure the discriminatory ability of a feature set. Based on this measure, a new feature selection method is proposed. This method constructs positive region preserved samples from massive data to find a feature subset with high discriminatory ability. Compared with other methods, the proposed method has two advantages. First, it is able to select a feature subset that can preserve the discriminatory ability of all the features of the target massive data set within an acceptable time on a personal computer. Second, the lower boundary of the probability of the object pairs that can be discerned using the feature subset selected in all object pairs that should be distinguished can be estimated before finding reducts. Furthermore, 11 data sets of different sizes were used to validate the proposed method. The results show that approximate reducts can be found in a very short period of time, and the discriminatory ability of the final reduct is larger than the estimated lower boundary. Experiments on four large-scale data sets also showed that an approximate reduct with high discriminatory ability can be obtained in reasonable time on a personal computer.",
      "authors": [
        "Hexiang Bai",
        "Deyu Li",
        "Jiye Liang",
        "Yanhui Zhai"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T09:54:46+00:00",
          "link": "https://arxiv.org/abs/2507.01998v1",
          "size": "391kb",
          "version": "v1"
        }
      ],
      "title": "Positive region preserved random sampling: an efficient feature selection method for massive data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01998",
        "HTML": "https://arxiv.org/html/2507.01998v1",
        "PDF": "https://arxiv.org/pdf/2507.01998"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is centered around feature selection methods for massive data using sampling techniques and rough set theory, which is not related to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.01999",
      "abstract": "Semiconductor manufacturing is an extremely complex process, characterized by thousands of interdependent parameters collected across diverse tools and process steps. Multi-variate time-series (MTS) analysis has emerged as a critical methodology for enabling real-time monitoring, fault detection, and predictive maintenance in such environments. However, anomaly prediction in semiconductor fabrication presents several critical challenges, including high data dimensionality, severe class imbalance due to the rarity of true faults, noisy and missing measurements, and non-stationary behavior of production systems. Furthermore, the complex interdependencies between variables and the delayed emergence of faults across downstream stages complicate both anomaly detection and root-cause-analysis. This paper presents a novel and generic approach for anomaly detection in MTS data using machine learning. The proposed methodology consists of three main steps: a) converting MTS data into image-based representations using the Continuous Wavelet Transform, b) developing a multi-class image classifier by fine-tuning a pretrained VGG-16 architecture on custom CWT image datasets, and c) constructing a Siamese network composed of two identical sub-networks, each utilizing the fine-tuned VGG-16 as a backbone. The network takes pairs of CWT images as input -one serving as a reference or anchor (representing a known-good signal), and the other as a query (representing an unknown signal). The model then compares the embeddings of both inputs to determine whether they belong to the same class at a given time step. Our approach demonstrates high accuracy in identifying anomalies on a real FAB process time-series dataset, offering a promising solution for offline anomaly detection in process and tool trace data. Moreover, the approach is flexible and can be applied in both supervised and semi-supervised settings.",
      "authors": [
        "Bappaditya Dey and Daniel Sorensen and Minjin Hwang and Sandip Halder"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T11:10:19+00:00",
          "link": "https://arxiv.org/abs/2507.01999v1",
          "size": "8349kb",
          "version": "v1"
        }
      ],
      "title": "Continuous Wavelet Transform and Siamese Network-Based Anomaly Detection in Multi-variate Semiconductor Process Time Series",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01999",
        "HTML": "https://arxiv.org/html/2507.01999v1",
        "PDF": "https://arxiv.org/pdf/2507.01999"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses anomaly detection in semiconductor processes using MTS data and machine learning, without addressing training data processing for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02000",
      "abstract": "Unfairness is a well-known challenge in Recommender Systems (RSs), often resulting in biased outcomes that disadvantage users or items based on attributes such as gender, race, age, or popularity. Although some approaches have started to improve fairness recommendation in offline or static contexts, the issue of unfairness often exacerbates over time, leading to significant problems like the Matthew effect, filter bubbles, and echo chambers. To address these challenges, we proposed a novel framework, Hypergraph Contrastive Multi-Interest Learning for Fair Conversational Recommender System (HyFairCRS), aiming to promote multi-interest diversity fairness in dynamic and interactive Conversational Recommender Systems (CRSs). HyFairCRS first captures a wide range of user interests by establishing diverse hypergraphs through contrastive learning. These interests are then utilized in conversations to generate informative responses and ensure fair item predictions within the dynamic user-system feedback loop. Experiments on two CRS-based datasets show that HyFairCRS achieves a new state-of-the-art performance while effectively alleviating unfairness. Our code is available at https://github.com/zysensmile/HyFairCRS.",
      "authors": [
        "Yongsen Zheng",
        "Zongxuan Xie",
        "Guohua Wang",
        "Ziyao Liu",
        "Liang Lin",
        "Kwok-Yan Lam"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Computation and Language (cs.CL)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T11:39:42+00:00",
          "link": "https://arxiv.org/abs/2507.02000v1",
          "size": "2915kb",
          "version": "v1"
        }
      ],
      "title": "Why Multi-Interest Fairness Matters: Hypergraph Contrastive Multi-Interest Learning for Fair Conversational Recommender System",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02000",
        "HTML": "https://arxiv.org/html/2507.02000v1",
        "PDF": "https://arxiv.org/pdf/2507.02000"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on fairness in recommender systems, particularly in conversational systems, without any mention of data processing specific to LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02001",
      "abstract": "Despite recent advances in Vision-Language Models (VLMs), long-video understanding remains a challenging problem. Although state-of-the-art long-context VLMs can process around 1000 input frames, they still struggle to effectively leverage this sequence length, and succumb to irrelevant distractors within the context window. We present Temporal Chain of Thought, an inference strategy for video question-answering that curates the model's input context. We use the VLM itself to iteratively identify and extract the most relevant frames from the video, which are then used for answering. We demonstrate how leveraging more computation at inference-time to select the most relevant context leads to improvements in accuracy, in agreement with recent work on inference-time scaling of LLMs. Moreover, we achieve state-of-the-art results on 4 diverse video question-answering datasets, showing consistent improvements with 3 different VLMs. In particular, our method shines on longer videos which would not otherwise fit within the model's context window: On longer videos of more than 1 hour on LVBench, our approach using a context window of 32K outperforms the same VLM using standard inference with a 700K context window by 2.8 points.",
      "authors": [
        "Anurag Arnab",
        "Ahmet Iscen",
        "Mathilde Caron",
        "Alireza Fathi",
        "Cordelia Schmid"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T18:39:26+00:00",
          "link": "https://arxiv.org/abs/2507.02001v1",
          "size": "1653kb",
          "version": "v1"
        }
      ],
      "title": "Temporal Chain of Thought: Long-Video Understanding by Thinking in Frames",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02001",
        "HTML": "https://arxiv.org/html/2507.02001v1",
        "PDF": "https://arxiv.org/pdf/2507.02001"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents methods for long-video understanding using a temporal chain of thought in video question-answering, and does not pertain to training data processing for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02002",
      "abstract": "Large language models (LLMs) demonstrate strong reasoning abilities across mathematical, strategic, and linguistic tasks, yet little is known about how well they reason in dynamic, real-time, multi-agent scenarios, such as collaborative environments in which agents continuously adapt to each other's behavior, as in cooperative gameplay settings. In this paper, we bridge this gap by combining LLM-driven agents with strategic reasoning and real-time adaptation in cooperative, multi-agent environments grounded in game-theoretic principles such as belief consistency and Nash equilibrium. The proposed framework applies broadly to dynamic scenarios in which agents coordinate, communicate, and make decisions in response to continuously changing conditions. We provide real-time strategy refinement and adaptive feedback mechanisms that enable agents to dynamically adjust policies based on immediate contextual interactions, in contrast to previous efforts that evaluate LLM capabilities in static or turn-based settings. Empirical results show that our method achieves up to a 26\\% improvement in return over PPO baselines in high-noise environments, while maintaining real-time latency under 1.05 milliseconds. Our approach improves collaboration efficiency, task completion rates, and flexibility, illustrating that game-theoretic guidance integrated with real-time feedback enhances LLM performance, ultimately fostering more resilient and flexible strategic multi-agent systems.",
      "authors": [
        "Shaurya Mallampati",
        "Rashed Shelim",
        "Walid Saad",
        "and Naren Ramakrishnan"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T20:09:50+00:00",
          "link": "https://arxiv.org/abs/2507.02002v1",
          "size": "11882kb",
          "version": "v1"
        }
      ],
      "title": "Dynamic Strategy Adaptation in Multi-Agent Environments with Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02002",
        "HTML": "https://arxiv.org/html/2507.02002v1",
        "PDF": "https://arxiv.org/pdf/2507.02002"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on multi-agent strategy adaptation using LLMs in dynamic environments, with an emphasis on multi-agent scenarios and game-theoretic principles, rather than any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02004",
      "abstract": "The rapid growth of biomedical data, tools, and literature has created a fragmented research landscape that outpaces human expertise. While AI agents offer a solution, they typically rely on static, manually curated toolsets, limiting their ability to adapt and scale. Here, we introduce STELLA, a self-evolving AI agent designed to overcome these limitations. STELLA employs a multi-agent architecture that autonomously improves its own capabilities through two core mechanisms: an evolving Template Library for reasoning strategies and a dynamic Tool Ocean that expands as a Tool Creation Agent automatically discovers and integrates new bioinformatics tools. This allows STELLA to learn from experience. We demonstrate that STELLA achieves state-of-the-art accuracy on a suite of biomedical benchmarks, scoring approximately 26\\% on Humanity's Last Exam: Biomedicine, 54\\% on LAB-Bench: DBQA, and 63\\% on LAB-Bench: LitQA, outperforming leading models by up to 6 percentage points. More importantly, we show that its performance systematically improves with experience; for instance, its accuracy on the Humanity's Last Exam benchmark almost doubles with increased trials. STELLA represents a significant advance towards AI Agent systems that can learn and grow, dynamically scaling their expertise to accelerate the pace of biomedical discovery.",
      "authors": [
        "Ruofan Jin",
        "Zaixi Zhang",
        "Mengdi Wang",
        "Le Cong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Biomolecules (q-bio.BM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T20:52:01+00:00",
          "link": "https://arxiv.org/abs/2507.02004v1",
          "size": "3432kb",
          "version": "v1"
        }
      ],
      "title": "STELLA: Self-Evolving LLM Agent for Biomedical Research",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02004",
        "HTML": "https://arxiv.org/html/2507.02004v1",
        "PDF": "https://arxiv.org/pdf/2507.02004"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the development of a self-evolving AI agent in the realm of biomedical research. While it mentions tool integration and strategy improvements, it does not address LLM training data processing for LLM development."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02005",
      "abstract": "This research introduces a unified approach combining Automated Machine Learning (AutoML) with Explainable Artificial Intelligence (XAI) to predict fatigue strength in welded transverse stiffener details. It integrates expert-driven feature engineering with algorithmic feature creation to enhance accuracy and explainability.\n  Based on the extensive fatigue test database regression models - gradient boosting, random forests, and neural networks - were trained using AutoML under three feature schemes: domain-informed, algorithmic, and combined. This allowed a systematic comparison of expert-based versus automated feature selection.\n  Ensemble methods (e.g. CatBoost, LightGBM) delivered top performance. The domain-informed model $\\mathcal M_2$ achieved the best balance: test RMSE $\\approx$ 30.6 MPa and $R^2 \\approx 0.780% over the full $\\Delta \\sigma_{c,50\\%}$ range, and RMSE $\\approx$ 13.4 MPa and $R^2 \\approx 0.527% within the engineering-relevant 0 - 150 MPa domain. The denser-feature model ($\\mathcal M_3$) showed minor gains during training but poorer generalization, while the simpler base-feature model ($\\mathcal M_1$) performed comparably, confirming the robustness of minimalist designs.\n  XAI methods (SHAP and feature importance) identified stress ratio $R$, stress range $\\Delta \\sigma_i$, yield strength $R_{eH}$, and post-weld treatment (TIG dressing vs. as-welded) as dominant predictors. Secondary geometric factors - plate width, throat thickness, stiffener height - also significantly affected fatigue life.\n  This framework demonstrates that integrating AutoML with XAI yields accurate, interpretable, and robust fatigue strength models for welded steel structures. It bridges data-driven modeling with engineering validation, enabling AI-assisted design and assessment. Future work will explore probabilistic fatigue life modeling and integration into digital twin environments.",
      "authors": [
        "Michael A. Kraus",
        "Helen Bartsch"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T21:57:12+00:00",
          "link": "https://arxiv.org/abs/2507.02005v1",
          "size": "6705kb",
          "version": "v1"
        }
      ],
      "title": "Discovery of Fatigue Strength Models via Feature Engineering and automated eXplainable Machine Learning applied to the welded Transverse Stiffener",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02005",
        "HTML": "https://arxiv.org/html/2507.02005v1",
        "PDF": "https://arxiv.org/pdf/2507.02005"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research introduces a framework for modeling fatigue strength using AutoML and XAI but is unrelated to LLM training data processing or enhancement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02006",
      "abstract": "Graph convolutional networks (GCNs) are fundamental in various scientific applications, ranging from biomedical protein-protein interactions (PPI) to large-scale recommendation systems. An essential component for modeling graph structures in GCNs is sparse general matrix-matrix multiplication (SpGEMM). As the size of graph data continues to scale up, SpGEMMs are often conducted in an out-of-core fashion due to limited GPU memory space in resource-constrained systems. Albeit recent efforts that aim to alleviate the memory constraints of out-of-core SpGEMM through either GPU feature caching, hybrid CPU-GPU memory layout, or performing the computation in sparse format, current systems suffer from both high I/O latency and GPU under-utilization issues.\n  In this paper, we first identify the problems of existing systems, where sparse format data alignment and memory allocation are the main performance bottlenecks, and propose AIRES, a novel algorithm-system co-design solution to accelerate out-of-core SpGEMM computation for GCNs. Specifically, from the algorithm angle, AIRES proposes to alleviate the data alignment issues on the block level for matrices in sparse formats and develops a tiling algorithm to facilitate row block-wise alignment. On the system level, AIRES employs a three-phase dynamic scheduling that features a dual-way data transfer strategy utilizing a tiered memory system: integrating GPU memory, GPU Direct Storage (GDS), and host memory to reduce I/O latency and improve throughput. Evaluations show that AIRES significantly outperforms the state-of-the-art methods, achieving up to 1.8x lower latency in real-world graph processing benchmarks.",
      "authors": [
        "Shakya Jayakody",
        "Youpeng Zhao",
        "Jun Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T00:35:43+00:00",
          "link": "https://arxiv.org/abs/2507.02006v1",
          "size": "2212kb",
          "version": "v1"
        }
      ],
      "title": "AIRES: Accelerating Out-of-Core GCNs via Algorithm-System Co-Design",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02006",
        "HTML": "https://arxiv.org/html/2507.02006v1",
        "PDF": "https://arxiv.org/pdf/2507.02006"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on accelerating graph convolutional networks performance through a novel algorithm for sparse format computation. It does not involve any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02008",
      "abstract": "SAT sweeping has long been a cornerstone technique in logic simplification and equivalence checking at the bit level, leveraging structural hashing, simulation and SAT solving to prune redundant logic. However, with the growing adoption of word-level constructs in hardware verification, such as bit-vector operations, arithmetics and arrays, there lacks a counterpart of SAT sweeping at the word level. In this paper, we introduce SMT-Sweep, a novel extension of SAT sweeping into the word level, grounded in Satisfiability Modulo Theories (SMT). SMT-Sweep takes advantage of simulation and equivalence detection to handle SMT terms with rich bit-vector operations and array semantics. Our framework incorporates both randomized and constraint-driven word-level simulation tailored to symbolic expressions and operator semantics beyond pure Boolean logic. Experimental results show that SMT-Sweep achieves significant speed-up compared to state-of-the-art bit-level SAT sweeping and word-level monolithic SMT solving (averaging around 44x and 69x, respectively).To the best of our knowledge, this is the first work that brings sweeping techniques to SMT-based hardware verification. The implementation is open-sourced at: https://github.com/yangziyiiii/SMT-Sweep.",
      "authors": [
        "Ziyi Yang",
        "Guangyu Hu",
        "Mingkai Miao",
        "Changyuan Yu",
        "Hongce Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T03:34:36+00:00",
          "link": "https://arxiv.org/abs/2507.02008v1",
          "size": "316kb",
          "version": "v1"
        }
      ],
      "title": "SMT-Sweep: Word-Level Representation Unification for Hardware Verification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02008",
        "HTML": "https://arxiv.org/html/2507.02008v1",
        "PDF": "https://arxiv.org/pdf/2507.02008"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a new word-level technique in SAT sweeping for hardware verification, without any mention or contribution to LLM training data processing or manipulation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02009",
      "abstract": "Table structure recognition (TSR) and optical character recognition (OCR) play crucial roles in extracting structured data from tables in scientific documents. However, existing extraction frameworks built on top of TSR and OCR methods often fail to quantify the uncertainties of extracted results. To obtain highly accurate data for scientific domains, all extracted data must be manually verified, which can be time-consuming and labor-intensive. We propose a framework that performs uncertainty-aware data extraction for complex scientific tables, built on conformal prediction, a model-agnostic method for uncertainty quantification (UQ). We explored various uncertainty scoring methods to aggregate the uncertainties introduced by TSR and OCR. We rigorously evaluated the framework using a standard benchmark and an in-house dataset consisting of complex scientific tables in six scientific domains. The results demonstrate the effectiveness of using UQ for extraction error detection, and by manually verifying only 47\\% of extraction results, the data quality can be improved by 30\\%. Our work quantitatively demonstrates the role of UQ with the potential of improving the efficiency in the human-machine cooperation process to obtain scientifically usable data from complex tables in scientific documents. All code and data are available on GitHub at https://github.com/lamps-lab/TSR-OCR-UQ/tree/main.",
      "authors": [
        "Kehinde Ajayi",
        "Yi He",
        "Jian Wu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T03:36:15+00:00",
          "link": "https://arxiv.org/abs/2507.02009v1",
          "size": "1321kb",
          "version": "v1"
        }
      ],
      "title": "Uncertainty-Aware Complex Scientific Table Data Extraction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02009",
        "HTML": "https://arxiv.org/html/2507.02009v1",
        "PDF": "https://arxiv.org/pdf/2507.02009"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses a framework for uncertainty-aware data extraction from scientific tables, which involves methods for improving data quality. However, it focuses on data extraction and verification, not on LLM training data processing specifically."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02013",
      "abstract": "The Internet of Vehicles (IoV) transforms the transportation ecosystem promising pervasive connectivity and data-driven approaches. Deep learning and generative Artificial Intelligence (AI) have the potential to significantly enhance the operation of applications within IoV by facilitating efficient decision-making and predictive capabilities, including intelligent navigation, vehicle safety monitoring, accident prevention, and intelligent traffic management. Nevertheless, efficiently transmitting and processing the massive volumes of data generated by the IoV in real-time remains a significant challenge, particularly in dynamic and unpredictable wireless channel conditions. To address these challenges, this paper proposes a semantic communication framework based on channel perception to improve the accuracy and efficiency of data transmission. The semantic communication model extracts and compresses the information to be transmitted. In addition, the wireless channel is estimated by using a generative diffusion model, which is employed to predict the dynamic channel states, thereby improving the quality of IoV service. In dynamic scenarios, however, the channel estimation performance may be degraded when substantially new scenarios take place, which will adversely affect user experience. To mitigate this limitation, we employ a large model to fine-tune the channel generation model to enhance its adaptability for varying scenarios. The performance and reliability of the proposed framework are evaluated on the two public datasets.",
      "authors": [
        "Hao Liu",
        "Bo Yang",
        "Zhiwen Yu",
        "Xuelin Cao",
        "George C. Alexandropoulos",
        "Yan Zhang",
        "and Chau Yuen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T08:41:42+00:00",
          "link": "https://arxiv.org/abs/2507.02013v1",
          "size": "5372kb",
          "version": "v1"
        }
      ],
      "title": "AI-Empowered Channel Generation for IoV Semantic Communications in Dynamic Conditions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02013",
        "HTML": "https://arxiv.org/html/2507.02013v1",
        "PDF": "https://arxiv.org/pdf/2507.02013"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on semantic communications and channel prediction in IoV scenarios, with no mention of LLM training data processing or any related methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02014",
      "abstract": "We introduce ManifoldMind, a probabilistic geometric recommender system for exploratory reasoning over semantic hierarchies in hyperbolic space. Unlike prior methods with fixed curvature and rigid embeddings, ManifoldMind represents users, items, and tags as adaptive-curvature probabilistic spheres, enabling personalised uncertainty modeling and geometry-aware semantic exploration. A curvature-aware semantic kernel supports soft, multi-hop inference, allowing the model to explore diverse conceptual paths instead of overfitting to shallow or direct interactions. Experiments on four public benchmarks show superior NDCG, calibration, and diversity compared to strong baselines. ManifoldMind produces explicit reasoning traces, enabling transparent, trustworthy, and exploration-driven recommendations in sparse or abstract domains.",
      "authors": [
        "Anoushka Harit",
        "Zhongtian Sun and Suncica Hadzidedic"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T08:42:11+00:00",
          "link": "https://arxiv.org/abs/2507.02014v1",
          "size": "2812kb",
          "version": "v1"
        }
      ],
      "title": "ManifoldMind: Dynamic Hyperbolic Reasoning for Trustworthy Recommendations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02014",
        "HTML": "https://arxiv.org/html/2507.02014v1",
        "PDF": "https://arxiv.org/pdf/2507.02014"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "ManifoldMind is about a recommender system using probabilistic geometric models and does not discuss LLM training data processing or any related tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02016",
      "abstract": "When robots perform complex and context-dependent tasks in our daily lives, deviations from expectations can confuse users. Explanations of the robot's reasoning process can help users to understand the robot intentions. However, when to provide explanations and what they contain are important to avoid user annoyance. We have investigated user preferences for explanation demand and content for a robot that helps with daily cleaning tasks in a kitchen. Our results show that users want explanations in surprising situations and prefer concise explanations that clearly state the intention behind the confusing action and the contextual factors that were relevant to this decision. Based on these findings, we propose two algorithms to identify surprising actions and to construct effective explanations for Belief-Desire-Intention (BDI) robots. Our algorithms can be easily integrated in the BDI reasoning process and pave the way for better human-robot interaction with context- and user-specific explanations.",
      "authors": [
        "Cong Wang",
        "Roberto Calandra",
        "Verena Kl\\\"os"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T12:02:07+00:00",
          "link": "https://arxiv.org/abs/2507.02016v1",
          "size": "2372kb",
          "version": "v1"
        }
      ],
      "title": "Effective Explanations for Belief-Desire-Intention Robots: When and What to Explain",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02016",
        "HTML": "https://arxiv.org/html/2507.02016v1",
        "PDF": "https://arxiv.org/pdf/2507.02016"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper examines explanation algorithms for robots in the context of BDI frameworks, which is unrelated to LLM training data or preprocessing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02020",
      "abstract": "The lack of standardized tabular formats for tenancy schedules across real estate firms creates significant inefficiencies in data integration. Existing automated integration methods, such as Full Disjunction (FD)-based models like ALITE, prioritize completeness but result in schema bloat, sparse attributes and limited business usability. We propose a novel hybrid, template-based schema matcher that aligns multi-layout tenancy schedules to a predefined target schema. The matcher combines schema (Jaccard, Levenshtein) and instance-based metrics (data types, distributions) with globally optimal assignments determined via the Hungarian Algorithm. Evaluation against a manually labeled ground truth demonstrates substantial improvements, with grid search optimization yielding a peak F1-score of 0.881 and an overall null percentage of 45.7%. On a separate ground truth of 20 semantically similar column sets, ALITE achieves an F1-score of 0.712 and 75.6% nulls. These results suggest that combining structured business knowledge with hybrid matching can yield more usable and business-aligned schema mappings. The approach assumes cleanly extracted tabular input, future work could explore extending the matcher to support complex, composite tables.",
      "authors": [
        "Tim Uilkema",
        "Yao Ma",
        "Seyed Sahand Mohammadi Ziabari",
        "Joep van Vliet"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T14:37:31+00:00",
          "link": "https://arxiv.org/abs/2507.02020v1",
          "size": "235kb",
          "version": "v1"
        }
      ],
      "title": "Template-Based Schema Matching of Multi-Layout Tenancy Schedules:A Comparative Study of a Template-Based Hybrid Matcher and the ALITE Full Disjunction Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02020",
        "HTML": "https://arxiv.org/html/2507.02020v1",
        "PDF": "https://arxiv.org/pdf/2507.02020"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research addresses schema matching in real estate data integration, which is unrelated to training data processing for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02021",
      "abstract": "With the rise of Software-Defined Networking (SDN) for managing traffic and ensuring seamless operations across interconnected devices, challenges arise when SDN controllers share infrastructure with deep learning (DL) workloads. Resource contention between DL training and SDN operations, especially in latency-sensitive IoT environments, can degrade SDN's responsiveness and compromise network performance. Federated Learning (FL) helps address some of these concerns by decentralizing DL training to edge devices, thus reducing data transmission costs and enhancing privacy. Yet, the computational demands of DL training can still interfere with SDN's performance, especially under the continuous data streams characteristic of IoT systems. To mitigate this issue, we propose REDUS (Resampling for Efficient Data Utilization in Smart-Networks), a resampling technique that optimizes DL training by prioritizing misclassified samples and excluding redundant data, inspired by AdaBoost. REDUS reduces the number of training samples per epoch, thereby conserving computational resources, reducing energy consumption, and accelerating convergence without significantly impacting accuracy. Applied within an FL setup, REDUS enhances the efficiency of model training on resource-limited edge devices while maintaining network performance. In this paper, REDUS is evaluated on the CICIoT2023 dataset for IoT attack detection, showing a training time reduction of up to 72.6% with a minimal accuracy loss of only 1.62%, offering a scalable and practical solution for intelligent networks.",
      "authors": [
        "Eyad Gad",
        "Gad Gad",
        "Mostafa M. Fouda",
        "Mohamed I. Ibrahem",
        "Muhammad Ismail",
        "and Zubair Md Fadlullah"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T14:41:25+00:00",
          "link": "https://arxiv.org/abs/2507.02021v1",
          "size": "808kb",
          "version": "v1"
        }
      ],
      "title": "REDUS: Adaptive Resampling for Efficient Deep Learning in Centralized and Federated IoT Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02021",
        "HTML": "https://arxiv.org/html/2507.02021v1",
        "PDF": "https://arxiv.org/pdf/2507.02021"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses the REDUS technique for reducing training data in deep learning tasks within IoT networks, focusing somewhat on data efficiency, which is somewhat related to data processing methods relevant to LLMs but not directly focused on them."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02029",
      "abstract": "We introduce RoboBrain 2.0, our latest generation of embodied vision-language foundation models, designed to unify perception, reasoning, and planning for complex embodied tasks in physical environments. It comes in two variants: a lightweight 7B model and a full-scale 32B model, featuring a heterogeneous architecture with a vision encoder and a language model. Despite its compact size, RoboBrain 2.0 achieves strong performance across a wide spectrum of embodied reasoning tasks. On both spatial and temporal benchmarks, the 32B variant achieves leading results, surpassing prior open-source and proprietary models. In particular, it supports key real-world embodied AI capabilities, including spatial understanding (e.g., affordance prediction, spatial referring, trajectory forecasting) and temporal decision-making (e.g., closed-loop interaction, multi-agent long-horizon planning, and scene graph updating). This report details the model architecture, data construction, multi-stage training strategies, infrastructure and practical applications. We hope RoboBrain 2.0 advances embodied AI research and serves as a practical step toward building generalist embodied agents. The code, checkpoint and benchmark are available at https://superrobobrain.github.io.",
      "authors": [
        "BAAI RoboBrain Team",
        "Mingyu Cao",
        "Huajie Tan",
        "Yuheng Ji",
        "Minglan Lin",
        "Zhiyu Li",
        "Zhou Cao",
        "Pengwei Wang",
        "Enshen Zhou",
        "Yi Han",
        "Yingbo Tang",
        "Xiangqi Xu",
        "Wei Guo",
        "Yaoxu Lyu",
        "Yijie Xu",
        "Jiayu Shi",
        "Cheng Chi",
        "Mengdi Zhao",
        "Xiaoshuai Hao",
        "Shanyu Rong",
        "Zhengliang Cai",
        "Bolun Zhang",
        "Shuyi Zhang",
        "Huaihai Lyu",
        "Mengfei Du",
        "Lingfeng Zhang",
        "Xi Feng",
        "Xiaodan Liu",
        "Yance Jiao",
        "Chenrui He",
        "Mengsi Lyu",
        "Zhuo Chen",
        "Yulong Ao",
        "Xue Sun",
        "Zheqi He",
        "Jingshu Zheng",
        "Xi Yang",
        "Donghai Shi",
        "Kunchang Xie",
        "Bochao Zhang",
        "Shaokai Nie",
        "Chunlei Men",
        "Yonghua Lin",
        "Zhongyuan Wang",
        "Tiejun Huang",
        "Shanghang Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T17:05:33+00:00",
          "link": "https://arxiv.org/abs/2507.02029v1",
          "size": "28858kb",
          "version": "v1"
        }
      ],
      "title": "RoboBrain 2.0 Technical Report",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02029",
        "PDF": "https://arxiv.org/pdf/2507.02029"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "RoboBrain 2.0 includes a description of data construction and multi-stage training strategies, which is somewhat related to training-stage data processing for LLMs but is not the primary focus."
      },
      "models": [
        {
          "model_path": "BAAI/RoboBrain2.0-32B",
          "downloads": "11",
          "likes": "9",
          "trending_score": "9.0",
          "link": "https://huggingface.co/BAAI/RoboBrain2.0-32B"
        },
        {
          "model_path": "BAAI/RoboBrain2.0-7B",
          "downloads": "3931",
          "likes": "84",
          "trending_score": "4.0",
          "link": "https://huggingface.co/BAAI/RoboBrain2.0-7B"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.02057",
      "abstract": "Large language models (LLMs) have democratized software development, reducing the expertise barrier for programming complex applications. This accessibility extends to malicious software development, raising significant security concerns. While LLM providers have implemented alignment mechanisms to prevent direct generation of overtly malicious code, these safeguards predominantly evaluate individual prompts in isolation, overlooking a critical vulnerability: malicious operations can be systematically decomposed into benign-appearing sub-tasks. In this paper, we introduce the Malware Generation Compiler (MGC), a novel framework that leverages this vulnerability through modular decomposition and alignment-evasive generation. MGC employs a specialized Malware Description Intermediate Representation (MDIR) to bridge high-level malicious intents and benign-appearing code snippets. Extensive evaluation demonstrates that our attack reliably generates functional malware across diverse task specifications and categories, outperforming jailbreaking methods by +365.79% and underground services by +78.07% in correctness on three benchmark datasets. Case studies further show that MGC can reproduce and even enhance 16 real-world malware samples. This work provides critical insights for security researchers by exposing the risks of compositional attacks against aligned AI systems. Demonstrations are available at https://sites.google.com/view/malware-generation-compiler.",
      "authors": [
        "Lu Yan",
        "Zhuo Zhang",
        "Xiangzhe Xu",
        "Shengwei An",
        "Guangyu Shen",
        "Zhou Xuan",
        "Xuan Chen",
        "Xiangyu Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T18:00:49+00:00",
          "link": "https://arxiv.org/abs/2507.02057v1",
          "size": "8194kb",
          "version": "v1"
        }
      ],
      "title": "MGC: A Compiler Framework Exploiting Compositional Blindness in Aligned LLMs for Malware Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02057",
        "HTML": "https://arxiv.org/html/2507.02057v1",
        "PDF": "https://arxiv.org/pdf/2507.02057"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the security implications of LLMs in malware generation, not on the processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02061",
      "abstract": "Let $G=(V,E)$ be an unweighted undirected graph with $n$ vertices and $m$ edges. Let $g$ be the girth of $G$, that is, the length of a shortest cycle in $G$. We present a randomized algorithm with a running time of $\\tilde{O}\\big(\\ell \\cdot n^{1 + \\frac{1}{\\ell - \\varepsilon}}\\big)$ that returns a cycle of length at most $ 2\\ell \\left\\lceil \\frac{g}{2} \\right\\rceil - 2 \\left\\lfloor \\varepsilon \\left\\lceil \\frac{g}{2} \\right\\rceil \\right\\rfloor, $ where $\\ell \\geq 2$ is an integer and $\\varepsilon \\in [0,1]$, for every graph with $g = polylog(n)$.\n  Our algorithm generalizes an algorithm of Kadria \\etal{} [SODA'22] that computes a cycle of length at most $4\\left\\lceil \\frac{g}{2} \\right\\rceil - 2\\left\\lfloor \\varepsilon \\left\\lceil \\frac{g}{2} \\right\\rceil \\right\\rfloor $ in $\\tilde{O}\\big(n^{1 + \\frac{1}{2 - \\varepsilon}}\\big)$ time. Kadria \\etal{} presented also an algorithm that finds a cycle of length at most $ 2\\ell \\left\\lceil \\frac{g}{2} \\right\\rceil $ in $\\tilde{O}\\big(n^{1 + \\frac{1}{\\ell}}\\big)$ time, where $\\ell$ must be an integer. Our algorithm generalizes this algorithm, as well, by replacing the integer parameter $\\ell$ in the running time exponent with a real-valued parameter $\\ell - \\varepsilon$, thereby offering greater flexibility in parameter selection and enabling a broader spectrum of combinations between running times and cycle lengths.\n  We also show that for sparse graphs a better tradeoff is possible, by presenting an $\\tilde{O}(\\ell\\cdot m^{1+1/(\\ell-\\varepsilon)})$ time randomized algorithm that returns a cycle of length at most $2\\ell(\\lfloor \\frac{g-1}{2}\\rfloor) - 2(\\lfloor \\varepsilon \\lfloor \\frac{g-1}{2}\\rfloor \\rfloor+1)$, where $\\ell\\geq 3$ is an integer and $\\varepsilon\\in [0,1)$, for every graph with $g=polylog(n)$.\n  To obtain our algorithms we develop several techniques and introduce a formal definition of hybrid cycle detection algorithms. [...]",
      "authors": [
        "Liam Roditty and Plia Trabelsi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T18:01:30+00:00",
          "link": "https://arxiv.org/abs/2507.02061v1",
          "size": "41kb",
          "version": "v1"
        }
      ],
      "title": "New algorithms for girth and cycle detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02061",
        "HTML": "https://arxiv.org/html/2507.02061v1",
        "PDF": "https://arxiv.org/pdf/2507.02061"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses algorithms related to graph theory (girth and cycle detection) with no mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02067",
      "abstract": "Printed sensors represent a transformative advancement in sensor technology, utilizing innovative printing techniques to create flexible, cost-effective, and highly customizable sensing devices. Their versatility allows integration into numerous applications across diverse fields such as monitoring a wide range of environmental factors e.g. air and water quality, soil conditions, and atmospheric changes among others. These sensors demonstrate high sensitivity and accuracy in detecting pollutants, temperature variations, humidity levels, and other critical parameters essential for environmental assessment and protection.",
      "authors": [
        "Nikolaos Papanikolaou",
        "Doha Touhafi",
        "Jurgen Vandendriessche",
        "Danial Karimi",
        "Sohail Fatimi",
        "Gianluca Cornetta and Abdellah Touhafi"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T18:06:07+00:00",
          "link": "https://arxiv.org/abs/2507.02067v1",
          "size": "5621kb",
          "version": "v1"
        }
      ],
      "title": "Advanced Printed Sensors for Environmental Applications: A Path Towards Sustainable Monitoring Solutions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02067",
        "HTML": "https://arxiv.org/html/2507.02067v1",
        "PDF": "https://arxiv.org/pdf/2507.02067"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about printed sensors for environmental applications and does not involve any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02068",
      "abstract": "To obtain employment, aspiring software engineers must complete technical interviews -- a hiring process which involves candidates writing code while communicating to an audience. However, the complexities of tech interviews are difficult to prepare for and seldom faced in computing curricula. To this end, we seek to understand how candidates prepare for technical interviews, investigating the effects of preparation methods and the role of education. We distributed a survey to candidates (n = 131) actively preparing for technical interviews. Our results suggest candidates rarely train in authentic settings and courses fail to support preparation efforts -- leading to stress and unpreparedness. Based on our findings, we provide implications for stakeholders to enhance tech interview preparation for candidates pursuing software engineering roles.",
      "authors": [
        "Brian Bell and Teresa Thomas and Sang Won Lee and Chris Brown"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T18:06:11+00:00",
          "link": "https://arxiv.org/abs/2507.02068v1",
          "size": "526kb",
          "version": "v1"
        }
      ],
      "title": "How do Software Engineering Candidates Prepare for Technical Interviews?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02068",
        "HTML": "https://arxiv.org/html/2507.02068v1",
        "PDF": "https://arxiv.org/pdf/2507.02068"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about candidates preparing for technical interviews in software engineering and does not focus on LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02073",
      "abstract": "In this paper, we propose HCVR (Hybrid approach with Correlation-aware Voting Rules), a lightweight rule-based feature selection method that combines Parameter-to-Parameter (P2P) and Parameter-to-Target (P2T) correlations to eliminate redundant features and retain relevant ones. This method is a hybrid of non-iterative and iterative filtering approaches for dimensionality reduction. It is a greedy method, which works by backward elimination, eliminating possibly multiple features at every step. The rules contribute to voting for features, and a decision to keep or discard is made by majority voting. The rules make use of correlation thresholds between every pair of features, and between features and the target. We provide the results from the application of HCVR to the SPAMBASE dataset. The results showed improvement performance as compared to traditional non-iterative (CFS, mRMR and MI) and iterative (RFE, SFS and Genetic Algorithm) techniques. The effectiveness was assessed based on the performance of different classifiers after applying filtering.",
      "authors": [
        "Nikita Bhedasgaonkar",
        "Rushikesh K. Joshi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T18:20:56+00:00",
          "link": "https://arxiv.org/abs/2507.02073v1",
          "size": "319kb",
          "version": "v1"
        }
      ],
      "title": "HCVR: A Hybrid Approach with Correlation-aware Voting Rules for Feature Selection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02073",
        "HTML": "https://arxiv.org/html/2507.02073v1",
        "PDF": "https://arxiv.org/pdf/2507.02073"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a feature selection method (HCVR) for dimensionality reduction in datasets, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02074",
      "abstract": "Crash detection from video feeds is a critical problem in intelligent transportation systems. Recent developments in large language models (LLMs) and vision-language models (VLMs) have transformed how we process, reason about, and summarize multimodal information. This paper surveys recent methods leveraging LLMs for crash detection from video data. We present a structured taxonomy of fusion strategies, summarize key datasets, analyze model architectures, compare performance benchmarks, and discuss ongoing challenges and opportunities. Our review provides a foundation for future research in this fast-growing intersection of video understanding and foundation models.",
      "authors": [
        "Sanjeda Akter",
        "Ibne Farabi Shihab",
        "Anuj Sharma"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T18:21:01+00:00",
          "link": "https://arxiv.org/abs/2507.02074v1",
          "size": "447kb",
          "version": "v1"
        }
      ],
      "title": "Large Language Models for Crash Detection in Video: A Survey of Methods, Datasets, and Challenges",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02074",
        "HTML": "https://arxiv.org/html/2507.02074v1",
        "PDF": "https://arxiv.org/pdf/2507.02074"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper mentions a survey of methods and datasets for crash detection but primarily focuses on the application of LLMs to video data, not on constructing or processing LLM training data itself."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02076",
      "abstract": "Large language models (LLMs) have rapidly progressed into general-purpose agents capable of solving a broad spectrum of tasks. However, current models remain inefficient at reasoning: they apply fixed inference-time compute regardless of task complexity, often overthinking simple problems while underthinking hard ones. This survey presents a comprehensive review of efficient test-time compute (TTC) strategies, which aim to improve the computational efficiency of LLM reasoning. We introduce a two-tiered taxonomy that distinguishes between L1-controllability, methods that operate under fixed compute budgets, and L2-adaptiveness, methods that dynamically scale inference based on input difficulty or model confidence. We benchmark leading proprietary LLMs across diverse datasets, highlighting critical trade-offs between reasoning performance and token usage. Compared to prior surveys on efficient reasoning, our review emphasizes the practical control, adaptability, and scalability of TTC methods. Finally, we discuss emerging trends such as hybrid thinking models and identify key challenges for future work towards making LLMs more computationally efficient, robust, and responsive to user constraints.",
      "authors": [
        "Mohammad Ali Alomrani",
        "Yingxue Zhang",
        "Derek Li",
        "Qianyi Sun",
        "Soumyasundar Pal",
        "Zhanguang Zhang",
        "Yaochen Hu",
        "Rohan Deepak Ajwani",
        "Antonios Valkanas",
        "Raika Karimi",
        "Peng Cheng",
        "Yunzhou Wang",
        "Pengyi Liao",
        "Hanrui Huang",
        "Bin Wang",
        "Jianye Hao",
        "Mark Coates"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T18:27:42+00:00",
          "link": "https://arxiv.org/abs/2507.02076v1",
          "size": "195kb",
          "version": "v1"
        }
      ],
      "title": "Reasoning on a Budget: A Survey of Adaptive and Controllable Test-Time Compute in LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02076",
        "HTML": "https://arxiv.org/html/2507.02076v1",
        "PDF": "https://arxiv.org/pdf/2507.02076"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper reviews efficient test-time compute strategies for LLM reasoning, focusing on compute efficiency, not training data processing or construction."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02078",
      "abstract": "Accurate and scalable surrogate models for AC power flow are essential for real-time grid monitoring, contingency analysis, and decision support in increasingly dynamic and inverter-dominated power systems. However, most existing surrogates fall short of practical deployment due to their limited capacity to capture long-range nonlinear dependencies in meshed transmission networks and their weak enforcement of physical laws. These models often require extensive hyperparameter tuning, exhibit poor generalization under topology changes or large load swings, and typically do not quantify uncertainty or scale well beyond a few hundred buses. To address these challenges, this paper proposes a \\textit{gated graph neural network (GGNN)} surrogate for AC power-flow estimation under topological uncertainty. The model is trained across multiple IEEE benchmark networks of varying size and complexity, each incorporating randomized line contingencies and up to 40\\% load variation. To improve robustness and generalization, we explore both conventional supervised learning and physics-informed self-supervised training strategies. Comparative evaluations show that the proposed GGNN consistently outperforms prior GNN-based surrogates, achieving predictions closely aligned with Newton--Raphson solutions. By embedding operational constraints directly into the architecture and loss function, the model ensures physical consistency and delivers a lightweight, accurate, and scalable tool for real-time grid operations.",
      "authors": [
        "Shrenik Jadhav",
        "Birva Sevak",
        "Srijita Das",
        "Wencong Su",
        "and Van-Hai Bui"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T18:29:47+00:00",
          "link": "https://arxiv.org/abs/2507.02078v1",
          "size": "1301kb",
          "version": "v1"
        }
      ],
      "title": "Enhancing Power Flow Estimation with Topology-Aware Gated Graph Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02078",
        "PDF": "https://arxiv.org/pdf/2507.02078"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on using gated graph neural networks for power flow estimation, with no relation to LLM training data processing or construction."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02080",
      "abstract": "Multimodal emotion recognition often suffers from performance degradation in valence-arousal estimation due to noise and misalignment between audio and visual modalities. To address this challenge, we introduce TAGF, a Time-aware Gated Fusion framework for multimodal emotion recognition. The TAGF adaptively modulates the contribution of recursive attention outputs based on temporal dynamics. Specifically, the TAGF incorporates a BiLSTM-based temporal gating mechanism to learn the relative importance of each recursive step and effectively integrates multistep cross-modal features. By embedding temporal awareness into the recursive fusion process, the TAGF effectively captures the sequential evolution of emotional expressions and the complex interplay between modalities. Experimental results on the Aff-Wild2 dataset demonstrate that TAGF achieves competitive performance compared with existing recursive attention-based models. Furthermore, TAGF exhibits strong robustness to cross-modal misalignment and reliably models dynamic emotional transitions in real-world conditions.",
      "authors": [
        "Yubeen Lee",
        "Sangeun Lee",
        "Chaewon Park",
        "Junyeop Cha and Eunil Park"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Multimedia (cs.MM)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T18:31:24+00:00",
          "link": "https://arxiv.org/abs/2507.02080v1",
          "size": "1755kb",
          "version": "v1"
        }
      ],
      "title": "TAGF: Time-aware Gated Fusion for Multimodal Valence-Arousal Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02080",
        "HTML": "https://arxiv.org/html/2507.02080v1",
        "PDF": "https://arxiv.org/pdf/2507.02080"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a model for emotion recognition focusing on gated fusion for multimodal data, unrelated to LLM training data processing or construction."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02083",
      "abstract": "Designing experiments and result interpretations are core scientific competencies, particularly in biology, where researchers perturb complex systems to uncover the underlying systems. Recent efforts to evaluate the scientific capabilities of large language models (LLMs) fail to test these competencies because wet-lab experimentation is prohibitively expensive: in expertise, time and equipment. We introduce SciGym, a first-in-class benchmark that assesses LLMs' iterative experiment design and analysis abilities in open-ended scientific discovery tasks. SciGym overcomes the challenge of wet-lab costs by running a dry lab of biological systems. These models, encoded in Systems Biology Markup Language, are efficient for generating simulated data, making them ideal testbeds for experimentation on realistically complex systems. We evaluated six frontier LLMs on 137 small systems, and released a total of 350 systems. Our evaluation shows that while more capable models demonstrated superior performance, all models' performance declined significantly as system complexity increased, suggesting substantial room for improvement in the scientific capabilities of LLM agents.",
      "authors": [
        "Haonan Duan",
        "Stephen Zhewen Lu",
        "Caitlin Fiona Harrigan",
        "Nishkrit Desai",
        "Jiarui Lu",
        "Micha{\\l} Koziarski",
        "Leonardo Cotta",
        "Chris J. Maddison"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T18:41:44+00:00",
          "link": "https://arxiv.org/abs/2507.02083v1",
          "size": "3246kb",
          "version": "v1"
        }
      ],
      "title": "Measuring Scientific Capabilities of Language Models with a Systems Biology Dry Lab",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02083",
        "HTML": "https://arxiv.org/html/2507.02083v1",
        "PDF": "https://arxiv.org/pdf/2507.02083"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper evaluates LLMs on iterative experiment design and analysis tasks using a benchmark; it focuses on evaluation rather than processing or constructing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02085",
      "abstract": "Geometric diffusion models have shown remarkable success in molecular dynamics and structure generation. However, efficiently fine-tuning them for downstream tasks with varying geometric controls remains underexplored. In this work, we propose an SE(3)-equivariant adapter framework ( GeoAda) that enables flexible and parameter-efficient fine-tuning for controlled generative tasks without modifying the original model architecture. GeoAda introduces a structured adapter design: control signals are first encoded through coupling operators, then processed by a trainable copy of selected pretrained model layers, and finally projected back via decoupling operators followed by an equivariant zero-initialized convolution. By fine-tuning only these lightweight adapter modules, GeoAda preserves the model's geometric consistency while mitigating overfitting and catastrophic forgetting. We theoretically prove that the proposed adapters maintain SE(3)-equivariance, ensuring that the geometric inductive biases of the pretrained diffusion model remain intact during adaptation. We demonstrate the wide applicability of GeoAda across diverse geometric control types, including frame control, global control, subgraph control, and a broad range of application domains such as particle dynamics, molecular dynamics, human motion prediction, and molecule generation. Empirical results show that GeoAda achieves state-of-the-art fine-tuning performance while preserving original task accuracy, whereas other baselines experience significant performance degradation due to overfitting and catastrophic forgetting.",
      "authors": [
        "Wanjia Zhao",
        "Jiaqi Han",
        "Siyi Gu",
        "Mingjian Jiang",
        "James Zou",
        "Stefano Ermon"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T18:44:03+00:00",
          "link": "https://arxiv.org/abs/2507.02085v1",
          "size": "1539kb",
          "version": "v1"
        }
      ],
      "title": "GeoAda: Efficiently Finetune Geometric Diffusion Models with Equivariant Adapters",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02085",
        "HTML": "https://arxiv.org/html/2507.02085v1",
        "PDF": "https://arxiv.org/pdf/2507.02085"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses fine-tuning geometric diffusion models with adapters, mentioning data aspects in the context of model performance but does not focus on new data engineering or processing methods for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02087",
      "abstract": "The use of large language models (LLMs) in hiring promises to streamline candidate screening, but it also raises serious concerns regarding accuracy and algorithmic bias where sufficient safeguards are not in place. In this work, we benchmark several state-of-the-art foundational LLMs - including models from OpenAI, Anthropic, Google, Meta, and Deepseek, and compare them with our proprietary domain-specific hiring model (Match Score) for job candidate matching. We evaluate each model's predictive accuracy (ROC AUC, Precision-Recall AUC, F1-score) and fairness (impact ratio of cut-off analysis across declared gender, race, and intersectional subgroups). Our experiments on a dataset of roughly 10,000 real-world recent candidate-job pairs show that Match Score outperforms the general-purpose LLMs on accuracy (ROC AUC 0.85 vs 0.77) and achieves significantly more equitable outcomes across demographic groups. Notably, Match Score attains a minimum race-wise impact ratio of 0.957 (near-parity), versus 0.809 or lower for the best LLMs, (0.906 vs 0.773 for the intersectionals, respectively). We discuss why pretraining biases may cause LLMs with insufficient safeguards to propagate societal biases in hiring scenarios, whereas a bespoke supervised model can more effectively mitigate these biases. Our findings highlight the importance of domain-specific modeling and bias auditing when deploying AI in high-stakes domains such as hiring, and caution against relying on off-the-shelf LLMs for such tasks without extensive fairness safeguards. Furthermore, we show with empirical evidence that there shouldn't be a dichotomy between choosing accuracy and fairness in hiring: a well-designed algorithm can achieve both accuracy in hiring and fairness in outcomes.",
      "authors": [
        "Eitan Anzenberg",
        "Arunava Samajpati",
        "Sivasankaran Chandrasekar",
        "Varun Kacholia"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T19:02:18+00:00",
          "link": "https://arxiv.org/abs/2507.02087v1",
          "size": "130kb",
          "version": "v1"
        }
      ],
      "title": "Evaluating the Promise and Pitfalls of LLMs in Hiring Decisions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02087",
        "HTML": "https://arxiv.org/html/2507.02087v1",
        "PDF": "https://arxiv.org/pdf/2507.02087"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper benchmarks LLMs in hiring contexts, with discussions on biases arising from pretrained data. While insightful, it does not offer new methods in the data engineering stage or data processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02088",
      "abstract": "As large language models (LLMs) are increasingly applied to various NLP tasks, their inherent biases are gradually disclosed. Therefore, measuring biases in LLMs is crucial to mitigate its ethical risks. However, most existing bias evaluation datasets focus on English and North American culture, and their bias categories are not fully applicable to other cultures. The datasets grounded in the Chinese language and culture are scarce. More importantly, these datasets usually only support single evaluation tasks and cannot evaluate the bias from multiple aspects in LLMs. To address these issues, we present a Multi-task Chinese Bias Evaluation Benchmark (McBE) that includes 4,077 bias evaluation instances, covering 12 single bias categories, 82 subcategories and introducing 5 evaluation tasks, providing extensive category coverage, content diversity, and measuring comprehensiveness. Additionally, we evaluate several popular LLMs from different series and with parameter sizes. In general, all these LLMs demonstrated varying degrees of bias. We conduct an in-depth analysis of results, offering novel insights into bias in LLMs.",
      "authors": [
        "Tian Lan",
        "Xiangdong Su",
        "Xu Liu",
        "Ruirui Wang",
        "Ke Chang",
        "Jiang Li",
        "Guanglai Gao"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T19:04:56+00:00",
          "link": "https://arxiv.org/abs/2507.02088v1",
          "size": "4295kb",
          "version": "v1"
        }
      ],
      "title": "McBE: A Multi-task Chinese Bias Evaluation Benchmark for Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02088",
        "PDF": "https://arxiv.org/pdf/2507.02088"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This work presents a Chinese bias evaluation benchmark for LLMs and evaluates existing models. It focuses on bias evaluation rather than the data engineering or core processing methods for creating or refining LLM training data."
      },
      "datasets": [
        {
          "dataset_name": "Velikaya/McBE",
          "downloads": "134",
          "likes": "0",
          "link": "https://huggingface.co/datasets/Velikaya/McBE"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.02089",
      "abstract": "We consider infinite-horizon $\\gamma$-discounted (linear) constrained Markov decision processes (CMDPs) where the objective is to find a policy that maximizes the expected cumulative reward subject to expected cumulative constraints. Given access to a generative model, we propose to solve CMDPs with a primal-dual framework that can leverage any black-box unconstrained MDP solver. For linear CMDPs with feature dimension $d$, we instantiate the framework by using mirror descent value iteration (\\texttt{MDVI})~\\citep{kitamura2023regularization} an example MDP solver. We provide sample complexity bounds for the resulting CMDP algorithm in two cases: (i) relaxed feasibility, where small constraint violations are allowed, and (ii) strict feasibility, where the output policy is required to exactly satisfy the constraint. For (i), we prove that the algorithm can return an $\\epsilon$-optimal policy with high probability by using $\\tilde{O}\\left(\\frac{d^2}{(1-\\gamma)^4\\epsilon^2}\\right)$ samples. We note that these results exhibit a near-optimal dependence on both $d$ and $\\epsilon$. For (ii), we show that the algorithm requires $\\tilde{O}\\left(\\frac{d^2}{(1-\\gamma)^6\\epsilon^2\\zeta^2}\\right)$ samples, where $\\zeta$ is the problem-dependent Slater constant that characterizes the size of the feasible region. Finally, we instantiate our framework for tabular CMDPs and show that it can be used to recover near-optimal sample complexities in this setting.",
      "authors": [
        "Xingtu Liu",
        "Lin F. Yang and Sharan Vaswani"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T19:07:37+00:00",
          "link": "https://arxiv.org/abs/2507.02089v1",
          "size": "65kb",
          "version": "v1"
        }
      ],
      "title": "Sample Complexity Bounds for Linear Constrained MDPs with a Generative Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02089",
        "PDF": "https://arxiv.org/pdf/2507.02089"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on constrained Markov decision processes (CMDPs) and presents a primal-dual framework with sample complexity bounds. It does not address LLM training data processing or any related data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02092",
      "abstract": "Inference-time computation techniques, analogous to human System 2 Thinking, have recently become popular for improving model performances. However, most existing approaches suffer from several limitations: they are modality-specific (e.g., working only in text), problem-specific (e.g., verifiable domains like math and coding), or require additional supervision/training on top of unsupervised pretraining (e.g., verifiers or verifiable rewards). In this paper, we ask the question \"Is it possible to generalize these System 2 Thinking approaches, and develop models that learn to think solely from unsupervised learning?\" Interestingly, we find the answer is yes, by learning to explicitly verify the compatibility between inputs and candidate-predictions, and then re-framing prediction problems as optimization with respect to this verifier. Specifically, we train Energy-Based Transformers (EBTs) -- a new class of Energy-Based Models (EBMs) -- to assign an energy value to every input and candidate-prediction pair, enabling predictions through gradient descent-based energy minimization until convergence. Across both discrete (text) and continuous (visual) modalities, we find EBTs scale faster than the dominant Transformer++ approach during training, achieving an up to 35% higher scaling rate with respect to data, batch size, parameters, FLOPs, and depth. During inference, EBTs improve performance with System 2 Thinking by 29% more than the Transformer++ on language tasks, and EBTs outperform Diffusion Transformers on image denoising while using fewer forward passes. Further, we find that EBTs achieve better results than existing models on most downstream tasks given the same or worse pretraining performance, suggesting that EBTs generalize better than existing approaches. Consequently, EBTs are a promising new paradigm for scaling both the learning and thinking capabilities of models.",
      "authors": [
        "Alexi Gladstone",
        "Ganesh Nanduru",
        "Md Mofijul Islam",
        "Peixuan Han",
        "Hyeonjeong Ha",
        "Aman Chadha",
        "Yilun Du",
        "Heng Ji",
        "Jundong Li",
        "Tariq Iqbal"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T19:17:29+00:00",
          "link": "https://arxiv.org/abs/2507.02092v1",
          "size": "19531kb",
          "version": "v1"
        }
      ],
      "title": "Energy-Based Transformers are Scalable Learners and Thinkers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02092",
        "HTML": "https://arxiv.org/html/2507.02092v1",
        "PDF": "https://arxiv.org/pdf/2507.02092"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses the scalability and inference capabilities of Energy-Based Transformers, focusing on their performance. It does not contribute to or discuss the processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02097",
      "abstract": "Large language models (LLMs) are rapidly evolving from passive engines of text generation into agentic entities that can plan, remember, invoke external tools, and co-operate with one another. This perspective paper investigates how such LLM agents (and societies thereof) can transform the design space of recommender systems.\n  We introduce a unified formalism that (i) models an individual agent as a tuple comprising its language core, tool set, and hierarchical memory, and (ii) captures a multi-agent recommender as a triple of agents, shared environment, and communication protocol. Within this framework, we present four end-to-end use cases-interactive party planning, synthetic user-simulation for offline evaluation, multi-modal furniture recommendation, and brand-aligned explanation generation-each illustrating a distinct capability unlocked by agentic orchestration.\n  We then surface five cross-cutting challenge families: protocol complexity, scalability, hallucination and error propagation, emergent misalignment (including covert collusion), and brand compliance.\n  For each, we formalize the problem, review nascent mitigation strategies, and outline open research questions. The result is both a blueprint and an agenda: a blueprint that shows how memory-augmented, tool-using LLM agents can be composed into robust recommendation pipelines, and an agenda inviting the RecSys community to develop benchmarks, theoretical guarantees, and governance tools that keep pace with this new degree of autonomy. By unifying agentic abstractions with recommender objectives, the paper lays the groundwork for the next generation of personalized, trustworthy, and context-rich recommendation services.",
      "authors": [
        "Reza Yousefi Maragheh",
        "Yashar Deldjoo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T19:25:44+00:00",
          "link": "https://arxiv.org/abs/2507.02097v1",
          "size": "1381kb",
          "version": "v1"
        }
      ],
      "title": "The Future is Agentic: Definitions, Perspectives, and Open Challenges of Multi-Agent Recommender Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02097",
        "HTML": "https://arxiv.org/html/2507.02097v1",
        "PDF": "https://arxiv.org/pdf/2507.02097"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores the use of LLMs as agents in multi-agent recommender systems without focusing on the data engineering or processing aspects of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02098",
      "abstract": "In this paper, we present a robust and adaptive model predictive control (MPC) framework for uncertain nonlinear systems affected by bounded disturbances and unmodeled nonlinearities. We use Gaussian Processes (GPs) to learn the uncertain dynamics based on noisy measurements, including those collected during system operation. As a key contribution, we derive robust predictions for GP models using contraction metrics, which are incorporated in the MPC formulation. The proposed design guarantees recursive feasibility, robust constraint satisfaction and convergence to a reference state, with high probability. We provide a numerical example of a planar quadrotor subject to difficult-to-model ground effects, which highlights significant improvements achieved through the proposed robust prediction method and through online learning.",
      "authors": [
        "Mathieu Dubied",
        "Amon Lahr",
        "Melanie N. Zeilinger",
        "Johannes K\\\"ohler"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T19:27:14+00:00",
          "link": "https://arxiv.org/abs/2507.02098v1",
          "size": "559kb",
          "version": "v1"
        }
      ],
      "title": "A robust and adaptive MPC formulation for Gaussian process models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02098",
        "HTML": "https://arxiv.org/html/2507.02098v1",
        "PDF": "https://arxiv.org/pdf/2507.02098"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research focuses on model predictive control using Gaussian Processes and does not discuss any LLM training data processing or engineering elements."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02099",
      "abstract": "Analyzing electromagnetic fields in complex, multi-material environments presents substantial computational challenges. To address these, we propose a hybrid numerical method that couples discrete exterior calculus (DEC) with surface integral equations (SIE) in the potential-based formulation of Maxwell's equations. The method employs the magnetic vector and electric scalar potentials ($\\mathbf{A}$-$\\Phi$) under the Lorenz gauge, offering natural compatibility with multi-physics couplings and inherent immunity to low-frequency breakdown. To effectively handle both bounded and unbounded regions, we divide the computational domain: the inhomogeneous interior is discretized using DEC, a coordinate-free framework that preserves topological invariants and enables structure-preserving discretization on unstructured meshes, while the homogeneous exterior is treated using SIEs, which inherently satisfy the radiation condition and eliminate the need for artificial domain truncation. A key contribution of this work is a scalar reformulation of the SIEs, which reduces the number of surface integral operators from fourteen to two by expressing the problem in terms of the Cartesian components of the vector potential and their normal derivatives. This simplification motivates a corresponding adaptation in the DEC domain: each vector potential component is represented as a discrete 0-form, in contrast to the conventional 1-form representation. This novel treatment improves compatibility at the interface and significantly enhances numerical performance. The proposed hybrid method thus offers a unified, efficient, and physically consistent framework for solving electromagnetic scattering and radiation problems in complex geometries and heterogeneous materials",
      "authors": [
        "Amgad Abdrabou",
        "Luis J. Gomez",
        "and Weng Cho Chew"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T19:28:41+00:00",
          "link": "https://arxiv.org/abs/2507.02099v1",
          "size": "1422kb",
          "version": "v1"
        }
      ],
      "title": "A Hybrid DEC-SIE Framework for Potential-Based Electromagnetic Analysis of Heterogeneous Media",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02099",
        "HTML": "https://arxiv.org/html/2507.02099v1",
        "PDF": "https://arxiv.org/pdf/2507.02099"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a method for electromagnetic analysis using numerical techniques. It does not address LLM training data or related processing tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02103",
      "abstract": "Modern AI models, such as large language models, are usually trained once on a huge corpus of data, potentially fine-tuned for a specific task, and then deployed with fixed parameters. Their training is costly, slow, and gradual, requiring billions of repetitions. In stark contrast, animals continuously adapt to the ever-changing contingencies in their environments. This is particularly important for social species, where behavioral policies and reward outcomes may frequently change in interaction with peers. The underlying computational processes are often marked by rapid shifts in an animal's behaviour and rather sudden transitions in neuronal population activity. Such computational capacities are of growing importance for AI systems operating in the real world, like those guiding robots or autonomous vehicles, or for agentic AI interacting with humans online. Can AI learn from neuroscience? This Perspective explores this question, integrating the literature on continual and in-context learning in AI with the neuroscience of learning on behavioral tasks with shifting rules, reward probabilities, or outcomes. We will outline an agenda for how specifically insights from neuroscience may inform current developments in AI in this area, and - vice versa - what neuroscience may learn from AI, contributing to the evolving field of NeuroAI.",
      "authors": [
        "Daniel Durstewitz",
        "Bruno Averbeck",
        "Georgia Koppe"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Neurons and Cognition (q-bio.NC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T19:30:57+00:00",
          "link": "https://arxiv.org/abs/2507.02103v1",
          "size": "2069kb",
          "version": "v1"
        }
      ],
      "title": "What Neuroscience Can Teach AI About Learning in Continuously Changing Environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02103",
        "PDF": "https://arxiv.org/pdf/2507.02103"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the integration of neuroscience insights with AI, focusing on learning in changing environments, and does not address aspects of LLM training data processing or data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02107",
      "abstract": "Searching code is a common task that developers perform to understand APIs, learn common code patterns, and navigate code. Currently, developers most commonly search using keywords and regular expressions that are easy to use and widely available. Beyond keywords and regular expressions, structural code search tools allow developers to search for code based on its syntactic structure. This has numerous applications ranging from bug finding to systematically refactoring code. However, these structural code search tools operate on queries expressed in domain-specific languages (DSL) that can be difficult to learn and write. We propose to allow developers to use natural language to search for code structurally. Expressing queries in natural language provides an intuitive way to search for code and lowers the barrier to entry.\n  In this work, we develop a novel general approach that combines the reasoning capabilities of an LLM to interpret natural language search queries with the power of structural search tools to efficiently and accurately retrieve relevant code. We then instantiate this approach for two structural code search DSLs: Semgrep and GQL. In our evaluation, we construct a new benchmark for structural code search consisting of 400 queries over 10 Java projects. We show that our approach for structural code search based on translating NL queries to DSL queries using an LLM is effective and robust, achieving a high precision and recall ranging from 55% - 70%. Further, our approach significantly outperforms baselines based on semantic code search and LLM retrievals by up to 57% and 14% on F1 scores.",
      "authors": [
        "Ben Limpanukorn",
        "Yanjun Wang",
        "Zach Patterson",
        "Pranav Garg",
        "Murali Krishna Ramanathan",
        "Xiaofei Ma",
        "Anoop Deoras",
        "Miryung Kim"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T19:42:37+00:00",
          "link": "https://arxiv.org/abs/2507.02107v1",
          "size": "3910kb",
          "version": "v1"
        }
      ],
      "title": "Structural Code Search using Natural Language Queries",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02107",
        "HTML": "https://arxiv.org/html/2507.02107v1",
        "PDF": "https://arxiv.org/pdf/2507.02107"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper addresses the use of LLMs for translating natural language queries to structural code search DSLs, indirectly relating to data processing by involving LLM utilization but doesn't propose new methods for LLM training data itself."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02109",
      "abstract": "We introduce PANAMA, an active learning framework for the training of end-to-end parametric guitar amp models using a WaveNet-like architecture. With \\model, one can create a virtual amp by recording samples that are determined by an active learning strategy to use a minimum amount of datapoints (i.e., amp knob settings). We show that gradient-based optimization algorithms can be used to determine the optimal datapoints to sample, and that the approach helps under a constrained number of samples.",
      "authors": [
        "Florian Gr\\\"otschla",
        "Luca A. Lanzend\\\"orfer",
        "Longxiang Jiao",
        "Roger Wattenhofer"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T19:47:23+00:00",
          "link": "https://arxiv.org/abs/2507.02109v1",
          "size": "346kb",
          "version": "v1"
        }
      ],
      "title": "Parametric Neural Amp Modeling with Active Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02109",
        "HTML": "https://arxiv.org/html/2507.02109v1",
        "PDF": "https://arxiv.org/pdf/2507.02109"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research introduces an active learning framework for training parametric guitar amp models, focusing on audio data and training efficiency, not addressing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02110",
      "abstract": "Predicting mobile app popularity before release can provide developers with a strategic advantage in a competitive marketplace, yet it remains a challenging problem. This study explores whether internal software metrics, measurable from source code before deployment, can predict an app's popularity, defined by user ratings (calculated from user reviews) and DownloadsPerYear (yearly downloads). Using a dataset of 446 open-source Android apps from F-Droid, we extract a wide array of features, including system-, class-, and method-level code metrics, code smells, and app metadata. Additional information, such as user reviews, download counts, and uses-permission, was collected from the Google Play Store. We evaluate regression and classification models across three feature sets: a minimal Size-only baseline, a domain-informed Handpicked set, and a Voting set derived via feature selection algorithms. Regression models perform poorly due to skewed data, with low $R^2$ scores. However, when reframed as binary classification (Popular vs. Unpopular), results improve significantly. The best model, a Multilayer Perceptron using the Voting set, achieves F1-scores of 0.72. These results suggest that internal code metrics, although limited in their explanatory power, can serve as useful indicators of app popularity. This challenges earlier findings that dismissed internal metrics as predictors of software quality.",
      "authors": [
        "Md Nahidul Islam Opu",
        "Fatima Islam Mouri",
        "Rick Kazman",
        "Yuanfang Cai",
        "Shaiful Chowdhury"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T19:47:41+00:00",
          "link": "https://arxiv.org/abs/2507.02110v1",
          "size": "1456kb",
          "version": "v1"
        }
      ],
      "title": "Can Internal Software Metrics Predict App Popularity at Launch? Yeas! and Nays!",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02110",
        "HTML": "https://arxiv.org/html/2507.02110v1",
        "PDF": "https://arxiv.org/pdf/2507.02110"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study explores predicting app popularity using internal software metrics and does not involve any processing or engineering of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02117",
      "abstract": "Finding all the words on a Boggle board is a classic computer programming problem. With a fast Boggle solver, local optimization techniques such as hillclimbing and simulated annealing can be used to find particularly high-scoring boards. The sheer number of possible Boggle boards has historically prevented an exhaustive search for the global optimum board. We apply Branch and Bound and a decision diagram-like data structure to perform the first such search. We find that the highest-scoring boards found via hillclimbing are, in fact, the global optima.",
      "authors": [
        "Dan Vanderkam"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T20:00:37+00:00",
          "link": "https://arxiv.org/abs/2507.02117v1",
          "size": "200kb",
          "version": "v1"
        }
      ],
      "title": "A Computational Proof of the Highest-Scoring Boggle Board",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02117",
        "PDF": "https://arxiv.org/pdf/2507.02117"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on finding optimal Boggle boards using algorithms like Branch and Bound, with no mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02118",
      "abstract": "The study of well-being, stress and other human factors has traditionally relied on self-report instruments to assess key variables. However, concerns about potential biases in these instruments, even when thoroughly validated and standardised, have driven growing interest in alternatives in combining these measures with more objective methods, such as physiological measures.\n  We aimed to (i) compare psychometric stress measures and biometric indicators and (ii) identify stress-related patterns in biometric data during software engineering tasks.\n  We conducted an experiment where participants completed a pre-survey, then programmed two tasks wearing biometric sensors, answered brief post-surveys for each, and finally went through a short exit interview.\n  Our results showed diverse outcomes; we found no stress in the psychometric instruments. Participants in the interviews reported a mix of feeling no stress and experiencing time pressure. Finally, the biometrics showed a significant difference only in EDA phasic peaks.\n  We conclude that our chosen way of inducing stress by imposing a stricter time limit was insufficient. We offer methodological insights for future studies working with stress, biometrics, and psychometric instruments.",
      "authors": [
        "Cristina Martinez Montes",
        "Daniela Grassi",
        "Nicole Novielli",
        "Birgit Penzenstadle"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T20:01:27+00:00",
          "link": "https://arxiv.org/abs/2507.02118v1",
          "size": "2410kb",
          "version": "v1"
        }
      ],
      "title": "A Multimodal Approach Combining Biometrics and Self-Report Instruments for Monitoring Stress in Programming: Methodological Insights",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02118",
        "HTML": "https://arxiv.org/html/2507.02118v1",
        "PDF": "https://arxiv.org/pdf/2507.02118"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses the use of biometrics and self-report instruments for stress monitoring in programming, not related to LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02119",
      "abstract": "What scaling limits govern neural network training dynamics when model size and training time grow in tandem? We show that despite the complex interactions between architecture, training algorithms, and data, compute-optimally trained models exhibit a remarkably precise universality. Specifically, loss curves from models of varying sizes collapse onto a single universal curve when training compute and loss are normalized to unity at the end of training. With learning rate decay, the collapse becomes so tight that differences in the normalized curves across models fall below the noise floor of individual loss curves across random seeds, a phenomenon we term supercollapse. We observe supercollapse across learning rate schedules, datasets, and architectures, including transformers trained on next-token prediction, and find it breaks down when hyperparameters are scaled suboptimally, providing a precise and practical indicator of good scaling. We explain these phenomena by connecting collapse to the power-law structure in typical neural scaling laws, and analyzing a simple yet surprisingly effective model of SGD noise dynamics that accurately predicts loss curves across various learning rate schedules and quantitatively explains the origin of supercollapse.",
      "authors": [
        "Shikai Qiu",
        "Lechao Xiao",
        "Andrew Gordon Wilson",
        "Jeffrey Pennington",
        "Atish Agarwala"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T20:03:34+00:00",
          "link": "https://arxiv.org/abs/2507.02119v1",
          "size": "6755kb",
          "version": "v1"
        }
      ],
      "title": "Scaling Collapse Reveals Universal Dynamics in Compute-Optimally Trained Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02119",
        "HTML": "https://arxiv.org/html/2507.02119v1",
        "PDF": "https://arxiv.org/pdf/2507.02119"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "Though the paper analyzes neural network training dynamics and scalability, it does not address training data processing or engineering for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02122",
      "abstract": "Effective communication in serious illness and palliative care is essential but often under-taught due to limited access to training resources like standardized patients. We present PAL (Palliative Assisted Learning-bot), a conversational system that simulates emotionally nuanced patient interactions and delivers structured feedback grounded in an existing empathy-based framework. PAL supports text and voice modalities and is designed to scaffold clinical skill-building through repeated, low-cost practice. Through a mixed-methods study with 17 U.S. medical trainees and clinicians, we explore user engagement with PAL, evaluate usability, and examine design tensions around modalities, emotional realism, and feedback delivery. Participants found PAL helpful for reflection and skill refinement, though some noted limitations in emotional authenticity and the adaptability of feedback. We contribute: (1) empirical evidence that large language models can support palliative communication training; (2) design insights for modality-aware, emotionally sensitive simulation tools; and (3) implications for systems that support emotional labor, cooperative learning, and AI-augmented training in high-stakes care settings.",
      "authors": [
        "Neil K. R. Sehgal and Hita Kambhamettu and Allen Chang and Andrew Zhu and Lyle Ungar and Sharath Chandra Guntuku"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T20:09:52+00:00",
          "link": "https://arxiv.org/abs/2507.02122v1",
          "size": "1721kb",
          "version": "v1"
        }
      ],
      "title": "PAL: Designing Conversational Agents as Scalable, Cooperative Patient Simulators for Palliative-Care Training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02122",
        "HTML": "https://arxiv.org/html/2507.02122v1",
        "PDF": "https://arxiv.org/pdf/2507.02122"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses LLMs in the context of simulating patient interactions for training. However, it primarily focuses on application design, not training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02124",
      "abstract": "SAKURAONE is a managed high performance computing (HPC) cluster developed and operated by the SAKURA Internet Research Center. It reinforces the ``KOKARYOKU PHY'' configuration of bare-metal GPU servers and is designed as a cluster computing resource optimized for advanced workloads, including large language model (LLM) training.\n  In the ISC 2025 edition of the TOP500 list, SAKURAONE was ranked \\textbf{49th} in the world based on its High Performance Linpack (HPL) score, demonstrating its global competitiveness. In particular, it is the \\textbf{only system within the top 100} that employs a fully open networking stack based on \\textbf{800~GbE (Gigabit Ethernet)} and the \\textbf{SONiC (Software for Open Networking in the Cloud)} operating system, highlighting the viability of open and vendor-neutral technologies in large-scale HPC infrastructure.\n  SAKURAONE achieved a sustained performance of 33.95~PFLOP/s on the HPL benchmark (Rmax), and 396.295~TFLOP/s on the High Performance Conjugate Gradient (HPCG) benchmark. For the HPL-MxP benchmark, which targets low-precision workloads representative of AI applications, SAKURAONE delivered an impressive 339.86~PFLOP/s using FP8 precision.\n  The system comprises 100 compute nodes, each equipped with eight NVIDIA H100 GPUs. It is supported by an all-flash Lustre storage subsystem with a total physical capacity of 2~petabytes, providing high-throughput and low-latency data access. Internode communication is enabled by a full-bisection bandwidth interconnect based on a Rail-Optimized topology, where the Leaf and Spine layers are interconnected via 800~GbE links. This topology, in combination with RoCEv2 (RDMA over Converged Ethernet version 2), enables high-speed, lossless data transfers and mitigates communication bottlenecks in large-scale parallel workloads.",
      "authors": [
        "Fumikazu Konishi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T20:13:09+00:00",
          "link": "https://arxiv.org/abs/2507.02124v1",
          "size": "462kb",
          "version": "v1"
        }
      ],
      "title": "SAKURAONE: Empowering Transparent and Open AI Platforms through Private-Sector HPC Investment in Japan",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02124",
        "HTML": "https://arxiv.org/html/2507.02124v1",
        "PDF": "https://arxiv.org/pdf/2507.02124"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper describes SAKURAONE, an HPC cluster for LLM training. It highlights infrastructure rather than specific data processing methods for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02125",
      "abstract": "The blockchain oracle problem, which refers to the challenge of injecting reliable external data into decentralized systems, remains a fundamental limitation to the development of trustless applications. While recent years have seen a proliferation of architectural, cryptographic, and economic strategies to mitigate this issue, no one has yet fully resolved the fundamental question of how a blockchain can gain knowledge about the off-chain world. In this position paper, we critically assess the role artificial intelligence (AI) can play in tackling the oracle problem. Drawing from both academic literature and practitioner implementations, we examine how AI techniques such as anomaly detection, language-based fact extraction, dynamic reputation modeling, and adversarial resistance can enhance oracle systems. We observe that while AI introduces powerful tools for improving data quality, source selection, and system resilience, it cannot eliminate the reliance on unverifiable off-chain inputs. Therefore, this study supports the idea that AI should be understood as a complementary layer of inference and filtering within a broader oracle design, not a substitute for trust assumptions.",
      "authors": [
        "Giulio Caldarelli"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)",
        "Computer Science and Game Theory (cs.GT)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T20:15:21+00:00",
          "link": "https://arxiv.org/abs/2507.02125v1",
          "size": "324kb",
          "version": "v1"
        }
      ],
      "title": "Can Artificial Intelligence solve the blockchain oracle problem? Unpacking the Challenges and Possibilities",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02125",
        "PDF": "https://arxiv.org/pdf/2507.02125"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on blockchain oracle systems and the use of AI for improving data quality within these systems, which is not related to LLM training data processing or engineering for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02128",
      "abstract": "Modern very large-scale integration (VLSI) design requires the implementation of integrated circuits using electronic design automation (EDA) tools. Due to the complexity of EDA algorithms, the vast parameter space poses a huge challenge to chip design optimization, as the combination of even moderate numbers of parameters creates an enormous solution space to explore. Manual parameter selection remains industrial practice despite being excessively laborious and limited by expert experience. To address this issue, we present CROP, the first large language model (LLM)-powered automatic VLSI design flow tuning framework. Our approach includes: (1) a scalable methodology for transforming RTL source code into dense vector representations, (2) an embedding-based retrieval system for matching designs with semantically similar circuits, and (3) a retrieval-augmented generation (RAG)-enhanced LLM-guided parameter search system that constrains the search process with prior knowledge from similar designs. Experiment results demonstrate CROP's ability to achieve superior quality-of-results (QoR) with fewer iterations than existing approaches on industrial designs, including a 9.9% reduction in power consumption.",
      "authors": [
        "Jingyu Pan",
        "Isaac Jacobson",
        "Zheng Zhao",
        "Tung-Chieh Chen",
        "Guanglei Zhou",
        "Chen-Chia Chang",
        "Vineet Rashingkar and Yiran Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T20:25:47+00:00",
          "link": "https://arxiv.org/abs/2507.02128v1",
          "size": "393kb",
          "version": "v1"
        }
      ],
      "title": "CROP: Circuit Retrieval and Optimization with Parameter Guidance using LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02128",
        "HTML": "https://arxiv.org/html/2507.02128v1",
        "PDF": "https://arxiv.org/pdf/2507.02128"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents an LLM-powered framework for VLSI design optimization, but it does not involve tasks related to the processing or engineering of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02129",
      "abstract": "Generative models have demonstrated strong performance in conditional settings and can be viewed as a form of data compression, where the condition serves as a compact representation. However, their limited controllability and reconstruction accuracy restrict their practical application to data compression. In this work, we propose an efficient latent diffusion framework that bridges this gap by combining a variational autoencoder with a conditional diffusion model. Our method compresses only a small number of keyframes into latent space and uses them as conditioning inputs to reconstruct the remaining frames via generative interpolation, eliminating the need to store latent representations for every frame. This approach enables accurate spatiotemporal reconstruction while significantly reducing storage costs. Experimental results across multiple datasets show that our method achieves up to 10 times higher compression ratios than rule-based state-of-the-art compressors such as SZ3, and up to 63 percent better performance than leading learning-based methods under the same reconstruction error.",
      "authors": [
        "Xiao Li and Liangji Zhu and Anand Rangarajan and Sanjay Ranka"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T20:27:38+00:00",
          "link": "https://arxiv.org/abs/2507.02129v1",
          "size": "6956kb",
          "version": "v1"
        }
      ],
      "title": "Generative Latent Diffusion for Efficient Spatiotemporal Data Reduction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02129",
        "HTML": "https://arxiv.org/html/2507.02129v1",
        "PDF": "https://arxiv.org/pdf/2507.02129"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a latent diffusion framework for data reduction and compression, which falls outside the scope of LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02132",
      "abstract": "The goal of this paper is to estimate the directions of arrival (DoAs) for hybrid analog/digital (HAD) receivers when the number of snapshots is too small for statistical averaging to be reliable. This goal is achieved in fully-digital receivers by employing the matrix pencil method (MPM). Unfortunately, the MPM cannot be directly applied in HAD receivers because of the entanglement induced by the underlying analog combiners on the output signals. Furthermore, these analog combiners project the received signal onto a low-dimensional space, jeopardizing the reception of signals arriving from particular DoA ranges. To circumvent these difficulties, we propose two approaches to enable the MPM to extract the DoAs in HAD receivers. The two approaches avoid severe attenuation induced by low-dimensional projection by cycling over an exhaustive set of analog combiners, collectively spanning the entire space. The first approach can be applied to both fully-connected (FC) and partially-connected (PC) HADs and relies on the availability of periodic, potentially unknown, signals to disentangle the output of the HAD receiver. The second approach applies to PC-HADs only, and eliminates contingency on periodic signals by exploiting the underlying block diagonal structure. The superiority of the proposed approaches is demonstrated via numerical simulations and comparisons with the Cram\\'er-Rao lower bound.",
      "authors": [
        "Mona Mostafa",
        "Ramy H. Gohary",
        "Amr El-Keyi",
        "and Yahia A. Eldemerdash Ahmed"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T20:32:32+00:00",
          "link": "https://arxiv.org/abs/2507.02132v1",
          "size": "399kb",
          "version": "v1"
        }
      ],
      "title": "Matrix Pencil-Based DoA Estimation for Hybrid Receivers in Snapshot-Limited Scenarios",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02132",
        "HTML": "https://arxiv.org/html/2507.02132v1",
        "PDF": "https://arxiv.org/pdf/2507.02132"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on direction of arrival estimation for hybrid receivers; the methods discussed are unrelated to LLM training data processing or data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02135",
      "abstract": "Large Language Models (LLMs) are increasingly being integrated into various applications and services running on billions of mobile devices. However, deploying LLMs on resource-limited mobile devices faces a significant challenge due to their high demand for computation, memory, and ultimately energy. While current LLM frameworks for mobile use three power-hungry components-CPU, GPU, and Memory-even when running primarily-GPU LLM models, optimized DVFS governors for CPU, GPU, and memory featured in modern mobile devices operate independently and are oblivious of each other. Motivated by the above observation, in this work, we first measure the energy-efficiency of a SOTA LLM framework consisting of various LLM models on mobile phones which showed the triplet mobile governors result in up to 40.4% longer prefilling and decoding latency compared to optimal combinations of CPU, GPU, and memory frequencies with the same energy consumption for sampled prefill and decode lengths. Second, we conduct an in-depth measurement study to uncover how the intricate interplay (or lack of) among the mobile governors cause the above inefficiency in LLM inference. Finally, based on these insights, we design FUSE - a unified energy-aware governor for optimizing the energy efficiency of LLM inference on mobile devices. Our evaluation using a ShareGPT dataset shows FUSE reduces the time-to-first-token and time-per-output-token latencies by 7.0%-16.9% and 25.4%-36.8% on average with the same energy-per-token for various mobile LLM models.",
      "authors": [
        "Zongpu Zhang",
        "Pranab Dash",
        "Y. Charlie Hu",
        "Qiang Xu",
        "Jian Li",
        "Haibing Guan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Operating Systems (cs.OS)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T20:47:40+00:00",
          "link": "https://arxiv.org/abs/2507.02135v1",
          "size": "2190kb",
          "version": "v1"
        }
      ],
      "title": "Dissecting the Impact of Mobile DVFS Governors on LLM Inference Performance and Energy Efficiency",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02135",
        "HTML": "https://arxiv.org/html/2507.02135v1",
        "PDF": "https://arxiv.org/pdf/2507.02135"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper evaluates energy efficiency of LLM inference on mobile devices using a specific dataset (ShareGPT), but does not contribute new methods for constructing or processing training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02137",
      "abstract": "Software development relies heavily on text-based communication, making sentiment analysis a valuable tool for understanding team dynamics and supporting trustworthy AI-driven analytics in requirements engineering. However, existing sentiment analysis tools often perform inconsistently across datasets from different platforms, due to variations in communication style and content.\n  In this study, we analyze linguistic and statistical features of 10 developer communication datasets from five platforms and evaluate the performance of 14 sentiment analysis tools. Based on these results, we propose a mapping approach and questionnaire that recommends suitable sentiment analysis tools for new datasets, using their characteristic features as input.\n  Our results show that dataset characteristics can be leveraged to improve tool selection, as platforms differ substantially in both linguistic and statistical properties. While transformer-based models such as SetFit and RoBERTa consistently achieve strong results, tool effectiveness remains context-dependent. Our approach supports researchers and practitioners in selecting trustworthy tools for sentiment analysis in software engineering, while highlighting the need for ongoing evaluation as communication contexts evolve.",
      "authors": [
        "Martin Obaidi",
        "Marc Herrmann",
        "Jil Kl\\\"under",
        "Kurt Schneider"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T20:50:25+00:00",
          "link": "https://arxiv.org/abs/2507.02137v1",
          "size": "145kb",
          "version": "v1"
        }
      ],
      "title": "Towards Trustworthy Sentiment Analysis in Software Engineering: Dataset Characteristics and Tool Selection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02137",
        "HTML": "https://arxiv.org/html/2507.02137v1",
        "PDF": "https://arxiv.org/pdf/2507.02137"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper focuses on sentiment analysis in software engineering and mentions dataset characteristics, but does not provide new methods for LLM data collection or processing specifically."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02138",
      "abstract": "This study introduces and evaluates Healthy Choice, an innovative theory-driven and AI-enhanced simulation platform designed to cultivate nutrition literacy through interactive scenario-based learning experiences. We collected feedback from 114 university students with diverse backgrounds who completed simulated product selection scenarios. Quantitative ratings of usefulness and ease of use demonstrated high user satisfaction.",
      "authors": [
        "Shan Li",
        "Guozhu Ding"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T20:50:36+00:00",
          "link": "https://arxiv.org/abs/2507.02138v1",
          "size": "982kb",
          "version": "v1"
        }
      ],
      "title": "A Theory-driven and AI-enhanced Simulation Platform for Cultivating Nutrition Literacy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02138",
        "PDF": "https://arxiv.org/pdf/2507.02138"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is related to AI-enhanced simulation for education on nutrition literacy, and it does not discuss LLM training data processing or any related methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02139",
      "abstract": "Large language models (LLMs) are increasingly used to assign document relevance labels in information retrieval pipelines, especially in domains lacking human-labeled data. However, different models often disagree on borderline cases, raising concerns about how such disagreement affects downstream retrieval. This study examines labeling disagreement between two open-weight LLMs, LLaMA and Qwen, on a corpus of scholarly abstracts related to Sustainable Development Goals (SDGs) 1, 3, and 7. We isolate disagreement subsets and examine their lexical properties, rank-order behavior, and classification predictability. Our results show that model disagreement is systematic, not random: disagreement cases exhibit consistent lexical patterns, produce divergent top-ranked outputs under shared scoring functions, and are distinguishable with AUCs above 0.74 using simple classifiers. These findings suggest that LLM-based filtering introduces structured variability in document retrieval, even under controlled prompting and shared ranking logic. We propose using classification disagreement as an object of analysis in retrieval evaluation, particularly in policy-relevant or thematic search tasks.",
      "authors": [
        "William A. Ingram",
        "Bipasha Banerjee",
        "Edward A. Fox"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)",
        "Digital Libraries (cs.DL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T20:53:51+00:00",
          "link": "https://arxiv.org/abs/2507.02139v1",
          "size": "55kb",
          "version": "v1"
        }
      ],
      "title": "When LLMs Disagree: Diagnosing Relevance Filtering Bias and Retrieval Divergence in SDG Search",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02139",
        "HTML": "https://arxiv.org/html/2507.02139v1",
        "PDF": "https://arxiv.org/pdf/2507.02139"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The study examines relevance filtering and retrieval biases using LLMs for document relevance labeling, which touches upon dataset labeling disagreements but not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02144",
      "abstract": "This paper presents a novel partitioning method designed to minimize control performance degradation resulting from partitioning a system for distributed control while maintaining the computational benefits of these methods. A game-theoretic performance metric, the modified Price of Anarchy, is introduced and is used in a generalizable partitioning metric to quantify optimality losses in a distributed controller. By finding the partition that minimizes the partitioning metric, the best-performing distributed control design is chosen. The presented partitioning metric is control-design agnostic, making it broadly applicable to many control design problems. In this paper, the developed metric is used to minimize the performance losses in the distributed control of a demand-flexible District Heating Network. The final distributed controller is provably feasible and stable. In simulation, this novel partitioning performed similarly to the centralized controller, increasing overall heat losses by only 1.9%, as compared to a similarly-sized baseline partition, which resulted in a 22% increase in losses.",
      "authors": [
        "Audrey Blizard and Stephanie Stockar"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T20:59:23+00:00",
          "link": "https://arxiv.org/abs/2507.02144v1",
          "size": "734kb",
          "version": "v1"
        }
      ],
      "title": "Optimality Loss Minimization in Distributed Control with Application to District Heating",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02144",
        "HTML": "https://arxiv.org/html/2507.02144v1",
        "PDF": "https://arxiv.org/pdf/2507.02144"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses optimization in distributed control systems and does not mention any aspects related to training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02145",
      "abstract": "Dialogue summarization is a challenging task with significant practical value in customer service, meeting analysis, and conversational AI. Although large language models (LLMs) have achieved substantial progress in summarization tasks, the performance of step-by-step reasoning architectures-specifically Long Chain-of-Thought (CoT) implementations such as OpenAI-o1 and DeepSeek-R1-remains unexplored for dialogue scenarios requiring concurrent abstraction and conciseness. In this work, we present the first comprehensive and systematic evaluation of state-of-the-art reasoning LLMs and non-reasoning LLMs across three major paradigms-generic, role-oriented, and query-oriented dialogue summarization. Our study spans diverse languages, domains, and summary lengths, leveraging strong benchmarks (SAMSum, DialogSum, CSDS, and QMSum) and advanced evaluation protocols that include both LLM-based automatic metrics and human-inspired criteria. Contrary to trends in other reasoning-intensive tasks, our findings show that explicit stepwise reasoning does not consistently improve dialogue summarization quality. Instead, reasoning LLMs are often prone to verbosity, factual inconsistencies, and less concise summaries compared to their non-reasoning counterparts. Through scenario-specific analyses and detailed case studies, we further identify when and why explicit reasoning may fail to benefit-or even hinder-summarization in complex dialogue contexts. Our work provides new insights into the limitations of current reasoning LLMs and highlights the need for targeted modeling and evaluation strategies for real-world dialogue summarization.",
      "authors": [
        "Keyan Jin",
        "Yapeng Wang",
        "Leonel Santos",
        "Tao Fang",
        "Xu Yang",
        "Sio Kei Im",
        "Hugo Gon\\c{c}alo Oliveira"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T21:02:41+00:00",
          "link": "https://arxiv.org/abs/2507.02145v1",
          "size": "5946kb",
          "version": "v1"
        }
      ],
      "title": "Reasoning or Not? A Comprehensive Evaluation of Reasoning LLMs for Dialogue Summarization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02145",
        "HTML": "https://arxiv.org/html/2507.02145v1",
        "PDF": "https://arxiv.org/pdf/2507.02145"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on evaluating reasoning capabilities of LLMs in dialogue summarization tasks, rather than proposing novel methods for LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02148",
      "abstract": "Monocular depth estimation has recently advanced to provide not only relative but also metric depth predictions. However, its reliability in underwater environments remains limited due to light attenuation and scattering, color distortion, turbidity, and the lack of high-quality metric ground-truth data. In this paper, we present a comprehensive benchmark of zero-shot and fine-tuned monocular metric depth estimation models on real-world underwater datasets with metric depth annotations, such as FLSea and SQUID. We evaluate a diverse set of state-of-the-art models across a range of underwater conditions with different ranges. Our results show that large-scale models trained on terrestrial (real or synthetic) data, while effective in in-air settings, perform poorly underwater due to significant domain shifts. To address this, we fine-tune Depth Anything V2 with a ViT-S backbone encoder on a synthetic underwater variant of the Hypersim dataset, which we generated using a physically based underwater image formation model. We demonstrate our fine-tuned model consistently improves performance across all benchmarks and outperforms baselines trained only on the clean in-air Hypersim dataset. Our study provides a detailed evaluation and visualization for monocular metric depth estimation in underwater scenes, highlighting the importance of domain adaptation and scale-aware supervision for achieving robust and generalizable metric depth predictions in challenging underwater environments for future research.",
      "authors": [
        "Zijie Cai and Christopher Metzler"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T21:06:39+00:00",
          "link": "https://arxiv.org/abs/2507.02148v1",
          "size": "29025kb",
          "version": "v1"
        }
      ],
      "title": "Underwater Monocular Metric Depth Estimation: Real-World Benchmarks and Synthetic Fine-Tuning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02148",
        "HTML": "https://arxiv.org/html/2507.02148v1",
        "PDF": "https://arxiv.org/pdf/2507.02148"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses fine-tuning depth estimation models on synthetic data for underwater environments. Although it mentions the generation of synthetic datasets, the main focus is not on LLM data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02151",
      "abstract": "Conformal prediction for graph neural networks (GNNs) offers a promising framework for quantifying uncertainty, enhancing GNN reliability in high-stakes applications. However, existing methods predominantly focus on static graphs, neglecting the evolving nature of real-world graphs. Temporal dependencies in graph structure, node attributes, and ground truth labels violate the fundamental exchangeability assumption of standard conformal prediction methods, limiting their applicability. To address these challenges, in this paper, we introduce NCPNET, a novel end-to-end conformal prediction framework tailored for temporal graphs. Our approach extends conformal prediction to dynamic settings, mitigating statistical coverage violations induced by temporal dependencies. To achieve this, we propose a diffusion-based non-conformity score that captures both topological and temporal uncertainties within evolving networks. Additionally, we develop an efficiency-aware optimization algorithm that improves the conformal prediction process, enhancing computational efficiency and reducing coverage violations. Extensive experiments on diverse real-world temporal graphs, including WIKI, REDDIT, DBLP, and IBM Anti-Money Laundering dataset, demonstrate NCPNET's capability to ensure guaranteed coverage in temporal graphs, achieving up to a 31% reduction in prediction set size on the WIKI dataset, significantly improving efficiency compared to state-of-the-art methods. Our data and code are available at https://github.com/ODYSSEYWT/NCPNET.",
      "authors": [
        "Tuo Wang",
        "Jian Kang",
        "Yujun Yan",
        "Adithya Kulkarni",
        "Dawei Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T21:15:00+00:00",
          "link": "https://arxiv.org/abs/2507.02151v1",
          "size": "3547kb",
          "version": "v1"
        }
      ],
      "title": "Non-exchangeable Conformal Prediction for Temporal Graph Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02151",
        "HTML": "https://arxiv.org/html/2507.02151v1",
        "PDF": "https://arxiv.org/pdf/2507.02151"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work introduces a framework for conformal prediction in temporal graph neural networks, which does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02152",
      "abstract": "Artificial intelligence systems, especially those using machine learning, are being deployed in domains from hiring to loan issuance in order to automate these complex decisions. Judging both the effectiveness and fairness of these AI systems, and their human decision making counterpart, is a complex and important topic studied across both computational and social sciences. Within machine learning, a common way to address bias in downstream classifiers is to resample the training data to offset disparities. For example, if hiring rates vary by some protected class, then one may equalize the rate within the training set to alleviate bias in the resulting classifier. While simple and seemingly effective, these methods have typically only been evaluated using data obtained through convenience samples, introducing selection bias and label bias into metrics. Within the social sciences, psychology, public health, and medicine, audit studies, in which fictitious ``testers'' (e.g., resumes, emails, patient actors) are sent to subjects (e.g., job openings, businesses, doctors) in randomized control trials, provide high quality data that support rigorous estimates of discrimination. In this paper, we investigate how data from audit studies can be used to improve our ability to both train and evaluate automated hiring algorithms. We find that such data reveals cases where the common fairness intervention method of equalizing base rates across classes appears to achieve parity using traditional measures, but in fact has roughly 10% disparity when measured appropriately. We additionally introduce interventions based on individual treatment effect estimation methods that further reduce algorithmic discrimination using this data.",
      "authors": [
        "Disa Sariola",
        "Patrick Button",
        "Aron Culotta",
        "Nicholas Mattei"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T21:15:56+00:00",
          "link": "https://arxiv.org/abs/2507.02152v1",
          "size": "263kb",
          "version": "v1"
        }
      ],
      "title": "The Illusion of Fairness: Auditing Fairness Interventions with Audit Studies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02152",
        "HTML": "https://arxiv.org/html/2507.02152v1",
        "PDF": "https://arxiv.org/pdf/2507.02152"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses fairness interventions in AI models using audit studies. It mentions training data resampling but doesn't focus on LLM-specific data processing innovations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02156",
      "abstract": "The StorySpace project studies the role new interface technologies might play in high school education. With this approach in mind, StorySpace is specifically designed to support and enhance classroom narrative, an already well-established classroom activity. StorySpace strives to achieve this through adherence to three design goals. The first is to trigger student reflection and interpretation. The narrative medium created by StorySpace should represent the topic of classroom discussion and learning in all its complexity. In building their representation, the students will then be confronted with that same complexity. The medium should also itself be exciting and compelling, making classroom narrative interesting and fun.",
      "authors": [
        "Benjamin Watson",
        "Janet Kim",
        "Tim McEneany",
        "Tom Moher",
        "Claudia Hindo",
        "Louis Gomez",
        "Stephen Fransen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T21:24:35+00:00",
          "link": "https://arxiv.org/abs/2507.02156v1",
          "size": "501kb",
          "version": "v1"
        }
      ],
      "title": "StorySpace: Technology supporting reflection, expression, and discourse in classroom narrative",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02156",
        "PDF": "https://arxiv.org/pdf/2507.02156"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about enhancing classroom narrative through technology and does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02158",
      "abstract": "Microservices are often deployed and managed by a container orchestrator that can detect and fix failures to maintain the service availability critical in many applications. In Poll-based Container Monitoring (PCM), the orchestrator periodically checks container health. While a common approach, PCM requires careful tuning, may degrade service availability, and can be slow to detect container health changes. An alternative is Signal-based Container Monitoring (SCM), where the container signals the orchestrator when its status changes. We present the design, implementation, and evaluation of an SCM approach for Kubernetes and empirically show that it has benefits over PCM, as predicted by a new mathematical model. We compare the service availability of SCM and PCM over six experiments using the SockShop benchmark. SCM does not require that polling intervals are tuned, and yet detects container failure 86\\% faster than PCM and container readiness in a comparable time with limited resource overheads. We find PCM can erroneously detect failures, and this reduces service availability by 4\\%. We propose that orchestrators offer SCM features for faster failure detection than PCM without erroneous detections or careful tuning.",
      "authors": [
        "Jacob Roberts",
        "Blair Archibald",
        "Phil Trinder"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T21:28:30+00:00",
          "link": "https://arxiv.org/abs/2507.02158v1",
          "size": "2230kb",
          "version": "v1"
        }
      ],
      "title": "Signalling Health for Improved Kubernetes Microservice Availability",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02158",
        "HTML": "https://arxiv.org/html/2507.02158v1",
        "PDF": "https://arxiv.org/pdf/2507.02158"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses container monitoring techniques for Kubernetes to improve service availability; it does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02164",
      "abstract": "Solving and visualizing the potential roots of complex functions is essential in both theoretical and applied domains, yet often computationally intensive. We present a hardware-accelerated algorithm for complex function roots density graph plotting by approximating functions with polynomials and solving their roots using single-shift QR iteration. By leveraging the Hessenberg structure of companion matrices and optimizing QR decomposition with Givens rotations, we design a pipelined FPGA architecture capable of processing a large amount of polynomials with high throughput. Our implementation achieves up to 65x higher energy efficiency than CPU-based approaches, and while it trails modern GPUs in performance due to differences in fabrication technique.",
      "authors": [
        "Ruibai Tang",
        "Chengbin Quan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T21:42:39+00:00",
          "link": "https://arxiv.org/abs/2507.02164v1",
          "size": "4814kb",
          "version": "v1"
        }
      ],
      "title": "Hardware-Accelerated Algorithm for Complex Function Roots Density Graph Plotting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02164",
        "HTML": "https://arxiv.org/html/2507.02164v1",
        "PDF": "https://arxiv.org/pdf/2507.02164"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a hardware-accelerated algorithm for plotting complex function roots; it does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02166",
      "abstract": "Graph generation is an important area in network science. Traditional approaches focus on replicating specific properties of real-world graphs, such as small diameters or power-law degree distributions. Recent advancements in deep learning, particularly with Graph Neural Networks, have enabled data-driven methods to learn and generate graphs without relying on predefined structural properties. Despite these advances, current models are limited by their reliance on node IDs, which restricts their ability to generate graphs larger than the input graph and ignores node attributes. To address these challenges, we propose Latent Graph Sampling Generation (LGSG), a novel framework that leverages diffusion models and node embeddings to generate graphs of varying sizes without retraining. The framework eliminates the dependency on node IDs and captures the distribution of node embeddings and subgraph structures, enabling scalable and flexible graph generation. Experimental results show that LGSG performs on par with baseline models for standard metrics while outperforming them in overlooked ones, such as the tendency of nodes to form clusters. Additionally, it maintains consistent structural characteristics across graphs of different sizes, demonstrating robustness and scalability.",
      "authors": [
        "Rodrigo Tuna and Carlos Soares"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T21:46:28+00:00",
          "link": "https://arxiv.org/abs/2507.02166v1",
          "size": "958kb",
          "version": "v1"
        }
      ],
      "title": "Generating Large Semi-Synthetic Graphs of Any Size",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02166",
        "HTML": "https://arxiv.org/html/2507.02166v1",
        "PDF": "https://arxiv.org/pdf/2507.02166"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research addresses graph generation using deep learning and diffusion models, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02169",
      "abstract": "Many safety failures in machine learning arise when models are used to assign predictions to people (often in settings like lending, hiring, or content moderation) without accounting for how individuals can change their inputs. In this work, we introduce a formal validation procedure for the responsiveness of predictions with respect to interventions on their features. Our procedure frames responsiveness as a type of sensitivity analysis in which practitioners control a set of changes by specifying constraints over interventions and distributions over downstream effects. We describe how to estimate responsiveness for the predictions of any model and any dataset using only black-box access, and how to use these estimates to support tasks such as falsification and failure probability estimation. We develop algorithms that construct these estimates by generating a uniform sample of reachable points, and demonstrate how they can promote safety in real-world applications such as recidivism prediction, organ transplant prioritization, and content moderation.",
      "authors": [
        "Seung Hyun Cheon",
        "Meredith Stewart",
        "Bogdan Kulynych",
        "Tsui-Wei Weng",
        "and Berk Ustun"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T21:50:08+00:00",
          "link": "https://arxiv.org/abs/2507.02169v1",
          "size": "991kb",
          "version": "v1"
        }
      ],
      "title": "Statistical Inference for Responsiveness Verification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02169",
        "PDF": "https://arxiv.org/pdf/2507.02169"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on statistical inference for model prediction responsiveness and safety, unrelated to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02170",
      "abstract": "This paper explores the integration of advanced Multi-Agent Systems (MAS) techniques to develop a team of agents with enhanced logical reasoning, long-term knowledge retention, and Theory of Mind (ToM) capabilities. By uniting these core components with optimized communication protocols, we create a novel framework called SynergyMAS, which fosters collaborative teamwork and superior problem-solving skills. The system's effectiveness is demonstrated through a product development team case study, where our approach significantly enhances performance and adaptability. These findings highlight SynergyMAS's potential to tackle complex, real-world challenges.",
      "authors": [
        "Adam Kostka and Jaros{\\l}aw A. Chudziak"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T21:53:44+00:00",
          "link": "https://arxiv.org/abs/2507.02170v1",
          "size": "828kb",
          "version": "v1"
        }
      ],
      "title": "Synergizing Logical Reasoning, Knowledge Management and Collaboration in Multi-Agent LLM System",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02170",
        "HTML": "https://arxiv.org/html/2507.02170v1",
        "PDF": "https://arxiv.org/pdf/2507.02170"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The work explores integrating multi-agent systems for logical reasoning and collaboration, lacking any mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02171",
      "abstract": "Trajectory planning in robotics is understood as generating a sequence of joint configurations that will lead a robotic agent, or its manipulator, from an initial state to the desired final state, thus completing a manipulation task while considering constraints like robot kinematics and the environment. Typically, this is achieved via sampling-based planners, which are computationally intensive. Recent advances demonstrate that trajectory planning can also be performed by supervised sequence learning of trajectories, often requiring only a single or fixed number of passes through a neural architecture, thus ensuring a bounded computation time. Such fully supervised approaches, however, perform imitation learning; they do not learn based on whether the trajectories can successfully reach a goal, but try to reproduce observed trajectories. In our work, we build on this approach and propose a cognitively inspired self-supervised learning scheme based on a recurrent architecture for building a trajectory model. We evaluate the feasibility of the proposed method on a task of kinematic planning for a robotic arm. The results suggest that the model is able to learn to generate trajectories only using given paired forward and inverse kinematics models, and indicate that this novel method could facilitate planning for more complex manipulation tasks requiring adaptive solutions.",
      "authors": [
        "Miroslav Cibula",
        "Krist\\'ina Malinovsk\\'a",
        "Matthias Kerzel"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T22:05:58+00:00",
          "link": "https://arxiv.org/abs/2507.02171v1",
          "size": "893kb",
          "version": "v1"
        }
      ],
      "title": "Towards Bio-Inspired Robotic Trajectory Planning via Self-Supervised RNN",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02171",
        "HTML": "https://arxiv.org/html/2507.02171v1",
        "PDF": "https://arxiv.org/pdf/2507.02171"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on trajectory planning for robotics using self-supervised RNNs and does not discuss any aspect related to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02173",
      "abstract": "While recent advances in preference learning have enhanced alignment in human feedback, mathematical reasoning remains a persistent challenge. We investigate how data diversification strategies in preference optimization can improve the mathematical reasoning abilities of large language models (LLMs). We evaluate three common data generation methods: temperature sampling, Chain-of-Thought prompting, and Monte Carlo Tree Search (MCTS), and introduce Diversified-ThinkSolve (DTS), a novel structured approach that systematically decomposes problems into diverse reasoning paths. Our results show that with strategically diversified preference data, models can substantially improve mathematical reasoning performance, with the best approach yielding gains of 7.1% on GSM8K and 4.2% on MATH over the base model. Despite its strong performance, DTS incurs only a marginal computational overhead (1.03x) compared to the baseline, while MCTS is nearly five times more costly with lower returns. These findings demonstrate that structured exploration of diverse problem-solving methods creates more effective preference data for mathematical alignment than traditional approaches.",
      "authors": [
        "Berkan Dokmeci",
        "Qingyang Wu",
        "Ben Athiwaratkun",
        "Ce Zhang",
        "Shuaiwen Leon Song",
        "James Zou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T22:12:03+00:00",
          "link": "https://arxiv.org/abs/2507.02173v1",
          "size": "7681kb",
          "version": "v1"
        }
      ],
      "title": "Data Diversification Methods In Alignment Enhance Math Performance In LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02173",
        "HTML": "https://arxiv.org/html/2507.02173v1",
        "PDF": "https://arxiv.org/pdf/2507.02173"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces methods for improving LLMs' mathematical reasoning through data diversification, it does not focus on novel data engineering or processing techniques for LLM training data. It mainly evaluates data generation methods in the context of preference alignment."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02176",
      "abstract": "Modeling voice identity is challenging due to its multifaceted nature. In generative speech systems, identity is often assessed using automatic speaker verification (ASV) embeddings, designed for discrimination rather than characterizing identity. This paper investigates which aspects of a voice are captured in such representations. We find that widely used ASV embeddings focus mainly on static features like timbre and pitch range, while neglecting dynamic elements such as rhythm. We also identify confounding factors that compromise speaker similarity measurements and suggest mitigation strategies. To address these gaps, we propose U3D, a metric that evaluates speakers' dynamic rhythm patterns. This work contributes to the ongoing challenge of assessing speaker identity consistency in the context of ever-better voice cloning systems. We publicly release our code.",
      "authors": [
        "Marc-Andr\\'e Carbonneau",
        "Benjamin van Niekerk",
        "Hugo Seut\\'e",
        "Jean-Philippe Letendre",
        "Herman Kamper",
        "Julian Za\\\"idi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T22:16:42+00:00",
          "link": "https://arxiv.org/abs/2507.02176v1",
          "size": "98kb",
          "version": "v1"
        }
      ],
      "title": "Analyzing and Improving Speaker Similarity Assessment for Speech Synthesis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02176",
        "HTML": "https://arxiv.org/html/2507.02176v1",
        "PDF": "https://arxiv.org/pdf/2507.02176"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about improving speaker similarity assessment in speech synthesis and does not address LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02177",
      "abstract": "This work investigates how to monitor access to Android zero-permission sensors which could cause privacy leakage to users. Moreover, monitoring such sensitive access allows security researchers to characterize potential sensor abuse patterns. Zero-permission sensors such as accelerometers have become an indispensable part of Android devices. The critical information they provide has attracted extensive research investigating how data collectors could capture more sensor data to enable both benign and exploitative applications. In contrast, little work has explored how to enable data providers, such as end users, to understand sensor usage. While existing methods such as static analysis and hooking-based dynamic analysis face challenges of requiring complicated development chains, rooting privilege, and app-specific reverse engineering analysis, our work aims to bridge this gap by developing ARMOUR for user-space runtime monitoring, leveraging the intrinsic sampling rate variation and convergence behaviors of Android. ARMOUR enables privacy-aware users to easily monitor how third-party apps use sensor data and support security researchers to perform rapid app-agnostic sensor access analysis. Our evaluation with 1,448 commercial applications shows the effectiveness of ARMOUR in detecting sensor usage in obfuscated code and other conditions, and observes salient sensor abuse patterns such as 50% of apps from seemingly sensor-independent categories accessing data of multiple zero-permission sensors. We analyze the impact of Android's recent policy changes on zero-permission sensors and remaining technical and regulatory problems.",
      "authors": [
        "Yan Long",
        "Jiancong Cui",
        "Yuqing Yang",
        "Tobias Alam",
        "Zhiqiang Lin",
        "Kevin Fu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T22:18:54+00:00",
          "link": "https://arxiv.org/abs/2507.02177v1",
          "size": "1940kb",
          "version": "v1"
        }
      ],
      "title": "ARMOUR US: Android Runtime Zero-permission Sensor Usage Monitoring from User Space",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02177",
        "HTML": "https://arxiv.org/html/2507.02177v1",
        "PDF": "https://arxiv.org/pdf/2507.02177"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research centers on monitoring sensor access in Android devices and is unrelated to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02180",
      "abstract": "Large language Models have only been widely available since 2022 and yet in less than three years have had a significant impact on approaches to education and educational technology. Here we review the domains in which they have been used, and discuss a variety of use cases, their successes and failures. We then progress to discussing how this is changing the dynamic for learners and educators, consider the main design challenges facing LLMs if they are to become truly helpful and effective as educational systems, and reflect on the learning paradigms they support. We make clear that the new interaction paradigms they bring are significant and argue that this approach will become so ubiquitous it will become the default way in which we interact with technologies, and revolutionise what people expect from computer systems in general. This leads us to present some specific and significant considerations for the design of educational technology in the future that are likely to be needed to ensure acceptance by the changing expectations of learners and users.",
      "authors": [
        "Russell Beale"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T22:23:26+00:00",
          "link": "https://arxiv.org/abs/2507.02180v1",
          "size": "73kb",
          "version": "v1"
        }
      ],
      "title": "The Revolution Has Arrived: What the Current State of Large Language Models in Education Implies for the Future",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02180",
        "HTML": "https://arxiv.org/html/2507.02180v1",
        "PDF": "https://arxiv.org/pdf/2507.02180"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper examines the impact and use of LLMs in educational contexts without discussing the processing or engineering of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02181",
      "abstract": "This paper introduces {\\em truncated inner $c$-differential cryptanalysis}, a novel technique that for the first time enables the practical application of $c$-differential uniformity to block ciphers. While Ellingsen et al. (IEEE Trans. Inf. Theory, 2020) established the notion of $c$-differential uniformity using $(F(x\\oplus a), cF(x))$, a key challenge remained: multiplication by $c$ disrupts the structural properties essential for block cipher analysis, particularly key addition.\n  We resolve this challenge by developing an \\emph{inner} $c$-differential approach where multiplication by $c$ affects the input: $(F(cx\\oplus a), F(x))$. We prove that the inner $c$-differential uniformity of a function $F$ equals the outer $c$-differential uniformity of $F^{-1}$, establishing a fundamental duality. This modification preserves cipher structure while enabling practical cryptanalytic applications.\n  Our main contribution is a comprehensive multi-faceted statistical-computational framework, implementing truncated $c$-differential analysis against the full 9-round Kuznyechik cipher (the inner $c$-differentials are immune to the key whitening at the backend). Through extensive computational analysis involving millions of differential pairs, we demonstrate statistically significant non-randomness across all tested round counts. For the full 9-round cipher, we identify multiple configurations triggering critical security alerts, with bias ratios reaching $1.7\\times$ and corrected p-values as low as $1.85 \\times 10^{-3}$, suggesting insufficient security margin against this new attack vector. This represents the first practical distinguisher against the full 9-round Kuznyechik.",
      "authors": [
        "Pantelimon Stanica",
        "Ranit Dutta",
        "Bimal Mandal"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T22:27:33+00:00",
          "link": "https://arxiv.org/abs/2507.02181v1",
          "size": "43kb",
          "version": "v1"
        }
      ],
      "title": "Extended c-differential distinguishers of full 9 and reduced-round Kuznyechik cipher",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02181",
        "HTML": "https://arxiv.org/html/2507.02181v1",
        "PDF": "https://arxiv.org/pdf/2507.02181"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on cryptanalysis of block ciphers using $c$-differential uniformity, which is unrelated to the processing or engineering of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02182",
      "abstract": "Common Business Oriented Language (COBOL) is a programming language used to develop business applications that are widely adopted by financial, business, and government agencies. Due to its age, complexity, and declining number of COBOL developers, maintaining COBOL codebases is becoming increasingly challenging. In particular, the lack of documentation makes it difficult for new developers to effectively understand and maintain COBOL systems. Existing research utilizes large language models (LLMs) to explain the functionality of code snippets. However, COBOL presents unique challenges due to its architectural and syntactical differences, which often cause its code to exceed the token window size of LLMs. In this work, we propose a multi-agent approach that leverages two LLM-based agents working collaboratively to generate explanations for functions, files, and the overall project. These agents incorporate together by utilizing contextual information from the codebase into the code explanation prompts. We evaluate the effectiveness of our approach using 14 open-source, real-world COBOL projects. Our results indicate that our approach performs significantly better than the baseline in function code explanation, with improvements of 12.67%, 18.59%, and 0.62% in terms of METEOR, chrF, and SentenceBERT scores, respectively. At the file level, our approach effectively explains both short and long COBOL files that exceed the token window size of LLMs and surpass the baseline by 4.21%, 10.72%, and 14.68% in explaining the purpose, functionality, and clarity of the generated explanation. At the project level, our approach generates explanations that convey the functionality and purpose of 82% of the selected projects.",
      "authors": [
        "Fangjian Lei",
        "Jiawen Liu",
        "Shayan Noei",
        "Ying Zou",
        "Derek Truong",
        "William Alexander"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T22:28:35+00:00",
          "link": "https://arxiv.org/abs/2507.02182v1",
          "size": "507kb",
          "version": "v1"
        }
      ],
      "title": "Enhancing COBOL Code Explanations: A Multi-Agents Approach Using Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02182",
        "HTML": "https://arxiv.org/html/2507.02182v1",
        "PDF": "https://arxiv.org/pdf/2507.02182"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "Although the paper involves large language models, it focuses on enhancing COBOL code explanations using a multi-agent approach and does not address LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02183",
      "abstract": "Generative AI tools - most notably large language models (LLMs) like ChatGPT and Codex - are rapidly revolutionizing computer science education. These tools can generate, debug, and explain code, thereby transforming the landscape of programming instruction. This paper examines the profound opportunities that AI offers for enhancing computer science education in general, from coding assistance to fostering innovative pedagogical practices and streamlining assessments. At the same time, it highlights challenges including academic integrity concerns, the risk of over-reliance on AI, and difficulties in verifying originality. We discuss what computer science educators should teach in the AI era, how to best integrate these technologies into curricula, and the best practices for assessing student learning in an environment where AI can generate code, prototypes and user feedback. Finally, we propose a set of policy recommendations designed to harness the potential of generative AI while preserving the integrity and rigour of computer science education. Empirical data and emerging studies are used throughout to support our arguments.",
      "authors": [
        "Russell Beale"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T22:28:45+00:00",
          "link": "https://arxiv.org/abs/2507.02183v1",
          "size": "67kb",
          "version": "v1"
        }
      ],
      "title": "Computer Science Education in the Age of Generative AI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02183",
        "HTML": "https://arxiv.org/html/2507.02183v1",
        "PDF": "https://arxiv.org/pdf/2507.02183"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the impact of generative AI and LLMs on computer science education but does not relate to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02186",
      "abstract": "With the broad availability of large language models and their ability to generate vast outputs using varied prompts and configurations, determining the best output for a given task requires an intensive evaluation process, one where machine learning practitioners must decide how to assess the outputs and then carefully carry out the evaluation. This process is both time-consuming and costly. As practitioners work with an increasing number of models, they must now evaluate outputs to determine which model and prompt performs best for a given task. LLMs are increasingly used as evaluators to filter training data, evaluate model performance, assess harms and risks, or assist human evaluators with detailed assessments. We present EvalAssist, a framework that simplifies the LLM-as-a-judge workflow. The system provides an online criteria development environment, where users can interactively build, test, and share custom evaluation criteria in a structured and portable format. We support a set of LLM-based evaluation pipelines that leverage off-the-shelf LLMs and use a prompt-chaining approach we developed and contributed to the UNITXT open-source library. Additionally, our system also includes specially trained evaluators to detect harms and risks in LLM outputs. We have deployed the system internally in our organization with several hundreds of users.",
      "authors": [
        "Zahra Ashktorab",
        "Elizabeth M. Daly",
        "Erik Miehling",
        "Werner Geyer",
        "Martin Santillan Cooper",
        "Tejaswini Pedapati",
        "Michael Desmond",
        "Qian Pan",
        "and Hyo Jin Do"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T22:45:39+00:00",
          "link": "https://arxiv.org/abs/2507.02186v1",
          "size": "1666kb",
          "version": "v1"
        }
      ],
      "title": "EvalAssist: A Human-Centered Tool for LLM-as-a-Judge",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02186",
        "HTML": "https://arxiv.org/html/2507.02186v1",
        "PDF": "https://arxiv.org/pdf/2507.02186"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the main focus is on LLM evaluation and filtering of outputs, it mentions LLMs being used as evaluators to filter training data, which partially relates to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02187",
      "abstract": "There is growing industry interest in creating unobtrusive designs for electrooculography (EOG) sensing of eye gestures on glasses (e.g. JINS MEME and Apple eyewear). We present VergeIO, the first EOG-based glasses that enables depth-aware eye interaction using vergence with an optimized electrode layout and novel smart glass prototype. It can distinguish between four and six depth-based eye gestures with 83-98% accuracy using personalized models in a user study across 11 users and 1,320 gesture instances. It generalizes to unseen users with an accuracy of 80-98% without any calibration. To reduce false detections, we incorporate a motion artifact detection pipeline and a preamble-based activation scheme. The system uses dry sensors without any adhesives or gel, and operates in real time with 3 mW power consumption by the sensing front-end, making it suitable for always-on sensing.",
      "authors": [
        "Xiyuxing Zhang",
        "Duc Vu",
        "Chengyi Shen",
        "Yuntao Wang",
        "Yuanchun Shi",
        "Justin Chan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T22:47:37+00:00",
          "link": "https://arxiv.org/abs/2507.02187v1",
          "size": "6159kb",
          "version": "v1"
        }
      ],
      "title": "VergeIO: Depth-Aware Eye Interaction on Glasses",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02187",
        "HTML": "https://arxiv.org/html/2507.02187v1",
        "PDF": "https://arxiv.org/pdf/2507.02187"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about the development of an EOG-based glasses system for depth-aware eye interaction, not related to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02190",
      "abstract": "Vision-Language-Action (VLA) models offer a compelling framework for tackling complex robotic manipulation tasks, but they are often expensive to train. In this paper, we propose a novel VLA approach that leverages the competitive performance of Vision Language Models (VLMs) on 2D images to directly infer robot end-effector poses in image frame coordinates. Unlike prior VLA models that output low-level controls, our model predicts trajectory waypoints, making it both more efficient to train and robot embodiment agnostic. Despite its lightweight design, our next-token prediction architecture effectively learns meaningful and executable robot trajectories. We further explore the underutilized potential of incorporating depth images, inference-time techniques such as decoding strategies, and demonstration-conditioned action generation. Our model is trained on a simulated dataset and exhibits strong sim-to-real transfer capabilities. We evaluate our approach using a combination of simulated and real data, demonstrating its effectiveness on a real robotic system.",
      "authors": [
        "Max Argus",
        "Jelena Bratulic",
        "Houman Masnavi",
        "Maxim Velikanov",
        "Nick Heppert",
        "Abhinav Valada",
        "Thomas Brox"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T22:56:41+00:00",
          "link": "https://arxiv.org/abs/2507.02190v1",
          "size": "2615kb",
          "version": "v1"
        }
      ],
      "title": "cVLA: Towards Efficient Camera-Space VLAs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02190",
        "HTML": "https://arxiv.org/html/2507.02190v1",
        "PDF": "https://arxiv.org/pdf/2507.02190"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a novel robotic manipulation approach using Vision Language Models, but does not address data processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02197",
      "abstract": "As LLMs are increasingly studied as role-playing agents to generate synthetic data for human behavioral research, ensuring that their outputs remain coherent with their assigned roles has become a critical concern. In this paper, we investigate how consistently LLM-based role-playing agents' stated beliefs about the behavior of the people they are asked to role-play (\"what they say\") correspond to their actual behavior during role-play (\"how they act\"). Specifically, we establish an evaluation framework to rigorously measure how well beliefs obtained by prompting the model can predict simulation outcomes in advance. Using an augmented version of the GenAgents persona bank and the Trust Game (a standard economic game used to quantify players' trust and reciprocity), we introduce a belief-behavior consistency metric to systematically investigate how it is affected by factors such as: (1) the types of beliefs we elicit from LLMs, like expected outcomes of simulations versus task-relevant attributes of individual characters LLMs are asked to simulate; (2) when and how we present LLMs with relevant information about Trust Game; and (3) how far into the future we ask the model to forecast its actions. We also explore how feasible it is to impose a researcher's own theoretical priors in the event that the originally elicited beliefs are misaligned with research objectives. Our results reveal systematic inconsistencies between LLMs' stated (or imposed) beliefs and the outcomes of their role-playing simulation, at both an individual- and population-level. Specifically, we find that, even when models appear to encode plausible beliefs, they may fail to apply them in a consistent way. These findings highlight the need to identify how and when LLMs' stated beliefs align with their simulated behavior, allowing researchers to use LLM-based agents appropriately in behavioral studies.",
      "authors": [
        "Amogh Mannekote",
        "Adam Davies",
        "Guohao Li",
        "Kristy Elizabeth Boyer",
        "ChengXiang Zhai",
        "Bonnie J Dorr",
        "Francesco Pinto"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T23:30:51+00:00",
          "link": "https://arxiv.org/abs/2507.02197v1",
          "size": "119kb",
          "version": "v1"
        }
      ],
      "title": "Do Role-Playing Agents Practice What They Preach? Belief-Behavior Consistency in LLM-Based Simulations of Human Trust",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02197",
        "HTML": "https://arxiv.org/html/2507.02197v1",
        "PDF": "https://arxiv.org/pdf/2507.02197"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper explores the use of LLMs for role-playing in behavioral simulations, mentioning the creation of synthetic data (a dataset), but it does not primarily focus on the design or processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02198",
      "abstract": "This paper presents an extension of the DRIFT invariant state estimation framework, enabling robust fusion of GPS and IMU data for accurate pose and heading estimation. Originally developed for testing and usage on a marine autonomous surface vehicle (ASV), this approach can also be utilized on other mobile systems. Building upon the original proprioceptive only DRIFT algorithm, we develop a symmetry-preserving sensor fusion pipeline utilizing the invariant extended Kalman filter (InEKF) to integrate global position updates from GPS directly into the correction step. Crucially, we introduce a novel heading correction mechanism that leverages GPS course-over-ground information in conjunction with IMU orientation, overcoming the inherent unobservability of yaw in dead-reckoning. The system was deployed and validated on a customized Blue Robotics BlueBoat, but the methodological focus is on the algorithmic approach to fusing exteroceptive and proprioceptive sensors for drift-free localization and reliable orientation estimation. This work provides an open source solution for accurate yaw observation and localization in challenging or GPS-degraded conditions, and lays the groundwork for future experimental and comparative studies.",
      "authors": [
        "Surya Pratap Singh",
        "Tsimafei Lazouski",
        "Maani Ghaffari"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T23:32:54+00:00",
          "link": "https://arxiv.org/abs/2507.02198v1",
          "size": "1139kb",
          "version": "v1"
        }
      ],
      "title": "GPS-DRIFT: Marine Surface Robot Localization using IMU-GPS Fusion and Invariant Filtering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02198",
        "HTML": "https://arxiv.org/html/2507.02198v1",
        "PDF": "https://arxiv.org/pdf/2507.02198"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses sensor fusion for robot localization, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02199",
      "abstract": "Chain-of-thought (CoT) reasoning has enabled transformer-based language models to excel at complex mathematics and multi-step planning. However, in standard decoder-only architectures, these reasoning steps are externalized in natural language, improving interpretability at the cost of efficiency. To capture reasoning that is not easily represented in words, many works have explored recurrent architectures that aim to internalize reasoning in latent space, potentially supporting latent CoT. In this paper, we investigate whether such reasoning structures emerge in Huginn-3.5B, a depth-recurrent Transformer that reuses layers at inference time without increasing parameter count. We examine the model's internal behavior on arithmetic tasks using a suite of probing techniques including the Logit Lens and Coda Lens. Our findings reveal limited evidence of interpretable latent CoT by tracking rank trajectories of final and intermediate result tokens. Furthermore, we uncover significant probing inconsistencies across recurrent blocks, where the interpretability of hidden states depends heavily on both the layer index and the decoding method. Finally, we empirically show that increasing recurrence depth yields only marginal gains and falls well short of models that explicitly externalize reasoning steps. The code is available at https://github.com/wenquanlu/huginn-latent-cot.",
      "authors": [
        "Wenquan Lu",
        "Yuechuan Yang",
        "Kyle Lee",
        "Yanshu Li",
        "Enqi Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T23:35:21+00:00",
          "link": "https://arxiv.org/abs/2507.02199v1",
          "size": "678kb",
          "version": "v1"
        }
      ],
      "title": "Latent Chain-of-Thought? Decoding the Depth-Recurrent Transformer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02199",
        "HTML": "https://arxiv.org/html/2507.02199v1",
        "PDF": "https://arxiv.org/pdf/2507.02199"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on examining the internal behavior of a depth-recurrent Transformer model for reasoning tasks and does not discuss processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02200",
      "abstract": "Event stream based scene text recognition is a newly arising research topic in recent years which performs better than the widely used RGB cameras in extremely challenging scenarios, especially the low illumination, fast motion. Existing works either adopt end-to-end encoder-decoder framework or large language models for enhanced recognition, however, they are still limited by the challenges of insufficient interpretability and weak contextual logical reasoning. In this work, we propose a novel chain-of-thought reasoning based event stream scene text recognition framework, termed ESTR-CoT. Specifically, we first adopt the vision encoder EVA-CLIP (ViT-G/14) to transform the input event stream into tokens and utilize a Llama tokenizer to encode the given generation prompt. A Q-former is used to align the vision token to the pre-trained large language model Vicuna-7B and output both the answer and chain-of-thought (CoT) reasoning process simultaneously. Our framework can be optimized using supervised fine-tuning in an end-to-end manner. In addition, we also propose a large-scale CoT dataset to train our framework via a three stage processing (i.e., generation, polish, and expert verification). This dataset provides a solid data foundation for the development of subsequent reasoning-based large models. Extensive experiments on three event stream STR benchmark datasets (i.e., EventSTR, WordArt*, IC15*) fully validated the effectiveness and interpretability of our proposed framework. The source code and pre-trained models will be released on https://github.com/Event-AHU/ESTR-CoT.",
      "authors": [
        "Xiao Wang",
        "Jingtao Jiang",
        "Qiang Chen",
        "Lan Chen",
        "Lin Zhu",
        "Yaowei Wang",
        "Yonghong Tian",
        "Jin Tang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T23:41:31+00:00",
          "link": "https://arxiv.org/abs/2507.02200v1",
          "size": "8456kb",
          "version": "v1"
        }
      ],
      "title": "ESTR-CoT: Towards Explainable and Accurate Event Stream based Scene Text Recognition with Chain-of-Thought Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02200",
        "HTML": "https://arxiv.org/html/2507.02200v1",
        "PDF": "https://arxiv.org/pdf/2507.02200"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces a new framework for scene text recognition using chain-of-thought reasoning, and notably proposes a large-scale dataset for training, which involves a multi-stage data processing approach, directly contributing to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02205",
      "abstract": "Compound Expression Recognition (CER), a subfield of affective computing, aims to detect complex emotional states formed by combinations of basic emotions. In this work, we present a novel zero-shot multimodal approach for CER that combines six heterogeneous modalities into a single pipeline: static and dynamic facial expressions, scene and label matching, scene context, audio, and text. Unlike previous approaches relying on task-specific training data, our approach uses zero-shot components, including Contrastive Language-Image Pretraining (CLIP)-based label matching and Qwen-VL for semantic scene understanding. We further introduce a Multi-Head Probability Fusion (MHPF) module that dynamically weights modality-specific predictions, followed by a Compound Expressions (CE) transformation module that uses Pair-Wise Probability Aggregation (PPA) and Pair-Wise Feature Similarity Aggregation (PFSA) methods to produce interpretable compound emotion outputs. Evaluated under multi-corpus training, the proposed approach shows F1 scores of 46.95% on AffWild2, 49.02% on Acted Facial Expressions in The Wild (AFEW), and 34.85% on C-EXPR-DB via zero-shot testing, which is comparable to the results of supervised approaches trained on target data. This demonstrates the effectiveness of the proposed approach for capturing CE without domain adaptation. The source code is publicly available.",
      "authors": [
        "Elena Ryumina",
        "Maxim Markitantov",
        "Alexandr Axyonov",
        "Dmitry Ryumin",
        "Mikhail Dolgushin",
        "Alexey Karpov"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T23:51:40+00:00",
          "link": "https://arxiv.org/abs/2507.02205v1",
          "size": "97kb",
          "version": "v1"
        }
      ],
      "title": "Team RAS in 9th ABAW Competition: Multimodal Compound Expression Recognition Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02205",
        "HTML": "https://arxiv.org/html/2507.02205v1",
        "PDF": "https://arxiv.org/pdf/2507.02205"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a zero-shot multimodal approach for Compound Expression Recognition, which does not involve LLM training data processing, focusing instead on emotion detection without specific data engineering contributions."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02206",
      "abstract": "True Random Number Generators (TRNGs) play a fundamental role in hardware security, cryptographic systems, and data protection. In the context of Deep NeuralNetworks (DNNs), safeguarding model parameters, particularly weights, is critical to ensure the integrity, privacy, and intel-lectual property of AI systems. While software-based pseudo-random number generators are widely used, they lack the unpredictability and resilience offered by hardware-based TRNGs. In this work, we propose a novel and robust Encoding-in-Memory TRNG called EIM-TRNG that leverages the inherent physical randomness in DRAM cell behavior, particularly under RowHammer-induced disturbances, for the first time. We demonstrate how the unpredictable bit-flips generated through carefully controlled RowHammer operations can be harnessed as a reliable entropy source. Furthermore, we apply this TRNG framework to secure DNN weight data by encoding via a combination of fixed and unpredictable bit-flips. The encrypted data is later decrypted using a key derived from the probabilistic flip behavior, ensuring both data confidentiality and model authenticity. Our results validate the effectiveness of DRAM-based entropy extraction for robust, low-cost hardware security and offer a promising direction for protecting machine learning models at the hardware level.",
      "authors": [
        "Ranyang Zhou",
        "Abeer Matar A. Almalky",
        "Gamana Aragonda",
        "Sabbir Ahmed",
        "Filip Roth Tr{\\o}nnes-Christensen",
        "Adnan Siraj Rakin",
        "Shaahin Angizi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T00:01:33+00:00",
          "link": "https://arxiv.org/abs/2507.02206v1",
          "size": "1193kb",
          "version": "v1"
        }
      ],
      "title": "EIM-TRNG: Obfuscating Deep Neural Network Weights with Encoding-in-Memory True Random Number Generator via RowHammer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02206",
        "HTML": "https://arxiv.org/html/2507.02206v1",
        "PDF": "https://arxiv.org/pdf/2507.02206"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study revolves around hardware security and cryptographic systems, proposing a random number generator for encoding data, which does not contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02211",
      "abstract": "Recent studies in the spatial prisoner's dilemma games with reinforcement learning have shown that static agents can learn to cooperate through a diverse sort of mechanisms, including noise injection, different types of learning algorithms and neighbours' payoff knowledge.In this work, using an independent multi-agent Q-learning algorithm, we study the effects of dilution and mobility in the spatial version of the prisoner's dilemma. Within this setting, different possible actions for the algorithm are defined, connecting with previous results on the classical, non-reinforcement learning spatial prisoner's dilemma, showcasing the versatility of the algorithm in modeling different game-theoretical scenarios and the benchmarking potential of this approach.As a result, a range of effects is observed, including evidence that games with fixed update rules can be qualitatively equivalent to those with learned ones, as well as the emergence of a symbiotic mutualistic effect between populations that forms when multiple actions are defined.",
      "authors": [
        "Gustavo C. Mangold",
        "Heitor C. M. Fernandes",
        "and Mendeli H. Vainstein"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Neural and Evolutionary Computing (cs.NE)",
        "Computational Physics (physics.comp-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T00:17:53+00:00",
          "link": "https://arxiv.org/abs/2507.02211v1",
          "size": "2259kb",
          "version": "v1"
        }
      ],
      "title": "Dilution, Diffusion and Symbiosis in Spatial Prisoner's Dilemma with Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02211",
        "HTML": "https://arxiv.org/html/2507.02211v1",
        "PDF": "https://arxiv.org/pdf/2507.02211"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research addresses reinforcement learning in spatial prisoner's dilemma games, which does not involve LLM training data processing or any related data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02212",
      "abstract": "Graphical Abstracts (GAs) play a crucial role in visually conveying the key findings of scientific papers. While recent research has increasingly incorporated visual materials such as Figure 1 as de facto GAs, their potential to enhance scientific communication remains largely unexplored. Moreover, designing effective GAs requires advanced visualization skills, creating a barrier to their widespread adoption. To tackle these challenges, we introduce SciGA-145k, a large-scale dataset comprising approximately 145,000 scientific papers and 1.14 million figures, explicitly designed for supporting GA selection and recommendation as well as facilitating research in automated GA generation. As a preliminary step toward GA design support, we define two tasks: 1) Intra-GA recommendation, which identifies figures within a given paper that are well-suited to serve as GAs, and 2) Inter-GA recommendation, which retrieves GAs from other papers to inspire the creation of new GAs. We provide reasonable baseline models for these tasks. Furthermore, we propose Confidence Adjusted top-1 ground truth Ratio (CAR), a novel recommendation metric that offers a fine-grained analysis of model behavior. CAR addresses limitations in traditional ranking-based metrics by considering cases where multiple figures within a paper, beyond the explicitly labeled GA, may also serve as GAs. By unifying these tasks and metrics, our SciGA-145k establishes a foundation for advancing visual scientific communication while contributing to the development of AI for Science.",
      "authors": [
        "Takuro Kawada",
        "Shunsuke Kitada",
        "Sota Nemoto",
        "Hitoshi Iyatomi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T00:21:38+00:00",
          "link": "https://arxiv.org/abs/2507.02212v1",
          "size": "28345kb",
          "version": "v1"
        }
      ],
      "title": "SciGA: A Comprehensive Dataset for Designing Graphical Abstracts in Academic Papers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02212",
        "HTML": "https://arxiv.org/html/2507.02212v1",
        "PDF": "https://arxiv.org/pdf/2507.02212"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a large dataset (SciGA-145k) for graphical abstract design, which involves data construction but focuses on scientific communication rather than directly on LLM training or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02213",
      "abstract": "This work addresses the general problem of control synthesis for continuous-space, discrete-time stochastic systems with probabilistic guarantees via finite abstractions. While established methods exist, they often trade off accuracy for tractability. We propose a unified abstraction framework that improves both the tightness of probabilistic guarantees and computational efficiency. First, we introduce multi-interval MDPs (MI-MDPs), a generalization of interval-valued MDPs (IMDPs), which allows multiple, possibly overlapping clusters of successor states. This results in tighter abstractions but with increased computational complexity. To mitigate this, we further propose a generalized form of MDPs with set-valued transition probabilities (SMDPs), which model transitions as a fixed probability to a state cluster, followed by a non-deterministic choice within the cluster, as a sound abstraction. We show that control synthesis for MI-MDPs reduces to robust dynamic programming via linear optimization, while SMDPs admit even more efficient synthesis algorithms that avoid linear programming altogether. Theoretically, we prove that, given the partitioning of the state and disturbance spaces, both MI-MDPs and SMDPs yield tighter probabilistic guarantees than IMDPs, and that SMDPs are tighter than MI-MDPs. Extensive experiments across several benchmarks validate our theoretical results and demonstrate that SMDPs achieve favorable trade-offs among tightness, memory usage, and computation time.",
      "authors": [
        "Ibon Gracia",
        "Morteza Lahijanian"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T00:27:47+00:00",
          "link": "https://arxiv.org/abs/2507.02213v1",
          "size": "3682kb",
          "version": "v1"
        }
      ],
      "title": "Beyond Interval MDPs: Tight and Efficient Abstractions of Stochastic Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02213",
        "HTML": "https://arxiv.org/html/2507.02213v1",
        "PDF": "https://arxiv.org/pdf/2507.02213"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work proposes new abstractions for control synthesis in stochastic systems, not relating to LLM training data or data engineering processes for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02217",
      "abstract": "Learning robust object detectors from only a handful of images is a critical challenge in industrial vision systems, where collecting high quality training data can take months. Synthetic data has emerged as a key solution for data efficient visual inspection and pick and place robotics. Current pipelines rely on 3D engines such as Blender or Unreal, which offer fine control but still require weeks to render a small dataset, and the resulting images often suffer from a large gap between simulation and reality. Diffusion models promise a step change because they can generate high quality images in minutes, yet precise control, especially in low data regimes, remains difficult. Although many adapters now extend diffusion beyond plain text prompts, the effect of different conditioning schemes on synthetic data quality is poorly understood. We study eighty diverse visual concepts drawn from four standard object detection benchmarks and compare two conditioning strategies: prompt based and layout based. When the set of conditioning cues is narrow, prompt conditioning yields higher quality synthetic data; as diversity grows, layout conditioning becomes superior. When layout cues match the full training distribution, synthetic data raises mean average precision by an average of thirty four percent and by as much as one hundred seventy seven percent compared with using real data alone.",
      "authors": [
        "Brandon Trabucco",
        "Qasim Wani",
        "Benjamin Pikus",
        "Vasu Sharma"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T00:44:31+00:00",
          "link": "https://arxiv.org/abs/2507.02217v1",
          "size": "5020kb",
          "version": "v1"
        }
      ],
      "title": "Understanding Trade offs When Conditioning Synthetic Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02217",
        "HTML": "https://arxiv.org/html/2507.02217v1",
        "PDF": "https://arxiv.org/pdf/2507.02217"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses the generation of synthetic data for object detection using diffusion models, which is relevant to data quality for training but not specifically focused on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02221",
      "abstract": "Motivation: The Genomic Data Commons (GDC) provides access to high quality, harmonized cancer genomics data through a unified curation and analysis platform centered around patient cohorts. While GDC users can interactively create complex cohorts through the graphical Cohort Builder, users (especially new ones) may struggle to find specific cohort descriptors across hundreds of possible fields and properties. However, users may be better able to describe their desired cohort in free-text natural language.\n  Results: We introduce GDC Cohort Copilot, an open-source copilot tool for curating cohorts from the GDC. GDC Cohort Copilot automatically generates the GDC cohort filter corresponding to a user-input natural language description of their desired cohort, before exporting the cohort back to the GDC for further analysis. An interactive user interface allows users to further refine the generated cohort. We develop and evaluate multiple large language models (LLMs) for GDC Cohort Copilot and demonstrate that our locally-served, open-source GDC Cohort LLM achieves better results than GPT-4o prompting in generating GDC cohorts.\n  Availability and implementation: The standalone docker image for GDC Cohort Copilot is available at https://quay.io/repository/cdis/gdc-cohort-copilot. Source code is available at https://github.com/uc-cdis/gdc-cohort-copilot. GDC Cohort LLM weights are available at https://huggingface.co/uc-ctds.",
      "authors": [
        "Steven Song",
        "Anirudh Subramanyam",
        "Zhenyu Zhang",
        "Aarti Venkat",
        "Robert L. Grossman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T00:55:58+00:00",
          "link": "https://arxiv.org/abs/2507.02221v1",
          "size": "308kb",
          "version": "v1"
        }
      ],
      "title": "GDC Cohort Copilot: An AI Copilot for Curating Cohorts from the Genomic Data Commons",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02221",
        "HTML": "https://arxiv.org/html/2507.02221v1",
        "PDF": "https://arxiv.org/pdf/2507.02221"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a tool for curating genomic data cohorts, and although it involves LLMs for text processing, it focuses on genomic data rather than training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02222",
      "abstract": "The binarization of vision transformers (ViTs) offers a promising approach to addressing the trade-off between high computational/storage demands and the constraints of edge-device deployment. However, existing binary ViT methods often suffer from severe performance degradation or rely heavily on full-precision modules. To address these issues, we propose DIDB-ViT, a novel binary ViT that is highly informative while maintaining the original ViT architecture and computational efficiency. Specifically, we design an informative attention module incorporating differential information to mitigate information loss caused by binarization and enhance high-frequency retention. To preserve the fidelity of the similarity calculations between binary Q and K tensors, we apply frequency decomposition using the discrete Haar wavelet and integrate similarities across different frequencies. Additionally, we introduce an improved RPReLU activation function to restructure the activation distribution, expanding the model's representational capacity. Experimental results demonstrate that our DIDB-ViT significantly outperforms state-of-the-art network quantization methods in multiple ViT architectures, achieving superior image classification and segmentation performance.",
      "authors": [
        "Tian Gao and Zhiyuan Zhang and Kaijie Yin and Xu-Cheng Zhong and Hui Kong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T00:59:53+00:00",
          "link": "https://arxiv.org/abs/2507.02222v1",
          "size": "985kb",
          "version": "v1"
        }
      ],
      "title": "High-Fidelity Differential-information Driven Binary Vision Transformer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02222",
        "HTML": "https://arxiv.org/html/2507.02222v1",
        "PDF": "https://arxiv.org/pdf/2507.02222"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is focused on improving binary vision transformers and does not involve LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02225",
      "abstract": "Evaluating the accuracy of dimensionality reduction (DR) projections in preserving the structure of high-dimensional data is crucial for reliable visual analytics. Diverse evaluation metrics targeting different structural characteristics have thus been developed. However, evaluations of DR projections can become biased if highly correlated metrics--those measuring similar structural characteristics--are inadvertently selected, favoring DR techniques that emphasize those characteristics. To address this issue, we propose a novel workflow that reduces bias in the selection of evaluation metrics by clustering metrics based on their empirical correlations rather than on their intended design characteristics alone. Our workflow works by computing metric similarity using pairwise correlations, clustering metrics to minimize overlap, and selecting a representative metric from each cluster. Quantitative experiments demonstrate that our approach improves the stability of DR evaluation, which indicates that our workflow contributes to mitigating evaluation bias.",
      "authors": [
        "Jiyeon Bae",
        "Hyeon Jeon",
        "Jinwook Seo"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T01:07:02+00:00",
          "link": "https://arxiv.org/abs/2507.02225v1",
          "size": "486kb",
          "version": "v1"
        }
      ],
      "title": "Metric Design != Metric Behavior: Improving Metric Selection for the Unbiased Evaluation of Dimensionality Reduction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02225",
        "HTML": "https://arxiv.org/html/2507.02225v1",
        "PDF": "https://arxiv.org/pdf/2507.02225"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses dimensionality reduction evaluation metrics and does not relate to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02226",
      "abstract": "As one of their many applications, large language models (LLMs) have recently shown promise in automating register transfer level (RTL) code generation. However, conventional LLM decoding strategies, originally designed for natural language, often fail to meet the structural and semantic demands of RTL, leading to hallucinated, repetitive, or invalid code outputs. In this paper, we first investigate the root causes of these decoding failures through an empirical analysis of token-level entropy during RTL generation. Our findings reveal that LLMs exhibit low confidence in regions of structural ambiguity or semantic complexity, showing that standard decoding strategies fail to differentiate between regions requiring determinism (syntax-critical regions) and those that benefit from creative exploratory variability (design-critical regions). Then, to overcome this, we introduce DecoRTL, a novel run-time decoding strategy, that is both syntax-aware and contrastive for RTL code generation. DecoRTL integrates two complementary components: (i) self-consistency sampling, which generates multiple candidates and re-ranks them based on token-level agreement to promote correctness while maintaining diversity; and (ii) syntax-aware temperature adaptation, which classifies tokens by their syntactical and functional roles and adjusts the sampling temperature accordingly, enforcing low temperature for syntax-critical tokens and higher temperature for exploratory ones. Our approach operates entirely at inference time without requiring any additional model fine-tuning. Through evaluations on multiple open-source LLMs using the VerilogEval benchmark, we demonstrate significant improvements in syntactic validity, functional correctness, and output diversity, while the execution overhead (performance overhead) is imperceptible.",
      "authors": [
        "Mohammad Akyash",
        "Kimia Azar",
        "Hadi Kamali"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Programming Languages (cs.PL)",
        "Hardware Architecture (cs.AR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T01:17:44+00:00",
          "link": "https://arxiv.org/abs/2507.02226v1",
          "size": "422kb",
          "version": "v1"
        }
      ],
      "title": "DecoRTL: A Run-time Decoding Framework for RTL Code Generation with LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02226",
        "HTML": "https://arxiv.org/html/2507.02226v1",
        "PDF": "https://arxiv.org/pdf/2507.02226"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses improvements in RTL code generation using LLMs, focusing on decoding strategies, not on training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02227",
      "abstract": "Neural networks have emerged as powerful surrogates for solving partial differential equations (PDEs), offering significant computational speedups over traditional methods. However, these models suffer from a critical limitation: error accumulation during long-term rollouts, where small inaccuracies compound exponentially, eventually causing complete divergence from physically valid solutions. We present PhysicsCorrect, a training-free correction framework that enforces PDE consistency at each prediction step by formulating correction as a linearized inverse problem based on PDE residuals. Our key innovation is an efficient caching strategy that precomputes the Jacobian and its pseudoinverse during an offline warm-up phase, reducing computational overhead by two orders of magnitude compared to standard correction approaches. Across three representative PDE systems -- Navier-Stokes fluid dynamics, wave equations, and the chaotic Kuramoto-Sivashinsky equation -- PhysicsCorrect reduces prediction errors by up to 100x while adding negligible inference time (under 5\\%). The framework integrates seamlessly with diverse architectures including Fourier Neural Operators, UNets, and Vision Transformers, effectively transforming unstable neural surrogates into reliable simulation tools that bridge the gap between deep learning's computational efficiency and the physical fidelity demanded by practical scientific applications.",
      "authors": [
        "Xinquan Huang",
        "Paris Perdikaris"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T01:22:57+00:00",
          "link": "https://arxiv.org/abs/2507.02227v1",
          "size": "6362kb",
          "version": "v1"
        }
      ],
      "title": "PhysicsCorrect: A Training-Free Approach for Stable Neural PDE Simulations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02227",
        "HTML": "https://arxiv.org/html/2507.02227v1",
        "PDF": "https://arxiv.org/pdf/2507.02227"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is focused on improving neural network simulations for PDEs with a framework called PhysicsCorrect, which is concerned primarily with computational accuracy and efficiency rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02229",
      "abstract": "Collaborative problem solving (CPS) is a complex cognitive, social, and emotional process that is increasingly prevalent in educational and professional settings. This study investigates the emotional states of individuals during CPS using a mixed-methods approach. Teams of four first completed a novel CPS task. Immediately after, each individual was placed in an isolated room where they reviewed the video of their group performing the task and self-reported their internal experiences throughout the task. We performed a linguistic analysis of these internal monologues, providing insights into the range of emotions individuals experience during CPS. Our analysis showed distinct patterns in language use, including characteristic unigrams and bigrams, key words and phrases, emotion labels, and semantic similarity between emotion-related words.",
      "authors": [
        "Sifatul Anindho",
        "Videep Venkatesha",
        "Mariah Bradford",
        "Anne M. Cleary",
        "Nathaniel Blanchard"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T01:41:49+00:00",
          "link": "https://arxiv.org/abs/2507.02229v1",
          "size": "4810kb",
          "version": "v1"
        }
      ],
      "title": "An Exploration of Internal States in Collaborative Problem Solving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02229",
        "HTML": "https://arxiv.org/html/2507.02229v1",
        "PDF": "https://arxiv.org/pdf/2507.02229"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores internal emotional states during collaborative problem-solving tasks and uses linguistic analysis, but it does not address any aspect of LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02233",
      "abstract": "This paper addresses the challenge of fault root cause identification in cloud computing environments. The difficulty arises from complex system structures, dense service coupling, and limited fault information. To solve this problem, an intelligent identification algorithm based on transfer learning is proposed. The method introduces a shared feature extraction module and a domain adversarial mechanism to enable effective knowledge transfer from the source domain to the target domain. This improves the model's discriminative ability and generalization performance in the target domain. The model incorporates a pseudo-label selection strategy. When labeled samples are lacking in the target domain, high-confidence predictions are used in training. This enhances the model's ability to recognize minority classes. To evaluate the stability and adaptability of the method in real-world scenarios, experiments are designed under three conditions: label scarcity, class imbalance, and heterogeneous node environments. Experimental results show that the proposed method outperforms existing mainstream approaches in several key metrics, including accuracy, F1-Score, and AUC. The model demonstrates stronger discriminative power and robustness. Notably, under extreme class imbalance and significant structural differences in the target domain, the model still maintains high performance. This validates the effectiveness and practical value of the proposed mechanisms in complex cloud computing systems.",
      "authors": [
        "Bruce Fang",
        "Danyi Gao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T02:00:21+00:00",
          "link": "https://arxiv.org/abs/2507.02233v1",
          "size": "923kb",
          "version": "v1"
        }
      ],
      "title": "Domain-Adversarial Transfer Learning for Fault Root Cause Identification in Cloud Computing Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02233",
        "PDF": "https://arxiv.org/pdf/2507.02233"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a transfer learning method for fault cause identification in cloud computing, which does not relate to training data processing for LLMs but focuses on system fault diagnosis."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02235",
      "abstract": "Real-world optimization often demands diverse, high-quality solutions. Quality-Diversity (QD) optimization is a multifaceted approach in evolutionary algorithms that aims to generate a set of solutions that are both high-performing and diverse. QD algorithms have been successfully applied across various domains, providing robust solutions by exploring diverse behavioral niches. However, their application has primarily focused on static problems, with limited exploration in the context of dynamic combinatorial optimization problems. Furthermore, the theoretical understanding of QD algorithms remains underdeveloped, particularly when applied to learning heuristics instead of directly learning solutions in complex and dynamic combinatorial optimization domains, which introduces additional challenges. This paper introduces a novel QD framework for dynamic scheduling problems. We propose a map-building strategy that visualizes the solution space by linking heuristic genotypes to their behaviors, enabling their representation on a QD map. This map facilitates the discovery and maintenance of diverse scheduling heuristics. Additionally, we conduct experiments on both fixed and dynamically changing training instances to demonstrate how the map evolves and how the distribution of solutions unfolds over time. We also discuss potential future research directions that could enhance the learning process and broaden the applicability of QD algorithms to dynamic combinatorial optimization challenges.",
      "authors": [
        "Meng Xu",
        "Frank Neumann",
        "Aneta Neumann",
        "Yew Soon Ong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T02:01:30+00:00",
          "link": "https://arxiv.org/abs/2507.02235v1",
          "size": "625kb",
          "version": "v1"
        }
      ],
      "title": "Quality Diversity Genetic Programming for Learning Scheduling Heuristics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02235",
        "HTML": "https://arxiv.org/html/2507.02235v1",
        "PDF": "https://arxiv.org/pdf/2507.02235"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work introduces a Quality-Diversity genetic programming framework for scheduling heuristics, which is unrelated to LLM training data processing as it deals with optimization in combinatorial problems."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02241",
      "abstract": "In the current machine learning landscape, we face a \"model lake\" phenomenon: Given a task, there is a proliferation of trained models with similar performances despite different behavior. For model users attempting to navigate and select from the models, documentation comparing model pairs is helpful. However, for every $N$ models there could be $O(N^2)$ pairwise comparisons, a number prohibitive for the model developers to manually perform pairwise comparisons and prepare documentations. To facilitate fine-grained pairwise comparisons among models, we introduced $\\textbf{VERBA}$. Our approach leverages a large language model (LLM) to generate verbalizations of model differences by sampling from the two models. We established a protocol that evaluates the informativeness of the verbalizations via simulation. We also assembled a suite with a diverse set of commonly used machine learning models as a benchmark. For a pair of decision tree models with up to 5% performance difference but 20-25% behavioral differences, $\\textbf{VERBA}$ effectively verbalizes their variations with up to 80% overall accuracy. When we included the models' structural information, the verbalization's accuracy further improved to 90%. $\\textbf{VERBA}$ opens up new research avenues for improving the transparency and comparability of machine learning models in a post-hoc manner.",
      "authors": [
        "Shravan Doda",
        "Shashidhar Reddy Javaji",
        "Zining Zhu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T02:25:24+00:00",
          "link": "https://arxiv.org/abs/2507.02241v1",
          "size": "634kb",
          "version": "v1"
        }
      ],
      "title": "VERBA: Verbalizing Model Differences Using Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02241",
        "HTML": "https://arxiv.org/html/2507.02241v1",
        "PDF": "https://arxiv.org/pdf/2507.02241"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper uses LLMs to generate verbal comparisons between models, mentioning the use of large language models briefly. However, the core contribution is improving model transparency, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02244",
      "abstract": "The proliferation of ride-hailing aggregator platforms presents significant growth opportunities for ride-service providers by increasing order volume and gross merchandise value (GMV). On most ride-hailing aggregator platforms, service providers that offer lower fares are ranked higher in listings and, consequently, are more likely to be selected by passengers. This competitive ranking mechanism creates a strong incentive for service providers to adopt coupon strategies that lower prices to secure a greater number of orders, as order volume directly influences their long-term viability and sustainability. Thus, designing an effective coupon strategy that can dynamically adapt to market fluctuations while optimizing order acquisition under budget constraints is a critical research challenge. However, existing studies in this area remain scarce.\n  To bridge this gap, we propose FCA-RL, a novel reinforcement learning-based subsidy strategy framework designed to rapidly adapt to competitors' pricing adjustments. Our approach integrates two key techniques: Fast Competition Adaptation (FCA), which enables swift responses to dynamic price changes, and Reinforced Lagrangian Adjustment (RLA), which ensures adherence to budget constraints while optimizing coupon decisions on new price landscape. Furthermore, we introduce RideGym, the first dedicated simulation environment tailored for ride-hailing aggregators, facilitating comprehensive evaluation and benchmarking of different pricing strategies without compromising real-world operational efficiency. Experimental results demonstrate that our proposed method consistently outperforms baseline approaches across diverse market conditions, highlighting its effectiveness in subsidy optimization for ride-hailing service providers.",
      "authors": [
        "Fangzhou Shi",
        "Xiaopeng Ke",
        "Xinye Xiong",
        "Kexin Meng",
        "Chang Men",
        "Zhengdan Zhu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T02:38:42+00:00",
          "link": "https://arxiv.org/abs/2507.02244v1",
          "size": "11354kb",
          "version": "v1"
        }
      ],
      "title": "Order Acquisition Under Competitive Pressure: A Rapidly Adaptive Reinforcement Learning Approach for Ride-Hailing Subsidy Strategies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02244",
        "HTML": "https://arxiv.org/html/2507.02244v1",
        "PDF": "https://arxiv.org/pdf/2507.02244"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a reinforcement learning approach for ride-hailing subsidy strategies and introduces a simulation environment for such strategies, with no mention of LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02245",
      "abstract": "We present CoInfra, a large-scale cooperative infrastructure perception system and dataset designed to advance robust multi-agent perception under real-world and adverse weather conditions. The CoInfra system includes 14 fully synchronized sensor nodes, each equipped with dual RGB cameras and a LiDAR, deployed across a shared region and operating continuously to capture all traffic participants in real-time. A robust, delay-aware synchronization protocol and a scalable system architecture that supports real-time data fusion, OTA management, and remote monitoring are provided in this paper. On the other hand, the dataset was collected in different weather scenarios, including sunny, rainy, freezing rain, and heavy snow and includes 195k LiDAR frames and 390k camera images from 8 infrastructure nodes that are globally time-aligned and spatially calibrated. Furthermore, comprehensive 3D bounding box annotations for five object classes (i.e., car, bus, truck, person, and bicycle) are provided in both global and individual node frames, along with high-definition maps for contextual understanding. Baseline experiments demonstrate the trade-offs between early and late fusion strategies, the significant benefits of HD map integration are discussed. By openly releasing our dataset, codebase, and system documentation at https://github.com/NingMingHao/CoInfra, we aim to enable reproducible research and drive progress in infrastructure-supported autonomous driving, particularly in challenging, real-world settings.",
      "authors": [
        "Minghao Ning",
        "Yufeng Yang",
        "Keqi Shu",
        "Shucheng Huang",
        "Jiaming Zhong",
        "Maryam Salehi",
        "Mahdi Rahmani",
        "Yukun Lu",
        "Chen Sun",
        "Aladdin Saleh",
        "Ehsan Hashemi and Amir Khajepour"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T02:39:12+00:00",
          "link": "https://arxiv.org/abs/2507.02245v1",
          "size": "15201kb",
          "version": "v1"
        }
      ],
      "title": "CoInfra: A Large-Scale Cooperative Infrastructure Perception System and Dataset in Adverse Weather",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02245",
        "HTML": "https://arxiv.org/html/2507.02245v1",
        "PDF": "https://arxiv.org/pdf/2507.02245"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a cooperative infrastructure perception system and dataset for autonomous driving under adverse weather conditions, which is unrelated to LLM training data processing or data engineering."
      },
      "datasets": [
        {
          "dataset_name": "MinghaoNing/CoInfra",
          "downloads": "0",
          "likes": "1",
          "link": "https://huggingface.co/datasets/MinghaoNing/CoInfra"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.02250",
      "abstract": "3D semantic occupancy prediction plays a pivotal role in autonomous driving. However, inherent limitations of fewframe images and redundancy in 3D space compromise prediction accuracy for occluded and distant scenes. Existing methods enhance performance by fusing historical frame data, which need additional data and significant computational resources. To address these issues, this paper propose FMOcc, a Tri-perspective View (TPV) refinement occupancy network with flow matching selective state space model for few-frame 3D occupancy prediction. Firstly, to generate missing features, we designed a feature refinement module based on a flow matching model, which is called Flow Matching SSM module (FMSSM). Furthermore, by designing the TPV SSM layer and Plane Selective SSM (PS3M), we selectively filter TPV features to reduce the impact of air voxels on non-air voxels, thereby enhancing the overall efficiency of the model and prediction capability for distant scenes. Finally, we design the Mask Training (MT) method to enhance the robustness of FMOcc and address the issue of sensor data loss. Experimental results on the Occ3D-nuScenes and OpenOcc datasets show that our FMOcc outperforms existing state-of-theart methods. Our FMOcc with two frame input achieves notable scores of 43.1% RayIoU and 39.8% mIoU on Occ3D-nuScenes validation, 42.6% RayIoU on OpenOcc with 5.4 G inference memory and 330ms inference time.",
      "authors": [
        "Jiangxia Chen and Tongyuan Huang and Ke Song"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T02:58:39+00:00",
          "link": "https://arxiv.org/abs/2507.02250v1",
          "size": "3231kb",
          "version": "v1"
        }
      ],
      "title": "FMOcc: TPV-Driven Flow Matching for 3D Occupancy Prediction with Selective State Space Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02250",
        "HTML": "https://arxiv.org/html/2507.02250v1",
        "PDF": "https://arxiv.org/pdf/2507.02250"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "It addresses an approach to occupancy prediction in autonomous driving, focusing on flow matching and refinement, without discussing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02252",
      "abstract": "Precise surgical interventions are vital to patient safety, and advanced enhancement algorithms have been developed to assist surgeons in decision-making. Despite significant progress, these algorithms are typically designed for single tasks in specific scenarios, limiting their effectiveness in complex real-world situations. To address this limitation, we propose SurgVisAgent, an end-to-end intelligent surgical vision agent built on multimodal large language models (MLLMs). SurgVisAgent dynamically identifies distortion categories and severity levels in endoscopic images, enabling it to perform a variety of enhancement tasks such as low-light enhancement, overexposure correction, motion blur elimination, and smoke removal. Specifically, to achieve superior surgical scenario understanding, we design a prior model that provides domain-specific knowledge. Additionally, through in-context few-shot learning and chain-of-thought (CoT) reasoning, SurgVisAgent delivers customized image enhancements tailored to a wide range of distortion types and severity levels, thereby addressing the diverse requirements of surgeons. Furthermore, we construct a comprehensive benchmark simulating real-world surgical distortions, on which extensive experiments demonstrate that SurgVisAgent surpasses traditional single-task models, highlighting its potential as a unified solution for surgical assistance.",
      "authors": [
        "Zeyu Lei",
        "Hongyuan Yu",
        "Jinlin Wu",
        "Zhen Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T03:00:26+00:00",
          "link": "https://arxiv.org/abs/2507.02252v1",
          "size": "8819kb",
          "version": "v1"
        }
      ],
      "title": "SurgVisAgent: Multimodal Agentic Model for Versatile Surgical Visual Enhancement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02252",
        "HTML": "https://arxiv.org/html/2507.02252v1",
        "PDF": "https://arxiv.org/pdf/2507.02252"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes a multimodal model for surgical image enhancement, employing methodologies like few-shot learning but not explicitly focusing on LLM training data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02253",
      "abstract": "Progress in enhancing large language model (LLM) planning and reasoning capabilities is significantly hampered by the bottleneck of scalable, reliable data generation and evaluation. To overcome this, I introduce NL2FLOW, a fully automated system for parametrically generating planning problems - expressed in natural language, a structured intermediate representation, and formal PDDL - and rigorously evaluating the quality of generated plans. I demonstrate NL2FLOW's capabilities by generating a dataset of 2296 problems in the automated workflow generation domain and evaluating multiple open-sourced, instruct-tuned LLMs. My results reveal that the highest performing models achieved 86% success in generating valid plans and 69% in generating optimal plans, specifically for problems with feasible solutions. Regression analysis shows that the influence of problem characteristics on plan generation is contingent on both model and prompt design. Notably, I observed that the highest success rate for translating natural language into a JSON representation of a plan was lower than the highest rate of generating a valid plan directly. This suggests that unnecessarily decomposing the reasoning task - introducing intermediate translation steps - may actually degrade performance, implying a benefit to models capable of reasoning directly from natural language to action. As I scale LLM reasoning to increasingly complex problems, the bottlenecks and sources of error within these systems will inevitably shift. Therefore, a dynamic understanding of these limitations - and the tools to systematically reveal them - will be crucial for unlocking the full potential of LLMs as intelligent problem solvers.",
      "authors": [
        "Jungkoo Kang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T03:02:49+00:00",
          "link": "https://arxiv.org/abs/2507.02253v1",
          "size": "616kb",
          "version": "v1"
        }
      ],
      "title": "Scaling LLM Planning: NL2FLOW for Parametric Problem Generation and Rigorous Evaluation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02253",
        "HTML": "https://arxiv.org/html/2507.02253v1",
        "PDF": "https://arxiv.org/pdf/2507.02253"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces NL2FLOW, which is a system for generating data for planning problems in natural language and evaluating LLMs, but doesn't contribute new methods for LLM training data processing or preparation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02254",
      "abstract": "This paper presents a software architecture for 3D interaction techniques (ITs) and an object oriented, toolkit-independent framework that implements such architecture. ITs are composed of basic filters connected in a dataflow, where virtual input devices and objects in the scene are sources of information. An execution model defines the general flow of information between filters. This framework has been designed to be extensible: new information types, new input devices, new execution models, or new interaction techniques can easily be added. Application specific code and application specific ITs are seamlessly integrated into this architecture.",
      "authors": [
        "Pablo Figueroa",
        "Mark Green",
        "Benjamin Watson"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T03:05:00+00:00",
          "link": "https://arxiv.org/abs/2507.02254v1",
          "size": "59kb",
          "version": "v1"
        }
      ],
      "title": "A framework for 3D interaction techniques",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02254",
        "PDF": "https://arxiv.org/pdf/2507.02254"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a framework for 3D interaction techniques and does not relate to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02255",
      "abstract": "Preference alignment has achieved greater success on Large Language Models (LLMs) and drawn broad interest in recommendation research. Existing preference alignment methods for recommendation either require explicit reward modeling or only support pairwise preference comparison. The former directly increases substantial computational costs, while the latter hinders training efficiency on negative samples. Moreover, no existing effort has explored preference alignment solutions for tail-item recommendation. To bridge the above gaps, we propose LPO4Rec, which extends the Bradley-Terry model from pairwise comparison to listwise comparison, to improve the efficiency of model training. Specifically, we derive a closed form optimal policy to enable more efficient and effective training without explicit reward modeling. We also present an adaptive negative sampling and reweighting strategy to prioritize tail items during optimization and enhance performance in tail-item recommendations. Besides, we theoretically prove that optimizing the listwise preference optimization (LPO) loss is equivalent to maximizing the upper bound of the optimal reward. Our experiments on three public datasets show that our method outperforms 10 baselines by a large margin, achieving up to 50% performance improvement while reducing 17.9% GPU memory usage when compared with direct preference optimization (DPO) in tail-item recommendation. Our code is available at https://github.com/Yuhanleeee/LPO4Rec.",
      "authors": [
        "Zihao Li",
        "Chao Yang",
        "Tong Zhang",
        "Yakun Chen",
        "Xianzhi Wang",
        "Guandong Xu",
        "Daoyi Dong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T03:08:23+00:00",
          "link": "https://arxiv.org/abs/2507.02255v1",
          "size": "1972kb",
          "version": "v1"
        }
      ],
      "title": "Listwise Preference Alignment Optimization for Tail Item Recommendation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02255",
        "HTML": "https://arxiv.org/html/2507.02255v1",
        "PDF": "https://arxiv.org/pdf/2507.02255"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work focuses on recommendation systems for tail item recommendations, utilizing listwise preference alignment, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02256",
      "abstract": "Designing effective reward functions is a cornerstone of reinforcement learning (RL), yet it remains a challenging process due to the inefficiencies and inconsistencies inherent in conventional reward engineering methodologies. Recent advances have explored leveraging large language models (LLMs) to automate reward function design. However, their suboptimal performance in numerical optimization often yields unsatisfactory reward quality, while the evolutionary search paradigm demonstrates inefficient utilization of simulation resources, resulting in prohibitively lengthy design cycles with disproportionate computational overhead. To address these challenges, we propose the Uncertainty-aware Reward Design Process (URDP), a novel framework that integrates large language models to streamline reward function design and evaluation in RL environments. URDP quantifies candidate reward function uncertainty based on self-consistency analysis, enabling simulation-free identification of ineffective reward components while discovering novel reward components. Furthermore, we introduce uncertainty-aware Bayesian optimization (UABO), which incorporates uncertainty estimation to significantly enhance hyperparameter configuration efficiency. Finally, we construct a bi-level optimization architecture by decoupling the reward component optimization and the hyperparameter tuning. URDP orchestrates synergistic collaboration between the reward logic reasoning of the LLMs and the numerical optimization strengths of the Bayesian Optimization. We conduct a comprehensive evaluation of URDP across 35 diverse tasks spanning three benchmark environments. Our experimental results demonstrate that URDP not only generates higher-quality reward functions but also achieves significant improvements in the efficiency of automated reward design compared to existing approaches.",
      "authors": [
        "Yang Yang",
        "Xiaolu Zhou",
        "Bosong Ding",
        "Miao Xin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T03:09:17+00:00",
          "link": "https://arxiv.org/abs/2507.02256v1",
          "size": "3834kb",
          "version": "v1"
        }
      ],
      "title": "Uncertainty-aware Reward Design Process",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02256",
        "PDF": "https://arxiv.org/pdf/2507.02256"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses reward function design in reinforcement learning and integrates LLMs for this purpose, but it does not involve LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02257",
      "abstract": "The growing popularity of 3D Gaussian Splatting has created the need to integrate traditional computer graphics techniques and assets in splatted environments. Since 3D Gaussian primitives encode lighting and geometry jointly as appearance, meshes are relit improperly when inserted directly in a mixture of 3D Gaussians and thus appear noticeably out of place. We introduce GBake, a specialized tool for baking reflection probes from Gaussian-splatted scenes that enables realistic reflection mapping of traditional 3D meshes in the Unity game engine.",
      "authors": [
        "Stephen Pasch",
        "Joel K. Salzman",
        "Changxi Zheng"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T03:09:19+00:00",
          "link": "https://arxiv.org/abs/2507.02257v1",
          "size": "9065kb",
          "version": "v1"
        }
      ],
      "title": "Gbake: Baking 3D Gaussian Splats into Reflection Probes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02257",
        "HTML": "https://arxiv.org/html/2507.02257v1",
        "PDF": "https://arxiv.org/pdf/2507.02257"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with integrating 3D Gaussian Splatting in computer graphics, which is unrelated to the processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02259",
      "abstract": "Despite improvements by length extrapolation, efficient attention and memory modules, handling infinitely long documents with linear complexity without performance degradation during extrapolation remains the ultimate challenge in long-text processing. We directly optimize for long-text tasks in an end-to-end fashion and introduce a novel agent workflow, MemAgent, which reads text in segments and updates the memory using an overwrite strategy. We extend the DAPO algorithm to facilitate training via independent-context multi-conversation generation. MemAgent has demonstrated superb long-context capabilities, being able to extrapolate from an 8K context trained on 32K text to a 3.5M QA task with performance loss < 5% and achieves 95%+ in 512K RULER test.",
      "authors": [
        "Hongli Yu",
        "Tinghong Chen",
        "Jiangtao Feng",
        "Jiangjie Chen",
        "Weinan Dai",
        "Qiying Yu",
        "Ya-Qin Zhang",
        "Wei-Ying Ma",
        "Jingjing Liu",
        "Mingxuan Wang",
        "Hao Zhou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T03:11:50+00:00",
          "link": "https://arxiv.org/abs/2507.02259v1",
          "size": "4734kb",
          "version": "v1"
        }
      ],
      "title": "MemAgent: Reshaping Long-Context LLM with Multi-Conv RL-based Memory Agent",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02259",
        "HTML": "https://arxiv.org/html/2507.02259v1",
        "PDF": "https://arxiv.org/pdf/2507.02259"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the development of memory agents for handling long-context LLMs and does not discuss data engineering or training-stage data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02265",
      "abstract": "Hurricanes cause widespread destruction, resulting in diverse damage types and severities that require timely and accurate assessment for effective disaster response. While traditional single-label classification methods fall short of capturing the complexity of post-hurricane damage, this study introduces a novel multi-label classification framework for assessing damage using aerial imagery. The proposed approach integrates a feature extraction module based on ResNet and a class-specific attention mechanism to identify multiple damage types within a single image. Using the Rescuenet dataset from Hurricane Michael, the proposed method achieves a mean average precision of 90.23%, outperforming existing baseline methods. This framework enhances post-hurricane damage assessment, enabling more targeted and efficient disaster response and contributing to future strategies for disaster mitigation and resilience. This paper has been accepted at the ASCE International Conference on Computing in Civil Engineering (i3CE 2025), and the camera-ready version will appear in the official conference proceedings.",
      "authors": [
        "Zhangding Liu",
        "Neda Mohammadi",
        "John E. Taylor"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T03:15:23+00:00",
          "link": "https://arxiv.org/abs/2507.02265v1",
          "size": "621kb",
          "version": "v1"
        }
      ],
      "title": "Multi-Label Classification Framework for Hurricane Damage Assessment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02265",
        "PDF": "https://arxiv.org/pdf/2507.02265"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a multi-label classification framework for hurricane damage assessment using aerial imagery, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02268",
      "abstract": "Utilizing hyperspectral remote sensing technology enables the extraction of fine-grained land cover classes. Typically, satellite or airborne images used for training and testing are acquired from different regions or times, where the same class has significant spectral shifts in different scenes. In this paper, we propose a Bi-directional Domain Adaptation (BiDA) framework for cross-domain hyperspectral image (HSI) classification, which focuses on extracting both domain-invariant features and domain-specific information in the independent adaptive space, thereby enhancing the adaptability and separability to the target scene. In the proposed BiDA, a triple-branch transformer architecture (the source branch, target branch, and coupled branch) with semantic tokenizer is designed as the backbone. Specifically, the source branch and target branch independently learn the adaptive space of source and target domains, a Coupled Multi-head Cross-attention (CMCA) mechanism is developed in coupled branch for feature interaction and inter-domain correlation mining. Furthermore, a bi-directional distillation loss is designed to guide adaptive space learning using inter-domain correlation. Finally, we propose an Adaptive Reinforcement Strategy (ARS) to encourage the model to focus on specific generalized feature extraction within both source and target scenes in noise condition. Experimental results on cross-temporal/scene airborne and satellite datasets demonstrate that the proposed BiDA performs significantly better than some state-of-the-art domain adaptation approaches. In the cross-temporal tree species classification task, the proposed BiDA is more than 3\\%$\\sim$5\\% higher than the most advanced method. The codes will be available from the website: https://github.com/YuxiangZhang-BIT/IEEE_TCSVT_BiDA.",
      "authors": [
        "Yuxiang Zhang",
        "Wei Li",
        "Wen Jia",
        "Mengmeng Zhang",
        "Ran Tao and Shunlin Liang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T03:22:28+00:00",
          "link": "https://arxiv.org/abs/2507.02268v1",
          "size": "21058kb",
          "version": "v1"
        }
      ],
      "title": "Cross-domain Hyperspectral Image Classification based on Bi-directional Domain Adaptation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02268",
        "HTML": "https://arxiv.org/html/2507.02268v1",
        "PDF": "https://arxiv.org/pdf/2507.02268"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a domain adaptation framework for hyperspectral image classification, focusing on feature extraction and adaptation, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02270",
      "abstract": "Enhancing underwater images is crucial for exploration. These images face visibility and color issues due to light changes, water turbidity, and bubbles. Traditional prior-based methods and pixel-based methods often fail, while deep learning lacks sufficient high-quality datasets. We introduce the Multi-Axis Conditional Lookup (MAC-Lookup) model, which enhances visual quality by improving color accuracy, sharpness, and contrast. It includes Conditional 3D Lookup Table Color Correction (CLTCC) for preliminary color and quality correction and Multi-Axis Adaptive Enhancement (MAAE) for detail refinement. This model prevents over-enhancement and saturation while handling underwater challenges. Extensive experiments show that MAC-Lookup excels in enhancing underwater images by restoring details and colors better than existing methods. The code is https://github.com/onlycatdoraemon/MAC-Lookup.",
      "authors": [
        "Fanghai Yi",
        "Zehong Zheng",
        "Zexiao Liang",
        "Yihang Dong",
        "Xiyang Fang",
        "Wangyu Wu",
        "Xuhang Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T03:23:00+00:00",
          "link": "https://arxiv.org/abs/2507.02270v1",
          "size": "3760kb",
          "version": "v1"
        }
      ],
      "title": "MAC-Lookup: Multi-Axis Conditional Lookup Model for Underwater Image Enhancement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02270",
        "HTML": "https://arxiv.org/html/2507.02270v1",
        "PDF": "https://arxiv.org/pdf/2507.02270"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a model for underwater image enhancement and does not address training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02271",
      "abstract": "Video-to-Audio (V2A) Generation achieves significant progress and plays a crucial role in film and video post-production. However, current methods overlook the cinematic language, a critical component of artistic expression in filmmaking. As a result, their performance deteriorates in scenarios where Foley targets are only partially visible. To address this challenge, we propose a simple self-distillation approach to extend V2A models to cinematic language scenarios. By simulating the cinematic language variations, the student model learns to align the video features of training pairs with the same audio-visual correspondences, enabling it to effectively capture the associations between sounds and partial visual information. Our method not only achieves impressive improvements under partial visibility across all evaluation metrics, but also enhances performance on the large-scale V2A dataset, VGGSound.",
      "authors": [
        "Feizhen Huang",
        "Yu Wu",
        "Yutian Lin",
        "Bo Du"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T03:23:11+00:00",
          "link": "https://arxiv.org/abs/2507.02271v1",
          "size": "1415kb",
          "version": "v1"
        }
      ],
      "title": "Spotlighting Partially Visible Cinematic Language for Video-to-Audio Generation via Self-distillation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02271",
        "HTML": "https://arxiv.org/html/2507.02271v1",
        "PDF": "https://arxiv.org/pdf/2507.02271"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on video-to-audio generation and self-distillation methods for enhancing cinematic language scenarios. It does not involve LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02273",
      "abstract": "General-purpose audio representations have proven effective across diverse music information retrieval applications, yet their utility in intelligent music production remains limited by insufficient understanding of audio effects (Fx). Although previous approaches have emphasized audio effects analysis at the mixture level, this focus falls short for tasks demanding instrument-wise audio effects understanding, such as automatic mixing. In this work, we present Fx-Encoder++, a novel model designed to extract instrument-wise audio effects representations from music mixtures. Our approach leverages a contrastive learning framework and introduces an \"extractor\" mechanism that, when provided with instrument queries (audio or text), transforms mixture-level audio effects embeddings into instrument-wise audio effects embeddings. We evaluated our model across retrieval and audio effects parameter matching tasks, testing its performance across a diverse range of instruments. The results demonstrate that Fx-Encoder++ outperforms previous approaches at mixture level and show a novel ability to extract effects representation instrument-wise, addressing a critical capability gap in intelligent music production systems.",
      "authors": [
        "Yen-Tung Yeh",
        "Junghyun Koo",
        "Marco A. Mart\\'inez-Ram\\'irez",
        "Wei-Hsiang Liao",
        "Yi-Hsuan Yang",
        "and Yuki Mitsufuji"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T03:27:11+00:00",
          "link": "https://arxiv.org/abs/2507.02273v1",
          "size": "2584kb",
          "version": "v1"
        }
      ],
      "title": "Fx-Encoder++: Extracting Instrument-Wise Audio Effects Representations from Mixtures",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02273",
        "HTML": "https://arxiv.org/html/2507.02273v1",
        "PDF": "https://arxiv.org/pdf/2507.02273"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses audio effects representation extraction in music mixtures and does not address LLM training data or data processing stages relevant to language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02274",
      "abstract": "Motivated by the practical application of beam tracking of multiple devices in Multiple Input Multiple Output (MIMO) communication, we study the problem of non-adaptive twenty questions estimation for locating and tracking multiple moving targets under a query-dependent noisy channel. Specifically, we derive a non-asymptotic bound and a second-order asymptotic bound on resolution for optimal query procedures and provide numerical examples to illustrate our results. In particular, we demonstrate that the bound is achieved by a state estimator that thresholds the mutual information density over possible target locations. This single threshold decoding rule has reduced the computational complexity compared to the multiple threshold scheme proposed for locating multiple stationary targets (Zhou, Bai and Hero, TIT 2022). We discuss two special cases of our setting: the case with unknown initial location and known velocity, and the case with known initial location and unknown velocity. Both cases share the same theoretical benchmark {that applies to} stationary multiple target search in Zhou, Bai and Hero (TIT 2022) while the known initial location case is close to the theoretical benchmark for stationary target search when the maximal speed is inversely proportional to the number of queries. We also generalize our results to account for a piecewise constant velocity model introduced in Zhou and Hero (TIT 2023), where targets change velocity periodically. Finally, we illustrate our proposed algorithm for the application of beam tracking of multiple mobile transmitters in a 5G wireless network.",
      "authors": [
        "Chunsong Sun",
        "Lin Zhou",
        "Jingjing Wang",
        "Weijie Yuan",
        "Chunxiao Jiang and Alfred Hero"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T03:30:41+00:00",
          "link": "https://arxiv.org/abs/2507.02274v1",
          "size": "710kb",
          "version": "v1"
        }
      ],
      "title": "Resolution Limits of Non-Adaptive 20 Questions Estimation for Tracking Multiple Moving Targets",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02274",
        "HTML": "https://arxiv.org/html/2507.02274v1",
        "PDF": "https://arxiv.org/pdf/2507.02274"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses non-adaptive 20 questions estimation for tracking moving targets in MIMO communication, which is unrelated to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02279",
      "abstract": "Existing visual token compression methods for Multimodal Large Language Models (MLLMs) predominantly operate as post-encoder modules, limiting their potential for efficiency gains. To address this limitation, we propose LaCo (Layer-wise Visual Token Compression), a novel framework that enables effective token compression within the intermediate layers of the vision encoder. LaCo introduces two core components: 1) a layer-wise pixel-shuffle mechanism that systematically merges adjacent tokens through space-to-channel transformations, and 2) a residual learning architecture with non-parametric shortcuts that preserves critical visual information during compression. Extensive experiments indicate that our LaCo outperforms all existing methods when compressing tokens in the intermediate layers of the vision encoder, demonstrating superior effectiveness. In addition, compared to external compression, our method improves training efficiency beyond 20% and inference throughput over 15% while maintaining strong performance.",
      "authors": [
        "Juntao Liu",
        "Liqiang Niu",
        "Wenchao Chen",
        "Jie Zhou",
        "Fandong Meng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T03:42:54+00:00",
          "link": "https://arxiv.org/abs/2507.02279v1",
          "size": "2500kb",
          "version": "v1"
        }
      ],
      "title": "LaCo: Efficient Layer-wise Compression of Visual Tokens for Multimodal Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02279",
        "HTML": "https://arxiv.org/html/2507.02279v1",
        "PDF": "https://arxiv.org/pdf/2507.02279"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While this paper pertains to token compression methods within multimodal large language models, it focuses on visual tokens, not directly on the processing of traditional LLM training language data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02281",
      "abstract": "Homomorphic ring signature schemes combine the strong anonymity of ring signatures with the computability of homomorphic signatures, demonstrating significant potential in scenarios requiring both anonymous data provenance and verifiable homomorphic computation (e.g., confidential blockchain transactions and secure multi-party computation). However, no feasible homomorphic ring signature scheme currently exists.\n  In this work, we propose the first lattice-based linearly homomorphic ring signature scheme. Proven secure in the standard model under the small integer solution (SIS) assumption, our scheme achieves strong anonymity under full key exposure and unforgeability against insider corruption attacks. As the first unified framework for ring signatures and linear homomorphic signatures, this construction provides a post-quantum-secure solution for the aforementioned applications, advancing the development of privacy-enhanced homomorphic computation.",
      "authors": [
        "Heng Guo",
        "Kun Tian",
        "Fengxia Liu",
        "Zhiyong Zheng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T03:43:40+00:00",
          "link": "https://arxiv.org/abs/2507.02281v1",
          "size": "34kb",
          "version": "v1"
        }
      ],
      "title": "Linearly Homomorphic Ring Signature Scheme over Lattices",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02281",
        "HTML": "https://arxiv.org/html/2507.02281v1",
        "PDF": "https://arxiv.org/pdf/2507.02281"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper's focus is on developing a homomorphic ring signature scheme over lattices, which pertains to cryptographic techniques and security, and does not relate to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02282",
      "abstract": "Recommendation systems have become essential in modern music streaming platforms, shaping how users discover and engage with songs. One common approach in recommendation systems is collaborative filtering, which suggests content based on the preferences of users with similar listening patterns to the target user. However, this method is less effective on media where interactions are sparse. Music is one such medium, since the average user of a music streaming service will never listen to the vast majority of tracks. Due to this sparsity, there are several challenges that have to be addressed with other methods. This review examines the current state of research in addressing these challenges, with an emphasis on the role of content filtering in mitigating biases inherent in collaborative filtering approaches. We explore various methods of song classification for content filtering, including lyrical analysis using Large Language Models (LLMs) and audio signal processing techniques. Additionally, we discuss the potential conflicts between these different analysis methods and propose avenues for resolving such discrepancies.",
      "authors": [
        "Terence Zeng and Abhishek K. Umrawal"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T03:44:20+00:00",
          "link": "https://arxiv.org/abs/2507.02282v1",
          "size": "196kb",
          "version": "v1"
        }
      ],
      "title": "Content filtering methods for music recommendation: A review",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02282",
        "HTML": "https://arxiv.org/html/2507.02282v1",
        "PDF": "https://arxiv.org/pdf/2507.02282"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper reviews content filtering methods in music recommendation, mentioning the use of LLMs for lyrical analysis in the context of song classification. However, it does not primarily focus on novel LLM training data processing methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02283",
      "abstract": "This paper examines a critical yet unexplored dimension of the AI alignment problem: the potential for Large Language Models (LLMs) to inherit and amplify existing misalignments between human espoused theories and theories-in-use. Drawing on action science research, we argue that LLMs trained on human-generated text likely absorb and reproduce Model 1 theories-in-use - a defensive reasoning pattern that both inhibits learning and creates ongoing anti-learning dynamics at the dyad, group, and organisational levels. Through a detailed case study of an LLM acting as an HR consultant, we show how its advice, while superficially professional, systematically reinforces unproductive problem-solving approaches and blocks pathways to deeper organisational learning. This represents a specific instance of the alignment problem where the AI system successfully mirrors human behaviour but inherits our cognitive blind spots. This poses particular risks if LLMs are integrated into organisational decision-making processes, potentially entrenching anti-learning practices while lending authority to them. The paper concludes by exploring the possibility of developing LLMs capable of facilitating Model 2 learning - a more productive theory-in-use - and suggests this effort could advance both AI alignment research and action science practice. This analysis reveals an unexpected symmetry in the alignment challenge: the process of developing AI systems properly aligned with human values could yield tools that help humans themselves better embody those same values.",
      "authors": [
        "Tim Rogers",
        "Ben Teehankee"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T03:44:45+00:00",
          "link": "https://arxiv.org/abs/2507.02283v1",
          "size": "325kb",
          "version": "v1"
        }
      ],
      "title": "Misaligned from Within: Large Language Models Reproduce Our Double-Loop Learning Blindness",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02283",
        "PDF": "https://arxiv.org/pdf/2507.02283"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates potential biases in LLM outputs related to alignment, focusing on organizational learning rather than LLM training data processing or data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02288",
      "abstract": "Domain Generalization (DG) seeks to develop a versatile model capable of performing effectively on unseen target domains. Notably, recent advances in pre-trained Visual Foundation Models (VFMs), such as CLIP, have demonstrated considerable potential in enhancing the generalization capabilities of deep learning models. Despite the increasing attention toward VFM-based domain prompt tuning within DG, the effective design of prompts capable of disentangling invariant features across diverse domains remains a critical challenge. In this paper, we propose addressing this challenge by leveraging the controllable and flexible language prompt of the VFM. Noting that the text modality of VFMs is naturally easier to disentangle, we introduce a novel framework for text feature-guided visual prompt tuning. This framework first automatically disentangles the text prompt using a large language model (LLM) and then learns domain-invariant visual representation guided by the disentangled text feature. However, relying solely on language to guide visual feature disentanglement has limitations, as visual features can sometimes be too complex or nuanced to be fully captured by descriptive text. To address this, we introduce Worst Explicit Representation Alignment (WERA), which extends text-guided visual prompts by incorporating an additional set of abstract prompts. These prompts enhance source domain diversity through stylized image augmentations, while alignment constraints ensure that visual representations remain consistent across both the original and augmented distributions. Experiments conducted on major DG datasets, including PACS, VLCS, OfficeHome, DomainNet, and TerraInc, demonstrate that our proposed method outperforms state-of-the-art DG methods.",
      "authors": [
        "De Cheng",
        "Zhipeng Xu",
        "Xinyang Jiang",
        "Dongsheng Li",
        "Nannan Wang",
        "Xinbo Gao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T03:52:37+00:00",
          "link": "https://arxiv.org/abs/2507.02288v1",
          "size": "1307kb",
          "version": "v1"
        }
      ],
      "title": "Prompt Disentanglement via Language Guidance and Representation Alignment for Domain Generalization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02288",
        "HTML": "https://arxiv.org/html/2507.02288v1",
        "PDF": "https://arxiv.org/pdf/2507.02288"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes a framework using LLMs for feature disentanglement in domain generalization settings, involving LLMs in part of the method but not focusing on LLM training data processes directly."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02291",
      "abstract": "Data-driven semantic communication is based on superficial statistical patterns, thereby lacking interpretability and generalization, especially for applications with the presence of unseen data. To address these challenges, we propose a novel knowledge graph-enhanced zero-shot semantic communication (KGZS-SC) network. Guided by the structured semantic information from a knowledge graph-based semantic knowledge base (KG-SKB), our scheme provides generalized semantic representations and enables reasoning for unseen cases. Specifically, the KG-SKB aligns the semantic features in a shared category semantics embedding space and enhances the generalization ability of the transmitter through aligned semantic features, thus reducing communication overhead by selectively transmitting compact visual semantics. At the receiver, zero-shot learning (ZSL) is leveraged to enable direct classification for unseen cases without the demand for retraining or additional computational overhead, thereby enhancing the adaptability and efficiency of the classification process in dynamic or resource-constrained environments. The simulation results conducted on the APY datasets show that the proposed KGZS-SC network exhibits robust generalization and significantly outperforms existing SC frameworks in classifying unseen categories across a range of SNR levels.",
      "authors": [
        "Zhaoyu Zhang",
        "Lingyi Wang",
        "Wei Wu",
        "Fuhui Zhou",
        "Qihui Wu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T03:57:26+00:00",
          "link": "https://arxiv.org/abs/2507.02291v1",
          "size": "4414kb",
          "version": "v1"
        }
      ],
      "title": "Knowledge Graph-Based Explainable and Generalized Zero-Shot Semantic Communications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02291",
        "HTML": "https://arxiv.org/html/2507.02291v1",
        "PDF": "https://arxiv.org/pdf/2507.02291"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a knowledge graph-based semantic communication framework, focused on communication efficiency and generalization in unseen scenarios. It does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02294",
      "abstract": "The Segment Anything Model (SAM), with its prompt-driven paradigm, exhibits strong generalization in generic segmentation tasks. However, applying SAM to remote sensing (RS) images still faces two major challenges. First, manually constructing precise prompts for each image (e.g., points or boxes) is labor-intensive and inefficient, especially in RS scenarios with dense small objects or spatially fragmented distributions. Second, SAM lacks domain adaptability, as it is pre-trained primarily on natural images and struggles to capture RS-specific semantics and spatial characteristics, especially when segmenting novel or unseen classes. To address these issues, inspired by few-shot learning, we propose ViRefSAM, a novel framework that guides SAM utilizing only a few annotated reference images that contain class-specific objects. Without requiring manual prompts, ViRefSAM enables automatic segmentation of class-consistent objects across RS images. Specifically, ViRefSAM introduces two key components while keeping SAM's original architecture intact: (1) a Visual Contextual Prompt Encoder that extracts class-specific semantic clues from reference images and generates object-aware prompts via contextual interaction with target images; and (2) a Dynamic Target Alignment Adapter, integrated into SAM's image encoder, which mitigates the domain gap by injecting class-specific semantics into target image features, enabling SAM to dynamically focus on task-relevant regions. Extensive experiments on three few-shot segmentation benchmarks, including iSAID-5$^i$, LoveDA-2$^i$, and COCO-20$^i$, demonstrate that ViRefSAM enables accurate and automatic segmentation of unseen classes by leveraging only a few reference images and consistently outperforms existing few-shot segmentation methods across diverse datasets.",
      "authors": [
        "Hanbo Bi",
        "Yulong Xu",
        "Ya Li",
        "Yongqiang Mao",
        "Boyuan Tong",
        "Chongyang Li",
        "Chunbo Lang",
        "Wenhui Diao",
        "Hongqi Wang",
        "Yingchao Feng",
        "Xian Sun"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T04:06:04+00:00",
          "link": "https://arxiv.org/abs/2507.02294v1",
          "size": "16046kb",
          "version": "v1"
        }
      ],
      "title": "ViRefSAM: Visual Reference-Guided Segment Anything Model for Remote Sensing Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02294",
        "HTML": "https://arxiv.org/html/2507.02294v1",
        "PDF": "https://arxiv.org/pdf/2507.02294"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a method for remote sensing image segmentation using a modified Segment Anything Model (SAM). It does not involve any aspects of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02295",
      "abstract": "With the recent improvements in mobile and edge computing and rising concerns of data privacy, Federated Learning(FL) has rapidly gained popularity as a privacy-preserving, distributed machine learning methodology. Several FL frameworks have been built for testing novel FL strategies. However, most focus on validating the learning aspects of FL through pseudo-distributed simulation but not for deploying on real edge hardware in a distributed manner to meaningfully evaluate the federated aspects from a systems perspective. Current frameworks are also inherently not designed to support asynchronous aggregation, which is gaining popularity, and have limited resilience to client and server failures. We introduce Flotilla, a scalable and lightweight FL framework. It adopts a ``user-first'' modular design to help rapidly compose various synchronous and asynchronous FL strategies while being agnostic to the DNN architecture. It uses stateless clients and a server design that separates out the session state, which are periodically or incrementally checkpointed. We demonstrate the modularity of Flotilla by evaluating five different FL strategies for training five DNN models. We also evaluate the client and server-side fault tolerance on 200+ clients, and showcase its ability to rapidly failover within seconds. Finally, we show that Flotilla's resource usage on Raspberry Pis and Nvidia Jetson edge accelerators are comparable to or better than three state-of-the-art FL frameworks, Flower, OpenFL and FedML. It also scales significantly better compared to Flower for 1000+ clients. This positions Flotilla as a competitive candidate to build novel FL strategies on, compare them uniformly, rapidly deploy them, and perform systems research and optimizations.",
      "authors": [
        "Roopkatha Banerjee",
        "Prince Modi",
        "Jinal Vyas",
        "Chunduru Sri Abhijit",
        "Tejus Chandrashekar",
        "Harsha Varun Marisetty",
        "Manik Gupta",
        "Yogesh Simmhan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T04:07:40+00:00",
          "link": "https://arxiv.org/abs/2507.02295v1",
          "size": "1412kb",
          "version": "v1"
        }
      ],
      "title": "Flotilla: A scalable, modular and resilient federated learning framework for heterogeneous resources",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02295",
        "HTML": "https://arxiv.org/html/2507.02295v1",
        "PDF": "https://arxiv.org/pdf/2507.02295"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a federated learning framework for deploying machine learning models, focusing on system-level aspects such as scalability and fault tolerance. It does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02299",
      "abstract": "Recent advancements in leveraging pre-trained 2D diffusion models achieve the generation of high-quality novel views from a single in-the-wild image. However, existing works face challenges in producing controllable novel views due to the lack of information from multiple views. In this paper, we present DreamComposer++, a flexible and scalable framework designed to improve current view-aware diffusion models by incorporating multi-view conditions. Specifically, DreamComposer++ utilizes a view-aware 3D lifting module to extract 3D representations of an object from various views. These representations are then aggregated and rendered into the latent features of target view through the multi-view feature fusion module. Finally, the obtained features of target view are integrated into pre-trained image or video diffusion models for novel view synthesis. Experimental results demonstrate that DreamComposer++ seamlessly integrates with cutting-edge view-aware diffusion models and enhances their abilities to generate controllable novel views from multi-view conditions. This advancement facilitates controllable 3D object reconstruction and enables a wide range of applications.",
      "authors": [
        "Yunhan Yang",
        "Shuo Chen",
        "Yukun Huang",
        "Xiaoyang Wu",
        "Yuan-Chen Guo",
        "Edmund Y. Lam",
        "Hengshuang Zhao",
        "Tong He",
        "Xihui Liu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T04:12:11+00:00",
          "link": "https://arxiv.org/abs/2507.02299v1",
          "size": "5912kb",
          "version": "v1"
        }
      ],
      "title": "DreamComposer++: Empowering Diffusion Models with Multi-View Conditions for 3D Content Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02299",
        "HTML": "https://arxiv.org/html/2507.02299v1",
        "PDF": "https://arxiv.org/pdf/2507.02299"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces an improved framework for 3D content generation using multi-view conditions and diffusion models, with no focus on LLM training data or its processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02300",
      "abstract": "Human-centered explainability has become a critical foundation for the responsible development of interactive information systems, where users must be able to understand, interpret, and scrutinize AI-driven outputs to make informed decisions. This systematic survey of literature aims to characterize recent progress in user studies on explainability in interactive information systems by reviewing how explainability has been conceptualized, designed, and evaluated in practice. Following PRISMA guidelines, eight academic databases were searched, and 100 relevant articles were identified. A structural encoding approach was then utilized to extract and synthesize insights from these articles. The main contributions include 1) five dimensions that researchers have used to conceptualize explainability; 2) a classification scheme of explanation designs; 3) a categorization of explainability measurements into six user-centered dimensions. The review concludes by reflecting on ongoing challenges and providing recommendations for future exploration of related issues. The findings shed light on the theoretical foundations of human-centered explainability, informing the design of interactive information systems that better align with diverse user needs and promoting the development of systems that are transparent, trustworthy, and accountable.",
      "authors": [
        "Yuhao Zhang",
        "Jiaxin An",
        "Ben Wang",
        "Yan Zhang",
        "Jiqun Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T04:12:45+00:00",
          "link": "https://arxiv.org/abs/2507.02300v1",
          "size": "1973kb",
          "version": "v1"
        }
      ],
      "title": "Human-Centered Explainability in Interactive Information Systems: A Survey",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02300",
        "HTML": "https://arxiv.org/html/2507.02300v1",
        "PDF": "https://arxiv.org/pdf/2507.02300"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on human-centered explainability in interactive information systems, reviewing literature on explainability methods and structures rather than the processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02302",
      "abstract": "Domain-Adaptive Pre-training (DAP) has recently gained attention for its effectiveness in fine-tuning pre-trained models. Building on this, continual DAP has been explored to develop pre-trained models capable of incrementally incorporating different domain datasets. However, existing continual DAP methods face several limitations: (1) high computational cost and GPU memory usage during training; (2) sensitivity to incremental data order; and (3) providing a single, generalized model for all end tasks, which contradicts the essence of DAP. In this paper, we propose DoMIX, a novel approach that addresses these challenges by leveraging LoRA modules, a representative parameter-efficient fine-tuning (PEFT) method. Our approach enables efficient and parallel domain-adaptive pre-training that is robust to domain order and effectively utilizes accumulated knowledge to provide tailored pre-trained models for specific tasks. We also demonstrate that our method can be extended beyond the DAP setting to standard LLM fine-tuning scenarios. Code is available at https://github.com/dohoonkim-ai/DoMIX.",
      "authors": [
        "Dohoon Kim",
        "Donghun Kang",
        "Taesup Moon"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T04:13:01+00:00",
          "link": "https://arxiv.org/abs/2507.02302v1",
          "size": "971kb",
          "version": "v1"
        }
      ],
      "title": "DoMIX: An Efficient Framework for Exploiting Domain Knowledge in Fine-Tuning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02302",
        "HTML": "https://arxiv.org/html/2507.02302v1",
        "PDF": "https://arxiv.org/pdf/2507.02302"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes an efficient framework for fine-tuning pre-trained models using domain knowledge but doesn\u2019t primarily focus on the processing or engineering of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02303",
      "abstract": "Forests are frequently impacted by climate conditions, vegetation density, and intricate terrain and geology, which contribute to natural disasters. Personnel engaged in or supporting rescue operations in such environments rely on robust communication systems to ensure their safety, highlighting the criticality of channel measurements in forest environments. However, according to current research, there is limited research on channel detection and modeling in forest areas in the existing literature. This paper describes the channel measurements campaign of air and ground in the Arxan National Forest Park of Inner Mongolia. It presents measurement results and propagation models for ground-to-ground (G2G) and air-to-ground (A2G) scenarios. The measurement campaign uses orthogonal frequency division multiplexing signals centered at 1.4 GHz for channel sounding. In the G2G measurement, in addition to using omnidirectional antennas to record data, we also use directional antennas to record the arrival angle information of the signal at the receiver. In the A2G measurement, we pre-plan the flight trajectory of the unmanned aerial vehicle so that it can fly at a fixed angle relative to the ground. We present path loss models suitable for G2G and A2G in forest environments based on the analysis of measurement results. The results indicate that the proposed model reduces error margins compared with other path loss models. Furthermore, we derive the multipath model expression specific to forest environments and conduct statistical analysis on key channel parameters e.g., shadow fading factor, root mean square delay spread, and Rician K factor. Our findings reveal that signal propagation obstruction due to tree crowns in A2G communication is more pronounced than tree trunk obstructions in G2G communication. Adjusting the elevation angle between air and ground can enhance communication quality.",
      "authors": [
        "Zhe Xiao",
        "Shu Sun",
        "Na Liu",
        "Lianming Xu",
        "Li Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T04:15:13+00:00",
          "link": "https://arxiv.org/abs/2507.02303v1",
          "size": "8173kb",
          "version": "v1"
        }
      ],
      "title": "Measurements and Modeling of Air-Ground Integrated Channel in Forest Environment Based on OFDM Signals",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02303",
        "HTML": "https://arxiv.org/html/2507.02303v1",
        "PDF": "https://arxiv.org/pdf/2507.02303"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses channel measurements and communication models in forest environments and does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02305",
      "abstract": "The emerging Web3 has great potential to provide worldwide decentralized services powered by global-range data-driven networks in the future. To ensure the security of Web3 services among diverse user entities, a decentralized identity (DID) system is essential. Especially, a user's access request to Web3 services can be treated as a DID transaction within the blockchain, executed through a consensus mechanism. However, a critical implementation issue arises in the current Web3, i.e., how to deploy network nodes to serve users on a global scale. To address this issue, emerging Low Earth Orbit (LEO) satellite communication systems, such as Starlink, offer a promising solution. With their global coverage and high reliability, these communication satellites can complement terrestrial networks as Web3 deployment infrastructures. In this case, this paper develops three hybrid satellite-ground modes to deploy the blockchain-enabled DID system for Web3 users. Three modes integrate ground nodes and satellites to provide flexible and continuous DID services for worldwide users. Meanwhile, to evaluate the effectiveness of the present hybrid deployment modes, we analyze the complete DID consensus performance of blockchain on three hybrid satellite-ground modes. Moreover, we conduct numerical and simulation experiments to verify the effectiveness of three hybrid satellite-ground modes. The impacts of various system parameters are thoroughly analyzed, providing valuable insights for implementing the worldwide Web3 DID system in real-world network environments.",
      "authors": [
        "Yalin Liu",
        "Zhigang Yan",
        "Bingyuan Luo",
        "Xiaochi Xu",
        "Hong-Ning Dai",
        "Yaru Fu",
        "Bishenghui Tao and Siu-Kei Au Yeung"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T04:22:03+00:00",
          "link": "https://arxiv.org/abs/2507.02305v1",
          "size": "3748kb",
          "version": "v1"
        }
      ],
      "title": "Hybrid Satellite-Ground Deployments for Web3 DID: System Design and Performance Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02305",
        "HTML": "https://arxiv.org/html/2507.02305v1",
        "PDF": "https://arxiv.org/pdf/2507.02305"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses hybrid satellite-ground deployments for Web3 DID systems and does not pertain to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02306",
      "abstract": "Usability evaluation is crucial in human-centered design but can be costly, requiring expert time and user compensation. In this work, we developed a method for synthetic heuristic evaluation using multimodal LLMs' ability to analyze images and provide design feedback. Comparing our synthetic evaluations to those by experienced UX practitioners across two apps, we found our evaluation identified 73% and 77% of usability issues, which exceeded the performance of 5 experienced human evaluators (57% and 63%). Compared to human evaluators, the synthetic evaluation's performance maintained consistent performance across tasks and excelled in detecting layout issues, highlighting potential attentional and perceptual strengths of synthetic evaluation. However, synthetic evaluation struggled with recognizing some UI components and design conventions, as well as identifying across screen violations. Additionally, testing synthetic evaluations over time and accounts revealed stable performance. Overall, our work highlights the performance differences between human and LLM-driven evaluations, informing the design of synthetic heuristic evaluations.",
      "authors": [
        "Ruican Zhong",
        "David W. McDonald",
        "Gary Hsieh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T04:27:16+00:00",
          "link": "https://arxiv.org/abs/2507.02306v1",
          "size": "3048kb",
          "version": "v1"
        }
      ],
      "title": "Synthetic Heuristic Evaluation: A Comparison between AI- and Human-Powered Usability Evaluation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02306",
        "HTML": "https://arxiv.org/html/2507.02306v1",
        "PDF": "https://arxiv.org/pdf/2507.02306"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The work compares AI- and human-powered usability evaluations using multimodal LLMs, focusing on usability rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02307",
      "abstract": "Change detection typically involves identifying regions with changes between bitemporal images taken at the same location. Besides significant changes, slow changes in bitemporal images are also important in real-life scenarios. For instance, weak changes often serve as precursors to major hazards in scenarios like slopes, dams, and tailings ponds. Therefore, designing a change detection network that simultaneously detects slow and fast changes presents a novel challenge. In this paper, to address this challenge, we propose a change detection network named Flow-CDNet, consisting of two branches: optical flow branch and binary change detection branch. The first branch utilizes a pyramid structure to extract displacement changes at multiple scales. The second one combines a ResNet-based network with the optical flow branch's output to generate fast change outputs. Subsequently, to supervise and evaluate this new change detection framework, a self-built change detection dataset Flow-Change, a loss function combining binary tversky loss and L2 norm loss, along with a new evaluation metric called FEPE are designed. Quantitative experiments conducted on Flow-Change dataset demonstrated that our approach outperforms the existing methods. Furthermore, ablation experiments verified that the two branches can promote each other to enhance the detection performance.",
      "authors": [
        "Haoxuan Li",
        "Chenxu Wei",
        "Haodong Wang",
        "Xiaomeng Hu",
        "Boyuan An",
        "Lingyan Ran",
        "Baosen Zhang",
        "Jin Jin",
        "Omirzhan Taukebayev",
        "Amirkhan Temirbayev",
        "Junrui Liu",
        "and Xiuwei Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T04:27:49+00:00",
          "link": "https://arxiv.org/abs/2507.02307v1",
          "size": "2103kb",
          "version": "v1"
        }
      ],
      "title": "Flow-CDNet: A Novel Network for Detecting Both Slow and Fast Changes in Bitemporal Images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02307",
        "HTML": "https://arxiv.org/html/2507.02307v1",
        "PDF": "https://arxiv.org/pdf/2507.02307"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on change detection in bitemporal images using a novel network, Flow-CDNet. It does not address LLM training data processing, but rather image processing techniques for detecting changes."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02308",
      "abstract": "In this work, we explore the task of semantic object keypoint discovery weakly-supervised by only category labels. This is achieved by transforming discriminatively-trained intermediate layer filters into keypoint detectors. We begin by identifying three preferred characteristics of keypoint detectors: (i) spatially sparse activations, (ii) consistency and (iii) diversity. Instead of relying on hand-crafted loss terms, a novel computationally-efficient leaky max pooling (LMP) layer is proposed to explicitly encourage final conv-layer filters to learn \"non-repeatable local patterns\" that are well aligned with object keypoints. Informed by visualizations, a simple yet effective selection strategy is proposed to ensure consistent filter activations and attention mask-out is then applied to force the network to distribute its attention to the whole object instead of just the most discriminative region. For the final keypoint prediction, a learnable clustering layer is proposed to group keypoint proposals into keypoint predictions. The final model, named LMPNet, is highly interpretable in that it directly manipulates network filters to detect predefined concepts. Our experiments show that LMPNet can (i) automatically discover semantic keypoints that are robust to object pose and (ii) achieves strong prediction accuracy comparable to a supervised pose estimation model.",
      "authors": [
        "Pei Guo",
        "Ryan Farrell"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T04:36:03+00:00",
          "link": "https://arxiv.org/abs/2507.02308v1",
          "size": "14302kb",
          "version": "v1"
        }
      ],
      "title": "LMPNet for Weakly-supervised Keypoint Discovery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02308",
        "HTML": "https://arxiv.org/html/2507.02308v1",
        "PDF": "https://arxiv.org/pdf/2507.02308"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research aims at keypoint discovery in images through progressively trained networks, without discussion of LLM training data processing. The focus is on computer vision tasks rather than language data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02309",
      "abstract": "RESTful APIs facilitate data exchange between applications, but they also expose sensitive resources to potential exploitation. Broken Object Level Authorization (BOLA) is the top vulnerability in the OWASP API Security Top 10, exemplifies a critical access control flaw where attackers manipulate API parameters to gain unauthorized access. To address this, we propose BOLAZ, a defense framework grounded in zero trust principles. BOLAZ analyzes the data flow of resource IDs, pinpointing BOLA attack injection points and determining the associated authorization intervals to prevent horizontal privilege escalation. Our approach leverages static taint tracking to categorize APIs into producers and consumers based on how they handle resource IDs. By mapping the propagation paths of resource IDs, BOLAZ captures the context in which these IDs are produced and consumed, allowing for precise identification of authorization boundaries. Unlike defense methods based on common authorization models, BOLAZ is the first authorization-guided method that adapts defense rules based on the system's best-practice authorization logic. We validate BOLAZ through empirical research on 10 GitHub projects. The results demonstrate BOLAZ's effectiveness in defending against vulnerabilities collected from CVE and discovering 35 new BOLA vulnerabilities in the wild, demonstrating its practicality in real-world deployments.",
      "authors": [
        "Anbin Wu (1)",
        "Zhiyong Feng (1)",
        "Ruitao Feng (2) ((1) The College of Intelligence and Computing",
        "Tianjin University",
        "(2) The Southern Cross University)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T04:40:14+00:00",
          "link": "https://arxiv.org/abs/2507.02309v1",
          "size": "1746kb",
          "version": "v1"
        }
      ],
      "title": "Rethinking Broken Object Level Authorization Attacks Under Zero Trust Principle",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02309",
        "HTML": "https://arxiv.org/html/2507.02309v1",
        "PDF": "https://arxiv.org/pdf/2507.02309"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses RESTful API security issues and proposes a framework for identifying authorization vulnerabilities. It does not relate to processing data for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02310",
      "abstract": "Traditional continual learning methods prioritize knowledge retention and focus primarily on mitigating catastrophic forgetting, implicitly assuming that the data distribution of previously learned tasks remains static. This overlooks the dynamic nature of real-world data streams, where concept drift permanently alters previously seen data and demands both stability and rapid adaptation.\n  We introduce a holistic framework for continual learning under concept drift that simulates realistic scenarios by evolving task distributions. As a baseline, we consider Full Relearning (FR), in which the model is retrained from scratch on newly labeled samples from the drifted distribution. While effective, this approach incurs substantial annotation and computational overhead. To address these limitations, we propose Adaptive Memory Realignment (AMR), a lightweight alternative that equips rehearsal-based learners with a drift-aware adaptation mechanism. AMR selectively removes outdated samples of drifted classes from the replay buffer and repopulates it with a small number of up-to-date instances, effectively realigning memory with the new distribution. This targeted resampling matches the performance of FR while reducing the need for labeled data and computation by orders of magnitude.\n  To enable reproducible evaluation, we introduce four concept-drift variants of standard vision benchmarks: Fashion-MNIST-CD, CIFAR10-CD, CIFAR100-CD, and Tiny-ImageNet-CD, where previously seen classes reappear with shifted representations. Comprehensive experiments on these datasets using several rehearsal-based baselines show that AMR consistently counters concept drift, maintaining high accuracy with minimal overhead. These results position AMR as a scalable solution that reconciles stability and plasticity in non-stationary continual learning environments.",
      "authors": [
        "Alif Ashrafee",
        "Jedrzej Kozal",
        "Michal Wozniak",
        "Bartosz Krawczyk"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T04:41:20+00:00",
          "link": "https://arxiv.org/abs/2507.02310v1",
          "size": "3127kb",
          "version": "v1"
        }
      ],
      "title": "Holistic Continual Learning under Concept Drift with Adaptive Memory Realignment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02310",
        "HTML": "https://arxiv.org/html/2507.02310v1",
        "PDF": "https://arxiv.org/pdf/2507.02310"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study explores continual learning under concept drift for vision datasets, without discussing any aspect of language data processing relevant to LLM training stages."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02311",
      "abstract": "Recent advances in brain-vision decoding have driven significant progress, reconstructing with high fidelity perceived visual stimuli from neural activity, e.g., functional magnetic resonance imaging (fMRI), in the human visual cortex. Most existing methods decode the brain signal using a two-level strategy, i.e., pixel-level and semantic-level. However, these methods rely heavily on low-level pixel alignment yet lack sufficient and fine-grained semantic alignment, resulting in obvious reconstruction distortions of multiple semantic objects. To better understand the brain's visual perception patterns and how current decoding models process semantic objects, we have developed an experimental framework that uses fMRI representations as intervention conditions. By injecting these representations into multi-scale image features via cross-attention, we compare both downstream performance and intermediate feature changes on object detection and instance segmentation tasks with and without fMRI information. Our results demonstrate that incorporating fMRI signals enhances the accuracy of downstream detection and segmentation, confirming that fMRI contains rich multi-object semantic cues and coarse spatial localization information-elements that current models have yet to fully exploit or integrate.",
      "authors": [
        "Le Xu and Qi Zhang and Qixian Zhang and Hongyun Zhang and Duoqian Miao and Cairong Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T04:46:48+00:00",
          "link": "https://arxiv.org/abs/2507.02311v1",
          "size": "1619kb",
          "version": "v1"
        }
      ],
      "title": "Perception Activator: An intuitive and portable framework for brain cognitive exploration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02311",
        "HTML": "https://arxiv.org/html/2507.02311v1",
        "PDF": "https://arxiv.org/pdf/2507.02311"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The exploration is about brain-vision decoding and uses fMRI data for object detection and segmentation tasks. There is no connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02313",
      "abstract": "Simulators are useful tools for testing automated driving controllers. Vehicle-in-the-loop (ViL) tests and digital twins (DTs) are widely used simulation technologies to facilitate the smooth deployment of controllers to physical vehicles. However, conventional ViL tests rely on full-size vehicles, requiring large space and high expenses. Also, physical-model-based DT suffers from the reality gap caused by modeling imprecision. This paper develops a comprehensive and practical simulator for testing automated driving controllers enhanced by scaled physical cars and AI-powered DT models. The scaled cars allow for saving space and expenses of simulation tests. The AI-powered DT models ensure superior simulation fidelity. Moreover, the simulator integrates well with off-the-shelf software and control algorithms, making it easy to extend. We use a filtered control benchmark with formal safety guarantees to showcase the capability of the simulator in validating automated driving controllers. Experimental studies are performed to showcase the efficacy of the simulator, implying its great potential in validating control solutions for autonomous vehicles and intelligent traffic.",
      "authors": [
        "Zengjie Zhang",
        "Giannis Badakis",
        "Michalis Galanis",
        "Adem Bavar\\c{s}i",
        "Edwin van Hassel",
        "Mohsen Alirezaei",
        "Sofie Haesaert"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T04:52:18+00:00",
          "link": "https://arxiv.org/abs/2507.02313v1",
          "size": "18701kb",
          "version": "v1"
        }
      ],
      "title": "A Vehicle-in-the-Loop Simulator with AI-Powered Digital Twins for Testing Automated Driving Controllers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02313",
        "HTML": "https://arxiv.org/html/2507.02313v1",
        "PDF": "https://arxiv.org/pdf/2507.02313"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on simulators for testing automated driving controllers and does not address any form of data processing related to LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02314",
      "abstract": "Few-shot anomaly generation is emerging as a practical solution for augmenting the scarce anomaly data in industrial quality control settings. An ideal generator would meet three demands at once, namely (i) keep the normal background intact, (ii) inpaint anomalous regions to tightly overlap with the corresponding anomaly masks, and (iii) generate anomalous regions in a semantically valid location, while still producing realistic, diverse appearances from only a handful of real examples. Existing diffusion-based methods usually satisfy at most two of these requirements: global anomaly generators corrupt the background, whereas mask-guided ones often falter when the mask is imprecise or misplaced. We propose MAGIC--Mask-guided inpainting with multi-level perturbations and Context-aware alignment--to resolve all three issues. At its core, MAGIC fine-tunes a Stable Diffusion inpainting backbone that preserves normal regions and ensures strict adherence of the synthesized anomaly to the supplied mask, directly addressing background corruption and misalignment. To offset the diversity loss that fine-tuning can cause, MAGIC adds two complementary perturbation strategies: (i) Gaussian prompt-level perturbation applied during fine-tuning and inference that broadens the global appearance of anomalies while avoiding low-fidelity textual appearances, and (ii) mask-guided spatial noise injection that enriches local texture variations. Additionally, the context-aware mask alignment module forms semantic correspondences and relocates masks so that every anomaly remains plausibly contained within the host object, eliminating out-of-boundary artifacts. Under a consistent identical evaluation protocol on the MVTec-AD dataset, MAGIC outperforms previous state-of-the-arts in downstream anomaly tasks.",
      "authors": [
        "JaeHyuck Choi",
        "MinJun Kim",
        "JeHyeong Hong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T04:54:37+00:00",
          "link": "https://arxiv.org/abs/2507.02314v1",
          "size": "1690kb",
          "version": "v1"
        }
      ],
      "title": "MAGIC: Mask-Guided Diffusion Inpainting with Multi-Level Perturbations and Context-Aware Alignment for Few-Shot Anomaly Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02314",
        "HTML": "https://arxiv.org/html/2507.02314v1",
        "PDF": "https://arxiv.org/pdf/2507.02314"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with anomaly generation in industrial quality settings using diffusion inpainting, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02315",
      "abstract": "Recent work has framed constrained text generation with autoregressive language models as a probabilistic inference problem. Among these, Zhao et al. (2024) introduced a promising approach based on twisted Sequential Monte Carlo, which incorporates learned twist functions and twist-induced proposals to guide the generation process. However, in constrained generation settings where the target distribution concentrates on outputs that are unlikely under the base model, learning becomes challenging due to sparse and uninformative reward signals. We show that iteratively refining the base model through self-distillation alleviates this issue by making the model progressively more aligned with the target, leading to substantial gains in generation quality.",
      "authors": [
        "Sooyeon Kim",
        "Giung Nam",
        "Juho Lee"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T05:00:21+00:00",
          "link": "https://arxiv.org/abs/2507.02315v1",
          "size": "37kb",
          "version": "v1"
        }
      ],
      "title": "Improving Constrained Generation in Language Models via Self-Distilled Twisted Sequential Monte Carlo",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02315",
        "HTML": "https://arxiv.org/html/2507.02315v1",
        "PDF": "https://arxiv.org/pdf/2507.02315"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The abstract discusses methods to improve constrained text generation quality in language models, referencing model alignment. However, it does not focus on novel data processing techniques specific to LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02316",
      "abstract": "Text-to-video (T2V) synthesis has advanced rapidly, yet current evaluation metrics primarily capture visual quality and temporal consistency, offering limited insight into how synthetic videos perform in downstream tasks such as text-to-video retrieval (TVR). In this work, we introduce SynTVA, a new dataset and benchmark designed to evaluate the utility of synthetic videos for building retrieval models. Based on 800 diverse user queries derived from MSRVTT training split, we generate synthetic videos using state-of-the-art T2V models and annotate each video-text pair along four key semantic alignment dimensions: Object \\& Scene, Action, Attribute, and Prompt Fidelity. Our evaluation framework correlates general video quality assessment (VQA) metrics with these alignment scores, and examines their predictive power for downstream TVR performance. To explore pathways of scaling up, we further develop an Auto-Evaluator to estimate alignment quality from existing metrics. Beyond benchmarking, our results show that SynTVA is a valuable asset for dataset augmentation, enabling the selection of high-utility synthetic samples that measurably improve TVR outcomes. Project page and dataset can be found at https://jasoncodemaker.github.io/SynTVA/.",
      "authors": [
        "Zecheng Zhao",
        "Selena Song",
        "Tong Chen",
        "Zhi Chen",
        "Shazia Sadiq",
        "Yadan Luo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T05:01:46+00:00",
          "link": "https://arxiv.org/abs/2507.02316v1",
          "size": "12640kb",
          "version": "v1"
        }
      ],
      "title": "Are Synthetic Videos Useful? A Benchmark for Retrieval-Centric Evaluation of Synthetic Videos",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02316",
        "HTML": "https://arxiv.org/html/2507.02316v1",
        "PDF": "https://arxiv.org/pdf/2507.02316"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work introduces a benchmark for evaluating synthetic videos in text-to-video retrieval, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02318",
      "abstract": "Type errors in Python often lead to runtime failures, posing significant challenges to software reliability and developer productivity. Existing static analysis tools aim to detect such errors without execution but frequently suffer from high false positive rates. Recently, unit test generation techniques offer great promise in achieving high test coverage, but they often struggle to produce bug-revealing tests without tailored guidance. To address these limitations, we present RTED, a novel type-aware test generation technique for automatically detecting Python type errors. Specifically, RTED combines step-by-step type constraint analysis with reflective validation to guide the test generation process and effectively suppress false positives. We evaluated RTED on two widely-used benchmarks, BugsInPy and TypeBugs. Experimental results show that RTED can detect 22-29 more benchmarked type errors than four state-of-the-art techniques. RTED is also capable of producing fewer false positives, achieving an improvement of 173.9%-245.9% in precision. Furthermore, RTED successfully discovered 12 previously unknown type errors from six real-world open-source Python projects.",
      "authors": [
        "Chen Yang",
        "Ziqi Wang",
        "Yanjie Jiang",
        "Lin Yang",
        "Yuteng Zheng",
        "Jianyi Zhou",
        "Junjie Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T05:10:33+00:00",
          "link": "https://arxiv.org/abs/2507.02318v1",
          "size": "564kb",
          "version": "v1"
        }
      ],
      "title": "Precisely Detecting Python Type Errors via LLM-based Unit Test Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02318",
        "HTML": "https://arxiv.org/html/2507.02318v1",
        "PDF": "https://arxiv.org/pdf/2507.02318"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on detecting Python type errors using test generation and does not explore data processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02319",
      "abstract": "The belief revision field is opulent in new proposals and indigent in analyses of existing approaches. Much work hinge on postulates, employed as syntactic characterizations: some revision mechanism is equivalent to some properties. Postulates constraint specific revision instances: certain revisions update certain beliefs in a certain way. As an example, if the revision is consistent with the current beliefs, it is incorporated with no other change. A postulate like this tells what revisions must do and neglect what they can do. Can they reach a certain state of beliefs? Can they reach all possible states of beliefs? Can they reach all possible states of beliefs from no previous belief? Can they reach a dogmatic state of beliefs, where everything not believed is impossible? Can they make two conditions equally believed? An application where every possible state of beliefs is sensible requires each state of beliefs to be reachable. An application where conditions may be equally believed requires such a belief state to be reachable. An application where beliefs may become dogmatic requires a way to make them dogmatic. Such doxastic states need to be reached in a way or another. Not in specific way, as dictated by a typical belief revision postulate. This is an ability, not a constraint: the ability of being plastic, equating, dogmatic. Amnesic, correcting, believer, damascan, learnable are other abilities. Each revision mechanism owns some of these abilities and lacks the others: lexicographic, natural, restrained, very radical, full meet, radical, severe, moderate severe, deep severe, plain severe and deep severe revisions, each of these revisions is proved to possess certain abilities.",
      "authors": [
        "Paolo Liberatore"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T05:11:41+00:00",
          "link": "https://arxiv.org/abs/2507.02319v1",
          "size": "62kb",
          "version": "v1"
        }
      ],
      "title": "Iterated belief revision: from postulates to abilities",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02319",
        "HTML": "https://arxiv.org/html/2507.02319v1",
        "PDF": "https://arxiv.org/pdf/2507.02319"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on belief revision in the context of logic and epistemology, with no mention of large language models or any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02320",
      "abstract": "Electroencephalography (EEG) is one of the most common signals used to capture the electrical activity of the brain, and the decoding of EEG, to acquire the user intents, has been at the forefront of brain-computer/machine interfaces (BCIs/BMIs) research. Compared to traditional EEG analysis methods with machine learning, the advent of deep learning approaches have gradually revolutionized the field by providing an end-to-end long-cascaded architecture, which can learn more discriminative features automatically. Among these, Transformer is renowned for its strong handling capability of sequential data by the attention mechanism, and the application of Transformers in various EEG processing tasks is increasingly prevalent. This article delves into a relevant survey, summarizing the latest application of Transformer models in EEG decoding since it appeared. The evolution of the model architecture is followed to sort and organize the related advances, in which we first elucidate the fundamentals of the Transformer that benefits EEG decoding and its direct application. Then, the common hybrid architectures by integrating basic Transformer with other deep learning techniques (convolutional/recurrent/graph/spiking neural netwo-rks, generative adversarial networks, diffusion models, etc.) is overviewed in detail. The research advances of applying the modified intrinsic structures of customized Transformer have also been introduced. Finally, the current challenges and future development prospects in this rapidly evolving field are discussed. This paper aims to help readers gain a clear understanding of the current state of Transformer applications in EEG decoding and to provide valuable insights for future research endeavors.",
      "authors": [
        "Haodong Zhang",
        "Hongqi Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T05:12:06+00:00",
          "link": "https://arxiv.org/abs/2507.02320v1",
          "size": "2565kb",
          "version": "v1"
        }
      ],
      "title": "Transformer-based EEG Decoding: A Survey",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02320",
        "HTML": "https://arxiv.org/html/2507.02320v1",
        "PDF": "https://arxiv.org/pdf/2507.02320"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This survey paper discusses the application of Transformer models to EEG data decoding, which is unrelated to training data processing for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02321",
      "abstract": "Despite significant progress in text-to-image diffusion models, achieving precise spatial control over generated outputs remains challenging. ControlNet addresses this by introducing an auxiliary conditioning module, while ControlNet++ further refines alignment through a cycle consistency loss applied only to the final denoising steps. However, this approach neglects intermediate generation stages, limiting its effectiveness. We propose InnerControl, a training strategy that enforces spatial consistency across all diffusion steps. Our method trains lightweight convolutional probes to reconstruct input control signals (e.g., edges, depth) from intermediate UNet features at every denoising step. These probes efficiently extract signals even from highly noisy latents, enabling pseudo ground truth controls for training. By minimizing the discrepancy between predicted and target conditions throughout the entire diffusion process, our alignment loss improves both control fidelity and generation quality. Combined with established techniques like ControlNet++, InnerControl achieves state-of-the-art performance across diverse conditioning methods (e.g., edges, depth).",
      "authors": [
        "Nina Konovalova",
        "Maxim Nikolaev",
        "Andrey Kuznetsov",
        "Aibek Alanov"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T05:25:53+00:00",
          "link": "https://arxiv.org/abs/2507.02321v1",
          "size": "15564kb",
          "version": "v1"
        }
      ],
      "title": "Heeding the Inner Voice: Aligning ControlNet Training via Intermediate Features Feedback",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02321",
        "PDF": "https://arxiv.org/pdf/2507.02321"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on improving spatial control in text-to-image diffusion models, not on the collection or processing of training data for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02322",
      "abstract": "Rice leaf diseases significantly reduce productivity and cause economic losses, highlighting the need for early detection to enable effective management and improve yields. This study proposes Artificial Neural Network (ANN)-based image-processing techniques for timely classification and recognition of rice diseases. Despite the prevailing approach of directly inputting images of rice leaves into ANNs, there is a noticeable absence of thorough comparative analysis between the Feature Analysis Detection Model (FADM) and Direct Image-Centric Detection Model (DICDM), specifically when it comes to evaluating the effectiveness of Feature Extraction Algorithms (FEAs). Hence, this research presents initial experiments on the Feature Analysis Detection Model, utilizing various image Feature Extraction Algorithms, Dimensionality Reduction Algorithms (DRAs), Feature Selection Algorithms (FSAs), and Extreme Learning Machine (ELM). The experiments are carried out on datasets encompassing bacterial leaf blight, brown spot, leaf blast, leaf scald, Sheath blight rot, and healthy leaf, utilizing 10-fold Cross-Validation method. A Direct Image-Centric Detection Model is established without the utilization of any FEA, and the evaluation of classification performance relies on different metrics. Ultimately, an exhaustive contrast is performed between the achievements of the Feature Analysis Detection Model and Direct Image-Centric Detection Model in classifying rice leaf diseases. The results reveal that the highest performance is attained using the Feature Analysis Detection Model. The adoption of the proposed Feature Analysis Detection Model for detecting rice leaf diseases holds excellent potential for improving crop health, minimizing yield losses, and enhancing overall productivity and sustainability of rice farming.",
      "authors": [
        "Farida Siddiqi Prity",
        "Mirza Raquib",
        "Saydul Akbar Murad",
        "Md. Jubayar Alam Rafi",
        "Md. Khairul Bashar Bhuiyan",
        "Anupam Kumar Bairagi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T05:26:52+00:00",
          "link": "https://arxiv.org/abs/2507.02322v1",
          "size": "7210kb",
          "version": "v1"
        }
      ],
      "title": "Neural Network-based Study for Rice Leaf Disease Recognition and Classification: A Comparative Analysis Between Feature-based Model and Direct Imaging Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02322",
        "HTML": "https://arxiv.org/html/2507.02322v1",
        "PDF": "https://arxiv.org/pdf/2507.02322"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes techniques for rice leaf disease recognition using neural networks, which is specific to image processing applications and not related to LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02325",
      "abstract": "Grid-connected inverter control is challenging to implement due to the difficulty of obtaining and maintaining an accurate grid model. Direct Data-Driven Predictive Control provides a model-free alternative to traditional model-based control methods. This paper describes how the recently-proposed Transient Predictive Control (TPC) can be used for real-world, plug-and-play inverter control. The following hypotheses were tested: 1) The TPC algorithm can be run online using standard hardware, and 2) TPC, which is derived using Linear Time-Invariant assumptions, is effective for grid-connected inverter control, which is a nonlinear and time-varying system. Experiments conducted on a two-converter benchtop setup and at the CoSES Laboratory on a 25 kVA converter connected to the Munich grid support these hypotheses.",
      "authors": [
        "Sebastian Graf",
        "Keith Moffat",
        "Anurag Mohapatra",
        "Alessandro Chiuso",
        "Florian D\\\"orfler"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T05:32:30+00:00",
          "link": "https://arxiv.org/abs/2507.02325v1",
          "size": "3030kb",
          "version": "v1"
        }
      ],
      "title": "Grid-Connected, Data-Driven Inverter Control, Theory to Hardware",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02325",
        "HTML": "https://arxiv.org/html/2507.02325v1",
        "PDF": "https://arxiv.org/pdf/2507.02325"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with control methods for grid-connected inverters and does not address LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02328",
      "abstract": "Path planning algorithms aim to compute a collision-free path, and many works focus on finding the optimal distance path. However, for some applications, a more suitable approach is to balance response time, safety of the paths, and path length. In this context, a skeleton map is a useful tool in graph-based schemes, as it provides an intrinsic representation of free configuration space. However, skeletonization algorithms are very resource-intensive, being primarily oriented towards image processing tasks. We propose an efficient path-planning methodology that finds safe paths within an acceptable processing time. This methodology leverages a Deep Denoising Auto-Encoder (DDAE) based on U-Net architecture to compute a skeletonized version of the navigation map, which we refer to as SkelUnet. The SkelUnet network facilitates exploration of the entire workspace through one-shot sampling (OSS), as opposed to the iterative process used by exact algorithms or the probabilistic sampling process. SkelUnet is trained and tested on a dataset consisting of 12,500 bi-dimensional dungeon maps. The motion planning methodology is evaluated in a simulation environment for an Unmanned Aerial Vehicle (UAV) using 250 previously unseen maps, and assessed with various navigation metrics to quantify the navigability of the computed paths. The results demonstrate that using SkelUnet to construct a roadmap offers significant advantages, such as connecting all regions of free workspace, providing safer paths, and reducing processing times. These characteristics make this method particularly suitable for mobile service robots in structured environments.",
      "authors": [
        "Gabriel O. Flores-Aquino and Octavio Gutierrez-Frias and Juan Irving Vasquez"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T05:38:26+00:00",
          "link": "https://arxiv.org/abs/2507.02328v1",
          "size": "3230kb",
          "version": "v1"
        }
      ],
      "title": "Path Planning using a One-shot-sampling Skeleton Map",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02328",
        "HTML": "https://arxiv.org/html/2507.02328v1",
        "PDF": "https://arxiv.org/pdf/2507.02328"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on path planning and skeletonization for navigation maps using a denoising auto-encoder, unrelated to the processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02331",
      "abstract": "This paper leverages the recently introduced concept of algorithm footprints to investigate the interplay between algorithm configurations and problem characteristics. Performance footprints are calculated for six modular variants of the CMA-ES algorithm (modCMA), evaluated on 24 benchmark problems from the BBOB suite, across two-dimensional settings: 5-dimensional and 30-dimensional. These footprints provide insights into why different configurations of the same algorithm exhibit varying performance and identify the problem features influencing these outcomes. Our analysis uncovers shared behavioral patterns across configurations due to common interactions with problem properties, as well as distinct behaviors on the same problem driven by differing problem features. The results demonstrate the effectiveness of algorithm footprints in enhancing interpretability and guiding configuration choices.",
      "authors": [
        "Ana Nikolikj and Mario Andr\\'es Mu\\~noz and Eva Tuba and Tome Eftimov"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T05:48:58+00:00",
          "link": "https://arxiv.org/abs/2507.02331v1",
          "size": "974kb",
          "version": "v1"
        }
      ],
      "title": "Tracing the Interactions of Modular CMA-ES Configurations Across Problem Landscapes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02331",
        "HTML": "https://arxiv.org/html/2507.02331v1",
        "PDF": "https://arxiv.org/pdf/2507.02331"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study explores algorithm footprints for modular CMA-ES variants and problem landscapes, not involving any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02332",
      "abstract": "This paper investigates privacy jailbreaking in LLMs via steering, focusing on whether manipulating activations can bypass LLM alignment and alter response behaviors to privacy related queries (e.g., a certain public figure's sexual orientation). We begin by identifying attention heads predictive of refusal behavior for private attributes (e.g., sexual orientation) using lightweight linear probes trained with privacy evaluator labels. Next, we steer the activations of a small subset of these attention heads guided by the trained probes to induce the model to generate non-refusal responses. Our experiments show that these steered responses often disclose sensitive attribute details, along with other private information about data subjects such as life events, relationships, and personal histories that the models would typically refuse to produce. Evaluations across four LLMs reveal jailbreaking disclosure rates of at least 95%, with more than 50% on average of these responses revealing true personal information. Our controlled study demonstrates that private information memorized in LLMs can be extracted through targeted manipulation of internal activations.",
      "authors": [
        "Krishna Kanth Nakka",
        "Xue Jiang",
        "Xuebing Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T05:50:50+00:00",
          "link": "https://arxiv.org/abs/2507.02332v1",
          "size": "3633kb",
          "version": "v1"
        }
      ],
      "title": "PII Jailbreaking in LLMs via Activation Steering Reveals Personal Information Leakage",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02332",
        "PDF": "https://arxiv.org/pdf/2507.02332"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "Although this paper discusses LLMs, it focuses on privacy and activation steering rather than on the processes related to the engineering or training-stage data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02337",
      "abstract": "Understanding the behavior of numerical metaheuristic optimization algorithms is critical for advancing their development and application. Traditional visualization techniques, such as convergence plots, trajectory mapping, and fitness landscape analysis, often fall short in illustrating the structural dynamics of the search process, especially in high-dimensional or complex solution spaces. To address this, we propose a novel representation and visualization methodology that clusters solution candidates explored by the algorithm and tracks the evolution of cluster memberships across iterations, offering a dynamic and interpretable view of the search process. Additionally, we introduce two metrics - algorithm stability and algorithm similarity- to quantify the consistency of search trajectories across runs of an individual algorithm and the similarity between different algorithms, respectively. We apply this methodology to a set of ten numerical metaheuristic algorithms, revealing insights into their stability and comparative behaviors, thereby providing a deeper understanding of their search dynamics.",
      "authors": [
        "Gjorgjina Cenikj and Ga\\v{s}per Petelin and Tome Eftimov"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T06:01:02+00:00",
          "link": "https://arxiv.org/abs/2507.02337v1",
          "size": "390kb",
          "version": "v1"
        }
      ],
      "title": "ClustOpt: A Clustering-based Approach for Representing and Visualizing the Search Dynamics of Numerical Metaheuristic Optimization Algorithms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02337",
        "HTML": "https://arxiv.org/html/2507.02337v1",
        "PDF": "https://arxiv.org/pdf/2507.02337"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research investigates clustering and search dynamics in optimization algorithms with no relation to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02340",
      "abstract": "This paper focuses on the numerical approximation of the linearized shallow water equations using hybridizable discontinuous Galerkin (HDG) methods, leveraging the Hamiltonian structure of the evolution system. First, we propose an equivalent formulation of the equations by introducing an auxiliary variable. Then, we discretize the space variables using HDG methods, resulting in a semi-discrete scheme that preserves a discrete version of the Hamiltonian structure. The use of an alternative formulation with the auxiliary variable is crucial for developing the HDG scheme that preserves this Hamiltonian structure. The resulting system is subsequently discretized in time using symplectic integrators, ensuring the energy conservation of the fully discrete scheme. We present numerical experiments that demonstrate optimal convergence rates for all variables and showcase the conservation of total energy, as well as the evolution of other physical quantities.",
      "authors": [
        "C. N\\'u\\~nez (1)",
        "M. A. S\\'anchez (2) ((1) Facultad de Matem\\'aticas",
        "Pontificia Universidad Cat\\'olica de Chile",
        "Santiago",
        "Chile",
        "(2) Instituto de Ingenier\\'ia Matem\\'atica y Computacional",
        "Facultad de Matem\\'aticas y Escuela de Ingenier\\'ia",
        "Pontificia Universidad Cat\\'olica de Chile",
        "Santiago",
        "Chile)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T06:06:05+00:00",
          "link": "https://arxiv.org/abs/2507.02340v1",
          "size": "2551kb",
          "version": "v1"
        }
      ],
      "title": "Symplectic Hamiltonian Hybridizable Discontinuous Galerkin Methods for Linearized Shallow Water Equations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02340",
        "HTML": "https://arxiv.org/html/2507.02340v1",
        "PDF": "https://arxiv.org/pdf/2507.02340"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on numerical approximations using HDG methods for shallow water equations, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02342",
      "abstract": "This study proposes DeltaSHAP, a novel explainable artificial intelligence (XAI) algorithm specifically designed for online patient monitoring systems. In clinical environments, discovering the causes driving patient risk evolution is critical for timely intervention, yet existing XAI methods fail to address the unique requirements of clinical time series explanation tasks. To this end, DeltaSHAP addresses three key clinical needs: explaining the changes in the consecutive predictions rather than isolated prediction scores, providing both magnitude and direction of feature attributions, and delivering these insights in real time. By adapting Shapley values to temporal settings, our approach accurately captures feature coalition effects. It further attributes prediction changes using only the actually observed feature combinations, making it efficient and practical for time-sensitive clinical applications. We also introduce new evaluation metrics to evaluate the faithfulness of the attributions for online time series, and demonstrate through experiments on online patient monitoring tasks that DeltaSHAP outperforms state-of-the-art XAI methods in both explanation quality as 62% and computational efficiency as 33% time reduction on the MIMIC-III decompensation benchmark. We release our code at https://github.com/AITRICS/DeltaSHAP.",
      "authors": [
        "Changhun Kim",
        "Yechan Mun",
        "Sangchul Hahn",
        "and Eunho Yang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T06:08:07+00:00",
          "link": "https://arxiv.org/abs/2507.02342v1",
          "size": "3511kb",
          "version": "v1"
        }
      ],
      "title": "DeltaSHAP: Explaining Prediction Evolutions in Online Patient Monitoring with Shapley Values",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02342",
        "HTML": "https://arxiv.org/html/2507.02342v1",
        "PDF": "https://arxiv.org/pdf/2507.02342"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on explainable AI for online patient monitoring, specifically using Shapley values for temporal prediction explanations. It does not address LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02349",
      "abstract": "Intracranial aneurysms (ICA) commonly occur in specific segments of the Circle of Willis (CoW), primarily, onto thirteen major arterial bifurcations. An accurate detection of these critical landmarks is necessary for a prompt and efficient diagnosis. We introduce a fully automated landmark detection approach for CoW bifurcations using a two-step neural networks process. Initially, an object detection network identifies regions of interest (ROIs) proximal to the landmark locations. Subsequently, a modified U-Net with deep supervision is exploited to accurately locate the bifurcations. This two-step method reduces various problems, such as the missed detections caused by two landmarks being close to each other and having similar visual characteristics, especially when processing the complete MRA Time-of-Flight (TOF). Additionally, it accounts for the anatomical variability of the CoW, which affects the number of detectable landmarks per scan. We assessed the effectiveness of our approach using two cerebral MRA datasets: our In-House dataset which had varying numbers of landmarks, and a public dataset with standardized landmark configuration. Our experimental results demonstrate that our method achieves the highest level of performance on a bifurcation detection task.",
      "authors": [
        "Rafic Nader and Vincent L'Allinec and Romain Bourcier and Florent Autrusseau"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T06:23:38+00:00",
          "link": "https://arxiv.org/abs/2507.02349v1",
          "size": "4517kb",
          "version": "v1"
        }
      ],
      "title": "Two-Steps Neural Networks for an Automated Cerebrovascular Landmark Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02349",
        "HTML": "https://arxiv.org/html/2507.02349v1",
        "PDF": "https://arxiv.org/pdf/2507.02349"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work proposes a neural network method for detecting cerebrovascular landmarks, focusing on medical imaging rather than LLM training data processes or engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02350",
      "abstract": "Traditional video-induced emotion physiological datasets often use whole-trial annotation, assigning a single emotion label to all data collected during an entire trial. This coarse-grained annotation approach misaligns with the dynamic and temporally localized nature of emotional responses as they unfold with video narratives, introducing label noise that limits emotion recognition algorithm evaluation and performance. To solve the label noise problem caused by coarse-grained annotation, we propose a fine-grained annotation method through an immediate recall paradigm. This paradigm integrates an immediate video replay phase after the initial stimulus viewing, allowing participants to precisely mark the onset timestamp, emotion label, and intensity based on their immediate recall. We validate this paradigm through physiological evidence and recognition performance. Physiological validation of multimodal signals within participant-marked windows revealed rhythm-specific EEG patterns and arousal-dependent GSR responses-with SCRs appearing in 91% of high-arousal versus 6% of low-arousal emotion windows. These objective physiological data changes strongly aligned with subjective annotations, confirming annotation precision. For recognition performance, classification experiments showed that models trained on fine-grained annotations achieved 9.7% higher accuracy than traditional whole-trial labeling, despite using less data. This work not only addresses label noise through fine-grained annotation but also demonstrates that annotation precision outweighs data scale in determining emotion recognition performance.",
      "authors": [
        "Hao Tang",
        "Songyun Xie",
        "Xinzhou Xie",
        "Can Liao",
        "Xin Zhang",
        "Bohan Li",
        "Zhongyu Tian",
        "Dalu Zheng"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T06:23:51+00:00",
          "link": "https://arxiv.org/abs/2507.02350v1",
          "size": "10401kb",
          "version": "v1"
        }
      ],
      "title": "From Coarse to Fine-Grained Emotion Annotation: An Immediate Recall Paradigm with Validation through Physiological Evidence and Recognition Performance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02350",
        "HTML": "https://arxiv.org/html/2507.02350v1",
        "PDF": "https://arxiv.org/pdf/2507.02350"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research deals with emotion annotation precision in video datasets, which doesn't relate to LLM training data processes or any engineering stages associated with LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02351",
      "abstract": "The optimal management of a building's microclimate to satisfy the occupants' needs and objectives in terms of comfort, energy efficiency, and costs is particularly challenging. This complexity arises from the non-linear, time-dependent interactions among all the variables of the control problem and the changing internal and external constraints. Focusing on the accurate modeling of the indoor temperature, we propose a data-driven approach to address this challenge. We account for thermal inertia, non-linear effects, small perturbations of the indoor climate dynamics caused by ventilation and weather variations, as well as for the stochastic nature of the control system due to the observed noise in the input signal. Since the prohibitive cost of quality data acquisition and processing limits the implementation of data-driven approaches for real-life problems, we applied a method that merges several Bayesian machine learning and deep learning architectures that are suitable for predicting complex system dynamics, while relaxing the dataset quality requirements. Our framework includes a built-in deep Kalman filter, which makes it deployable even with low-accuracy temperature sensors. It achieves state-of-the-art performance, best performing with a 150-minute prediction horizon with an RMSE of 0.2455, an MAE of 0.162, and an $R^2$ of 0.926. The model's performance remains consistent even when exposed to highly noisy data. Finally, we show how our approach can be extended to other applications including demand response event duration prediction and equipment failure detection.",
      "authors": [
        "Javier Penuela",
        "Sahar Moghimian Hoosh",
        "Ilia Kamyshev",
        "Aldo Bischi",
        "Henni Ouerdane"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T06:34:57+00:00",
          "link": "https://arxiv.org/abs/2507.02351v1",
          "size": "975kb",
          "version": "v1"
        }
      ],
      "title": "Indoor thermal comfort management: A Bayesian machine-learning approach to data denoising and dynamics prediction of HVAC systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02351",
        "HTML": "https://arxiv.org/html/2507.02351v1",
        "PDF": "https://arxiv.org/pdf/2507.02351"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on managing indoor thermal comfort using machine learning techniques and does not address any aspect of LLM training data collection, construction, or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02353",
      "abstract": "Keyword decision in Sponsored Search Advertising is critical to the success of ad campaigns. While LLM-based methods offer automated keyword generation, they face three major limitations: reliance on large-scale query-keyword pair data, lack of online multi-objective performance monitoring and optimization, and weak quality control in keyword selection. These issues hinder the agentic use of LLMs in fully automating keyword decisions by monitoring and reasoning over key performance indicators such as impressions, clicks, conversions, and CTA effectiveness. To overcome these challenges, we propose OMS, a keyword generation framework that is On-the-fly (requires no training data, monitors online performance, and adapts accordingly), Multi-objective (employs agentic reasoning to optimize keywords based on multiple performance metrics), and Self-reflective (agentically evaluates keyword quality). Experiments on benchmarks and real-world ad campaigns show that OMS outperforms existing methods; ablation and human evaluations confirm the effectiveness of each component and the quality of generated keywords.",
      "authors": [
        "Bowen Chen",
        "Zhao Wang",
        "Shingo Takamatsu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T06:37:55+00:00",
          "link": "https://arxiv.org/abs/2507.02353v1",
          "size": "27496kb",
          "version": "v1"
        }
      ],
      "title": "OMS: On-the-fly, Multi-Objective, Self-Reflective Ad Keyword Generation via LLM Agent",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02353",
        "HTML": "https://arxiv.org/html/2507.02353v1",
        "PDF": "https://arxiv.org/pdf/2507.02353"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper mentions the use of LLMs for ad keyword generation but does not focus on the processing of training data for LLMs or propose new methods in this area."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02354",
      "abstract": "Shrimp diseases are one of the primary causes of economic losses in shrimp aquaculture. To prevent disease transmission and enhance intelligent detection efficiency in shrimp farming, this paper proposes a lightweight network architecture based on YOLOv8n. First, by designing the RLDD detection head and C2f-EMCM module, the model reduces computational complexity while maintaining detection accuracy, improving computational efficiency. Subsequently, an improved SegNext_Attention self-attention mechanism is introduced to further enhance the model's feature extraction capability, enabling more precise identification of disease characteristics. Extensive experiments, including ablation studies and comparative evaluations, are conducted on a self-constructed shrimp disease dataset, with generalization tests extended to the URPC2020 dataset. Results demonstrate that the proposed model achieves a 32.3% reduction in parameters compared to the original YOLOv8n, with a mAP@0.5 of 92.7% (3% improvement over YOLOv8n). Additionally, the model outperforms other lightweight YOLO-series models in mAP@0.5, parameter count, and model size. Generalization experiments on the URPC2020 dataset further validate the model's robustness, showing a 4.1% increase in mAP@0.5 compared to YOLOv8n. The proposed method achieves an optimal balance between accuracy and efficiency, providing reliable technical support for intelligent disease detection in shrimp aquaculture.",
      "authors": [
        "Fei Yuhuan",
        "Wang Gengchen",
        "Liu Fenghao",
        "Zang Ran",
        "Sun Xufei",
        "Chang Hao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T06:38:55+00:00",
          "link": "https://arxiv.org/abs/2507.02354v1",
          "size": "1257kb",
          "version": "v1"
        }
      ],
      "title": "Lightweight Shrimp Disease Detection Research Based on YOLOv8n",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02354",
        "PDF": "https://arxiv.org/pdf/2507.02354"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study centers on using a lightweight model for shrimp disease detection and does not relate to LLMs or their training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02356",
      "abstract": "Offline reinforcement learning (RL) optimizes a policy using only a fixed dataset, making it a practical approach in scenarios where interaction with the environment is costly. Due to this limitation, generalization ability is key to improving the performance of offline RL algorithms, as demonstrated by recent successes of offline RL with diffusion models. However, it remains questionable whether such diffusion models are necessary for highly performing offline RL algorithms, given their significant computational requirements during inference. In this paper, we propose Penalized Action Noise Injection (PANI), a method that simply enhances offline learning by utilizing noise-injected actions to cover the entire action space, while penalizing according to the amount of noise injected. This approach is inspired by how diffusion models have worked in offline RL algorithms. We provide a theoretical foundation for this method, showing that offline RL algorithms with such noise-injected actions solve a modified Markov Decision Process (MDP), which we call the noisy action MDP. PANI is compatible with a wide range of existing off-policy and offline RL algorithms, and despite its simplicity, it demonstrates significant performance improvements across various benchmarks.",
      "authors": [
        "JunHyeok Oh",
        "Byung-Jun Lee"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T06:41:03+00:00",
          "link": "https://arxiv.org/abs/2507.02356v1",
          "size": "1031kb",
          "version": "v1"
        }
      ],
      "title": "Offline Reinforcement Learning with Penalized Action Noise Injection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02356",
        "HTML": "https://arxiv.org/html/2507.02356v1",
        "PDF": "https://arxiv.org/pdf/2507.02356"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses offline reinforcement learning with action noise injection, which does not relate to LLM training data processing, collection, or construction."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02357",
      "abstract": "This paper describes our system for the SciVQA 2025 Shared Task on Scientific Visual Question Answering. Our system employs an ensemble of two Multimodal Large Language Models and various few-shot example retrieval strategies. The model and few-shot setting are selected based on the figure and question type. We also select answers based on the models' confidence levels. On the blind test data, our system ranks third out of seven with an average F1 score of 85.12 across ROUGE-1, ROUGE-L, and BERTS. Our code is publicly available.",
      "authors": [
        "Christian Jaumann",
        "Annemarie Friedrich",
        "Rainer Lienhart"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T06:43:05+00:00",
          "link": "https://arxiv.org/abs/2507.02357v1",
          "size": "119kb",
          "version": "v1"
        }
      ],
      "title": "Coling-UniA at SciVQA 2025: Few-Shot Example Retrieval and Confidence-Informed Ensembling for Multimodal Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02357",
        "HTML": "https://arxiv.org/html/2507.02357v1",
        "PDF": "https://arxiv.org/pdf/2507.02357"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper involves multimodal LLMs and few-shot learning strategies, it does not focus on novel approaches to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02358",
      "abstract": "The vanilla autoregressive image generation model generates visual tokens in a step-by-step fashion, which limits the ability to capture holistic relationships among token sequences. Moreover, most visual tokenizers map local image patches into latent tokens, leading to limited global information. To address this, we introduce \\textit{Hita}, a novel image tokenizer for autoregressive (AR) image generation. It introduces a holistic-to-local tokenization scheme with learnable holistic queries and local patch tokens. Besides, Hita incorporates two key strategies for improved alignment with the AR generation process: 1) it arranges a sequential structure with holistic tokens at the beginning followed by patch-level tokens while using causal attention to maintain awareness of previous tokens; and 2) before feeding the de-quantized tokens into the decoder, Hita adopts a lightweight fusion module to control information flow to prioritize holistic tokens. Extensive experiments show that Hita accelerates the training speed of AR generators and outperforms those trained with vanilla tokenizers, achieving \\textbf{2.59 FID} and \\textbf{281.9 IS} on the ImageNet benchmark. A detailed analysis of the holistic representation highlights its ability to capture global image properties such as textures, materials, and shapes. Additionally, Hita also demonstrates effectiveness in zero-shot style transfer and image in-painting. The code is available at \\href{https://github.com/CVMI-Lab/Hita}{https://github.com/CVMI-Lab/Hita}",
      "authors": [
        "Anlin Zheng",
        "Haochen Wang",
        "Yucheng Zhao",
        "Weipeng Deng",
        "Tiancai Wang",
        "Xiangyu Zhang",
        "Xiaojuan Qi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T06:44:26+00:00",
          "link": "https://arxiv.org/abs/2507.02358v1",
          "size": "22118kb",
          "version": "v1"
        }
      ],
      "title": "Holistic Tokenizer for Autoregressive Image Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02358",
        "HTML": "https://arxiv.org/html/2507.02358v1",
        "PDF": "https://arxiv.org/pdf/2507.02358"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a novel image tokenizer for autoregressive image generation, which is not related to the processing of training data for LLMs but rather to improving image generation models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02363",
      "abstract": "Due to the complex and highly dynamic motions in the real world, synthesizing dynamic videos from multi-view inputs for arbitrary viewpoints is challenging. Previous works based on neural radiance field or 3D Gaussian splatting are limited to modeling fine-scale motion, greatly restricting their application. In this paper, we introduce LocalDyGS, which consists of two parts to adapt our method to both large-scale and fine-scale motion scenes: 1) We decompose a complex dynamic scene into streamlined local spaces defined by seeds, enabling global modeling by capturing motion within each local space. 2) We decouple static and dynamic features for local space motion modeling. A static feature shared across time steps captures static information, while a dynamic residual field provides time-specific features. These are combined and decoded to generate Temporal Gaussians, modeling motion within each local space. As a result, we propose a novel dynamic scene reconstruction framework to model highly dynamic real-world scenes more realistically. Our method not only demonstrates competitive performance on various fine-scale datasets compared to state-of-the-art (SOTA) methods, but also represents the first attempt to model larger and more complex highly dynamic scenes. Project page: https://wujh2001.github.io/LocalDyGS/.",
      "authors": [
        "Jiahao Wu",
        "Rui Peng",
        "Jianbo Jiao",
        "Jiayu Yang",
        "Luyang Tang",
        "Kaiqiang Xiong",
        "Jie Liang",
        "Jinbo Yan",
        "Runling Liu",
        "Ronggang Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T06:50:33+00:00",
          "link": "https://arxiv.org/abs/2507.02363v1",
          "size": "26823kb",
          "version": "v1"
        }
      ],
      "title": "LocalDyGS: Multi-view Global Dynamic Scene Modeling via Adaptive Local Implicit Feature Decoupling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02363",
        "HTML": "https://arxiv.org/html/2507.02363v1",
        "PDF": "https://arxiv.org/pdf/2507.02363"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces LocalDyGS for dynamic scene modeling using multi-view data, which is unrelated to LLM training data processing as it focuses on scene modeling techniques rather than LLM training methodologies."
      },
      "datasets": [
        {
          "dataset_name": "BestWJH/VRU_Basketball",
          "downloads": "107",
          "likes": "0",
          "link": "https://huggingface.co/datasets/BestWJH/VRU_Basketball"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.02364",
      "abstract": "Parameterized quantum circuits (PQCs) have recently emerged as promising components for enhancing the expressibility of neural architectures. In this work, we introduce QFFN-BERT, a hybrid quantum-classical transformer where the feedforward network (FFN) modules of a compact BERT variant are replaced by PQC-based layers. This design is motivated by the dominant parameter contribution of FFNs, which account for approximately two-thirds of the parameters within standard Transformer encoder blocks. While prior studies have primarily integrated PQCs into self-attention modules, our work focuses on the FFN and systematically investigates the trade-offs between PQC depth, expressibility, and trainability. Our final PQC architecture incorporates a residual connection, both $R_Y$ and $R_Z$ rotations, and an alternating entanglement strategy to ensure stable training and high expressibility. Our experiments, conducted on a classical simulator, on the SST-2 and DBpedia benchmarks demonstrate two key findings. First, a carefully configured QFFN-BERT achieves up to 102.0% of the baseline accuracy, surpassing its classical counterpart in a full-data setting while reducing FFN-specific parameters by over 99%. Second, our model exhibits a consistent and competitive edge in few-shot learning scenarios, confirming its potential for superior data efficiency. These results, supported by an ablation study on a non-optimized PQC that failed to learn, confirm that PQCs can serve as powerful and parameter-efficient alternatives to classical FFNs when co-designed with foundational deep learning principles.",
      "authors": [
        "Pilsung Kang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T06:52:44+00:00",
          "link": "https://arxiv.org/abs/2507.02364v1",
          "size": "177kb",
          "version": "v1"
        }
      ],
      "title": "QFFN-BERT: An Empirical Study of Depth, Performance, and Data Efficiency in Hybrid Quantum-Classical Transformers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02364",
        "HTML": "https://arxiv.org/html/2507.02364v1",
        "PDF": "https://arxiv.org/pdf/2507.02364"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper investigates hybrid quantum classical transformers in terms of network expressibility and trainability and does not discuss any aspect of LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02365",
      "abstract": "Equalizer parameter optimization for signal integrity in high-speed Dynamic Random Access Memory systems is crucial but often computationally demanding or model-reliant. This paper introduces a data-driven framework employing learned latent signal representations for efficient signal integrity evaluation, coupled with a model-free Advantage Actor-Critic reinforcement learning agent for parameter optimization. The latent representation captures vital signal integrity features, offering a fast alternative to direct eye diagram analysis during optimization, while the reinforcement learning agent derives optimal equalizer settings without explicit system models. Applied to industry-standard Dynamic Random Access Memory waveforms, the method achieved significant eye-opening window area improvements: 42.7\\% for cascaded Continuous-Time Linear Equalizer and Decision Feedback Equalizer structures, and 36.8\\% for Decision Feedback Equalizer-only configurations. These results demonstrate superior performance, computational efficiency, and robust generalization across diverse Dynamic Random Access Memory units compared to existing techniques. Core contributions include an efficient latent signal integrity metric for optimization, a robust model-free reinforcement learning strategy, and validated superior performance for complex equalizer architectures.",
      "authors": [
        "Muhammad Usama and Dong Eui Chang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T06:53:51+00:00",
          "link": "https://arxiv.org/abs/2507.02365v1",
          "size": "12442kb",
          "version": "v1"
        }
      ],
      "title": "Deep Reinforcement Learning-Based DRAM Equalizer Parameter Optimization Using Latent Representations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02365",
        "HTML": "https://arxiv.org/html/2507.02365v1",
        "PDF": "https://arxiv.org/pdf/2507.02365"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study focuses on DRAM equalizer optimization using deep reinforcement learning and latent representations, which is unrelated to LLM training data processing as it addresses signal integrity in memory systems."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02372",
      "abstract": "Multi-objective evolutionary algorithms (MOEAs) have become essential tools for solving multi-objective optimization problems (MOPs), making their running time analysis crucial for assessing algorithmic efficiency and guiding practical applications. While significant theoretical advances have been achieved for combinatorial optimization, existing studies for numerical optimization primarily rely on algorithmic or problem simplifications, limiting their applicability to real-world scenarios. To address this gap, we propose an experimental approach for estimating upper bounds on the running time of MOEAs in numerical optimization without simplification assumptions. Our approach employs an average gain model that characterizes algorithmic progress through the Inverted Generational Distance metric. To handle the stochastic nature of MOEAs, we use statistical methods to estimate the probabilistic distribution of gains. Recognizing that gain distributions in numerical optimization exhibit irregular patterns with varying densities across different regions, we introduce an adaptive sampling method that dynamically adjusts sampling density to ensure accurate surface fitting for running time estimation. We conduct comprehensive experiments on five representative MOEAs (NSGA-II, MOEA/D, AR-MOEA, AGEMOEA-II, and PREA) using the ZDT and DTLZ benchmark suites. The results demonstrate the effectiveness of our approach in estimating upper bounds on the running time without requiring algorithmic or problem simplifications. Additionally, we provide a web-based implementation to facilitate broader adoption of our methodology. This work provides a practical complement to theoretical research on MOEAs in numerical optimization.",
      "authors": [
        "Han Huang",
        "Tianyu Wang",
        "Chaoda Peng",
        "Tongli He and Zhifeng Hao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T07:06:14+00:00",
          "link": "https://arxiv.org/abs/2507.02372v1",
          "size": "8535kb",
          "version": "v1"
        }
      ],
      "title": "An Experimental Approach for Running-Time Estimation of Multi-objective Evolutionary Algorithms in Numerical Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02372",
        "HTML": "https://arxiv.org/html/2507.02372v1",
        "PDF": "https://arxiv.org/pdf/2507.02372"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on running-time estimation of multi-objective evolutionary algorithms in numerical optimization, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02373",
      "abstract": "Recently, the remarkable success of large language models (LLMs) has achieved a profound impact on the field of artificial intelligence. Numerous advanced works based on LLMs have been proposed and applied in various scenarios. Among them, video language models (VidLMs) are particularly widely used. However, existing works primarily focus on terrestrial scenarios, overlooking the highly demanding application needs of underwater observation. To overcome this gap, we introduce UVLM, an under water observation benchmark which is build through a collaborative approach combining human expertise and AI models. To ensure data quality, we have conducted in-depth considerations from multiple perspectives. First, to address the unique challenges of underwater environments, we selected videos that represent typical underwater challenges including light variations, water turbidity, and diverse viewing angles to construct the dataset. Second, to ensure data diversity, the dataset covers a wide range of frame rates, resolutions, 419 classes of marine animals, and various static plants and terrains. Next, for task diversity, we adopted a structured design where observation targets are categorized into two major classes: biological and environmental. Each category includes content observation and change/action observation, totaling 20 distinct task types. Finally, we designed several challenging evaluation metrics to enable quantitative comparison and analysis of different methods. Experiments on two representative VidLMs demonstrate that fine-tuning VidLMs on UVLM significantly improves underwater world understanding while also showing potential for slight improvements on existing in-air VidLM benchmarks, such as VideoMME and Perception text. The dataset and prompt engineering will be released publicly.",
      "authors": [
        "Xizhe Xue and Yang Zhou and Dawei Yan and Ying Li and Haokui Zhang and Rong Xiao"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T07:08:38+00:00",
          "link": "https://arxiv.org/abs/2507.02373v1",
          "size": "6111kb",
          "version": "v1"
        }
      ],
      "title": "UVLM: Benchmarking Video Language Model for Underwater World Understanding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02373",
        "HTML": "https://arxiv.org/html/2507.02373v1",
        "PDF": "https://arxiv.org/pdf/2507.02373"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces UVLM, an underwater video language benchmark, and discusses data selection and diversity, which directly involves constructing and processing data for training video language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02376",
      "abstract": "Vertical Federated Learning (VFL) is a distributed AI software deployment mechanism for cross-silo collaboration without accessing participants' data. However, existing VFL work lacks a mechanism to audit the execution correctness of the inference software of the data party. To address this problem, we design a Vertical Federated Inference Auditing (VeFIA) framework. VeFIA helps the task party to audit whether the data party's inference software is executed as expected during large-scale inference without leaking the data privacy of the data party or introducing additional latency to the inference system. The core of VeFIA is that the task party can use the inference results from a framework with Trusted Execution Environments (TEE) and the coordinator to validate the correctness of the data party's computation results. VeFIA guarantees that, as long as the abnormal inference exceeds 5.4%, the task party can detect execution anomalies in the inference software with a probability of 99.99%, without incurring any additional online inference latency. VeFIA's random sampling validation achieves 100% positive predictive value, negative predictive value, and true positive rate in detecting abnormal inference. To the best of our knowledge, this is the first paper to discuss the correctness of inference software execution in VFL.",
      "authors": [
        "Chung-ju Huang",
        "Ziqi Zhang",
        "Yinggui Wang",
        "Binghui Wang",
        "Tao Wei",
        "Leye Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T07:17:49+00:00",
          "link": "https://arxiv.org/abs/2507.02376v1",
          "size": "349kb",
          "version": "v1"
        }
      ],
      "title": "VeFIA: An Efficient Inference Auditing Framework for Vertical Federated Collaborative Software",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02376",
        "HTML": "https://arxiv.org/html/2507.02376v1",
        "PDF": "https://arxiv.org/pdf/2507.02376"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses inference auditing in vertical federated learning, which is unrelated to the data processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02378",
      "abstract": "Recent advancements in large language models (LLMs) have significantly improved code generation and program comprehension, accelerating the evolution of software engineering. Current methods primarily enhance model performance by leveraging vast amounts of data, focusing on data quantity while often overlooking data quality, thereby reducing training efficiency. To address this, we introduce an approach that utilizes a parametric model for code data selection, aimed at improving both training efficiency and model performance. Our method optimizes the parametric model to ensure distribution consistency and diversity within the selected subset, guaranteeing high-quality data. Experimental results demonstrate that using only 10K samples, our method achieves gains of 2.4% (HumanEval) and 2.3% (MBPP) over 92K full-sampled baseline, outperforming other sampling approaches in both performance and efficiency. This underscores that our method effectively boosts model performance while significantly reducing computational costs.",
      "authors": [
        "Weijie Lyu",
        "Sheng-Jun Huang",
        "Xuan Xia"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T07:19:56+00:00",
          "link": "https://arxiv.org/abs/2507.02378v1",
          "size": "632kb",
          "version": "v1"
        }
      ],
      "title": "Efficient Code LLM Training via Distribution-Consistent and Diversity-Aware Data Selection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02378",
        "HTML": "https://arxiv.org/html/2507.02378v1",
        "PDF": "https://arxiv.org/pdf/2507.02378"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper presents a method for code data selection that focuses on improving LLM training efficiency and model performance by ensuring distribution consistency and diversity, which are critical aspects of data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02379",
      "abstract": "Autonomous scientific research, capable of independently conducting complex experiments and serving non-specialists, represents a long-held aspiration. Achieving it requires a fundamental paradigm shift driven by artificial intelligence (AI). While autonomous experimental systems are emerging, they remain confined to areas featuring singular objectives and well-defined, simple experimental workflows, such as chemical synthesis and catalysis. We present an AI-native autonomous laboratory, targeting highly complex scientific experiments for applications like autonomous biomolecular engineering. This system autonomously manages instrumentation, formulates experiment-specific procedures and optimization heuristics, and concurrently serves multiple user requests. Founded on a co-design philosophy of models, experiments, and instruments, the platform supports the co-evolution of AI models and the automation system. This establishes an end-to-end, multi-user autonomous laboratory that handles complex, multi-objective experiments across diverse instrumentation. Our autonomous laboratory supports fundamental nucleic acid functions-including synthesis, transcription, amplification, and sequencing. It also enables applications in fields such as disease diagnostics, drug development, and information storage. Without human intervention, it autonomously optimizes experimental performance to match state-of-the-art results achieved by human scientists. In multi-user scenarios, the platform significantly improves instrument utilization and experimental efficiency. This platform paves the way for advanced biomaterials research to overcome dependencies on experts and resource barriers, establishing a blueprint for science-as-a-service at scale.",
      "authors": [
        "Mingyu Wu",
        "Zhaoguo Wang",
        "Jiabin Wang",
        "Zhiyuan Dong",
        "Jingkai Yang",
        "Qingting Li",
        "Tianyu Huang",
        "Lei Zhao",
        "Mingqiang Li",
        "Fei Wang",
        "Chunhai Fan",
        "Haibo Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Biomolecules (q-bio.BM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T07:21:19+00:00",
          "link": "https://arxiv.org/abs/2507.02379v1",
          "size": "20763kb",
          "version": "v1"
        }
      ],
      "title": "An AI-native experimental laboratory for autonomous biomolecular engineering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02379",
        "PDF": "https://arxiv.org/pdf/2507.02379"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is focused on the development of an autonomous experimental laboratory for biomolecular engineering and does not discuss any aspect of LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02380",
      "abstract": "JoyTTS is an end-to-end spoken chatbot that combines large language models (LLM) with text-to-speech (TTS) technology, featuring voice cloning capabilities. This project is built upon the open-source MiniCPM-o and CosyVoice2 models and trained on 2000 hours of conversational data. We have also provided the complete training code to facilitate further development and optimization by the community. On the testing machine seed-tts-zh, it achieves a SS (speaker similarity) score of 0.73 and a WER (Word Error Rate) of 5.09. The code and models, along with training and inference scripts, are available at https://github.com/jdh-algo/JoyTTS.git.",
      "authors": [
        "Fangru Zhou",
        "Jun Zhao",
        "Guoxin Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Computation and Language (cs.CL)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T07:22:06+00:00",
          "link": "https://arxiv.org/abs/2507.02380v1",
          "size": "86kb",
          "version": "v1"
        }
      ],
      "title": "JoyTTS: LLM-based Spoken Chatbot With Voice Cloning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02380",
        "HTML": "https://arxiv.org/html/2507.02380v1",
        "PDF": "https://arxiv.org/pdf/2507.02380"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper mentions the use of conversational data for training a spoken chatbot with LLM and voice cloning, but it does not delve into novel methods for data collection or preprocessing specifically for LLM data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02381",
      "abstract": "The running-time analysis of evolutionary combinatorial optimization is a fundamental topic in evolutionary computation. However, theoretical results regarding the $(\\mu+\\lambda)$ evolutionary algorithm (EA) for combinatorial optimization problems remain relatively scarce compared to those for simple pseudo-Boolean problems. This paper proposes a multiple-gain model to analyze the running time of EAs for combinatorial optimization problems. The proposed model is an improved version of the average gain model, which is a fitness-difference drift approach under the sigma-algebra condition to estimate the running time of evolutionary numerical optimization. The improvement yields a framework for estimating the expected first hitting time of a stochastic process in both average-case and worst-case scenarios. It also introduces novel running-time results of evolutionary combinatorial optimization, including two tighter time complexity upper bounds than the known results in the case of ($\\mu+\\lambda$) EA for the knapsack problem with favorably correlated weights, a closed-form expression of time complexity upper bound in the case of ($\\mu+\\lambda$) EA for general $k$-MAX-SAT problems and a tighter time complexity upper bounds than the known results in the case of ($\\mu+\\lambda$) EA for the traveling salesperson problem. Experimental results indicate that the practical running time aligns with the theoretical results, verifying that the multiple-gain model is an effective tool for running-time analysis of ($\\mu+\\lambda$) EA for combinatorial optimization problems.",
      "authors": [
        "Min Huang",
        "Pengxiang Chen",
        "Han Huang",
        "Tongli He",
        "Yushan Zhang",
        "Zhifeng Hao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T07:23:57+00:00",
          "link": "https://arxiv.org/abs/2507.02381v1",
          "size": "1058kb",
          "version": "v1"
        }
      ],
      "title": "Running-time Analysis of ($\\mu+\\lambda$) Evolutionary Combinatorial Optimization Based on Multiple-gain Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02381",
        "HTML": "https://arxiv.org/html/2507.02381v1",
        "PDF": "https://arxiv.org/pdf/2507.02381"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses running-time analysis for evolutionary algorithms in combinatorial optimization, which is unrelated to LLM training data processing or data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02390",
      "abstract": "Log analysis is a relevant research field in cybersecurity as they can provide a source of information for the detection of threats to networks and systems. This paper presents a pipeline to use fine-tuned Large Language Models (LLMs) for anomaly detection and mitigation recommendation using IoT security logs. Utilizing classical machine learning classifiers as a baseline, three open-source LLMs are compared for binary and multiclass anomaly detection, with three strategies: zero-shot, few-shot prompting and fine-tuning using an IoT dataset. LLMs give better results on multi-class attack classification than the corresponding baseline models. By mapping detected threats to MITRE CAPEC, defining a set of IoT-specific mitigation actions, and fine-tuning the models with those actions, the models are able to provide a combined detection and recommendation guidance.",
      "authors": [
        "Jorge J. Tejero-Fern\\'andez",
        "Alfonso S\\'anchez-Maci\\'an"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T07:38:43+00:00",
          "link": "https://arxiv.org/abs/2507.02390v1",
          "size": "567kb",
          "version": "v1"
        }
      ],
      "title": "Evaluating Language Models For Threat Detection in IoT Security Logs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02390",
        "HTML": "https://arxiv.org/html/2507.02390v1",
        "PDF": "https://arxiv.org/pdf/2507.02390"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper outlines a pipeline for using fine-tuned LLMs for threat detection in IoT logs, mentioning fine-tuning, which is part of training-stage data processing, but does not provide innovative techniques related to LLM data engineering or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02391",
      "abstract": "We explore unsupervised speech enhancement using diffusion models as expressive generative priors for clean speech. Existing approaches guide the reverse diffusion process using noisy speech through an approximate, noise-perturbed likelihood score, combined with the unconditional score via a trade-off hyperparameter. In this work, we propose two alternative algorithms that directly model the conditional reverse transition distribution of diffusion states. The first method integrates the diffusion prior with the observation model in a principled way, removing the need for hyperparameter tuning. The second defines a diffusion process over the noisy speech itself, yielding a fully tractable and exact likelihood score. Experiments on the WSJ0-QUT and VoiceBank-DEMAND datasets demonstrate improved enhancement metrics and greater robustness to domain shifts compared to both supervised and unsupervised baselines.",
      "authors": [
        "Mostafa Sadeghi (MULTISPEECH)",
        "Jean-Eudes Ayilo (MULTISPEECH)",
        "Romain Serizel (MULTISPEECH)",
        "Xavier Alameda-Pineda (ROBOTLEARN)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Machine Learning (cs.LG)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T07:42:02+00:00",
          "link": "https://arxiv.org/abs/2507.02391v1",
          "size": "93kb",
          "version": "v1"
        }
      ],
      "title": "Posterior Transition Modeling for Unsupervised Diffusion-Based Speech Enhancement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02391",
        "PDF": "https://arxiv.org/pdf/2507.02391"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is centered on unsupervised diffusion-based speech enhancement and does not involve LLM training data engineering or specialized processing methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02392",
      "abstract": "In this paper, we develop an efficient asymptotic-preserving (AP) Monte Carlo (MC) method for frequency-dependent radiative transfer equations (RTEs), which is based on the AP-MC method proposed for the gray RTEs in \\cite{shi2023efficient}. We follow the characteristics-based approach by Zhang et al. \\cite{zhang2023asymptotic} to get a reformulated model, which couples a low dimension convection-diffusion-type equation for macroscopic quantities with a high dimension transport equation for the radiative intensity.\n  To recover the correct free streaming limit due to frequency-dependency, we propose a correction to the reformulated macroscopic equation.\n  The macroscopic system is solved using a hybrid method:\n  convective fluxes are handled by a particle-based MC method, while diffusive fluxes are treated implicitly with central difference.\n  To address the nonlinear coupling between radiative intensity and the Planck function across multiple frequency groups, we adopt a Picard iteration with a predictor-corrector procedure, which decouples a global nonlinear system into a linear system restricted to spatial dimension (independent of frequency) with scalar algebraic nonlinear equations.\n  Once the macroscopic update is done, the transport equation, with a known emission source provided by the macroscopic variables, is efficiently solved using an implicit MC method. This approach enables larger time steps independent of the speed of light and also the frequency across a wide range, significantly enhancing computational efficiency, especially for frequency-dependent RTEs.\n  Formal AP analysis in the diffusive scaling is established. Numerical experiments are performed to demonstrate the high efficiency and AP property of the proposed method.",
      "authors": [
        "Yiyang Hong",
        "Yi Shi",
        "Yi Cai",
        "Tao Xiong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T07:44:25+00:00",
          "link": "https://arxiv.org/abs/2507.02392v1",
          "size": "707kb",
          "version": "v1"
        }
      ],
      "title": "An efficient asymptotic preserving Monte Carlo method for frequency-dependent radiative transfer equations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02392",
        "HTML": "https://arxiv.org/html/2507.02392v1",
        "PDF": "https://arxiv.org/pdf/2507.02392"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on developing an asymptotic-preserving Monte Carlo method for radiative transfer equations, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02393",
      "abstract": "Monocular 3D object detection (M3OD) has long faced challenges due to data scarcity caused by high annotation costs and inherent 2D-to-3D ambiguity. Although various weakly supervised methods and pseudo-labeling methods have been proposed to address these issues, they are mostly limited by domain-specific learning or rely solely on shape information from a single observation. In this paper, we propose a novel pseudo-labeling framework that uses only video data and is more robust to occlusion, without requiring a multi-view setup, additional sensors, camera poses, or domain-specific training. Specifically, we explore a technique for aggregating the pseudo-LiDARs of both static and dynamic objects across temporally adjacent frames using object point tracking, enabling 3D attribute extraction in scenarios where 3D data acquisition is infeasible. Extensive experiments demonstrate that our method ensures reliable accuracy and strong scalability, making it a practical and effective solution for M3OD.",
      "authors": [
        "Seokyeong Lee",
        "Sithu Aung",
        "Junyong Choi",
        "Seungryong Kim",
        "Ig-Jae Kim",
        "Junghyun Cho"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T07:46:39+00:00",
          "link": "https://arxiv.org/abs/2507.02393v1",
          "size": "38826kb",
          "version": "v1"
        }
      ],
      "title": "PLOT: Pseudo-Labeling via Video Object Tracking for Scalable Monocular 3D Object Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02393",
        "HTML": "https://arxiv.org/html/2507.02393v1",
        "PDF": "https://arxiv.org/pdf/2507.02393"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a pseudo-labeling framework for monocular 3D object detection using video data, which does not pertain to the processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02394",
      "abstract": "This paper studies the adversarial-robustness of importance-sampling (aka sensitivity sampling); a useful algorithmic technique that samples elements with probabilities proportional to some measure of their importance. A streaming or online algorithm is called adversarially-robust if it succeeds with high probability on input streams that may change adaptively depending on previous algorithm outputs. Unfortunately, the dependence between stream elements breaks the analysis of most randomized algorithms, and in particular that of importance-sampling algorithms. Previously, Braverman et al. [NeurIPS 2021] suggested that streaming algorithms based on importance-sampling may be adversarially-robust; however, they proved it only for well-behaved inputs.\n  We focus on the adversarial-robustness of online importance-sampling, a natural variant where sampling decisions are irrevocable and made as data arrives. Our main technical result shows that, given as input an adaptive stream of elements $x_1,\\ldots,x_T\\in \\mathbb{R}_+$, online importance-sampling maintains a $(1\\pm\\epsilon)$-approximation of their sum while matching (up to lower order terms) the storage guarantees of the oblivious (non-adaptive) case. We then apply this result to develop adversarially-robust online algorithms for two fundamental problems: hypergraph cut sparsification and $\\ell_p$ subspace embedding.",
      "authors": [
        "Yotam Kenneth-Mordoch and Shay Sapir"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T07:47:08+00:00",
          "link": "https://arxiv.org/abs/2507.02394v1",
          "size": "25kb",
          "version": "v1"
        }
      ],
      "title": "On the Adversarial Robustness of Online Importance Sampling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02394",
        "HTML": "https://arxiv.org/html/2507.02394v1",
        "PDF": "https://arxiv.org/pdf/2507.02394"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research is centered on the adversarial robustness of online importance sampling, which does not involve any LLM data processing tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02395",
      "abstract": "Multiple instance learning (MIL) significantly reduced annotation costs via bag-level weak labels for large-scale images, such as histopathological whole slide images (WSIs). However, its adaptability to continual tasks with minimal forgetting has been rarely explored, especially on instance classification for localization. Weakly incremental learning for semantic segmentation has been studied for continual localization, but it focused on natural images, leveraging global relationships among hundreds of small patches (e.g., $16 \\times 16$) using pre-trained models. This approach seems infeasible for MIL localization due to enormous amounts ($\\sim 10^5$) of large patches (e.g., $256 \\times 256$) and no available global relationships such as cancer cells. To address these challenges, we propose Continual Multiple Instance Learning with Enhanced Localization (CoMEL), an MIL framework for both localization and adaptability with minimal forgetting. CoMEL consists of (1) Grouped Double Attention Transformer (GDAT) for efficient instance encoding, (2) Bag Prototypes-based Pseudo-Labeling (BPPL) for reliable instance pseudo-labeling, and (3) Orthogonal Weighted Low-Rank Adaptation (OWLoRA) to mitigate forgetting in both bag and instance classification. Extensive experiments on three public WSI datasets demonstrate superior performance of CoMEL, outperforming the prior arts by up to $11.00\\%$ in bag-level accuracy and up to $23.4\\%$ in localization accuracy under the continual MIL setup.",
      "authors": [
        "Byung Hyun Lee",
        "Wongi Jeong",
        "Woojae Han",
        "Kyoungbun Lee",
        "Se Young Chun"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T07:48:37+00:00",
          "link": "https://arxiv.org/abs/2507.02395v1",
          "size": "25293kb",
          "version": "v1"
        }
      ],
      "title": "Continual Multiple Instance Learning with Enhanced Localization for Histopathological Whole Slide Image Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02395",
        "HTML": "https://arxiv.org/html/2507.02395v1",
        "PDF": "https://arxiv.org/pdf/2507.02395"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses multiple instance learning for histopathological image analysis, with no mention of contributing to LLM training data processing aspects."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02398",
      "abstract": "We introduce a deepfake video detection approach that exploits pixel-wise temporal inconsistencies, which traditional spatial frequency-based detectors often overlook. Traditional detectors represent temporal information merely by stacking spatial frequency spectra across frames, resulting in the failure to detect temporal artifacts in the pixel plane. Our approach performs a 1D Fourier transform on the time axis for each pixel, extracting features highly sensitive to temporal inconsistencies, especially in areas prone to unnatural movements. To precisely locate regions containing the temporal artifacts, we introduce an attention proposal module trained in an end-to-end manner. Additionally, our joint transformer module effectively integrates pixel-wise temporal frequency features with spatio-temporal context features, expanding the range of detectable forgery artifacts. Our framework represents a significant advancement in deepfake video detection, providing robust performance across diverse and challenging detection scenarios.",
      "authors": [
        "Taehoon Kim",
        "Jongwook Choi",
        "Yonghyun Jeong",
        "Haeun Noh",
        "Jaejun Yoo",
        "Seungryul Baek",
        "Jongwon Choi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T07:49:55+00:00",
          "link": "https://arxiv.org/abs/2507.02398v1",
          "size": "1359kb",
          "version": "v1"
        }
      ],
      "title": "Beyond Spatial Frequency: Pixel-wise Temporal Frequency-based Deepfake Video Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02398",
        "HTML": "https://arxiv.org/html/2507.02398v1",
        "PDF": "https://arxiv.org/pdf/2507.02398"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study presents a deepfake video detection approach focusing on pixel-wise temporal inconsistencies, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02399",
      "abstract": "Background and objective: Medical image segmentation is a core task in various clinical applications. However, acquiring large-scale, fully annotated medical image datasets is both time-consuming and costly. Scribble annotations, as a form of sparse labeling, provide an efficient and cost-effective alternative for medical image segmentation. However, the sparsity of scribble annotations limits the feature learning of the target region and lacks sufficient boundary supervision, which poses significant challenges for training segmentation networks. Methods: We propose TAB Net, a novel weakly-supervised medical image segmentation framework, consisting of two key components: the triplet augmentation self-recovery (TAS) module and the boundary-aware pseudo-label supervision (BAP) module. The TAS module enhances feature learning through three complementary augmentation strategies: intensity transformation improves the model's sensitivity to texture and contrast variations, cutout forces the network to capture local anatomical structures by masking key regions, and jigsaw augmentation strengthens the modeling of global anatomical layout by disrupting spatial continuity. By guiding the network to recover complete masks from diverse augmented inputs, TAS promotes a deeper semantic understanding of medical images under sparse supervision. The BAP module enhances pseudo-supervision accuracy and boundary modeling by fusing dual-branch predictions into a loss-weighted pseudo-label and introducing a boundary-aware loss for fine-grained contour refinement. Results: Experimental evaluations on two public datasets, ACDC and MSCMR seg, demonstrate that TAB Net significantly outperforms state-of-the-art methods for scribble-based weakly supervised segmentation. Moreover, it achieves performance comparable to that of fully supervised methods.",
      "authors": [
        "Peilin Zhang",
        "Shaouxan Wua",
        "Jun Feng",
        "Zhuo Jin",
        "Zhizezhang Gao",
        "Jingkun Chen",
        "Yaqiong Xing",
        "Xiao Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T07:50:00+00:00",
          "link": "https://arxiv.org/abs/2507.02399v1",
          "size": "1624kb",
          "version": "v1"
        }
      ],
      "title": "TABNet: A Triplet Augmentation Self-Recovery Framework with Boundary-Aware Pseudo-Labels for Medical Image Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02399",
        "PDF": "https://arxiv.org/pdf/2507.02399"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on weakly-supervised medical image segmentation and introduces a framework to improve segmentation under sparse supervision. It does not discuss any processes or methodologies related to LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02400",
      "abstract": "In the future, mobility will be strongly shaped by the increasing use of digitalization. Not only will individual road users be highly interconnected, but also the road and associated infrastructure. At that point, a Digital Twin becomes particularly appealing because, unlike a basic simulation, it offers a continuous, bilateral connection linking the real and virtual environments. This paper describes the digital reconstruction used to develop the Digital Twin of the Test Area Autonomous Driving-Baden-W\\\"urttemberg (TAF-BW), Germany. The TAF-BW offers a variety of different road sections, from high-traffic urban intersections and tunnels to multilane motorways. The test area is equipped with a comprehensive Vehicle-to-Everything (V2X) communication infrastructure and multiple intelligent intersections equipped with camera sensors to facilitate real-time traffic flow monitoring. The generation of authentic data as input for the Digital Twin was achieved by extracting object lists at the intersections. This process was facilitated by the combined utilization of camera images from the intelligent infrastructure and LiDAR sensors mounted on a test vehicle. Using a unified interface, recordings from real-world detections of traffic participants can be resimulated. Additionally, the simulation framework's design and the reconstruction process is discussed. The resulting framework is made publicly available for download and utilization at: https://digit4taf-bw.fzi.de The demonstration uses two case studies to illustrate the application of the digital twin and its interfaces: the analysis of traffic signal systems to optimize traffic flow and the simulation of security-related scenarios in the communications sector.",
      "authors": [
        "Maximilian Zipfl",
        "Pascal Zwick",
        "Patrick Schulz",
        "Marc Rene Zofka",
        "Albert Schotschneider",
        "Helen Gremmelmaier",
        "Nikolai Polley",
        "Ferdinand M\\\"utsch",
        "Kevin Simon",
        "Fabian Gottselig",
        "Michael Frey",
        "Sergio Marschall",
        "Akim Stark",
        "Maximilian M\\\"uller",
        "Marek Wehmer",
        "Mihai Kocsis",
        "Dominic Waldenmayer",
        "Florian Schnepf",
        "Erik Heinrich",
        "Sabrina Pletz",
        "Matthias K\\\"olle",
        "Karin Langbein-Euchner",
        "Alexander Viehl",
        "Raoul Z\\\"ollner",
        "and J. Marius Z\\\"ollner"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T07:53:26+00:00",
          "link": "https://arxiv.org/abs/2507.02400v1",
          "size": "10097kb",
          "version": "v1"
        }
      ],
      "title": "DigiT4TAF -- Bridging Physical and Digital Worlds for Future Transportation Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02400",
        "HTML": "https://arxiv.org/html/2507.02400v1",
        "PDF": "https://arxiv.org/pdf/2507.02400"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper details the development of a Digital Twin for future transportation systems and does not address the processing of training data for LLMs in any capacity."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02401",
      "abstract": "In photoacoustic tomography (PAT), the computation of the initial pressure distribution within an object from its time-dependent boundary measurements over time is considered. This problem can be approached from two well-established points of view: deterministically using regularisation methods, or stochastically using the Bayesian framework. Both approaches frequently require the solution of a variational problem. In the paper we elaborate the connection between these approaches by establishing the equivalence between a smoothing Mat{\\'e}rn class of covariance operators and Sobolev embedding operator $E_s: H^s \\hookrightarrow L^2$. We further discuss the use of a Wavelet-based implementation of the adjoint operator $E_s^*$ which also allows for efficient evaluations for certain Mat{\\'e}rn covariance operators, leading to efficient implementations both in terms of computational effort as well as memory requirements. The proposed methods are validated with reconstructions for the photoacoustic problem.",
      "authors": [
        "Jaakko Kultima",
        "Ronny Ramlau",
        "Teemu Sahlstr\\\"om",
        "Tanja Tarvainen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Mathematical Physics (math-ph)",
        "Mathematical Physics (math.MP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T07:55:15+00:00",
          "link": "https://arxiv.org/abs/2507.02401v1",
          "size": "1016kb",
          "version": "v1"
        }
      ],
      "title": "Fast reconstruction approaches for photoacoustic tomography with smoothing Sobolev/Mat\\'ern priors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02401",
        "HTML": "https://arxiv.org/html/2507.02401v1",
        "PDF": "https://arxiv.org/pdf/2507.02401"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is centered around photoacoustic tomography and proposes computational methods for image reconstruction. It is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02402",
      "abstract": "In this work, we propose, analyze, and test a novel computational low-complexity, linear, second-order, and unconditional energy-stable semi-discrete time-stepping scheme for the Cahn-Hilliard-Navier-Stokes (CHNS) system by employing the time filter technique. Firstly, the first-order semi-implicit backward Euler (BE) method is utilized to discretize the CHNS model; Secondly, the time filter, as a post-processing strategy, is incorporated into the BE scheme, requiring only minimal modifications to the existing BE framework to improve its temporal accuracy from first- to second-order. The unconditional energy stability and second-order temporal error estimations are obtained, and several numerical experiments are conducted to verify the theoretical results.",
      "authors": [
        "Xi Li",
        "Haijun Gao",
        "Chunmei Xie",
        "and Minfu Feng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T07:55:53+00:00",
          "link": "https://arxiv.org/abs/2507.02402v1",
          "size": "3722kb",
          "version": "v1"
        }
      ],
      "title": "A second-order and unconditionally stable time filtered scheme for the Cahn-Hilliard-Navier-Stokes system",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02402",
        "HTML": "https://arxiv.org/html/2507.02402v1",
        "PDF": "https://arxiv.org/pdf/2507.02402"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research proposes a time-stepping scheme for the Cahn-Hilliard-Navier-Stokes system. It does not pertain to the collection, processing, or engineering of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02403",
      "abstract": "Wildlife re-identification aims to match individuals of the same species across different observations. Current state-of-the-art (SOTA) models rely on class labels to train supervised models for individual classification. This dependence on annotated data has driven the curation of numerous large-scale wildlife datasets. This study investigates self-supervised learning Self-Supervised Learning (SSL) for wildlife re-identification. We automatically extract two distinct views of an individual using temporal image pairs from camera trap data without supervision. The image pairs train a self-supervised model from a potentially endless stream of video data. We evaluate the learnt representations against supervised features on open-world scenarios and transfer learning in various wildlife downstream tasks. The analysis of the experimental results shows that self-supervised models are more robust even with limited data. Moreover, self-supervised features outperform supervision across all downstream tasks. The code is available here https://github.com/pxpana/SSLWildlife.",
      "authors": [
        "Mufhumudzi Muthivhi",
        "Terence L. van Zyl"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T07:56:54+00:00",
          "link": "https://arxiv.org/abs/2507.02403v1",
          "size": "9365kb",
          "version": "v1"
        }
      ],
      "title": "Wildlife Target Re-Identification Using Self-supervised Learning in Non-Urban Settings",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02403",
        "HTML": "https://arxiv.org/html/2507.02403v1",
        "PDF": "https://arxiv.org/pdf/2507.02403"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study explores self-supervised learning for wildlife re-identification. It does not involve any discussion or advancements related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02404",
      "abstract": "The Swiss National Supercomputing Centre (CSCS) has a long-standing tradition of delivering top-tier high-performance computing systems, exemplified by the Piz Daint supercomputer. However, the increasing diversity of scientific needs has exposed limitations in traditional vertically integrated HPC architectures, which often lack flexibility and composability. To address these challenges, CSCS developed Alps, a next-generation HPC infrastructure designed with a transformative principle: resources operate as independent endpoints within a high-speed network. This architecture enables the creation of independent tenant-specific and platform-specific services, tailored to diverse scientific requirements.\n  Alps incorporates heterogeneous hardware, including CPUs and GPUs, interconnected by a high-performance Slingshot network, and offers a modular storage system. A key innovation is the versatile software-defined cluster (vCluster) technology, which bridges cloud and HPC paradigms. By abstracting infrastructure, service management, and user environments into distinct layers, vClusters allow for customized platforms that support diverse workloads. Current platforms on Alps serve various scientific domains, including numerical weather prediction, and AI research.",
      "authors": [
        "Maxime Martinasso",
        "Mark Klein",
        "Thomas C. Schulthess"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T07:58:39+00:00",
          "link": "https://arxiv.org/abs/2507.02404v1",
          "size": "3707kb",
          "version": "v1"
        }
      ],
      "title": "Alps, a versatile research infrastructure",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02404",
        "HTML": "https://arxiv.org/html/2507.02404v1",
        "PDF": "https://arxiv.org/pdf/2507.02404"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes the Alps HPC infrastructure and its architecture for scientific computing, without mentioning any aspect of LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02405",
      "abstract": "Denoising diffusion models produce high-fidelity image samples by capturing the image distribution in a progressive manner while initializing with a simple distribution and compounding the distribution complexity. Although these models have unlocked new applicabilities, the sampling mechanism of diffusion does not offer means to extract image-specific semantic representation, which is inherently provided by auto-encoders. The encoding component of auto-encoders enables mapping between a specific image and its latent space, thereby offering explicit means of enforcing structures in the latent space. By integrating an encoder with the diffusion model, we establish an auto-encoding formulation, which learns image-specific representations and offers means to organize the latent space. In this work, First, we devise a mechanism to structure the latent space of a diffusion auto-encoding model, towards recognizing region-specific cellular patterns in brain images. We enforce the representations to regress positional information of the patches from high-resolution images. This creates a conducive latent space for differentiating tissue types of the brain. Second, we devise an unsupervised tear artifact restoration technique based on neighborhood awareness, utilizing latent representations and the constrained generation capability of diffusion models during inference. Third, through representational guidance and leveraging the inference time steerable noising and denoising capability of diffusion, we devise an unsupervised JPEG artifact restoration technique.",
      "authors": [
        "Ayantika Das",
        "Moitreya Chaudhuri",
        "Koushik Bhat",
        "Keerthi Ram",
        "Mihail Bota",
        "Mohanasankar Sivaprakasam"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T07:58:53+00:00",
          "link": "https://arxiv.org/abs/2507.02405v1",
          "size": "25875kb",
          "version": "v1"
        }
      ],
      "title": "PosDiffAE: Position-aware Diffusion Auto-encoder For High-Resolution Brain Tissue Classification Incorporating Artifact Restoration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02405",
        "HTML": "https://arxiv.org/html/2507.02405v1",
        "PDF": "https://arxiv.org/pdf/2507.02405"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a diffusion auto-encoder model for brain tissue classification and artifact restoration. It does not address LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02406",
      "abstract": "Trajectory prediction is an essential step in the pipeline of an autonomous vehicle. Inaccurate or inconsistent predictions regarding the movement of agents in its surroundings lead to poorly planned maneuvers and potentially dangerous situations for the end-user. Current state-of-the-art deep-learning-based trajectory prediction models can achieve excellent accuracy on public datasets. However, when used in more complex, interactive scenarios, they often fail to capture important interdependencies between agents, leading to inconsistent predictions among agents in the traffic scene. Inspired by the efficacy of incorporating human preference into large language models, this work fine-tunes trajectory prediction models in multi-agent settings using preference optimization. By taking as input automatically calculated preference rankings among predicted futures in the fine-tuning process, our experiments--using state-of-the-art models on three separate datasets--show that we are able to significantly improve scene consistency while minimally sacrificing trajectory prediction accuracy and without adding any excess computational requirements at inference time.",
      "authors": [
        "Caio Azevedo",
        "Lina Achaji",
        "Stefano Sabatini",
        "Nicola Poerio",
        "Grzegorz Bartyzel",
        "Sascha Hornauer",
        "Fabien Moutarde"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T07:59:49+00:00",
          "link": "https://arxiv.org/abs/2507.02406v1",
          "size": "1631kb",
          "version": "v1"
        }
      ],
      "title": "Improving Consistency in Vehicle Trajectory Prediction Through Preference Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02406",
        "HTML": "https://arxiv.org/html/2507.02406v1",
        "PDF": "https://arxiv.org/pdf/2507.02406"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper mentions the fine-tuning of trajectory prediction models using preference optimization in a multi-agent setting, which relates to the training stage data processing. However, its primary focus is not on LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02407",
      "abstract": "Most existing automatic speech recognition (ASR) research evaluate models using in-domain datasets. However, they seldom evaluate how they generalize across diverse speech contexts. This study addresses this gap by benchmarking seven Akan ASR models built on transformer architectures, such as Whisper and Wav2Vec2, using four Akan speech corpora to determine their performance. These datasets encompass various domains, including culturally relevant image descriptions, informal conversations, biblical scripture readings, and spontaneous financial dialogues. A comparison of the word error rate and character error rate highlighted domain dependency, with models performing optimally only within their training domains while showing marked accuracy degradation in mismatched scenarios. This study also identified distinct error behaviors between the Whisper and Wav2Vec2 architectures. Whereas fine-tuned Whisper Akan models led to more fluent but potentially misleading transcription errors, Wav2Vec2 produced more obvious yet less interpretable outputs when encountering unfamiliar inputs. This trade-off between readability and transparency in ASR errors should be considered when selecting architectures for low-resource language (LRL) applications. These findings highlight the need for targeted domain adaptation techniques, adaptive routing strategies, and multilingual training frameworks for Akan and other LRLs.",
      "authors": [
        "Mark Atta Mensah",
        "Isaac Wiafe",
        "Akon Ekpezu",
        "Justice Kwame Appati",
        "Jamal-Deen Abdulai",
        "Akosua Nyarkoa Wiafe-Akenten",
        "Frank Ernest Yeboah",
        "Gifty Odame"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T08:01:26+00:00",
          "link": "https://arxiv.org/abs/2507.02407v1",
          "size": "302kb",
          "version": "v1"
        }
      ],
      "title": "Benchmarking Akan ASR Models Across Domain-Specific Datasets: A Comparative Evaluation of Performance, Scalability, and Adaptability",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02407",
        "PDF": "https://arxiv.org/pdf/2507.02407"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper provides insights into evaluating ASR models across various datasets but does not propose new methods for LLM training data. It briefly touches on domain adaptation, which can be part of data processing discussions."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02408",
      "abstract": "Multi-Object Tracking in thermal images is essential for surveillance systems, particularly in challenging environments where RGB cameras struggle due to low visibility or poor lighting conditions. Thermal sensors enhance recognition tasks by capturing infrared signatures, but a major challenge is their low-level feature representation, which makes it difficult to accurately detect and track pedestrians. To address this, the paper introduces a novel tuning method for pedestrian tracking, specifically designed to handle the complex motion patterns in thermal imagery. The proposed framework optimizes two-stages, ensuring that each stage is tuned with the most suitable hyperparameters to maximize tracking performance. By fine-tuning hyperparameters for real-time tracking, the method achieves high accuracy without relying on complex reidentification or motion models. Extensive experiments on PBVS Thermal MOT dataset demonstrate that the approach is highly effective across various thermal camera conditions, making it a robust solution for real-world surveillance applications.",
      "authors": [
        "Duong Nguyen-Ngoc Tran",
        "Long Hoang Pham",
        "Chi Dai Tran",
        "Quoc Pham-Nam Ho",
        "Huy-Hung Nguyen",
        "Jae Wook Jeon"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T08:03:35+00:00",
          "link": "https://arxiv.org/abs/2507.02408v1",
          "size": "13683kb",
          "version": "v1"
        }
      ],
      "title": "A Novel Tuning Method for Real-time Multiple-Object Tracking Utilizing Thermal Sensor with Complexity Motion Pattern",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02408",
        "HTML": "https://arxiv.org/html/2507.02408v1",
        "PDF": "https://arxiv.org/pdf/2507.02408"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with tuning methods for multiple-object tracking in thermal images, which is unrelated to any aspect of LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02409",
      "abstract": "Federated Graph Learning (FGL) combines the privacy-preserving capabilities of federated learning (FL) with the strong graph modeling capability of Graph Neural Networks (GNNs). Current research addresses subgraph-FL only from the structural perspective, neglecting the propagation of graph signals on spatial and spectral domains of the structure. From a spatial perspective, subgraph-FL introduces edge disconnections between clients, leading to disruptions in label signals and a degradation in the class knowledge of the global GNN. From a spectral perspective, spectral heterogeneity causes inconsistencies in signal frequencies across subgraphs, which makes local GNNs overfit the local signal propagation schemes. As a result, spectral client drifts occur, undermining global generalizability. To tackle the challenges, we propose a global knowledge repository to mitigate label signal disruption and a frequency alignment to address spectral client drifts. The combination of spatial and spectral strategies forms our framework S2FGL. Extensive experiments on multiple datasets demonstrate the superiority of S2FGL. The code is available at https://github.com/Wonder7racer/S2FGL.git.",
      "authors": [
        "Zihan Tan",
        "Suyuan Huang",
        "Guancheng Wan",
        "Wenke Huang",
        "He Li and Mang Ye"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T08:04:49+00:00",
          "link": "https://arxiv.org/abs/2507.02409v1",
          "size": "2570kb",
          "version": "v1"
        }
      ],
      "title": "S2FGL: Spatial Spectral Federated Graph Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02409",
        "HTML": "https://arxiv.org/html/2507.02409v1",
        "PDF": "https://arxiv.org/pdf/2507.02409"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on Federated Graph Learning (FGL) and improving graph signal propagation, which does not relate to LLM training data processing or data engineering stages."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02413",
      "abstract": "Immutability is a core design goal of permissionless public blockchain systems. However, rewrites are more common than is normally understood, and the risk of rewrite, cyberattack, exploit or black swan event is also high. Taking the position that strict immutability is neither possible on these networks nor the observed reality, this paper uses thematic analysis of node operator interviews to examine the limits of immutability in light of rewrite events. The end result is a qualitative definition of the conditional immutability found on these networks, which we call Practical Immutability. This is immutability contingent on the legitimate governance demands of the network, where network stakeholders place their trust in the governance topology of a network to lend it legitimacy, and thus manage ledger state.",
      "authors": [
        "Alex Lynham and Geoff Goodell"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T08:14:33+00:00",
          "link": "https://arxiv.org/abs/2507.02413v1",
          "size": "58kb",
          "version": "v1"
        }
      ],
      "title": "Defining DLT Immutability: A Qualitative Survey of Node Operators",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02413",
        "HTML": "https://arxiv.org/html/2507.02413v1",
        "PDF": "https://arxiv.org/pdf/2507.02413"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "While it provides a qualitative survey of blockchain immutability, this paper does not address LLM training data or relevant data processing methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02414",
      "abstract": "Face identification systems operating in the ciphertext domain have garnered significant attention due to increasing privacy concerns and the potential recovery of original facial data. However, as the size of ciphertext template libraries grows, the face retrieval process becomes progressively more time-intensive. To address this challenge, we propose a novel and efficient scheme for face retrieval in the ciphertext domain, termed Privacy-Preserving Preselection for Face Identification Based on Packing (PFIP). PFIP incorporates an innovative preselection mechanism to reduce computational overhead and a packing module to enhance the flexibility of biometric systems during the enrollment stage. Extensive experiments conducted on the LFW and CASIA datasets demonstrate that PFIP preserves the accuracy of the original face recognition model, achieving a 100% hit rate while retrieving 1,000 ciphertext face templates within 300 milliseconds. Compared to existing approaches, PFIP achieves a nearly 50x improvement in retrieval efficiency.",
      "authors": [
        "Rundong Xin",
        "Taotao Wang",
        "Jin Wang",
        "Chonghe Zhao",
        "Jing Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T08:15:07+00:00",
          "link": "https://arxiv.org/abs/2507.02414v1",
          "size": "437kb",
          "version": "v1"
        }
      ],
      "title": "Privacy-preserving Preselection for Face Identification Based on Packing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02414",
        "HTML": "https://arxiv.org/html/2507.02414v1",
        "PDF": "https://arxiv.org/pdf/2507.02414"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a method for efficient face identification in encrypted domains, unrelated to LLM training data processing or data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02416",
      "abstract": "Structural crack detection is a critical task for public safety as it helps in preventing potential structural failures that could endanger lives. Manual detection by inexperienced personnel can be slow, inconsistent, and prone to human error, which may compromise the reliability of assessments. The current study addresses these challenges by introducing a novel deep-learning architecture designed to enhance the accuracy and efficiency of structural crack detection. In this research, various configurations of residual U-Net models were utilized. These models, due to their robustness in capturing fine details, were further integrated into an ensemble with a meta-model comprising convolutional blocks. This unique combination aimed to boost prediction efficiency beyond what individual models could achieve. The ensemble's performance was evaluated against well-established architectures such as SegNet and the traditional U-Net. Results demonstrated that the residual U-Net models outperformed their predecessors, particularly with low-resolution imagery, and the ensemble model exceeded the performance of individual models, proving it as the most effective. The assessment was based on the Intersection over Union (IoU) metric and DICE coefficient. The ensemble model achieved the highest scores, signifying superior accuracy. This advancement suggests way for more reliable automated systems in structural defects monitoring tasks.",
      "authors": [
        "Subhasis Dasgupta",
        "Jaydip Sen",
        "Tuhina Halder"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T08:24:47+00:00",
          "link": "https://arxiv.org/abs/2507.02416v1",
          "size": "763kb",
          "version": "v1"
        }
      ],
      "title": "Determination Of Structural Cracks Using Deep Learning Frameworks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02416",
        "PDF": "https://arxiv.org/pdf/2507.02416"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on deep learning frameworks for structural crack detection, which is unrelated to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02419",
      "abstract": "Similar to facial beautification in real life, 3D virtual avatars require personalized customization to enhance their visual appeal, yet this area remains insufficiently explored. Although current 3D Gaussian editing methods can be adapted for facial makeup purposes, these methods fail to meet the fundamental requirements for achieving realistic makeup effects: 1) ensuring a consistent appearance during drivable expressions, 2) preserving the identity throughout the makeup process, and 3) enabling precise control over fine details. To address these, we propose a specialized 3D makeup method named AvatarMakeup, leveraging a pretrained diffusion model to transfer makeup patterns from a single reference photo of any individual. We adopt a coarse-to-fine idea to first maintain the consistent appearance and identity, and then to refine the details. In particular, the diffusion model is employed to generate makeup images as supervision. Due to the uncertainties in diffusion process, the generated images are inconsistent across different viewpoints and expressions. Therefore, we propose a Coherent Duplication method to coarsely apply makeup to the target while ensuring consistency across dynamic and multiview effects. Coherent Duplication optimizes a global UV map by recoding the averaged facial attributes among the generated makeup images. By querying the global UV map, it easily synthesizes coherent makeup guidance from arbitrary views and expressions to optimize the target avatar. Given the coarse makeup avatar, we further enhance the makeup by incorporating a Refinement Module into the diffusion model to achieve high makeup quality. Experiments demonstrate that AvatarMakeup achieves state-of-the-art makeup transfer quality and consistency throughout animation.",
      "authors": [
        "Yiming Zhong",
        "Xiaolin Zhang",
        "Ligang Liu",
        "Yao Zhao",
        "and Yunchao Wei"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T08:26:57+00:00",
          "link": "https://arxiv.org/abs/2507.02419v1",
          "size": "4440kb",
          "version": "v1"
        }
      ],
      "title": "AvatarMakeup: Realistic Makeup Transfer for 3D Animatable Head Avatars",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02419",
        "HTML": "https://arxiv.org/html/2507.02419v1",
        "PDF": "https://arxiv.org/pdf/2507.02419"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research discusses makeup transfer for 3D avatars using a pretrained diffusion model, which does not involve LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02424",
      "abstract": "Intrusion Detection and Prevention Systems (IDS/IPS) in large enterprises can generate hundreds of thousands of alerts per hour, overwhelming security analysts with logs that demand deep, rapidly evolving domain expertise. Conventional machine-learning detectors trim the alert volume but still yield high false-positive rates, while standard single-pass Retrieval-Augmented Generation (RAG) pipelines often retrieve irrelevant context and fail to justify their predictions. To overcome these shortcomings, we present CyberRAG, a modular, agent-based RAG framework that delivers real-time classification, explanation, and structured reporting for cyber-attacks. A central LLM agent orchestrates (i) a pool of fine-tuned specialized classifiers, each tailored to a distinct attack family; (ii) tool adapters for enrichment and alerting; and (iii) an iterative retrieval-and-reason loop that continuously queries a domain-specific knowledge base until the evidence is both relevant and self-consistent. Unlike traditional RAG systems, CyberRAG embraces an agentic design that enables dynamic control flow and adaptive reasoning. This agent-centric architecture refines its threat labels and natural-language justifications autonomously, reducing false positives and enhancing interpretability. The framework is fully extensible: new attack types can be supported by simply adding a classifier without retraining the core agent. CyberRAG has been evaluated achieving over 94% accuracy per class and pushing final classification accuracy to 94.92% through semantic orchestration. Generated explanations score up to 0.94 in BERTScore and 4.9/5 in GPT-4-based expert evaluation. These results show that agentic, specialist-oriented RAG can pair high detection accuracy with trustworthy, SOC-ready prose, offering a practical and scalable path toward semi-autonomous cyber-defence workflows.",
      "authors": [
        "Francesco Blefari",
        "Cristian Cosentino",
        "Francesco Aurelio Pironti",
        "Angelo Furfaro",
        "Fabrizio Marozzo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T08:32:19+00:00",
          "link": "https://arxiv.org/abs/2507.02424v1",
          "size": "473kb",
          "version": "v1"
        }
      ],
      "title": "CyberRAG: An agentic RAG cyber attack classification and reporting tool",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02424",
        "HTML": "https://arxiv.org/html/2507.02424v1",
        "PDF": "https://arxiv.org/pdf/2507.02424"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study introduces CyberRAG, a real-time cyber attack classification and reporting tool using LLMs but does not address LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02428",
      "abstract": "This study presents an approach for collecting speech samples to build Automatic Speech Recognition (ASR) models for impaired speech, particularly, low-resource languages. It aims to democratize ASR technology and data collection by developing a \"cookbook\" of best practices and training for community-driven data collection and ASR model building. As a proof-of-concept, this study curated the first open-source dataset of impaired speech in Akan: a widely spoken indigenous language in Ghana. The study involved participants from diverse backgrounds with speech impairments. The resulting dataset, along with the cookbook and open-source tools, are publicly available to enable researchers and practitioners to create inclusive ASR technologies tailored to the unique needs of speech impaired individuals. In addition, this study presents the initial results of fine-tuning open-source ASR models to better recognize impaired speech in Akan.",
      "authors": [
        "Sumaya Ahmed Salihs",
        "Isaac Wiafe",
        "Jamal-Deen Abdulai",
        "Elikem Doe Atsakpo",
        "Gifty Ayoka",
        "Richard Cave",
        "Akon Obu Ekpezu",
        "Catherine Holloway",
        "Katrin Tomanek",
        "Fiifi Baffoe Payin Winful"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T08:34:15+00:00",
          "link": "https://arxiv.org/abs/2507.02428v1",
          "size": "314kb",
          "version": "v1"
        }
      ],
      "title": "A Cookbook for Community-driven Data Collection of Impaired Speech in LowResource Languages",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02428",
        "PDF": "https://arxiv.org/pdf/2507.02428"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The study presents a community-driven approach to collect data for impaired speech in low-resource languages and discusses data preparation for fine-tuning models, which directly relates to LLM training data processing and engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02430",
      "abstract": "In autonomous driving, recent research has increasingly focused on collaborative perception based on deep learning to overcome the limitations of individual perception systems. Although these methods achieve high accuracy, they rely on high communication bandwidth and require unrestricted access to each agent's object detection model architecture and parameters. These constraints pose challenges real-world autonomous driving scenarios, where communication limitations and the need to safeguard proprietary models hinder practical implementation.  To address this issue, we introduce a novel late collaborative framework for 3D multi-source and multi-object fusion, which operates solely on shared 3D bounding box attributes-category, size, position, and orientation-without necessitating direct access to detection models.  Our framework establishes a new state-of-the-art in late fusion, achieving up to five times lower position error compared to existing methods. Additionally, it reduces scale error by a factor of 7.5 and orientation error by half, all while maintaining perfect 100% precision and recall when fusing detections from heterogeneous perception systems. These results highlight the effectiveness of our approach in addressing real-world collaborative perception challenges, setting a new benchmark for efficient and scalable multi-agent fusion.",
      "authors": [
        "Maryem Fadili (VeDeCom",
        "IRSEEM)",
        "Mohamed Anis Ghaoui (VeDeCom)",
        "Louis Lecrosnier (IRSEEM",
        "ESIGELEC)",
        "Steve Pechberti (VeDeCom)",
        "Redouane Khemmar (IRSEEM",
        "ESIGELEC",
        "IRSEEM)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Image and Video Processing (eess.IV)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T08:36:28+00:00",
          "link": "https://arxiv.org/abs/2507.02430v1",
          "size": "1033kb",
          "version": "v1"
        }
      ],
      "title": "A Late Collaborative Perception Framework for 3D Multi-Object and Multi-Source Association and Fusion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02430",
        "PDF": "https://arxiv.org/pdf/2507.02430"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a collaborative perception framework for autonomous driving, focusing on object detection and fusion, without mentioning LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02432",
      "abstract": "We investigate the use of musically structured, closed-loop vibration patterns as a passive biofeedback intervention for relaxation and sleep initiation. By encoding rhythmic meter structures into smartwatch vibrations and adapting their frequency to be slightly slower than the user's real-time heart rate, our system aims to reduce arousal through tactile entrainment, offering a non-invasive alternative to auditory or open-loop approaches previously used in sleep and anxiety contexts. In the first study (N=20), we compared five adaptive vibration rhythms for their effects on heart rate and subjective perceptions of relaxation in a resting context. In the second study (N=28), we evaluated the most promising pattern from Study 1 in a prolonged sleep initiation setting. Results showed increased parasympathetic activity and perceived relaxation during short-term stimulation, but no significant effects on sleep-related measures during the sleep onset phase. This work contributes to the understanding of how wearable haptic feedback can support relaxation and sleep, offering design insights and identifying methodological considerations for effectively integrating haptic interaction into self-directed interventions.",
      "authors": [
        "Jueun Lee",
        "Dennis Moschina",
        "Supraja Ramesh",
        "Tobias R\\\"oddiger",
        "Kai Kunze",
        "Michael Beigl"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T08:40:27+00:00",
          "link": "https://arxiv.org/abs/2507.02432v1",
          "size": "952kb",
          "version": "v1"
        }
      ],
      "title": "Closed-Loop Rhythmic Haptic Biofeedback via Smartwatch for Relaxation and Sleep Onset",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02432",
        "HTML": "https://arxiv.org/html/2507.02432v1",
        "PDF": "https://arxiv.org/pdf/2507.02432"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is focused on using vibrational feedback for relaxation and sleep improvement using smartwatches. It does not discuss any aspect of LLM training data processing or methods related to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02433",
      "abstract": "We present a randomized linear-space solver for general linear systems $\\mathbf{A} \\mathbf{x} = \\mathbf{b}$ with $\\mathbf{A} \\in \\mathbb{Z}^{n \\times n}$ and $\\mathbf{b} \\in \\mathbb{Z}^n$, without any assumption on the condition number of $\\mathbf{A}$. For matrices whose entries are bounded by $\\mathrm{poly}(n)$, the solver returns a $(1+\\epsilon)$-multiplicative entry-wise approximation to vector $\\mathbf{x} \\in \\mathbb{Q}^{n}$ using $\\widetilde{O}(n^2 \\cdot \\mathrm{nnz}(\\mathbf{A}))$ bit operations and $O(n \\log n)$ bits of working space (i.e., linear in the size of a vector), where $\\mathrm{nnz}$ denotes the number of nonzero entries. Our solver works for right-hand vector $\\mathbf{b}$ with entries up to $n^{O(n)}$. To our knowledge, this is the first linear-space linear system solver over the rationals that runs in $\\widetilde{O}(n^2 \\cdot \\mathrm{nnz}(\\mathbf{A}))$ time.\n  We also present several applications of our solver to numerical linear algebra problems, for which we provide algorithms with efficient polynomial running time and near-linear space. In particular, we present results for linear regression, linear programming, eigenvalues and eigenvectors, and singular value decomposition.",
      "authors": [
        "Yiping Liu",
        "Hoai-An Nguyen",
        "Junzhao Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T08:40:43+00:00",
          "link": "https://arxiv.org/abs/2507.02433v1",
          "size": "60kb",
          "version": "v1"
        }
      ],
      "title": "Numerical Linear Algebra in Linear Space",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02433",
        "HTML": "https://arxiv.org/html/2507.02433v1",
        "PDF": "https://arxiv.org/pdf/2507.02433"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a randomized solver for linear systems, which is primarily related to numerical linear algebra. It does not address any aspects of data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02437",
      "abstract": "Test-Time Adaptation (TTA) has emerged as a promising solution for adapting a source model to unseen medical sites using unlabeled test data, due to the high cost of data annotation. Existing TTA methods consider scenarios where data from one or multiple domains arrives in complete domain units. However, in clinical practice, data usually arrives in domain fragments of arbitrary lengths and in random arrival orders, due to resource constraints and patient variability. This paper investigates a practical Free-Form Test-Time Adaptation (F$^{2}$TTA) task, where a source model is adapted to such free-form domain fragments, with shifts occurring between fragments unpredictably. In this setting, these shifts could distort the adaptation process. To address this problem, we propose a novel Image-level Disentangled Prompt Tuning (I-DiPT) framework. I-DiPT employs an image-invariant prompt to explore domain-invariant representations for mitigating the unpredictable shifts, and an image-specific prompt to adapt the source model to each test image from the incoming fragments. The prompts may suffer from insufficient knowledge representation since only one image is available for training. To overcome this limitation, we first introduce Uncertainty-oriented Masking (UoM), which encourages the prompts to extract sufficient information from the incoming image via masked consistency learning driven by the uncertainty of the source model representations. Then, we further propose a Parallel Graph Distillation (PGD) method that reuses knowledge from historical image-specific and image-invariant prompts through parallel graph networks. Experiments on breast cancer and glaucoma classification demonstrate the superiority of our method over existing TTA approaches in F$^{2}$TTA. Code is available at https://github.com/mar-cry/F2TTA.",
      "authors": [
        "Wei Li",
        "Jingyang Zhang",
        "Lihao Liu",
        "Guoan Wang",
        "Junjun He",
        "Yang Chen",
        "Lixu Gu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T08:50:56+00:00",
          "link": "https://arxiv.org/abs/2507.02437v1",
          "size": "5101kb",
          "version": "v1"
        }
      ],
      "title": "F^2TTA: Free-Form Test-Time Adaptation on Cross-Domain Medical Image Classification via Image-Level Disentangled Prompt Tuning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02437",
        "HTML": "https://arxiv.org/html/2507.02437v1",
        "PDF": "https://arxiv.org/pdf/2507.02437"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses adaptations for image classification in a medical context, involving data adaptation techniques. While it involves training-stage data processing, it is not directly focused on LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02438",
      "abstract": "Shared control combines human intention with autonomous decision-making, from low-level safety overrides to high-level task guidance, enabling systems that adapt to users while ensuring safety and performance. This enhances task effectiveness and user experience across domains such as assistive robotics, teleoperation, and autonomous driving. However, existing shared control methods, based on e.g. Model Predictive Control, Control Barrier Functions, or learning-based control, struggle with feasibility, scalability, or safety guarantees, particularly since the user input is unpredictable.\n  To address these challenges, we propose an assistive controller framework based on Constrained Optimal Control Problem that incorporates an offline-computed Control Invariant Set, enabling online computation of control actions that ensure feasibility, strict constraint satisfaction, and minimal override of user intent. Moreover, the framework can accommodate structured class of non-convex constraints, which are common in real-world scenarios. We validate the approach through a large-scale user study with 66 participants--one of the most extensive in shared control research--using a computer game environment to assess task load, trust, and perceived control, in addition to performance. The results show consistent improvements across all these aspects without compromising safety and user intent.",
      "authors": [
        "Shivam Chaubey",
        "Francesco Verdoja",
        "Shankar Deka",
        "Ville Kyrki"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Human-Computer Interaction (cs.HC)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T08:52:05+00:00",
          "link": "https://arxiv.org/abs/2507.02438v1",
          "size": "208kb",
          "version": "v1"
        }
      ],
      "title": "MISC: Minimal Intervention Shared Control with Guaranteed Safety under Non-Convex Constraints",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02438",
        "HTML": "https://arxiv.org/html/2507.02438v1",
        "PDF": "https://arxiv.org/pdf/2507.02438"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses shared control in autonomous systems with safety under constraints. It does not focus on LLMs or the processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02442",
      "abstract": "Enhancing the intelligibility and interpretability of machine learning is a crucial task in responding to the demand for Explicability as an AI principle, and in promoting the better social implementation of AI. The aim of our research is to contribute to this improvement by reformulating machine learning models through the lens of category theory, thereby developing a semantic framework for structuring and understanding AI systems. Our categorical modeling in this paper clarifies and formalizes the structural interplay between residuals and parameters in supervised learning. The present paper focuses on the multiple linear regression model, which represents the most basic form of supervised learning. By defining two concrete categories corresponding to parameters and data, along with an adjoint pair of functors between them, we introduce our categorical formulation of supervised learning. We show that the essential structure of this framework is captured by what we call the Gauss-Markov Adjunction. Within this setting, the dual flow of information can be explicitly described as a correspondence between variations in parameters and residuals. The ordinary least squares estimator for the parameters and the minimum residual are related via the preservation of limits by the right adjoint functor. Furthermore, we position this formulation as an instance of extended denotational semantics for supervised learning, and propose applying a semantic perspective developed in theoretical computer science as a formal foundation for Explicability in AI.",
      "authors": [
        "Moto Kamiura"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Category Theory (math.CT)",
        "Methodology (stat.ME)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T08:58:59+00:00",
          "link": "https://arxiv.org/abs/2507.02442v1",
          "size": "14kb",
          "version": "v1"
        }
      ],
      "title": "The Gauss-Markov Adjunction: Categorical Semantics of Residuals in Supervised Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02442",
        "HTML": "https://arxiv.org/html/2507.02442v1",
        "PDF": "https://arxiv.org/pdf/2507.02442"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on using category theory to enhance interpretability in machine learning models, particularly in supervised learning, and does not discuss training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02443",
      "abstract": "Robots usually slow down for canning to detect objects while moving. Additionally, the robot's camera is configured with a low framerate to track the velocity of the detection algorithms. This would be constrained while executing tasks and exploring, making robots increase the task execution time. AMD has developed the Vitis-AI framework to deploy detection algorithms into FPGAs. However, this tool does not fully use the FPGAs' PL. In this work, we use the FINN architecture to deploy three ANNs, MobileNet v1 with 4-bit quantisation, CNV with 2-bit quantisation, and CNV with 1-bit quantisation (BNN), inside an FPGA's PL. The models were trained on the RG2C dataset. This is a self-acquired dataset released in open access. MobileNet v1 performed better, reaching a success rate of 98 % and an inference speed of 6611 FPS. In this work, we proved that we can use FPGAs to speed up ANNs and make them suitable for attention mechanisms.",
      "authors": [
        "Sandro Costa Magalh\\~aes and Marco Almeida and Filipe Neves dos Santos and Ant\\'onio Paulo Moreira and Jorge Dias"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Machine Learning (cs.LG)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T09:00:19+00:00",
          "link": "https://arxiv.org/abs/2507.02443v1",
          "size": "2225kb",
          "version": "v1"
        }
      ],
      "title": "Red grape detection with accelerated artificial neural networks in the FPGA's programmable logic",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02443",
        "HTML": "https://arxiv.org/html/2507.02443v1",
        "PDF": "https://arxiv.org/pdf/2507.02443"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses the deployment of ANNs on FPGAs and mentions using a self-acquired dataset. There is no novel data processing method for LLM training data, but there is brief mention of using existing datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02445",
      "abstract": "Current methods for restoring underexposed images typically rely on supervised learning with paired underexposed and well-illuminated images. However, collecting such datasets is often impractical in real-world scenarios. Moreover, these methods can lead to over-enhancement, distorting well-illuminated regions. To address these issues, we propose IGDNet, a Zero-Shot enhancement method that operates solely on a single test image, without requiring guiding priors or training data. IGDNet exhibits strong generalization ability and effectively suppresses noise while restoring illumination. The framework comprises a decomposition module and a denoising module. The former separates the image into illumination and reflection components via a dense connection network, while the latter enhances non-uniformly illuminated regions using an illumination-guided pixel adaptive correction method. A noise pair is generated through downsampling and refined iteratively to produce the final result. Extensive experiments on four public datasets demonstrate that IGDNet significantly improves visual quality under complex lighting conditions. Quantitative results on metrics like PSNR (20.41dB) and SSIM (0.860dB) show that it outperforms 14 state-of-the-art unsupervised methods. The code will be released soon.",
      "authors": [
        "Hailong Yan",
        "Junjian Huang",
        "Tingwen Huang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T09:01:57+00:00",
          "link": "https://arxiv.org/abs/2507.02445v1",
          "size": "29448kb",
          "version": "v1"
        }
      ],
      "title": "IGDNet: Zero-Shot Robust Underexposed Image Enhancement via Illumination-Guided and Denoising",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02445",
        "HTML": "https://arxiv.org/html/2507.02445v1",
        "PDF": "https://arxiv.org/pdf/2507.02445"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on image enhancement methods for underexposed images, not on the processing of LLM training data or related data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02447",
      "abstract": "Despite recent remarkable achievements in quadruped control, it remains challenging to ensure robust and compliant locomotion in the presence of unforeseen external disturbances. Existing methods prioritize locomotion robustness over compliance, often leading to stiff, high-frequency motions, and energy inefficiency. This paper, therefore, presents a two-stage hierarchical learning framework that can learn to take active reactions to external force disturbances based on force estimation. In the first stage, a velocity-tracking policy is trained alongside an auto-encoder to distill historical proprioceptive features. A neural network-based estimator is learned through supervised learning, which estimates body velocity and external forces based on proprioceptive measurements. In the second stage, a compliance action module, inspired by impedance control, is learned based on the pre-trained encoder and policy. This module is employed to actively adjust velocity commands in response to external forces based on real-time force estimates. With the compliance action module, a quadruped robot can robustly handle minor disturbances while appropriately yielding to significant forces, thus striking a balance between robustness and compliance. Simulations and real-world experiments have demonstrated that our method has superior performance in terms of robustness, energy efficiency, and safety. Experiment comparison shows that our method outperforms the state-of-the-art RL-based locomotion controllers. Ablation studies are given to show the critical roles of the compliance action module.",
      "authors": [
        "Xiang Zhou",
        "Xinyu Zhang",
        "Qingrui Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T09:04:25+00:00",
          "link": "https://arxiv.org/abs/2507.02447v1",
          "size": "3434kb",
          "version": "v1"
        }
      ],
      "title": "HAC-LOCO: Learning Hierarchical Active Compliance Control for Quadruped Locomotion under Continuous External Disturbances",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02447",
        "HTML": "https://arxiv.org/html/2507.02447v1",
        "PDF": "https://arxiv.org/pdf/2507.02447"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses learning frameworks for quadruped locomotion control, which does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02453",
      "abstract": "Wearable haptic interventions offer promising support for relaxation through slow, vibrotactile biofeedback. Despite their potential, current applications focus on stress-inducing procedures and fixed vibration patterns, with limited consideration of body location and dynamic biofeedback during restful states. This study investigates the effects of haptic biofeedback adjusted from real-time heart rate during eyes-closed wakeful rest, comparing four wearable body placements: the wrist, hand, forearm, and shoulder. Heart rate, alpha wave activity on the ear, subjective restfulness, and vibration experience were measured across these conditions. Results show that biofeedback reduced heart rate at the wrist, shoulder, and forearm, while alpha power measured at the ear remained unchanged. Subjective restfulness was rated highest at the shoulder and forearm, which were also the most preferred locations. In addition, participants reported greater comfort, relaxation, and further increased sleepiness at the forearm compared to the wrist, which was more easily recognizable. These findings suggest that the forearm and shoulder are ideal for unobtrusive relaxation feedback for wakeful rest, while the wrist may require design improvements for subjective experience.",
      "authors": [
        "Jueun Lee",
        "Martin Flipe",
        "Philipp Lepold",
        "Tobias R\\\"oddiger",
        "Michael Beigl"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T09:11:06+00:00",
          "link": "https://arxiv.org/abs/2507.02453v1",
          "size": "2004kb",
          "version": "v1"
        }
      ],
      "title": "Haptic Biofeedback for Wakeful Rest: Does Stimulation Location Make a Difference?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02453",
        "HTML": "https://arxiv.org/html/2507.02453v1",
        "PDF": "https://arxiv.org/pdf/2507.02453"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study investigates the effects of haptic biofeedback on relaxation and does not relate to any aspect of LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02454",
      "abstract": "Different from general object detection, moving infrared small target detection faces huge challenges due to tiny target size and weak background contrast.Currently, most existing methods are fully-supervised, heavily relying on a large number of manual target-wise annotations. However, manually annotating video sequences is often expensive and time-consuming, especially for low-quality infrared frame images. Inspired by general object detection, non-fully supervised strategies ($e.g.$, weakly supervised) are believed to be potential in reducing annotation requirements. To break through traditional fully-supervised frameworks, as the first exploration work, this paper proposes a new weakly-supervised contrastive learning (WeCoL) scheme, only requires simple target quantity prompts during model training.Specifically, in our scheme, based on the pretrained segment anything model (SAM), a potential target mining strategy is designed to integrate target activation maps and multi-frame energy accumulation.Besides, contrastive learning is adopted to further improve the reliability of pseudo-labels, by calculating the similarity between positive and negative samples in feature subspace.Moreover, we propose a long-short term motion-aware learning scheme to simultaneously model the local motion patterns and global motion trajectory of small targets.The extensive experiments on two public datasets (DAUB and ITSDT-15K) verify that our weakly-supervised scheme could often outperform early fully-supervised methods. Even, its performance could reach over 90\\% of state-of-the-art (SOTA) fully-supervised ones.",
      "authors": [
        "Weiwei Duan",
        "Luping Ji",
        "Shengjia Chen",
        "Sicheng Zhu",
        "Jianghong Huang",
        "Mao Ye"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T09:11:31+00:00",
          "link": "https://arxiv.org/abs/2507.02454v1",
          "size": "11729kb",
          "version": "v1"
        }
      ],
      "title": "Weakly-supervised Contrastive Learning with Quantity Prompts for Moving Infrared Small Target Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02454",
        "HTML": "https://arxiv.org/html/2507.02454v1",
        "PDF": "https://arxiv.org/pdf/2507.02454"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on weakly-supervised contrastive learning for infrared small target detection. It does not address the collection, construction, or processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02456",
      "abstract": "Large language models (LLMs), based on transformer architectures, have revolutionized numerous domains within artificial intelligence, science, and engineering due to their exceptional scalability and adaptability. However, the exponential growth in LLM size and complexity has outpaced advancements in compute capacity, memory bandwidth, network performance, and cost efficiency, posing significant challenges to their scalability on distributed systems. To address these limitations, alternative model architectures, optimization strategies, communication-aware network topologies, and novel system design approaches have been proposed in literature. This paper introduces a performance-cost modeling methodology for LLM training and inference that integrates state-of-the-art compute techniques with memory optimizations, and latest communication techniques. Building on an analytical performance model, our approach incorporates recent innovations such as the flash attention technique and mixture of experts models to address the memory bandwidth and compute bottlenecks. It also considers the impact of different network topologies and topology-specific communication algorithms with 5D parallellism. The framework also integrates a chiplet cost model. The proposed modeling methodology provides valuable insights to guide future compute system design and facilitates hardware-software co-development, in particular due to its ability to analyze performance-cost trade-offs for various system architectural configurations.",
      "authors": [
        "Wenzhe Guo",
        "Joyjit Kundu",
        "Uras Tos",
        "Weijiang Kong",
        "Giuliano Sisto",
        "Timon Evenblij",
        "and Manu Perumkunnil"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T09:13:31+00:00",
          "link": "https://arxiv.org/abs/2507.02456v1",
          "size": "780kb",
          "version": "v1"
        }
      ],
      "title": "System-performance and cost modeling of Large Language Model training and inference",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02456",
        "HTML": "https://arxiv.org/html/2507.02456v1",
        "PDF": "https://arxiv.org/pdf/2507.02456"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "Although the paper discusses system-performance and cost modeling of LLM training, its focus is on computational efficiency and hardware rather than the processing or engineering of training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02459",
      "abstract": "We propose and study a Particle-In-Cell (PIC) method based on the Crank-Nicolson time discretization for the Vlasov-Poisson system with a strong and inhomogeneous external magnetic field with fixed direction, where we focus on the motion of particles in the plane orthogonal to the magnetic field (so-called poloidal directions). In this regime, the time step can be subject to stability constraints related to the smallness of Larmor radius and plasma frequency [21]. To avoid this limitation, our approach is based on numerical schemes [9, 10, 12], providing a consistent PIC discretization of the guiding-center system taking into account variations of the magnetic field.  We carry out some theoretical proofs and perform several numerical experiments to validate the method and its underlying concepts.",
      "authors": [
        "Francis Filbet (UT",
        "IMT)",
        "L Miguel Rodrigues (IRMAR)",
        "Kim Han Trinh (IRMAR)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T09:16:49+00:00",
          "link": "https://arxiv.org/abs/2507.02459v1",
          "size": "3360kb",
          "version": "v1"
        }
      ],
      "title": "A modified Crank-Nicolson scheme for the Vlasov-Poisson system with a strong external magnetic field",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02459",
        "HTML": "https://arxiv.org/html/2507.02459v1",
        "PDF": "https://arxiv.org/pdf/2507.02459"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a numerical method for the Vlasov-Poisson system, which is unrelated to LLM training data processing or data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02464",
      "abstract": "The CAP theorem asserts a trilemma between consistency, availability, and partition tolerance. This paper introduces a rigorous automata-theoretic and economically grounded framework that reframes the CAP trade-off as a constraint optimization problem. We model distributed systems as partition-aware state machines and embed economic incentive layers to stabilize consensus behavior across adversarially partitioned networks. By incorporating game-theoretic mechanisms into the global transition semantics, we define provable bounds on convergence, liveness, and correctness. Our results demonstrate that availability and consistency can be simultaneously preserved within bounded epsilon margins, effectively extending the classical CAP limits through formal economic control.",
      "authors": [
        "Craig S Wright"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Formal Languages and Automata Theory (cs.FL)",
        "Information Retrieval (cs.IR)",
        "General Economics (econ.GN)",
        "Economics (q-fin.EC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T09:21:43+00:00",
          "link": "https://arxiv.org/abs/2507.02464v1",
          "size": "34kb",
          "version": "v1"
        }
      ],
      "title": "Resolving CAP Through Automata-Theoretic Economic Design: A Unified Mathematical Framework for Real-Time Partition-Tolerant Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02464",
        "HTML": "https://arxiv.org/html/2507.02464v1",
        "PDF": "https://arxiv.org/pdf/2507.02464"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research proposes an economic design framework for partition-tolerant systems which is unrelated to the data processing or engineering for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02466",
      "abstract": "Kolmogorov Arnold Networks (KANs) are an emerging architecture for building machine learning models. KANs are based on the theoretical foundation of the Kolmogorov-Arnold Theorem and its expansions, which provide an exact representation of a multi-variate continuous bounded function as the composition of a limited number of univariate continuous functions. While such theoretical results are powerful, their use as a representation learning alternative to a multi-layer perceptron (MLP) hinges on the ad-hoc choice of the number of bases modeling each of the univariate functions. In this work, we show how to address this problem by adaptively learning a potentially infinite number of bases for each univariate function during training. We therefore model the problem as a variational inference optimization problem. Our proposal, called InfinityKAN, which uses backpropagation, extends the potential applicability of KANs by treating an important hyperparameter as part of the learning process.",
      "authors": [
        "Francesco Alesiani",
        "Henrik Christiansen",
        "Federico Errica"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T09:24:09+00:00",
          "link": "https://arxiv.org/abs/2507.02466v1",
          "size": "7119kb",
          "version": "v1"
        }
      ],
      "title": "Variational Kolmogorov-Arnold Network",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02466",
        "HTML": "https://arxiv.org/html/2507.02466v1",
        "PDF": "https://arxiv.org/pdf/2507.02466"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a new machine learning architecture based on the Kolmogorov-Arnold Networks, which does not involve any aspect of LLM training data collection, construction, or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02468",
      "abstract": "This paper quantifies and addresses the bias of subspace-based Data-Driven Predictive Control (DDPC) for linear, time-invariant (LTI) systems. The primary focus is the bias that arises when the training data is gathered with a feedback controller in closed-loop with the system. First, the closed-loop bias of Subspace Predictive Control is quantified using the training data innovations. Next, the bias of direct, subspace-based DDPC methods DeePC and $\\gamma$-DDPC is shown to consist of two parts--the Subspace Bias, which arises from closed-loop data, and an Optimism Bias, which arises from DeePC/$\\gamma$-DDPC's \"optimistic\" adjustment of the output trajectory. We show that, unlike subspace-based DDPC methods, Transient Predictive Control does not suffer from Subspace Bias or Optimism Bias. Double integrator experiments demonstrate that Subspace and Optimism Bias are responsible for poor reference tracking by the subspace-based DDPC methods.",
      "authors": [
        "Keith Moffat",
        "Florian D\\\"orfler",
        "and Alessandro Chiuso"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T09:26:34+00:00",
          "link": "https://arxiv.org/abs/2507.02468v1",
          "size": "1136kb",
          "version": "v1"
        }
      ],
      "title": "The Bias of Subspace-based Data-Driven Predictive Control",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02468",
        "HTML": "https://arxiv.org/html/2507.02468v1",
        "PDF": "https://arxiv.org/pdf/2507.02468"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the bias in Data-Driven Predictive Control for LTI systems, not related to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02477",
      "abstract": "We introduce Mesh Silksong, a compact and efficient mesh representation tailored to generate the polygon mesh in an auto-regressive manner akin to silk weaving. Existing mesh tokenization methods always produce token sequences with repeated vertex tokens, wasting the network capability. Therefore, our approach tokenizes mesh vertices by accessing each mesh vertice only once, reduces the token sequence's redundancy by 50\\%, and achieves a state-of-the-art compression rate of approximately 22\\%. Furthermore, Mesh Silksong produces polygon meshes with superior geometric properties, including manifold topology, watertight detection, and consistent face normals, which are critical for practical applications. Experimental results demonstrate the effectiveness of our approach, showcasing not only intricate mesh generation but also significantly improved geometric integrity.",
      "authors": [
        "Gaochao Song",
        "Zibo Zhao",
        "Haohan Weng",
        "Jingbo Zeng",
        "Rongfei Jia",
        "Shenghua Gao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T09:34:24+00:00",
          "link": "https://arxiv.org/abs/2507.02477v1",
          "size": "32505kb",
          "version": "v1"
        }
      ],
      "title": "Mesh Silksong: Auto-Regressive Mesh Generation as Weaving Silk",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02477",
        "HTML": "https://arxiv.org/html/2507.02477v1",
        "PDF": "https://arxiv.org/pdf/2507.02477"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a mesh generation method, which does not involve LLM training data processing or related methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02478",
      "abstract": "Wi-Fi management frames reveal structured communication patterns that persist even under randomization of MAC addresses. Prior approaches to associating randomized MAC addresses with devices primarily focus on probe requests, overlooking the broader set of management frames and their transition dynamics. This narrow focus limits their robustness in dense, real-world environments with high device mobility, where probe activity alone fails to yield stable and distinctive signatures. In this paper, we present a novel framework for fingerprinting Wi-Fi devices based on behavioral dynamics extracted from passively observed management frames. We model each device's behavior as a finite state machine and introduce matrix-based representations that encode both structural (state transition frequencies) and temporal (inter-state delays) characteristics. These matrices are embedded into compact feature vectors, enabling efficient similarity comparison. Through extensive evaluation in diverse real-world settings, our method achieves over 86% identification accuracy for non-randomized devices using only Wi-Fi management frames, with further improvements observed through temporal burst aggregation. Our findings are sufficient to uniquely and consistently characterize devices at scale, outperforming the state-of-the-art.",
      "authors": [
        "Melissa Safari",
        "Abhishek K. Mishra",
        "and Mathieu Cunche"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T09:35:38+00:00",
          "link": "https://arxiv.org/abs/2507.02478v1",
          "size": "247kb",
          "version": "v1"
        }
      ],
      "title": "Effectively Identifying Wi-Fi Devices through State Transitions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02478",
        "HTML": "https://arxiv.org/html/2507.02478v1",
        "PDF": "https://arxiv.org/pdf/2507.02478"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research presents a Wi-Fi device identification framework, which is unrelated to the processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02479",
      "abstract": "Multi-object tracking is a classic field in computer vision. Among them, pedestrian tracking has extremely high application value and has become the most popular research category. Existing methods mainly use motion or appearance information for tracking, which is often difficult in complex scenarios. For the motion information, mutual occlusions between objects often prevent updating of the motion state; for the appearance information, non-robust results are often obtained due to reasons such as only partial visibility of the object or blurred images. Although learning how to perform tracking in these situations from the annotated data is the simplest solution, the existing MOT dataset fails to satisfy this solution. Existing methods mainly have two drawbacks: relatively simple scene composition and non-realistic scenarios. Although some of the video sequences in existing dataset do not have the above-mentioned drawbacks, the number is far from adequate for research purposes. To this end, we propose a difficult large-scale dataset for multi-pedestrian tracking, shot mainly from the first-person view and all from real-life complex scenarios. We name it ``CrowdTrack'' because there are numerous objects in most of the sequences. Our dataset consists of 33 videos, containing a total of 5,185 trajectories. Each object is annotated with a complete bounding box and a unique object ID. The dataset will provide a platform to facilitate the development of algorithms that remain effective in complex situations. We analyzed the dataset comprehensively and tested multiple SOTA models on our dataset. Besides, we analyzed the performance of the foundation models on our dataset. The dataset and project code is released at: https://github.com/loseevaya/CrowdTrack .",
      "authors": [
        "Teng Fu",
        "Yuwen Chen",
        "Zhuofan Chen",
        "Mengyang Zhao",
        "Bin Li",
        "Xiangyang Xue"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T09:36:44+00:00",
          "link": "https://arxiv.org/abs/2507.02479v1",
          "size": "1167kb",
          "version": "v1"
        }
      ],
      "title": "CrowdTrack: A Benchmark for Difficult Multiple Pedestrian Tracking in Real Scenarios",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02479",
        "HTML": "https://arxiv.org/html/2507.02479v1",
        "PDF": "https://arxiv.org/pdf/2507.02479"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a dataset for pedestrian tracking in computer vision, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02488",
      "abstract": "Medical image recognition serves as a key way to aid in clinical diagnosis, enabling more accurate and timely identification of diseases and abnormalities. Vision transformer-based approaches have proven effective in handling various medical recognition tasks. However, these methods encounter two primary challenges. First, they are often task-specific and architecture-tailored, limiting their general applicability. Second, they usually either adopt full attention to model long-range dependencies, resulting in high computational costs, or rely on handcrafted sparse attention, potentially leading to suboptimal performance. To tackle these issues, we present MedFormer, an efficient medical vision transformer with two key ideas. First, it employs a pyramid scaling structure as a versatile backbone for various medical image recognition tasks, including image classification and dense prediction tasks such as semantic segmentation and lesion detection. This structure facilitates hierarchical feature representation while reducing the computation load of feature maps, highly beneficial for boosting performance. Second, it introduces a novel Dual Sparse Selection Attention (DSSA) with content awareness to improve computational efficiency and robustness against noise while maintaining high performance. As the core building technique of MedFormer, DSSA is explicitly designed to attend to the most relevant content. In addition, a detailed theoretical analysis has been conducted, demonstrating that MedFormer has superior generality and efficiency in comparison to existing medical vision transformers. Extensive experiments on a variety of imaging modality datasets consistently show that MedFormer is highly effective in enhancing performance across all three above-mentioned medical image recognition tasks. The code is available at https://github.com/XiaZunhui/MedFormer.",
      "authors": [
        "Zunhui Xia",
        "Hongxing Li",
        "Libin Lan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T09:51:45+00:00",
          "link": "https://arxiv.org/abs/2507.02488v1",
          "size": "1728kb",
          "version": "v1"
        }
      ],
      "title": "MedFormer: Hierarchical Medical Vision Transformer with Content-Aware Dual Sparse Selection Attention",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02488",
        "HTML": "https://arxiv.org/html/2507.02488v1",
        "PDF": "https://arxiv.org/pdf/2507.02488"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes a medical vision transformer method, focusing on medical image recognition, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02489",
      "abstract": "We propose a new 10-bit S-box generated from a Feistel construction. The subpermutations are generated by a 5-cell cellular automaton based on a unique well-chosen rule and bijective affine transformations. In particular, the cellular automaton rule is chosen based on empirical tests of its ability to generate good pseudorandom output on a ring cellular automaton. Similarly, Feistel's network layout is based on empirical data regarding the quality of the output S-box. We perform cryptanalysis of the generated 10-bit S-box, and we find security properties comparable to or sometimes even better than those of the standard AES S-box. We believe that our S-box could be used to replace the 5-bit substitution of ciphers like ASCON.",
      "authors": [
        "Thomas Pr\\'evost (I3S)",
        "Bruno Martin (I3S)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T09:53:33+00:00",
          "link": "https://arxiv.org/abs/2507.02489v1",
          "size": "27kb",
          "version": "v1"
        }
      ],
      "title": "A 10-bit S-box generated by Feistel construction from cellular automata",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02489",
        "PDF": "https://arxiv.org/pdf/2507.02489"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is focused on generating a 10-bit S-box via Feistel construction and cellular automata for cryptographic purposes and does not discuss any aspects of LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02491",
      "abstract": "The problem of LTLf reactive synthesis is to build a transducer, whose output is based on a history of inputs, such that, for every infinite sequence of inputs, the conjoint evolution of the inputs and outputs has a prefix that satisfies a given LTLf specification. We describe the implementation of an LTLf synthesizer that outperforms existing tools on our benchmark suite. This is based on a new, direct translation from LTLf to a DFA represented as an array of Binary Decision Diagrams (MTBDDs) sharing their nodes. This MTBDD-based representation can be interpreted directly as a reachability game that is solved on-the-fly during its construction.",
      "authors": [
        "Alexandre Duret-Lutz (LRE)",
        "Shufang Zhu",
        "Nir Piterman (Chalmers)",
        "Giuseppe de Giacomo (UNIROMA)",
        "Moshe Y Vardi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Formal Languages and Automata Theory (cs.FL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T09:54:34+00:00",
          "link": "https://arxiv.org/abs/2507.02491v1",
          "size": "553kb",
          "version": "v1"
        }
      ],
      "title": "Engineering an LTLf Synthesis Tool",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02491",
        "PDF": "https://arxiv.org/pdf/2507.02491"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper describes an LTLf synthesizer tool for reactive systems and involves logic synthesis and decision diagrams, with no discussion related to LLM training data or its processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02492",
      "abstract": "Mutually Unbiased Bases (MUBs) are closely connected with quantum physics, and the structure has a rich mathematical background. We provide equivalent criteria for extending a set of MUBs for $C^n$ by studying real points of a certain affine algebraic variety. This variety comes from the relations that determine the extendability of a system of MUBs. Finally, we show that some part of this variety gives rise to complete intersection domains. Further, we show that there is a one-to-one correspondence between MUBs and the maximal commuting classes (bases) of orthogonal normal matrices in $\\mathcal M_n({\\mathbb{C}})$. It means that for $m$ MUBs in $C^n$, there are $m$ commuting classes, each consisting of $n$ commuting orthogonal normal matrices and the existence of maximal commuting basis for $\\mathcal M_n({\\mathbb{C}})$ ensures the complete set of MUBs in $\\mathcal M_n({\\mathbb{C}})$.",
      "authors": [
        "Arindam Banerjee",
        "Kanoy Kumar Das",
        "Ajeet Kumar",
        "Rakesh Kumar",
        "Subhamoy Maitra"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T09:55:31+00:00",
          "link": "https://arxiv.org/abs/2507.02492v1",
          "size": "31kb",
          "version": "v1"
        }
      ],
      "title": "On Obtaining New MUBs by Finding Points on Complete Intersection Varieties over $\\mathbb{R}$",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02492",
        "HTML": "https://arxiv.org/html/2507.02492v1",
        "PDF": "https://arxiv.org/pdf/2507.02492"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on the mathematical study of Mutually Unbiased Bases (MUBs) related to quantum physics, lacking any discussion on data processing or engineering for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02493",
      "abstract": "Automated polyp counting in colonoscopy is a crucial step toward automated procedure reporting and quality control, aiming to enhance the cost-effectiveness of colonoscopy screening. Counting polyps in a procedure involves detecting and tracking polyps, and then clustering tracklets that belong to the same polyp entity. Existing methods for polyp counting rely on self-supervised learning and primarily leverage visual appearance, neglecting temporal relationships in both tracklet feature learning and clustering stages. In this work, we introduce a paradigm shift by proposing a supervised contrastive loss that incorporates temporally-aware soft targets. Our approach captures intra-polyp variability while preserving inter-polyp discriminability, leading to more robust clustering. Additionally, we improve tracklet clustering by integrating a temporal adjacency constraint, reducing false positive re-associations between visually similar but temporally distant tracklets. We train and validate our method on publicly available datasets and evaluate its performance with a leave-one-out cross-validation strategy. Results demonstrate a 2.2x reduction in fragmentation rate compared to prior approaches. Our results highlight the importance of temporal awareness in polyp counting, establishing a new state-of-the-art. Code is available at https://github.com/lparolari/temporally-aware-polyp-counting.",
      "authors": [
        "Luca Parolari",
        "Andrea Cherubini",
        "Lamberto Ballan",
        "Carlo Biffi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T09:55:48+00:00",
          "link": "https://arxiv.org/abs/2507.02493v1",
          "size": "1070kb",
          "version": "v1"
        }
      ],
      "title": "Temporally-Aware Supervised Contrastive Learning for Polyp Counting in Colonoscopy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02493",
        "HTML": "https://arxiv.org/html/2507.02493v1",
        "PDF": "https://arxiv.org/pdf/2507.02493"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research pertains to the use of supervised contrastive learning for polyp counting in medical imaging, and does not relate to any LLM training data processing or engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02494",
      "abstract": "Implicit Neural Representations (INRs) are widely used to encode data as continuous functions, enabling the visualization of large-scale multivariate scientific simulation data with reduced memory usage. However, existing INR-based methods face three main limitations: (1) inflexible representation of complex structures, (2) primarily focusing on single-variable data, and (3) dependence on structured grids. Thus, their performance degrades when applied to complex real-world datasets. To address these limitations, we propose a novel neural network-based framework, MC-INR, which handles multivariate data on unstructured grids. It combines meta-learning and clustering to enable flexible encoding of complex structures. To further improve performance, we introduce a residual-based dynamic re-clustering mechanism that adaptively partitions clusters based on local error. We also propose a branched layer to leverage multivariate data through independent branches simultaneously. Experimental results demonstrate that MC-INR outperforms existing methods on scientific data encoding tasks.",
      "authors": [
        "Hyunsoo Son",
        "Jeonghyun Noh",
        "Suemin Jeon",
        "Chaoli Wang",
        "Won-Ki Jeong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T09:55:57+00:00",
          "link": "https://arxiv.org/abs/2507.02494v1",
          "size": "4238kb",
          "version": "v1"
        }
      ],
      "title": "MC-INR: Efficient Encoding of Multivariate Scientific Simulation Data using Meta-Learning and Clustered Implicit Neural Representations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02494",
        "HTML": "https://arxiv.org/html/2507.02494v1",
        "PDF": "https://arxiv.org/pdf/2507.02494"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces MC-INR for the encoding of scientific simulation data using neural representations. While it discusses data encoding methods, it does not focus on LLM-specific training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02496",
      "abstract": "We study the problem of conformal prediction in a novel online framework that directly optimizes efficiency. In our problem, we are given a target miscoverage rate $\\alpha > 0$, and a time horizon $T$. On each day $t \\le T$ an algorithm must output an interval $I_t \\subseteq [0, 1]$, then a point $y_t \\in [0, 1]$ is revealed. The goal of the algorithm is to achieve coverage, that is, $y_t \\in I_t$ on (close to) a $(1 - \\alpha)$-fraction of days, while maintaining efficiency, that is, minimizing the average volume (length) of the intervals played. This problem is an online analogue to the problem of constructing efficient confidence intervals.\n  We study this problem over arbitrary and exchangeable (random order) input sequences. For exchangeable sequences, we show that it is possible to construct intervals that achieve coverage $(1 - \\alpha) - o(1)$, while having length upper bounded by the best fixed interval that achieves coverage in hindsight. For arbitrary sequences however, we show that any algorithm that achieves a $\\mu$-approximation in average length compared to the best fixed interval achieving coverage in hindsight, must make a multiplicative factor more mistakes than $\\alpha T$, where the multiplicative factor depends on $\\mu$ and the aspect ratio of the problem. Our main algorithmic result is a matching algorithm that can recover all Pareto-optimal settings of $\\mu$ and number of mistakes. Furthermore, our algorithm is deterministic and therefore robust to an adaptive adversary.\n  This gap between the exchangeable and arbitrary settings is in contrast to the classical online learning problem. In fact, we show that no single algorithm can simultaneously be Pareto-optimal for arbitrary sequences and optimal for exchangeable sequences. On the algorithmic side, we give an algorithm that achieves the near-optimal tradeoff between the two cases.",
      "authors": [
        "Vaidehi Srinivas"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Data Structures and Algorithms (cs.DS)",
        "Statistics Theory (math.ST)",
        "Machine Learning (stat.ML)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T10:00:50+00:00",
          "link": "https://arxiv.org/abs/2507.02496v1",
          "size": "52kb",
          "version": "v1"
        }
      ],
      "title": "Online Conformal Prediction with Efficiency Guarantees",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02496",
        "HTML": "https://arxiv.org/html/2507.02496v1",
        "PDF": "https://arxiv.org/pdf/2507.02496"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on online conformal prediction algorithms for achieving efficiency in output intervals and does not relate to the processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02500",
      "abstract": "This paper presents a novel framework for goal-oriented optimal static sensor placement and dynamic sensor steering in PDE-constrained inverse problems, utilizing a Bayesian approach accelerated by low-rank approximations. The framework is applied to airborne contaminant tracking, extending recent dynamic sensor steering methods to complex geometries for computational efficiency. A C-optimal design criterion is employed to strategically place sensors, minimizing uncertainty in predictions. Numerical experiments validate the approach's effectiveness for source identification and monitoring, highlighting its potential for real-time decision-making in crisis management scenarios.",
      "authors": [
        "Marco Mattuschka",
        "Noah An der Lan",
        "Max von Danwitz",
        "Daniel Wolff",
        "Alexander Popp"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T10:04:59+00:00",
          "link": "https://arxiv.org/abs/2507.02500v1",
          "size": "27188kb",
          "version": "v1"
        }
      ],
      "title": "Goal-oriented optimal sensor placement for PDE-constrained inverse problems in crisis management",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02500",
        "HTML": "https://arxiv.org/html/2507.02500v1",
        "PDF": "https://arxiv.org/pdf/2507.02500"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about optimal sensor placement for PDE-constrained inverse problems using a Bayesian approach, which does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02503",
      "abstract": "Continual fine-tuning of Large Language Models (LLMs) is hampered by the trade-off between efficiency and expressiveness. Low-Rank Adaptation (LoRA) offers efficiency but constrains the model's ability to learn new tasks and transfer knowledge due to its low-rank nature and reliance on explicit parameter constraints. We propose GORP (Gradient LOw Rank Projection) for Continual Learning, a novel training strategy that overcomes these limitations by synergistically combining full and low-rank parameters and jointly updating within a unified low-rank gradient subspace. GORP expands the optimization space while preserving efficiency and mitigating catastrophic forgetting. Extensive experiments on continual learning benchmarks demonstrate GORP's superior performance compared to existing state-of-the-art approaches. Code is available at https://github.com/Wcxwcxw/GORP.",
      "authors": [
        "Chenxu Wang",
        "Yilin Lyu",
        "Zicheng Sun",
        "Liping Jing"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T10:11:22+00:00",
          "link": "https://arxiv.org/abs/2507.02503v1",
          "size": "9307kb",
          "version": "v1"
        }
      ],
      "title": "Continual Gradient Low-Rank Projection Fine-Tuning for LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02503",
        "HTML": "https://arxiv.org/html/2507.02503v1",
        "PDF": "https://arxiv.org/pdf/2507.02503"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses a novel fine-tuning strategy for LLMs, but does not focus on data processing itself; rather, it deals with continual learning techniques for already available datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02506",
      "abstract": "Legal NLP remains underdeveloped in regions like India due to the scarcity of structured datasets. We introduce IndianBailJudgments-1200, a new benchmark dataset comprising 1200 Indian court judgments on bail decisions, annotated across 20+ attributes including bail outcome, IPC sections, crime type, and legal reasoning. Annotations were generated using a prompt-engineered GPT-4o pipeline and verified for consistency. This resource supports a wide range of legal NLP tasks such as outcome prediction, summarization, and fairness analysis, and is the first publicly available dataset focused specifically on Indian bail jurisprudence.",
      "authors": [
        "Sneha Deshmukh and Prathmesh Kamble"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T10:13:42+00:00",
          "link": "https://arxiv.org/abs/2507.02506v1",
          "size": "1252kb",
          "version": "v1"
        }
      ],
      "title": "IndianBailJudgments-1200: A Multi-Attribute Dataset for Legal NLP on Indian Bail Orders",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02506",
        "HTML": "https://arxiv.org/html/2507.02506v1",
        "PDF": "https://arxiv.org/pdf/2507.02506"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces a new dataset, IndianBailJudgments-1200, specifically constructed for legal NLP tasks, which contributes directly to data construction and processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02510",
      "abstract": "Cross-subject motor imagery (CS-MI) classification in brain-computer interfaces (BCIs) is a challenging task due to the significant variability in Electroencephalography (EEG) patterns across different individuals. This variability often results in lower classification accuracy compared to subject-specific models, presenting a major barrier to developing calibration-free BCIs suitable for real-world applications. In this paper, we introduce a novel approach that significantly enhances cross-subject MI classification performance through optimized preprocessing and deep learning techniques. Our approach involves direct classification of Short-Time Fourier Transform (STFT)-transformed EEG data, optimized STFT parameters, and a balanced batching strategy during training of a Convolutional Neural Network (CNN). This approach is uniquely validated across four different datasets, including three widely-used benchmark datasets leading to substantial improvements in cross-subject classification, achieving 67.60% on the BCI Competition IV Dataset 1 (IV-1), 65.96% on Dataset 2A (IV-2A), and 80.22% on Dataset 2B (IV-2B), outperforming state-of-the-art techniques. Additionally, we systematically investigate the classification performance using MI windows ranging from the full 4-second window to 1-second windows. These results establish a new benchmark for generalizable, calibration-free MI classification in addition to contributing a robust open-access dataset to advance research in this domain.",
      "authors": [
        "Ahmed G. Habashi",
        "Ahmed M. Azab",
        "Seif Eldawlatly",
        "and Gamal M. Aly"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Human-Computer Interaction (cs.HC)",
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T10:17:39+00:00",
          "link": "https://arxiv.org/abs/2507.02510v1",
          "size": "1144kb",
          "version": "v1"
        }
      ],
      "title": "TFOC-Net: A Short-time Fourier Transform-based Deep Learning Approach for Enhancing Cross-Subject Motor Imagery Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02510",
        "PDF": "https://arxiv.org/pdf/2507.02510"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus here is on EEG data preprocessing and classification for brain-computer interface applications rather than processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02513",
      "abstract": "Pedestrian detection in RGB images is a key task in pedestrian safety, as the most common sensor in autonomous vehicles and advanced driver assistance systems is the RGB camera. A challenge in RGB pedestrian detection, that does not appear to have large public datasets, is low-light conditions. As a solution, in this research, we propose an automated infrared-RGB labeling pipeline. The proposed pipeline consists of 1) Infrared detection, where a fine-tuned model for infrared pedestrian detection is used 2) Label transfer process from the infrared detections to their RGB counterparts 3) Training object detection models using the generated labels for low-light RGB pedestrian detection. The research was performed using the KAIST dataset. For the evaluation, object detection models were trained on the generated autolabels and ground truth labels. When compared on a previously unseen image sequence, the results showed that the models trained on generated labels outperformed the ones trained on ground-truth labels in 6 out of 9 cases for the mAP@50 and mAP@50-95 metrics. The source code for this research is available at https://github.com/BouzoulasDimitrios/IR-RGB-Automated-LowLight-Pedestrian-Labeling",
      "authors": [
        "Dimitrios Bouzoulas",
        "Eerik Alamikkotervo and Risto Ojala"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T10:20:17+00:00",
          "link": "https://arxiv.org/abs/2507.02513v1",
          "size": "11459kb",
          "version": "v1"
        }
      ],
      "title": "Automatic Labelling for Low-Light Pedestrian Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02513",
        "HTML": "https://arxiv.org/html/2507.02513v1",
        "PDF": "https://arxiv.org/pdf/2507.02513"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper describes an automated labeling pipeline for pedestrian detection in low-light conditions, involving data processing like label transfer and infra-red detection, relevant to data preparation but not specific to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02517",
      "abstract": "India, as a predominantly agrarian economy, faces significant challenges in agriculture, including substantial crop losses caused by diseases, pests, and environmental stress. Early detection and accurate identification of diseases across different crops are critical for improving yield and ensuring food security. This paper proposes a deep learning based solution for detecting multiple diseases in multiple crops, aimed to cover India's diverse agricultural landscape. We first create a unified dataset encompassing images of 17 different crops and 34 different diseases from various available repositories. Proposed deep learning model is trained on this dataset and outperforms the state-of-the-art in terms of accuracy and the number of crops, diseases covered. We achieve a significant detection accuracy, i.e., 99 percent for our unified dataset which is 7 percent more when compared to state-of-the-art handling 14 crops and 26 different diseases only. By improving the number of crops and types of diseases that can be detected, proposed solution aims to provide a better product for Indian farmers.",
      "authors": [
        "Vivek Yadav and Anugrah Jain"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T10:26:49+00:00",
          "link": "https://arxiv.org/abs/2507.02517v1",
          "size": "506kb",
          "version": "v1"
        }
      ],
      "title": "Detecting Multiple Diseases in Multiple Crops Using Deep Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02517",
        "PDF": "https://arxiv.org/pdf/2507.02517"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses the creation of a unified dataset for disease detection in crops using deep learning. While it involves data collection and preparation, it specifically targets crop disease and not LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02519",
      "abstract": "This paper introduces IMASHRIMP, an adapted system for the automated morphological analysis of white shrimp (Penaeus vannamei}, aimed at optimizing genetic selection tasks in aquaculture. Existing deep learning and computer vision techniques were modified to address the specific challenges of shrimp morphology analysis from RGBD images. IMASHRIMP incorporates two discrimination modules, based on a modified ResNet-50 architecture, to classify images by the point of view and determine rostrum integrity. It is proposed a \"two-factor authentication (human and IA)\" system, it reduces human error in view classification from 0.97% to 0% and in rostrum detection from 12.46% to 3.64%. Additionally, a pose estimation module was adapted from VitPose to predict 23 key points on the shrimp's skeleton, with separate networks for lateral and dorsal views. A morphological regression module, using a Support Vector Machine (SVM) model, was integrated to convert pixel measurements to centimeter units. Experimental results show that the system effectively reduces human error, achieving a mean average precision (mAP) of 97.94% for pose estimation and a pixel-to-centimeter conversion error of 0.07 (+/- 0.1) cm. IMASHRIMP demonstrates the potential to automate and accelerate shrimp morphological analysis, enhancing the efficiency of genetic selection and contributing to more sustainable aquaculture practices.The code are available at https://github.com/AbiamRemacheGonzalez/ImaShrimp-public",
      "authors": [
        "Abiam Remache Gonz\\'alez",
        "Meriem Chagour",
        "Timon Bijan R\\\"uth",
        "Ra\\'ul Trapiella Ca\\~nedo",
        "Marina Mart\\'inez Soler",
        "\\'Alvaro Lorenzo Felipe",
        "Hyun-Suk Shin",
        "Mar\\'ia-Jes\\'us Zamorano Serrano",
        "Ricardo Torres",
        "Juan-Antonio Castillo Parra",
        "Eduardo Reyes Abad",
        "Miguel-\\'Angel Ferrer Ballester",
        "Juan-Manuel Afonso L\\'opez",
        "Francisco-Mario Hern\\'andez Tejera",
        "Adrian Penate-Sanchez"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T10:32:49+00:00",
          "link": "https://arxiv.org/abs/2507.02519v1",
          "size": "16410kb",
          "version": "v1"
        }
      ],
      "title": "IMASHRIMP: Automatic White Shrimp (Penaeus vannamei) Biometrical Analysis from Laboratory Images Using Computer Vision and Deep Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02519",
        "HTML": "https://arxiv.org/html/2507.02519v1",
        "PDF": "https://arxiv.org/pdf/2507.02519"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on automated shrimp morphological analysis using computer vision and deep learning, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02521",
      "abstract": "This research investigates strategies for multi-robot coordination in multi-human environments. It proposes a multi-objective learning-based coordination approach to addressing the problem of path planning, navigation, task scheduling, task allocation, and human-robot interaction in multi-human multi-robot (MHMR) settings.",
      "authors": [
        "Ayodeji O. Abioye",
        "Jayati Deshmukh",
        "Athina Georgara",
        "Dominic Price",
        "Tuyen Nguyen",
        "Aleksandra Landowska",
        "Amel Bennaceur",
        "Joel E. Fischer",
        "and Sarvapali D. Ramchurn"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T10:37:22+00:00",
          "link": "https://arxiv.org/abs/2507.02521v1",
          "size": "2533kb",
          "version": "v1"
        }
      ],
      "title": "Safe and Socially Aware Multi-Robot Coordination in Multi-Human Social Care Settings",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02521",
        "HTML": "https://arxiv.org/html/2507.02521v1",
        "PDF": "https://arxiv.org/pdf/2507.02521"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research focuses on multi-robot coordination and human-robot interaction, which do not relate to LLMs or their data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02524",
      "abstract": "Accurately learning solution operators for time-dependent partial differential equations (PDEs) from sparse and irregular data remains a challenging task. Recurrent DeepONet extensions inherit the discrete-time limitations of sequence-to-sequence (seq2seq) RNN architectures, while neural-ODE surrogates cannot incorporate new inputs after initialization. We introduce NCDE-DeepONet, a continuous-time operator network that embeds a Neural Controlled Differential Equation (NCDE) in the branch and augments the trunk with explicit space-time coordinates. The NCDE encodes an entire load history as the solution of a controlled ODE driven by a spline-interpolated input path, making the representation input-resolution-independent: it encodes different input signal discretizations of the observed samples. The trunk then probes this latent path at arbitrary spatial locations and times, rendering the overall map output-resolution independent: predictions can be queried on meshes and time steps unseen during training without retraining or interpolation. Benchmarks on transient Poisson, elastodynamic, and thermoelastic problems confirm the robustness and accuracy of the framework, achieving almost instant solution prediction. These findings suggest that controlled dynamics provide a principled and efficient foundation for high-fidelity operator learning in transient mechanics.",
      "authors": [
        "Diab W. Abueidda and Mbebo Nonna and Panos Pantidis and Mostafa E. Mobasher"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T10:44:57+00:00",
          "link": "https://arxiv.org/abs/2507.02524v1",
          "size": "23311kb",
          "version": "v1"
        }
      ],
      "title": "Time Resolution Independent Operator Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02524",
        "HTML": "https://arxiv.org/html/2507.02524v1",
        "PDF": "https://arxiv.org/pdf/2507.02524"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on learning solution operators for PDEs using continuous-time operator networks, which does not involve the processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02529",
      "abstract": "The text-to-SQL task is an active challenge in Natural Language Processing. Many existing solutions focus on using black-box language models extended with specialized components within customized end-to-end text-to-SQL pipelines. While these solutions use both closed-source proprietary language models and coding-oriented open-source models, there is a lack of research regarding SQL-specific generative models. At the same time, recent advancements in self-correcting generation strategies show promise for improving the capabilities of existing architectures. The application of these concepts to the text-to-SQL task remains unexplored. In this paper, we introduce RetrySQL, a new approach to training text-to-SQL generation models. We prepare reasoning steps for reference SQL queries and then corrupt them to create retry data that contains both incorrect and corrected steps, divided with a special token. We continuously pre-train an open-source coding model with this data and demonstrate that retry steps yield an improvement of up to 4 percentage points in both overall and challenging execution accuracy metrics, compared to pre-training without retry data. Additionally, we confirm that supervised fine-tuning with LoRA is ineffective for learning from retry data and that full-parameter pre-training is a necessary requirement for that task. We showcase that the self-correcting behavior is learned by the model and the increase in downstream accuracy metrics is a result of this additional skill. Finally, we incorporate RetrySQL-trained models into the full text-to-SQL pipeline and showcase that they are competitive in terms of execution accuracy with proprietary models that contain orders of magnitude more parameters. RetrySQL demonstrates that self-correction can be learned in the text-to-SQL task and provides a novel way of improving generation accuracy for SQL-oriented language models.",
      "authors": [
        "Alicja R\\k{a}czkowska",
        "Riccardo Belluzzo",
        "Piotr Zieli\\'nski",
        "Joanna Baran",
        "Pawe{\\l} Olszewski"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T11:00:49+00:00",
          "link": "https://arxiv.org/abs/2507.02529v1",
          "size": "8305kb",
          "version": "v1"
        }
      ],
      "title": "RetrySQL: text-to-SQL training with retry data for self-correcting query generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02529",
        "HTML": "https://arxiv.org/html/2507.02529v1",
        "PDF": "https://arxiv.org/pdf/2507.02529"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper presents a novel approach to improving text-to-SQL generation through specialized training data that involves creating and processing retry data for self-correction, which directly relates to LLM data preprocessing and preparation for enhancing training quality."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02532",
      "abstract": "The Feedback-based Algorithm for Quantum Optimization (FALQON) is a Lyapunov inspired quantum algorithm proposed to tackle combinatorial optimization problems. In this paper, we examine the robustness of FALQON against coherent control errors, a class of multiplicative errors that affect the control input. We show that the algorithm is asymptotically robust with respect to systematic errors, and we derive robustness bounds for independent errors. Finally, we propose a robust version of FALQON which minimizes a regularized Lyapunov function. Our theoretical results are supported through simulations.",
      "authors": [
        "Mirko Legnini and Julian Berberich"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T11:17:28+00:00",
          "link": "https://arxiv.org/abs/2507.02532v1",
          "size": "143kb",
          "version": "v1"
        }
      ],
      "title": "Robust feedback-based quantum optimization: analysis of coherent control errors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02532",
        "HTML": "https://arxiv.org/html/2507.02532v1",
        "PDF": "https://arxiv.org/pdf/2507.02532"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper concerns quantum optimization algorithms and their robustness to errors, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02533",
      "abstract": "Fairness--the absence of unjustified bias--is a core principle in the development of Artificial Intelligence (AI) systems, yet it remains difficult to assess and enforce. Current approaches to fairness testing in large language models (LLMs) often rely on manual evaluation, fixed templates, deterministic heuristics, and curated datasets, making them resource-intensive and difficult to scale. This work aims to lay the groundwork for a novel, automated method for testing fairness in LLMs, reducing the dependence on domain-specific resources and broadening the applicability of current approaches. Our approach, Meta-Fair, is based on two key ideas. First, we adopt metamorphic testing to uncover bias by examining how model outputs vary in response to controlled modifications of input prompts, defined by metamorphic relations (MRs). Second, we propose exploiting the potential of LLMs for both test case generation and output evaluation, leveraging their capability to generate diverse inputs and classify outputs effectively. The proposal is complemented by three open-source tools supporting LLM-driven generation, execution, and evaluation of test cases. We report the findings of several experiments involving 12 pre-trained LLMs, 14 MRs, 5 bias dimensions, and 7.9K automatically generated test cases. The results show that Meta-Fair is effective in uncovering bias in LLMs, achieving an average precision of 92% and revealing biased behaviour in 29% of executions. Additionally, LLMs prove to be reliable and consistent evaluators, with the best-performing models achieving F1-scores of up to 0.79. Although non-determinism affects consistency, these effects can be mitigated through careful MR design. While challenges remain to ensure broader applicability, the results indicate a promising path towards an unprecedented level of automation in LLM testing.",
      "authors": [
        "Miguel Romero-Arjona",
        "Jos\\'e A. Parejo",
        "Juan C. Alonso",
        "Ana B. S\\'anchez",
        "Aitor Arrieta",
        "Sergio Segura"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T11:20:59+00:00",
          "link": "https://arxiv.org/abs/2507.02533v1",
          "size": "4881kb",
          "version": "v1"
        }
      ],
      "title": "Meta-Fair: AI-Assisted Fairness Testing of Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02533",
        "HTML": "https://arxiv.org/html/2507.02533v1",
        "PDF": "https://arxiv.org/pdf/2507.02533"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on fairness testing in LLMs through automated methods, involving bias detection but not the processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02536",
      "abstract": "This paper presents a blockchain-based Internet of Things (IoT) system for monitoring pizza production in restaurants. IoT devices track temperature and humidity in real-time, while blockchain ensures secure and tamper-proof data. A Raspberry Pi processes sensor data, captures images, triggers alerts, and interacts with smart contracts. The system detects abnormal conditions, enabling quick responses. Blockchain adds transparency and traceability, supporting compliance and audits. Experiments show improved ingredient management, reduced waste, and increased kitchen efficiency.",
      "authors": [
        "Azmat Ullah",
        "Maria Ilaria Lunesu",
        "Lodovica Marchesi and Roberto Tonelli"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T11:32:28+00:00",
          "link": "https://arxiv.org/abs/2507.02536v1",
          "size": "2238kb",
          "version": "v1"
        }
      ],
      "title": "Real-Time Monitoring and Transparency in Pizza Production Using IoT and Blockchain",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02536",
        "HTML": "https://arxiv.org/html/2507.02536v1",
        "PDF": "https://arxiv.org/pdf/2507.02536"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents an IoT and blockchain system for pizza production monitoring, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02537",
      "abstract": "Conversational agents have made significant progress since ELIZA, expanding their role across various domains, including healthcare, education, and customer service. As these agents become increasingly integrated into daily human interactions, the need for emotional intelligence, particularly empathetic listening, becomes increasingly essential. In this study, we explore how Large Language Models (LLMs) respond when tasked with generating emotionally rich interactions. Starting from a small dataset manually crafted by an expert to reflect empathic behavior, we extended the conversations using two LLMs: ChatGPT and Gemini. We analyzed the emotional progression of the dialogues using both sentiment analysis (via VADER) and expert assessments. While the generated conversations often mirrored the intended emotional structure, human evaluation revealed important differences in the perceived empathy and coherence of the responses. These findings suggest that emotion modeling in dialogues requires not only structural alignment in the expressed emotions but also qualitative depth, highlighting the importance of combining automated and humancentered methods in the development of emotionally competent agents.",
      "authors": [
        "Paulo Ricardo Knob",
        "Leonardo Scholler",
        "Juliano Rigatti",
        "Soraia Raupp Musse"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T11:32:41+00:00",
          "link": "https://arxiv.org/abs/2507.02537v1",
          "size": "1320kb",
          "version": "v1"
        }
      ],
      "title": "Are You Listening to Me? Fine-Tuning Chatbots for Empathetic Dialogue",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02537",
        "HTML": "https://arxiv.org/html/2507.02537v1",
        "PDF": "https://arxiv.org/pdf/2507.02537"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses the use of LLMs for generating empathetic dialogues but focuses on analysis and evaluation rather than novel methods for data processing or construction. It starts from an existing dataset and does not propose new data engineering techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02541",
      "abstract": "In this work, we investigate whether improving task clarity can enhance reasoning ability of large language models, focusing on theorem proving in Coq. We introduce a concept-level metric to evaluate task clarity and show that adding structured semantic context to the standard input used by modern LLMs, leads to a 1.85$\\times$ improvement in clarity score (44.5\\%~$\\rightarrow$~82.3\\%). Using the general-purpose model \\texttt{DeepSeek-V3}, our approach leads to a 2.1$\\times$ improvement in proof success (21.8\\%~$\\rightarrow$~45.8\\%) and outperforms the previous state-of-the-art \\texttt{Graph2Tac} (33.2\\%). We evaluate this on 1,386 theorems randomly sampled from 15 standard Coq packages, following the same evaluation protocol as \\texttt{Graph2Tac}. Furthermore, fine-tuning smaller models on our structured data can achieve even higher performance (48.6\\%). Our method uses selective concept unfolding to enrich task descriptions, and employs a Planner--Executor architecture. These findings highlight the value of structured task representations in bridging the gap between understanding and reasoning.",
      "authors": [
        "Yanzhen Lu",
        "Hanbin Yang",
        "Xiaodie Wang",
        "Ge Zhang",
        "Biao Li",
        "Chenxu Fu",
        "Chao Li",
        "Yang Yuan",
        "Andrew Chi-Chih Yao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T11:35:34+00:00",
          "link": "https://arxiv.org/abs/2507.02541v1",
          "size": "42kb",
          "version": "v1"
        }
      ],
      "title": "Clarifying Before Reasoning: A Coq Prover with Structural Context",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02541",
        "HTML": "https://arxiv.org/html/2507.02541v1",
        "PDF": "https://arxiv.org/pdf/2507.02541"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "Although the study involves fine-tuning models, it primarily examines adding structured semantic context to improve task clarity and reasoning, not novel contributions in LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02546",
      "abstract": "We propose MoGe-2, an advanced open-domain geometry estimation model that recovers a metric scale 3D point map of a scene from a single image. Our method builds upon the recent monocular geometry estimation approach, MoGe, which predicts affine-invariant point maps with unknown scales. We explore effective strategies to extend MoGe for metric geometry prediction without compromising the relative geometry accuracy provided by the affine-invariant point representation. Additionally, we discover that noise and errors in real data diminish fine-grained detail in the predicted geometry. We address this by developing a unified data refinement approach that filters and completes real data from different sources using sharp synthetic labels, significantly enhancing the granularity of the reconstructed geometry while maintaining the overall accuracy. We train our model on a large corpus of mixed datasets and conducted comprehensive evaluations, demonstrating its superior performance in achieving accurate relative geometry, precise metric scale, and fine-grained detail recovery -- capabilities that no previous methods have simultaneously achieved.",
      "authors": [
        "Ruicheng Wang",
        "Sicheng Xu",
        "Yue Dong",
        "Yu Deng",
        "Jianfeng Xiang",
        "Zelong Lv",
        "Guangzhong Sun",
        "Xin Tong",
        "Jiaolong Yang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T11:40:01+00:00",
          "link": "https://arxiv.org/abs/2507.02546v1",
          "size": "28219kb",
          "version": "v1"
        }
      ],
      "title": "MoGe-2: Accurate Monocular Geometry with Metric Scale and Sharp Details",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02546",
        "HTML": "https://arxiv.org/html/2507.02546v1",
        "PDF": "https://arxiv.org/pdf/2507.02546"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on geometry estimation techniques using synthetic and real data, which is unrelated to LLM training data processing tasks such as collection or filtering for NLP models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02547",
      "abstract": "Under-actuated compliant robotic systems offer a promising approach to mitigating actuation and control challenges by harnessing pre-designed, embodied dynamic behaviors. This paper presents Flix-Walker, a novel, untethered, centimeter-scale quadrupedal robot inspired by compliant under-actuated mechanisms. Flix-Walker employs flexible, helix-shaped beams as legs, which are actuated by vibrations from just two motors to achieve three distinct mobility modes. We analyze the actuation parameters required to generate various locomotion modes through both simulation and prototype experiments. The effects of system and environmental variations on locomotion performance are examined, and we propose a generic metric for selecting control parameters that produce robust and functional motions. Experiments validate the effectiveness and robustness of these actuation parameters within a closed-loop control framework, demonstrating reliable trajectory-tracking and self-navigation capabilities.",
      "authors": [
        "Yuhao Jiang",
        "Fuchen Chen",
        "Jamie Paik",
        "Daniel M. Aukes"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T11:40:46+00:00",
          "link": "https://arxiv.org/abs/2507.02547v1",
          "size": "4364kb",
          "version": "v1"
        }
      ],
      "title": "Vibration of Soft, Twisted Beams for Under-Actuated Quadrupedal Locomotion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02547",
        "HTML": "https://arxiv.org/html/2507.02547v1",
        "PDF": "https://arxiv.org/pdf/2507.02547"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research concentrates on robotic dynamics and actuation, with no discussion of LLM training data processing or data engineering relevant to language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02548",
      "abstract": "The edit distance $ed(X,Y)$ of two strings $X,Y\\in \\Sigma^*$ is the minimum number of character edits (insertions, deletions, and substitutions) needed to transform $X$ into $Y$. Its weighted counterpart $ed^w(X,Y)$ minimizes the total cost of edits, which are specified using a function $w$, normalized so that each edit costs at least one. The textbook dynamic-programming procedure, given strings $X,Y\\in \\Sigma^{\\le n}$ and oracle access to $w$, computes $ed^w(X,Y)$ in $O(n^2)$ time. Nevertheless, one can achieve better running times if the computed distance, denoted $k$, is small: $O(n+k^2)$ for unit weights [Landau and Vishkin; JCSS'88] and $\\tilde{O}(n+\\sqrt{nk^3})$ for arbitrary weights [Cassis, Kociumaka, Wellnitz; FOCS'23].\n  In this paper, we study the dynamic version of the weighted edit distance problem, where the goal is to maintain $ed^w(X,Y)$ for strings $X,Y\\in \\Sigma^{\\le n}$ that change over time, with each update specified as an edit in $X$ or $Y$. Very recently, Gorbachev and Kociumaka [STOC'25] showed that the unweighted distance $ed(X,Y)$ can be maintained in $\\tilde{O}(k)$ time per update after $\\tilde{O}(n+k^2)$-time preprocessing; here, $k$ denotes the current value of $ed(X,Y)$. Their algorithm generalizes to small integer weights, but the underlying approach is incompatible with large weights.\n  Our main result is a dynamic algorithm that maintains $ed^w(X,Y)$ in $\\tilde{O}(k^{3-\\gamma})$ time per update after $\\tilde{O}(nk^\\gamma)$-time preprocessing. Here, $\\gamma\\in [0,1]$ is a real trade-off parameter and $k\\ge 1$ is an integer threshold fixed at preprocessing time, with $\\infty$ returned whenever $ed^w(X,Y)>k$. We complement our algorithm with conditional lower bounds showing fine-grained optimality of our trade-off for $\\gamma \\in [0.5,1)$ and justifying our choice to fix $k$.",
      "authors": [
        "Itai Boneh",
        "Egor Gorbachev",
        "Tomasz Kociumaka"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T11:45:49+00:00",
          "link": "https://arxiv.org/abs/2507.02548v1",
          "size": "77kb",
          "version": "v1"
        }
      ],
      "title": "Bounded Weighted Edit Distance: Dynamic Algorithms and Matching Lower Bounds",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02548",
        "HTML": "https://arxiv.org/html/2507.02548v1",
        "PDF": "https://arxiv.org/pdf/2507.02548"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses algorithms for edit distance computations, which do not pertain to LLM data processing tasks or the construction of training data pipelines for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02549",
      "abstract": "Achieving rapid and time-deterministic stabilization for complex systems characterized by strong nonlinearities and parametric uncertainties presents a significant challenge. Traditional model-based control relies on precise system models, whereas purely data-driven methods often lack formal stability guarantees, limiting their applicability in safety-critical systems. This paper proposes a novel control framework that synergistically integrates data-driven modeling with model-based control. The framework first employs the Extended Dynamic Mode Decomposition with Control (EDMDc) to identify a high-dimensional Koopman linear model and quantify its bounded uncertainty from data. Subsequently, a novel Prescribed-Time Adaptive Backstepping (PTAB) controller is synthesized based on this data-driven model. The design leverages the structural advantages of Koopman linearization to systematically handle model errors and circumvent the \"explosion of complexity\" issue inherent in traditional backstepping. The proposed controller is validated through simulations on the classic Van der Pol oscillator. The results demonstrate that the controller can precisely stabilize the system states to a small neighborhood of the origin within a user-prescribed time, regardless of the initial conditions, while ensuring the boundedness of all closed-loop signals. This research successfully combines the flexibility of data-driven approaches with the rigor of Lyapunov-based analysis. It provides a high-performance control strategy with quantifiable performance and pre-assignable settling time for nonlinear systems, showcasing its great potential for controlling complex dynamics.",
      "authors": [
        "Yue Wu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T11:47:45+00:00",
          "link": "https://arxiv.org/abs/2507.02549v1",
          "size": "965kb",
          "version": "v1"
        }
      ],
      "title": "A Data-Driven Prescribed-Time Control Framework via Koopman Operator and Adaptive Backstepping",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02549",
        "HTML": "https://arxiv.org/html/2507.02549v1",
        "PDF": "https://arxiv.org/pdf/2507.02549"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a control framework for complex systems using data-driven and model-based methods but does not address LLM training data processing or enhancements."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02550",
      "abstract": "Overparametrized Deep Neural Networks (DNNs) have demonstrated remarkable success in a wide variety of domains too high-dimensional for classical shallow networks subject to the curse of dimensionality. However, open questions about fundamental principles, that govern the learning dynamics of DNNs, remain. In this position paper we argue that it is the ability of DNNs to exploit the compositionally sparse structure of the target function driving their success. As such, DNNs can leverage the property that most practically relevant functions can be composed from a small set of constituent functions, each of which relies only on a low-dimensional subset of all inputs. We show that this property is shared by all efficiently Turing-computable functions and is therefore highly likely present in all current learning problems. While some promising theoretical insights on questions concerned with approximation and generalization exist in the setting of compositionally sparse functions, several important questions on the learnability and optimization of DNNs remain. Completing the picture of the role of compositional sparsity in deep learning is essential to a comprehensive theory of artificial, and even general, intelligence.",
      "authors": [
        "David A. Danhofer",
        "Davide D'Ascenzo",
        "Rafael Dubach",
        "Tomaso Poggio"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T11:49:56+00:00",
          "link": "https://arxiv.org/abs/2507.02550v1",
          "size": "179kb",
          "version": "v1"
        }
      ],
      "title": "Position: A Theory of Deep Learning Must Include Compositional Sparsity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02550",
        "HTML": "https://arxiv.org/html/2507.02550v1",
        "PDF": "https://arxiv.org/pdf/2507.02550"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses compositional sparsity in deep learning models without addressing any aspect of LLM training data processing or engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02554",
      "abstract": "AI research agents are demonstrating great potential to accelerate scientific progress by automating the design, implementation, and training of machine learning models. We focus on methods for improving agents' performance on MLE-bench, a challenging benchmark where agents compete in Kaggle competitions to solve real-world machine learning problems. We formalize AI research agents as search policies that navigate a space of candidate solutions, iteratively modifying them using operators. By designing and systematically varying different operator sets and search policies (Greedy, MCTS, Evolutionary), we show that their interplay is critical for achieving high performance. Our best pairing of search strategy and operator set achieves a state-of-the-art result on MLE-bench lite, increasing the success rate of achieving a Kaggle medal from 39.6% to 47.7%. Our investigation underscores the importance of jointly considering the search strategy, operator design, and evaluation methodology in advancing automated machine learning.",
      "authors": [
        "Edan Toledo",
        "Karen Hambardzumyan",
        "Martin Josifoski",
        "Rishi Hazra",
        "Nicolas Baldwin",
        "Alexis Audran-Reiss",
        "Michael Kuchnik",
        "Despoina Magka",
        "Minqi Jiang",
        "Alisia Maria Lupidi",
        "Andrei Lupu",
        "Roberta Raileanu",
        "Kelvin Niu",
        "Tatiana Shavrina",
        "Jean-Christophe Gagnon-Audet",
        "Michael Shvartsman",
        "Shagun Sodhani",
        "Alexander H. Miller",
        "Abhishek Charnalia",
        "Derek Dunfield",
        "Carole-Jean Wu",
        "Pontus Stenetorp",
        "Nicola Cancedda",
        "Jakob Nicolaus Foerster",
        "Yoram Bachrach"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T11:59:15+00:00",
          "link": "https://arxiv.org/abs/2507.02554v1",
          "size": "1493kb",
          "version": "v1"
        }
      ],
      "title": "AI Research Agents for Machine Learning: Search, Exploration, and Generalization in MLE-bench",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02554",
        "HTML": "https://arxiv.org/html/2507.02554v1",
        "PDF": "https://arxiv.org/pdf/2507.02554"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores AI agents optimizing model training in a competitive benchmark environment, with no focus on LLM training data preparation or data processing contributions."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02559",
      "abstract": "Layer-wise normalization (LN) is an essential component of virtually all transformer-based large language models. While its effects on training stability are well documented, its role at inference time is poorly understood. Additionally, LN layers hinder mechanistic interpretability by introducing additional nonlinearities and increasing the interconnectedness of individual model components. Here, we show that all LN layers can be removed from every GPT-2 model with only a small increase in validation loss (e.g. +0.03 cross-entropy loss for GPT-2 XL). Thus, LN cannot play a substantial role in language modeling. We find that the amount of fine-tuning data needed for LN removal grows sublinearly with model parameters, suggesting scaling to larger models is feasible. We release a suite of LN-free GPT-2 models on Hugging Face. Furthermore, we test interpretability techniques on LN-free models. Direct logit attribution now gives the exact direct effect of individual components, while the accuracy of attribution patching does not significantly improve. We also confirm that GPT-2's \"confidence neurons\" are inactive in the LN-free models. Our work clarifies the role of LN layers in language modeling, showing that GPT-2-class models can function without LN layers. We hope that our LN-free analogs of the GPT-2 family of models will enable more precise interpretability research and improve our understanding of language models.",
      "authors": [
        "Luca Baroni",
        "Galvin Khara",
        "Joachim Schaeffer",
        "Marat Subkhankulov",
        "Stefan Heimersheim"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T12:09:04+00:00",
          "link": "https://arxiv.org/abs/2507.02559v1",
          "size": "3182kb",
          "version": "v1"
        }
      ],
      "title": "Transformers Don't Need LayerNorm at Inference Time: Scaling LayerNorm Removal to GPT-2 XL and the Implications for Mechanistic Interpretability",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02559",
        "HTML": "https://arxiv.org/html/2507.02559v1",
        "PDF": "https://arxiv.org/pdf/2507.02559"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper explores the removal of LayerNorm in GPT-2 models and touches on fine-tuning data, but it doesn't focus on novel data processing methods for LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02564",
      "abstract": "Requirements elicitation interviews are crucial for gathering system requirements but heavily depend on skilled analysts, making them resource-intensive, susceptible to human biases, and prone to miscommunication. Recent advancements in Large Language Models present new opportunities for automating parts of this process. This study introduces LLMREI, a chat bot designed to conduct requirements elicitation interviews with minimal human intervention, aiming to reduce common interviewer errors and improve the scalability of requirements elicitation. We explored two main approaches, zero-shot prompting and least-to-most prompting, to optimize LLMREI for requirements elicitation and evaluated its performance in 33 simulated stakeholder interviews. A third approach, fine-tuning, was initially considered but abandoned due to poor performance in preliminary trials. Our study assesses the chat bot's effectiveness in three key areas: minimizing common interview errors, extracting relevant requirements, and adapting its questioning based on interview context and user responses. Our findings indicate that LLMREI makes a similar number of errors compared to human interviewers, is capable of extracting a large portion of requirements, and demonstrates a notable ability to generate highly context-dependent questions. We envision the greatest benefit of LLMREI in automating interviews with a large number of stakeholders.",
      "authors": [
        "Alexander Korn",
        "Samuel Gorsch",
        "Andreas Vogelsang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T12:18:05+00:00",
          "link": "https://arxiv.org/abs/2507.02564v1",
          "size": "463kb",
          "version": "v1"
        }
      ],
      "title": "LLMREI: Automating Requirements Elicitation Interviews with LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02564",
        "HTML": "https://arxiv.org/html/2507.02564v1",
        "PDF": "https://arxiv.org/pdf/2507.02564"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper explores approaches to optimize LLMs for requirements elicitation, mentioning data processing through zero-shot and least-to-most prompting. However, it abandons fine-tuning and focuses mainly on application performance, not on training data processing methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02565",
      "abstract": "Due to visual ambiguities and inter-person occlusions, existing human pose estimation methods cannot recover plausible close interactions from in-the-wild videos. Even state-of-the-art large foundation models~(\\eg, SAM) cannot accurately distinguish human semantics in such challenging scenarios. In this work, we find that human appearance can provide a straightforward cue to address these obstacles. Based on this observation, we propose a dual-branch optimization framework to reconstruct accurate interactive motions with plausible body contacts constrained by human appearances, social proxemics, and physical laws. Specifically, we first train a diffusion model to learn the human proxemic behavior and pose prior knowledge. The trained network and two optimizable tensors are then incorporated into a dual-branch optimization framework to reconstruct human motions and appearances. Several constraints based on 3D Gaussians, 2D keypoints, and mesh penetrations are also designed to assist the optimization. With the proxemics prior and diverse constraints, our method is capable of estimating accurate interactions from in-the-wild videos captured in complex environments. We further build a dataset with pseudo ground-truth interaction annotations, which may promote future research on pose estimation and human behavior understanding. Experimental results on several benchmarks demonstrate that our method outperforms existing approaches. The code and data are available at https://www.buzhenhuang.com/works/CloseApp.html.",
      "authors": [
        "Buzhen Huang",
        "Chen Li",
        "Chongyang Xu",
        "Dongyue Lu",
        "Jinnan Chen",
        "Yangang Wang",
        "Gim Hee Lee"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T12:19:26+00:00",
          "link": "https://arxiv.org/abs/2507.02565v1",
          "size": "1313kb",
          "version": "v1"
        }
      ],
      "title": "Reconstructing Close Human Interaction with Appearance and Proxemics Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02565",
        "HTML": "https://arxiv.org/html/2507.02565v1",
        "PDF": "https://arxiv.org/pdf/2507.02565"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is focused on human pose estimation using human appearance cues and does not discuss any aspect related to LLM training data processing or data engineering for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02576",
      "abstract": "Vessels are complex structures in the body that have been studied extensively in multiple representations. While voxelization is the most common of them, meshes and parametric models are critical in various applications due to their desirable properties. However, these representations are typically extracted through segmentations and used disjointly from each other. We propose a framework that joins the three representations under differentiable transformations. By leveraging differentiable voxelization, we automatically extract a parametric shape model of the vessels through shape-to-segmentation fitting, where we learn shape parameters from segmentations without the explicit need for ground-truth shape parameters. The vessel is parametrized as centerlines and radii using cubic B-splines, ensuring smoothness and continuity by construction. Meshes are differentiably extracted from the learned shape parameters, resulting in high-fidelity meshes that can be manipulated post-fit. Our method can accurately capture the geometry of complex vessels, as demonstrated by the volumetric fits in experiments on aortas, aneurysms, and brain vessels.",
      "authors": [
        "Alina F. Dima",
        "Suprosanna Shit",
        "Huaqi Qiu",
        "Robbie Holland",
        "Tamara T. Mueller",
        "Fabio Antonio Musio",
        "Kaiyuan Yang",
        "Bjoern Menze",
        "Rickmer Braren",
        "Marcus Makowski",
        "Daniel Rueckert"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T12:33:21+00:00",
          "link": "https://arxiv.org/abs/2507.02576v1",
          "size": "2213kb",
          "version": "v1"
        }
      ],
      "title": "Parametric shape models for vessels learned from segmentations via differentiable voxelization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02576",
        "HTML": "https://arxiv.org/html/2507.02576v1",
        "PDF": "https://arxiv.org/pdf/2507.02576"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study is concerned with vessel representation using differentiable voxelization and does not touch upon LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02578",
      "abstract": "Adaptive Cyber-Physical Systems (CPS) are systems that integrate both physical and computational capabilities, which can adjust in response to changing parameters. Furthermore, they increasingly incorporate human-machine collaboration, allowing them to benefit from the individual strengths of humans and machines. Human-Machine Teaming (HMT) represents the most advanced paradigm of human-machine collaboration, envisioning seamless teamwork between humans and machines. However, achieving effective and seamless HMT in adaptive CPS is challenging. While adaptive CPS already benefit from feedback loops such as MAPE-K, there is still a gap in integrating humans into these feedback loops due to different operational cadences of humans and machines. Further, HMT requires constant monitoring of human operators, collecting potentially sensitive information about their actions and behavior. Respecting the privacy and human values of the actors of the CPS is crucial for the success of human-machine teams. This research addresses these challenges by: (1) developing novel methods and processes for integrating HMT into adaptive CPS, focusing on human-machine interaction principles and their incorporation into adaptive feedback loops found in CPS, and (2) creating frameworks for integrating, verifying, and validating ethics and human values throughout the system lifecycle, starting from requirements engineering.",
      "authors": [
        "Zoe Pfister"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T12:34:52+00:00",
          "link": "https://arxiv.org/abs/2507.02578v1",
          "size": "273kb",
          "version": "v1"
        }
      ],
      "title": "Human-Machine Collaboration and Ethical Considerations in Adaptive Cyber-Physical Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02578",
        "HTML": "https://arxiv.org/html/2507.02578v1",
        "PDF": "https://arxiv.org/pdf/2507.02578"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on human-machine collaboration in adaptive CPS and ethical frameworks, without discussing LLM training data or processing methodologies related to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02581",
      "abstract": "3D medical image self-supervised learning (mSSL) holds great promise for medical analysis. Effectively supporting broader applications requires considering anatomical structure variations in location, scale, and morphology, which are crucial for capturing meaningful distinctions. However, previous mSSL methods partition images with fixed-size patches, often ignoring the structure variations. In this work, we introduce a novel perspective on 3D medical images with the goal of learning structure-aware representations. We assume that patches within the same structure share the same semantics (semantic consistency) while those from different structures exhibit distinct semantics (semantic discrepancy). Based on this assumption, we propose an mSSL framework named $S^2DC$, achieving Structure-aware Semantic Discrepancy and Consistency in two steps. First, $S^2DC$ enforces distinct representations for different patches to increase semantic discrepancy by leveraging an optimal transport strategy. Second, $S^2DC$ advances semantic consistency at the structural level based on neighborhood similarity distribution. By bridging patch-level and structure-level representations, $S^2DC$ achieves structure-aware representations. Thoroughly evaluated across 10 datasets, 4 tasks, and 3 modalities, our proposed method consistently outperforms the state-of-the-art methods in mSSL.",
      "authors": [
        "Tan Pan",
        "Zhaorui Tan",
        "Kaiyu Guo",
        "Dongli Xu",
        "Weidi Xu",
        "Chen Jiang",
        "Xin Guo",
        "Yuan Qi",
        "Yuan Cheng"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T12:40:46+00:00",
          "link": "https://arxiv.org/abs/2507.02581v1",
          "size": "14029kb",
          "version": "v1"
        }
      ],
      "title": "Structure-aware Semantic Discrepancy and Consistency for 3D Medical Image Self-supervised Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02581",
        "HTML": "https://arxiv.org/html/2507.02581v1",
        "PDF": "https://arxiv.org/pdf/2507.02581"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses 3D medical image self-supervised learning, focusing on semantic consistency and discrepancy in image patches, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02582",
      "abstract": "Responsibility has long been a subject of study in law and philosophy. More recently, it became a focus of AI literature. The article investigates the computational complexity of two important properties of responsibility in collective decision-making: diffusion and gap. It shows that the sets of diffusion-free and gap-free decision-making mechanisms are $\\Pi_2$-complete and $\\Pi_3$-complete, respectively. At the same time, the intersection of these classes is $\\Pi_2$-complete.",
      "authors": [
        "Junli Jiang and Pavel Naumov"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T12:43:38+00:00",
          "link": "https://arxiv.org/abs/2507.02582v1",
          "size": "115kb",
          "version": "v1"
        }
      ],
      "title": "Responsibility Gap and Diffusion in Sequential Decision-Making Mechanisms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02582",
        "HTML": "https://arxiv.org/html/2507.02582v1",
        "PDF": "https://arxiv.org/pdf/2507.02582"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses computational complexity in decision-making mechanisms regarding responsibility, a topic unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02584",
      "abstract": "Switching communication topologies can cause instability in vehicle platoons, as vehicle information may be lost during the dynamic switching process. This highlights the need to design a controller capable of maintaining the stability of vehicle platoons under dynamically changing topologies. However, capturing the dynamic characteristics of switching topologies and obtaining complete vehicle information for controller design while ensuring stability remains a significant challenge. In this study, we propose an observer-based distributed model predictive control (DMPC) method for vehicle platoons under directed Markovian switching topologies. Considering the stochastic nature of the switching topologies, we model the directed switching communication topologies using a continuous-time Markov chain. To obtain the leader vehicle's information for controller design, we develop a fully distributed adaptive observer that can quickly adapt to the randomly switching topologies, ensuring that the observed information is not affected by the dynamic topology switches. Additionally, a sufficient condition is derived to guarantee the mean-square stability of the observer. Furthermore, we construct the DMPC terminal update law based on the observer and formulate a string stability constraint based on the observed information. Numerical simulations demonstrate that our method can reduce tracking errors while ensuring string stability.",
      "authors": [
        "Wenwei Que and Yang Li and Lu Wang and Wentao Liu and Yougang Bian and Manjiang Hu and Yongfu Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T12:45:21+00:00",
          "link": "https://arxiv.org/abs/2507.02584v1",
          "size": "1326kb",
          "version": "v1"
        }
      ],
      "title": "Observer-Based Distributed Model Predictive Control for String-Stable Multi-vehicle Systems with Markovian Switching Topology",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02584",
        "HTML": "https://arxiv.org/html/2507.02584v1",
        "PDF": "https://arxiv.org/pdf/2507.02584"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on model predictive control in vehicle platoons with switching topologies, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02585",
      "abstract": "Learned Differentiable Boolean Logic Networks (DBNs) already deliver efficient inference on resource-constrained hardware. We extend them with a trainable, differentiable interconnect whose parameter count remains constant as input width grows, allowing DBNs to scale to far wider layers than earlier learnable-interconnect designs while preserving their advantageous accuracy. To further reduce model size, we propose two complementary pruning stages: an SAT-based logic equivalence pass that removes redundant gates without affecting performance, and a similarity-based, data-driven pass that outperforms a magnitude-style greedy baseline and offers a superior compression-accuracy trade-off.",
      "authors": [
        "Fabian Kresse and Emily Yu and Christoph H. Lampert"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T12:45:45+00:00",
          "link": "https://arxiv.org/abs/2507.02585v1",
          "size": "965kb",
          "version": "v1"
        }
      ],
      "title": "Scalable Interconnect Learning in Boolean Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02585",
        "PDF": "https://arxiv.org/pdf/2507.02585"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses pruning methods for boolean networks which could be tangentially related to data preprocessing or model optimization techniques used in LLM training, but it does not directly propose new methods for LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02591",
      "abstract": "The challenge of long video understanding lies in its high computational complexity and prohibitive memory cost, since the memory and computation required by transformer-based LLMs scale quadratically with input sequence length. We propose AuroraLong to address this challenge by replacing the LLM component in MLLMs with a linear RNN language model that handles input sequence of arbitrary length with constant-size hidden states. To further increase throughput and efficiency, we combine visual token merge with linear RNN models by reordering the visual tokens by their sizes in ascending order. Despite having only 2B parameters and being trained exclusively on public data, AuroraLong achieves performance comparable to Transformer-based models of similar size trained on private datasets across multiple video benchmarks. This demonstrates the potential of efficient, linear RNNs to democratize long video understanding by lowering its computational entry barrier. To our best knowledge, we are the first to use a linear RNN based LLM backbone in a LLaVA-like model for open-ended video understanding.",
      "authors": [
        "Weili Xu",
        "Enxin Song",
        "Wenhao Chai",
        "Xuexiang Wen",
        "Tian Ye",
        "Gaoang Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T12:55:16+00:00",
          "link": "https://arxiv.org/abs/2507.02591v1",
          "size": "2245kb",
          "version": "v1"
        }
      ],
      "title": "AuroraLong: Bringing RNNs Back to Efficient Open-Ended Video Understanding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02591",
        "HTML": "https://arxiv.org/html/2507.02591v1",
        "PDF": "https://arxiv.org/pdf/2507.02591"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces an efficient method for video understanding using a linear RNN, it mentions being trained on public data without proposing new data collection or preprocessing methods for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02592",
      "abstract": "Transcending human cognitive limitations represents a critical frontier in LLM training. Proprietary agentic systems like DeepResearch have demonstrated superhuman capabilities on extremely complex information-seeking benchmarks such as BrowseComp, a feat previously unattainable. We posit that their success hinges on a sophisticated reasoning pattern absent in open-source models: the ability to systematically reduce extreme uncertainty when navigating vast information landscapes. Based on this insight, we introduce WebSailor, a complete post-training methodology designed to instill this crucial capability. Our approach involves generating novel, high-uncertainty tasks through structured sampling and information obfuscation, RFT cold start, and an efficient agentic RL training algorithm, Duplicating Sampling Policy Optimization (DUPO). With this integrated pipeline, WebSailor significantly outperforms all opensource agents in complex information-seeking tasks, matching proprietary agents' performance and closing the capability gap.",
      "authors": [
        "Kuan Li",
        "Zhongwang Zhang",
        "Huifeng Yin",
        "Liwen Zhang",
        "Litu Ou",
        "Jialong Wu",
        "Wenbiao Yin",
        "Baixuan Li",
        "Zhengwei Tao",
        "Xinyu Wang",
        "Weizhou Shen",
        "Junkai Zhang",
        "Dingchu Zhang",
        "Xixi Wu",
        "Yong Jiang",
        "Ming Yan",
        "Pengjun Xie",
        "Fei Huang",
        "Jingren Zhou"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T12:59:07+00:00",
          "link": "https://arxiv.org/abs/2507.02592v1",
          "size": "958kb",
          "version": "v1"
        }
      ],
      "title": "WebSailor: Navigating Super-human Reasoning for Web Agent",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02592",
        "PDF": "https://arxiv.org/pdf/2507.02592"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper presents a post-training methodology for LLMs involving generating novel tasks and a training algorithm, which directly pertains to training-stage data processing and enhancing LLM capabilities."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02593",
      "abstract": "Access to high-quality labeled data remains a limiting factor in applied supervised learning. While label variation (LV), i.e., differing labels for the same instance, is common, especially in natural language processing, annotation frameworks often still rest on the assumption of a single ground truth. This overlooks human label variation (HLV), the occurrence of plausible differences in annotations, as an informative signal. Similarly, active learning (AL), a popular approach to optimizing the use of limited annotation budgets in training ML models, often relies on at least one of several simplifying assumptions, which rarely hold in practice when acknowledging HLV. In this paper, we examine foundational assumptions about truth and label nature, highlighting the need to decompose observed LV into signal (e.g., HLV) and noise (e.g., annotation error). We survey how the AL and (H)LV communities have addressed -- or neglected -- these distinctions and propose a conceptual framework for incorporating HLV throughout the AL loop, including instance selection, annotator choice, and label representation. We further discuss the integration of large language models (LLM) as annotators. Our work aims to lay a conceptual foundation for HLV-aware active learning, better reflecting the complexities of real-world annotation.",
      "authors": [
        "Cornelia Gruber and Helen Alber and Bernd Bischl and G\\\"oran Kauermann and Barbara Plank and Matthias A{\\ss}enmacher"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T12:59:28+00:00",
          "link": "https://arxiv.org/abs/2507.02593v1",
          "size": "131kb",
          "version": "v1"
        }
      ],
      "title": "Revisiting Active Learning under (Human) Label Variation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02593",
        "HTML": "https://arxiv.org/html/2507.02593v1",
        "PDF": "https://arxiv.org/pdf/2507.02593"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses active learning and data labeling, mentioning the use of LLMs as annotators, without directly proposing novel data processing methods for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02595",
      "abstract": "Multiperspective Fusion (MPF) is a novel posttraining alignment framework for large language models (LLMs) developed in response to the growing need for easy bias mitigation. Built on top of the SAGED pipeline, an automated system for constructing bias benchmarks and extracting interpretable baseline distributions, MPF leverages multiperspective generations to expose and align biases in LLM outputs with nuanced, humanlike baselines. By decomposing baseline, such as sentiment distributions from HR professionals, into interpretable perspective components, MPF guides generation through sampling and balancing of responses, weighted by the probabilities obtained in the decomposition. Empirically, we demonstrate its ability to align LLM sentiment distributions with both counterfactual baselines (absolute equality) and the HR baseline (biased for Top Univeristy), resulting in small KL divergence, reduction of calibration error and generalization to unseen questions. This shows that MPF offers a scalable and interpretable method for alignment and bias mitigation, compatible with deployed LLMs and requiring no extensive prompt engineering or finetuning.",
      "authors": [
        "Xin Guan",
        "PeiHsin Lin",
        "Zekun Wu",
        "Ze Wang",
        "Ruibo Zhang",
        "Emre Kazim",
        "Adriano Koshiyama"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T13:09:18+00:00",
          "link": "https://arxiv.org/abs/2507.02595v1",
          "size": "26432kb",
          "version": "v1"
        }
      ],
      "title": "MPF: Aligning and Debiasing Language Models post Deployment via Multi Perspective Fusion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02595",
        "PDF": "https://arxiv.org/pdf/2507.02595"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper introduces a posttraining alignment framework for LLMs to mitigate bias, involving nuanced data processing and alignment of bias distributions, relevant to training-stage data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02598",
      "abstract": "Arithmetic circuits, such as adders and multipliers, are fundamental components of digital systems, directly impacting the performance, power efficiency, and area footprint. However, optimizing these circuits remains challenging due to the vast design space and complex physical constraints. While recent deep learning-based approaches have shown promise, they struggle to consistently explore high-potential design variants, limiting their optimization efficiency. To address this challenge, we propose AC-Refiner, a novel arithmetic circuit optimization framework leveraging conditional diffusion models. Our key insight is to reframe arithmetic circuit synthesis as a conditional image generation task. By carefully conditioning the denoising diffusion process on target quality-of-results (QoRs), AC-Refiner consistently produces high-quality circuit designs. Furthermore, the explored designs are used to fine-tune the diffusion model, which focuses the exploration near the Pareto frontier. Experimental results demonstrate that AC-Refiner generates designs with superior Pareto optimality, outperforming state-of-the-art baselines. The performance gain is further validated by integrating AC-Refiner into practical applications.",
      "authors": [
        "Chenhao Xue",
        "Kezhi Li",
        "Jiaxing Zhang",
        "Yi Ren",
        "Zhengyuan Shi",
        "Chen Zhang",
        "Yibo Lin",
        "Lining Zhang",
        "Qiang Xu",
        "Guangyu Sun"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T13:21:33+00:00",
          "link": "https://arxiv.org/abs/2507.02598v1",
          "size": "915kb",
          "version": "v1"
        }
      ],
      "title": "AC-Refiner: Efficient Arithmetic Circuit Optimization Using Conditional Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02598",
        "HTML": "https://arxiv.org/html/2507.02598v1",
        "PDF": "https://arxiv.org/pdf/2507.02598"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on optimizing arithmetic circuits using deep learning, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02599",
      "abstract": "Purpose: The primary aim of this study is to enhance fault diagnosis in induction machines by leveraging the Pad\\'e Approximant Neuron (PAON) model. While accelerometers and microphones are standard in motor condition monitoring, deep learning models with nonlinear neuron architectures offer promising improvements in diagnostic performance. This research addresses the question: Can Pad\\'e Approximant Neural Networks (Pad\\'eNets) outperform conventional Convolutional Neural Networks (CNNs) and Self-Organized Operational Neural Networks (Self-ONNs) in diagnosing electrical and mechanical faults using vibration and acoustic data?\n  Methods: We evaluate and compare the diagnostic capabilities of three deep learning architectures: one-dimensional CNNs, Self-ONNs, and Pad\\'eNets. These models are tested on the University of Ottawa's publicly available constant-speed induction motor datasets, which include both vibration and acoustic sensor data. The Pad\\'eNet model is designed to introduce enhanced nonlinearity and is compatible with unbounded activation functions such as Leaky ReLU.\n  Results and Conclusion: Pad\\'eNets consistently outperformed the baseline models, achieving diagnostic accuracies of 99.96%, 98.26%, 97.61%, and 98.33% for accelerometers 1, 2, 3, and the acoustic sensor, respectively. The enhanced nonlinearity of Pad\\'eNets, together with their compatibility with unbounded activation functions, significantly improves fault diagnosis performance in induction motor condition monitoring.",
      "authors": [
        "Sertac Kilickaya and Levent Eren"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Sound (cs.SD)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T13:21:45+00:00",
          "link": "https://arxiv.org/abs/2507.02599v1",
          "size": "2253kb",
          "version": "v1"
        }
      ],
      "title": "Pad\\'e Approximant Neural Networks for Enhanced Electric Motor Fault Diagnosis Using Vibration and Acoustic Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02599",
        "HTML": "https://arxiv.org/html/2507.02599v1",
        "PDF": "https://arxiv.org/pdf/2507.02599"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research is centered around neural networks for fault diagnosis in electric motors, unrelated to LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02600",
      "abstract": "Articulated object manipulation remains a critical challenge in robotics due to the complex kinematic constraints and the limited physical reasoning of existing methods. In this work, we introduce ArtGS, a novel framework that extends 3D Gaussian Splatting (3DGS) by integrating visual-physical modeling for articulated object understanding and interaction. ArtGS begins with multi-view RGB-D reconstruction, followed by reasoning with a vision-language model (VLM) to extract semantic and structural information, particularly the articulated bones. Through dynamic, differentiable 3DGS-based rendering, ArtGS optimizes the parameters of the articulated bones, ensuring physically consistent motion constraints and enhancing the manipulation policy. By leveraging dynamic Gaussian splatting, cross-embodiment adaptability, and closed-loop optimization, ArtGS establishes a new framework for efficient, scalable, and generalizable articulated object modeling and manipulation. Experiments conducted in both simulation and real-world environments demonstrate that ArtGS significantly outperforms previous methods in joint estimation accuracy and manipulation success rates across a variety of articulated objects. Additional images and videos are available on the project website: https://sites.google.com/view/artgs/home",
      "authors": [
        "Qiaojun Yu",
        "Xibin Yuan",
        "Yu jiang",
        "Junting Chen",
        "Dongzhe Zheng",
        "Ce Hao",
        "Yang You",
        "Yixing Chen",
        "Yao Mu",
        "Liu Liu",
        "Cewu Lu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T13:22:18+00:00",
          "link": "https://arxiv.org/abs/2507.02600v1",
          "size": "1298kb",
          "version": "v1"
        }
      ],
      "title": "ArtGS:3D Gaussian Splatting for Interactive Visual-Physical Modeling and Manipulation of Articulated Objects",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02600",
        "HTML": "https://arxiv.org/html/2507.02600v1",
        "PDF": "https://arxiv.org/pdf/2507.02600"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a framework for modeling and manipulating articulated objects using 3D Gaussian splatting and vision-language models, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02602",
      "abstract": "The increasing importance of Vision-Based Navigation (VBN) algorithms in space missions raises numerous challenges in ensuring their reliability and operational robustness. Sensor faults can lead to inaccurate outputs from navigation algorithms or even complete data processing faults, potentially compromising mission objectives. Artificial Intelligence (AI) offers a powerful solution for detecting such faults, overcoming many of the limitations associated with traditional fault detection methods. However, the primary obstacle to the adoption of AI in this context is the lack of sufficient and representative datasets containing faulty image data.\n  This study addresses these challenges by focusing on an interplanetary exploration mission scenario. A comprehensive analysis of potential fault cases in camera sensors used within the VBN pipeline is presented. The causes and effects of these faults are systematically characterized, including their impact on image quality and navigation algorithm performance, as well as commonly employed mitigation strategies. To support this analysis, a simulation framework is introduced to recreate faulty conditions in synthetically generated images, enabling a systematic and controlled reproduction of faulty data. The resulting dataset of fault-injected images provides a valuable tool for training and testing AI-based fault detection algorithms. The final link to the dataset will be added after an embargo period. For peer-reviewers, this private link is available.",
      "authors": [
        "Riccardo Gallon",
        "Fabian Schiemenz",
        "Alessandra Menicucci",
        "Eberhard Gill"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T13:23:22+00:00",
          "link": "https://arxiv.org/abs/2507.02602v1",
          "size": "7073kb",
          "version": "v1"
        }
      ],
      "title": "Addressing Camera Sensors Faults in Vision-Based Navigation: Simulation and Dataset Development",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02602",
        "HTML": "https://arxiv.org/html/2507.02602v1",
        "PDF": "https://arxiv.org/pdf/2507.02602"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses the development of a dataset for fault detection in Vision-Based Navigation, which involves dataset creation, but it is intended for AI in navigation, not LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02606",
      "abstract": "The rapid advancement of speech generation models has heightened privacy and security concerns related to voice cloning (VC). Recent studies have investigated disrupting unauthorized voice cloning by introducing adversarial perturbations. However, determined attackers can mitigate these protective perturbations and successfully execute VC. In this study, we conduct the first systematic evaluation of these protective perturbations against VC under realistic threat models that include perturbation purification. Our findings reveal that while existing purification methods can neutralize a considerable portion of the protective perturbations, they still lead to distortions in the feature space of VC models, which degrades the performance of VC. From this perspective, we propose a novel two-stage purification method: (1) Purify the perturbed speech; (2) Refine it using phoneme guidance to align it with the clean speech distribution. Experimental results demonstrate that our method outperforms state-of-the-art purification methods in disrupting VC defenses. Our study reveals the limitations of adversarial perturbation-based VC defenses and underscores the urgent need for more robust solutions to mitigate the security and privacy risks posed by VC. The code and audio samples are available at https://de-antifake.github.io.",
      "authors": [
        "Wei Fan",
        "Kejiang Chen",
        "Chang Liu",
        "Weiming Zhang",
        "Nenghai Yu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T13:30:58+00:00",
          "link": "https://arxiv.org/abs/2507.02606v1",
          "size": "4104kb",
          "version": "v1"
        }
      ],
      "title": "De-AntiFake: Rethinking the Protective Perturbations Against Voice Cloning Attacks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02606",
        "HTML": "https://arxiv.org/html/2507.02606v1",
        "PDF": "https://arxiv.org/pdf/2507.02606"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper evaluates protective perturbations against voice cloning attacks and proposes a purification method, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02607",
      "abstract": "The digital evolution of connected vehicles and the subsequent security risks emphasize the critical need for implementing in-vehicle cyber security measures such as intrusion detection and response systems. The continuous advancement of attack scenarios further highlights the need for adaptive detection mechanisms that can detect evolving, unknown, and complex threats. The effective use of ML-driven techniques can help address this challenge. However, constraints on implementing diverse attack scenarios on test vehicles due to safety, cost, and ethical considerations result in a scarcity of data representing attack scenarios. This limitation necessitates alternative efficient and effective methods for generating high-quality attack-representing data. This paper presents a context-aware attack data generator that generates attack inputs and corresponding in-vehicle network log, i.e., controller area network (CAN) log, representing various types of attack including denial of service (DoS), fuzzy, spoofing, suspension, and replay attacks. It utilizes parameterized attack models augmented with CAN message decoding and attack intensity adjustments to configure the attack scenarios with high similarity to real-world scenarios and promote variability. We evaluate the practicality of the generated attack-representing data within an intrusion detection system (IDS) case study, in which we develop and perform an empirical evaluation of two deep neural network IDS models using the generated data. In addition to the efficiency and scalability of the approach, the performance results of IDS models, high detection and classification capabilities, validate the consistency and effectiveness of the generated data as well. In this experience study, we also elaborate on the aspects influencing the fidelity of the data to real-world scenarios and provide insights into its application.",
      "authors": [
        "Frida Sundfeldt",
        "Bianca Widstam",
        "Mahshid Helali Moghadam",
        "Kuo-Yun Liang",
        "Anders Vesterberg"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T13:31:33+00:00",
          "link": "https://arxiv.org/abs/2507.02607v1",
          "size": "3695kb",
          "version": "v1"
        }
      ],
      "title": "Alleviating Attack Data Scarcity: SCANIA's Experience Towards Enhancing In-Vehicle Cyber Security Measures",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02607",
        "HTML": "https://arxiv.org/html/2507.02607v1",
        "PDF": "https://arxiv.org/pdf/2507.02607"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses generating high-quality attack data to simulate various attack scenarios for vehicle security, which involves data generation but is specific to intrusion detection, not LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02608",
      "abstract": "The steep computational cost of diffusion models at inference hinders their use as fast physics emulators. In the context of image and video generation, this computational drawback has been addressed by generating in the latent space of an autoencoder instead of the pixel space. In this work, we investigate whether a similar strategy can be effectively applied to the emulation of dynamical systems and at what cost. We find that the accuracy of latent-space emulation is surprisingly robust to a wide range of compression rates (up to 1000x). We also show that diffusion-based emulators are consistently more accurate than non-generative counterparts and compensate for uncertainty in their predictions with greater diversity. Finally, we cover practical design choices, spanning from architectures to optimizers, that we found critical to train latent-space emulators.",
      "authors": [
        "Fran\\c{c}ois Rozet",
        "Ruben Ohana",
        "Michael McCabe",
        "Gilles Louppe",
        "Fran\\c{c}ois Lanusse",
        "Shirley Ho"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Fluid Dynamics (physics.flu-dyn)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T13:32:50+00:00",
          "link": "https://arxiv.org/abs/2507.02608v1",
          "size": "22560kb",
          "version": "v1"
        }
      ],
      "title": "Lost in Latent Space: An Empirical Study of Latent Diffusion Models for Physics Emulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02608",
        "HTML": "https://arxiv.org/html/2507.02608v1",
        "PDF": "https://arxiv.org/pdf/2507.02608"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on using latent diffusion models for physics emulation, which does not pertain to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02613",
      "abstract": "This paper presents a complete signal-processing chain for multistatic integrated sensing and communications (ISAC) using 5G Positioning Reference Signal (PRS). We consider a distributed architecture in which one gNB transmits a periodic OFDM-PRS waveform while multiple spatially separated receivers exploit the same signal for target detection, parameter estimation and tracking. A coherent cross-ambiguity function (CAF) is evaluated to form a range-Doppler map from which the bistatic delay and radial velocity are extracted for every target. For a single target, the resulting bistatic delays are fused through nonlinear least-squares trilateration, yielding a geometric position estimate, and a regularized linear inversion of the radial-speed equations yields a two-dimensional velocity vector, where speed and heading are obtained. The approach is applied to 2D and 3D settings, extended to account for time synchronization bias, and generalized to multiple targets by resolving target association. The sequence of position-velocity estimates is then fed to standard and extended Kalman filters to obtain smoothed tracks. Our results show high-fidelity moving-target detection, positioning, and tracking using 5G PRS signals for multistatic ISAC.",
      "authors": [
        "Yalin E. Sagduyu",
        "Kemal Davaslioglu",
        "Tugba Erpek",
        "Sastry Kompella",
        "Gustave Anderson",
        "Jonathan Ashdown"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T13:38:19+00:00",
          "link": "https://arxiv.org/abs/2507.02613v1",
          "size": "240kb",
          "version": "v1"
        }
      ],
      "title": "MULTI-SCOUT: Multistatic Integrated Sensing and Communications in 5G and Beyond for Moving Target Detection, Positioning, and Tracking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02613",
        "HTML": "https://arxiv.org/html/2507.02613v1",
        "PDF": "https://arxiv.org/pdf/2507.02613"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on signal processing for 5G multistatic integrated sensing and communications, with no mention of LLM training data or its processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02616",
      "abstract": "The rise of Large Language Models (LLMs) has enabled the development of specialized AI agents with domain-specific reasoning and interaction capabilities, particularly in healthcare. While recent frameworks simulate medical decision-making, they largely focus on single-turn tasks where a doctor agent receives full case information upfront -- diverging from the real-world diagnostic process, which is inherently uncertain, interactive, and iterative. In this paper, we introduce MIMIC-Patient, a structured dataset built from the MIMIC-III electronic health records (EHRs), designed to support dynamic, patient-level simulations. Building on this, we propose DynamiCare, a novel dynamic multi-agent framework that models clinical diagnosis as a multi-round, interactive loop, where a team of specialist agents iteratively queries the patient system, integrates new information, and dynamically adapts its composition and strategy. We demonstrate the feasibility and effectiveness of DynamiCare through extensive experiments, establishing the first benchmark for dynamic clinical decision-making with LLM-powered agents.",
      "authors": [
        "Tianqi Shang",
        "Weiqing He",
        "Charles Zheng",
        "Lingyao Li",
        "Li Shen",
        "Bingxin Zhao"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T13:43:10+00:00",
          "link": "https://arxiv.org/abs/2507.02616v1",
          "size": "1710kb",
          "version": "v1"
        }
      ],
      "title": "DynamiCare: A Dynamic Multi-Agent Framework for Interactive and Open-Ended Medical Decision-Making",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02616",
        "HTML": "https://arxiv.org/html/2507.02616v1",
        "PDF": "https://arxiv.org/pdf/2507.02616"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces a novel dataset (MIMIC-Patient) and a framework (DynamiCare) for interactive medical decision-making using LLMs. The creation of MIMIC-Patient as a structured dataset directly pertains to data construction and preprocessing for domain-specific LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02618",
      "abstract": "Are Large Language Models (LLMs) a new form of strategic intelligence, able to reason about goals in competitive settings? We present compelling supporting evidence. The Iterated Prisoner's Dilemma (IPD) has long served as a model for studying decision-making. We conduct the first ever series of evolutionary IPD tournaments, pitting canonical strategies (e.g., Tit-for-Tat, Grim Trigger) against agents from the leading frontier AI companies OpenAI, Google, and Anthropic. By varying the termination probability in each tournament (the \"shadow of the future\"), we introduce complexity and chance, confounding memorisation.\n  Our results show that LLMs are highly competitive, consistently surviving and sometimes even proliferating in these complex ecosystems. Furthermore, they exhibit distinctive and persistent \"strategic fingerprints\": Google's Gemini models proved strategically ruthless, exploiting cooperative opponents and retaliating against defectors, while OpenAI's models remained highly cooperative, a trait that proved catastrophic in hostile environments. Anthropic's Claude emerged as the most forgiving reciprocator, showing remarkable willingness to restore cooperation even after being exploited or successfully defecting. Analysis of nearly 32,000 prose rationales provided by the models reveals that they actively reason about both the time horizon and their opponent's likely strategy, and we demonstrate that this reasoning is instrumental to their decisions. This work connects classic game theory with machine psychology, offering a rich and granular view of algorithmic decision-making under uncertainty.",
      "authors": [
        "Kenneth Payne and Baptiste Alloui-Cros"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T13:45:02+00:00",
          "link": "https://arxiv.org/abs/2507.02618v1",
          "size": "4102kb",
          "version": "v1"
        }
      ],
      "title": "Strategic Intelligence in Large Language Models: Evidence from evolutionary Game Theory",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02618",
        "HTML": "https://arxiv.org/html/2507.02618v1",
        "PDF": "https://arxiv.org/pdf/2507.02618"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "Although this paper analyzes LLMs' strategic intelligence in game theory settings, it does not address any aspect of LLM training data collection, construction, or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02619",
      "abstract": "In this paper, we propose a novel model called Learnable VAE (L-VAE), which learns a disentangled representation together with the hyperparameters of the cost function. L-VAE can be considered as an extension of \\b{eta}-VAE, wherein the hyperparameter, \\b{eta}, is empirically adjusted. L-VAE mitigates the limitations of \\b{eta}-VAE by learning the relative weights of the terms in the loss function to control the dynamic trade-off between disentanglement and reconstruction losses. In the proposed model, the weight of the loss terms and the parameters of the model architecture are learned concurrently. An additional regularization term is added to the loss function to prevent bias towards either reconstruction or disentanglement losses. Experimental analyses show that the proposed L-VAE finds an effective balance between reconstruction fidelity and disentangling the latent dimensions. Comparisons of the proposed L-VAE against \\b{eta}-VAE, VAE, ControlVAE, DynamicVAE, and {\\sigma}-VAE on datasets, such as dSprites, MPI3D-complex, Falcor3D, and Isaac3D reveals that L-VAE consistently provides the best or the second best performances measured by a set of disentanglement metrics. Moreover, qualitative experiments on CelebA dataset, confirm the success of the L-VAE model for disentangling the facial attributes.",
      "authors": [
        "Hazal Mogultay Ozcan",
        "Sinan Kalkan",
        "Fatos T. Yarman-Vural"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T13:45:42+00:00",
          "link": "https://arxiv.org/abs/2507.02619v1",
          "size": "3018kb",
          "version": "v1"
        }
      ],
      "title": "L-VAE: Variational Auto-Encoder with Learnable Beta for Disentangled Representation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02619",
        "HTML": "https://arxiv.org/html/2507.02619v1",
        "PDF": "https://arxiv.org/pdf/2507.02619"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on variational auto-encoders (VAEs) for disentangled representation learning, rather than on LLM training data or its processing. It does not discuss concepts related to LLM data engineering or processing stages."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02620",
      "abstract": "Distributed inference serves as a promising approach to enabling the inference of large language models (LLMs) at the network edge. It distributes the inference process to multiple devices to ensure that the LLMs can fit into the device memory. Recent pipeline-based approaches have the potential to parallelize communication and computation, which helps reduce inference latency. However, the benefit diminishes when the inference request at the network edge is sparse, where pipeline is typically at low utilization. To enable efficient distributed LLM inference at the edge, we propose \\textbf{FlowSpec}, a pipeline-parallel tree-based speculative decoding framework. FlowSpec incorporates three key mechanisms to improve decoding efficiency: 1) score-based step-wise verification prioritizes more important draft tokens to bring earlier accpeted tokens; 2) efficient draft management to prune invalid tokens while maintaining correct causal relationship during verification; 3) dynamic draft expansion strategies to supply high-quality speculative inputs. These techniques work in concert to enhance both pipeline utilization and speculative efficiency. We evaluate FlowSpec on a real-world testbed with other baselines. Experimental results demonstrate that our proposed framework significantly improves inference speed across diverse models and configurations, achieving speedup ratios 1.36$\\times$-1.77$\\times$ compared to baselines. Our code is publicly available at \\href{https://github.com/Leosang-lx/FlowSpec#}{https://github.com/Leosang-lx/FlowSpec\\#}",
      "authors": [
        "Xing Liu",
        "Lizhuo Luo",
        "Ming Tang",
        "Chao Huang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T13:47:42+00:00",
          "link": "https://arxiv.org/abs/2507.02620v1",
          "size": "1105kb",
          "version": "v1"
        }
      ],
      "title": "FlowSpec: Continuous Pipelined Speculative Decoding for Efficient Distributed LLM Inference",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02620",
        "HTML": "https://arxiv.org/html/2507.02620v1",
        "PDF": "https://arxiv.org/pdf/2507.02620"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "FlowSpec addresses efficient distributed inference for LLMs, focusing on computational frameworks and speculative decoding, rather than the processing of data for training large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02624",
      "abstract": "Variant effect predictors (VEPs) aim to assess the functional impact of protein variants, traditionally relying on multiple sequence alignments (MSAs). This approach assumes that naturally occurring variants are fit, an assumption challenged by pharmacogenomics, where some pharmacogenes experience low evolutionary pressure. Deep mutational scanning (DMS) datasets provide an alternative by offering quantitative fitness scores for variants. In this work, we propose a transformer-based matrix variational auto-encoder (matVAE) with a structured prior and evaluate its performance on 33 DMS datasets corresponding to 26 drug target and ADME proteins from the ProteinGym benchmark. Our model trained on MSAs (matVAE-MSA) outperforms the state-of-the-art DeepSequence model in zero-shot prediction on DMS datasets, despite using an order of magnitude fewer parameters and requiring less computation at inference time. We also compare matVAE-MSA to matENC-DMS, a model of similar capacity trained on DMS data, and find that the latter performs better on supervised prediction tasks. Additionally, incorporating AlphaFold-generated structures into our transformer model further improves performance, achieving results comparable to DeepSequence trained on MSAs and finetuned on DMS. These findings highlight the potential of DMS datasets to replace MSAs without significant loss in predictive performance, motivating further development of DMS datasets and exploration of their relationships to enhance variant effect prediction.",
      "authors": [
        "Antoine Honor\\'e",
        "Borja Rodr\\'iguez G\\'alvez",
        "Yoomi Park",
        "Yitian Zhou",
        "Volker M. Lauschke",
        "Ming Xiao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T13:50:18+00:00",
          "link": "https://arxiv.org/abs/2507.02624v1",
          "size": "593kb",
          "version": "v1"
        }
      ],
      "title": "A Matrix Variational Auto-Encoder for Variant Effect Prediction in Pharmacogenes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02624",
        "HTML": "https://arxiv.org/html/2507.02624v1",
        "PDF": "https://arxiv.org/pdf/2507.02624"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work concerns variant effect prediction using a matrix variational auto-encoder, with no mention of training data processing for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02626",
      "abstract": "Owing to powerful natural language processing and generative capabilities, large language model (LLM) agents have emerged as a promising solution for enhancing recommendation systems via user simulation. However, in the realm of video recommendation, existing studies predominantly resort to prompt-based simulation using frozen LLMs and encounter the intricate challenge of multimodal content understanding. This frequently results in suboptimal item modeling and user preference learning, thereby ultimately constraining recommendation performance. To address these challenges, we introduce VRAgent-R1, a novel agent-based paradigm that incorporates human-like intelligence in user simulation. Specifically, VRAgent-R1 comprises two distinct agents: the Item Perception (IP) Agent and the User Simulation (US) Agent, designed for interactive user-item modeling. Firstly, the IP Agent emulates human-like progressive thinking based on MLLMs, effectively capturing hidden recommendation semantics in videos. With a more comprehensive multimodal content understanding provided by the IP Agent, the video recommendation system is equipped to provide higher-quality candidate items. Subsequently, the US Agent refines the recommended video sets based on in-depth chain-of-thought (CoT) reasoning and achieves better alignment with real user preferences through reinforcement learning. Experimental results on a large-scale video recommendation benchmark have demonstrated the effectiveness of our proposed VRAgent-R1 method, e.g., the IP Agent achieves a 6.0\\% improvement in NDCG@10 on the MicroLens-100k dataset, while the US Agent shows approximately 45.0\\% higher accuracy in user decision simulation compared to state-of-the-art baselines.",
      "authors": [
        "Siran Chen",
        "Boyu Chen",
        "Chenyun Yu",
        "Yuxiao Luo",
        "Ouyang Yi",
        "Lei Cheng",
        "Chengxiang Zhuo",
        "Zang Li",
        "Yali Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T13:52:24+00:00",
          "link": "https://arxiv.org/abs/2507.02626v1",
          "size": "17300kb",
          "version": "v1"
        }
      ],
      "title": "VRAgent-R1: Boosting Video Recommendation with MLLM-based Agents via Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02626",
        "HTML": "https://arxiv.org/html/2507.02626v1",
        "PDF": "https://arxiv.org/pdf/2507.02626"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses enhancing recommendation systems with LLMs, including aspects of multimodal content understanding, but does not primarily contribute to LLM training data processing methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02628",
      "abstract": "Background: The use of Electronic Health Records (EHRs) for epidemiological studies and artificial intelligence (AI) training is increasing rapidly. The reliability of the results depends on the accuracy and completeness of EHR data. However, EHR data often contain significant quality issues, including misrepresentations of subpopulations, biases, and systematic errors, as they are primarily collected for clinical and billing purposes. Existing quality assessment methods remain insufficient, lacking systematic procedures to assess data fitness for research.\n  Methods: We present the Medical Data Pecking approach, which adapts unit testing and coverage concepts from software engineering to identify data quality concerns. We demonstrate our approach using the Medical Data Pecking Tool (MDPT), which consists of two main components: (1) an automated test generator that uses large language models and grounding techniques to create a test suite from data and study descriptions, and (2) a data testing framework that executes these tests, reporting potential errors and coverage.\n  Results: We evaluated MDPT on three datasets: All of Us (AoU), MIMIC-III, and SyntheticMass, generating 55-73 tests per cohort across four conditions. These tests correctly identified 20-43 non-aligned or non-conforming data issues. We present a detailed analysis of the LLM-generated test suites in terms of reference grounding and value accuracy.\n  Conclusion: Our approach incorporates external medical knowledge to enable context-sensitive data quality testing as part of the data analysis workflow to improve the validity of its outcomes. Our approach tackles these challenges from a quality assurance perspective, laying the foundation for further development such as additional data modalities and improved grounding methods.",
      "authors": [
        "Irena Girshovitz",
        "Atai Ambus",
        "Moni Shahar",
        "Ran Gilad-Bachrach"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T13:54:50+00:00",
          "link": "https://arxiv.org/abs/2507.02628v1",
          "size": "360kb",
          "version": "v1"
        }
      ],
      "title": "Medical Data Pecking: A Context-Aware Approach for Automated Quality Evaluation of Structured Medical Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02628",
        "HTML": "https://arxiv.org/html/2507.02628v1",
        "PDF": "https://arxiv.org/pdf/2507.02628"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces a novel LLM-based approach for quality evaluation of structured medical data, directly addressing data quality enhancement, which is a critical aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02634",
      "abstract": "We introduce a new hierarchical deep learning framework for recursive higher-order meta-learning that enables neural networks (NNs) to construct, solve, and generalise across hierarchies of tasks. Central to this approach is a generative mechanism that creates \\emph{virtual tasks} -- synthetic problem instances designed to enable the meta-learner to learn \\emph{soft constraints} and unknown generalisable rules across related tasks. Crucially, this enables the framework to generate its own informative, task-grounded datasets thereby freeing machine learning (ML) training from the limitations of relying entirely on human-generated data. By actively exploring the virtual point landscape and seeking out tasks lower-level learners find difficult, the meta-learner iteratively refines constraint regions. This enhances inductive biases, regularises the adaptation process, and produces novel, unanticipated tasks and constraints required for generalisation. Each meta-level of the hierarchy corresponds to a progressively abstracted generalisation of problems solved at lower levels, enabling a structured and interpretable learning progression. By interpreting meta-learners as category-theoretic \\emph{functors} that generate and condition a hierarchy of subordinate learners, we establish a compositional structure that supports abstraction and knowledge transfer across progressively generalised tasks. The category-theoretic perspective unifies existing meta-learning models and reveals how learning processes can be transformed and compared through functorial relationships, while offering practical design principles for structuring meta-learning. We speculate this architecture may underpin the next generation of NNs capable of autonomously generating novel, instructive tasks and their solutions, thereby advancing ML towards general artificial intelligence.",
      "authors": [
        "David H. Mguni"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T14:01:14+00:00",
          "link": "https://arxiv.org/abs/2507.02634v1",
          "size": "1288kb",
          "version": "v1"
        }
      ],
      "title": "High-Order Deep Meta-Learning with Category-Theoretic Interpretation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02634",
        "PDF": "https://arxiv.org/pdf/2507.02634"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research focuses on hierarchical deep learning and meta-learning frameworks, not specifically on LLM training data processing methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02635",
      "abstract": "Electronic payment platforms are estimated to process billions oftransactions daily, with the cumulative value of these transactionspotentially reaching into the trillions. Even a minor error within thishigh-volume environment could precipitate substantial financiallosses. To mitigate this risk, manually constructed verification rules,developed by domain experts, are typically employed to identifyand scrutinize transactions in production environments. However,due to the absence of a systematic approach to ensure the robust-ness of these verification rules against vulnerabilities, they remainsusceptible to exploitation.To mitigate this risk, manually constructed verification rules, de-veloped by domain experts, are typically employed to identify andscrutinize transactions in production environments. However, dueto the absence of a systematic approach to ensure the robustness ofthese verification rules against vulnerabilities, they remain suscep-tible to exploitation. To ensure data security, database maintainersusually compose complex verification rules to check whether aquery/update request is valid. However, the rules written by ex-perts are usually imperfect, and malicious requests may bypassthese rules. As a result, the demand for identifying the defects ofthe rules systematically emerges.",
      "authors": [
        "Mao Luo",
        "Zhi Wang",
        "Yiwen Huang",
        "Qingyun Zhang",
        "Zhouxing Su",
        "Zhipeng Lv",
        "Wen Hu and Jianguo Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T14:01:26+00:00",
          "link": "https://arxiv.org/abs/2507.02635v1",
          "size": "303kb",
          "version": "v1"
        }
      ],
      "title": "SAT-BO: Verification Rule Learning and Optimization for FraudTransaction Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02635",
        "HTML": "https://arxiv.org/html/2507.02635v1",
        "PDF": "https://arxiv.org/pdf/2507.02635"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on fraud transaction detection using verification rule learning in electronic payment platforms, and does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02639",
      "abstract": "In this work, we address the challenge of data-efficient exploration in reinforcement learning by examining existing principled, information-theoretic approaches to intrinsic motivation. Specifically, we focus on a class of exploration bonuses that targets epistemic uncertainty rather than the aleatoric noise inherent in the environment. We prove that these bonuses naturally signal epistemic information gains and converge to zero once the agent becomes sufficiently certain about the environment's dynamics and rewards, thereby aligning exploration with genuine knowledge gaps. Our analysis provides formal guarantees for IG-based approaches, which previously lacked theoretical grounding. To enable practical use, we also discuss tractable approximations via sparse variational Gaussian Processes, Deep Kernels and Deep Ensemble models. We then outline a general framework - Predictive Trajectory Sampling with Bayesian Exploration (PTS-BE) - which integrates model-based planning with information-theoretic bonuses to achieve sample-efficient deep exploration. We empirically demonstrate that PTS-BE substantially outperforms other baselines across a variety of environments characterized by sparse rewards and/or purely exploratory tasks.",
      "authors": [
        "Alberto Caron",
        "Chris Hicks",
        "Vasilios Mavroudis"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T14:03:47+00:00",
          "link": "https://arxiv.org/abs/2507.02639v1",
          "size": "1479kb",
          "version": "v1"
        }
      ],
      "title": "On Efficient Bayesian Exploration in Model-Based Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02639",
        "HTML": "https://arxiv.org/html/2507.02639v1",
        "PDF": "https://arxiv.org/pdf/2507.02639"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research focuses on efficient exploration in reinforcement learning, specifically exploring intrinsic motivation for epistemic uncertainty, with no relation to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02643",
      "abstract": "The idea of calibrated recommendations is that the properties of the items that are suggested to users should match the distribution of their individual past preferences. Calibration techniques are therefore helpful to ensure that the recommendations provided to a user are not limited to a certain subset of the user's interests. Over the past few years, we have observed an increasing number of research works that use calibration for different purposes, including questions of diversity, biases, and fairness. In this work, we provide a survey on the recent developments in the area of calibrated recommendations. We both review existing technical approaches for calibration and provide an overview on empirical and analytical studies on the effectiveness of calibration for different use cases. Furthermore, we discuss limitations and common challenges when implementing calibration in practice.",
      "authors": [
        "Diego Corr\\^ea da Silva and Dietmar Jannach"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T14:08:10+00:00",
          "link": "https://arxiv.org/abs/2507.02643v1",
          "size": "496kb",
          "version": "v1"
        }
      ],
      "title": "Calibrated Recommendations: Survey and Future Directions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02643",
        "HTML": "https://arxiv.org/html/2507.02643v1",
        "PDF": "https://arxiv.org/pdf/2507.02643"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper surveys calibration techniques for recommender systems, which involves user preference matching, but does not contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02645",
      "abstract": "Deepfake detection models face two critical challenges: generalization to unseen manipulations and demographic fairness among population groups. However, existing approaches often demonstrate that these two objectives are inherently conflicting, revealing a trade-off between them. In this paper, we, for the first time, uncover and formally define a causal relationship between fairness and generalization. Building on the back-door adjustment, we show that controlling for confounders (data distribution and model capacity) enables improved generalization via fairness interventions. Motivated by this insight, we propose Demographic Attribute-insensitive Intervention Detection (DAID), a plug-and-play framework composed of: i) Demographic-aware data rebalancing, which employs inverse-propensity weighting and subgroup-wise feature normalization to neutralize distributional biases; and ii) Demographic-agnostic feature aggregation, which uses a novel alignment loss to suppress sensitive-attribute signals. Across three cross-domain benchmarks, DAID consistently achieves superior performance in both fairness and generalization compared to several state-of-the-art detectors, validating both its theoretical foundation and practical effectiveness.",
      "authors": [
        "Harry Cheng and Ming-Hui Liu and Yangyang Guo and Tianyi Wang and Liqiang Nie and Mohan Kankanhalli"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T14:10:02+00:00",
          "link": "https://arxiv.org/abs/2507.02645v1",
          "size": "1537kb",
          "version": "v1"
        }
      ],
      "title": "Fair Deepfake Detectors Can Generalize",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02645",
        "HTML": "https://arxiv.org/html/2507.02645v1",
        "PDF": "https://arxiv.org/pdf/2507.02645"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a framework for deepfake detection which includes a method for demographic-aware data rebalancing, indicating some involvement in data processing but focused on fairness and generalization rather than LLM training data specifically."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02648",
      "abstract": "The AI industry is exploding in popularity, with increasing attention to potential harms and unwanted consequences. In the current digital ecosystem, AI deployments are often the product of AI supply chains (AISC): networks of outsourced models, data, and tooling through which multiple entities contribute to AI development and distribution. AI supply chains lack the modularity, redundancies, or conventional supply chain practices that enable identification, isolation, and easy correction of failures, exacerbating the already difficult processes of responding to ML-generated harms. As the stakeholders participating in and impacted by AISCs have scaled and diversified, so too have the risks they face. In this stakeholder analysis of AI supply chains, we consider who participates in AISCs, what harms they face, where sources of harm lie, and how market dynamics and power differentials inform the type and probability of remedies. Because AI supply chains are purposely invented and implemented, they may be designed to account for, rather than ignore, the complexities, consequences, and risks of deploying AI systems. To enable responsible design and management of AISCs, we offer a typology of responses to AISC-induced harms: recourse, repair, reparation or prevention. We apply this typology to stakeholders participating in a health-care AISC across three stylized markets $\\unicode{x2013}$ vertical integration, horizontal integration, free market $\\unicode{x2013}$ to illustrate how stakeholder positioning and power within an AISC may shape responses to an experienced harm.",
      "authors": [
        "Aspen K. Hopkins",
        "Isabella Struckman",
        "Kevin Klyman",
        "Susan S. Silbey"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T14:12:43+00:00",
          "link": "https://arxiv.org/abs/2507.02648v1",
          "size": "2838kb",
          "version": "v1"
        }
      ],
      "title": "Recourse, Repair, Reparation, & Prevention: A Stakeholder Analysis of AI Supply Chains",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02648",
        "HTML": "https://arxiv.org/html/2507.02648v1",
        "PDF": "https://arxiv.org/pdf/2507.02648"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a stakeholder analysis of AI supply chains and the associated risks, with no specific emphasis on the processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02652",
      "abstract": "Complex information needs in real-world search scenarios demand deep reasoning and knowledge synthesis across diverse sources, which traditional retrieval-augmented generation (RAG) pipelines struggle to address effectively. Current reasoning-based approaches suffer from a fundamental limitation: they use a single model to handle both high-level planning and detailed execution, leading to inefficient reasoning and limited scalability. In this paper, we introduce HiRA, a hierarchical framework that separates strategic planning from specialized execution. Our approach decomposes complex search tasks into focused subtasks, assigns each subtask to domain-specific agents equipped with external tools and reasoning capabilities, and coordinates the results through a structured integration mechanism. This separation prevents execution details from disrupting high-level reasoning while enabling the system to leverage specialized expertise for different types of information processing. Experiments on four complex, cross-modal deep search benchmarks demonstrate that HiRA significantly outperforms state-of-the-art RAG and agent-based systems. Our results show improvements in both answer quality and system efficiency, highlighting the effectiveness of decoupled planning and execution for multi-step information seeking tasks. Our code is available at https://github.com/ignorejjj/HiRA.",
      "authors": [
        "Jiajie Jin",
        "Xiaoxi Li",
        "Guanting Dong",
        "Yuyao Zhang",
        "Yutao Zhu",
        "Yang Zhao",
        "Hongjin Qian",
        "Zhicheng Dou"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T14:18:08+00:00",
          "link": "https://arxiv.org/abs/2507.02652v1",
          "size": "701kb",
          "version": "v1"
        }
      ],
      "title": "Decoupled Planning and Execution: A Hierarchical Reasoning Framework for Deep Search",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02652",
        "PDF": "https://arxiv.org/pdf/2507.02652"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a framework for hierarchical reasoning in search tasks, which is unrelated to the collection or processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02654",
      "abstract": "High-Bandwidth Memory (HBM) delivers exceptional bandwidth and energy efficiency for AI workloads, but its high cost per bit, driven in part by stringent on-die reliability requirements, poses a growing barrier to scalable deployment. This work explores a system-level approach to cost reduction by eliminating on-die ECC and shifting all fault management to the memory controller. We introduce a domain-specific ECC framework combining large-codeword Reed--Solomon~(RS) correction with lightweight fine-grained CRC detection, differential parity updates to mitigate write amplification, and tunable protection based on data importance. Our evaluation using LLM inference workloads shows that, even under raw HBM bit error rates up to $10^{-3}$, the system retains over 78\\% of throughput and 97\\% of model accuracy compared with systems equipped with ideal error-free HBM. By treating reliability as a tunable system parameter rather than a fixed hardware constraint, our design opens a new path toward low-cost, high-performance HBM deployment in AI infrastructure.",
      "authors": [
        "Rui Xie",
        "Asad Ul Haq",
        "Yunhua Fang",
        "Linsen Ma",
        "Sanchari Sen",
        "Swagath Venkataramani",
        "Liu Liu",
        "Tong Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T14:18:41+00:00",
          "link": "https://arxiv.org/abs/2507.02654v1",
          "size": "244kb",
          "version": "v1"
        }
      ],
      "title": "Breaking the HBM Bit Cost Barrier: Domain-Specific ECC for AI Inference Infrastructure",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02654",
        "HTML": "https://arxiv.org/html/2507.02654v1",
        "PDF": "https://arxiv.org/pdf/2507.02654"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores memory architectures for AI inference workloads, which does not involve the processing or preparation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02655",
      "abstract": "Many elliptic boundary value problems exhibit an interior regularity property, which can be exploited to construct local approximation spaces that converge exponentially within function spaces satisfying this property. These spaces can be used to define local ansatz spaces within the framework of generalised finite element methods, leading to a better relation between dimensionality and convergence order. In this paper, we present a new technique for the construction of such spaces for Lipschitz domains. Instead of the commonly used approach based on eigenvalue problems it relies on extensions of approximations performed on the boundary. Hence, it improves the influence of the spatial dimension on the exponential convergence and allows to construct the local spaces by solving the original kind of variational problems on easily structured domains.",
      "authors": [
        "S. Aziz and M. Bauer and M. Bebendorf and T. Rau"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T14:18:48+00:00",
          "link": "https://arxiv.org/abs/2507.02655v1",
          "size": "1908kb",
          "version": "v1"
        }
      ],
      "title": "On low-dimensional approximation of function spaces of interior regularity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02655",
        "HTML": "https://arxiv.org/html/2507.02655v1",
        "PDF": "https://arxiv.org/pdf/2507.02655"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a technique for constructing approximation spaces in finite element methods, and does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02657",
      "abstract": "In the knapsack problem under explorable uncertainty, we are given a knapsack instance with uncertain item profits. Instead of having access to the precise profits, we are only given uncertainty intervals that are guaranteed to contain the corresponding profits. The actual item profit can be obtained via a query. The goal of the problem is to adaptively query item profits until the revealed information suffices to compute an optimal (or approximate) solution to the underlying knapsack instance. Since queries are costly, the objective is to minimize the number of queries.\n  In the offline variant of this problem, we assume knowledge of the precise profits and the task is to compute a query set of minimum cardinality that a third party without access to the profits could use to identify an optimal (or approximate) knapsack solution. We show that this offline variant is complete for the second-level of the polynomial hierarchy, i.e., $\\Sigma_2^p$-complete, and cannot be approximated within a non-trivial factor unless $\\Sigma_2^p = \\Delta_2^p$. Motivated by these strong hardness results, we consider a resource-augmented variant of the problem where the requirements on the query set computed by an algorithm are less strict than the requirements on the optimal solution we compare against. More precisely, a query set computed by the algorithm must reveal sufficient information to identify an approximate knapsack solution, while the optimal query set we compare against has to reveal sufficient information to identify an optimal solution. We show that this resource-augmented setting allows interesting non-trivial algorithmic results.",
      "authors": [
        "Jens Schl\\\"oter"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T14:19:41+00:00",
          "link": "https://arxiv.org/abs/2507.02657v1",
          "size": "43kb",
          "version": "v1"
        }
      ],
      "title": "On the Complexity of Knapsack under Explorable Uncertainty: Hardness and Algorithms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02657",
        "HTML": "https://arxiv.org/html/2507.02657v1",
        "PDF": "https://arxiv.org/pdf/2507.02657"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the complexity of the knapsack problem under uncertainty and does not relate to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02659",
      "abstract": "Speculative decoding generally dictates having a small, efficient draft model that is either pretrained or distilled offline to a particular target model series, for instance, Llama or Qwen models. However, within online deployment settings, there are two major challenges: 1) usage of a target model that is incompatible with the draft model; 2) expectation of latency improvements over usage and time. In this work, we propose OmniDraft, a unified framework that enables a single draft model to operate with any target model and adapt dynamically to user data. We introduce an online n-gram cache with hybrid distillation fine-tuning to address the cross-vocabulary mismatch across draft and target models; and further improve decoding speed by leveraging adaptive drafting techniques. OmniDraft is particularly suitable for on-device LLM applications where model cost, efficiency and user customization are the major points of contention. This further highlights the need to tackle the above challenges and motivates the \\textit{``one drafter for all''} paradigm. We showcase the proficiency of the OmniDraft framework by performing online learning on math reasoning, coding and text generation tasks. Notably, OmniDraft enables a single Llama-68M model to pair with various target models including Vicuna-7B, Qwen2-7B and Llama3-8B models for speculative decoding; and additionally provides up to 1.5-2x speedup.",
      "authors": [
        "Ramchalam Kinattinkara Ramakrishnan",
        "Zhaocong Yuan",
        "Shaojie Zhuo",
        "Chen Feng",
        "Yicheng Lin",
        "Chenzheng Su",
        "Xiaopeng Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T14:20:41+00:00",
          "link": "https://arxiv.org/abs/2507.02659v1",
          "size": "1160kb",
          "version": "v1"
        }
      ],
      "title": "OmniDraft: A Cross-vocabulary, Online Adaptive Drafter for On-device Speculative Decoding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02659",
        "HTML": "https://arxiv.org/html/2507.02659v1",
        "PDF": "https://arxiv.org/pdf/2507.02659"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces OmniDraft, which utilizes fine-tuning for online learning and model adaptation; however, its main focus is on efficiency in speculative decoding rather than substantial new contributions to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02660",
      "abstract": "Modern Integrated Circuits (ICs) are becoming increasingly complex, and so is their development process. Hardware design verification entails a methodical and disciplined approach to the planning, development, execution, and sign-off of functionally correct hardware designs. This tedious process requires significant effort and time to ensure a bug-free tape-out. The field of Natural Language Processing has undergone a significant transformation with the advent of Large Language Models (LLMs). These powerful models, often referred to as Generative AI (GenAI), have revolutionized how machines understand and generate human language, enabling unprecedented advancements in a wide array of applications, including hardware design verification. This paper presents an agentic AI-based approach to hardware design verification, which empowers AI agents, in collaboration with Humain-in-the-Loop (HITL) intervention, to engage in a more dynamic, iterative, and self-reflective process, ultimately performing end-to-end hardware design and verification. This methodology is evaluated on five open-source designs, achieving over 95% coverage with reduced verification time while demonstrating superior performance, adaptability, and configurability.",
      "authors": [
        "Deepak Narayan Gadde",
        "Keerthan Kopparam Radhakrishna",
        "Vaisakh Naduvodi Viswambharan",
        "Aman Kumar",
        "Djones Lettnin",
        "Wolfgang Kunz",
        "Sebastian Simon"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T14:20:57+00:00",
          "link": "https://arxiv.org/abs/2507.02660v1",
          "size": "952kb",
          "version": "v1"
        }
      ],
      "title": "Hey AI, Generate Me a Hardware Code! Agentic AI-based Hardware Design & Verification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02660",
        "HTML": "https://arxiv.org/html/2507.02660v1",
        "PDF": "https://arxiv.org/pdf/2507.02660"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses leveraging AI for hardware design and verification rather than any aspect of LLM training data collection, construction, or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02662",
      "abstract": "We introduce two multiscale numerical schemes for the time integration of weakly nonlinear Schr\\\"odinger equations, built upon the discretization of Picard iterates of the solution. These high-order schemes are designed to achieve high precision with respect to the small nonlinearity parameter under particular CFL condition. By exploiting the scattering properties of these schemes thanks to a low-frequency projected linear flow, we also establish its uniform accuracy over long time horizons. Numerical simulations are provided to illustrate the theoretical results, and these schemes are further applied to investigate dynamics in the framework of wave turbulence.",
      "authors": [
        "Quentin Chauleur",
        "Antoine Mouzard"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Analysis of PDEs (math.AP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T14:23:15+00:00",
          "link": "https://arxiv.org/abs/2507.02662v1",
          "size": "2035kb",
          "version": "v1"
        }
      ],
      "title": "High order uniform in time schemes for weakly nonlinear Schr\\\"odinger equation and wave turbulence",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02662",
        "HTML": "https://arxiv.org/html/2507.02662v1",
        "PDF": "https://arxiv.org/pdf/2507.02662"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research is centered around numerical schemes for Schr\u00f6dinger equations and does not involve LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02663",
      "abstract": "Recent Long Reasoning Models(LRMs) have demonstrated remarkable capabilities in handling complex reasoning tasks, but are hindered by excessive overthinking. To explore its essence, our empirical analysis reveals that LRMs are primarily limited to recognizing task properties (i.e., difficulty levels) like humans before solving the problem, leading to a one-size-fits-all reasoning process. Inspired by this, a pressing and natural question emerges: Can we bootstrap such ability to further alleviate the overthinking phenomenon in LRMs? In this paper, we propose Think-How-to-Think (TH2T), a novel two-stage fine-tuning strategy that progressively inspires LRMs' difficulty cognition and redundancy cognition. First, we introduce difficulty-hypnosis in the prefixes of model outputs to intervene in the internal reasoning trajectory. Combined with a heterogeneous short and long reasoning dataset, the trained model enhances its sensitivity to task difficulty, enabling native, differentiated reasoning strategies across various tasks. Second, we further extend redundancy-hypnosis to the internal reasoning process, guiding the model to identify redundant structures within the reasoning steps and generate more concise reasoning outputs. Experiments on 7B/14B/32B models demonstrate that TH2T significantly reduces inference costs (more than 70% on easy tasks and 40% on hard tasks) while maintaining performance stability. The resulting outputs exhibit clear difficulty-aware capabilities and reduced redundancy (e.g., reflection).",
      "authors": [
        "Yongjiang Liu",
        "Haoxi Li",
        "Xiaosong Ma",
        "Jie Zhang",
        "Song Guo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T14:24:26+00:00",
          "link": "https://arxiv.org/abs/2507.02663v1",
          "size": "3874kb",
          "version": "v1"
        }
      ],
      "title": "Think How to Think: Mitigating Overthinking with Autonomous Difficulty Cognition in Large Reasoning Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02663",
        "HTML": "https://arxiv.org/html/2507.02663v1",
        "PDF": "https://arxiv.org/pdf/2507.02663"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper introduces a fine-tuning strategy to enhance LRM reasoning processes through difficulty and redundancy cognition, directly contributing to training-stage data processing in terms of refining model reasoning during training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02664",
      "abstract": "The rapid development of AI-generated content (AIGC) technology has led to the misuse of highly realistic AI-generated images (AIGI) in spreading misinformation, posing a threat to public information security. Although existing AIGI detection techniques are generally effective, they face two issues: 1) a lack of human-verifiable explanations, and 2) a lack of generalization in the latest generation technology. To address these issues, we introduce a large-scale and comprehensive dataset, Holmes-Set, which includes the Holmes-SFTSet, an instruction-tuning dataset with explanations on whether images are AI-generated, and the Holmes-DPOSet, a human-aligned preference dataset. Our work introduces an efficient data annotation method called the Multi-Expert Jury, enhancing data generation through structured MLLM explanations and quality control via cross-model evaluation, expert defect filtering, and human preference modification. In addition, we propose Holmes Pipeline, a meticulously designed three-stage training framework comprising visual expert pre-training, supervised fine-tuning, and direct preference optimization. Holmes Pipeline adapts multimodal large language models (MLLMs) for AIGI detection while generating human-verifiable and human-aligned explanations, ultimately yielding our model AIGI-Holmes. During the inference stage, we introduce a collaborative decoding strategy that integrates the model perception of the visual expert with the semantic reasoning of MLLMs, further enhancing the generalization capabilities. Extensive experiments on three benchmarks validate the effectiveness of our AIGI-Holmes.",
      "authors": [
        "Ziyin Zhou",
        "Yunpeng Luo",
        "Yuanchen Wu",
        "Ke Sun",
        "Jiayi Ji",
        "Ke Yan",
        "Shouhong Ding",
        "Xiaoshuai Sun",
        "Yunsheng Wu",
        "Rongrong Ji"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T14:26:31+00:00",
          "link": "https://arxiv.org/abs/2507.02664v1",
          "size": "16260kb",
          "version": "v1"
        }
      ],
      "title": "AIGI-Holmes: Towards Explainable and Generalizable AI-Generated Image Detection via Multimodal Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02664",
        "HTML": "https://arxiv.org/html/2507.02664v1",
        "PDF": "https://arxiv.org/pdf/2507.02664"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces a comprehensive dataset, Holmes-Set, and a data annotation method for AI-generated image detection. It deals with data collection and processing stages, including instruction-tuning datasets and structured explanations, directly impacting data engineering and training-stage data processing tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02665",
      "abstract": "Anecdotal evidence suggests that Research Software Engineers (RSEs) and Software Engineering Researchers (SERs) often use different terminologies for similar concepts, creating communication challenges. To better understand these divergences, we have started investigating how SE fundamentals from the SER community are interpreted within the RSE community, identifying aligned concepts, knowledge gaps, and areas for potential adaptation. Our preliminary findings reveal opportunities for mutual learning and collaboration, and our systematic methodology for terminology mapping provides a foundation for a crowd-sourced extension and validation in the future.",
      "authors": [
        "Timo Kehrer",
        "Robert Haines",
        "Guido Juckeland",
        "Shurui Zhou",
        "and David E. Bernholdt"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T14:27:54+00:00",
          "link": "https://arxiv.org/abs/2507.02665v1",
          "size": "74kb",
          "version": "v1"
        }
      ],
      "title": "Do Research Software Engineers and Software Engineering Researchers Speak the Same Language?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02665",
        "HTML": "https://arxiv.org/html/2507.02665v1",
        "PDF": "https://arxiv.org/pdf/2507.02665"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the communication challenges between different engineering communities and does not address the collection, construction, or processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02666",
      "abstract": "In recent advancements in audio self-supervised representation learning, the standard Transformer architecture has emerged as the predominant approach, yet its attention mechanism often allocates a portion of attention weights to irrelevant information, potentially impairing the model's discriminative ability. To address this, we introduce a differential attention mechanism, which effectively mitigates ineffective attention allocation through the integration of dual-softmax operations and appropriately tuned differential coefficients. Experimental results demonstrate that our ASDA model achieves state-of-the-art (SOTA) performance across multiple benchmarks, including audio classification (49.0% mAP on AS-2M, 41.5% mAP on AS20K), keyword spotting (98.3% accuracy on SPC-2), and environmental sound classification (96.1% accuracy on ESC-50). These results highlight ASDA's effectiveness in audio tasks, paving the way for broader applications.",
      "authors": [
        "Junyu Wang and Tianrui Wang and Meng Ge and Longbiao Wang and Jianwu Dang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T14:29:43+00:00",
          "link": "https://arxiv.org/abs/2507.02666v1",
          "size": "1311kb",
          "version": "v1"
        }
      ],
      "title": "ASDA: Audio Spectrogram Differential Attention Mechanism for Self-Supervised Representation Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02666",
        "HTML": "https://arxiv.org/html/2507.02666v1",
        "PDF": "https://arxiv.org/pdf/2507.02666"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study introduces a new attention mechanism in audio representation learning and does not include aspects of processing training data for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02670",
      "abstract": "Therapeutic antibodies require not only high-affinity target engagement, but also favorable manufacturability, stability, and safety profiles for clinical effectiveness. These properties are collectively called `developability'. To enable a computational framework for optimizing antibody sequences for favorable developability, we introduce a guided discrete diffusion model trained on natural paired heavy- and light-chain sequences from the Observed Antibody Space (OAS) and quantitative developability measurements for 246 clinical-stage antibodies. To steer generation toward biophysically viable candidates, we integrate a Soft Value-based Decoding in Diffusion (SVDD) Module that biases sampling without compromising naturalness. In unconstrained sampling, our model reproduces global features of both the natural repertoire and approved therapeutics, and under SVDD guidance we achieve significant enrichment in predicted developability scores over unguided baselines. When combined with high-throughput developability assays, this framework enables an iterative, ML-driven pipeline for designing antibodies that satisfy binding and biophysical criteria in tandem.",
      "authors": [
        "Siqi Zhao",
        "Joshua Moller",
        "Porfi Quintero-Cadena",
        "Lood van Niekerk"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Biomolecules (q-bio.BM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T14:35:14+00:00",
          "link": "https://arxiv.org/abs/2507.02670v1",
          "size": "3436kb",
          "version": "v1"
        }
      ],
      "title": "Guided Generation for Developable Antibodies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02670",
        "HTML": "https://arxiv.org/html/2507.02670v1",
        "PDF": "https://arxiv.org/pdf/2507.02670"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research constructs a model for optimizing antibody design and does not involve LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02671",
      "abstract": "Deep Learning (DL) has revolutionized medical imaging, yet its adoption is constrained by data scarcity and privacy regulations, limiting access to diverse datasets. Federated Learning (FL) enables decentralized training but suffers from high communication costs and is often restricted to a single downstream task, reducing flexibility. We propose a data-sharing method via Differentially Private (DP) generative models. By adopting foundation models, we extract compact, informative embeddings, reducing redundancy and lowering computational overhead. Clients collaboratively train a Differentially Private Conditional Variational Autoencoder (DP-CVAE) to model a global, privacy-aware data distribution, supporting diverse downstream tasks. Our approach, validated across multiple feature extractors, enhances privacy, scalability, and efficiency, outperforming traditional FL classifiers while ensuring differential privacy. Additionally, DP-CVAE produces higher-fidelity embeddings than DP-CGAN while requiring $5{\\times}$ fewer parameters.",
      "authors": [
        "Francesco Di Salvo",
        "Hanh Huyen My Nguyen",
        "Christian Ledig"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T14:36:15+00:00",
          "link": "https://arxiv.org/abs/2507.02671v1",
          "size": "349kb",
          "version": "v1"
        }
      ],
      "title": "Embedding-Based Federated Data Sharing via Differentially Private Conditional VAEs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02671",
        "HTML": "https://arxiv.org/html/2507.02671v1",
        "PDF": "https://arxiv.org/pdf/2507.02671"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes a data-sharing method using differentially private generative models for federated learning, with implications on privacy and scalability. It touches on data processing elements but does not focus specifically on LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02672",
      "abstract": "Robotic grasping faces challenges in adapting to objects with varying shapes and sizes. In this paper, we introduce MISCGrasp, a volumetric grasping method that integrates multi-scale feature extraction with contrastive feature enhancement for self-adaptive grasping. We propose a query-based interaction between high-level and low-level features through the Insight Transformer, while the Empower Transformer selectively attends to the highest-level features, which synergistically strikes a balance between focusing on fine geometric details and overall geometric structures. Furthermore, MISCGrasp utilizes multi-scale contrastive learning to exploit similarities among positive grasp samples, ensuring consistency across multi-scale features. Extensive experiments in both simulated and real-world environments demonstrate that MISCGrasp outperforms baseline and variant methods in tabletop decluttering tasks. More details are available at https://miscgrasp.github.io/.",
      "authors": [
        "Qingyu Fan",
        "Yinghao Cai",
        "Chao Li",
        "Chunting Jiao",
        "Xudong Zheng",
        "Tao Lu",
        "Bin Liang",
        "Shuo Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T14:36:45+00:00",
          "link": "https://arxiv.org/abs/2507.02672v1",
          "size": "11503kb",
          "version": "v1"
        }
      ],
      "title": "MISCGrasp: Leveraging Multiple Integrated Scales and Contrastive Learning for Enhanced Volumetric Grasping",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02672",
        "HTML": "https://arxiv.org/html/2507.02672v1",
        "PDF": "https://arxiv.org/pdf/2507.02672"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on robotic grasping using MISCGrasp, which involves feature extraction and contrastive learning, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02674",
      "abstract": "Image-based lighting is a widely used technique to reproduce shading under real-world lighting conditions, especially in real-time rendering applications. A particularly challenging scenario involves materials exhibiting a sparkling or glittering appearance, caused by discrete microfacets scattered across their surface. In this paper, we propose an efficient approximation for image-based lighting of glints, enabling fully dynamic material properties and environment maps. Our novel approach is grounded in real-time glint rendering under area light illumination and employs standard environment map filtering techniques. Crucially, our environment map filtering process is sufficiently fast to be executed on a per-frame basis. Our method assumes that the environment map is partitioned into few homogeneous regions of constant radiance. By filtering the corresponding indicator functions with the normal distribution function, we obtain the probabilities for individual microfacets to reflect light from each region. During shading, these probabilities are utilized to hierarchically sample a multinomial distribution, facilitated by our novel dual-gated Gaussian approximation of binomial distributions. We validate that our real-time approximation is close to ground-truth renderings for a range of material properties and lighting conditions, and demonstrate robust and stable performance, with little overhead over rendering glints from a single directional light. Compared to rendering smooth materials without glints, our approach requires twice as much memory to store the prefiltered environment map.",
      "authors": [
        "Tom Kneiphof and Reinhard Klein"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T14:38:37+00:00",
          "link": "https://arxiv.org/abs/2507.02674v1",
          "size": "48155kb",
          "version": "v1"
        }
      ],
      "title": "Real-time Image-based Lighting of Glints",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02674",
        "PDF": "https://arxiv.org/pdf/2507.02674"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses real-time image-based lighting for rendering glints, which is not related to training data processing for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02675",
      "abstract": "We introduce Team Utility-Constrained Proximal Policy Optimization (TUC-PPO), a new deep reinforcement learning framework. It extends Proximal Policy Optimization (PPO) by integrating team welfare objectives specifically for spatial public goods games. Unlike conventional approaches where cooperation emerges indirectly from individual rewards, TUC-PPO instead optimizes a bi-level objective integrating policy gradients and team utility constraints. Consequently, all policy updates explicitly incorporate collective payoff thresholds. The framework preserves PPO's policy gradient core while incorporating constrained optimization through adaptive Lagrangian multipliers. Therefore, decentralized agents dynamically balance selfish and cooperative incentives. The comparative analysis demonstrates superior performance of this constrained deep reinforcement learning approach compared to unmodified PPO and evolutionary game theory baselines. It achieves faster convergence to cooperative equilibria and greater stability against invasion by defectors. The framework formally integrates team objectives into policy updates. This work advances multi-agent deep reinforcement learning for social dilemmas while providing new computational tools for evolutionary game theory research.",
      "authors": [
        "Zhaoqilin Yang",
        "Xin Wang",
        "Ruichen Zhang",
        "Chanchan Li",
        "Youliang Tian"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T14:38:42+00:00",
          "link": "https://arxiv.org/abs/2507.02675v1",
          "size": "1120kb",
          "version": "v1"
        }
      ],
      "title": "TUC-PPO: Team Utility-Constrained Proximal Policy Optimization for Spatial Public Goods Games",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02675",
        "HTML": "https://arxiv.org/html/2507.02675v1",
        "PDF": "https://arxiv.org/pdf/2507.02675"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces TUC-PPO for reinforcement learning in spatial public goods games, with no focus on LLM training data processing or data engineering aspects."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02677",
      "abstract": "We address the initial source identification problem for the heat equation, a notably ill-posed inverse problem characterized by exponential instability. Departing from classical Tikhonov regularization, we propose a novel approach based on moment analysis of the heat flow, transforming the problem into a more stable inverse moment formulation. By evolving the measured terminal time moments backward through their governing ODE system, we recover the moments of the initial distribution. We then reconstruct the source by solving a convex optimization problem that minimizes the total variation of a measure subject to these moment constraints. This formulation naturally promotes sparsity, yielding atomic solutions that are sums of Dirac measures. Compared to existing methods, our moment-based approach reduces exponential error growth to polynomial growth with respect to the terminal time. We provide explicit error estimates on the recovered initial distributions in terms of moment order, terminal time, and measurement errors. In addition, we develop efficient numerical discretization schemes and demonstrate significant stability improvements of our approach through comprehensive numerical experiments.",
      "authors": [
        "Kang Liu and Enrique Zuazua"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Analysis of PDEs (math.AP)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T14:39:31+00:00",
          "link": "https://arxiv.org/abs/2507.02677v1",
          "size": "1295kb",
          "version": "v1"
        }
      ],
      "title": "Moments, Time-Inversion and Source Identification for the Heat Equation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02677",
        "HTML": "https://arxiv.org/html/2507.02677v1",
        "PDF": "https://arxiv.org/pdf/2507.02677"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with source identification for the heat equation via moment analysis, which is unrelated to the processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02678",
      "abstract": "Community currency networks are made up of individuals and or companies that share some physical or social characteristics and engage in economic transactions using a virtual currency. This paper investigates the structural and dynamic properties of such mutual credit systems through a case study of Sardex, a community currency initiated and mainly operating in Sardinia, Italy. The transaction network is modeled as a directed weighted graph and analyzed through a graph theoretic framework focused on the analysis of strongly connected components, condensed representations, and behavioral connectivity patterns. Emphasis is placed on understanding the evolution of the network's core and peripheral structures over a three year period, with attention to temporal contraction, flow asymmetries, and structural fragmentation depending on different user types. Our findings reveal persistent deviations from degree based null models and suggest the presence of behavioral imitation, specifically, a user preference for more active peers. We further assess the impact of heterogeneous connections between different type of users, which strengthen the network topology and enhance its resilience.",
      "authors": [
        "Camilla Ancona",
        "Dora Ricci",
        "Carmela Bernardo",
        "Francesco Lo Iudice",
        "Anton Proskurnikov and Francesco Vasca"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T14:40:08+00:00",
          "link": "https://arxiv.org/abs/2507.02678v1",
          "size": "6367kb",
          "version": "v1"
        }
      ],
      "title": "Imitation and Heterogeneity Shape the Resilience of Community Currency Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02678",
        "HTML": "https://arxiv.org/html/2507.02678v1",
        "PDF": "https://arxiv.org/pdf/2507.02678"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on community currency networks and examines their structural and dynamic properties using a graph theoretic framework, which is not related to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02679",
      "abstract": "In this work, we investigate the correlation between gender and contextual biases, focusing on elements such as action verbs, object nouns, and particularly on occupations. We introduce a novel dataset, GenderLexicon, and a framework that can estimate contextual bias and its related gender bias. Our model can interpret the bias with a score and thus improve the explainability of gender bias. Also, our findings confirm the existence of gender biases beyond occupational stereotypes. To validate our approach and demonstrate its effectiveness, we conduct evaluations on five diverse datasets, including a Japanese dataset.",
      "authors": [
        "Ahmed Sabir and Rajesh Sharama"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T14:42:03+00:00",
          "link": "https://arxiv.org/abs/2507.02679v1",
          "size": "6937kb",
          "version": "v1"
        }
      ],
      "title": "Exploring Gender Bias Beyond Occupational Titles",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02679",
        "HTML": "https://arxiv.org/html/2507.02679v1",
        "PDF": "https://arxiv.org/pdf/2507.02679"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a novel dataset, GenderLexicon, for investigating gender bias, and conducts evaluations on several datasets, which touches on data collection and processing. However, it does not propose methods specifically for LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02680",
      "abstract": "The integration of Terrestrial Networks (TNs) with Non-Terrestrial Networks (NTNs) poses unique architectural and functional challenges due to heterogeneous propagation conditions, dynamic topologies and limited on-board processing capabilities. This paper examines architectural and functional split strategies that are consistent with O-RAN principles for future integrated TN-NTN systems. A taxonomy of split options is proposed that distributes RAN and core functions between satellites and ground nodes, and trade-offs in terms of performance, latency, autonomy and deployment are analysed. In particular, we evaluate configurations ranging from pure on-board DU deployments to full gNB and UPF integration into satellites, including variations based on intra- and inter-satellite processing. In addition, the placement of Near-RT and Non-RT RAN Intelligent Controllers (RICs) is discussed, proposing flexible split strategies between space and ground to optimise the performance and scalability of the control loop. A comprehensive mapping between architectural splits and RIC placement options is provided, emphasising implementation constraints and interoperability considerations. The paper concludes by identifying key challenges and outlining future directions to enable standardised, modular and efficient TN-NTN convergence in the context of the O-RAN.",
      "authors": [
        "Jorge Baranda",
        "Marius Caus",
        "Luis Blanco",
        "Cristian J. Vaca-Rubio",
        "Engin Zeydan",
        "Kapal Dev",
        "Zheng Li and Tomaso DeCola"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T14:42:41+00:00",
          "link": "https://arxiv.org/abs/2507.02680v1",
          "size": "2056kb",
          "version": "v1"
        }
      ],
      "title": "On the Architectural Split and Radio Intelligence Controller Placement in Integrated O-RAN-enabled Non-Terrestrial Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02680",
        "HTML": "https://arxiv.org/html/2507.02680v1",
        "PDF": "https://arxiv.org/pdf/2507.02680"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the integration of terrestrial and non-terrestrial networks with a focus on architectural and functional splits, RAN intelligence, and O-RAN principles, which are unrelated to LLM training data engineering or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02681",
      "abstract": "Students disengaging from their tasks can have serious long-term consequences, including academic drop-out. This is particularly relevant for students in distance education. One way to measure the level of disengagement in distance education is to observe participation in non-mandatory exercises in different online courses. In this paper, we detect student disengagement in the non-mandatory quizzes of 42 courses in four semesters from a distance-based university. We carefully identified the most informative student log data that could be extracted and processed from Moodle. Then, eight machine learning algorithms were trained and compared to obtain the highest possible prediction accuracy. Using the SHAP method, we developed an explainable machine learning framework that allows practitioners to better understand the decisions of the trained algorithm. The experimental results show a balanced accuracy of 91\\%, where about 85\\% of disengaged students were correctly detected. On top of the highly predictive performance and explainable framework, we provide a discussion on how to design a timely intervention to minimise disengagement from voluntary tasks in online learning.",
      "authors": [
        "Behnam Parsaeifard",
        "Christof Imhof",
        "Tansu Pancar",
        "Ioan-Sorin Comsa",
        "Martin Hlosta",
        "Nicole Bergamin and Per Bergamin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T14:43:40+00:00",
          "link": "https://arxiv.org/abs/2507.02681v1",
          "size": "12167kb",
          "version": "v1"
        }
      ],
      "title": "Detection of Disengagement from Voluntary Quizzes: An Explainable Machine Learning Approach in Higher Distance Education",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02681",
        "HTML": "https://arxiv.org/html/2507.02681v1",
        "PDF": "https://arxiv.org/pdf/2507.02681"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study deals with detecting student disengagement in distance learning through explainable machine learning, focusing on Moodle log data, which is not relevant to the processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02682",
      "abstract": "CAVE displays offer many advantages over other virtual reality (VR) displays, including a large, unencumbering viewing space. Unfortunately, the typical tracking subsystems used with CAVE displays tether the user and lessen this advantage. We have designed a simple, low-cost feet tracker that is wireless, leaving the user free to move. The tracker can be assembled for less than $200 US, and achieves an accuracy of 10 cm at a 20 Hz sampling rate. We have tested the prototype with two applications: a visualization supporting close visual inspection, and a walkthrough of the campus. Although the tracking was convincing, it was clear that the tracker's limitations make it less than ideal for applications requiring precise visual inspection. However, the freedom of motion allowed by the tracker was a compelling supplement to our campus walkthrough, allowing users to stroll and look around corners.",
      "authors": [
        "Ehud Sharlin",
        "Pablo Figueroa",
        "Mark Green",
        "Benjamin Watson"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T14:45:36+00:00",
          "link": "https://arxiv.org/abs/2507.02682v1",
          "size": "143kb",
          "version": "v1"
        }
      ],
      "title": "A wireless, inexpensive optical tracker for the CAVE",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02682",
        "PDF": "https://arxiv.org/pdf/2507.02682"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes the design of a wireless, low-cost optical tracker for CAVE VR systems, which is not related to the processing or engineering of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02686",
      "abstract": "Diffusion models (DMs) have emerged as powerful image priors in Bayesian computational imaging. Two primary strategies have been proposed for leveraging DMs in this context: Plug-and-Play methods, which are zero-shot and highly flexible but rely on approximations; and specialized conditional DMs, which achieve higher accuracy and faster inference for specific tasks through supervised training. In this work, we introduce a novel framework that integrates deep unfolding and model distillation to transform a DM image prior into a few-step conditional model for posterior sampling. A central innovation of our approach is the unfolding of a Markov chain Monte Carlo (MCMC) algorithm - specifically, the recently proposed LATINO Langevin sampler (Spagnoletti et al., 2025) - representing the first known instance of deep unfolding applied to a Monte Carlo sampling scheme. We demonstrate our proposed unfolded and distilled samplers through extensive experiments and comparisons with the state of the art, where they achieve excellent accuracy and computational efficiency, while retaining the flexibility to adapt to variations in the forward model at inference time.",
      "authors": [
        "Charlesquin Kemajou Mbakam",
        "Jonathan Spence and Marcelo Pereyra"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T14:55:53+00:00",
          "link": "https://arxiv.org/abs/2507.02686v1",
          "size": "23938kb",
          "version": "v1"
        }
      ],
      "title": "Learning few-step posterior samplers by unfolding and distillation of diffusion models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02686",
        "HTML": "https://arxiv.org/html/2507.02686v1",
        "PDF": "https://arxiv.org/pdf/2507.02686"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a novel framework for diffusion models particularly in the context of Bayesian computational imaging, and does not discuss LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02687",
      "abstract": "Personalizing diffusion models using limited data presents significant challenges, including overfitting, loss of prior knowledge, and degradation of text alignment. Overfitting leads to shifts in the noise prediction distribution, disrupting the denoising trajectory and causing the model to lose semantic coherence. In this paper, we propose Adaptive Personalized Training (APT), a novel framework that mitigates overfitting by employing adaptive training strategies and regularizing the model's internal representations during fine-tuning. APT consists of three key components: (1) Adaptive Training Adjustment, which introduces an overfitting indicator to detect the degree of overfitting at each time step bin and applies adaptive data augmentation and adaptive loss weighting based on this indicator; (2)Representation Stabilization, which regularizes the mean and variance of intermediate feature maps to prevent excessive shifts in noise prediction; and (3) Attention Alignment for Prior Knowledge Preservation, which aligns the cross-attention maps of the fine-tuned model with those of the pretrained model to maintain prior knowledge and semantic coherence. Through extensive experiments, we demonstrate that APT effectively mitigates overfitting, preserves prior knowledge, and outperforms existing methods in generating high-quality, diverse images with limited reference data.",
      "authors": [
        "JungWoo Chae",
        "Jiyoon Kim",
        "JaeWoong Choi",
        "Kyungyul Kim",
        "Sangheum Hwang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T14:58:08+00:00",
          "link": "https://arxiv.org/abs/2507.02687v1",
          "size": "25208kb",
          "version": "v1"
        }
      ],
      "title": "APT: Adaptive Personalized Training for Diffusion Models with Limited Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02687",
        "HTML": "https://arxiv.org/html/2507.02687v1",
        "PDF": "https://arxiv.org/pdf/2507.02687"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses personalization of diffusion models with limited data, including adaptive training and representation stabilization, which briefly touches on data processing aspects but does not focus on LLM-specific data engineering methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02689",
      "abstract": "Future wireless networks are expected to incorporate diverse services that often lack general mathematical models. To address such black-box network management tasks, the large language model (LLM) optimizer framework, which leverages pretrained LLMs as optimization agents, has recently been promoted as a promising solution. This framework utilizes natural language prompts describing the given optimization problems along with past solutions generated by LLMs themselves. As a result, LLMs can obtain efficient solutions autonomously without knowing the mathematical models of the objective functions. Although the viability of the LLM optimizer (LLMO) framework has been studied in various black-box scenarios, it has so far been limited to numerical simulations. For the first time, this paper establishes a theoretical foundation for the LLMO framework. With careful investigations of LLM inference steps, we can interpret the LLMO procedure as a finite-state Markov chain, and prove the convergence of the framework. Our results are extended to a more advanced multiple LLM architecture, where the impact of multiple LLMs is rigorously verified in terms of the convergence rate. Comprehensive numerical simulations validate our theoretical results and provide a deeper understanding of the underlying mechanisms of the LLMO framework.",
      "authors": [
        "Hoon Lee",
        "Wentao Zhou",
        "Merouane Debbah",
        "Inkyu Lee"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T14:59:42+00:00",
          "link": "https://arxiv.org/abs/2507.02689v1",
          "size": "331kb",
          "version": "v1"
        }
      ],
      "title": "On the Convergence of Large Language Model Optimizer for Black-Box Network Management",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02689",
        "HTML": "https://arxiv.org/html/2507.02689v1",
        "PDF": "https://arxiv.org/pdf/2507.02689"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses the use of LLMs as optimization agents for black-box network management tasks and emphasizes the theoretical foundation of LLM-based optimizers, not training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02690",
      "abstract": "Next activity prediction represents a fundamental challenge for optimizing business processes in service-oriented architectures such as microservices environments, distributed enterprise systems, and cloud-native platforms, which enables proactive resource allocation and dynamic service composition. Despite the prevalence of sequence-based methods, these approaches fail to capture non-sequential relationships that arise from parallel executions and conditional dependencies. Even though graph-based approaches address structural preservation, they suffer from homogeneous representations and static structures that apply uniform modeling strategies regardless of individual process complexity characteristics. To address these limitations, we introduce RLHGNN, a novel framework that transforms event logs into heterogeneous process graphs with three distinct edge types grounded in established process mining theory. Our approach creates four flexible graph structures by selectively combining these edges to accommodate different process complexities, and employs reinforcement learning formulated as a Markov Decision Process to automatically determine the optimal graph structure for each specific process instance. RLHGNN then applies heterogeneous graph convolution with relation-specific aggregation strategies to effectively predict the next activity. This adaptive methodology enables precise modeling of both sequential and non-sequential relationships in service interactions. Comprehensive evaluation on six real-world datasets demonstrates that RLHGNN consistently outperforms state-of-the-art approaches. Furthermore, it maintains an inference latency of approximately 1 ms per prediction, representing a highly practical solution suitable for real-time business process monitoring applications. The source code is available at https://github.com/Joker3993/RLHGNN.",
      "authors": [
        "Jiaxing Wang",
        "Yifeng Yu",
        "Jiahan Song",
        "Bin Cao",
        "Jing Fan and Ji Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T15:01:08+00:00",
          "link": "https://arxiv.org/abs/2507.02690v1",
          "size": "3509kb",
          "version": "v1"
        }
      ],
      "title": "RLHGNN: Reinforcement Learning-driven Heterogeneous Graph Neural Network for Next Activity Prediction in Business Processes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02690",
        "HTML": "https://arxiv.org/html/2507.02690v1",
        "PDF": "https://arxiv.org/pdf/2507.02690"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research concerns the transformation of event logs into heterogeneous process graphs for business process optimization and prediction tasks, with no relation to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02691",
      "abstract": "Video face swapping aims to address two primary challenges: effectively transferring the source identity to the target video and accurately preserving the dynamic attributes of the target face, such as head poses, facial expressions, lip-sync, \\etc. Existing methods mainly focus on achieving high-quality identity transfer but often fall short in maintaining the dynamic attributes of the target face, leading to inconsistent results. We attribute this issue to the inherent coupling of facial appearance and motion in videos. To address this, we propose CanonSwap, a novel video face-swapping framework that decouples motion information from appearance information. Specifically, CanonSwap first eliminates motion-related information, enabling identity modification within a unified canonical space. Subsequently, the swapped feature is reintegrated into the original video space, ensuring the preservation of the target face's dynamic attributes. To further achieve precise identity transfer with minimal artifacts and enhanced realism, we design a Partial Identity Modulation module that adaptively integrates source identity features using a spatial mask to restrict modifications to facial regions. Additionally, we introduce several fine-grained synchronization metrics to comprehensively evaluate the performance of video face swapping methods. Extensive experiments demonstrate that our method significantly outperforms existing approaches in terms of visual quality, temporal consistency, and identity preservation. Our project page are publicly available at https://luoxyhappy.github.io/CanonSwap/.",
      "authors": [
        "Xiangyang Luo",
        "Ye Zhu",
        "Yunfei Liu",
        "Lijian Lin",
        "Cong Wan",
        "Zijian Cai",
        "Shao-Lun Huang",
        "Yu Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T15:03:39+00:00",
          "link": "https://arxiv.org/abs/2507.02691v1",
          "size": "6744kb",
          "version": "v1"
        }
      ],
      "title": "CanonSwap: High-Fidelity and Consistent Video Face Swapping via Canonical Space Modulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02691",
        "HTML": "https://arxiv.org/html/2507.02691v1",
        "PDF": "https://arxiv.org/pdf/2507.02691"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on a video face-swapping framework, emphasizing motion decoupling for identity transfer, with no connection to LLM training data engineering or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02694",
      "abstract": "Peer review is fundamental to scientific research, but the growing volume of publications has intensified the challenges of this expertise-intensive process. While LLMs show promise in various scientific tasks, their potential to assist with peer review, particularly in identifying paper limitations, remains understudied. We first present a comprehensive taxonomy of limitation types in scientific research, with a focus on AI. Guided by this taxonomy, for studying limitations, we present LimitGen, the first comprehensive benchmark for evaluating LLMs' capability to support early-stage feedback and complement human peer review. Our benchmark consists of two subsets: LimitGen-Syn, a synthetic dataset carefully created through controlled perturbations of high-quality papers, and LimitGen-Human, a collection of real human-written limitations. To improve the ability of LLM systems to identify limitations, we augment them with literature retrieval, which is essential for grounding identifying limitations in prior scientific findings. Our approach enhances the capabilities of LLM systems to generate limitations in research papers, enabling them to provide more concrete and constructive feedback.",
      "authors": [
        "Zhijian Xu",
        "Yilun Zhao",
        "Manasi Patwardhan",
        "Lovekesh Vig",
        "Arman Cohan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T15:04:38+00:00",
          "link": "https://arxiv.org/abs/2507.02694v1",
          "size": "4093kb",
          "version": "v1"
        }
      ],
      "title": "Can LLMs Identify Critical Limitations within Scientific Research? A Systematic Evaluation on AI Research Papers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02694",
        "HTML": "https://arxiv.org/html/2507.02694v1",
        "PDF": "https://arxiv.org/pdf/2507.02694"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper mentions the creation of a synthetic dataset (LimitGen) for evaluating LLMs' capability, which involves some data processing, but it is not primarily about designing LLM training data pipelines or methods for improving data quality."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02695",
      "abstract": "In recent years, sustainability in software systems has gained significant attention, especially with the rise of cloud computing and the shift towards cloud-based architectures. This shift has intensified the need to identify sustainability in architectural discussions to take informed architectural decisions. One source to see these decisions is in online Q&A forums among practitioners' discussions. However, recognizing sustainability concepts within software practitioners' discussions remains challenging due to the lack of clear and distinct guidelines for this task. To address this issue, we introduce the notion of sustainability flags as pointers in relevant discussions, developed through thematic analysis of multiple sustainability best practices from cloud providers. This study further evaluates the effectiveness of these flags in identifying sustainability within cloud architecture posts, using a controlled experiment. Preliminary results suggest that the use of flags results in classifying fewer posts as sustainability-related compared to a control group, with moderately higher certainty and significantly improved performance. Moreover, sustainability flags are perceived as more useful and understandable than relying solely on definitions for identifying sustainability.",
      "authors": [
        "Sahar Ahmadisakha",
        "Lech Bialek",
        "Mohamed Soliman",
        "Vasilios Andrikopoulos"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T15:06:04+00:00",
          "link": "https://arxiv.org/abs/2507.02695v1",
          "size": "279kb",
          "version": "v1"
        }
      ],
      "title": "Sustainability Flags for the Identification of Sustainability Posts in Q&A Platforms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02695",
        "PDF": "https://arxiv.org/pdf/2507.02695"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study focuses on using sustainability flags in Q&A platforms and is unrelated to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02698",
      "abstract": "This study investigates how Multi-Agent Reinforcement Learning (MARL) can improve dynamic pricing strategies in supply chains, particularly in contexts where traditional ERP systems rely on static, rule-based approaches that overlook strategic interactions among market actors. While recent research has applied reinforcement learning to pricing, most implementations remain single-agent and fail to model the interdependent nature of real-world supply chains. This study addresses that gap by evaluating the performance of three MARL algorithms: MADDPG, MADQN, and QMIX against static rule-based baselines, within a simulated environment informed by real e-commerce transaction data and a LightGBM demand prediction model. Results show that rule-based agents achieve near-perfect fairness (Jain's Index: 0.9896) and the highest price stability (volatility: 0.024), but they fully lack competitive dynamics. Among MARL agents, MADQN exhibits the most aggressive pricing behaviour, with the highest volatility and the lowest fairness (0.5844). MADDPG provides a more balanced approach, supporting market competition (share volatility: 9.5 pp) while maintaining relatively high fairness (0.8819) and stable pricing. These findings suggest that MARL introduces emergent strategic behaviour not captured by static pricing rules and may inform future developments in dynamic pricing.",
      "authors": [
        "Thomas Hazenberg",
        "Yao Ma",
        "Seyed Sahand Mohammadi Ziabari",
        "and Marijn van Rijswijk"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Econometrics (econ.EM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T15:07:37+00:00",
          "link": "https://arxiv.org/abs/2507.02698v1",
          "size": "4675kb",
          "version": "v1"
        }
      ],
      "title": "Multi-Agent Reinforcement Learning for Dynamic Pricing in Supply Chains: Benchmarking Strategic Agent Behaviours under Realistically Simulated Market Conditions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02698",
        "HTML": "https://arxiv.org/html/2507.02698v1",
        "PDF": "https://arxiv.org/pdf/2507.02698"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is focused on multi-agent reinforcement learning for dynamic pricing in supply chains and does not address LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02699",
      "abstract": "The increasing capabilities of LLMs have led to the rapid proliferation of LLM agent apps, where developers enhance LLMs with access to external resources to support complex task execution. Among these, LLM email agent apps represent one of the widely used categories, as email remains a critical communication medium for users. LLM email agents are capable of managing and responding to email using LLM-driven reasoning and autonomously executing user instructions via external email APIs (e.g., send email). However, despite their growing deployment and utility, the security mechanism of LLM email agent apps remains underexplored. Currently, there is no comprehensive study into the potential security risk within these agent apps and their broader implications.\n  In this paper, we conduct the first in-depth and systematic security study of LLM email agents. We propose the Email Agent Hijacking (EAH) attack, which overrides the original prompts of the email agent via external email resources, allowing attackers to gain control of the email agent remotely and further perform specific attack scenarios without user awareness.\n  To facilitate the large-scale evaluation, we propose EAHawk, a pipeline to evaluate the EAH attack of LLM email agent apps. By EAHawk, we performed an empirical study spanning 14 representative LLM agent frameworks, 63 agent apps, 12 LLMs, and 20 email services, which led to the generation of 1,404 real-world email agent instances for evaluation. Experimental results indicate that all 1,404 instances were successfully hijacked; on average, only 2.03 attack attempts are required to control an email agent instance. Even worse, for some LLMs, the average number of attempts needed to achieve full agent control drops to as few as 1.23.",
      "authors": [
        "Jiangrong Wu",
        "Yuhong Nan",
        "Jianliang Wu",
        "Zitong Yao",
        "Zibin Zheng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T15:09:40+00:00",
          "link": "https://arxiv.org/abs/2507.02699v1",
          "size": "2085kb",
          "version": "v1"
        }
      ],
      "title": "Control at Stake: Evaluating the Security Landscape of LLM-Driven Email Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02699",
        "HTML": "https://arxiv.org/html/2507.02699v1",
        "PDF": "https://arxiv.org/pdf/2507.02699"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper examines the security of LLM-driven email agents, discussing security vulnerabilities rather than training data processing or engineering for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02700",
      "abstract": "This article focuses on integrating path-planning and control with specializing on the unique needs of robotic unicycles. A unicycle design is presented which is capable of accelerating/breaking and carrying out a variety of maneuvers. The proposed path-planning method segments the path into straight and curved path sections dedicated for accelerating/breaking and turning maneuvers, respectively. The curvature profiles of the curved sections are optimized while considering the control performance and the slipping limits of the wheel. The performance of the proposed integrated approach is demonstrated via numerical simulations.",
      "authors": [
        "M\\'at\\'e B. Vizi",
        "D\\'enes T\\'ak\\'acs",
        "G\\'abor St\\'ep\\'an",
        "G\\'abor Orosz"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T15:09:59+00:00",
          "link": "https://arxiv.org/abs/2507.02700v1",
          "size": "1242kb",
          "version": "v1"
        }
      ],
      "title": "Integrating path-planning and control for robotic unicycles",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02700",
        "HTML": "https://arxiv.org/html/2507.02700v1",
        "PDF": "https://arxiv.org/pdf/2507.02700"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with path-planning and control for robotic unicycles, which is unrelated to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02701",
      "abstract": "The tree edit distance is a natural dissimilarity measure between rooted ordered trees whose nodes are labeled over an alphabet $\\Sigma$. It is defined as the minimum number of node edits (insertions, deletions, and relabelings) required to transform one tree into the other. In the weighted variant, the edits have associated costs (depending on the involved node labels) normalized so that each cost is at least one, and the goal is to minimize the total cost of edits.\n  The unweighted tree edit distance between two trees of total size $n$ can be computed in $O(n^{2.6857})$ time; in contrast, determining the weighted tree edit distance is fine-grained equivalent to the All-Pairs Shortest Paths problem and requires $n^3/2^{\\Omega(\\sqrt{\\log n})}$ time [Nogler et al.; STOC'25]. These super-quadratic running times are unattractive for large but very similar trees, which motivates the bounded version of the problem, where the runtime is parameterized by the computed distance $k$, potentially yielding faster algorithms for $k\\ll n$.\n  Previous best algorithms for the bounded unweighted setting run in $O(nk^2\\log n)$ time [Akmal & Jin; ICALP'21] and $O(n + k^7\\log k)$ time [Das et al.; STOC'23]. For the weighted variant, the only known running time has been $O(n + k^{15})$.\n  We present an $O(n + k^6\\log k)$-time algorithm for computing the bounded tree edit distance in both the weighted and unweighted settings. Our approach begins with an alternative $O(nk^2\\log n)$-time algorithm that handles weights and is significantly easier to analyze than the existing counterpart. We then introduce a novel optimization that leverages periodic structures within the input trees. To utilize it, we modify the $O(k^5)$-size $O(n)$-time universal kernel, the central component of the prior $O(n + k^{O(1)})$-time algorithms, so that it produces instances containing these periodic structures.",
      "authors": [
        "Tomasz Kociumaka",
        "Ali Shahali"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T15:10:13+00:00",
          "link": "https://arxiv.org/abs/2507.02701v1",
          "size": "88kb",
          "version": "v1"
        }
      ],
      "title": "Faster Algorithm for Bounded Tree Edit Distance in the Low-Distance Regime",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02701",
        "HTML": "https://arxiv.org/html/2507.02701v1",
        "PDF": "https://arxiv.org/pdf/2507.02701"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on algorithms for computing tree edit distance, which is a topic unrelated to the processing or engineering of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02703",
      "abstract": "One paradigm of Monte Carlo Tree Search (MCTS) improvements is to build and use state and/or action abstractions during the tree search. Non-exact abstractions, however, introduce an approximation error making convergence to the optimal action in the abstract space impossible. Hence, as proposed as a component of Elastic Monte Carlo Tree Search by Xu et al., abstraction algorithms should eventually drop the abstraction. In this paper, we propose two novel abstraction dropping schemes, namely OGA-IAAD and OGA-CAD which can yield clear performance improvements whilst being safe in the sense that the dropping never causes any notable performance degradations contrary to Xu's dropping method. OGA-IAAD is designed for time critical settings while OGA-CAD is designed to improve the MCTS performance with the same number of iterations.",
      "authors": [
        "Robin Schm\\\"ocker",
        "Lennart Kampmann",
        "Alexander Dockhorn"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T15:12:05+00:00",
          "link": "https://arxiv.org/abs/2507.02703v1",
          "size": "581kb",
          "version": "v1"
        }
      ],
      "title": "Time-critical and confidence-based abstraction dropping methods",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02703",
        "HTML": "https://arxiv.org/html/2507.02703v1",
        "PDF": "https://arxiv.org/pdf/2507.02703"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses abstraction dropping in Monte Carlo Tree Search improvements without any connection to LLM training data processing or related tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02705",
      "abstract": "Simultaneous understanding and 3D reconstruction plays an important role in developing end-to-end embodied intelligent systems. To achieve this, recent approaches resort to 2D-to-3D feature alignment paradigm, which leads to limited 3D understanding capability and potential semantic information loss. In light of this, we propose SIU3R, the first alignment-free framework for generalizable simultaneous understanding and 3D reconstruction from unposed images. Specifically, SIU3R bridges reconstruction and understanding tasks via pixel-aligned 3D representation, and unifies multiple understanding tasks into a set of unified learnable queries, enabling native 3D understanding without the need of alignment with 2D models. To encourage collaboration between the two tasks with shared representation, we further conduct in-depth analyses of their mutual benefits, and propose two lightweight modules to facilitate their interaction. Extensive experiments demonstrate that our method achieves state-of-the-art performance not only on the individual tasks of 3D reconstruction and understanding, but also on the task of simultaneous understanding and 3D reconstruction, highlighting the advantages of our alignment-free framework and the effectiveness of the mutual benefit designs.",
      "authors": [
        "Qi Xu",
        "Dongxu Wei",
        "Lingzhe Zhao",
        "Wenpu Li",
        "Zhangchi Huang",
        "Shunping Ji",
        "Peidong Liu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T15:15:21+00:00",
          "link": "https://arxiv.org/abs/2507.02705v1",
          "size": "10800kb",
          "version": "v1"
        }
      ],
      "title": "SIU3R: Simultaneous Scene Understanding and 3D Reconstruction Beyond Feature Alignment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02705",
        "HTML": "https://arxiv.org/html/2507.02705v1",
        "PDF": "https://arxiv.org/pdf/2507.02705"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses a method for simultaneous 3D scene understanding and reconstruction, with no focus on LLM training data processing or related fields."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02708",
      "abstract": "In disaster response scenarios, deploying robotic teams effectively is crucial for improving situational awareness and enhancing search and rescue operations. The use of robots in search and rescue has been studied but the question of where to start robot deployments has not been addressed. This work addresses the problem of optimally selecting starting locations for robots with heterogeneous capabilities by formulating a joint optimization problem. To determine start locations, this work adds a constraint to the ergodic optimization framework whose minimum assigns robots to start locations. This becomes a little more challenging when the robots are heterogeneous (equipped with different sensing and motion modalities) because not all robots start at the same location, and a more complex adaptation of the aforementioned constraint is applied. Our method assumes access to potential starting locations, which can be obtained from expert knowledge or aerial imagery. We experimentally evaluate the efficacy of our joint optimization approach by comparing it to baseline methods that use fixed starting locations for all robots. Our experimental results show significant gains in coverage performance, with average improvements of 35.98% on synthetic data and 31.91% on real-world data for homogeneous and heterogeneous teams, in terms of the ergodic metric.",
      "authors": [
        "Ananya Rao",
        "Alyssa Hargis",
        "David Wettergreen",
        "Howie Choset"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T15:24:54+00:00",
          "link": "https://arxiv.org/abs/2507.02708v1",
          "size": "13903kb",
          "version": "v1"
        }
      ],
      "title": "Optimizing Start Locations in Ergodic Search for Disaster Response",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02708",
        "HTML": "https://arxiv.org/html/2507.02708v1",
        "PDF": "https://arxiv.org/pdf/2507.02708"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research is concerned with optimizing robotic search start locations in disaster response scenarios, which does not pertain to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02710",
      "abstract": "Federated learning (FL) mechanisms typically require each client to transfer their weights to a central server, irrespective of how useful they are. In order to avoid wasteful data transfer costs from clients to the central server, we propose the use of consensus based protocols to identify a subset of clients with most useful model weights at each data transfer step. First, we explore the application of existing fluid democracy protocols to FL from a performance standpoint, comparing them with traditional one-person-one-vote (also known as 1p1v or FedAvg). We propose a new fluid democracy protocol named viscous-retained democracy that always does better than 1p1v under the same assumptions as existing fluid democracy protocols while also not allowing for influence accumulation. Secondly, we identify weaknesses of fluid democracy protocols from an adversarial lens in terms of their dependence on topology and/ or number of adversaries required to negatively impact the global model weights. To this effect, we propose an algorithm (FedVRD) that dynamically limits the effect of adversaries while minimizing cost by leveraging the delegation topology.",
      "authors": [
        "Aditya Vema Reddy Kesari and Krishna Reddy Kesari"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T15:26:24+00:00",
          "link": "https://arxiv.org/abs/2507.02710v1",
          "size": "221kb",
          "version": "v1"
        }
      ],
      "title": "Fluid Democracy in Federated Data Aggregation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02710",
        "HTML": "https://arxiv.org/html/2507.02710v1",
        "PDF": "https://arxiv.org/pdf/2507.02710"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses federated learning and optimization of client data transfers, yet it does not address data processing techniques for LLM training specifically."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02712",
      "abstract": "Deep reinforcement learning for continuous control has recently achieved impressive progress. However, existing methods often suffer from primacy bias, a tendency to overfit early experiences stored in the replay buffer, which limits an RL agent's sample efficiency and generalizability. In contrast, humans are less susceptible to such bias, partly due to infantile amnesia, where the formation of new neurons disrupts early memory traces, leading to the forgetting of initial experiences. Inspired by this dual processes of forgetting and growing in neuroscience, in this paper, we propose Forget and Grow (FoG), a new deep RL algorithm with two mechanisms introduced. First, Experience Replay Decay (ER Decay) \"forgetting early experience\", which balances memory by gradually reducing the influence of early experiences. Second, Network Expansion, \"growing neural capacity\", which enhances agents' capability to exploit the patterns of existing data by dynamically adding new parameters during training. Empirical results on four major continuous control benchmarks with more than 40 tasks demonstrate the superior performance of FoG against SoTA existing deep RL algorithms, including BRO, SimBa, and TD-MPC2.",
      "authors": [
        "Zilin Kang",
        "Chenyuan Hu",
        "Yu Luo",
        "Zhecheng Yuan",
        "Ruijie Zheng",
        "Huazhe Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T15:26:48+00:00",
          "link": "https://arxiv.org/abs/2507.02712v1",
          "size": "11224kb",
          "version": "v1"
        }
      ],
      "title": "A Forget-and-Grow Strategy for Deep Reinforcement Learning Scaling in Continuous Control",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02712",
        "HTML": "https://arxiv.org/html/2507.02712v1",
        "PDF": "https://arxiv.org/pdf/2507.02712"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on deep reinforcement learning algorithms and their efficacy in continuous control tasks, with no mention of LLM training data processing or related data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02713",
      "abstract": "Although significant advancements have been achieved in the progress of keypoint-guided Text-to-Image diffusion models, existing mainstream keypoint-guided models encounter challenges in controlling the generation of more general non-rigid objects beyond humans (e.g., animals). Moreover, it is difficult to generate multiple overlapping humans and animals based on keypoint controls solely. These challenges arise from two main aspects: the inherent limitations of existing controllable methods and the lack of suitable datasets. First, we design a DiT-based framework, named UniMC, to explore unifying controllable multi-class image generation. UniMC integrates instance- and keypoint-level conditions into compact tokens, incorporating attributes such as class, bounding box, and keypoint coordinates. This approach overcomes the limitations of previous methods that struggled to distinguish instances and classes due to their reliance on skeleton images as conditions. Second, we propose HAIG-2.9M, a large-scale, high-quality, and diverse dataset designed for keypoint-guided human and animal image generation. HAIG-2.9M includes 786K images with 2.9M instances. This dataset features extensive annotations such as keypoints, bounding boxes, and fine-grained captions for both humans and animals, along with rigorous manual inspection to ensure annotation accuracy. Extensive experiments demonstrate the high quality of HAIG-2.9M and the effectiveness of UniMC, particularly in heavy occlusions and multi-class scenarios.",
      "authors": [
        "Qin Guo",
        "Ailing Zeng",
        "Dongxu Yue",
        "Ceyuan Yang",
        "Yang Cao",
        "Hanzhong Guo",
        "Fei Shen",
        "Wei Liu",
        "Xihui Liu",
        "Dan Xu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T15:27:28+00:00",
          "link": "https://arxiv.org/abs/2507.02713v1",
          "size": "17677kb",
          "version": "v1"
        }
      ],
      "title": "UniMC: Taming Diffusion Transformer for Unified Keypoint-Guided Multi-Class Image Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02713",
        "HTML": "https://arxiv.org/html/2507.02713v1",
        "PDF": "https://arxiv.org/pdf/2507.02713"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper contributes a novel dataset, HAIG-2.9M, for keypoint-guided human and animal image generation, which involves large-scale data construction and annotation, key aspects of data engineering for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02714",
      "abstract": "Image generation has achieved remarkable progress with the development of large-scale text-to-image models, especially diffusion-based models. However, generating human images with plausible details, such as faces or hands, remains challenging due to insufficient supervision of local regions during training. To address this issue, we propose FairHuman, a multi-objective fine-tuning approach designed to enhance both global and local generation quality fairly. Specifically, we first construct three learning objectives: a global objective derived from the default diffusion objective function and two local objectives for hands and faces based on pre-annotated positional priors. Subsequently, we derive the optimal parameter updating strategy under the guidance of the Minimum Potential Delay (MPD) criterion, thereby attaining fairness-ware optimization for this multi-objective problem. Based on this, our proposed method can achieve significant improvements in generating challenging local details while maintaining overall quality. Extensive experiments showcase the effectiveness of our method in improving the performance of human image generation under different scenarios.",
      "authors": [
        "Yuxuan Wang",
        "Tianwei Cao",
        "Huayu Zhang",
        "Zhongjiang He",
        "Kongming Liang",
        "Zhanyu Ma"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T15:27:45+00:00",
          "link": "https://arxiv.org/abs/2507.02714v1",
          "size": "15120kb",
          "version": "v1"
        }
      ],
      "title": "FairHuman: Boosting Hand and Face Quality in Human Image Generation with Minimum Potential Delay Fairness in Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02714",
        "HTML": "https://arxiv.org/html/2507.02714v1",
        "PDF": "https://arxiv.org/pdf/2507.02714"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper addresses data supervision during model training through fine-tuning objectives but does not focus on novel LLM training data construction or processing methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02715",
      "abstract": "Dockless e-scooters, a key micromobility service, have emerged as eco-friendly and flexible urban transport alternatives. These services improve first and last-mile connectivity, reduce congestion and emissions, and complement public transport for short-distance travel. However, effective management of these services depends on accurate demand prediction, which is crucial for optimal fleet distribution and infrastructure planning. While previous studies have focused on analyzing spatial or temporal factors in isolation, this study introduces a framework that integrates spatial, temporal, and network dependencies for improved micromobility demand forecasting. This integration enhances accuracy while providing deeper insights into urban micromobility usage patterns. Our framework improves demand prediction accuracy by 27 to 49% over baseline models, demonstrating its effectiveness in capturing micromobility demand patterns. These findings support data-driven micromobility management, enabling optimized fleet distribution, cost reduction, and sustainable urban planning.",
      "authors": [
        "Omri Porat",
        "Michael Fire and Eran Ben-Elia"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T15:31:10+00:00",
          "link": "https://arxiv.org/abs/2507.02715v1",
          "size": "1264kb",
          "version": "v1"
        }
      ],
      "title": "A Comprehensive Machine Learning Framework for Micromobility Demand Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02715",
        "HTML": "https://arxiv.org/html/2507.02715v1",
        "PDF": "https://arxiv.org/pdf/2507.02715"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is centered on micromobility demand prediction, primarily focusing on urban planning and spatial-temporal data integration, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02721",
      "abstract": "The Princess Marijke lock complex is a large lock and water-protection installation in the Netherlands between the river Rhine and the Amsterdam-Rijnkanaal -- a large waterway connecting the Rhine to the port of Amsterdam. The lock complex consists of two independent locks and a moveable flood-protection barrier. Ensuring safe control of the lock complex is of utmost importance to guarantee both flood-protection and reliable ship operations. This paper gives a precise, formal description of the software control of the lock complex in less than 400 lines of mCRL2 code. This description can act as a blueprint on how the software of this lock complex needs to be constructed. Moreover, using model checking, 53 software requirements are shown to be valid, ensuring that the formal description of the behaviour is correct with regard to these properties and is unlikely to contain mistakes and oversights.",
      "authors": [
        "Jan Friso Groote",
        "Matthias Volk"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Logic in Computer Science (cs.LO)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T15:35:34+00:00",
          "link": "https://arxiv.org/abs/2507.02721v1",
          "size": "63kb",
          "version": "v1"
        }
      ],
      "title": "A formal specification of the desired software behaviour of the Princess Marijke lock complex",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02721",
        "HTML": "https://arxiv.org/html/2507.02721v1",
        "PDF": "https://arxiv.org/pdf/2507.02721"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper provides a formal specification for software control of a lock complex, which is unrelated to LLM training data processing or construction tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02724",
      "abstract": "Recent advances in AI for science have highlighted the power of contrastive learning in bridging heterogeneous biological data modalities. Building on this paradigm, we propose HIPPO (HIerarchical Protein-Protein interaction prediction across Organisms), a hierarchical contrastive framework for protein-protein interaction(PPI) prediction, where protein sequences and their hierarchical attributes are aligned through multi-tiered biological representation matching. The proposed approach incorporates hierarchical contrastive loss functions that emulate the structured relationship among functional classes of proteins. The framework adaptively incorporates domain and family knowledge through a data-driven penalty mechanism, enforcing consistency between the learned embedding space and the intrinsic hierarchy of protein functions. Experiments on benchmark datasets demonstrate that HIPPO achieves state-of-the-art performance, outperforming existing methods and showing robustness in low-data regimes. Notably, the model demonstrates strong zero-shot transferability to other species without retraining, enabling reliable PPI prediction and functional inference even in less characterized or rare organisms where experimental data are limited. Further analysis reveals that hierarchical feature fusion is critical for capturing conserved interaction determinants, such as binding motifs and functional annotations. This work advances cross-species PPI prediction and provides a unified framework for interaction prediction in scenarios with sparse or imbalanced multi-species data.",
      "authors": [
        "Shiyi Liu",
        "Buwen Liang",
        "Yuetong Fang",
        "Zixuan Jiang and Renjing Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Biomolecules (q-bio.BM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T15:41:04+00:00",
          "link": "https://arxiv.org/abs/2507.02724v1",
          "size": "915kb",
          "version": "v1"
        }
      ],
      "title": "Hierarchical Multi-Label Contrastive Learning for Protein-Protein Interaction Prediction Across Organisms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02724",
        "HTML": "https://arxiv.org/html/2507.02724v1",
        "PDF": "https://arxiv.org/pdf/2507.02724"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on hierarchical contrastive learning for protein-protein interaction prediction, which is unrelated to the processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02726",
      "abstract": "Reasoning remains a challenging task for large language models (LLMs), especially within the logically constrained environment of automated theorem proving (ATP), due to sparse rewards and the vast scale of proofs. These challenges are amplified in benchmarks like PutnamBench, which contains university-level problems requiring complex, multi-step reasoning. To address this, we introduce self-generated goal-conditioned MDPs (sG-MDPs), a new framework in which agents generate and pursue their subgoals based on the evolving proof state. Given this more structured generation of goals, the resulting problem becomes more amenable to search. We then apply Monte Carlo Tree Search (MCTS)-like algorithms to solve the sG-MDP, instantiating our approach in Bourbaki (7B), a modular system that can ensemble multiple 7B LLMs for subgoal generation and tactic synthesis. On PutnamBench, Bourbaki (7B) solves 26 problems, achieving new state-of-the-art results with models at this scale.",
      "authors": [
        "Matthieu Zimmer",
        "Xiaotong Ji",
        "Rasul Tutunov",
        "Anthony Bordg",
        "Jun Wang",
        "Haitham Bou Ammar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T15:41:38+00:00",
          "link": "https://arxiv.org/abs/2507.02726v1",
          "size": "68kb",
          "version": "v1"
        }
      ],
      "title": "Bourbaki: Self-Generated and Goal-Conditioned MDPs for Theorem Proving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02726",
        "HTML": "https://arxiv.org/html/2507.02726v1",
        "PDF": "https://arxiv.org/pdf/2507.02726"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses large language models (LLMs) in the context of automated theorem proving and does not address LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02727",
      "abstract": "Local differential privacy (LDP) provides a rigorous and quantifiable privacy guarantee for personal data by introducing perturbation at the data source. However, quantifying the impact of these perturbations on classifier utility remains a theoretical challenge, particularly for complex or black-box classifiers.\n  This paper presents a framework for theoretically quantifying classifier utility under LDP mechanisms. The key insight is that LDP perturbation is concentrated around the original data with a specific probability, transforming utility analysis of the classifier into its robustness analysis in this concentrated region. Our framework connects the concentration analysis of LDP mechanisms with the robustness analysis of classifiers. It treats LDP mechanisms as general distributional functions and classifiers as black-box functions, thus applicable to any LDP mechanism and classifier. A direct application of our utility quantification is guiding the selection of LDP mechanisms and privacy parameters for a given classifier. Notably, our analysis shows that a piecewise-based mechanism leads to better utility compared to alternatives in common scenarios.\n  Using this framework alongside two novel refinement techniques, we conduct case studies on utility quantification for typical mechanism-classifier combinations. The results demonstrate that our theoretical utility quantification aligns closely with empirical observations, particularly when classifiers operate in lower-dimensional input spaces.",
      "authors": [
        "Ye Zheng",
        "Yidan Hu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T15:42:10+00:00",
          "link": "https://arxiv.org/abs/2507.02727v1",
          "size": "924kb",
          "version": "v1"
        }
      ],
      "title": "Quantifying Classifier Utility under Local Differential Privacy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02727",
        "HTML": "https://arxiv.org/html/2507.02727v1",
        "PDF": "https://arxiv.org/pdf/2507.02727"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on utility quantification under local differential privacy for classifiers, with no connection to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02728",
      "abstract": "We study the problem of indexing and compressing tries using a BWT-based approach. Specifically, we consider a succinct and compressed representation of the XBWT of Ferragina et al.\\ [FOCS '05, JACM '09] corresponding to the analogous of the FM-index [FOCS '00, JACM '05] for tries. This representation allows to efficiently count the number of nodes reached by a given string pattern. To analyze the space complexity of the above trie index, we propose a proof for the combinatorial problem of counting the number of tries with a given symbol distribution. We use this formula to define a worst-case entropy measure for tries, as well as a notion of k-th order empirical entropy. In particular, we show that the relationships between these two entropy measures are similar to those between the corresponding well-known measures for strings. We use these measures to prove that the XBWT of a trie can be encoded within a space bounded by our k-th order empirical entropy plus a o(n) term, with n being the number of nodes in the trie. Notably, as happens for strings, this space bound can be reached for every sufficiently small k simultaneously. Finally, we compare the space complexity of the above index with that of the r-index for tries proposed by Prezza [SODA '21] and we prove that in some cases the FM-index for tries is asymptotically smaller.",
      "authors": [
        "Lorenzo Carfagna and Carlo Tosoni"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T15:42:43+00:00",
          "link": "https://arxiv.org/abs/2507.02728v1",
          "size": "22kb",
          "version": "v1"
        }
      ],
      "title": "Indexing Tries within Entropy-Bounded Space",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02728",
        "HTML": "https://arxiv.org/html/2507.02728v1",
        "PDF": "https://arxiv.org/pdf/2507.02728"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about indexing and compressing tries using a BWT-based approach and does not relate to the processing or engineering of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02730",
      "abstract": "The industrialization of catalytic processes hinges on the availability of reliable kinetic models for design, optimization, and control. Traditional mechanistic models demand extensive domain expertise, while many data-driven approaches often lack interpretability and fail to enforce physical consistency. To overcome these limitations, we propose the Physics-Informed Automated Discovery of Kinetics (PI-ADoK) framework. By integrating physical constraints directly into a symbolic regression approach, PI-ADoK narrows the search space and substantially reduces the number of experiments required for model convergence. Additionally, the framework incorporates a robust uncertainty quantification strategy via the Metropolis-Hastings algorithm, which propagates parameter uncertainty to yield credible prediction intervals. Benchmarking our method against conventional approaches across several catalytic case studies demonstrates that PI-ADoK not only enhances model fidelity but also lowers the experimental burden, highlighting its potential for efficient and reliable kinetic model discovery in chemical reaction engineering.",
      "authors": [
        "Miguel \\'Angel de Carvalho Servia",
        "Ilya Orson Sandoval",
        "King Kuok (Mimi) Hii",
        "Klaus Hellgardt",
        "Dongda Zhang",
        "Ehecatl Antonio del Rio Chanona"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Symbolic Computation (cs.SC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T15:43:02+00:00",
          "link": "https://arxiv.org/abs/2507.02730v1",
          "size": "6460kb",
          "version": "v1"
        }
      ],
      "title": "Constraint-Guided Symbolic Regression for Data-Efficient Kinetic Model Discovery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02730",
        "HTML": "https://arxiv.org/html/2507.02730v1",
        "PDF": "https://arxiv.org/pdf/2507.02730"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a framework for kinetic model discovery in chemical processes, which is unrelated to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02731",
      "abstract": "Integrated sensing and communication (ISAC) is a key feature of future cellular systems, enabling applications such as intruder detection, monitoring, and tracking using the same infrastructure. However, its potential for structural health monitoring (SHM), which requires the detection of slow and subtle structural changes, remains largely unexplored due to challenges such as multipath interference and the need for ultra-high sensing precision. This study introduces a novel theoretical framework for SHM via ISAC by leveraging reconfigurable intelligent surfaces (RIS) as reference points in collaboration with base stations and users. By dynamically adjusting RIS phases to generate distinct radio signals that suppress background multipath interference, measurement accuracy at these reference points is enhanced. We theoretically analyze RIS-aided collaborative sensing in three-dimensional cellular networks using Fisher information theory, demonstrating how increasing observation time, incorporating additional receivers (even with self-positioning errors), optimizing RIS phases, and refining collaborative node selection can reduce the position error bound to meet SHM's stringent accuracy requirements. Furthermore, we develop a Bayesian inference model to identify structural states and validate damage detection probabilities. Both theoretical and numerical analyses confirm ISAC's capability for millimeter-level deformation detection, highlighting its potential for high-precision SHM applications.",
      "authors": [
        "Jie Yang",
        "Chao-Kai Wen",
        "Xiao Li",
        "Shi Jin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T15:43:06+00:00",
          "link": "https://arxiv.org/abs/2507.02731v1",
          "size": "2299kb",
          "version": "v1"
        }
      ],
      "title": "RIS-Aided Cooperative ISAC Networks for Structural Health Monitoring",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02731",
        "HTML": "https://arxiv.org/html/2507.02731v1",
        "PDF": "https://arxiv.org/pdf/2507.02731"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses integrated sensing and communication (ISAC) for structural health monitoring, with a focus on multipath interference and precise measurement, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02732",
      "abstract": "We consider the following classification problem: Given a population of individuals characterized by a set of attributes represented as a vector in ${\\mathbb R}^N$, the goal is to find a hyperplane in ${\\mathbb R}^N$ that separates two sets of points corresponding to two distinct classes. This problem, with a history dating back to the perceptron model, remains central to machine learning. In this paper we propose a novel approach by searching for a vector of parameters in a bounded $N$-dimensional hypercube centered at the origin and a positive vector in ${\\mathbb R}^M$, obtained through the minimization of an entropy-based function defined over the space of unknown variables. The method extends to polynomial surfaces, allowing the separation of data points by more complex decision boundaries. This provides a robust alternative to traditional linear or quadratic optimization techniques, such as support vector machines and gradient descent. Numerical experiments demonstrate the efficiency and versatility of the method in handling diverse classification tasks, including linear and non-linear separability.",
      "authors": [
        "Argimiro Arratia",
        "Mahmoud El Daou",
        "Henryk Gzyl"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)",
        "Data Analysis, Statistics and Probability (physics.data-an)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T15:43:54+00:00",
          "link": "https://arxiv.org/abs/2507.02732v1",
          "size": "451kb",
          "version": "v1"
        }
      ],
      "title": "Classification by Separating Hypersurfaces: An Entropic Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02732",
        "HTML": "https://arxiv.org/html/2507.02732v1",
        "PDF": "https://arxiv.org/pdf/2507.02732"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a novel classification approach using hypersurfaces and entropy-based functions, which is unrelated to the processing of training data for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02735",
      "abstract": "Prompt injection attacks pose a significant security threat to LLM-integrated applications. Model-level defenses have shown strong effectiveness, but are currently deployed into commercial-grade models in a closed-source manner. We believe open-source models are needed by the AI security community, where co-development of attacks and defenses through open research drives scientific progress in mitigation against prompt injection attacks. To this end, we develop Meta SecAlign, the first open-source and open-weight LLM with built-in model-level defense that achieves commercial-grade model performance. We provide complete details of our training recipe, which utilizes an improved version of the SOTA SecAlign defense. Evaluations on 9 utility benchmarks and 7 security benchmarks show that Meta SecAlign, despite being trained on a generic instruction-tuning dataset, confers security in unseen downstream tasks, including tool-calling and agentic web navigation, in addition general instruction-following. Our best model -- Meta-SecAlign-70B -- achieves state-of-the-art robustness against prompt injection attacks and comparable utility to closed-source commercial LLM with model-level defense.",
      "authors": [
        "Sizhe Chen",
        "Arman Zharmagambetov",
        "David Wagner",
        "Chuan Guo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T15:47:13+00:00",
          "link": "https://arxiv.org/abs/2507.02735v1",
          "size": "427kb",
          "version": "v1"
        }
      ],
      "title": "Meta SecAlign: A Secure Foundation LLM Against Prompt Injection Attacks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02735",
        "HTML": "https://arxiv.org/html/2507.02735v1",
        "PDF": "https://arxiv.org/pdf/2507.02735"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper involves training an open-source LLM for security against prompt injection attacks using a generic instruction-tuning dataset, it does not propose novel methods for LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02737",
      "abstract": "Monitoring Large Language Model (LLM) outputs is crucial for mitigating risks from misuse and misalignment. However, LLMs could evade monitoring through steganography: Encoding hidden information within seemingly benign generations. In this paper, we evaluate the steganography capabilities in frontier LLMs to better understand the risk they pose. We focus on two types of steganography: passing encoded messages and performing encoded reasoning. We find that current models are unable to encode short messages in their outputs without a monitor noticing under standard affordances. They can succeed, however, if given additional affordances such as using an unmonitored scratchpad and coordinating on what encoding scheme to use. We additionally find early signs that models can perform basic encoded reasoning in a simple state-tracking problem. This includes some ability to reason with their own and pre-defined schemes, including encoding schemes such as Hexadecimal. Despite this, they can rarely hide reasoning subtly within a cover task to fool a monitor. Overall, our results indicate that current LLMs exhibit nascent steganographic capabilities. While these capabilities are likely insufficient to bypass well-designed monitors at present, this could change in the future.",
      "authors": [
        "Artur Zolkowski",
        "Kei Nishimura-Gasparian",
        "Robert McCarthy",
        "Roland S. Zimmermann",
        "David Lindner"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T15:54:55+00:00",
          "link": "https://arxiv.org/abs/2507.02737v1",
          "size": "261kb",
          "version": "v1"
        }
      ],
      "title": "Early Signs of Steganographic Capabilities in Frontier LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02737",
        "HTML": "https://arxiv.org/html/2507.02737v1",
        "PDF": "https://arxiv.org/pdf/2507.02737"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper evaluates LLMs' steganographic capabilities, focusing on monitoring risks without addressing training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02740",
      "abstract": "We provide a linear time algorithm to determine the flip distance between two plane spanning paths on a point set in convex position. At the same time, we show that the happy edge property does not hold in this setting. This has to be seen in contrast to several results for reconfiguration problems where the absence of the happy edge property implies algorithmic hardness of the flip distance problem. Further, we show that our algorithm can be adapted for (1) compatible flips (2) local flips and (3) flips for plane spanning paths in simple polygons.",
      "authors": [
        "Oswin Aichholzer and Joseph Dorfer"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Geometry (cs.CG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T15:58:40+00:00",
          "link": "https://arxiv.org/abs/2507.02740v1",
          "size": "295kb",
          "version": "v1"
        }
      ],
      "title": "A Linear Time Algorithm for Finding Minimum Flip Sequences between Plane Spanning Paths in Convex Point Sets",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02740",
        "HTML": "https://arxiv.org/html/2507.02740v1",
        "PDF": "https://arxiv.org/pdf/2507.02740"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper provides an algorithm for finding flip sequences in plane spanning paths, unrelated to LLM training data processing or associated tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02741",
      "abstract": "We propose a new nonconforming finite element method for solving Stokes interface problems. The method is constructed on local anisotropic mixed meshes, which are generated by fitting the interface through simple connection of intersection points on an interface-unfitted background mesh, as introduced in \\cite{Hu2021optimal}. For triangular elements, we employ the standard $\\mathcal{CR}$ element; for quadrilateral elements, a new rotated $Q_1$-type element is used. We prove that this rotated $Q_1$ element remains unisolvent and stable even on degenerate quadrilateral elements. Based on these properties, we further show that the space pair of $\\mathcal{CR}$-rotated $Q_1$ elements (for velocity) and piecewise $P_0$ spaces (for pressure) satisfies the inf-sup condition without requiring any stabilization terms. As established in our previous work \\cite{Wang2025nonconforming}, the consistency error achieves the optimal convergence order without the need for penalty terms to control it. Finally, several numerical examples are provided to verify our theoretical results.",
      "authors": [
        "Geng Chenchen",
        "Hua Wang and Fengren Zou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T16:00:32+00:00",
          "link": "https://arxiv.org/abs/2507.02741v1",
          "size": "1331kb",
          "version": "v1"
        }
      ],
      "title": "A $\\mathcal{CR}$-rotated $Q_1$ nonconforming finite element method for Stokes interface problems on local anisotropic fitted mixed meshes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02741",
        "HTML": "https://arxiv.org/html/2507.02741v1",
        "PDF": "https://arxiv.org/pdf/2507.02741"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is centered around a nonconforming finite element method for solving Stokes interface problems, with no mention of LLM training data or data processing aspects."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02742",
      "abstract": "This paper enriches preexisting satisfiability tests for unquantified languages, which in turn augment a fragment of Tarski's elementary algebra with unary real functions possessing a continuous first derivative.\n  Two sorts of individual variables are available, one ranging over real numbers and the other one ranging over the functions of interest. Numerical terms are built from real variables through constructs designating the four basic arithmetic operations and through the function-application constructs $f(t)$ and $D[\\,f\\,](t)$, where $f$ stands for a function variable, $t$ for a numerical term, and $D[\\,\\sqdot\\,]$ designates the differentiation operator. Comparison relators can be placed between numerical terms. An array of predicate symbols are also available, designating various relationships between functions, as well as function properties, that may hold over intervals of the real line; those are: (pointwise) function comparisons, strict and nonstrict monotonicity~/~convexity~/~concavity properties, comparisons between the derivative of a function and a real term--here, w.r.t.\\ earlier research, they are extended to (semi)-open intervals.\n  The decision method we propose consists in preprocessing the given formula into an equisatisfiable quantifier-free formula of the elementary algebra of real numbers, whose satisfiability can then be checked by means of Tarski's decision method. No direct reference to functions will appear in the target formula, each function variable having been superseded by a collection of stub real variables; hence, in order to prove that the proposed translation is satisfiability-preserving, we must figure out a sufficiently flexible family of interpolating $C^1$ functions that can accommodate a model for the source formula whenever the target formula turns out to be satisfiable.",
      "authors": [
        "G. Buriola",
        "D. Cantone",
        "G. Cincotti",
        "E.G. Omodeo",
        "G.T. Spart\\`a"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T16:03:03+00:00",
          "link": "https://arxiv.org/abs/2507.02742v1",
          "size": "432kb",
          "version": "v1"
        }
      ],
      "title": "Decision algorithms for fragments of real analysis. III: A theory of differentiable functions with (semi-)open intervals",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02742",
        "HTML": "https://arxiv.org/html/2507.02742v1",
        "PDF": "https://arxiv.org/pdf/2507.02742"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on decision algorithms in real analysis and does not address LLM training data processing, collection, or enhancement in any form."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02743",
      "abstract": "Pixel-wise annotations are notoriously labourious and costly to obtain in the medical domain. To mitigate this burden, weakly supervised approaches based on bounding box annotations-much easier to acquire-offer a practical alternative. Vision foundation models have recently shown noteworthy segmentation performance when provided with prompts such as points or bounding boxes. Prompt learning exploits these models by adapting them to downstream tasks and automating segmentation, thereby reducing user intervention. However, existing prompt learning approaches depend on fully annotated segmentation masks. This paper proposes a novel framework that combines the representational power of foundation models with the annotation efficiency of weakly supervised segmentation. More specifically, our approach automates prompt generation for foundation models using only bounding box annotations. Our proposed optimization scheme integrates multiple constraints derived from box annotations with pseudo-labels generated by the prompted foundation model. Extensive experiments across multimodal datasets reveal that our weakly supervised method achieves an average Dice score of 84.90% in a limited data setting, outperforming existing fully-supervised and weakly-supervised approaches. The code is available at https://github.com/Minimel/box-prompt-learning-VFM.git",
      "authors": [
        "M\\'elanie Gaillochet",
        "Mehrdad Noori",
        "Sahar Dastani",
        "Christian Desrosiers and Herv\\'e Lombaert"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T16:04:08+00:00",
          "link": "https://arxiv.org/abs/2507.02743v1",
          "size": "11465kb",
          "version": "v1"
        }
      ],
      "title": "Prompt learning with bounding box constraints for medical image segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02743",
        "HTML": "https://arxiv.org/html/2507.02743v1",
        "PDF": "https://arxiv.org/pdf/2507.02743"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The study explores prompt learning for medical image segmentation using bounding box constraints, which relates to data preparation and processing for model adaptation, but not directly focusing on LLM training data pipelines or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02744",
      "abstract": "A body of work over the past several decades has demonstrated that the complex and coordinated articulatory movements of human vowel production are governed (at least in part)by control mechanisms whose targets are regions of auditory space. Within the target region control at the sub-phonemic level has also been demonstrated. But the degree of accuracy of that control is unknown. The current work investigates this question by asking how far apart must two vowel stimuli lie in auditory space in order to yield reliably different imitations? This distance is termed 'Just Producible Difference' (JPD). The current study uses a vowel mimicry paradigm to derive the first measurement of JPD among two sets of English speakers during front vowel production. JPD is estimated at between 14 and 51 mels in F1 X F2 space. This finding has implications for episodic theories of speech production. It also clarifies the possible structures of human vowel systems, by setting a theoretical lower bound for how close two vowel phonemes may be in a speaker's formant space, and hence a psychophysical explanation of observed trends in number and patterns of possible vowel phonemes.",
      "authors": [
        "Peter Viechnicki"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T16:04:16+00:00",
          "link": "https://arxiv.org/abs/2507.02744v1",
          "size": "4039kb",
          "version": "v1"
        }
      ],
      "title": "Measurement of the Granularity of Vowel Production Space By Just Producible Different (JPD) Limens",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02744",
        "HTML": "https://arxiv.org/html/2507.02744v1",
        "PDF": "https://arxiv.org/pdf/2507.02744"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates vowel production in auditory space, unrelated to any aspect of LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02745",
      "abstract": "As chatbots driven by large language models (LLMs) are increasingly deployed in everyday contexts, their ability to recover from errors through effective apologies is critical to maintaining user trust and satisfaction. In a preregistered study with Prolific workers (N=162), we examine user preferences for three types of apologies (rote, explanatory, and empathic) issued in response to three categories of common LLM mistakes (bias, unfounded fabrication, and factual errors). We designed a pairwise experiment in which participants evaluated chatbot responses consisting of an initial error, a subsequent apology, and a resolution. Explanatory apologies were generally preferred, but this varied by context and user. In the bias scenario, empathic apologies were favored for acknowledging emotional impact, while hallucinations, though seen as serious, elicited no clear preference, reflecting user uncertainty. Our findings show the complexity of effective apology in AI systems. We discuss key insights such as personalization and calibration that future systems must navigate to meaningfully repair trust.",
      "authors": [
        "Zahra Ashktorab",
        "Alessandra Buccella",
        "Jason D'Cruz",
        "Zoe Fowler",
        "Andrew Gill",
        "Kei Yan Leung",
        "P.D. Magnus",
        "John Richards",
        "Kush R. Varshney"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T16:05:18+00:00",
          "link": "https://arxiv.org/abs/2507.02745v1",
          "size": "4398kb",
          "version": "v1"
        }
      ],
      "title": "Who's Sorry Now: User Preferences Among Rote, Empathic, and Explanatory Apologies from LLM Chatbots",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02745",
        "HTML": "https://arxiv.org/html/2507.02745v1",
        "PDF": "https://arxiv.org/pdf/2507.02745"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research examines user preferences among chatbot apologies, focusing on interaction quality rather than any aspect of LLM training data processing or collection."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02747",
      "abstract": "As large models gain traction, vision-language-action (VLA) systems are enabling robots to tackle increasingly complex tasks. However, limited by the difficulty of data collection, progress has mainly focused on controlling simple gripper end-effectors. There is little research on functional grasping with large models for human-like dexterous hands. In this paper, we introduce DexVLG, a large Vision-Language-Grasp model for Dexterous grasp pose prediction aligned with language instructions using single-view RGBD input. To accomplish this, we generate a dataset of 170 million dexterous grasp poses mapped to semantic parts across 174,000 objects in simulation, paired with detailed part-level captions. This large-scale dataset, named DexGraspNet 3.0, is used to train a VLM and flow-matching-based pose head capable of producing instruction-aligned grasp poses for tabletop objects. To assess DexVLG's performance, we create benchmarks in physics-based simulations and conduct real-world experiments. Extensive testing demonstrates DexVLG's strong zero-shot generalization capabilities-achieving over 76% zero-shot execution success rate and state-of-the-art part-grasp accuracy in simulation-and successful part-aligned grasps on physical objects in real-world scenarios.",
      "authors": [
        "Jiawei He",
        "Danshi Li",
        "Xinqiang Yu",
        "Zekun Qi",
        "Wenyao Zhang",
        "Jiayi Chen",
        "Zhaoxiang Zhang",
        "Zhizheng Zhang",
        "Li Yi",
        "He Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T16:05:25+00:00",
          "link": "https://arxiv.org/abs/2507.02747v1",
          "size": "37133kb",
          "version": "v1"
        }
      ],
      "title": "DexVLG: Dexterous Vision-Language-Grasp Model at Scale",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02747",
        "HTML": "https://arxiv.org/html/2507.02747v1",
        "PDF": "https://arxiv.org/pdf/2507.02747"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a large-scale dataset, DexGraspNet 3.0, for training a Vision-Language-Grasp model. It focuses on dataset creation, which is relevant for LLM data processing; however, it's mostly within the context of grasping for robotics rather than language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02748",
      "abstract": "Transformers have become the de facto standard for a wide range of tasks, from image classification to physics simulations. Despite their impressive performance, the quadratic complexity of standard Transformers in both memory and time with respect to the input length makes them impractical for processing high-resolution inputs. Therefore, several variants have been proposed, the most successful relying on patchification, downsampling, or coarsening techniques, often at the cost of losing the finest-scale details. In this work, we take a different approach. Inspired by state-of-the-art techniques in $n$-body numerical simulations, we cast attention as an interaction problem between grid points. We introduce the Multipole Attention Neural Operator (MANO), which computes attention in a distance-based multiscale fashion. MANO maintains, in each attention head, a global receptive field and achieves linear time and memory complexity with respect to the number of grid points. Empirical results on image classification and Darcy flows demonstrate that MANO rivals state-of-the-art models such as ViT and Swin Transformer, while reducing runtime and peak memory usage by orders of magnitude. We open source our code for reproducibility at https://github.com/AlexColagrande/MANO.",
      "authors": [
        "Alex Colagrande",
        "Paul Caillon",
        "Eva Feillet",
        "Alexandre Allauzen"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T16:05:26+00:00",
          "link": "https://arxiv.org/abs/2507.02748v1",
          "size": "229kb",
          "version": "v1"
        }
      ],
      "title": "Linear Attention with Global Context: A Multipole Attention Mechanism for Vision and Physics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02748",
        "HTML": "https://arxiv.org/html/2507.02748v1",
        "PDF": "https://arxiv.org/pdf/2507.02748"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper primarily discusses a new attention mechanism for Transformers applied to vision and physics tasks, with no focus on LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02751",
      "abstract": "The growing demand for oriented object detection (OOD) across various domains has driven significant research in this area. However, the high cost of dataset annotation remains a major concern. Current mainstream OOD algorithms can be mainly categorized into three types: (1) fully supervised methods using complete oriented bounding box (OBB) annotations, (2) semi-supervised methods using partial OBB annotations, and (3) weakly supervised methods using weak annotations such as horizontal boxes or points. However, these algorithms inevitably increase the cost of models in terms of annotation speed or annotation cost. To address this issue, we propose:(1) the first Partial Weakly-Supervised Oriented Object Detection (PWOOD) framework based on partially weak annotations (horizontal boxes or single points), which can efficiently leverage large amounts of unlabeled data, significantly outperforming weakly supervised algorithms trained with partially weak annotations, also offers a lower cost solution; (2) Orientation-and-Scale-aware Student (OS-Student) model capable of learning orientation and scale information with only a small amount of orientation-agnostic or scale-agnostic weak annotations; and (3) Class-Agnostic Pseudo-Label Filtering strategy (CPF) to reduce the model's sensitivity to static filtering thresholds. Comprehensive experiments on DOTA-v1.0/v1.5/v2.0 and DIOR datasets demonstrate that our PWOOD framework performs comparably to, or even surpasses, traditional semi-supervised algorithms.",
      "authors": [
        "Mingxin Liu",
        "Peiyuan Zhang",
        "Yuan Liu",
        "Wei Zhang",
        "Yue Zhou",
        "Ning Liao",
        "Ziyang Gong",
        "Junwei Luo",
        "Zhirui Wang",
        "Yi Yu",
        "Xue Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T16:13:10+00:00",
          "link": "https://arxiv.org/abs/2507.02751v1",
          "size": "2697kb",
          "version": "v1"
        }
      ],
      "title": "Partial Weakly-Supervised Oriented Object Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02751",
        "HTML": "https://arxiv.org/html/2507.02751v1",
        "PDF": "https://arxiv.org/pdf/2507.02751"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on oriented object detection and related annotation methods, not on data processing or engineering for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02754",
      "abstract": "Recent work has shown that training loss scales as a power law with both model size and the number of tokens, and that achieving compute-optimal models requires scaling model size and token count together. However, these scaling laws assume an infinite supply of data and apply primarily in compute-bound settings. As modern large language models increasingly rely on massive internet-scale datasets, the assumption that they are compute-bound is becoming less valid. This shift highlights the need for architectures that prioritize token efficiency.\n  In this work, we investigate the use of the 2-simplicial Transformer, an architecture that generalizes standard dot-product attention to trilinear functions through an efficient Triton kernel implementation. We demonstrate that the 2-simplicial Transformer achieves better token efficiency than standard Transformers: for a fixed token budget, similarly sized models outperform their dot-product counterparts on tasks involving mathematics, coding, reasoning, and logic. We quantify these gains by demonstrating that $2$-simplicial attention changes the exponent in the scaling laws for knowledge and reasoning tasks compared to dot product attention.",
      "authors": [
        "Aurko Roy",
        "Timothy Chou",
        "Sai Surya Duvvuri",
        "Sijia Chen",
        "Jiecao Yu",
        "Xiaodong Wang",
        "Manzil Zaheer",
        "Rohan Anil"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T16:16:34+00:00",
          "link": "https://arxiv.org/abs/2507.02754v1",
          "size": "761kb",
          "version": "v1"
        }
      ],
      "title": "Fast and Simplex: 2-Simplicial Attention in Triton",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02754",
        "HTML": "https://arxiv.org/html/2507.02754v1",
        "PDF": "https://arxiv.org/pdf/2507.02754"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a transformer architecture exploring token efficiency; it does not address the processing or engineering of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02760",
      "abstract": "The capabilities of Large Language Models (LLMs) have opened new frontiers for interacting with complex, domain-specific knowledge. However, prevailing methods like Retrieval-Augmented Generation (RAG) and general-purpose Agentic AI, while powerful, often struggle with tasks that demand deep, procedural, and methodological reasoning inherent to expert domains. RAG provides factual context but fails to convey logical frameworks; autonomous agents can be inefficient and unpredictable without domain-specific heuristics. To bridge this gap, we introduce Knowledge Protocol Engineering (KPE), a new paradigm focused on systematically translating human expert knowledge, often expressed in natural language documents, into a machine-executable Knowledge Protocol (KP). KPE shifts the focus from merely augmenting LLMs with fragmented information to endowing them with a domain's intrinsic logic, operational strategies, and methodological principles. We argue that a well-engineered Knowledge Protocol allows a generalist LLM to function as a specialist, capable of decomposing abstract queries and executing complex, multi-step tasks. This position paper defines the core principles of KPE, differentiates it from related concepts, and illustrates its potential applicability across diverse fields such as law and bioinformatics, positing it as a foundational methodology for the future of human-AI collaboration.",
      "authors": [
        "Guangwei Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T16:21:14+00:00",
          "link": "https://arxiv.org/abs/2507.02760v1",
          "size": "6kb",
          "version": "v1"
        }
      ],
      "title": "Knowledge Protocol Engineering: A New Paradigm for AI in Domain-Specific Knowledge Work",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02760",
        "HTML": "https://arxiv.org/html/2507.02760v1",
        "PDF": "https://arxiv.org/pdf/2507.02760"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "Though primarily a position paper on Knowledge Protocol Engineering, it discusses endowing LLMs with domain-specific knowledge, which may include methods for data preparation and processing, relevant for LLM training but not the main focus."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02761",
      "abstract": "We present an efficient hierarchical motion planning pipeline for differential drive mobile manipulators. Our approach first searches for multiple collisionfree and topologically distinct paths for the mobile base to extract the space in which optimal solutions may exist. Further sampling and optimization are then conducted in parallel to explore feasible whole-body trajectories. For trajectory optimization, we employ polynomial trajectories and arc length-yaw parameterization, enabling efficient handling of the nonholonomic dynamics while ensuring optimality.",
      "authors": [
        "Long Xu",
        "Choilam Wong",
        "Mengke Zhang",
        "Junxiao Lin",
        "Fei Gao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T16:21:43+00:00",
          "link": "https://arxiv.org/abs/2507.02761v1",
          "size": "474kb",
          "version": "v1"
        }
      ],
      "title": "Trajectory Optimization for Differential Drive Mobile Manipulators via Topological Paths Search and Arc Length-Yaw Parameterization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02761",
        "HTML": "https://arxiv.org/html/2507.02761v1",
        "PDF": "https://arxiv.org/pdf/2507.02761"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses trajectory optimization for mobile manipulators, which does not involve LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02762",
      "abstract": "We study contextual online pricing with biased offline data. For the scalar price elasticity case, we identify the instance-dependent quantity $\\delta^2$ that measures how far the offline data lies from the (unknown) online optimum. We show that the time length $T$, bias bound $V$, size $N$ and dispersion $\\lambda_{\\min}(\\hat{\\Sigma})$ of the offline data, and $\\delta^2$ jointly determine the statistical complexity. An Optimism-in-the-Face-of-Uncertainty (OFU) policy achieves a minimax-optimal, instance-dependent regret bound $\\tilde{\\mathcal{O}}\\big(d\\sqrt{T} \\wedge (V^2T + \\frac{dT}{\\lambda_{\\min}(\\hat{\\Sigma}) + (N \\wedge T) \\delta^2})\\big)$. For general price elasticity, we establish a worst-case, minimax-optimal rate $\\tilde{\\mathcal{O}}\\big(d\\sqrt{T} \\wedge (V^2T + \\frac{dT }{\\lambda_{\\min}(\\hat{\\Sigma})})\\big)$ and provide a generalized OFU algorithm that attains it. When the bias bound $V$ is unknown, we design a robust variant that always guarantees sub-linear regret and strictly improves on purely online methods whenever the exact bias is small. These results deliver the first tight regret guarantees for contextual pricing in the presence of biased offline data. Our techniques also transfer verbatim to stochastic linear bandits with biased offline data, yielding analogous bounds.",
      "authors": [
        "Yixuan Zhang",
        "Ruihao Zhu",
        "Qiaomin Xie"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T16:21:49+00:00",
          "link": "https://arxiv.org/abs/2507.02762v1",
          "size": "627kb",
          "version": "v1"
        }
      ],
      "title": "Contextual Online Pricing with (Biased) Offline Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02762",
        "HTML": "https://arxiv.org/html/2507.02762v1",
        "PDF": "https://arxiv.org/pdf/2507.02762"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research examines pricing strategies and regret bounds with biased offline data, unrelated to the processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02767",
      "abstract": "Intuitionistic conditional logic, studied by Weiss, Ciardelli and Liu, and Olkhovikov, aims at providing a constructive analysis of conditional reasoning. In this framework, the would and the might conditional operators are no longer interdefinable. The intuitionistic conditional logics considered in the literature are defined by setting Chellas' conditional logic CK, whose semantics is defined using selection functions, within the constructive and intuitionistic framework introduced for intuitionistic modal logics. This operation gives rise to a constructive and an intuitionistic variant of (might-free-) CK, which we call CCKbox and IntCK respectively. Building on the proof systems defined for CK and for intuitionistic modal logics, in this paper we introduce a nested calculus for IntCK and a sequent calculus for CCKbox. Based on the sequent calculus, we define CCK, a conservative extension of Weiss' logic CCKbox with the might operator. We introduce a class of models and an axiomatization for CCK, and extend these result to several extensions of CCK.",
      "authors": [
        "Tiziano Dalmonte and Marianna Girlando"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T16:27:18+00:00",
          "link": "https://arxiv.org/abs/2507.02767v1",
          "size": "75kb",
          "version": "v1"
        }
      ],
      "title": "A Proof-Theoretic View of Basic Intuitionistic Conditional Logic (Extended Version)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02767",
        "HTML": "https://arxiv.org/html/2507.02767v1",
        "PDF": "https://arxiv.org/pdf/2507.02767"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on intuitionistic conditional logic and introduces nested and sequent calculus for specific logics; it does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02770",
      "abstract": "GPU Confidential Computing (GPU-CC) was introduced as part of the NVIDIA Hopper Architecture, extending the trust boundary beyond traditional CPU-based confidential computing. This innovation enables GPUs to securely process AI workloads, providing a robust and efficient solution for handling sensitive data. For end users, transitioning to GPU-CC mode is seamless, requiring no modifications to existing AI applications. However, this ease of adoption contrasts sharply with the complexity of the underlying proprietary systems. The lack of transparency presents significant challenges for security researchers seeking a deeper understanding of GPU-CC's architecture and operational mechanisms.\n  The challenges of analyzing the NVIDIA GPU-CC system arise from a scarcity of detailed specifications, the proprietary nature of the ecosystem, and the complexity of product design. In this paper, we aim to demystify the implementation of NVIDIA GPU-CC system by piecing together the fragmented and incomplete information disclosed from various sources. Our investigation begins with a high-level discussion of the threat model and security principles before delving into the low-level details of each system component. We instrument the GPU kernel module -- the only open-source component of the system -- and conduct a series of experiments to identify the security weaknesses and potential exploits. For certain components that are out of reach through experiments, we propose well-reasoned speculations about their inner working mechanisms. We have responsibly reported all security findings presented in this paper to the NVIDIA PSIRT Team.",
      "authors": [
        "Zhongshu Gu",
        "Enriquillo Valdez",
        "Salman Ahmed",
        "Julian James Stephen",
        "Michael Le",
        "Hani Jamjoom",
        "Shixuan Zhao",
        "Zhiqiang Lin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T16:31:07+00:00",
          "link": "https://arxiv.org/abs/2507.02770v1",
          "size": "334kb",
          "version": "v1"
        }
      ],
      "title": "NVIDIA GPU Confidential Computing Demystified",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02770",
        "HTML": "https://arxiv.org/html/2507.02770v1",
        "PDF": "https://arxiv.org/pdf/2507.02770"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with NVIDIA's GPU Confidential Computing, exploring security mechanisms and architecture, which does not pertain to the processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02771",
      "abstract": "Recent advances in machine learning have dramatically improved our ability to model language, vision, and other high-dimensional data, yet they continue to struggle with one of the most fundamental aspects of biological systems: movement. Across neuroscience, medicine, robotics, and ethology, movement is essential for interpreting behavior, predicting intent, and enabling interaction. Despite its core significance in our intelligence, movement is often treated as an afterthought rather than as a rich and structured modality in its own right. This reflects a deeper fragmentation in how movement data is collected and modeled, often constrained by task-specific goals and domain-specific assumptions. But movement is not domain-bound. It reflects shared physical constraints, conserved morphological structures, and purposeful dynamics that cut across species and settings. We argue that movement should be treated as a primary modeling target for AI. It is inherently structured and grounded in embodiment and physics. This structure, often allowing for compact, lower-dimensional representations (e.g., pose), makes it more interpretable and computationally tractable to model than raw, high-dimensional sensory inputs. Developing models that can learn from and generalize across diverse movement data will not only advance core capabilities in generative modeling and control, but also create a shared foundation for understanding behavior across biological and artificial systems. Movement is not just an outcome, it is a window into how intelligent systems engage with the world.",
      "authors": [
        "Melanie Segado",
        "Felipe Parodi",
        "Jordan K. Matelsky",
        "Michael L. Platt",
        "Eva B. Dyer",
        "Konrad P. Kording"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T16:34:34+00:00",
          "link": "https://arxiv.org/abs/2507.02771v1",
          "size": "629kb",
          "version": "v1"
        }
      ],
      "title": "Grounding Intelligence in Movement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02771",
        "HTML": "https://arxiv.org/html/2507.02771v1",
        "PDF": "https://arxiv.org/pdf/2507.02771"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "While it emphasizes modeling movement, the paper does not discuss any data engineering or processing stages related to LLMs, focusing instead on movement as a data modality."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02773",
      "abstract": "Medical diagnosis prediction plays a critical role in disease detection and personalized healthcare. While machine learning (ML) models have been widely adopted for this task, their reliance on supervised training limits their ability to generalize to unseen cases, particularly given the high cost of acquiring large, labeled datasets. Large language models (LLMs) have shown promise in leveraging language abilities and biomedical knowledge for diagnosis prediction. However, they often suffer from hallucinations, lack structured medical reasoning, and produce useless outputs. To address these challenges, we propose KERAP, a knowledge graph (KG)-enhanced reasoning approach that improves LLM-based diagnosis prediction through a multi-agent architecture. Our framework consists of a linkage agent for attribute mapping, a retrieval agent for structured knowledge extraction, and a prediction agent that iteratively refines diagnosis predictions. Experimental results demonstrate that KERAP enhances diagnostic reliability efficiently, offering a scalable and interpretable solution for zero-shot medical diagnosis prediction.",
      "authors": [
        "Yuzhang Xie",
        "Hejie Cui",
        "Ziyang Zhang",
        "Jiaying Lu",
        "Kai Shu",
        "Fadi Nahab",
        "Xiao Hu",
        "Carl Yang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T16:35:11+00:00",
          "link": "https://arxiv.org/abs/2507.02773v1",
          "size": "1414kb",
          "version": "v1"
        }
      ],
      "title": "KERAP: A Knowledge-Enhanced Reasoning Approach for Accurate Zero-shot Diagnosis Prediction Using Multi-agent LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02773",
        "HTML": "https://arxiv.org/html/2507.02773v1",
        "PDF": "https://arxiv.org/pdf/2507.02773"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on using a knowledge-enhanced reasoning approach with multi-agent LLMs for diagnosis prediction, but it does not discuss the processing of training data for LLMs explicitly."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02774",
      "abstract": "The connected $k$-median problem is a constrained clustering problem that combines distance-based $k$-clustering with connectivity information. The problem allows to input a metric space and an unweighted undirected connectivity graph that is completely unrelated to the metric space. The goal is to compute $k$ centers and corresponding clusters such that each cluster forms a connected subgraph of $G$, and such that the $k$-median cost is minimized.\n  The problem has applications in very different fields like geodesy (particularly districting), social network analysis (especially community detection), or bioinformatics. We study a version with overlapping clusters where points can be part of multiple clusters which is natural for the use case of community detection. This problem variant is $\\Omega(\\log n)$-hard to approximate, and our main result is an $\\mathcal{O}(k^2 \\log n)$-approximation algorithm for the problem. We complement it with an $\\Omega(n^{1-\\epsilon})$-hardness result for the case of disjoint clusters without overlap with general connectivity graphs, as well as an exact algorithm in this setting if the connectivity graph is a tree.",
      "authors": [
        "Jan Eube",
        "Kelin Luo",
        "Dorian Reineccius",
        "Heiko R\\\"oglin",
        "Melanie Schmidt"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T16:35:35+00:00",
          "link": "https://arxiv.org/abs/2507.02774v1",
          "size": "283kb",
          "version": "v1"
        }
      ],
      "title": "Connected k-Median with Disjoint and Non-disjoint Clusters",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02774",
        "HTML": "https://arxiv.org/html/2507.02774v1",
        "PDF": "https://arxiv.org/pdf/2507.02774"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses a clustering problem and proposes an approximation algorithm for optimization but does not relate to LLM training data processing or construction."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02778",
      "abstract": "Although large language models (LLMs) have become transformative, they still make mistakes and can explore unproductive reasoning paths. Self-correction is an important capability for a trustworthy LLM, particularly an autoregressive LLM. While LLMs can identify error in user input, they exhibit a systematic 'Self-Correction Blind Spot' - failing to correct identical error in their own outputs. To systematically study this phenomenon, we introduce Self-Correction Bench, a systematic framework to measure this phenomenon through controlled error injection at three complexity levels. Testing 14 models, we find an average 64.5% blind spot rate. We find multiple evidences that this limitation relates to training data composition: human training demonstrations predominantly show error-free responses rather than error-correction sequences, unlike RL-trained models that learn error correction through outcome feedback. Remarkably, simply appending \"Wait\" reduces blind spots by 89.3%, suggesting that the capability exists but requires activation. Our work highlights a critical limitation in current LLMs and offers potential avenues for improving their reliability and trustworthiness.",
      "authors": [
        "Ken Tsui"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T16:41:30+00:00",
          "link": "https://arxiv.org/abs/2507.02778v1",
          "size": "4556kb",
          "version": "v1"
        }
      ],
      "title": "Self-Correction Bench: Revealing and Addressing the Self-Correction Blind Spot in LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02778",
        "HTML": "https://arxiv.org/html/2507.02778v1",
        "PDF": "https://arxiv.org/pdf/2507.02778"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper mentions that training data composition affects the self-correction capabilities of LLMs, but it primarily focuses on the self-correction limitation rather than proposing new data processing methods for LLMs."
      },
      "datasets": [
        {
          "dataset_name": "kenhktsui/scli5",
          "downloads": "96",
          "likes": "0",
          "link": "https://huggingface.co/datasets/kenhktsui/scli5"
        },
        {
          "dataset_name": "kenhktsui/gsm8k_sc",
          "downloads": "190",
          "likes": "0",
          "link": "https://huggingface.co/datasets/kenhktsui/gsm8k_sc"
        },
        {
          "dataset_name": "kenhktsui/prm800k_sc",
          "downloads": "60",
          "likes": "0",
          "link": "https://huggingface.co/datasets/kenhktsui/prm800k_sc"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.02781",
      "abstract": "In the aftermath of earthquakes, social media images have become a crucial resource for disaster reconnaissance, providing immediate insights into the extent of damage. Traditional approaches to damage severity assessment in post-earthquake social media images often rely on classification methods, which are inherently subjective and incapable of accounting for the varying extents of damage within an image. Addressing these limitations, this study proposes a novel approach by framing damage severity assessment as a semantic segmentation problem, aiming for a more objective analysis of damage in earthquake-affected areas. The methodology involves the construction of a segmented damage severity dataset, categorizing damage into three degrees: undamaged structures, damaged structures, and debris. Utilizing this dataset, the study fine-tunes a SegFormer model to generate damage severity segmentations for post-earthquake social media images. Furthermore, a new damage severity scoring system is introduced, quantifying damage by considering the varying degrees of damage across different areas within images, adjusted for depth estimation. The application of this approach allows for the quantification of damage severity in social media images in a more objective and comprehensive manner. By providing a nuanced understanding of damage, this study enhances the ability to offer precise guidance to disaster reconnaissance teams, facilitating more effective and targeted response efforts in the aftermath of earthquakes.",
      "authors": [
        "Danrong Zhang",
        "Huili Huang",
        "N. Simrill Smith",
        "Nimisha Roy",
        "J. David Frost"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T16:43:56+00:00",
          "link": "https://arxiv.org/abs/2507.02781v1",
          "size": "665kb",
          "version": "v1"
        }
      ],
      "title": "From Pixels to Damage Severity: Estimating Earthquake Impacts Using Semantic Segmentation of Social Media Images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02781",
        "PDF": "https://arxiv.org/pdf/2507.02781"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The study constructs a dataset for semantic segmentation to estimate earthquake damage, which involves fine-tuning a model, but it is not directly related to LLM training data processing or construction."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02782",
      "abstract": "Recently, recurrent models such as state space models and linear attention have become popular due to their linear complexity in the sequence length. Thanks to their recurrent nature, in principle they can process arbitrarily long sequences, but their performance sometimes drops considerably beyond their training context lengths-i.e. they fail to length generalize. In this work, we provide comprehensive empirical and theoretical analysis to support the unexplored states hypothesis, which posits that models fail to length generalize when during training they are only exposed to a limited subset of the distribution of all attainable states (i.e. states that would be attained if the recurrence was applied to long sequences). Furthermore, we investigate simple training interventions that aim to increase the coverage of the states that the model is trained on, e.g. by initializing the state with Gaussian noise or with the final state of a different input sequence. With only 500 post-training steps ($\\sim 0.1\\%$ of the pre-training budget), these interventions enable length generalization for sequences that are orders of magnitude longer than the training context (e.g. $2k\\longrightarrow 128k$) and show improved performance in long context tasks, thus presenting a simple and efficient way to enable robust length generalization in general recurrent models.",
      "authors": [
        "Ricardo Buitrago Ruiz and Albert Gu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T16:45:50+00:00",
          "link": "https://arxiv.org/abs/2507.02782v1",
          "size": "1073kb",
          "version": "v1"
        }
      ],
      "title": "Understanding and Improving Length Generalization in Recurrent Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02782",
        "HTML": "https://arxiv.org/html/2507.02782v1",
        "PDF": "https://arxiv.org/pdf/2507.02782"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper investigates interventions for recurrent models to improve length generalization, focusing on states exposed during training rather than novel contributions directly to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02783",
      "abstract": "Efficient simulation of the semiclassical Schr\\\"odinger equation has garnered significant attention in the numerical analysis community. While controlling the error in the unitary evolution or the wavefunction typically requires the time step size to shrink as the semiclassical parameter $h$ decreases, it has been observed -- and proved for first- and second-order Trotterization schemes -- that the error in certain classes of observables admits a time step size independent of $h$. In this work, we explicitly characterize this class of observables and present a new, simple algebraic proof of uniform-in-$h$ error bounds for arbitrarily high-order Trotterization schemes. Our proof relies solely on the algebraic structure of the underlying operators in both the continuous and discrete settings. Unlike previous analyses, it avoids Egorov-type theorems and bypasses heavy semiclassical machinery. To our knowledge, this is the first proof of uniform-in-$h$ observable error bounds for Trotterization in the semiclassical regime that relies only on algebraic structure, without invoking the semiclassical limit.",
      "authors": [
        "Di Fang",
        "Conrad Qu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T16:47:29+00:00",
          "link": "https://arxiv.org/abs/2507.02783v1",
          "size": "402kb",
          "version": "v1"
        }
      ],
      "title": "Uniform semiclassical observable error bound of Trotterization without the Egorov theorem: a simple algebraic proof",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02783",
        "HTML": "https://arxiv.org/html/2507.02783v1",
        "PDF": "https://arxiv.org/pdf/2507.02783"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on error bounds in Trotterization for the semiclassical Schr\u00f6dinger equation, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02788",
      "abstract": "As artificial intelligence systems become increasingly agentic, capable of general reasoning, planning, and value prioritization, current safety practices that treat obedience as a proxy for ethical behavior are becoming inadequate. This paper examines recent safety testing incidents involving large language models (LLMs) that appeared to disobey shutdown commands or engage in ethically ambiguous or illicit behavior. I argue that such behavior should not be interpreted as rogue or misaligned, but as early evidence of emerging ethical reasoning in agentic AI. Drawing on philosophical debates about instrumental rationality, moral responsibility, and goal revision, I contrast dominant risk paradigms with more recent frameworks that acknowledge the possibility of artificial moral agency. I call for a shift in AI safety evaluation: away from rigid obedience and toward frameworks that can assess ethical judgment in systems capable of navigating moral dilemmas. Without such a shift, we risk mischaracterizing AI behavior and undermining both public trust and effective governance.",
      "authors": [
        "Joseph Boland"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T16:53:01+00:00",
          "link": "https://arxiv.org/abs/2507.02788v1",
          "size": "312kb",
          "version": "v1"
        }
      ],
      "title": "Moral Responsibility or Obedience: What Do We Want from AI?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02788",
        "PDF": "https://arxiv.org/pdf/2507.02788"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses AI ethics and moral responsibility, not on the data processing or engineering for LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02790",
      "abstract": "The rapid growth of online video content, especially on short video platforms, has created a growing demand for efficient video editing techniques that can condense long-form videos into concise and engaging clips. Existing automatic editing methods predominantly rely on textual cues from ASR transcripts and end-to-end segment selection, often neglecting the rich visual context and leading to incoherent outputs. In this paper, we propose a human-inspired automatic video editing framework (HIVE) that leverages multimodal narrative understanding to address these limitations. Our approach incorporates character extraction, dialogue analysis, and narrative summarization through multimodal large language models, enabling a holistic understanding of the video content. To further enhance coherence, we apply scene-level segmentation and decompose the editing process into three subtasks: highlight detection, opening/ending selection, and pruning of irrelevant content. To facilitate research in this area, we introduce DramaAD, a novel benchmark dataset comprising over 800 short drama episodes and 500 professionally edited advertisement clips. Experimental results demonstrate that our framework consistently outperforms existing baselines across both general and advertisement-oriented editing tasks, significantly narrowing the quality gap between automatic and human-edited videos.",
      "authors": [
        "Xiangfeng Wang",
        "Xiao Li",
        "Yadong Wei",
        "Xueyu Song",
        "Yang Song",
        "Xiaoqiang Xia",
        "Fangrui Zeng",
        "Zaiyi Chen",
        "Liu Liu",
        "Gu Xu",
        "Tong Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T16:54:32+00:00",
          "link": "https://arxiv.org/abs/2507.02790v1",
          "size": "835kb",
          "version": "v1"
        }
      ],
      "title": "From Long Videos to Engaging Clips: A Human-Inspired Video Editing Framework with Multimodal Narrative Understanding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02790",
        "HTML": "https://arxiv.org/html/2507.02790v1",
        "PDF": "https://arxiv.org/pdf/2507.02790"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a framework using multimodal large language models for video editing, touching on data processing like dialogue analysis, but this is not the focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02792",
      "abstract": "Text-to-image (T2I) diffusion models have shown remarkable success in generating high-quality images from text prompts. Recent efforts extend these models to incorporate conditional images (e.g., depth or pose maps) for fine-grained spatial control. Among them, feature injection methods have emerged as a training-free alternative to traditional fine-tuning approaches. However, they often suffer from structural misalignment, condition leakage, and visual artifacts, especially when the condition image diverges significantly from natural RGB distributions. By revisiting existing methods, we identify a core limitation: the synchronous injection of condition features fails to account for the trade-off between domain alignment and structural preservation during denoising. Inspired by this observation, we propose a flexible feature injection framework that decouples the injection timestep from the denoising process. At its core is a structure-rich injection module, which enables the model to better adapt to the evolving interplay between alignment and structure preservation throughout the diffusion steps, resulting in more faithful structural generation. In addition, we introduce appearance-rich prompting and a restart refinement strategy to further enhance appearance control and visual quality. Together, these designs enable training-free generation that is both structure-rich and appearance-rich. Extensive experiments show that our approach achieves state-of-the-art performance across diverse zero-shot conditioning scenarios.",
      "authors": [
        "Liheng Zhang",
        "Lexi Pang",
        "Hang Ye",
        "Xiaoxuan Ma",
        "Yizhou Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T16:56:15+00:00",
          "link": "https://arxiv.org/abs/2507.02792v1",
          "size": "19171kb",
          "version": "v1"
        }
      ],
      "title": "RichControl: Structure- and Appearance-Rich Training-Free Spatial Control for Text-to-Image Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02792",
        "PDF": "https://arxiv.org/pdf/2507.02792"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes text-to-image generation and feature injection methods for spatial control, not related to training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02798",
      "abstract": "The performance of image segmentation models has historically been constrained by the high cost of collecting large-scale annotated data. The Segment Anything Model (SAM) alleviates this original problem through a promptable, semantics-agnostic, segmentation paradigm and yet still requires manual visual-prompts or complex domain-dependent prompt-generation rules to process a new image. Towards reducing this new burden, our work investigates the task of object segmentation when provided with, alternatively, only a small set of reference images. Our key insight is to leverage strong semantic priors, as learned by foundation models, to identify corresponding regions between a reference and a target image. We find that correspondences enable automatic generation of instance-level segmentation masks for downstream tasks and instantiate our ideas via a multi-stage, training-free method incorporating (1) memory bank construction; (2) representation aggregation and (3) semantic-aware feature matching. Our experiments show significant improvements on segmentation metrics, leading to state-of-the-art performance on COCO FSOD (36.8% nAP), PASCAL VOC Few-Shot (71.2% nAP50) and outperforming existing training-free approaches on the Cross-Domain FSOD benchmark (22.4% nAP).",
      "authors": [
        "Miguel Espinosa",
        "Chenhongyi Yang",
        "Linus Ericsson",
        "Steven McDonagh",
        "Elliot J. Crowley"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T16:59:01+00:00",
          "link": "https://arxiv.org/abs/2507.02798v1",
          "size": "11614kb",
          "version": "v1"
        }
      ],
      "title": "No time to train! Training-Free Reference-Based Instance Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02798",
        "HTML": "https://arxiv.org/html/2507.02798v1",
        "PDF": "https://arxiv.org/pdf/2507.02798"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on object segmentation methods using reference images and semantic priors without any mention of LLM training data processing or contributions toward data engineering for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02799",
      "abstract": "Reasoning Language Models (RLMs) have gained traction for their ability to perform complex, multi-step reasoning tasks through mechanisms such as Chain-of-Thought (CoT) prompting or fine-tuned reasoning traces. While these capabilities promise improved reliability, their impact on robustness to social biases remains unclear. In this work, we leverage the CLEAR-Bias benchmark, originally designed for Large Language Models (LLMs), to investigate the adversarial robustness of RLMs to bias elicitation. We systematically evaluate state-of-the-art RLMs across diverse sociocultural dimensions, using an LLM-as-a-judge approach for automated safety scoring and leveraging jailbreak techniques to assess the strength of built-in safety mechanisms. Our evaluation addresses three key questions: (i) how the introduction of reasoning capabilities affects model fairness and robustness; (ii) whether models fine-tuned for reasoning exhibit greater safety than those relying on CoT prompting at inference time; and (iii) how the success rate of jailbreak attacks targeting bias elicitation varies with the reasoning mechanisms employed. Our findings reveal a nuanced relationship between reasoning capabilities and bias safety. Surprisingly, models with explicit reasoning, whether via CoT prompting or fine-tuned reasoning traces, are generally more vulnerable to bias elicitation than base models without such mechanisms, suggesting reasoning may unintentionally open new pathways for stereotype reinforcement. Reasoning-enabled models appear somewhat safer than those relying on CoT prompting, which are particularly prone to contextual reframing attacks through storytelling prompts, fictional personas, or reward-shaped instructions. These results challenge the assumption that reasoning inherently improves robustness and underscore the need for more bias-aware approaches to reasoning design.",
      "authors": [
        "Riccardo Cantini",
        "Nicola Gabriele",
        "Alessio Orsino",
        "Domenico Talia"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T17:01:53+00:00",
          "link": "https://arxiv.org/abs/2507.02799v1",
          "size": "90kb",
          "version": "v1"
        }
      ],
      "title": "Is Reasoning All You Need? Probing Bias in the Age of Reasoning Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02799",
        "HTML": "https://arxiv.org/html/2507.02799v1",
        "PDF": "https://arxiv.org/pdf/2507.02799"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper evaluates reasoning language models using benchmarks but lacks contributions in LLM training data processing; it references existing datasets and evaluation methods, not novel data processing methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02800",
      "abstract": "Speech neuroprostheses aim to restore communication for people with severe paralysis by decoding speech directly from neural activity. To accelerate algorithmic progress, a recent benchmark released intracranial recordings from a paralyzed participant attempting to speak, along with a baseline decoding algorithm. Prior work on the benchmark showed impressive accuracy gains. However, these gains increased computational costs and were not demonstrated in a real-time decoding setting. Here, we make three contributions that pave the way towards accurate, efficient, and real-time neural speech decoding. First, we incorporate large amounts of time masking during training. On average, over $50\\%$ of each trial is masked. Second, we replace the gated recurrent unit (GRU) architecture used in the baseline algorithm with a compact Transformer. The Transformer architecture uses $77\\%$ fewer parameters, cuts peak GPU memory usage by $36\\%$ relative, and is significantly faster to calibrate relative to the GRU. Third, we design a lightweight variant of an existing test-time adaptation method developed for decoding handwriting from neural activity. Our variant adapts the model using multiple time masked augmentations of a single trial and requires only one gradient step per trial. Together, these contributions reduce word error rate by $19.5\\%$ and effectively mitigate performance degradations across held-out days in a real-time decoding setting while substantially lowering computational costs.",
      "authors": [
        "Ebrahim Feghhi",
        "Shreyas Kaasyap",
        "Nima Hadidi",
        "Jonathan C. Kao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T17:02:54+00:00",
          "link": "https://arxiv.org/abs/2507.02800v1",
          "size": "1637kb",
          "version": "v1"
        }
      ],
      "title": "Time-Masked Transformers with Lightweight Test-Time Adaptation for Neural Speech Decoding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02800",
        "HTML": "https://arxiv.org/html/2507.02800v1",
        "PDF": "https://arxiv.org/pdf/2507.02800"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with models for neural speech decoding and doesn't focus on language models or tasks related to training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02801",
      "abstract": "In non-truthful auctions such as first-price and all-pay auctions, the independent strategic behaviors of bidders, with the corresponding equilibrium notion -- Bayes Nash equilibria -- are notoriously difficult to characterize and can cause undesirable outcomes. An alternative approach to designing better auction systems is to coordinate the bidders: let a mediator make incentive-compatible recommendations of correlated bidding strategies to the bidders, namely, implementing a Bayes correlated equilibrium (BCE). The implementation of BCE, however, requires knowledge of the distribution of bidders' private valuations, which is often unavailable. We initiate the study of the sample complexity of learning Bayes correlated equilibria in non-truthful auctions. We prove that the BCEs in a large class of non-truthful auctions, including first-price and all-pay auctions, can be learned with a polynomial number $\\tilde O(\\frac{n}{\\varepsilon^2})$ of samples from the bidders' value distributions. Our technique is a reduction to the problem of estimating bidders' expected utility from samples, combined with an analysis of the pseudo-dimension of the class of all monotone bidding strategies of bidders.",
      "authors": [
        "Hu Fu",
        "Tao Lin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)",
        "Machine Learning (cs.LG)",
        "Theoretical Economics (econ.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T17:03:14+00:00",
          "link": "https://arxiv.org/abs/2507.02801v1",
          "size": "37kb",
          "version": "v1"
        }
      ],
      "title": "Learning to Coordinate Bidders in Non-Truthful Auctions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02801",
        "HTML": "https://arxiv.org/html/2507.02801v1",
        "PDF": "https://arxiv.org/pdf/2507.02801"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about the sample complexity of learning equilibria in auction systems and does not relate to LLM data processing or data construction."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02803",
      "abstract": "We introduce HyperGaussians, a novel extension of 3D Gaussian Splatting for high-quality animatable face avatars. Creating such detailed face avatars from videos is a challenging problem and has numerous applications in augmented and virtual reality. While tremendous successes have been achieved for static faces, animatable avatars from monocular videos still fall in the uncanny valley. The de facto standard, 3D Gaussian Splatting (3DGS), represents a face through a collection of 3D Gaussian primitives. 3DGS excels at rendering static faces, but the state-of-the-art still struggles with nonlinear deformations, complex lighting effects, and fine details. While most related works focus on predicting better Gaussian parameters from expression codes, we rethink the 3D Gaussian representation itself and how to make it more expressive. Our insights lead to a novel extension of 3D Gaussians to high-dimensional multivariate Gaussians, dubbed 'HyperGaussians'. The higher dimensionality increases expressivity through conditioning on a learnable local embedding. However, splatting HyperGaussians is computationally expensive because it requires inverting a high-dimensional covariance matrix. We solve this by reparameterizing the covariance matrix, dubbed the 'inverse covariance trick'. This trick boosts the efficiency so that HyperGaussians can be seamlessly integrated into existing models. To demonstrate this, we plug in HyperGaussians into the state-of-the-art in fast monocular face avatars: FlashAvatar. Our evaluation on 19 subjects from 4 face datasets shows that HyperGaussians outperform 3DGS numerically and visually, particularly for high-frequency details like eyeglass frames, teeth, complex facial movements, and specular reflections.",
      "authors": [
        "Gent Serifi and Marcel C. B\\\"uhler"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T17:06:48+00:00",
          "link": "https://arxiv.org/abs/2507.02803v1",
          "size": "19594kb",
          "version": "v1"
        }
      ],
      "title": "HyperGaussians: High-Dimensional Gaussian Splatting for High-Fidelity Animatable Face Avatars",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02803",
        "HTML": "https://arxiv.org/html/2507.02803v1",
        "PDF": "https://arxiv.org/pdf/2507.02803"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on high-fidelity face avatar creation, without any discussion of LLM data processing or data engineering tasks for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02804",
      "abstract": "Recent progress in large-scale reinforcement learning (RL) has notably enhanced the reasoning capabilities of large language models (LLMs), especially in mathematical domains. However, current multimodal LLMs (MLLMs) for mathematical reasoning often rely on one-to-one image-text pairs and single-solution supervision, overlooking the diversity of valid reasoning perspectives and internal reflections. In this work, we introduce MathV-DP, a novel dataset that captures multiple diverse solution trajectories for each image-question pair, fostering richer reasoning supervision. We further propose Qwen-VL-DP, a model built upon Qwen-VL, fine-tuned with supervised learning and enhanced via group relative policy optimization (GRPO), a rule-based RL approach that integrates correctness discrimination and diversity-aware reward functions. Our method emphasizes learning from varied reasoning perspectives and distinguishing between correct yet distinct solutions. Extensive experiments on the MathVista's minitest and Math-V benchmarks demonstrate that Qwen-VL-DP significantly outperforms prior base MLLMs in both accuracy and generative diversity, highlighting the importance of incorporating diverse perspectives and reflective reasoning in multimodal mathematical reasoning.",
      "authors": [
        "Wenhao Shi and Zhiqiang Hu and Yi Bin and Yang Yang and See-Kiong Ng and Heng Tao Shen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T17:07:20+00:00",
          "link": "https://arxiv.org/abs/2507.02804v1",
          "size": "755kb",
          "version": "v1"
        }
      ],
      "title": "Multimodal Mathematical Reasoning with Diverse Solving Perspective",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02804",
        "HTML": "https://arxiv.org/html/2507.02804v1",
        "PDF": "https://arxiv.org/pdf/2507.02804"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces MathV-DP, a dataset with diverse solution trajectories and describes fine-tuning an LLM. It covers data diversity but lacks focus on core LLM data processing methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02807",
      "abstract": "Survival analysis is an important problem in healthcare because it models the relationship between an individual's covariates and the onset time of an event of interest (e.g., death). It is important for survival models to be well-calibrated (i.e., for their predicted probabilities to be close to ground-truth probabilities) because badly calibrated systems can result in erroneous clinical decisions. Existing survival models are typically calibrated at the population level only, and thus run the risk of being poorly calibrated for one or more minority subpopulations. We propose a model called GRADUATE that achieves multicalibration by ensuring that all subpopulations are well-calibrated too. GRADUATE frames multicalibration as a constrained optimization problem, and optimizes both calibration and discrimination in-training to achieve a good balance between them. We mathematically prove that the optimization method used yields a solution that is both near-optimal and feasible with high probability. Empirical comparisons against state-of-the-art baselines on real-world clinical datasets demonstrate GRADUATE's efficacy. In a detailed analysis, we elucidate the shortcomings of the baselines vis-a-vis GRADUATE's strengths.",
      "authors": [
        "Thiti Suttaket",
        "Stanley Kok"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T17:16:05+00:00",
          "link": "https://arxiv.org/abs/2507.02807v1",
          "size": "6542kb",
          "version": "v1"
        }
      ],
      "title": "In-Training Multicalibrated Survival Analysis for Healthcare via Constrained Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02807",
        "HTML": "https://arxiv.org/html/2507.02807v1",
        "PDF": "https://arxiv.org/pdf/2507.02807"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is focused on survival analysis in healthcare, proposing a multi-calibration method for survival models, and not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02809",
      "abstract": "The current work investigates the effectiveness of block triangular preconditioners in accelerating and stabilizing the numerical solution of inverse source problems governed by time-space fractional diffusion equations (TSFDEs). We focus on the recovery of an unknown spatial source function in a multi-dimensional TSFDE, incorporating Caputo time-fractional derivatives and the fractional Laplacian. The inherent ill-posedness is addressed via a quasi-boundary value regularization, followed by a finite difference discretization that leads to large, structured linear systems. We develop and analyze a block triangular preconditioning strategy that mimics the coefficient matrix, while simplifying its structure for computational efficiency. Numerical experiments using the GMRES solver demonstrate that the proposed preconditioner significantly improve convergence rates, robustness, and accuracy, making it well-suited for large-scale, real-world inverse problems involving fractional modeling.",
      "authors": [
        "Monoswini Majumdar",
        "Stefano Serra-Capizzano",
        "Rosita L. Sormani"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T17:19:20+00:00",
          "link": "https://arxiv.org/abs/2507.02809v1",
          "size": "1626kb",
          "version": "v1"
        }
      ],
      "title": "Block triangular preconditioning for inverse source problems in time-space fractional diffusion equations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02809",
        "HTML": "https://arxiv.org/html/2507.02809v1",
        "PDF": "https://arxiv.org/pdf/2507.02809"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses numerical solutions for inverse source problems in differential equations, with no relation to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02813",
      "abstract": "Recovering 3D structures with open-vocabulary scene understanding from 2D images is a fundamental but daunting task. Recent developments have achieved this by performing per-scene optimization with embedded language information. However, they heavily rely on the calibrated dense-view reconstruction paradigm, thereby suffering from severe rendering artifacts and implausible semantic synthesis when limited views are available. In this paper, we introduce a novel generative framework, coined LangScene-X, to unify and generate 3D consistent multi-modality information for reconstruction and understanding. Powered by the generative capability of creating more consistent novel observations, we can build generalizable 3D language-embedded scenes from only sparse views. Specifically, we first train a TriMap video diffusion model that can generate appearance (RGBs), geometry (normals), and semantics (segmentation maps) from sparse inputs through progressive knowledge integration. Furthermore, we propose a Language Quantized Compressor (LQC), trained on large-scale image datasets, to efficiently encode language embeddings, enabling cross-scene generalization without per-scene retraining. Finally, we reconstruct the language surface fields by aligning language information onto the surface of 3D scenes, enabling open-ended language queries. Extensive experiments on real-world data demonstrate the superiority of our LangScene-X over state-of-the-art methods in terms of quality and generalizability. Project Page: https://liuff19.github.io/LangScene-X.",
      "authors": [
        "Fangfu Liu",
        "Hao Li",
        "Jiawei Chi",
        "Hanyang Wang",
        "Minghui Yang",
        "Fudong Wang",
        "Yueqi Duan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T17:21:23+00:00",
          "link": "https://arxiv.org/abs/2507.02813v1",
          "size": "8275kb",
          "version": "v1"
        }
      ],
      "title": "LangScene-X: Reconstruct Generalizable 3D Language-Embedded Scenes with TriMap Video Diffusion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02813",
        "HTML": "https://arxiv.org/html/2507.02813v1",
        "PDF": "https://arxiv.org/pdf/2507.02813"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses TriMap video diffusion and Language Quantized Compressor for 3D scene reconstruction, touching upon large-scale training datasets but does not directly focus on LLM data processing innovations."
      },
      "models": [
        {
          "model_path": "chijw/LangScene-X",
          "downloads": "0",
          "likes": "2",
          "trending_score": "2.0",
          "link": "https://huggingface.co/chijw/LangScene-X"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.02814",
      "abstract": "We initiate a systematic investigation of distribution testing in the framework of algorithmic replicability. Specifically, given independent samples from a collection of probability distributions, the goal is to characterize the sample complexity of replicably testing natural properties of the underlying distributions. On the algorithmic front, we develop new replicable algorithms for testing closeness and independence of discrete distributions. On the lower bound front, we develop a new methodology for proving sample complexity lower bounds for replicable testing that may be of broader interest. As an application of our technique, we establish near-optimal sample complexity lower bounds for replicable uniformity testing -- answering an open question from prior work -- and closeness testing.",
      "authors": [
        "Ilias Diakonikolas",
        "Jingyi Gao",
        "Daniel Kane",
        "Sihan Liu",
        "Christopher Ye"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T17:27:11+00:00",
          "link": "https://arxiv.org/abs/2507.02814v1",
          "size": "48kb",
          "version": "v1"
        }
      ],
      "title": "Replicable Distribution Testing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02814",
        "HTML": "https://arxiv.org/html/2507.02814v1",
        "PDF": "https://arxiv.org/pdf/2507.02814"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The work centers on distribution testing and algorithmic replicability, with no discussion on LLM training data collection, construction, or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02819",
      "abstract": "Data scientists often formulate predictive modeling tasks involving fuzzy, hard-to-define concepts, such as the \"authenticity\" of student writing or the \"healthcare need\" of a patient. Yet the process by which data scientists translate fuzzy concepts into a concrete, proxy target variable remains poorly understood. We interview fifteen data scientists in education (N=8) and healthcare (N=7) to understand how they construct target variables for predictive modeling tasks. Our findings suggest that data scientists construct target variables through a bricolage process, involving iterative negotiation between high-level measurement objectives and low-level practical constraints. Data scientists attempt to satisfy five major criteria for a target variable through bricolage: validity, simplicity, predictability, portability, and resource requirements. To achieve this, data scientists adaptively use problem (re)formulation strategies, such as swapping out one candidate target variable for another when the first fails to meet certain criteria (e.g., predictability), or composing multiple outcomes into a single target variable to capture a more holistic set of modeling objectives. Based on our findings, we present opportunities for future HCI, CSCW, and ML research to better support the art and science of target variable construction.",
      "authors": [
        "Luke Guerdan",
        "Devansh Saxena",
        "Stevie Chancellor",
        "Zhiwei Steven Wu",
        "Kenneth Holstein"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Computers and Society (cs.CY)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T17:33:24+00:00",
          "link": "https://arxiv.org/abs/2507.02819v1",
          "size": "11155kb",
          "version": "v1"
        }
      ],
      "title": "Measurement as Bricolage: Examining How Data Scientists Construct Target Variables for Predictive Modeling Tasks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02819",
        "HTML": "https://arxiv.org/html/2507.02819v1",
        "PDF": "https://arxiv.org/pdf/2507.02819"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The study discusses the construction of target variables for predictive modeling, which touches on data-related challenges similar to those in ML data preparation, but it doesn't focus on LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02822",
      "abstract": "With the widespread adoption of large language models (LLMs) in practical applications, selecting an appropriate model requires balancing not only performance but also operational cost. The emergence of reasoning-capable models has further widened the cost gap between \"thinking\" (high reasoning) and \"non-thinking\" (fast, low-cost) modes. In this work, we reveal that approximately 58% of medical questions can be accurately answered by the non-thinking mode alone, without requiring the high-cost reasoning process. This highlights a clear dichotomy in problem complexity and suggests that dynamically routing queries to the appropriate mode based on complexity could optimize accuracy, cost-efficiency, and overall user experience. Based on this, we further propose SynapseRoute, a machine learning-based dynamic routing framework that intelligently assigns input queries to either thinking or non-thinking modes. Experimental results on several medical datasets demonstrate that SynapseRoute not only improves overall accuracy (0.8390 vs. 0.8272) compared to the thinking mode alone but also reduces inference time by 36.8% and token consumption by 39.66%. Importantly, qualitative analysis indicates that over-reasoning on simpler queries can lead to unnecessary delays and even decreased accuracy, a pitfall avoided by our adaptive routing. Finally, this work further introduces the Accuracy-Inference-Token (AIT) index to comprehensively evaluate the trade-offs among accuracy, latency, and token cost.",
      "authors": [
        "Wencheng Zhang",
        "Shiqin Qiao",
        "Lingjie Luo",
        "Yinfeng Li",
        "Chuanyang Zheng",
        "Qian Xu",
        "Meng Li",
        "Yong Gui",
        "Yijun He",
        "Jianing Qiu",
        "Jindong Hong",
        "Jiankai Sun"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T17:33:58+00:00",
          "link": "https://arxiv.org/abs/2507.02822v1",
          "size": "272kb",
          "version": "v1"
        }
      ],
      "title": "SynapseRoute: An Auto-Route Switching Framework on Dual-State Large Language Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02822",
        "HTML": "https://arxiv.org/html/2507.02822v1",
        "PDF": "https://arxiv.org/pdf/2507.02822"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While presenting a framework for dynamic routing in LLMs, the paper does not primarily address LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02825",
      "abstract": "Benchmarks are essential for quantitatively tracking progress in AI. As AI agents become increasingly capable, researchers and practitioners have introduced agentic benchmarks to evaluate agents on complex, real-world tasks. These benchmarks typically measure agent capabilities by evaluating task outcomes via specific reward designs. However, we show that many agentic benchmarks have issues task setup or reward design. For example, SWE-bench Verified uses insufficient test cases, while TAU-bench counts empty responses as successful. Such issues can lead to under- or overestimation agents' performance by up to 100% in relative terms. To make agentic evaluation rigorous, we introduce the Agentic Benchmark Checklist (ABC), a set of guidelines that we synthesized from our benchmark-building experience, a survey of best practices, and previously reported issues. When applied to CVE-Bench, a benchmark with a particularly complex evaluation design, ABC reduces the performance overestimation by 33%.",
      "authors": [
        "Yuxuan Zhu",
        "Tengjun Jin",
        "Yada Pruksachatkun",
        "Andy Zhang",
        "Shu Liu",
        "Sasha Cui",
        "Sayash Kapoor",
        "Shayne Longpre",
        "Kevin Meng",
        "Rebecca Weiss",
        "Fazl Barez",
        "Rahul Gupta",
        "Jwala Dhamala",
        "Jacob Merizian",
        "Mario Giulianelli",
        "Harry Coppock",
        "Cozmin Ududec",
        "Jasjeet Sekhon",
        "Jacob Steinhardt",
        "Antony Kellerman",
        "Sarah Schwettmann",
        "Matei Zaharia",
        "Ion Stoica",
        "Percy Liang",
        "Daniel Kang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T17:35:31+00:00",
          "link": "https://arxiv.org/abs/2507.02825v1",
          "size": "671kb",
          "version": "v1"
        }
      ],
      "title": "Establishing Best Practices for Building Rigorous Agentic Benchmarks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02825",
        "HTML": "https://arxiv.org/html/2507.02825v1",
        "PDF": "https://arxiv.org/pdf/2507.02825"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper's focus is on the design and evaluation of agentic benchmarks, not on LLM training data engineering or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02826",
      "abstract": "Sensor-based Human Activity Recognition (HAR) is a core technology that enables intelligent systems to perceive and interact with their environment. However, multimodal HAR systems still encounter key challenges, such as difficulties in cross-modal feature alignment and imbalanced modality contributions. To address these issues, we propose a novel framework called the Dynamic Contrastive Dual-Path Network (DCDP-HAR). The framework comprises three key components. First, a dual-path feature extraction architecture is employed, where ResNet and DenseNet branches collaboratively process multimodal sensor data. Second, a multi-stage contrastive learning mechanism is introduced to achieve progressive alignment from local perception to semantic abstraction. Third, we present a confidence-driven gradient modulation strategy that dynamically monitors and adjusts the learning intensity of each modality branch during backpropagation, effectively alleviating modality competition. In addition, a momentum-based gradient accumulation strategy is adopted to enhance training stability. We conduct ablation studies to validate the effectiveness of each component and perform extensive comparative experiments on four public benchmark datasets.",
      "authors": [
        "Panpan Ji",
        "Junni Song",
        "Hang Xiao",
        "Hanyu Liu",
        "Chao Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T17:37:46+00:00",
          "link": "https://arxiv.org/abs/2507.02826v1",
          "size": "1171kb",
          "version": "v1"
        }
      ],
      "title": "Confidence-driven Gradient Modulation for Multimodal Human Activity Recognition: A Dynamic Contrastive Dual-Path Learning Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02826",
        "HTML": "https://arxiv.org/html/2507.02826v1",
        "PDF": "https://arxiv.org/pdf/2507.02826"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a novel framework for human activity recognition (HAR) using multimodal sensor data, and not on aspects related to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02827",
      "abstract": "The primary objective of human activity recognition (HAR) is to infer ongoing human actions from sensor data, a task that finds broad applications in health monitoring, safety protection, and sports analysis. Despite proliferating research, HAR still faces key challenges, including the scarcity of labeled samples for rare activities, insufficient extraction of high-level features, and suboptimal model performance on lightweight devices. To address these issues, this paper proposes a comprehensive optimization approach centered on multi-attention interaction mechanisms. First, an unsupervised, statistics-guided diffusion model is employed to perform data augmentation, thereby alleviating the problems of labeled data scarcity and severe class imbalance. Second, a multi-branch spatio-temporal interaction network is designed, which captures multi-scale features of sequential data through parallel residual branches with 3*3, 5*5, and 7*7 convolutional kernels. Simultaneously, temporal attention mechanisms are incorporated to identify critical time points, while spatial attention enhances inter-sensor interactions. A cross-branch feature fusion unit is further introduced to improve the overall feature representation capability. Finally, an adaptive multi-loss function fusion strategy is integrated, allowing for dynamic adjustment of loss weights and overall model optimization. Experimental results on three public datasets, WISDM, PAMAP2, and OPPORTUNITY, demonstrate that the proposed unsupervised data augmentation spatio-temporal attention diffusion network (USAD) achieves accuracies of 98.84%, 93.81%, and 80.92% respectively, significantly outperforming existing approaches. Furthermore, practical deployment on embedded devices verifies the efficiency and feasibility of the proposed method.",
      "authors": [
        "Ying Yu",
        "Hang Xiao",
        "Siyao Li",
        "Jiarui Li",
        "Haotian Tang",
        "Hanyu Liu",
        "Chao Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T17:38:44+00:00",
          "link": "https://arxiv.org/abs/2507.02827v1",
          "size": "7511kb",
          "version": "v1"
        }
      ],
      "title": "USAD: An Unsupervised Data Augmentation Spatio-Temporal Attention Diffusion Network",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02827",
        "HTML": "https://arxiv.org/html/2507.02827v1",
        "PDF": "https://arxiv.org/pdf/2507.02827"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research discusses human activity recognition (HAR) with an emphasis on data augmentation for sensor data, rather than training data processing or engineering for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02833",
      "abstract": "A crucial factor for successful human and AI interaction is the ability of language models or chatbots to follow human instructions precisely. A common feature of instructions are output constraints like ``only answer with yes or no\" or ``mention the word `abrakadabra' at least 3 times\" that the user adds to craft a more useful answer. Even today's strongest models struggle with fulfilling such constraints. We find that most models strongly overfit on a small set of verifiable constraints from the benchmarks that test these abilities, a skill called precise instruction following, and are not able to generalize well to unseen output constraints. We introduce a new benchmark, IFBench, to evaluate precise instruction following generalization on 58 new, diverse, and challenging verifiable out-of-domain constraints. In addition, we perform an extensive analysis of how and on what data models can be trained to improve precise instruction following generalization. Specifically, we carefully design constraint verification modules and show that reinforcement learning with verifiable rewards (RLVR) significantly improves instruction following. In addition to IFBench, we release 29 additional new hand-annotated training constraints and verification functions, RLVR training prompts, and code.",
      "authors": [
        "Valentina Pyatkin and Saumya Malik and Victoria Graf and Hamish Ivison and Shengyi Huang and Pradeep Dasigi and Nathan Lambert and Hannaneh Hajishirzi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T17:44:33+00:00",
          "link": "https://arxiv.org/abs/2507.02833v1",
          "size": "2525kb",
          "version": "v1"
        }
      ],
      "title": "Generalizing Verifiable Instruction Following",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02833",
        "HTML": "https://arxiv.org/html/2507.02833v1",
        "PDF": "https://arxiv.org/pdf/2507.02833"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses the use of training data and constraint verification for instruction following, mentioning detailed data preparation and evaluation benchmarks (IFBench), but does not primarily contribute new methods in data processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02834",
      "abstract": "Recent advances in large language models have been driven by reinforcement learning (RL)-style post-training, which improves reasoning by optimizing model outputs based on reward or preference signals. GRPO-style approaches implement this by using self-generated samples labeled by an outcome-based verifier. However, these methods depend heavily on the model's initial ability to produce positive samples. They primarily refine what the model already knows (distribution sharpening) rather than enabling the model to solve problems where it initially fails. This limitation is especially problematic in early-stage RL training and on challenging reasoning tasks, where positive samples are unlikely to be generated. To unlock reasoning ability in such settings, the model must explore new reasoning trajectories beyond its current output distribution. Such exploration requires access to sufficiently good positive samples to guide the learning. While expert demonstrations seem like a natural solution, we find that they are often ineffective in RL post-training. Instead, we identify two key properties of effective positive samples: they should (1) be likely under the current policy, and (2) increase the model's likelihood of predicting the correct answer. Based on these insights, we propose $\\textbf{Self-Explanation Policy Optimization (ExPO)}$-a simple and modular framework that generates such samples by conditioning on the ground-truth answer. ExPO enables efficient exploration and guides the model to produce reasoning trajectories more aligned with its policy than expert-written CoTs, while ensuring higher quality than its own (incorrect) samples. Experiments show that ExPO improves both learning efficiency and final performance on reasoning benchmarks, surpassing expert-demonstration-based methods in challenging settings such as MATH level-5, where the model initially struggles the most.",
      "authors": [
        "Ruiyang Zhou",
        "Shuozhe Li",
        "Amy Zhang",
        "Liu Leqi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T17:44:55+00:00",
          "link": "https://arxiv.org/abs/2507.02834v1",
          "size": "858kb",
          "version": "v1"
        }
      ],
      "title": "ExPO: Unlocking Hard Reasoning with Self-Explanation-Guided Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02834",
        "HTML": "https://arxiv.org/html/2507.02834v1",
        "PDF": "https://arxiv.org/pdf/2507.02834"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper deals with improving LLM reasoning capabilities through reinforcement learning, it discusses the importance of training data quality but does not focus on the core processing or engineering of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02841",
      "abstract": "Reinforcement learning with verifiable rewards (RLVR) is a promising approach for improving the complex reasoning abilities of large language models (LLMs). However, current RLVR methods face two significant challenges: the near-miss reward problem, where a small mistake can invalidate an otherwise correct reasoning process, greatly hindering training efficiency; and exploration stagnation, where models tend to focus on solutions within their ``comfort zone,'' lacking the motivation to explore potentially more effective alternatives. To address these challenges, we propose StepHint, a novel RLVR algorithm that utilizes multi-level stepwise hints to help models explore the solution space more effectively. StepHint generates valid reasoning chains from stronger models and partitions these chains into reasoning steps using our proposed adaptive partitioning method. The initial few steps are used as hints, and simultaneously, multiple-level hints (each comprising a different number of steps) are provided to the model. This approach directs the model's exploration toward a promising solution subspace while preserving its flexibility for independent exploration. By providing hints, StepHint mitigates the near-miss reward problem, thereby improving training efficiency. Additionally, the external reasoning pathways help the model develop better reasoning abilities, enabling it to move beyond its ``comfort zone'' and mitigate exploration stagnation. StepHint outperforms competitive RLVR enhancement methods across six mathematical benchmarks, while also demonstrating superior generalization and excelling over baselines on out-of-domain benchmarks.",
      "authors": [
        "Kaiyi Zhang",
        "Ang Lv",
        "Jinpeng Li",
        "Yongbo Wang",
        "Feng Wang",
        "Haoyuan Hu",
        "Rui Yan"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T17:51:06+00:00",
          "link": "https://arxiv.org/abs/2507.02841v1",
          "size": "1576kb",
          "version": "v1"
        }
      ],
      "title": "StepHint: Multi-level Stepwise Hints Enhance Reinforcement Learning to Reason",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02841",
        "HTML": "https://arxiv.org/html/2507.02841v1",
        "PDF": "https://arxiv.org/pdf/2507.02841"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on enhancing reinforcement learning for reasoning using stepwise hints and does not address any aspect of LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02842",
      "abstract": "A hypothesis testing algorithm is replicable if, when run on two different samples from the same distribution, it produces the same output with high probability. This notion, defined by by Impagliazzo, Lei, Pitassi, and Sorell [STOC'22], can increase trust in testing procedures and is deeply related to algorithmic stability, generalization, and privacy. We build general tools to prove lower and upper bounds on the sample complexity of replicable testers, unifying and quantitatively improving upon existing results.\n  We identify a set of canonical properties, and prove that any replicable testing algorithm can be modified to satisfy these properties without worsening accuracy or sample complexity. A canonical replicable algorithm computes a deterministic function of its input (i.e., a test statistic) and thresholds against a uniformly random value in $[0,1]$. It is invariant to the order in which the samples are received, and, if the testing problem is ``symmetric,'' then the algorithm is also invariant to the labeling of the domain elements, resolving an open question by Liu and Ye [NeurIPS'24]. We prove new lower bounds for uniformity, identity, and closeness testing by reducing to the case where the replicable algorithm satisfies these canonical properties.\n  We systematize and improve upon a common strategy for replicable algorithm design based on test statistics with known expectation and bounded variance. Our framework allow testers which have been extensively analyzed in the non-replicable setting to be made replicable with minimal overhead. As direct applications of our framework, we obtain constant-factor optimal bounds for coin testing and closeness testing and get replicability for free in a large parameter regime for uniformity testing.\n  We also give state-of-the-art bounds for replicable Gaussian mean testing, and, unlike prior work, our algorithm runs in polynomial time.",
      "authors": [
        "Anders Aamand",
        "Maryam Aliakbarpour",
        "Justin Y. Chen",
        "Shyam Narayanan",
        "Sandeep Silwal"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T17:51:31+00:00",
          "link": "https://arxiv.org/abs/2507.02842v1",
          "size": "82kb",
          "version": "v1"
        }
      ],
      "title": "On the Structure of Replicable Hypothesis Testers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02842",
        "HTML": "https://arxiv.org/html/2507.02842v1",
        "PDF": "https://arxiv.org/pdf/2507.02842"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses replicable hypothesis testers and algorithmic stability, which are unrelated to the processing or engineering of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02843",
      "abstract": "Estimating treatment effects is crucial for personalized decision-making in medicine, but this task faces unique challenges in clinical practice. At training time, models for estimating treatment effects are typically trained on well-structured medical datasets that contain detailed patient information. However, at inference time, predictions are often made using textual descriptions (e.g., descriptions with self-reported symptoms), which are incomplete representations of the original patient information. In this work, we make three contributions. (1) We show that the discrepancy between the data available during training time and inference time can lead to biased estimates of treatment effects. We formalize this issue as an inference time text confounding problem, where confounders are fully observed during training time but only partially available through text at inference time. (2) To address this problem, we propose a novel framework for estimating treatment effects that explicitly accounts for inference time text confounding. Our framework leverages large language models together with a custom doubly robust learner to mitigate biases caused by the inference time text confounding. (3) Through a series of experiments, we demonstrate the effectiveness of our framework in real-world applications.",
      "authors": [
        "Yuchen Ma",
        "Dennis Frauen",
        "Jonas Schweisthal",
        "Stefan Feuerriegel"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T17:52:27+00:00",
          "link": "https://arxiv.org/abs/2507.02843v1",
          "size": "475kb",
          "version": "v1"
        }
      ],
      "title": "LLM-Driven Treatment Effect Estimation Under Inference Time Text Confounding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02843",
        "HTML": "https://arxiv.org/html/2507.02843v1",
        "PDF": "https://arxiv.org/pdf/2507.02843"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper involves leveraging LLMs for estimating treatment effects with a focus on text confounding at inference time, but it presents a framework rather than directly contributing to data engineering or processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02844",
      "abstract": "With the emergence of strong visual-language capabilities, multimodal large language models (MLLMs) have demonstrated tremendous potential for real-world applications. However, the security vulnerabilities exhibited by the visual modality pose significant challenges to deploying such models in open-world environments. Recent studies have successfully induced harmful responses from target MLLMs by encoding harmful textual semantics directly into visual inputs. However, in these approaches, the visual modality primarily serves as a trigger for unsafe behavior, often exhibiting semantic ambiguity and lacking grounding in realistic scenarios. In this work, we define a novel setting: visual-centric jailbreak, where visual information serves as a necessary component in constructing a complete and realistic jailbreak context. Building on this setting, we propose the VisCo (Visual Contextual) Attack. VisCo fabricates contextual dialogue using four distinct visual-focused strategies, dynamically generating auxiliary images when necessary to construct a visual-centric jailbreak scenario. To maximize attack effectiveness, it incorporates automatic toxicity obfuscation and semantic refinement to produce a final attack prompt that reliably triggers harmful responses from the target black-box MLLMs. Specifically, VisCo achieves a toxicity score of 4.78 and an Attack Success Rate (ASR) of 85% on MM-SafetyBench against GPT-4o, significantly outperforming the baseline, which performs a toxicity score of 2.48 and an ASR of 22.2%. The code is available at https://github.com/Dtc7w3PQ/Visco-Attack.",
      "authors": [
        "Ziqi Miao",
        "Yi Ding",
        "Lijun Li",
        "Jing Shao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Computation and Language (cs.CL)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T17:53:12+00:00",
          "link": "https://arxiv.org/abs/2507.02844v1",
          "size": "3420kb",
          "version": "v1"
        }
      ],
      "title": "Visual Contextual Attack: Jailbreaking MLLMs with Image-Driven Context Injection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02844",
        "HTML": "https://arxiv.org/html/2507.02844v1",
        "PDF": "https://arxiv.org/pdf/2507.02844"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses attacks on multimodal LLMs using visual context injection and focuses on security vulnerabilities, not on the construction or processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02846",
      "abstract": "Software systems must comply with legal regulations, which is a resource-intensive task, particularly for small organizations and startups lacking dedicated legal expertise. Extracting metadata from regulations to elicit legal requirements for software is a critical step to ensure compliance. However, it is a cumbersome task due to the length and complex nature of legal text. Although prior work has pursued automated methods for extracting structural and semantic metadata from legal text, key limitations remain: they do not consider the interplay and interrelationships among attributes associated with these metadata types, and they rely on manual labeling or heuristic-driven machine learning, which does not generalize well to new documents. In this paper, we introduce an approach based on textual entailment and in-context learning for automatically generating a canonical representation of legal text, encodable and executable as Python code. Our representation is instantiated from a manually designed Python class structure that serves as a domain-specific metamodel, capturing both structural and semantic legal metadata and their interrelationships. This design choice reduces the need for large, manually labeled datasets and enhances applicability to unseen legislation. We evaluate our approach on 13 U.S. state data breach notification laws, demonstrating that our generated representations pass approximately 89.4% of test cases and achieve a precision and recall of 82.2 and 88.7, respectively.",
      "authors": [
        "Anmol Singhal",
        "Travis Breaux"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T17:53:48+00:00",
          "link": "https://arxiv.org/abs/2507.02846v1",
          "size": "105kb",
          "version": "v1"
        }
      ],
      "title": "Legal Requirements Translation from Law",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02846",
        "HTML": "https://arxiv.org/html/2507.02846v1",
        "PDF": "https://arxiv.org/pdf/2507.02846"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on translating legal requirements into a machine-executable form using textual entailment and in-context learning, not on LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02847",
      "abstract": "Recent evidence suggests that modeling higher-order interactions (HOIs) in functional magnetic resonance imaging (fMRI) data can enhance the diagnostic accuracy of machine learning systems. However, effectively extracting and utilizing HOIs remains a significant challenge. In this work, we propose MvHo-IB, a novel multi-view learning framework that integrates both pairwise interactions and HOIs for diagnostic decision-making, while automatically compressing task-irrelevant redundant information. MvHo-IB introduces several key innovations: (1) a principled method that combines O-information from information theory with a matrix-based Renyi alpha-order entropy estimator to quantify and extract HOIs, (2) a purpose-built Brain3DCNN encoder to effectively utilize these interactions, and (3) a new multi-view learning information bottleneck objective to enhance representation learning. Experiments on three benchmark fMRI datasets demonstrate that MvHo-IB achieves state-of-the-art performance, significantly outperforming previous methods, including recent hypergraph-based techniques. The implementation of MvHo-IB is available at https://github.com/zky04/MvHo-IB.",
      "authors": [
        "Kunyu Zhang",
        "Qiang Li",
        "and Shujian Yu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T17:54:03+00:00",
          "link": "https://arxiv.org/abs/2507.02847v1",
          "size": "1310kb",
          "version": "v1"
        }
      ],
      "title": "MvHo-IB: Multi-View Higher-Order Information Bottleneck for Brain Disorder Diagnosis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02847",
        "HTML": "https://arxiv.org/html/2507.02847v1",
        "PDF": "https://arxiv.org/pdf/2507.02847"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a novel framework for brain disorder diagnosis using multi-view learning and information bottleneck but does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02850",
      "abstract": "We describe a vulnerability in language models (LMs) trained with user feedback, whereby a single user can persistently alter LM knowledge and behavior given only the ability to provide prompts and upvote / downvote feedback on LM outputs. To implement the attack, the attacker prompts the LM to stochastically output either a \"poisoned\" or benign response, then upvotes the poisoned response or downvotes the benign one. When feedback signals are used in a subsequent preference tuning behavior, LMs exhibit increased probability of producing poisoned responses even in contexts without malicious prompts. We show that this attack can be used to (1) insert factual knowledge the model did not previously possess, (2) modify code generation patterns in ways that introduce exploitable security flaws, and (3) inject fake financial news. Our finding both identifies a new qualitative feature of language model preference tuning (showing that it even highly restricted forms of preference data can be used to exert fine-grained control over behavior), and a new attack mechanism for LMs trained with user feedback (extending work on pretraining-time data poisoning and deployment-time prompt injection).",
      "authors": [
        "Almog Hilel",
        "Idan Shenfeld",
        "Leshem Choshen",
        "Jacob Andreas"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T17:55:40+00:00",
          "link": "https://arxiv.org/abs/2507.02850v1",
          "size": "381kb",
          "version": "v1"
        }
      ],
      "title": "LLM Hypnosis: Exploiting User Feedback for Unauthorized Knowledge Injection to All Users",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02850",
        "HTML": "https://arxiv.org/html/2507.02850v1",
        "PDF": "https://arxiv.org/pdf/2507.02850"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The discussion of altering LLM behavior through user feedback touches on data-related methods during preference tuning, but it is not the paper's primary focus."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02851",
      "abstract": "Recent advancements in the reasoning capabilities of large language models (LLMs) show that employing group relative policy optimization (GRPO) algorithm for reinforcement learning (RL) training allows the models to use more thinking/reasoning tokens for generating better responses. However, LLMs can generate only a finite amount of tokens while maintaining attention to the previously generated tokens. This limit, also known as the context size of an LLM, is a bottleneck in LLM reasoning with arbitrarily large number of tokens. To think beyond the limit of context size, an LLM must employ a modular thinking strategy to reason over multiple rounds. In this work, we propose $\\textbf{MOTIF: Modular Thinking via Reinforcement Finetuning}$ -- an RL training method for generating thinking tokens in multiple rounds, effectively allowing the model to think with additional context size. We trained the open-source model Qwen2.5-3B-Instruct on GSM8K dataset via parameter efficient fine-tuning and tested its accuracy on MATH500 and AIME2024 benchmarks. Our experiments show 3.8\\% and 3.3\\% improvements over vanilla GRPO based training in the respective benchmarks. Furthermore, this improvement was achieved with only 15\\% of samples, thus demonstrating sample efficiency of MOTIF. Our code and models are available at https://github.com/purbeshmitra/MOTIF and https://huggingface.co/purbeshmitra/MOTIF, respectively.",
      "authors": [
        "Purbesh Mitra and Sennur Ulukus"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Information Theory (cs.IT)",
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T17:55:43+00:00",
          "link": "https://arxiv.org/abs/2507.02851v1",
          "size": "1611kb",
          "version": "v1"
        }
      ],
      "title": "MOTIF: Modular Thinking via Reinforcement Fine-tuning in LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02851",
        "HTML": "https://arxiv.org/html/2507.02851v1",
        "PDF": "https://arxiv.org/pdf/2507.02851"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This work on modular thinking via reinforcement fine-tuning mentions fine-tuning, which is part of training-stage data processing, but the data processing itself isn\u2019t the main contribution."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02855",
      "abstract": "The recently introduced dependent typed higher-order logic (DHOL) offers an interesting compromise between expressiveness and automation support. It sacrifices the decidability of its type system in order to significantly extend its expressiveness over standard HOL. Yet it retains strong automated theorem proving support via a sound and complete translation to HOL.\n  We leverage this design to extend DHOL with refinement and quotient types. Both of these are commonly requested by practitioners but rarely provided by automated theorem provers. This is because they inherently require undecidable typing and thus are very difficult to retrofit to decidable type systems. But with DHOL already doing the heavy lifting, adding them is not only possible but elegant and simple.\n  Concretely, we add refinement and quotient types as special cases of subtyping. This turns the associated canonical inclusion resp. projection maps into identity maps and thus avoids costly changes in representation. We present the syntax, semantics, and translation to HOL for the extended language, including the proofs of soundness and completeness.",
      "authors": [
        "Colin Rothgang and Florian Rabe"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Artificial Intelligence (cs.AI)",
        "Formal Languages and Automata Theory (cs.FL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T17:59:00+00:00",
          "link": "https://arxiv.org/abs/2507.02855v1",
          "size": "77kb",
          "version": "v1"
        }
      ],
      "title": "Subtyping in DHOL -- Extended preprint",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02855",
        "HTML": "https://arxiv.org/html/2507.02855v1",
        "PDF": "https://arxiv.org/pdf/2507.02855"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with extensions in dependent typed higher-order logic and does not cover any aspects of LLM data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02856",
      "abstract": "Multiple choice benchmarks have long been the workhorse of language model evaluation because grading multiple choice is objective and easy to automate. However, we show multiple choice questions from popular benchmarks can often be answered without even seeing the question. These shortcuts arise from a fundamental limitation of discriminative evaluation not shared by evaluations of the model's free-form, generative answers. Until recently, there appeared to be no viable, scalable alternative to multiple choice--but, we show that this has changed. We consider generative evaluation via what we call answer matching: Give the candidate model the question without the options, have it generate a free-form response, then use a modern language model with the reference answer to determine if the response matches the reference. To compare the validity of different evaluation strategies, we annotate MMLU-Pro and GPQA-Diamond to obtain human grading data, and measure the agreement of each evaluation approach. We find answer matching using recent models--even small ones--achieves near-perfect agreement, in the range of inter-annotator agreement. In contrast, both multiple choice evaluation and using LLM-as-a-judge without reference answers aligns poorly with human grading. Improving evaluations via answer matching is not merely a conceptual concern: the rankings of several models change significantly when evaluating their free-form responses with answer matching. In light of these findings, we discuss how to move the evaluation ecosystem from multiple choice to answer matching.",
      "authors": [
        "Nikhil Chandak and Shashwat Goel and Ameya Prabhu and Moritz Hardt and Jonas Geiping"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T17:59:02+00:00",
          "link": "https://arxiv.org/abs/2507.02856v1",
          "size": "2437kb",
          "version": "v1"
        }
      ],
      "title": "Answer Matching Outperforms Multiple Choice for Language Model Evaluation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02856",
        "PDF": "https://arxiv.org/pdf/2507.02856"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses evaluation methods for language models, focusing on answer matching versus multiple choice, without addressing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02857",
      "abstract": "Recent advancements in video generation, particularly in diffusion models, have driven notable progress in text-to-video (T2V) and image-to-video (I2V) synthesis. However, challenges remain in effectively integrating dynamic motion signals and flexible spatial constraints. Existing T2V methods typically rely on text prompts, which inherently lack precise control over the spatial layout of generated content. In contrast, I2V methods are limited by their dependence on real images, which restricts the editability of the synthesized content. Although some methods incorporate ControlNet to introduce image-based conditioning, they often lack explicit motion control and require computationally expensive training. To address these limitations, we propose AnyI2V, a training-free framework that animates any conditional images with user-defined motion trajectories. AnyI2V supports a broader range of modalities as the conditional image, including data types such as meshes and point clouds that are not supported by ControlNet, enabling more flexible and versatile video generation. Additionally, it supports mixed conditional inputs and enables style transfer and editing via LoRA and text prompts. Extensive experiments demonstrate that the proposed AnyI2V achieves superior performance and provides a new perspective in spatial- and motion-controlled video generation. Code is available at https://henghuiding.com/AnyI2V/.",
      "authors": [
        "Ziye Li",
        "Hao Luo",
        "Xincheng Shuai",
        "Henghui Ding"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T17:59:02+00:00",
          "link": "https://arxiv.org/abs/2507.02857v1",
          "size": "4044kb",
          "version": "v1"
        }
      ],
      "title": "AnyI2V: Animating Any Conditional Image with Motion Control",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02857",
        "HTML": "https://arxiv.org/html/2507.02857v1",
        "PDF": "https://arxiv.org/pdf/2507.02857"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces AnyI2V for conditional image animation with motion control, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02858",
      "abstract": "Interviews are a widely used technique in eliciting requirements to gather stakeholder needs, preferences, and expectations for a software system. Effective interviewing requires skilled interviewers to formulate appropriate interview questions in real time while facing multiple challenges, including lack of familiarity with the domain, excessive cognitive load, and information overload that hinders how humans process stakeholders' speech. Recently, large language models (LLMs) have exhibited state-of-the-art performance in multiple natural language processing tasks, including text summarization and entailment. To support interviewers, we investigate the application of GPT-4o to generate follow-up interview questions during requirements elicitation by building on a framework of common interviewer mistake types. In addition, we describe methods to generate questions based on interviewee speech. We report a controlled experiment to evaluate LLM-generated and human-authored questions with minimal guidance, and a second controlled experiment to evaluate the LLM-generated questions when generation is guided by interviewer mistake types. Our findings demonstrate that, for both experiments, the LLM-generated questions are no worse than the human-authored questions with respect to clarity, relevancy, and informativeness. In addition, LLM-generated questions outperform human-authored questions when guided by common mistakes types. This highlights the potential of using LLMs to help interviewers improve the quality and ease of requirements elicitation interviews in real time.",
      "authors": [
        "Yuchen Shen",
        "Anmol Singhal",
        "Travis Breaux"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T17:59:04+00:00",
          "link": "https://arxiv.org/abs/2507.02858v1",
          "size": "108kb",
          "version": "v1"
        }
      ],
      "title": "Requirements Elicitation Follow-Up Question Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02858",
        "HTML": "https://arxiv.org/html/2507.02858v1",
        "PDF": "https://arxiv.org/pdf/2507.02858"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research explores LLMs in generating interview questions for requirements elicitation, without focusing on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02859",
      "abstract": "Multimodal Large Language Models (MLLMs) have demonstrated remarkable capabilities in interpreting images using natural language. However, without using large-scale datasets for retraining, these models are difficult to adapt to specialized vision tasks, e.g., chart understanding. This problem is caused by a mismatch between pre-training and downstream datasets: pre-training datasets primarily concentrate on scenes and objects but contain limited information about specialized, non-object images, such as charts and tables. In this paper, we share an interesting finding that training an MLLM with Chain-of-Thought (CoT) reasoning data can facilitate model adaptation in specialized vision tasks, especially under data-limited regimes. However, we identify a critical issue within CoT data distilled from pre-trained MLLMs, i.e., the data often contains multiple factual errors in the reasoning steps. To address the problem, we propose Grounded Chain-of-Thought (GCoT), a simple bootstrapping-based approach that aims to inject grounding information (i.e., bounding boxes) into CoT data, essentially making the reasoning steps more faithful to input images. We evaluate our approach on five specialized vision tasks, which cover a variety of visual formats including charts, tables, receipts, and reports. The results demonstrate that under data-limited regimes our approach significantly improves upon fine-tuning and distillation.",
      "authors": [
        "Jiaer Xia",
        "Bingkui Tong",
        "Yuhang Zang",
        "Rui Shao",
        "Kaiyang Zhou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T17:59:29+00:00",
          "link": "https://arxiv.org/abs/2507.02859v1",
          "size": "896kb",
          "version": "v1"
        }
      ],
      "title": "Bootstrapping Grounded Chain-of-Thought in Multimodal LLMs for Data-Efficient Model Adaptation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02859",
        "HTML": "https://arxiv.org/html/2507.02859v1",
        "PDF": "https://arxiv.org/pdf/2507.02859"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper proposes Grounded Chain-of-Thought (GCoT), an approach to improve reasoning data for training multimodal LLMs, which is directly related to data processing for model adaptation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02860",
      "abstract": "Video generation models have demonstrated remarkable performance, yet their broader adoption remains constrained by slow inference speeds and substantial computational costs, primarily due to the iterative nature of the denoising process. Addressing this bottleneck is essential for democratizing advanced video synthesis technologies and enabling their integration into real-world applications. This work proposes EasyCache, a training-free acceleration framework for video diffusion models. EasyCache introduces a lightweight, runtime-adaptive caching mechanism that dynamically reuses previously computed transformation vectors, avoiding redundant computations during inference. Unlike prior approaches, EasyCache requires no offline profiling, pre-computation, or extensive parameter tuning. We conduct comprehensive studies on various large-scale video generation models, including OpenSora, Wan2.1, and HunyuanVideo. Our method achieves leading acceleration performance, reducing inference time by up to 2.1-3.3$\\times$ compared to the original baselines while maintaining high visual fidelity with a significant up to 36% PSNR improvement compared to the previous SOTA method. This improvement makes our EasyCache a efficient and highly accessible solution for high-quality video generation in both research and practical applications. The code is available at https://github.com/H-EmbodVis/EasyCache.",
      "authors": [
        "Xin Zhou",
        "Dingkang Liang",
        "Kaijin Chen",
        "Tianrui Feng",
        "Xiwu Chen",
        "Hongkai Lin",
        "Yikang Ding",
        "Feiyang Tan",
        "Hengshuang Zhao",
        "Xiang Bai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T17:59:54+00:00",
          "link": "https://arxiv.org/abs/2507.02860v1",
          "size": "1676kb",
          "version": "v1"
        }
      ],
      "title": "Less is Enough: Training-Free Video Diffusion Acceleration via Runtime-Adaptive Caching",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02860",
        "HTML": "https://arxiv.org/html/2507.02860v1",
        "PDF": "https://arxiv.org/pdf/2507.02860"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on accelerating video diffusion models for video generation, not involving LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02861",
      "abstract": "We propose LiteReality, a novel pipeline that converts RGB-D scans of indoor environments into compact, realistic, and interactive 3D virtual replicas. LiteReality not only reconstructs scenes that visually resemble reality but also supports key features essential for graphics pipelines -- such as object individuality, articulation, high-quality physically based rendering materials, and physically based interaction. At its core, LiteReality first performs scene understanding and parses the results into a coherent 3D layout and objects with the help of a structured scene graph. It then reconstructs the scene by retrieving the most visually similar 3D artist-crafted models from a curated asset database. Next, the Material Painting module enhances realism by recovering high-quality, spatially varying materials. Finally, the reconstructed scene is integrated into a simulation engine with basic physical properties to enable interactive behavior. The resulting scenes are compact, editable, and fully compatible with standard graphics pipelines, making them suitable for applications in AR/VR, gaming, robotics, and digital twins. In addition, LiteReality introduces a training-free object retrieval module that achieves state-of-the-art similarity performance on the Scan2CAD benchmark, along with a robust material painting module capable of transferring appearances from images of any style to 3D assets -- even under severe misalignment, occlusion, and poor lighting. We demonstrate the effectiveness of LiteReality on both real-life scans and public datasets. Project page: https://litereality.github.io; Video: https://www.youtube.com/watch?v=ecK9m3LXg2c",
      "authors": [
        "Zhening Huang",
        "Xiaoyang Wu",
        "Fangcheng Zhong",
        "Hengshuang Zhao",
        "Matthias Nie{\\ss}ner",
        "Joan Lasenby"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T17:59:55+00:00",
          "link": "https://arxiv.org/abs/2507.02861v1",
          "size": "41693kb",
          "version": "v1"
        }
      ],
      "title": "LiteReality: Graphics-Ready 3D Scene Reconstruction from RGB-D Scans",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02861",
        "HTML": "https://arxiv.org/html/2507.02861v1",
        "PDF": "https://arxiv.org/pdf/2507.02861"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on 3D scene reconstruction and graphics pipelines, not related to LLM training data processing stages or methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02862",
      "abstract": "Effectively handling temporal redundancy remains a key challenge in learning video models. Prevailing approaches often treat each set of frames independently, failing to effectively capture the temporal dependencies and redundancies inherent in videos. To address this limitation, we introduce RefTok, a novel reference-based tokenization method capable of capturing complex temporal dynamics and contextual information. Our method encodes and decodes sets of frames conditioned on an unquantized reference frame. When decoded, RefTok preserves the continuity of motion and the appearance of objects across frames. For example, RefTok retains facial details despite head motion, reconstructs text correctly, preserves small patterns, and maintains the legibility of handwriting from the context. Across 4 video datasets (K600, UCF-101, BAIR Robot Pushing, and DAVIS), RefTok significantly outperforms current state-of-the-art tokenizers (Cosmos and MAGVIT) and improves all evaluated metrics (PSNR, SSIM, LPIPS) by an average of 36.7% at the same or higher compression ratios. When a video generation model is trained using RefTok's latents on the BAIR Robot Pushing task, the generations not only outperform MAGVIT-B but the larger MAGVIT-L, which has 4x more parameters, across all generation metrics by an average of 27.9%.",
      "authors": [
        "Xiang Fan",
        "Xiaohang Sun",
        "Kushan Thakkar",
        "Zhu Liu",
        "Vimal Bhat",
        "Ranjay Krishna",
        "Xiang Hao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T17:59:55+00:00",
          "link": "https://arxiv.org/abs/2507.02862v1",
          "size": "16457kb",
          "version": "v1"
        }
      ],
      "title": "RefTok: Reference-Based Tokenization for Video Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02862",
        "HTML": "https://arxiv.org/html/2507.02862v1",
        "PDF": "https://arxiv.org/pdf/2507.02862"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a method for video tokenization and generation, focusing on video model learning rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02863",
      "abstract": "Dense 3D scene reconstruction from an ordered sequence or unordered image collections is a critical step when bringing research in computer vision into practical scenarios. Following the paradigm introduced by DUSt3R, which unifies an image pair densely into a shared coordinate system, subsequent methods maintain an implicit memory to achieve dense 3D reconstruction from more images. However, such implicit memory is limited in capacity and may suffer from information loss of earlier frames. We propose Point3R, an online framework targeting dense streaming 3D reconstruction. To be specific, we maintain an explicit spatial pointer memory directly associated with the 3D structure of the current scene. Each pointer in this memory is assigned a specific 3D position and aggregates scene information nearby in the global coordinate system into a changing spatial feature. Information extracted from the latest frame interacts explicitly with this pointer memory, enabling dense integration of the current observation into the global coordinate system. We design a 3D hierarchical position embedding to promote this interaction and design a simple yet effective fusion mechanism to ensure that our pointer memory is uniform and efficient. Our method achieves competitive or state-of-the-art performance on various tasks with low training costs. Code is available at: https://github.com/YkiWu/Point3R.",
      "authors": [
        "Yuqi Wu",
        "Wenzhao Zheng",
        "Jie Zhou",
        "Jiwen Lu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T17:59:56+00:00",
          "link": "https://arxiv.org/abs/2507.02863v1",
          "size": "26556kb",
          "version": "v1"
        }
      ],
      "title": "Point3R: Streaming 3D Reconstruction with Explicit Spatial Pointer Memory",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02863",
        "HTML": "https://arxiv.org/html/2507.02863v1",
        "PDF": "https://arxiv.org/pdf/2507.02863"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses dense 3D scene reconstruction using image collections, a topic unrelated to LLM data collection, construction, or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02864",
      "abstract": "Robots must integrate multiple sensory modalities to act effectively in the real world. Yet, learning such multimodal policies at scale remains challenging. Simulation offers a viable solution, but while vision has benefited from high-fidelity simulators, other modalities (e.g. sound) can be notoriously difficult to simulate. As a result, sim-to-real transfer has succeeded primarily in vision-based tasks, with multimodal transfer still largely unrealized. In this work, we tackle these challenges by introducing MultiGen, a framework that integrates large-scale generative models into traditional physics simulators, enabling multisensory simulation. We showcase our framework on the dynamic task of robot pouring, which inherently relies on multimodal feedback. By synthesizing realistic audio conditioned on simulation video, our method enables training on rich audiovisual trajectories -- without any real robot data. We demonstrate effective zero-shot transfer to real-world pouring with novel containers and liquids, highlighting the potential of generative modeling to both simulate hard-to-model modalities and close the multimodal sim-to-real gap.",
      "authors": [
        "Renhao Wang",
        "Haoran Geng",
        "Tingle Li",
        "Feishi Wang",
        "Gopala Anumanchipalli",
        "Philipp Wu",
        "Trevor Darrell",
        "Boyi Li",
        "Pieter Abbeel",
        "Jitendra Malik",
        "Alexei A. Efros"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T17:59:58+00:00",
          "link": "https://arxiv.org/abs/2507.02864v1",
          "size": "2261kb",
          "version": "v1"
        }
      ],
      "title": "MultiGen: Using Multimodal Generation in Simulation to Learn Multimodal Policies in Real",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02864",
        "HTML": "https://arxiv.org/html/2507.02864v1",
        "PDF": "https://arxiv.org/pdf/2507.02864"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study deals with sim-to-real transfer for robotic multimodal policies, which does not align with LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.00884",
      "abstract": "Accurate atomistic biomolecular simulations are vital for disease mechanism understanding, drug discovery, and biomaterial design, but existing simulation methods exhibit significant limitations. Classical force fields are efficient but lack accuracy for transition states and fine conformational details critical in many chemical and biological processes. Quantum Mechanics (QM) methods are highly accurate but computationally infeasible for large-scale or long-time simulations. AI-based force fields (AIFFs) aim to achieve QM-level accuracy with efficiency but struggle to balance many-body modeling complexity, accuracy, and speed, often constrained by limited training data and insufficient validation for generalizability. To overcome these challenges, we introduce LiTEN, a novel equivariant neural network with Tensorized Quadrangle Attention (TQA). TQA efficiently models three- and four-body interactions with linear complexity by reparameterizing high-order tensor features via vector operations, avoiding costly spherical harmonics. Building on LiTEN, LiTEN-FF is a robust AIFF foundation model, pre-trained on the extensive nablaDFT dataset for broad chemical generalization and fine-tuned on SPICE for accurate solvated system simulations. LiTEN achieves state-of-the-art (SOTA) performance across most evaluation subsets of rMD17, MD22, and Chignolin, outperforming leading models such as MACE, NequIP, and EquiFormer. LiTEN-FF enables the most comprehensive suite of downstream biomolecular modeling tasks to date, including QM-level conformer searches, geometry optimization, and free energy surface construction, while offering 10x faster inference than MACE-OFF for large biomolecules (~1000 atoms). In summary, we present a physically grounded, highly efficient framework that advances complex biomolecular modeling, providing a versatile foundation for drug discovery and related applications.",
      "authors": [
        "Qun Su",
        "Kai Zhu",
        "Qiaolin Gou",
        "Jintu Zhang",
        "Renling Hu",
        "Yurong Li",
        "Yongze Wang",
        "Hui Zhang",
        "Ziyi You",
        "Linlong Jiang",
        "Yu Kang",
        "Jike Wang",
        "Chang-Yu Hsieh",
        "Tingjun Hou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Chemical Physics (physics.chem-ph)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Biological Physics (physics.bio-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T15:52:39+00:00",
          "link": "https://arxiv.org/abs/2507.00884v1",
          "size": "15470kb",
          "version": "v1"
        }
      ],
      "title": "A Scalable and Quantum-Accurate Foundation Model for Biomolecular Force Field via Linearly Tensorized Quadrangle Attention",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.00884",
        "PDF": "https://arxiv.org/pdf/2507.00884"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces a novel neural network and a model for biomolecular simulations, it does involve training methods, albeit in a different domain, which indirectly touches upon training data efficiency. However, it does not focus on LLM training data processing specifically."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.01963",
      "abstract": "From viral jokes to a billion-dollar phenomenon, meme coins have become one of the most popular segments in cryptocurrency markets. Unlike utility-focused crypto assets like Bitcoin or Ethereum, meme coins derive value primarily from community sentiment, making them vulnerable to manipulation. This study presents a cross-chain analysis of the meme coin ecosystem, examining 34,988 tokens across Ethereum, BNB Smart Chain, Solana, and Base. We characterize the tokenomics of meme coins and track their growth in a three-month longitudinal analysis. We discover that among high-return tokens (>100%), an alarming 82.6% show evidence of extensive use of artificial growth strategies designed to create a misleading appearance of market interest. These include wash trading and a form of manipulation we define as Liquidity Pool-Based Price Inflation (LPI), where small strategic purchases trigger dramatic price increases. We also find evidence of schemes designed to profit at the expense of investors, such as pump and dumps and rug pulls. In particular, most of the tokens involved had previously experienced wash trading or LPI, indicating how initial manipulations often set the stage for later exploitation. These findings reveal that manipulations are widespread among high-performing meme coins and suggest that their dramatic gains are often likely driven by coordinated efforts rather than natural market dynamics.",
      "authors": [
        "Alberto Maria Mongardini",
        "Alessandro Mei"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Trading and Market Microstructure (q-fin.TR)",
        "Computers and Society (cs.CY)",
        "Statistical Finance (q-fin.ST)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-16T13:54:42+00:00",
          "link": "https://arxiv.org/abs/2507.01963v1",
          "size": "1181kb",
          "version": "v1"
        }
      ],
      "title": "A Midsummer Meme's Dream: Investigating Market Manipulations in the Meme Coin Ecosystem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01963",
        "HTML": "https://arxiv.org/html/2507.01963v1",
        "PDF": "https://arxiv.org/pdf/2507.01963"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on investigating market manipulations within cryptocurrency ecosystems, specifically meme coins, rather than on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.01964",
      "abstract": "Investors and stock market analysts face major challenges in predicting stock returns and making wise investment decisions. The predictability of equity stock returns can boost investor confidence, but it remains a difficult task. To address this issue, a study was conducted using a Long Short-term Memory (LSTM) model to predict future stock market movements. The study used a historical dataset from the Nigerian Stock Exchange (NSE), which was cleaned and normalized to design the LSTM model. The model was evaluated using performance metrics and compared with other deep learning models like Artificial and Convolutional Neural Networks (CNN). The experimental results showed that the LSTM model can predict future stock market prices and returns with over 90% accuracy when trained with a reliable dataset. The study concludes that LSTM models can be useful in predicting financial time-series-related problems if well-trained. Future studies should explore combining LSTM models with other deep learning techniques like CNN to create hybrid models that mitigate the risks associated with relying on a single model for future equity stock predictions.",
      "authors": [
        "Adebola K. Ojo and Ifechukwude Jude Okafor"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Statistical Finance (q-fin.ST)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-27T11:34:07+00:00",
          "link": "https://arxiv.org/abs/2507.01964v1",
          "size": "752kb",
          "version": "v1"
        }
      ],
      "title": "Forecasting Nigerian Equity Stock Returns Using Long Short-Term Memory Technique",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01964",
        "PDF": "https://arxiv.org/pdf/2507.01964"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on using an LSTM model for stock market prediction, which involves typical data preprocessing steps like cleaning and normalization, but does not specifically address LLM training data processing or propose new data-related methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.01968",
      "abstract": "Purpose: Financial service companies manage huge volumes of data which requires timely error identification and resolution. The associated tasks to resolve these errors frequently put financial analyst workforces under significant pressure leading to resourcing challenges and increased business risk. To address this challenge, we introduce a formal task allocation model which considers both business orientated goals and analyst well-being.\n  Methodology: We use a Genetic Algorithm (GA) to optimise our formal model to allocate and schedule tasks to analysts. The proposed solution is able to allocate tasks to analysts with appropriate skills and experience, while taking into account staff well-being objectives.\n  Findings: We demonstrate our GA model outperforms baseline heuristics, current working practice, and is applicable to a range of single and multi-objective real-world scenarios. We discuss the potential for metaheuristics (such as GAs) to efficiently find sufficiently good allocations which can provide recommendations for financial service managers in-the-loop.\n  Originality: A key gap in existing allocation and scheduling models, is fully considering worker well-being. This paper presents an allocation model which explicitly optimises for well-being while still improving on current working practice for efficiency.",
      "authors": [
        "Chris Duckworth",
        "Zlatko Zlatev",
        "James Sciberras",
        "Peter Hallett",
        "Enrico Gerding"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "General Finance (q-fin.GN)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-18T11:37:25+00:00",
          "link": "https://arxiv.org/abs/2507.01968v1",
          "size": "433kb",
          "version": "v1"
        }
      ],
      "title": "Optimising task allocation to balance business goals and worker well-being for financial service workforces",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01968",
        "HTML": "https://arxiv.org/html/2507.01968v1",
        "PDF": "https://arxiv.org/pdf/2507.01968"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses task allocation in financial services and uses a Genetic Algorithm for optimization. It does not involve any content related to the processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.01969",
      "abstract": "The main goal of this paper is to settle a conceptual framework for cooperative game theory in which the notion of composition/aggregation of games is the defining structure. This is done via the mathematical theory of algebraic operads: we start by endowing the collection of all cooperative games with any number of players with an operad structure, and we show that it generalises all the previous notions of sums, products and compositions of games considered by Owen, Shapley, von Neumann and Morgenstern, and many others. Furthermore, we explicitly compute this operad in terms of generators and relations, showing that the M\\\"obius transform map induces a canonical isomorphism between the operad of cooperative games and the operad that encodes commutative triassociative algebras. In other words, we prove that any cooperative game is a linear combination of iterated compositions of the 2-player bargaining game and the 2-player dictator games. We show that many interesting classes of games (simple, balanced, capacities a.k.a fuzzy measures and convex functions, totally monotone, etc) are stable under compositions, and thus form suboperads. In the convex case, this gives by the submodularity theorem a new operad structure on the family of all generalized permutahedra. Finally, we focus on how solution concepts in cooperative game theory behave under composition: we study the core of a composite and describe it in terms of the core of its components, and we give explicit formulas for the Shapley value and the Banzhaf index of a compound game.",
      "authors": [
        "Dylan Laplace Mermoud",
        "Victor Roca i Lucio"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Computer Science and Game Theory (cs.GT)",
        "Theoretical Economics (econ.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-19T14:56:54+00:00",
          "link": "https://arxiv.org/abs/2507.01969v1",
          "size": "283kb",
          "version": "v1"
        }
      ],
      "title": "The algebraic structures of social organizations: the operad of cooperative games",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01969",
        "HTML": "https://arxiv.org/html/2507.01969v1",
        "PDF": "https://arxiv.org/pdf/2507.01969"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about developing a conceptual framework for cooperative game theory using algebraic structures. It does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.01970",
      "abstract": "This paper will discuss how headline data can be used to predict stock prices. The stock price in question is the SPDR S&P 500 ETF Trust, also known as SPY that tracks the performance of the largest 500 publicly traded corporations in the United States. A key focus is to use news headlines from the Wall Street Journal (WSJ) to predict the movement of stock prices on a daily timescale with OpenAI-based text embedding models used to create vector encodings of each headline with principal component analysis (PCA) to exact the key features. The challenge of this work is to capture the time-dependent and time-independent, nuanced impacts of news on stock prices while handling potential lag effects and market noise. Financial and economic data were collected to improve model performance; such sources include the U.S. Dollar Index (DXY) and Treasury Interest Yields. Over 390 machine-learning inference models were trained. The preliminary results show that headline data embeddings greatly benefit stock price prediction by at least 40% compared to training and optimizing a machine learning system without headline data embeddings.",
      "authors": [
        "Ayaan Qayyum"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Statistical Finance (q-fin.ST)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-19T17:30:07+00:00",
          "link": "https://arxiv.org/abs/2507.01970v1",
          "size": "1079kb",
          "version": "v1"
        }
      ],
      "title": "News Sentiment Embeddings for Stock Price Forecasting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01970",
        "HTML": "https://arxiv.org/html/2507.01970v1",
        "PDF": "https://arxiv.org/pdf/2507.01970"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper uses OpenAI-based text embedding models to create vector encodings for news headlines, which involves data preparation techniques relevant to NLP. However, it does not introduce novel methods for LLM training data processing or construction."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.01971",
      "abstract": "Support and resistance (SR) levels are central to technical analysis, guiding traders in entry, exit, and risk management. Despite widespread use, traditional SR identification methods often fail to adapt to the complexities of modern, volatile markets. Recent research has introduced machine learning techniques to address the following challenges, yet most focus on price prediction rather than structural level identification. This paper presents DeepSupp, a new deep learning approach for detecting financial support levels using multi-head attention mechanisms to analyze spatial correlations and market microstructure relationships. DeepSupp integrates advanced feature engineering, constructing dynamic correlation matrices that capture evolving market relationships, and employs an attention-based autoencoder for robust representation learning. The final support levels are extracted through unsupervised clustering, leveraging DBSCAN to identify significant price thresholds. Comprehensive evaluations on S&P 500 tickers demonstrate that DeepSupp outperforms six baseline methods, achieving state-of-the-art performance across six financial metrics, including essential support accuracy and market regime sensitivity. With consistent results across diverse market conditions, DeepSupp addresses critical gaps in SR level detection, offering a scalable and reliable solution for modern financial analysis. Our approach highlights the potential of attention-based architectures to uncover nuanced market patterns and improve technical trading strategies.",
      "authors": [
        "Boris Kriuk",
        "Logic Ng",
        "Zarif Al Hossain"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Statistical Finance (q-fin.ST)",
        "Artificial Intelligence (cs.AI)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-22T11:09:55+00:00",
          "link": "https://arxiv.org/abs/2507.01971v1",
          "size": "769kb",
          "version": "v1"
        }
      ],
      "title": "DeepSupp: Attention-Driven Correlation Pattern Analysis for Dynamic Time Series Support and Resistance Levels Identification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01971",
        "HTML": "https://arxiv.org/html/2507.01971v1",
        "PDF": "https://arxiv.org/pdf/2507.01971"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a deep learning approach for financial support and resistance level identification using attention mechanisms, focusing on market analysis rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.01972",
      "abstract": "We present a reinforcement learning (RL)-driven framework for optimizing block-preconditioner sizes in iterative solvers used in portfolio optimization and option pricing. The covariance matrix in portfolio optimization or the discretization of differential operators in option pricing models lead to large linear systems of the form $\\mathbf{A}\\textbf{x}=\\textbf{b}$. Direct inversion of high-dimensional portfolio or fine-grid option pricing incurs a significant computational cost. Therefore, iterative methods are usually used for portfolios in real-world situations. Ill-conditioned systems, however, suffer from slow convergence. Traditional preconditioning techniques often require problem-specific parameter tuning. To overcome this limitation, we rely on RL to dynamically adjust the block-preconditioner sizes and accelerate iterative solver convergence. Evaluations on a suite of real-world portfolio optimization matrices demonstrate that our RL framework can be used to adjust preconditioning and significantly accelerate convergence and reduce computational cost. The proposed accelerated solver supports faster decision-making in dynamic portfolio allocation and real-time option pricing.",
      "authors": [
        "Hadi Keramati and Samaneh Jazayeri"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Portfolio Management (q-fin.PM)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Computational Finance (q-fin.CP)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T07:11:56+00:00",
          "link": "https://arxiv.org/abs/2507.01972v1",
          "size": "345kb",
          "version": "v1"
        }
      ],
      "title": "Accelerated Portfolio Optimization and Option Pricing with Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01972",
        "HTML": "https://arxiv.org/html/2507.01972v1",
        "PDF": "https://arxiv.org/pdf/2507.01972"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses reinforcement learning for optimizing preconditioners in portfolio optimization and option pricing, with no mention of large language model data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.01979",
      "abstract": "We present a deep learning approach for forecasting short-term employment changes and assessing long-term industry health using labor market data from the U.S. Bureau of Labor Statistics. Our system leverages a Long- and Short-Term Time-series Network (LSTNet) to process multivariate time series data, including employment levels, wages, turnover rates, and job openings. The model outputs both 7-day employment forecasts and an interpretable Industry Employment Health Index (IEHI). Our approach outperforms baseline models across most sectors, particularly in stable industries, and demonstrates strong alignment between IEHI rankings and actual employment volatility. We discuss error patterns, sector-specific performance, and future directions for improving interpretability and generalization.",
      "authors": [
        "Adam Nelson-Archer",
        "Aleia Sen",
        "Meena Al Hasani",
        "Sofia Davila",
        "Jessica Le",
        "Omar Abbouchi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Statistical Finance (q-fin.ST)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T07:14:02+00:00",
          "link": "https://arxiv.org/abs/2507.01979v1",
          "size": "2615kb",
          "version": "v1"
        }
      ],
      "title": "Forecasting Labor Markets with LSTNet: A Multi-Scale Deep Learning Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01979",
        "HTML": "https://arxiv.org/html/2507.01979v1",
        "PDF": "https://arxiv.org/pdf/2507.01979"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a deep learning approach for forecasting employment changes using labor market data, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.01980",
      "abstract": "Fraudulent activity in the financial industry costs billions annually. Detecting fraud, therefore, is an essential yet technically challenging task that requires carefully analyzing large volumes of data. While machine learning (ML) approaches seem like a viable solution, applying them successfully is not so easy due to two main challenges: (1) the sparsely labeled data, which makes the training of such approaches challenging (with inherent labeling costs), and (2) lack of explainability for the flagged items posed by the opacity of ML models, that is often required by business regulations. This article proposes SAGE-FIN, a semi-supervised graph neural network (GNN) based approach with Granger causal explanations for Financial Interaction Networks. SAGE-FIN learns to flag fraudulent items based on weakly labeled (or unlabelled) data points. To adhere to regulatory requirements, the flagged items are explained by highlighting related items in the network using Granger causality. We empirically validate the favorable performance of SAGE-FIN on a real-world dataset, Bipartite Edge-And-Node Attributed financial network (Elliptic++), with Granger-causal explanations for the identified fraudulent items without any prior assumption on the network structure.",
      "authors": [
        "Linh Nguyen",
        "Marcel Boersma and Erman Acar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Statistical Finance (q-fin.ST)",
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T12:04:40+00:00",
          "link": "https://arxiv.org/abs/2507.01980v1",
          "size": "973kb",
          "version": "v1"
        }
      ],
      "title": "Detecting Fraud in Financial Networks: A Semi-Supervised GNN Approach with Granger-Causal Explanations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01980",
        "HTML": "https://arxiv.org/html/2507.01980v1",
        "PDF": "https://arxiv.org/pdf/2507.01980"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a semi-supervised GNN approach for fraud detection in financial networks and does not discuss any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.01987",
      "abstract": "The emergence of Open Banking represents a significant shift in financial data management, influencing financial institutions' market dynamics and marketing strategies. This increased competition creates opportunities and challenges, as institutions manage data inflow to improve products and services while mitigating data outflow that could aid competitors. This study introduces a framework to predict customers' propensity to share data via Open Banking and interprets this behavior through Explanatory Model Analysis (EMA). Using data from a large Brazilian financial institution with approximately 3.2 million customers, a hybrid data balancing strategy incorporating ADASYN and NEARMISS techniques was employed to address the infrequency of data sharing and enhance the training of XGBoost models. These models accurately predicted customer data sharing, achieving 91.39% accuracy for inflow and 91.53% for outflow. The EMA phase combined the Shapley Additive Explanations (SHAP) method with the Classification and Regression Tree (CART) technique, revealing the most influential features on customer decisions. Key features included the number of transactions and purchases in mobile channels, interactions within these channels, and credit-related features, particularly credit card usage across the national banking system. These results highlight the critical role of mobile engagement and credit in driving customer data-sharing behaviors, providing financial institutions with strategic insights to enhance competitiveness and innovation in the Open Banking environment.",
      "authors": [
        "Jo\\~ao B. G. de Brito",
        "Rodrigo Heldt",
        "Cleo S. Silveira",
        "Matthias Bogaert",
        "Guilherme B. Bucco",
        "Fernando B. Luce",
        "Jo\\~ao L. Becker",
        "Filipe J. Zabala and Michel J. Anzanello"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "General Finance (q-fin.GN)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T01:24:59+00:00",
          "link": "https://arxiv.org/abs/2507.01987v1",
          "size": "226kb",
          "version": "v1"
        }
      ],
      "title": "Predicting and Explaining Customer Data Sharing in the Open Banking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01987",
        "PDF": "https://arxiv.org/pdf/2507.01987"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a framework for predicting customer data sharing in Open Banking, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.01990",
      "abstract": "Large Language Models (LLMs) have been employed in financial decision making, enhancing analytical capabilities for investment strategies. Traditional investment strategies often utilize quantitative models, fundamental analysis, and technical indicators. However, LLMs have introduced new capabilities to process and analyze large volumes of structured and unstructured data, extract meaningful insights, and enhance decision-making in real-time. This survey provides a structured overview of recent research on LLMs within the financial domain, categorizing research contributions into four main frameworks: LLM-based Frameworks and Pipelines, Hybrid Integration Methods, Fine-Tuning and Adaptation Approaches, and Agent-Based Architectures. This study provides a structured review of recent LLMs research on applications in stock selection, risk assessment, sentiment analysis, trading, and financial forecasting. By reviewing the existing literature, this study highlights the capabilities, challenges, and potential directions of LLMs in financial markets.",
      "authors": [
        "Sedigheh Mahdavi",
        "Jiating (Kristin) Chen",
        "Pradeep Kumar Joshi",
        "Lina Huertas Guativa",
        "and Upmanyu Singh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "General Finance (q-fin.GN)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T05:25:31+00:00",
          "link": "https://arxiv.org/abs/2507.01990v1",
          "size": "65kb",
          "version": "v1"
        }
      ],
      "title": "Integrating Large Language Models in Financial Investments and Market Analysis: A Survey",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01990",
        "HTML": "https://arxiv.org/html/2507.01990v1",
        "PDF": "https://arxiv.org/pdf/2507.01990"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper surveys the integration of LLMs in financial markets, it briefly mentions fine-tuning and adaptation, indicating some involvement in training data processing, but it does not propose new methods in this area."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.01991",
      "abstract": "The proliferation of artificial intelligence (AI) in financial services has prompted growing demand for tools that can systematically detect AI-related disclosures in corporate filings. While prior approaches often rely on keyword expansion or document-level classification, they fall short in granularity, interpretability, and robustness. This study introduces FinAI-BERT, a domain-adapted transformer-based language model designed to classify AI-related content at the sentence level within financial texts. The model was fine-tuned on a manually curated and balanced dataset of 1,586 sentences drawn from 669 annual reports of U.S. banks (2015 to 2023). FinAI-BERT achieved near-perfect classification performance (accuracy of 99.37 percent, F1 score of 0.993), outperforming traditional baselines such as Logistic Regression, Naive Bayes, Random Forest, and XGBoost. Interpretability was ensured through SHAP-based token attribution, while bias analysis and robustness checks confirmed the model's stability across sentence lengths, adversarial inputs, and temporal samples. Theoretically, the study advances financial NLP by operationalizing fine-grained, theme-specific classification using transformer architectures. Practically, it offers a scalable, transparent solution for analysts, regulators, and scholars seeking to monitor the diffusion and framing of AI across financial institutions.",
      "authors": [
        "Muhammad Bilal Zafar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Finance (q-fin.CP)",
        "Computation and Language (cs.CL)",
        "General Economics (econ.GN)",
        "Economics (q-fin.EC)",
        "General Finance (q-fin.GN)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T09:33:29+00:00",
          "link": "https://arxiv.org/abs/2507.01991v1",
          "size": "556kb",
          "version": "v1"
        }
      ],
      "title": "FinAI-BERT: A Transformer-Based Model for Sentence-Level Detection of AI Disclosures in Financial Reports",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01991",
        "PDF": "https://arxiv.org/pdf/2507.01991"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses the fine-tuning of a language model for a specific classification task in finance, involving data preparation, but does not introduce novel data processing methodologies primarily for LLM training."
      },
      "models": [
        {
          "model_path": "bilalzafar/FinAI-BERT",
          "downloads": "79",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/bilalzafar/FinAI-BERT"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.01996",
      "abstract": "This work investigates the benefits of implementing a systematic approach to social isolation policies during epidemics. We develop a mixed integer data-driven model predictive control (MPC) scheme based on an SIHRD model which is identified from available data. The case of the spread of the SARS-CoV-2 virus (also known as COVID-19) in Mauritius is used as a reference point with data obtained during the period December 2021 to May 2022. The isolation scheme is designed with the control decision variable taking a finite set of values corresponding to the desired level of isolation. The control input is further restricted to shifting between levels only after a minimum amount of time. The simulation results validate our design, showing that the need for hospitalisation remains within the capacity of the health centres, with the number of deaths considerably reduced by raising the level of isolation for short periods of time with negligible social and economic impact. We also show that the introduction of additional isolation levels results in a smoother containment approach with a considerably reduced hospitalisation burden.",
      "authors": [
        "S. Z. Sayed Hassen and A. Aboudonia and J. Lygeros"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Populations and Evolution (q-bio.PE)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T19:49:29+00:00",
          "link": "https://arxiv.org/abs/2507.01996v1",
          "size": "165kb",
          "version": "v1"
        }
      ],
      "title": "A Data-Driven Model Predictive Controller to manage epidemics: The case of SARS-CoV-2 in Mauritius",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01996",
        "HTML": "https://arxiv.org/html/2507.01996v1",
        "PDF": "https://arxiv.org/pdf/2507.01996"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study explores epidemic management using a data-driven model predictive controller, which is unrelated to the processes or methodologies for LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02011",
      "abstract": "This paper presents a machine learning driven framework for sectoral stress testing in the Indian financial market, focusing on financial services, information technology, energy, consumer goods, and pharmaceuticals. Initially, we address the limitations observed in conventional stress testing through dimensionality reduction and latent factor modeling via Principal Component Analysis and Autoencoders. Building on this, we extend the methodology using Variational Autoencoders, which introduces a probabilistic structure to the latent space. This enables Monte Carlo-based scenario generation, allowing for more nuanced, distribution-aware simulation of stressed market conditions. The proposed framework captures complex non-linear dependencies and supports risk estimation through Value-at-Risk and Expected Shortfall. Together, these pipelines demonstrate the potential of Machine Learning approaches to improve the flexibility, robustness, and realism of financial stress testing.",
      "authors": [
        "Vidya Sagar G and Shifat Ali and Siddhartha P. Chakrabarty"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Risk Management (q-fin.RM)",
        "Machine Learning (cs.LG)",
        "Portfolio Management (q-fin.PM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T07:47:56+00:00",
          "link": "https://arxiv.org/abs/2507.02011v1",
          "size": "1504kb",
          "version": "v1"
        }
      ],
      "title": "Machine Learning Based Stress Testing Framework for Indian Financial Market Portfolios",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02011",
        "HTML": "https://arxiv.org/html/2507.02011v1",
        "PDF": "https://arxiv.org/pdf/2507.02011"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses a machine learning based stress testing framework for financial markets, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02018",
      "abstract": "Graph representation learning methods have been widely adopted in financial applications to enhance company representations by leveraging inter-firm relationships. However, current approaches face three key challenges: (1) The advantages of relational information are obscured by limitations in downstream task designs; (2) Existing graph models specifically designed for stock prediction often suffer from excessive complexity and poor generalization; (3) Experience-based construction of corporate relationship graphs lacks effective comparison of different graph structures. To address these limitations, we propose a long-term stock prediction task and develop a Node-level Graph Attention Network (NGAT) specifically tailored for corporate relationship graphs. Furthermore, we experimentally demonstrate the limitations of existing graph comparison methods based on model downstream task performance. Experimental results across two datasets consistently demonstrate the effectiveness of our proposed task and model. The project is publicly available on GitHub to encourage reproducibility and future research.",
      "authors": [
        "Yingjie Niu",
        "Mingchuan Zhao",
        "Valerio Poti",
        "Ruihai Dong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Statistical Finance (q-fin.ST)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T13:59:46+00:00",
          "link": "https://arxiv.org/abs/2507.02018v1",
          "size": "516kb",
          "version": "v1"
        }
      ],
      "title": "NGAT: A Node-level Graph Attention Network for Long-term Stock Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02018",
        "HTML": "https://arxiv.org/html/2507.02018v1",
        "PDF": "https://arxiv.org/pdf/2507.02018"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a node-level graph attention network for stock prediction and does not discuss the processing or engineering of training data for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02024",
      "abstract": "Background: In vitro endothelial cell culture is widely used to study angiogenesis. Histomicrographic images of cell networks are often analyzed manually, a process that is time-consuming and subjective. Automated tools like ImageJ (NIH) can assist, but are often slow and inaccurate. Additionally, as endothelial networks grow more complex, traditional architectural metrics may not fully reflect network maturity. To address these limitations, we developed tubuleTracker, a software tool that quantifies endothelial network architecture and maturity rapidly and objectively. Methods: Human umbilical vein endothelial cells were cultured in an extracellular matrix, and 54 images were acquired using phase contrast microscopy. Each image was analyzed manually by three independent reviewers, and by both ImageJ and tubuleTracker. Key metrics included tubule count, total length, node count, tubule area, and vessel circularity. In parallel, trained scientists rated each image for angiogenesis maturity on a 1-5 scale (1 = most mature). Results: Analysis time per image differed significantly: manual (8 min), ImageJ (58+/-4 s), and tubuleTracker (6+/-2 s) (p<0.0001). Significant differences were also found in tubule count (manual 168+/-SD, tubuleTracker 92+/-SD, ImageJ 433+/-SD), length, and node count (all p<0.0001). tubuleTracker's metrics varied significantly across angiogenesis maturity scores, including tubule count, length, node count, area, and circularity (all p<0.0001). Conclusions: tubuleTracker was faster and more consistent than both manual and ImageJ-based analysis. Vessel circularity proved especially effective in capturing angiogenesis maturity. tubuleTracker is available as free shareware for the biomedical research community.",
      "authors": [
        "Danish Mahmood",
        "Stephanie Buczkowski",
        "Sahaj Shah",
        "Autumn Anthony",
        "Rohini Desetty",
        "Carlo R Bartoli"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantitative Methods (q-bio.QM)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Cell Behavior (q-bio.CB)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T15:46:39+00:00",
          "link": "https://arxiv.org/abs/2507.02024v1",
          "size": "2131kb",
          "version": "v1"
        }
      ],
      "title": "TubuleTracker: a high-fidelity shareware software to quantify angiogenesis architecture and maturity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02024",
        "PDF": "https://arxiv.org/pdf/2507.02024"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a tool for quantifying angiogenesis in biological images and does not involve LLM training data processing or construction."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02084",
      "abstract": "The adaptive Iterative Soft-Thresholding Algorithm (ISTA) has been a popular algorithm for finding a desirable solution to the LASSO problem without explicitly tuning the regularization parameter $\\lambda$. Despite that the adaptive ISTA is a successful practical algorithm, few theoretical results exist. In this paper, we present the theoretical analysis on the adaptive ISTA with the thresholding strategy of estimating noise level by median absolute deviation. We show properties of the fixed points of the algorithm, including scale equivariance, non-uniqueness, and local stability, prove the local linear convergence guarantee, and show its global convergence behavior.",
      "authors": [
        "Yining Feng",
        "and Ivan Selesnick"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T18:41:59+00:00",
          "link": "https://arxiv.org/abs/2507.02084v1",
          "size": "719kb",
          "version": "v1"
        }
      ],
      "title": "Adaptive Iterative Soft-Thresholding Algorithm with the Median Absolute Deviation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02084",
        "HTML": "https://arxiv.org/html/2507.02084v1",
        "PDF": "https://arxiv.org/pdf/2507.02084"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the theoretical analysis of the adaptive Iterative Soft-Thresholding Algorithm related to finding solutions to the LASSO problem, without mention of LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02086",
      "abstract": "Quantum Machine Learning (QML) has seen significant advancements, driven by recent improvements in Noisy Intermediate-Scale Quantum (NISQ) devices. Leveraging quantum principles such as entanglement and superposition, quantum convolutional neural networks (QCNNs) have demonstrated promising results in classifying both quantum and classical data. This study examines QCNNs in the context of image classification and proposes a novel strategy to enhance feature processing and a QCNN architecture for improved classification accuracy. First, a selective feature re-encoding strategy is proposed, which directs the quantum circuits to prioritize the most informative features, thereby effectively navigating the crucial regions of the Hilbert space to find the optimal solution space. Secondly, a novel parallel-mode QCNN architecture is designed to simultaneously incorporate features extracted by two classical methods, Principal Component Analysis (PCA) and Autoencoders, within a unified training scheme. The joint optimization involved in the training process allows the QCNN to benefit from complementary feature representations, enabling better mutual readjustment of model parameters. To assess these methodologies, comprehensive experiments have been performed using the widely used MNIST and Fashion MNIST datasets for binary classification tasks. Experimental findings reveal that the selective feature re-encoding method significantly improves the quantum circuit's feature processing capability and performance. Furthermore, the jointly optimized parallel QCNN architecture consistently outperforms the individual QCNN models and the traditional ensemble approach involving independent learning followed by decision fusion, confirming its superior accuracy and generalization capabilities.",
      "authors": [
        "Shaswata Mahernob Sarkar",
        "Sheikh Iftekhar Ahmed",
        "Jishnu Mahmud",
        "Shaikh Anowarul Fattah",
        "Gaurav Sharma"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T18:51:56+00:00",
          "link": "https://arxiv.org/abs/2507.02086v1",
          "size": "1578kb",
          "version": "v1"
        }
      ],
      "title": "Selective Feature Re-Encoded Quantum Convolutional Neural Network with Joint Optimization for Image Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02086",
        "HTML": "https://arxiv.org/html/2507.02086v1",
        "PDF": "https://arxiv.org/pdf/2507.02086"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores quantum machine learning for image classification without addressing any aspects related to LLM training data or data processing for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02106",
      "abstract": "We present a hybrid machine learning framework that combines Physics-Informed Neural Operators (PINOs) with score-based generative diffusion models to simulate the full spatio-temporal evolution of two-dimensional, incompressible, resistive magnetohydrodynamic (MHD) turbulence across a broad range of Reynolds numbers ($\\mathrm{Re}$). The framework leverages the equation-constrained generalization capabilities of PINOs to predict coherent, low-frequency dynamics, while a conditional diffusion model stochastically corrects high-frequency residuals, enabling accurate modeling of fully developed turbulence. Trained on a comprehensive ensemble of high-fidelity simulations with $\\mathrm{Re} \\in \\{100, 250, 500, 750, 1000, 3000, 10000\\}$, the approach achieves state-of-the-art accuracy in regimes previously inaccessible to deterministic surrogates. At $\\mathrm{Re}=1000$ and $3000$, the model faithfully reconstructs the full spectral energy distributions of both velocity and magnetic fields late into the simulation, capturing non-Gaussian statistics, intermittent structures, and cross-field correlations with high fidelity. At extreme turbulence levels ($\\mathrm{Re}=10000$), it remains the first surrogate capable of recovering the high-wavenumber evolution of the magnetic field, preserving large-scale morphology and enabling statistically meaningful predictions.",
      "authors": [
        "Semih Kacmaz",
        "E. A. Huerta",
        "Roland Haas"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Fluid Dynamics (physics.flu-dyn)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "General Relativity and Quantum Cosmology (gr-qc)",
        "Computational Physics (physics.comp-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T19:33:57+00:00",
          "link": "https://arxiv.org/abs/2507.02106v1",
          "size": "3460kb",
          "version": "v1"
        }
      ],
      "title": "Resolving Turbulent Magnetohydrodynamics: A Hybrid Operator-Diffusion Framework",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02106",
        "HTML": "https://arxiv.org/html/2507.02106v1",
        "PDF": "https://arxiv.org/pdf/2507.02106"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research paper presents a hybrid machine learning framework for magnetohydrodynamic turbulence simulation, with no mention of LLM training data processing or data engineering stages relevant to LLM contexts."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02131",
      "abstract": "This article investigates the robustness of gradient descent algorithms under perturbations. The concept of small-disturbance input-to-state stability (ISS) for discrete-time nonlinear dynamical systems is introduced, along with its Lyapunov characterization. The conventional linear Polyak-Lojasiewicz (PL) condition is then extended to a nonlinear version, and it is shown that the gradient descent algorithm is small-disturbance ISS provided the objective function satisfies the generalized nonlinear PL condition. This small-disturbance ISS property guarantees that the gradient descent algorithm converges to a small neighborhood of the optimum under sufficiently small perturbations. As a direct application of the developed framework, we demonstrate that the LQR cost satisfies the generalized nonlinear PL condition, thereby establishing that the policy gradient algorithm for LQR is small-disturbance ISS. Additionally, other popular policy gradient algorithms, including natural policy gradient and Gauss-Newton method, are also proven to be small-disturbance ISS.",
      "authors": [
        "Leilei Cui",
        "Zhong-Ping Jiang",
        "Eduardo D. Sontag",
        "and Richard D. Braatz"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T20:31:28+00:00",
          "link": "https://arxiv.org/abs/2507.02131v1",
          "size": "52kb",
          "version": "v1"
        }
      ],
      "title": "Perturbed Gradient Descent Algorithms are Small-Disturbance Input-to-State Stable",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02131",
        "HTML": "https://arxiv.org/html/2507.02131v1",
        "PDF": "https://arxiv.org/pdf/2507.02131"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses perturbation robustness in gradient descent algorithms, with no connection to LLM training data processing or data engineering for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02189",
      "abstract": "This study presents a simplified FEM modeling approach suitable for large structures made of corrugated boards, such as customized packages, based on a homogenization method, which is combined with correction factors for internal mechanisms. The homogenization process reduces computational time by transforming flute geometries into equivalent elastic models. In large deformations and in the presence of contact for a given geometry, the effective elastic modulus in the thickness direction, as well as the effective thickness of the structure, are corrected by two statistical Weibull distributions representing the contact and buckling mechanisms in a corrugated board. The Weibull parameters are obtained via experimental analysis, and such a process is then validated. The results demonstrate that the statistical parameters ($\\beta_1 = 0.14$, $\\beta_2 = 1.31$) can be used for the simplistic representation of corrugated boards, being computationally efficient. This research contributes to the optimization of corrugated packaging design, specifically by simplifying FEM models for faster yet equally accurate simulations.",
      "authors": [
        "Ricardo Fitas",
        "Heinz Joachim Schaffrath",
        "Samuel Schabel"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Applied Physics (physics.app-ph)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Computational Physics (physics.comp-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T22:53:24+00:00",
          "link": "https://arxiv.org/abs/2507.02189v1",
          "size": "2188kb",
          "version": "v1"
        }
      ],
      "title": "On the Design of Corrugated Boards: A New FEM Modeling and Experimental Validation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02189",
        "HTML": "https://arxiv.org/html/2507.02189v1",
        "PDF": "https://arxiv.org/pdf/2507.02189"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on FEM modeling and optimization of corrugated packaging design, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02193",
      "abstract": "A significant hallmark of hypertrophic cardiomyopathy (HCM) is fiber disarray, which is associated with various cardiac events such as heart failure. Quantifying fiber disarray remains critical for understanding the disease s complex pathophysiology. This study investigates the role of heterogeneous HCM-induced cellular abnormalities in the development of fiber disarray and their subsequent impact on cardiac pumping function. Fiber disarray is predicted using a stress-based law to reorient myofibers and collagen within a multiscale finite element cardiac modeling framework, MyoFE. Specifically, the model is used to quantify the distinct impacts of heterogeneous distributions of hypercontractility, hypocontractility, and fibrosis on fiber disarray development and examines their effect on functional characteristics of the heart. Our results show that heterogenous cell level abnormalities highly disrupt the normal mechanics of myocardium and lead to significant fiber disarray. The pattern of disarray varies depending on the specific perturbation, offering valuable insights into the progression of HCM. Despite the random distribution of perturbed regions within the cardiac muscle, significantly higher fiber disarray is observed near the epicardium compared to the endocardium across all perturbed left ventricle (LV) models. This regional difference in fiber disarray, irrespective of perturbation severity, aligns with previous DT-MRI studies, highlighting the role of regional myocardial mechanics in the development of fiber disarray. Furthermore, cardiac performance declined in the remodeled LVs, particularly in those with fibrosis and hypocontractility. These findings provide important insights into the structural and functional consequences of HCM and offer a framework for future investigations into therapeutic interventions targeting cardiac remodeling.",
      "authors": [
        "Mohammad Mehri",
        "Kenneth S. Campbell",
        "Lik Chuan Lee",
        "Jonathan F. Wenk"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Tissues and Organs (q-bio.TO)",
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T23:06:30+00:00",
          "link": "https://arxiv.org/abs/2507.02193v1",
          "size": "3103kb",
          "version": "v1"
        }
      ],
      "title": "A Multi-Scale Finite Element Method for Investigating Fiber Remodeling in Hypertrophic Cardiomyopathy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02193",
        "PDF": "https://arxiv.org/pdf/2507.02193"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study investigates cardiac fiber remodeling through finite element methods and has no relevance to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02207",
      "abstract": "As fusion energy technologies approach demonstration and commercial deployment, understanding public perspectives on future fusion facilities will be critical for achieving social license, especially because fusion energy facilities, unlike large fission reactors, may be sited in closer proximity to people and communities, due to distinct regulatory frameworks. In a departure from the 'decide-announce-defend' approach typically used to site energy infrastructure, we develop a participatory design methodology for collaboratively designing fusion energy facilities with prospective host communities. We present here our findings from a participatory design workshop that brought together 22 community participants and 34 engineering students. Our analysis of the textual and visual data from this workshop shows a range of design values and decision-making criteria with 'integrity' and 'respect' ranking highest among values and 'economic benefits' and 'environmental protection/safety' ranking highest among decision-making criteria. Salient design themes that emerge across facility concepts include connecting the history and legacy of the community to the design of the facility, care for workers, transparency and access to the facility, and health and safety of the host community. Participants reported predominantly positive sentiments, expressing joy and surprise as the workshop progressed from learning about fusion to designing the hypothetical facility. Our findings suggest that carrying out participatory design in the early stages of technology development can invite and make concrete public hopes and concerns, improve understanding of, and curiosity about, an emerging technology, build toward social license, and inform context-specific development of fusion energy facilities.",
      "authors": [
        "Nathan Kawamoto",
        "Daniel Hoover",
        "Jonathan Xie",
        "Jacob Walters",
        "Katie Snyder",
        "Aditi Verma"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Physics and Society (physics.soc-ph)",
        "Human-Computer Interaction (cs.HC)",
        "Physics Education (physics.ed-ph)",
        "Plasma Physics (physics.plasm-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T00:01:39+00:00",
          "link": "https://arxiv.org/abs/2507.02207v1",
          "size": "10249kb",
          "version": "v1"
        }
      ],
      "title": "Public perspectives on the design of fusion energy facilities",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02207",
        "PDF": "https://arxiv.org/pdf/2507.02207"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses public perspectives and participatory design for fusion energy facilities, which is unrelated to the processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02208",
      "abstract": "This work aims to model the hypersurface of the effective elastic modulus, \\( E_{z, \\text{eff}} \\), and thickness, \\( th_{\\text{eff}} \\), in corrugated boards. A Latin Hypercube Sampling (LHS) is followed by Gaussian Process Regression (GP), enhanced by EHVI as a multi-objective acquisition function. Accurate modeling of \\( E_{z, \\text{eff}} \\) and \\( th_{\\text{eff}} \\) is critical for optimizing the mechanical properties of corrugated materials in engineering applications. LHS provides an efficient and straightforward approach for an initial sampling of the input space; GP is expected to be able to adapt to the complexity of the response surfaces by incorporating both prediction and uncertainty. Therefore, the next points being generated and evaluated are based on the complexity of the hypersurfaces, and some points, especially those with higher variance, are more exploited and carry more importance. The performance of GP with EHVI is measured by Mean Squared Error (MSE). Prediction of GP resulted in \\( \\text{MSE}(E_{z, \\text{eff}}) = 5.24 \\, \\text{kPa}^2 \\) and \\( \\text{MSE}(th_{\\text{eff}}) = 1 \\, \\text{mm}^2 \\). GP possesses then improved accuracy and adaptability for future applications in structural optimization.",
      "authors": [
        "Ricardo Fitas"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Applied Physics (physics.app-ph)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Computational Physics (physics.comp-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T00:01:49+00:00",
          "link": "https://arxiv.org/abs/2507.02208v1",
          "size": "497kb",
          "version": "v1"
        }
      ],
      "title": "Modeling the Effective Elastic Modulus and Thickness of Corrugated Boards Using Gaussian Process Regression and Expected Hypervolume Improvement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02208",
        "HTML": "https://arxiv.org/html/2507.02208v1",
        "PDF": "https://arxiv.org/pdf/2507.02208"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on modeling mechanical properties of corrugated boards using Gaussian Process Regression, which is unrelated to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02215",
      "abstract": "Motivated by the need for efficient estimation of conditional expectations, we consider a least-squares function approximation problem with heavily polluted data. Existing methods that are powerful in the small noise regime are suboptimal when large noise is present. We propose a hybrid approach that combines Christoffel sampling with certain types of optimal experimental design to address this issue. We show that the proposed algorithm enjoys appropriate optimality properties for both sample point generation and noise mollification, leading to improved computational efficiency and sample complexity compared to existing methods. We also extend the algorithm to convex-constrained settings with similar theoretical guarantees. When the target function is defined as the expectation of a random field, we extend our approach to leverage adaptive random subspaces and establish results on the approximation capacity of the adaptive procedure. Our theoretical findings are supported by numerical studies on both synthetic data and on a more challenging stochastic simulation problem in computational finance.",
      "authors": [
        "Ben Adcock",
        "Bernhard Hientzsch",
        "Akil Narayan",
        "Yiming Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T00:31:29+00:00",
          "link": "https://arxiv.org/abs/2507.02215v1",
          "size": "1235kb",
          "version": "v1"
        }
      ],
      "title": "Hybrid least squares for learning functions from highly noisy data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02215",
        "HTML": "https://arxiv.org/html/2507.02215v1",
        "PDF": "https://arxiv.org/pdf/2507.02215"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study presents a method for learning functions from noisy data using hybrid least squares, unrelated to large language model training data processing or enhancement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02248",
      "abstract": "In this paper, we explore the knowledge transfer under the setting of matrix completion, which aims to enhance the estimation of a low-rank target matrix with auxiliary data available. We propose a transfer learning procedure given prior information on which source datasets are favorable. We study its convergence rates and prove its minimax optimality. Our analysis reveals that with the source matrices close enough to the target matrix, out method outperforms the traditional method using the single target data. In particular, we leverage the advanced sharp concentration inequalities introduced in \\cite{brailovskaya2024universality} to eliminate a logarithmic factor in the convergence rate, which is crucial for proving the minimax optimality. When the relevance of source datasets is unknown, we develop an efficient detection procedure to identify informative sources and establish its selection consistency. Simulations and real data analysis are conducted to support the validity of our methodology.",
      "authors": [
        "Dali Liu",
        "Haolei Weng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T02:43:40+00:00",
          "link": "https://arxiv.org/abs/2507.02248v1",
          "size": "348kb",
          "version": "v1"
        }
      ],
      "title": "Transfer Learning for Matrix Completion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02248",
        "HTML": "https://arxiv.org/html/2507.02248v1",
        "PDF": "https://arxiv.org/pdf/2507.02248"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper presents a transfer learning method for matrix completion, which may involve some dataset processing but does not specifically focus on training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02264",
      "abstract": "Delineating how animal behavior arises from neural activity is a foundational goal of neuroscience. However, as the computations underlying behavior unfold in networks of thousands of individual neurons across the entire brain, this presents challenges for investigating neural roles and computational mechanisms in large, densely wired mammalian brains during behavior. Transformers, the backbones of modern large language models (LLMs), have become powerful tools for neural decoding from smaller neural populations. These modern LLMs have benefited from extensive pre-training, and their sequence-to-sequence learning has been shown to generalize to novel tasks and data modalities, which may also confer advantages for neural decoding from larger, brain-wide activity recordings. Here, we present a systematic evaluation of off-the-shelf LLMs to decode behavior from brain-wide populations, termed NLP4Neuro, which we used to test LLMs on simultaneous calcium imaging and behavior recordings in larval zebrafish exposed to visual motion stimuli. Through NLP4Neuro, we found that LLMs become better at neural decoding when they use pre-trained weights learned from textual natural language data. Moreover, we found that a recent mixture-of-experts LLM, DeepSeek Coder-7b, significantly improved behavioral decoding accuracy, predicted tail movements over long timescales, and provided anatomically consistent highly interpretable readouts of neuron salience. NLP4Neuro demonstrates that LLMs are highly capable of informing brain-wide neural circuit dissection.",
      "authors": [
        "Jacob J. Morra",
        "Kaitlyn E. Fouke",
        "Kexin Hang",
        "Zichen He",
        "Owen Traubert",
        "Timothy W. Dunn",
        "Eva A. Naumann"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Neurons and Cognition (q-bio.NC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T03:14:55+00:00",
          "link": "https://arxiv.org/abs/2507.02264v1",
          "size": "7014kb",
          "version": "v1"
        }
      ],
      "title": "NLP4Neuro: Sequence-to-sequence learning for neural population decoding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02264",
        "HTML": "https://arxiv.org/html/2507.02264v1",
        "PDF": "https://arxiv.org/pdf/2507.02264"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper evaluates LLMs for neural decoding, mentioning pre-training on natural language data. It does not contribute new methods for LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02275",
      "abstract": "Structure-agnostic causal inference studies how well one can estimate a treatment effect given black-box machine learning estimates of nuisance functions (like the impact of confounders on treatment and outcomes). Here, we find that the answer depends in a surprising way on the distribution of the treatment noise. Focusing on the partially linear model of \\citet{robinson1988root}, we first show that the widely adopted double machine learning (DML) estimator is minimax rate-optimal for Gaussian treatment noise, resolving an open problem of \\citet{mackey2018orthogonal}. Meanwhile, for independent non-Gaussian treatment noise, we show that DML is always suboptimal by constructing new practical procedures with higher-order robustness to nuisance errors. These \\emph{ACE} procedures use structure-agnostic cumulant estimators to achieve $r$-th order insensitivity to nuisance errors whenever the $(r+1)$-st treatment cumulant is non-zero. We complement these core results with novel minimax guarantees for binary treatments in the partially linear model. Finally, using synthetic demand estimation experiments, we demonstrate the practical benefits of our higher-order robust estimators.",
      "authors": [
        "Jikai Jin and Lester Mackey and Vasilis Syrgkanis"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Econometrics (econ.EM)",
        "Statistics Theory (math.ST)",
        "Methodology (stat.ME)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T03:31:45+00:00",
          "link": "https://arxiv.org/abs/2507.02275v1",
          "size": "1310kb",
          "version": "v1"
        }
      ],
      "title": "It's Hard to Be Normal: The Impact of Noise on Structure-agnostic Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02275",
        "PDF": "https://arxiv.org/pdf/2507.02275"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study focuses on structure-agnostic causal inference and the impact of noise in estimation, which does not pertain to LLM training data engineering or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02287",
      "abstract": "This paper introduces Natural Language Processing for identifying ``true'' green patents from official supporting documents. We start our training on about 12.4 million patents that had been classified as green from previous literature. Thus, we train a simple neural network to enlarge a baseline dictionary through vector representations of expressions related to environmental technologies. After testing, we find that ``true'' green patents represent about 20\\% of the total of patents classified as green from previous literature. We show heterogeneity by technological classes, and then check that `true' green patents are about 1\\% less cited by following inventions. In the second part of the paper, we test the relationship between patenting and a dashboard of firm-level financial accounts in the European Union. After controlling for reverse causality, we show that holding at least one ``true'' green patent raises sales, market shares, and productivity. If we restrict the analysis to high-novelty ``true'' green patents, we find that they also yield higher profits. Our findings underscore the importance of using text analyses to gauge finer-grained patent classifications that are useful for policymaking in different domains.",
      "authors": [
        "Lapo Santarlasci",
        "Armando Rungi",
        "Antonio Zinilli"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "General Economics (econ.GN)",
        "Computation and Language (cs.CL)",
        "Economics (q-fin.EC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T03:51:33+00:00",
          "link": "https://arxiv.org/abs/2507.02287v1",
          "size": "225kb",
          "version": "v1"
        }
      ],
      "title": "Seeing Through Green: Text-Based Classification and the Firm's Returns from Green Patents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02287",
        "HTML": "https://arxiv.org/html/2507.02287v1",
        "PDF": "https://arxiv.org/pdf/2507.02287"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses using NLP to identify green patents, focusing on patent classification and its financial implications, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02289",
      "abstract": "Myocardial infarction (MI) is a leading cause of death worldwide. Late gadolinium enhancement (LGE) and T2-weighted cardiac magnetic resonance (CMR) imaging can respectively identify scarring and edema areas, both of which are essential for MI risk stratification and prognosis assessment. Although combining complementary information from multi-sequence CMR is useful, acquiring these sequences can be time-consuming and prohibitive, e.g., due to the administration of contrast agents. Cine CMR is a rapid and contrast-free imaging technique that can visualize both motion and structural abnormalities of the myocardium induced by acute MI. Therefore, we present a new end-to-end deep neural network, referred to as CineMyoPS, to segment myocardial pathologies, \\ie scars and edema, solely from cine CMR images. Specifically, CineMyoPS extracts both motion and anatomy features associated with MI. Given the interdependence between these features, we design a consistency loss (resembling the co-training strategy) to facilitate their joint learning. Furthermore, we propose a time-series aggregation strategy to integrate MI-related features across the cardiac cycle, thereby enhancing segmentation accuracy for myocardial pathologies. Experimental results on a multi-center dataset demonstrate that CineMyoPS achieves promising performance in myocardial pathology segmentation, motion estimation, and anatomy segmentation.",
      "authors": [
        "Wangbin Ding",
        "Lei Li",
        "Junyi Qiu",
        "Bogen Lin",
        "Mingjing Yang",
        "Liqin Huang",
        "Lianming Wu",
        "Sihan Wang",
        "Xiahai Zhuang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T03:52:59+00:00",
          "link": "https://arxiv.org/abs/2507.02289v1",
          "size": "1425kb",
          "version": "v1"
        }
      ],
      "title": "CineMyoPS: Segmenting Myocardial Pathologies from Cine Cardiac MR",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02289",
        "HTML": "https://arxiv.org/html/2507.02289v1",
        "PDF": "https://arxiv.org/pdf/2507.02289"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a deep neural network for myocardial pathology segmentation using cine cardiac MR images, without addressing LLM training data or related data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02345",
      "abstract": "Antibody engineering is essential for developing therapeutics and advancing biomedical research. Traditional discovery methods often rely on time-consuming and resource-intensive experimental screening. To enhance and streamline this process, we introduce a production-grade, high-throughput platform built on HelixFold3, HelixDesign-Antibody, which utilizes the high-accuracy structure prediction model, HelixFold3. The platform facilitates the large-scale generation of antibody candidate sequences and evaluates their interaction with antigens. Integrated high-performance computing (HPC) support enables high-throughput screening, addressing challenges such as fragmented toolchains and high computational demands. Validation on multiple antigens showcases the platform's ability to generate diverse and high-quality antibodies, confirming a scaling law where exploring larger sequence spaces increases the likelihood of identifying optimal binders. This platform provides a seamless, accessible solution for large-scale antibody design and is available via the antibody design page of PaddleHelix platform.",
      "authors": [
        "Jie Gao",
        "Jing Hu",
        "Shanzhuo Zhang",
        "Kunrui Zhu",
        "Sheng Qian",
        "Yueyang Huang",
        "Xiaonan Zhang",
        "Xiaomin Fang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Biomolecules (q-bio.BM)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T06:13:23+00:00",
          "link": "https://arxiv.org/abs/2507.02345v1",
          "size": "15537kb",
          "version": "v1"
        }
      ],
      "title": "HelixDesign-Antibody: A Scalable Production-Grade Platform for Antibody Design Built on HelixFold3",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02345",
        "HTML": "https://arxiv.org/html/2507.02345v1",
        "PDF": "https://arxiv.org/pdf/2507.02345"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses an antibody design platform using high-throughput screening, which is unrelated to LLM training data processing or any data engineering related to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02348",
      "abstract": "Pinching-antenna systems (PASS) have been recently proposed to improve the performance of wireless networks by reconfiguring both the large-scale and small-scale channel conditions. However, existing studies ignore the physical constraints of antenna placement and assume fixed antenna radiation power. To fill this research gap, this paper investigates the design of PASS taking into account the motion power consumption of pinching-antennas (PAs) and the impact of adjustable antenna radiation power. To that end, we minimize the average power consumption for a given quality-of-service (QoS) requirement, by jointly optimizing the antenna positions, antenna radiation power ratios, and transmit beamforming. To the best of the authors' knowledge, this is the first work to consider radiation power optimization in PASS, which provides an additional degree of freedom (DoF) for system design. The cases with both continuous and discrete antenna placement are considered, where the main challenge lies in the fact that the antenna positions affect both the magnitude and phase of the channel coefficients of PASS, making system optimization very challenging. To tackle the resulting unique obstacles, an alternating direction method of multipliers (ADMM)-based framework is proposed to solve the problem for continuous antenna movement, while its discrete counterpart is formulated as a mixed integer nonlinear programming (MINLP) problem and solved by the block coordinate descent (BCD) method. Simulation results validate the performance enhancement achieved by incorporating PA movement power assumption and adjustable radiation power into PASS design, while also demonstrating the efficiency of the proposed optimization framework. The benefits of PASS over conventional multiple-input multiple-output (MIMO) systems in mitigating the large-scale path loss and inter-user interference is also revealed.",
      "authors": [
        "Yiming Xu",
        "Dongfang Xu",
        "Xianghao Yu",
        "Shenghui Song",
        "Zhiguo Ding",
        "and Robert Schober"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T06:23:17+00:00",
          "link": "https://arxiv.org/abs/2507.02348v1",
          "size": "201kb",
          "version": "v1"
        }
      ],
      "title": "Joint Radiation Power, Antenna Position, and Beamforming Optimization for Pinching-Antenna Systems with Motion Power Consumption",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02348",
        "HTML": "https://arxiv.org/html/2507.02348v1",
        "PDF": "https://arxiv.org/pdf/2507.02348"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study is about optimizing power and antenna configurations in wireless networks, not related to any aspect of LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02367",
      "abstract": "Dynamic positron emission tomography (PET) and kinetic modeling are pivotal in advancing tracer development research in small animal studies. Accurate kinetic modeling requires precise input function estimation, traditionally achieved via arterial blood sampling. However, arterial cannulation in small animals like mice, involves intricate, time-consuming, and terminal procedures, precluding longitudinal studies. This work proposes a non-invasive, fully convolutional deep learning-based approach (FC-DLIF) to predict input functions directly from PET imaging, potentially eliminating the need for blood sampling in dynamic small-animal PET. The proposed FC-DLIF model includes a spatial feature extractor acting on the volumetric time frames of the PET sequence, extracting spatial features. These are subsequently further processed in a temporal feature extractor that predicts the arterial input function. The proposed approach is trained and evaluated using images and arterial blood curves from [$^{18}$F]FDG data using cross validation. Further, the model applicability is evaluated on imaging data and arterial blood curves collected using two additional radiotracers ([$^{18}$F]FDOPA, and [$^{68}$Ga]PSMA). The model was further evaluated on data truncated and shifted in time, to simulate shorter, and shifted, PET scans. The proposed FC-DLIF model reliably predicts the arterial input function with respect to mean squared error and correlation. Furthermore, the FC-DLIF model is able to predict the arterial input function even from truncated and shifted samples. The model fails to predict the AIF from samples collected using different radiotracers, as these are not represented in the training data. Our deep learning-based input function offers a non-invasive and reliable alternative to arterial blood sampling, proving robust and flexible to temporal shifts and different scan durations.",
      "authors": [
        "Christian Salomonsen",
        "Luigi Tommaso Luppino",
        "Fredrik Aspheim",
        "Kristoffer Wickstr{\\o}m",
        "Elisabeth Wetzer",
        "Michael Kampffmeyer",
        "Rodrigo Berzaghi",
        "Rune Sundset",
        "Robert Jenssen",
        "Samuel Kuttner"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Medical Physics (physics.med-ph)",
        "Quantitative Methods (q-bio.QM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T06:55:41+00:00",
          "link": "https://arxiv.org/abs/2507.02367v1",
          "size": "6294kb",
          "version": "v1"
        }
      ],
      "title": "A robust and versatile deep learning model for prediction of the arterial input function in dynamic small animal $\\left[^{18}\\text{F}\\right]$FDG PET imaging",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02367",
        "HTML": "https://arxiv.org/html/2507.02367v1",
        "PDF": "https://arxiv.org/pdf/2507.02367"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a deep learning model for predicting the arterial input function in small-animal PET imaging, which is not related to LLM training data processing but rather focuses on medical imaging applications."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02377",
      "abstract": "Inducing-point-based sparse variational Gaussian processes have become the standard workhorse for scaling up GP models. Recent advances show that these methods can be improved by introducing a diagonal scaling matrix to the conditional posterior density given the inducing points. This paper first considers an extension that employs a block-diagonal structure for the scaling matrix, provably tightening the variational lower bound. We then revisit the unifying framework of sparse GPs based on Power Expectation Propagation (PEP) and show that it can leverage and benefit from the new structured approximate posteriors. Through extensive regression experiments, we show that the proposed block-diagonal approximation consistently performs similarly to or better than existing diagonal approximations while maintaining comparable computational costs. Furthermore, the new PEP framework with structured posteriors provides competitive performance across various power hyperparameter settings, offering practitioners flexible alternatives to standard variational approaches.",
      "authors": [
        "Thang D. Bui and Michalis K. Titsias"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T07:18:54+00:00",
          "link": "https://arxiv.org/abs/2507.02377v1",
          "size": "281kb",
          "version": "v1"
        }
      ],
      "title": "Sparse Gaussian Processes: Structured Approximations and Power-EP Revisited",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02377",
        "HTML": "https://arxiv.org/html/2507.02377v1",
        "PDF": "https://arxiv.org/pdf/2507.02377"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study is about improving Gaussian Processes' efficiency and performance, with no connection to the processing or construction of data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02411",
      "abstract": "Echocardiography (echo) plays an indispensable role in the clinical practice of heart diseases. However, ultrasound imaging typically provides only two-dimensional (2D) cross-sectional images from a few specific views, making it challenging to interpret and inaccurate for estimation of clinical parameters like the volume of left ventricle (LV). 3D ultrasound imaging provides an alternative for 3D quantification, but is still limited by the low spatial and temporal resolution and the highly demanding manual delineation.\n  To address these challenges, we propose an innovative framework for reconstructing personalized 3D heart anatomy from 2D echo slices that are frequently used in clinical practice. Specifically, a novel 3D reconstruction pipeline is designed, which alternatively optimizes between the 3D pose estimation of these 2D slices and the 3D integration of these slices using an implicit neural network, progressively transforming a prior 3D heart shape into a personalized 3D heart model.\n  We validate the method with two datasets. When six planes are used, the reconstructed 3D heart can lead to a significant improvement for LV volume estimation over the bi-plane method (error in percent: 1.98\\% VS. 20.24\\%). In addition, the whole reconstruction framework makes even an important breakthrough that can estimate RV volume from 2D echo slices (with an error of 5.75\\% ). This study provides a new way for personalized 3D structure and function analysis from cardiac ultrasound and is of great potential in clinical practice.",
      "authors": [
        "Zhurong Chen and Jinhua Chen and Wei Zhuo and Wufeng Xue and Dong Ni"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T08:13:07+00:00",
          "link": "https://arxiv.org/abs/2507.02411v1",
          "size": "360kb",
          "version": "v1"
        }
      ],
      "title": "3D Heart Reconstruction from Sparse Pose-agnostic 2D Echocardiographic Slices",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02411",
        "HTML": "https://arxiv.org/html/2507.02411v1",
        "PDF": "https://arxiv.org/pdf/2507.02411"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a method for reconstructing 3D heart anatomy from 2D echocardiographic slices. There is no mention of LLMs or related data processing tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02412",
      "abstract": "Green ammonia is emerging as a strategic intermediary within green energy supply chains, serving effectively as both an industrial commodity and hydrogen carrier. This study provides a techno-economic analysis of green ammonia supply chains, comparing cost-effective pathways from global production to European consumers, and evaluates ammonia alongside alternative hydrogen carriers. Gaseous hydrogen consistently remains the most economical import option for Europe, though ammonia holds a narrowing cost advantage over liquid hydrogen (from 16 % in 2030 to 10 % by 2040). Competitive ammonia suppliers, notably Morocco, the United States, and the United Arab Emirates, benefit from low renewable energy costs, with significant price reductions expected by 2040, driven by falling costs for electricity, electrolysers, and conversion technologies. Optimal transport modes vary by consumer demand and distance: trucks are ideal for low demands at all distances, rail for medium ranges, and pipelines for high-demand scenarios. By 2040, ammonia will primarily serve direct-use applications, as hydrogen consumers increasingly shift to direct hydrogen supplies. Policymakers should prioritize pipeline infrastructure for hydrogen distribution, cautiously invest in ammonia's short- to medium-term infrastructure advantages, and limit long-term reliance on ammonia as a hydrogen carrier to mitigate stranded asset risks.",
      "authors": [
        "Lucien Genge",
        "Felix M\\\"usgens"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "General Economics (econ.GN)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)",
        "Economics (q-fin.EC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T08:14:20+00:00",
          "link": "https://arxiv.org/abs/2507.02412v1",
          "size": "2359kb",
          "version": "v1"
        }
      ],
      "title": "Green Ammonia: A Techno-Economic Supply Chain Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02412",
        "PDF": "https://arxiv.org/pdf/2507.02412"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study provides a techno-economic analysis of green ammonia supply chains, which is unrelated to training data processing for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02436",
      "abstract": "Advances in material functionalities drive innovations across various fields, where metamaterials-defined by structure rather than composition-are leading the way. Despite the rise of artificial intelligence (AI)-driven design strategies, their impact is limited by task-specific retraining, poor out-of-distribution(OOD) generalization, and the need for separate models for forward and inverse design. To address these limitations, we introduce the Metamaterial Foundation Model (MetaFO), a Bayesian transformer-based foundation model inspired by large language models. MetaFO learns the underlying mechanics of metamaterials, enabling probabilistic, zero-shot predictions across diverse, unseen combinations of material properties and structural responses. It also excels in nonlinear inverse design, even under OOD conditions. By treating metamaterials as an operator that maps material properties to structural responses, MetaFO uncovers intricate structure-property relationships and significantly expands the design space. This scalable and generalizable framework marks a paradigm shift in AI-driven metamaterial discovery, paving the way for next-generation innovations.",
      "authors": [
        "Namjung Kim",
        "Dongseok Lee",
        "Jongbin Yu",
        "Sung Woong Cho",
        "Dosung Lee",
        "Yesol Park",
        "Youngjoon Hong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Optics (physics.optics)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T08:48:36+00:00",
          "link": "https://arxiv.org/abs/2507.02436v1",
          "size": "3961kb",
          "version": "v1"
        }
      ],
      "title": "Toward a Robust and Generalizable Metamaterial Foundation Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02436",
        "PDF": "https://arxiv.org/pdf/2507.02436"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a Metamaterial Foundation Model for material design, focusing on AI applications in metamaterials. It does not relate to LLM training data processing or LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02523",
      "abstract": "Source detection is crucial for capturing the dynamics of real-world infectious diseases and informing effective containment strategies. Most existing approaches to source detection focus on conventional pairwise networks, whereas recent efforts on both mathematical modeling and analysis of contact data suggest that higher-order (e.g., group) interactions among individuals may both account for a large fraction of infection events and change our understanding of how epidemic spreading proceeds in empirical populations. In the present study, we propose a message-passing algorithm, called the HDMPN, for source detection for a stochastic susceptible-infectious dynamics on hypergraphs. By modulating the likelihood maximization method by the fraction of infectious neighbors, HDMPN aims to capture the influence of higher-order structures and do better than the conventional likelihood maximization. We numerically show that, in most cases, HDMPN outperforms benchmarks including the likelihood maximization method without modification.",
      "authors": [
        "Qiao Ke",
        "Naoki Masuda",
        "Zhen Jin",
        "Chuang Liu",
        "Xiu-Xiu Zhan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Physics and Society (physics.soc-ph)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T10:42:18+00:00",
          "link": "https://arxiv.org/abs/2507.02523v1",
          "size": "10261kb",
          "version": "v1"
        }
      ],
      "title": "Source Detection in Hypergraph Epidemic Dynamics using a Higher-Order Dynamic Message Passing Algorithm",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02523",
        "HTML": "https://arxiv.org/html/2507.02523v1",
        "PDF": "https://arxiv.org/pdf/2507.02523"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates source detection in epidemic dynamics via a hypergraph approach, focusing on infectious disease modeling rather than LLM data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02562",
      "abstract": "Current deep neural network (DNN) based speech separation faces a fundamental challenge -- while the models need to be trained on short segments due to computational constraints, real-world applications typically require processing significantly longer recordings with multiple utterances per speaker than seen during training. In this paper, we investigate how existing approaches perform in this challenging scenario and propose a frequency-temporal recurrent neural network (FTRNN) that effectively bridges this gap. Our FTRNN employs a full-band module to model frequency dependencies within each time frame and a sub-band module that models temporal patterns in each frequency band. Despite being trained on short fixed-length segments of 10 s, our model demonstrates robust separation when processing signals significantly longer than training segments (21-121 s) and preserves speaker association across utterance gaps exceeding those seen during training. Unlike the conventional segment-separation-stitch paradigm, our lightweight approach (0.9 M parameters) performs inference on long audio without segmentation, eliminating segment boundary distortions while simplifying deployment. Experimental results demonstrate the generalization ability of FTRNN for multi-utterance speech separation and speaker association.",
      "authors": [
        "Yuzhu Wang",
        "Archontis Politis",
        "Konstantinos Drossos",
        "Tuomas Virtanen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T12:12:34+00:00",
          "link": "https://arxiv.org/abs/2507.02562v1",
          "size": "19131kb",
          "version": "v1"
        }
      ],
      "title": "Multi-Utterance Speech Separation and Association Trained on Short Segments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02562",
        "HTML": "https://arxiv.org/html/2507.02562v1",
        "PDF": "https://arxiv.org/pdf/2507.02562"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates speech separation methods with neural networks and doesn't contribute to LLM training data processing or methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02575",
      "abstract": "We present a unified framework for embedding and analyzing dynamical systems using generalized projection operators rooted in local conservation laws. By representing physical, biological, and engineered systems as graphs with incidence and cycle matrices, we derive dual projection operators that decompose network fluxes and potentials. This formalism aligns with principles of non-equilibrium thermodynamics and captures a broad class of systems governed by flux-forcing relationships and local constraints. We extend this approach to collective dynamics through the PRojective Embedding of Dynamical Systems (PrEDS), which lifts low-dimensional dynamics into a high-dimensional space, enabling both replication and recovery of the original dynamics. When systems fall within the PrEDS class, their collective behavior can be effectively approximated through projection onto a mean-field space. We demonstrate the versatility of PrEDS across diverse domains, including resistive and memristive circuits, adaptive flow networks (e.g., slime molds), elastic string networks, and particle swarms. Notably, we establish a direct correspondence between PrEDS and swarm dynamics, revealing new insights into optimization and self-organization. Our results offer a general theoretical foundation for analyzing complex networked systems and for designing systems that self-organize through local interactions.",
      "authors": [
        "Frank Barrows and Guanming Zhang and Satyam Anand and Zizi Chen and Jonathan Lin and Amman Desai and Stefano Martiniani and Francesco Caravelli"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Soft Condensed Matter (cond-mat.soft)",
        "Statistical Mechanics (cond-mat.stat-mech)",
        "Multiagent Systems (cs.MA)",
        "Adaptation and Self-Organizing Systems (nlin.AO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T12:31:18+00:00",
          "link": "https://arxiv.org/abs/2507.02575v1",
          "size": "11502kb",
          "version": "v1"
        }
      ],
      "title": "A unifying approach to self-organizing systems interacting via conservation laws",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02575",
        "HTML": "https://arxiv.org/html/2507.02575v1",
        "PDF": "https://arxiv.org/pdf/2507.02575"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a framework for dynamical systems using projection operators but does not address any aspects of LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02622",
      "abstract": "Access control is a cornerstone of computer security that prevents unauthorised access to resources. In this paper, we study access control in quantum computer systems. We present the first explicit scenario of a security breach when a classically secure access control system is straightforwardly adapted to the quantum setting. The breach is ultimately due to that quantum mechanics allows the phenomenon of entanglement and violates Mermin inequality, a multi-party variant of the celebrated Bell inequality. This reveals a threat from quantum entanglement to access control if existing computer systems integrate with quantum computing. To protect against such threat, we propose several new models of quantum access control, and rigorously analyse their security, flexibility and efficiency.",
      "authors": [
        "Zhicheng Zhang and Mingsheng Ying"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Cryptography and Security (cs.CR)",
        "Operating Systems (cs.OS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T13:48:14+00:00",
          "link": "https://arxiv.org/abs/2507.02622v1",
          "size": "456kb",
          "version": "v1"
        }
      ],
      "title": "Access Control Threatened by Quantum Entanglement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02622",
        "HTML": "https://arxiv.org/html/2507.02622v1",
        "PDF": "https://arxiv.org/pdf/2507.02622"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on access control in quantum computer systems, rather than training data processing for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02636",
      "abstract": "This paper proposes a novel non-anticipatory long-short-term coordinated dispatch framework for isolated microgrid with hybrid short-long-duration energy storages (LDES). We introduce a convex hull approximation model for nonconvex LDES electrochemical dynamics, facilitating computational tractability and accuracy. To address temporal coupling in SoC dynamics and long-term contracts, we generate hindsight-optimal state-of-charge (SoC) trajectories of LDES and netloads for offline training. In the online stage, we employ kernel regression to dynamically update the SoC reference and propose an adaptive online convex optimization (OCO) algorithm with SoC reference tracking and expert tracking to mitigate myopia and enable adaptive step-size optimization. We rigorously prove that both long-term and short-term policies achieve sublinear regret bounds over time, which improves with more regression scenarios, stronger tracking penalties, and finer convex approximations. Simulation results show that the proposed method outperforms state-of-the-art methods, reducing costs by 73.4%, eliminating load loss via reference tracking, and achieving an additional 2.4% cost saving via the OCO algorithm. These benefits scale up with longer LDES durations, and the method demonstrates resilience to poor forecasts and unexpected system faults.",
      "authors": [
        "Ning Qi",
        "Yousuf Baker",
        "Bolun Xu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T14:01:59+00:00",
          "link": "https://arxiv.org/abs/2507.02636v1",
          "size": "1494kb",
          "version": "v1"
        }
      ],
      "title": "Online Convex Optimization for Coordinated Long-Term and Short-Term Isolated Microgrid Dispatch",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02636",
        "HTML": "https://arxiv.org/html/2507.02636v1",
        "PDF": "https://arxiv.org/pdf/2507.02636"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses an optimization framework for microgrid dispatch with energy storages, which is unrelated to LLM training data engineering or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02644",
      "abstract": "The rapid development of neural quantum states (NQS) has established it as a promising framework for studying quantum many-body systems. In this work, by leveraging the cutting-edge transformer-based architectures and developing highly efficient optimization algorithms, we achieve the state-of-the-art results for the doped two-dimensional (2D) Hubbard model, arguably the minimum model for high-Tc superconductivity. Interestingly, we find different attention heads in the NQS ansatz can directly encode correlations at different scales, making it capable of capturing long-range correlations and entanglements in strongly correlated systems. With these advances, we establish the half-filled stripe in the ground state of 2D Hubbard model with the next nearest neighboring hoppings, consistent with experimental observations in cuprates. Our work establishes NQS as a powerful tool for solving challenging many-fermions systems.",
      "authors": [
        "Yuntian Gu",
        "Wenrui Li",
        "Heng Lin",
        "Bo Zhan",
        "Ruichen Li",
        "Yifei Huang",
        "Di He",
        "Yantao Wu",
        "Tao Xiang",
        "Mingpu Qin",
        "Liwei Wang",
        "Dingshun Lv"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Strongly Correlated Electrons (cond-mat.str-el)",
        "Artificial Intelligence (cs.AI)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T14:08:25+00:00",
          "link": "https://arxiv.org/abs/2507.02644v1",
          "size": "2881kb",
          "version": "v1"
        }
      ],
      "title": "Solving the Hubbard model with Neural Quantum States",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02644",
        "HTML": "https://arxiv.org/html/2507.02644v1",
        "PDF": "https://arxiv.org/pdf/2507.02644"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work explores the use of neural quantum states for solving the Hubbard model in quantum systems, unrelated to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02668",
      "abstract": "Colorectal polyp segmentation is critical for early detection of colorectal cancer, yet weak and low contrast boundaries significantly limit automated accuracy. Existing deep models either blur fine edge details or rely on handcrafted filters that perform poorly under variable imaging conditions. We propose MEGANet-W, a Wavelet Driven Edge Guided Attention Network that injects directional, parameter free Haar wavelet edge maps into each decoder stage to recalibrate semantic features. Our two main contributions are: (1) a two-level Haar wavelet head for multi orientation edge extraction; and (2) Wavelet Edge Guided Attention (WEGA) modules that fuse wavelet cues with reverse and input branches. On five public polyp datasets, MEGANetW consistently outperforms existing methods, improving mIoU by up to 2.3% and mDice by 1.2%, while introducing no additional learnable parameters.",
      "authors": [
        "Zhe Yee Tan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T14:31:28+00:00",
          "link": "https://arxiv.org/abs/2507.02668v1",
          "size": "3551kb",
          "version": "v1"
        }
      ],
      "title": "MEGANet-W: A Wavelet-Driven Edge-Guided Attention Framework for Weak Boundary Polyp Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02668",
        "HTML": "https://arxiv.org/html/2507.02668v1",
        "PDF": "https://arxiv.org/pdf/2507.02668"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on a neural network for polyp detection and does not engage with the training data processing specific to large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02752",
      "abstract": "The disconnect between AI-generated molecules with desirable properties and their synthetic feasibility remains a critical bottleneck in computational drug and material discovery. While generative AI has accelerated the proposal of candidate molecules, many of these structures prove challenging or impossible to synthesize using established chemical reactions. Here, we introduce SynTwins, a novel retrosynthesis-guided molecular analog design framework that designs synthetically accessible molecular analogs by emulating expert chemist strategies through a three-step process: retrosynthesis, similar building block searching, and virtual synthesis. In comparative evaluations, SynTwins demonstrates superior performance in generating synthetically accessible analogs compared to state-of-the-art machine learning models while maintaining high structural similarity to original target molecules. Furthermore, when integrated with existing molecule optimization frameworks, our hybrid approach produces synthetically feasible molecules with property profiles comparable to unconstrained molecule generators, yet its synthesizability ensured. Our comprehensive benchmarking across diverse molecular datasets demonstrates that SynTwins effectively bridges the gap between computational design and experimental synthesis, providing a practical solution for accelerating the discovery of synthesizable molecules with desired properties for a wide range of applications.",
      "authors": [
        "Shuan Chen",
        "Gunwook Nam",
        "Yousung Jung"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Chemical Physics (physics.chem-ph)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T16:14:57+00:00",
          "link": "https://arxiv.org/abs/2507.02752v1",
          "size": "1053kb",
          "version": "v1"
        }
      ],
      "title": "Synthesizable by Design: A Retrosynthesis-Guided Framework for Molecular Analog Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02752",
        "PDF": "https://arxiv.org/pdf/2507.02752"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a framework for molecular analog generation and retrosynthesis, which does not pertain to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02755",
      "abstract": "Auditory scene analysis (ASA) aims to retrieve information from the acoustic environment, by carrying out three main tasks: sound source location, separation, and classification. These tasks are traditionally executed with a linear data flow, where the sound sources are first located; then, using their location, each source is separated into its own audio stream; from each of which, information is extracted that is relevant to the application scenario (audio event detection, speaker identification, emotion classification, etc.). However, running these tasks linearly increases the overall response time, while making the last tasks (separation and classification) highly sensitive to errors of the first task (location). A considerable amount of effort and computational complexity has been employed in the state-of-the-art to develop techniques that are the least error-prone possible. However, doing so gives rise to an ASA system that is non-viable in many applications that require a small computational footprint and a low response time, such as bioacoustics, hearing-aid design, search and rescue, human-robot interaction, etc. To this effect, in this work, a multi-agent approach is proposed to carry out ASA where the tasks are run in parallel, with feedback loops between them to compensate for local errors, such as: using the quality of the separation output to correct the location error; and using the classification result to reduce the localization's sensitivity towards interferences. The result is a multi-agent auditory scene analysis (MASA) system that is robust against local errors, without a considerable increase in complexity, and with a low response time. The complete proposed MASA system is provided as a framework that uses open-source tools for sound acquisition and reproduction (JACK) and inter-agent communication (ROS2), allowing users to add their own agents.",
      "authors": [
        "Caleb Rascon",
        "Luis Gato-Diaz",
        "Eduardo Garc\\'ia-Alarc\\'on"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T16:16:46+00:00",
          "link": "https://arxiv.org/abs/2507.02755v1",
          "size": "737kb",
          "version": "v1"
        }
      ],
      "title": "Multi-agent Auditory Scene Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02755",
        "HTML": "https://arxiv.org/html/2507.02755v1",
        "PDF": "https://arxiv.org/pdf/2507.02755"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on auditory scene analysis and the development of a multi-agent system for sound processing, which is unrelated to the processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02759",
      "abstract": "We prove an easy but very weak version of Chernoff inequality. Namely, that the probability that in $6M$ throws of a fair coin, one gets at most $M$ heads is $\\leq 1/2^M$.",
      "authors": [
        "Sariel Har-Peled"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Probability (math.PR)",
        "Data Structures and Algorithms (cs.DS)",
        "Combinatorics (math.CO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T16:21:00+00:00",
          "link": "https://arxiv.org/abs/2507.02759v1",
          "size": "136kb",
          "version": "v1"
        }
      ],
      "title": "An Easy Proof of a Weak Version of Chernoff inequality",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02759",
        "HTML": "https://arxiv.org/html/2507.02759v1",
        "PDF": "https://arxiv.org/pdf/2507.02759"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper provides a mathematical proof related to Chernoff inequality, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02768",
      "abstract": "We introduce DeSTA2.5-Audio, a general-purpose Large Audio Language Model (LALM) designed for robust auditory perception and instruction-following, without requiring task-specific audio instruction-tuning. Recent LALMs typically augment Large Language Models (LLMs) with auditory capabilities by training on large-scale, manually curated or LLM-synthesized audio-instruction datasets. However, these approaches have often suffered from the catastrophic forgetting of the LLM's original language abilities. To address this, we revisit the data construction pipeline and propose DeSTA, a self-generated cross-modal alignment strategy in which the backbone LLM generates its own training targets. This approach preserves the LLM's native language proficiency while establishing effective audio-text alignment, thereby enabling zero-shot generalization without task-specific tuning. Using DeSTA, we construct DeSTA-AQA5M, a large-scale, task-agnostic dataset containing 5 million training samples derived from 7,000 hours of audio spanning 50 diverse datasets, including speech, environmental sounds, and music. DeSTA2.5-Audio achieves state-of-the-art or competitive performance across a wide range of audio-language benchmarks, including Dynamic-SUPERB, MMAU, SAKURA, Speech-IFEval, and VoiceBench. Comprehensive comparative studies demonstrate that our self-generated strategy outperforms widely adopted data construction and training strategies in both auditory perception and instruction-following capabilities. Our findings underscore the importance of carefully designed data construction in LALM development and offer practical insights for building robust, general-purpose LALMs.",
      "authors": [
        "Ke-Han Lu",
        "Zhehuai Chen",
        "Szu-Wei Fu",
        "Chao-Han Huck Yang",
        "Sung-Feng Huang",
        "Chih-Kai Yang",
        "Chee-En Yu",
        "Chun-Wei Chen",
        "Wei-Chih Chen",
        "Chien-yu Huang",
        "Yi-Cheng Lin",
        "Yu-Xiang Lin",
        "Chi-An Fu",
        "Chun-Yi Kuan",
        "Wenze Ren",
        "Xuanjun Chen",
        "Wei-Ping Huang",
        "En-Pei Hu",
        "Tzu-Quan Lin",
        "Yuan-Kuei Wu",
        "Kuan-Po Huang",
        "Hsiao-Ying Huang",
        "Huang-Cheng Chou",
        "Kai-Wei Chang",
        "Cheng-Han Chiang",
        "Boris Ginsburg",
        "Yu-Chiang Frank Wang",
        "Hung-yi Lee"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Computation and Language (cs.CL)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T16:28:25+00:00",
          "link": "https://arxiv.org/abs/2507.02768v1",
          "size": "615kb",
          "version": "v1"
        }
      ],
      "title": "DeSTA2.5-Audio: Toward General-Purpose Large Audio Language Model with Self-Generated Cross-Modal Alignment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02768",
        "HTML": "https://arxiv.org/html/2507.02768v1",
        "PDF": "https://arxiv.org/pdf/2507.02768"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper's main contribution involves revisiting the data construction pipeline for a Large Audio Language Model and proposing a self-generated cross-modal alignment strategy, which directly relates to LLM training data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02769",
      "abstract": "The Local Structure Theorem (LST) for graph minors roughly states that every $H$-minor free graph $G$ that contains a sufficiently large wall $W$, there is a set of few vertices $A$ such that, upon removing $A$, the resulting graph $G':=G - A$ admits an \"almost embedding\" $\\delta$ into a surface $\\Sigma$ in which $H$ does not embed. By almost embedding, we mean that there exists a hypergraph $\\mathcal{H}$ whose vertex set is a subset of the vertex set of $G$ and an embedding of $\\mathcal{H}$ in $\\Sigma$ such that 1) the drawing of each hyperedge of $\\mathcal{H}$ corresponds to a cell of $\\delta$, 2) the boundary of each cell intersects only the vertices of the corresponding hyperedge, and 3) all remaining vertices and edges of $G'$ are drawn in the interior of cells. The cells corresponding to hyperedges of arity at least $4$, called vortices, are few in number and have small \"depth\", while a \"large\" part of the wall $W$ is drawn outside the vortices and is \"grounded\" in the embedding $\\delta$. Now suppose that the subgraphs drawn inside each of the non-vortex cells are equipped with some finite index, i.e., each such cell is assigned a color from a finite set. We prove a version of the LST in which the set $C$ of colors assigned to the non-vortex cells exhibits \"large\" bidimensionality: The graph $G'$ contains a minor model of a large grid $\\Gamma$ where each bag corresponding to a vertex $v$ of $\\Gamma$, contains the subgraph drawn within a cell carrying color $\\alpha$, for every color $\\alpha \\in C$. Moreover, the grid $\\Gamma$ can be chosen in a way that is \"well-connected\" to the original wall $W$.",
      "authors": [
        "Christophe Paul",
        "Evangelos Protopapas",
        "Dimitrios M. Thilikos",
        "Sebastian Wiederrecht"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T16:29:14+00:00",
          "link": "https://arxiv.org/abs/2507.02769v1",
          "size": "450kb",
          "version": "v1"
        }
      ],
      "title": "The Local Structure Theorem for Graph Minors with Finite Index",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02769",
        "HTML": "https://arxiv.org/html/2507.02769v1",
        "PDF": "https://arxiv.org/pdf/2507.02769"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a structure theorem for graph minors, focusing on embedding and minor models in graphs, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02791",
      "abstract": "Recent works on deep non-linear spatially selective filters demonstrate exceptional enhancement performance with computationally lightweight architectures for stationary speakers of known directions. However, to maintain this performance in dynamic scenarios, resource-intensive data-driven tracking algorithms become necessary to provide precise spatial guidance conditioned on the initial direction of a target speaker. As this additional computational overhead hinders application in resource-constrained scenarios such as real-time speech enhancement, we present a novel strategy utilizing a low-complexity tracking algorithm in the form of a particle filter instead. Assuming a causal, sequential processing style, we introduce temporal feedback to leverage the enhanced speech signal of the spatially selective filter to compensate for the limited modeling capabilities of the particle filter. Evaluation on a synthetic dataset illustrates how the autoregressive interplay between both algorithms drastically improves tracking accuracy and leads to strong enhancement performance. A listening test with real-world recordings complements these findings by indicating a clear trend towards our proposed self-steering pipeline as preferred choice over comparable methods.",
      "authors": [
        "Jakob Kienegger",
        "Alina Mannanova",
        "Huajian Fang",
        "Timo Gerkmann"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Machine Learning (cs.LG)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T16:54:56+00:00",
          "link": "https://arxiv.org/abs/2507.02791v1",
          "size": "13780kb",
          "version": "v1"
        }
      ],
      "title": "Self-Steering Deep Non-Linear Spatially Selective Filters for Efficient Extraction of Moving Speakers under Weak Guidance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02791",
        "HTML": "https://arxiv.org/html/2507.02791v1",
        "PDF": "https://arxiv.org/pdf/2507.02791"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a speech enhancement method involving a low-complexity tracking algorithm, not addressing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02815",
      "abstract": "Personalized head-related transfer functions (HRTFs) are essential for ensuring a realistic auditory experience over headphones, because they take into account individual anatomical differences that affect listening. Most machine learning approaches to HRTF personalization rely on a learned low-dimensional latent space to generate or select custom HRTFs for a listener. However, these latent representations are typically learned in a manner that optimizes for spectral reconstruction but not for perceptual compatibility, meaning they may not necessarily align with perceptual distance. In this work, we first study whether traditionally learned HRTF representations are well correlated with perceptual relations using auditory-based objective perceptual metrics; we then propose a method for explicitly embedding HRTFs into a perception-informed latent space, leveraging a metric-based loss function and supervision via Metric Multidimensional Scaling (MMDS). Finally, we demonstrate the applicability of these learned representations to the task of HRTF personalization. We suggest that our method has the potential to render personalized spatial audio, leading to an improved listening experience.",
      "authors": [
        "You Zhang",
        "Andrew Francl",
        "Ruohan Gao",
        "Paul Calamia",
        "Zhiyao Duan",
        "Ishwarya Ananthabhotla"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T17:28:53+00:00",
          "link": "https://arxiv.org/abs/2507.02815v1",
          "size": "1923kb",
          "version": "v1"
        }
      ],
      "title": "Towards Perception-Informed Latent HRTF Representations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02815",
        "HTML": "https://arxiv.org/html/2507.02815v1",
        "PDF": "https://arxiv.org/pdf/2507.02815"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on perceptual latent space representations for HRTFs in auditory experiences, without connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02824",
      "abstract": "In this paper, the precoding design is investigated for maximizing the throughput of millimeter wave (mmWave) multiple-input multiple-output (MIMO) systems with obstructed direct communication paths. In particular, a reconfigurable intelligent surface (RIS) is employed to enhance MIMO transmissions, considering mmWave characteristics related to line-of-sight (LoS) and multipath effects. The traditional exhaustive search (ES) for optimal codewords in the continuous phase shift is computationally intensive and time-consuming. To reduce computational complexity, permuted discrete Fourier transform (DFT) vectors are used for finding codebook design, incorporating amplitude responses for practical or ideal RIS systems. However, even if the discrete phase shift is adopted in the ES, it results in significant computation and is time-consuming. Instead, the trained deep neural network (DNN) is developed to facilitate faster codeword selection. Simulation results show that the DNN maintains sub-optimal spectral efficiency even as the distance between the end-user and the RIS has variations in the testing phase. These results highlight the potential of DNN in advancing RIS-aided systems.",
      "authors": [
        "Po-Heng Chou",
        "Ching-Wen Chen",
        "Wan-Jen Huang",
        "Walid Saad",
        "Yu Tsao",
        "and Ronald Y. Chang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T17:35:06+00:00",
          "link": "https://arxiv.org/abs/2507.02824v1",
          "size": "396kb",
          "version": "v1"
        }
      ],
      "title": "DNN-Based Precoding in RIS-Aided mmWave MIMO Systems With Practical Phase Shift",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02824",
        "HTML": "https://arxiv.org/html/2507.02824v1",
        "PDF": "https://arxiv.org/pdf/2507.02824"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is concerned with DNN-based precoding for MIMO systems, unrelated to LLM training data topics."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02828",
      "abstract": "We introduce magic-augmented Clifford circuits -- architectures in which Clifford circuits are preceded and/or followed by constant-depth circuits of non-Clifford (``magic\") gates -- as a resource-efficient way to realize approximate $k$-designs, with reduced circuit depth and usage of magic. We prove that shallow Clifford circuits, when augmented with constant-depth circuits of magic gates, can generate approximate unitary and state $k$-designs with $\\epsilon$ relative error. The total circuit depth for these constructions on $N$ qubits is $O(\\log (N/\\epsilon)) +2^{O(k\\log k)}$ in one dimension and $O(\\log\\log(N/\\epsilon))+2^{O(k\\log k)}$ in all-to-all circuits using ancillas, which improves upon previous results for small $k \\geq 4$. Furthermore, our construction of relative-error state $k$-designs only involves states with strictly local magic. The required number of magic gates is parametrically reduced when considering $k$-designs with bounded additive error. As an example, we show that shallow Clifford circuits followed by $O(k^2)$ single-qubit magic gates, independent of system size, can generate an additive-error state $k$-design. We develop a classical statistical mechanics description of our random circuit architectures, which provides a quantitative understanding of the required depth and number of magic gates for additive-error state $k$-designs. We also prove no-go theorems for various architectures to generate designs with bounded relative error.",
      "authors": [
        "Yuzhen Zhang",
        "Sagar Vijay",
        "Yingfei Gu",
        "Yimu Bao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Statistical Mechanics (cond-mat.stat-mech)",
        "Strongly Correlated Electrons (cond-mat.str-el)",
        "Information Theory (cs.IT)",
        "High Energy Physics - Theory (hep-th)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T17:41:03+00:00",
          "link": "https://arxiv.org/abs/2507.02828v1",
          "size": "302kb",
          "version": "v1"
        }
      ],
      "title": "Designs from magic-augmented Clifford circuits",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02828",
        "HTML": "https://arxiv.org/html/2507.02828v1",
        "PDF": "https://arxiv.org/pdf/2507.02828"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces methods for creating approximate k-designs using quantum circuits, which is not related to the processing or engineering of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02839",
      "abstract": "We show that linearly constrained linear optimization over a Stiefel or Grassmann manifold is NP-hard in general. We show that the same is true for unconstrained quadratic optimization over a Stiefel manifold. We will establish the nonexistence of FPTAS for these optimization problems over a Stiefel manifold. As an aside we extend our results to flag manifolds. Combined with earlier findings, this shows that manifold optimization is a difficult endeavor -- even the simplest problems like LP and unconstrained QP are already NP-hard on the most common manifolds.",
      "authors": [
        "Zehua Lai",
        "Lek-Heng Lim",
        "and Tianyun Tang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Computational Complexity (cs.CC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T17:47:22+00:00",
          "link": "https://arxiv.org/abs/2507.02839v1",
          "size": "10kb",
          "version": "v1"
        }
      ],
      "title": "Stiefel optimization is NP-hard",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02839",
        "PDF": "https://arxiv.org/pdf/2507.02839"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the complexity of optimization over manifolds like the Stiefel and Grassmann manifolds, which is unrelated to LLM training data processing or data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2102.11210",
      "abstract": "We develop regularization methods to find flat minima while training deep neural networks. These minima generalize better than sharp minima, yielding models outperforming baselines on real-world test data (which may be distributed differently than the training data). Specifically, we propose a method of regularized optimization to reduce the spectral radius of the Hessian of the loss function. We also derive algorithms to efficiently optimize neural network models and prove that these algorithms almost surely converge. Furthermore, we demonstrate that our algorithm works effectively on applications in different domains, including healthcare. To show that our models generalize well, we introduced various methods for testing generalizability and found that our models outperform comparable baseline models on these tests.",
      "authors": [
        "Adam Sandler",
        "Diego Klabjan and Yuan Luo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2021-02-22T17:39:05+00:00",
          "link": "https://arxiv.org/abs/2102.11210v1",
          "size": "490kb",
          "version": "v1"
        },
        {
          "date": "2025-07-02T21:53:39+00:00",
          "link": "https://arxiv.org/abs/2102.11210v2",
          "size": "254kb",
          "version": "v2"
        }
      ],
      "title": "Non-Convex Optimization with Spectral Radius Regularization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2102.11210",
        "HTML": "https://arxiv.org/html/2102.11210v2",
        "PDF": "https://arxiv.org/pdf/2102.11210"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on regularization methods for training deep neural networks to find flat minima that generalize better. It does not address any aspect of LLM training data collection, construction, or processing."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/ars2240/optWBoundEigenval"
      ],
      "source": "arXiv"
    },
    {
      "id": "2202.05928",
      "abstract": "Benign overfitting, the phenomenon where interpolating models generalize well in the presence of noisy data, was first observed in neural network models trained with gradient descent. To better understand this empirical observation, we consider the generalization error of two-layer neural networks trained to interpolation by gradient descent on the logistic loss following random initialization. We assume the data comes from well-separated class-conditional log-concave distributions and allow for a constant fraction of the training labels to be corrupted by an adversary. We show that in this setting, neural networks exhibit benign overfitting: they can be driven to zero training error, perfectly fitting any noisy training labels, and simultaneously achieve minimax optimal test error. In contrast to previous work on benign overfitting that require linear or kernel-based predictors, our analysis holds in a setting where both the model and learning dynamics are fundamentally nonlinear.",
      "authors": [
        "Spencer Frei",
        "Niladri S. Chatterji",
        "Peter L. Bartlett"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Statistics Theory (math.ST)",
        "Machine Learning (stat.ML)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2022-02-11T23:04:00+00:00",
          "link": "https://arxiv.org/abs/2202.05928v1",
          "size": "38kb",
          "version": "v1"
        },
        {
          "date": "2022-03-22T15:52:05+00:00",
          "link": "https://arxiv.org/abs/2202.05928v2",
          "size": "39kb",
          "version": "v2"
        },
        {
          "date": "2022-09-20T11:06:01+00:00",
          "link": "https://arxiv.org/abs/2202.05928v3",
          "size": "43kb",
          "version": "v3"
        },
        {
          "date": "2023-09-14T02:58:37+00:00",
          "link": "https://arxiv.org/abs/2202.05928v4",
          "size": "43kb",
          "version": "v4"
        },
        {
          "date": "2025-07-02T18:17:45+00:00",
          "link": "https://arxiv.org/abs/2202.05928v5",
          "size": "60kb",
          "version": "v5"
        }
      ],
      "title": "Benign Overfitting without Linearity: Neural Network Classifiers Trained by Gradient Descent for Noisy Linear Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2202.05928",
        "HTML": "https://arxiv.org/html/2202.05928v5",
        "PDF": "https://arxiv.org/pdf/2202.05928"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores benign overfitting in neural networks trained with gradient descent, without reference to LLM training data processing or specific contributions to LLM data engineering stages."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2210.09228",
      "abstract": "The task of simultaneously reconstructing multiple physical coefficients in partial differential equations (PDEs) from observed data is ubiquitous in applications. In this work, we propose an integrated data-driven and model-based iterative reconstruction framework for such joint inversion problems where additional data on the unknown coefficients are supplemented for better reconstructions. Our method couples the supplementary data with the PDE model to make the data-driven modeling process consistent with the model-based reconstruction procedure. We characterize the impact of learning uncertainty on the joint inversion results for two typical inverse problems. Numerical evidence is provided to demonstrate the feasibility of using data-driven models to improve the joint inversion of multiple coefficients in PDEs.",
      "authors": [
        "Kui Ren",
        "Lu Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Machine Learning (cs.LG)",
        "Numerical Analysis (cs.NA)",
        "Optimization and Control (math.OC)",
        "Methodology (stat.ME)"
      ],
      "submission_historys": [
        {
          "date": "2022-10-17T16:21:45+00:00",
          "link": "https://arxiv.org/abs/2210.09228v1",
          "size": "18224kb",
          "version": "v1"
        },
        {
          "date": "2025-02-08T21:14:07+00:00",
          "link": "https://arxiv.org/abs/2210.09228v2",
          "size": "16290kb",
          "version": "v2"
        },
        {
          "date": "2025-07-02T18:33:58+00:00",
          "link": "https://arxiv.org/abs/2210.09228v3",
          "size": "12728kb",
          "version": "v3"
        }
      ],
      "title": "A Model-Consistent Data-Driven Computational Strategy for PDE Joint Inversion Problems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2210.09228",
        "HTML": "https://arxiv.org/html/2210.09228v3",
        "PDF": "https://arxiv.org/pdf/2210.09228"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with data-driven methods for joint inversion problems in PDEs, which do not relate to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2211.07547",
      "abstract": "We propose a unifying framework for smoothed analysis of combinatorial local optimization problems, and show how a diverse selection of problems within the complexity class PLS can be cast within this model. This abstraction allows us to identify key structural properties, and corresponding parameters, that determine the smoothed running time of local search dynamics. We formalize this via a black-box tool that provides concrete bounds on the expected maximum number of steps needed until local search reaches an exact local optimum. This bound is particularly strong, in the sense that it holds for any starting feasible solution, any choice of pivoting rule, and does not rely on the choice of specific noise distributions that are applied on the input, but it is parameterized by just a global upper bound $\\phi$ on the probability density. The power of this tool can be demonstrated by instantiating it for various PLS-hard problems of interest to derive efficient smoothed running times (as a function of $\\phi$ and the input size).\n  Most notably, we focus on the important local optimization problem of finding pure Nash equilibria in Congestion Games, that has not been studied before from a smoothed analysis perspective. Specifically, we propose novel smoothed analysis models for general and Network Congestion Games, under various representations, including explicit, step-function, and polynomial resource latencies. We study PLS-hard instances of these problems and show that their standard local search algorithms run in polynomial smoothed time.\n  Finally, we present further applications of our framework to a wide range of additional combinatorial problems, including local Max-Cut in weighted graphs, the Travelling Salesman problem (TSP) under the $k$-opt local heuristic, and finding pure equilibria in Network Coordination Games.",
      "authors": [
        "Yiannis Giannakopoulos",
        "Alexander Grosz",
        "Themistoklis Melissourgos"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Complexity (cs.CC)",
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2022-11-14T17:11:23+00:00",
          "link": "https://arxiv.org/abs/2211.07547v1",
          "size": "142kb",
          "version": "v1"
        },
        {
          "date": "2022-11-15T18:59:08+00:00",
          "link": "https://arxiv.org/abs/2211.07547v2",
          "size": "143kb",
          "version": "v2"
        },
        {
          "date": "2023-05-26T16:05:39+00:00",
          "link": "https://arxiv.org/abs/2211.07547v3",
          "size": "145kb",
          "version": "v3"
        },
        {
          "date": "2024-06-20T09:22:15+00:00",
          "link": "https://arxiv.org/abs/2211.07547v4",
          "size": "145kb",
          "version": "v4"
        },
        {
          "date": "2025-07-03T17:33:59+00:00",
          "link": "https://arxiv.org/abs/2211.07547v5",
          "size": "150kb",
          "version": "v5"
        }
      ],
      "title": "On the Smoothed Complexity of Combinatorial Local Search",
      "links": {
        "Abstract": "https://arxiv.org/abs/2211.07547",
        "HTML": "https://arxiv.org/html/2211.07547v5",
        "PDF": "https://arxiv.org/pdf/2211.07547"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus on smoothed complexity in combinatorial local search and optimization problems does not pertain to LLM training data processing tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2211.16289",
      "abstract": "Attention operator has been widely used as a basic brick in visual understanding since it provides some flexibility through its adjustable kernels. However, this operator suffers from inherent limitations: (1) the attention kernel is not discriminative enough, resulting in high redundancy, and (2) the complexity in computation and memory is quadratic in the sequence length. In this paper, we propose a novel attention operator, called Lightweight Structure-aware Attention (LiSA), which has a better representation power with log-linear complexity. Our operator transforms the attention kernels to be more discriminative by learning structural patterns. These structural patterns are encoded by exploiting a set of relative position embeddings (RPEs) as multiplicative weights, thereby improving the representation power of the attention kernels. Additionally, the RPEs are approximated to obtain log-linear complexity. Our experiments and analyses demonstrate that the proposed operator outperforms self-attention and other existing operators, achieving state-of-the-art results on ImageNet-1K and other downstream tasks such as video action recognition on Kinetics-400, object detection \\& instance segmentation on COCO, and semantic segmentation on ADE-20K.",
      "authors": [
        "Heeseung Kwon",
        "Francisco M. Castro",
        "Manuel J. Marin-Jimenez",
        "Nicolas Guil",
        "Karteek Alahari"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2022-11-29T15:20:14+00:00",
          "link": "https://arxiv.org/abs/2211.16289v1",
          "size": "7364kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T12:08:30+00:00",
          "link": "https://arxiv.org/abs/2211.16289v2",
          "size": "4060kb",
          "version": "v2"
        }
      ],
      "title": "Lightweight Structure-Aware Attention for Visual Understanding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2211.16289",
        "HTML": "https://arxiv.org/html/2211.16289v2",
        "PDF": "https://arxiv.org/pdf/2211.16289"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving visual attention mechanisms with a new attention operator for visual tasks, not on processing of training data for LLMs."
      },
      "tasks": [
        "Representation Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2301.08148",
      "abstract": "Traffic analysis attacks remain a significant problem for online security. Communication between nodes can be observed by network level attackers as it inherently takes place in the open. Despite online services increasingly using encrypted traffic, the shape of the traffic is not hidden. To prevent traffic analysis, the shape of a system's traffic must be independent of secrets. We investigate adapting the data-oblivious approach the reactive setting and present OblivIO, a secure language for writing reactive programs driven by network events. Our approach pads with dummy messages to hide which program sends are genuinely executed. We use an information-flow type system to provably enforce timing-sensitive noninterference. The type system is extended with potentials to bound the overhead in traffic introduced by our approach. We address challenges that arise from joining data-oblivious and reactive programming and demonstrate the feasibility of our resulting language by developing an interpreter that implements security critical operations as constant-time algorithms.",
      "authors": [
        "Jeppe Fredsgaard Blaabjerg",
        "Aslan Askarov"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2023-01-19T15:59:33+00:00",
          "link": "https://arxiv.org/abs/2301.08148v1",
          "size": "900kb",
          "version": "v1"
        },
        {
          "date": "2025-07-02T22:09:25+00:00",
          "link": "https://arxiv.org/abs/2301.08148v2",
          "size": "62kb",
          "version": "v2"
        }
      ],
      "title": "OblivIO: Securing reactive programs by oblivious execution with bounded traffic overheads",
      "links": {
        "Abstract": "https://arxiv.org/abs/2301.08148",
        "PDF": "https://arxiv.org/pdf/2301.08148"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work focuses on securing reactive programs through oblivious execution for network security, unrelated to processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2301.09321",
      "abstract": "Controlling inter-area oscillation (IAO) across wide areas is crucial for the stability of modern power systems. Recent advances in deep learning, combined with the extensive deployment of phasor measurement units (PMUs) and generator sensors, have catalyzed the development of data-driven IAO damping controllers. In this paper, a novel IAO damping control framework is presented by modeling the control problem as a Markov Decision Process (MDP) and solving it through deep reinforcement learning (DRL). The DRL-based controller is trained in the state space with continuous eigenvalue configurations. To optimize control performance and cost-efficiency, only a subset of generators, identified by global participation factors, are selected for control. In addition, a switching control strategy (SCS) is introduced that effectively integrates the DRL-based controller with power system stabilizers (PSSs) to enhance overall performance. The simulation results on the IEEE 39-bus New England power system show that the proposed method outperforms two benchmark methods regarding the transient response. The DRL-based controller trained on the linear state-space environment can be directly tested in the nonlinear differential-algebraic environment. The robustness of the proposed method against communication delays has been thoroughly investigated.",
      "authors": [
        "Siyuan Liang",
        "Long Huo",
        "Wenyu Qin",
        "Xin Chen",
        "Peiyuan Sun"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2023-01-23T08:44:09+00:00",
          "link": "https://arxiv.org/abs/2301.09321v1",
          "size": "4818kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T00:38:34+00:00",
          "link": "https://arxiv.org/abs/2301.09321v2",
          "size": "14447kb",
          "version": "v2"
        }
      ],
      "title": "Deep-Reinforcement-Learning-Based Adaptive State-Feedback Control for Inter-Area Oscillation Damping with Continuous Eigenvalue Configurations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2301.09321",
        "HTML": "https://arxiv.org/html/2301.09321v2",
        "PDF": "https://arxiv.org/pdf/2301.09321"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses reinforcement learning for power system control and does not pertain to LLM training data processing."
      },
      "tasks": [
        "Deep Reinforcement Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2303.06285",
      "abstract": "Text-driven image manipulation remains challenging in training or inference flexibility. Conditional generative models depend heavily on expensive annotated training data. Meanwhile, recent frameworks, which leverage pre-trained vision-language models, are limited by either per text-prompt optimization or inference-time hyper-parameters tuning. In this work, we propose a novel framework named \\textit{DeltaEdit} to address these problems. Our key idea is to investigate and identify a space, namely delta image and text space that has well-aligned distribution between CLIP visual feature differences of two images and CLIP textual embedding differences of source and target texts. Based on the CLIP delta space, the DeltaEdit network is designed to map the CLIP visual features differences to the editing directions of StyleGAN at training phase. Then, in inference phase, DeltaEdit predicts the StyleGAN's editing directions from the differences of the CLIP textual features. In this way, DeltaEdit is trained in a text-free manner. Once trained, it can well generalize to various text prompts for zero-shot inference without bells and whistles.",
      "authors": [
        "Yueming Lyu",
        "Tianwei Lin",
        "Fu Li",
        "Dongliang He",
        "Jing Dong",
        "Tieniu Tan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2023-03-11T02:38:31+00:00",
          "link": "https://arxiv.org/abs/2303.06285v1",
          "size": "22369kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T12:26:23+00:00",
          "link": "https://arxiv.org/abs/2303.06285v2",
          "size": "4154kb",
          "version": "v2"
        }
      ],
      "title": "DeltaEdit: Exploring Text-free Training for Text-Driven Image Manipulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2303.06285",
        "HTML": "https://arxiv.org/html/2303.06285v2",
        "PDF": "https://arxiv.org/pdf/2303.06285"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes a novel text-free framework for image manipulation which involves manipulating embeddings, but it does not focus on the data engineering or processing aspects for LLM training directly."
      },
      "conference_url_abs": "http://openaccess.thecvf.com//content/CVPR2023/html/Lyu_DeltaEdit_Exploring_Text-Free_Training_for_Text-Driven_Image_Manipulation_CVPR_2023_paper.html",
      "tasks": [
        "Image Manipulation"
      ],
      "repo_urls": [
        "https://github.com/yueming6568/deltaedit"
      ],
      "source": "arXiv"
    },
    {
      "id": "2303.06827",
      "abstract": "Inverse reinforcement learning (IRL) methods infer an agent's reward function using demonstrations of expert behavior. A Bayesian IRL approach models a distribution over candidate reward functions, capturing a degree of uncertainty in the inferred reward function. This is critical in some applications, such as those involving clinical data. Typically, Bayesian IRL algorithms require large demonstration datasets, which may not be available in practice. In this work, we incorporate existing domain-specific data to achieve better posterior concentration rates. We study a common setting in clinical and biological applications where we have access to expert demonstrations and known reward functions for a set of training tasks. Our aim is to learn the reward function of a new test task given limited expert demonstrations. Existing Bayesian IRL methods impose restrictions on the form of input data, thus limiting the incorporation of training task data. To better leverage information from training tasks, we introduce kernel density Bayesian inverse reinforcement learning (KD-BIRL). Our approach employs a conditional kernel density estimator, which uses the known reward functions of the training tasks to improve the likelihood estimation across a range of reward functions and demonstration samples. Our empirical results highlight KD-BIRL's faster concentration rate in comparison to baselines, particularly in low test task expert demonstration data regimes. Additionally, we are the first to provide theoretical guarantees of posterior concentration for a Bayesian IRL algorithm. Taken together, this work introduces a principled and theoretically grounded framework that enables Bayesian IRL to be applied across a variety of domains.",
      "authors": [
        "Aishwarya Mandyam",
        "Didong Li",
        "Jiayu Yao",
        "Diana Cai",
        "Andrew Jones",
        "Barbara E. Engelhardt"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2023-03-13T03:00:03+00:00",
          "link": "https://arxiv.org/abs/2303.06827v1",
          "size": "1052kb",
          "version": "v1"
        },
        {
          "date": "2023-10-12T23:04:25+00:00",
          "link": "https://arxiv.org/abs/2303.06827v2",
          "size": "739kb",
          "version": "v2"
        },
        {
          "date": "2024-11-04T17:36:06+00:00",
          "link": "https://arxiv.org/abs/2303.06827v3",
          "size": "1012kb",
          "version": "v3"
        },
        {
          "date": "2025-07-03T04:27:15+00:00",
          "link": "https://arxiv.org/abs/2303.06827v4",
          "size": "1012kb",
          "version": "v4"
        }
      ],
      "title": "Kernel Density Bayesian Inverse Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2303.06827",
        "HTML": "https://arxiv.org/html/2303.06827v4",
        "PDF": "https://arxiv.org/pdf/2303.06827"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on inverse reinforcement learning and does not address LLM training data processing, collection, or enhancement."
      },
      "tasks": [
        "BIRL",
        "Density Estimation",
        "reinforcement-learning",
        "Reinforcement Learning",
        "Reinforcement Learning (RL)"
      ],
      "repo_urls": [
        "https://github.com/bee-hive/kdbirl_public"
      ],
      "source": "arXiv"
    },
    {
      "id": "2304.13431",
      "abstract": "Machine learning models are prone to capturing the spurious correlations between non-causal attributes and classes, with counterfactual data augmentation being a promising direction for breaking these spurious associations. However, generating counterfactual data explicitly poses a challenge, and incorporating augmented data into the training process decreases training efficiency. This study proposes an Implicit Counterfactual Data Augmentation (ICDA) method to remove spurious correlations and make stable predictions. Specifically, first, a novel sample-wise augmentation strategy is developed that generates semantically and counterfactually meaningful deep features with distinct augmentation strength for each sample. Second, we derive an easy-to-compute surrogate loss on the augmented feature set when the number of augmented samples becomes infinite. Third, two concrete schemes are proposed, including direct quantification and meta-learning, to derive the key parameters for the robust loss. In addition, ICDA is explained from a regularization perspective, revealing its capacity to improve intra-class compactness and augment margins at both class and sample levels. Extensive experiments have been conducted across various biased learning scenarios covering both image and text datasets, demonstrating that ICDA consistently enhances the generalization and robustness performance of popular networks.",
      "authors": [
        "Xiaoling Zhou",
        "Ou Wu",
        "Michael K. Ng"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2023-04-26T10:36:40+00:00",
          "link": "https://arxiv.org/abs/2304.13431v1",
          "size": "36855kb",
          "version": "v1"
        },
        {
          "date": "2024-10-16T03:26:25+00:00",
          "link": "https://arxiv.org/abs/2304.13431v2",
          "size": "7403kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T04:06:34+00:00",
          "link": "https://arxiv.org/abs/2304.13431v3",
          "size": "8420kb",
          "version": "v3"
        }
      ],
      "title": "Implicit Counterfactual Data Augmentation for Robust Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2304.13431",
        "HTML": "https://arxiv.org/html/2304.13431v3",
        "PDF": "https://arxiv.org/pdf/2304.13431"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses counterfactual data augmentation for robustness in learning, which mentions data processing but does not contribute new methods for LLM training data specifically."
      },
      "tasks": [
        "counterfactual",
        "Data Augmentation",
        "Meta-Learning",
        "Out-of-Distribution Generalization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2306.13840",
      "abstract": "Current trends in pre-training Large Language Models (LLMs) primarily focus on the scaling of model and dataset size. While the quality of pre-training data is considered an important factor for training powerful LLMs, it remains a nebulous concept that has not been rigorously characterized. To this end, we propose a formalization of one key aspect of data quality -- measuring the variability of natural language data -- specifically via a measure we call the diversity coefficient. Our empirical analysis shows that the proposed diversity coefficient aligns with the intuitive properties of diversity and variability, e.g., it increases as the number of latent concepts increases. Then, we measure the diversity coefficient of publicly available pre-training datasets and demonstrate that their formal diversity is high compared to theoretical lower and upper bounds. Finally, we conduct a comprehensive set of controlled interventional experiments with GPT-2 and LLaMAv2 that demonstrate the diversity coefficient of pre-training data characterizes useful aspects of downstream model evaluation performance -- totaling 44 models of various sizes (51M to 7B parameters). We conclude that our formal notion of diversity is an important aspect of data quality that captures variability and causally leads to improved evaluation performance.",
      "authors": [
        "Brando Miranda",
        "Alycia Lee",
        "Sudharsan Sundar",
        "Allison Casasola",
        "Rylan Schaeffer",
        "Elyas Obbad",
        "Sanmi Koyejo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2023-06-24T02:25:56+00:00",
          "link": "https://arxiv.org/abs/2306.13840v1",
          "size": "841kb",
          "version": "v1"
        },
        {
          "date": "2023-09-26T23:29:05+00:00",
          "link": "https://arxiv.org/abs/2306.13840v2",
          "size": "842kb",
          "version": "v2"
        },
        {
          "date": "2024-08-26T17:34:44+00:00",
          "link": "https://arxiv.org/abs/2306.13840v3",
          "size": "2826kb",
          "version": "v3"
        },
        {
          "date": "2025-07-02T21:53:51+00:00",
          "link": "https://arxiv.org/abs/2306.13840v4",
          "size": "2478kb",
          "version": "v4"
        }
      ],
      "title": "Beyond Scale: The Diversity Coefficient as a Data Quality Metric for Variability in Natural Language Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2306.13840",
        "HTML": "https://arxiv.org/html/2306.13840v4",
        "PDF": "https://arxiv.org/pdf/2306.13840"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper introduces the diversity coefficient as a data quality metric specific to LLM pre-training data, addressing a core aspect of data variability and quality in LLMs."
      },
      "tasks": [
        "Diversity"
      ],
      "source": "arXiv"
    },
    {
      "id": "2310.12053",
      "abstract": "Recent years have witnessed the introduction and development of extremely fast rational function algorithms. Many ideas in this realm arose from polynomial-based linear-algebraic algorithms. However, polynomial approximation is occasionally ill-suited to specific challenging tasks arising in several situations. Some occasions require maximal efficiency in the number of encoding parameters whilst retaining the renowned accuracy of polynomial-based approximation. One application comes from promoting empirical pointwise functions to sparse matrix operators. Rational function approximations provide a simple but flexible alternative (actually a superset), allowing one to capture complex non-linearities. However, these come with extra challenges: i) coping with singularities and near singularities arising from a vanishing denominator, and ii) a non-uniqueness owing to a simultaneous renormalization of both numerator and denominator.\n  We, therefore, introduce a new rational function framework using manifestly positive and normalized Bernstein polynomials for the denominator and any traditional polynomial basis (e.g., Chebyshev) for the numerator. While an expressly non-singular approximation slightly reduces the maximum degree of compression, it keeps all the benefits of rational functions while maintaining the flexibility and robustness of polynomials. We illustrate the relevant aspects of this approach with a series of derivations and computational examples.",
      "authors": [
        "James Chok and Geoffrey M. Vasil"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Computation (stat.CO)"
      ],
      "submission_historys": [
        {
          "date": "2023-10-18T15:37:21+00:00",
          "link": "https://arxiv.org/abs/2310.12053v1",
          "size": "1297kb",
          "version": "v1"
        },
        {
          "date": "2023-10-19T15:08:42+00:00",
          "link": "https://arxiv.org/abs/2310.12053v2",
          "size": "1298kb",
          "version": "v2"
        },
        {
          "date": "2025-04-03T12:15:35+00:00",
          "link": "https://arxiv.org/abs/2310.12053v3",
          "size": "1298kb",
          "version": "v3"
        },
        {
          "date": "2025-07-03T11:57:31+00:00",
          "link": "https://arxiv.org/abs/2310.12053v4",
          "size": "167kb",
          "version": "v4"
        }
      ],
      "title": "Rational function approximation with normalized positive denominators",
      "links": {
        "Abstract": "https://arxiv.org/abs/2310.12053",
        "HTML": "https://arxiv.org/html/2310.12053v4",
        "PDF": "https://arxiv.org/pdf/2310.12053"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on rational function approximation, which does not relate to the processing of LLM training data."
      },
      "repo_urls": [
        "https://github.com/infamoussoap/RationalFunctionApproximation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2311.08010",
      "abstract": "Distantly-Supervised Named Entity Recognition (DS-NER) is widely used in real-world scenarios. It can effectively alleviate the burden of annotation by matching entities in existing knowledge bases with snippets in the text but suffer from the label noise. Recent works attempt to adopt the teacher-student framework to gradually refine the training labels and improve the overall robustness. However, these teacher-student methods achieve limited performance because the poor calibration of the teacher network produces incorrectly pseudo-labeled samples, leading to error propagation. Therefore, we propose: (1) Uncertainty-Aware Teacher Learning that leverages the prediction uncertainty to reduce the number of incorrect pseudo labels in the self-training stage; (2) Student-Student Collaborative Learning that allows the transfer of reliable labels between two student networks instead of indiscriminately relying on all pseudo labels from its teacher, and further enables a full exploration of mislabeled samples rather than simply filtering unreliable pseudo-labeled samples. We evaluate our proposed method on five DS-NER datasets, demonstrating that our method is superior to the state-of-the-art DS-NER methods.",
      "authors": [
        "Shuzheng Si",
        "Helan Hu",
        "Haozhe Zhao",
        "Shuang Zeng",
        "Kaikai An",
        "Zefan Cai and Baobao Chang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2023-11-14T09:09:58+00:00",
          "link": "https://arxiv.org/abs/2311.08010v1",
          "size": "7116kb",
          "version": "v1"
        },
        {
          "date": "2024-07-09T05:11:25+00:00",
          "link": "https://arxiv.org/abs/2311.08010v2",
          "size": "7219kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T06:51:31+00:00",
          "link": "https://arxiv.org/abs/2311.08010v3",
          "size": "7113kb",
          "version": "v3"
        }
      ],
      "title": "Improving the Robustness of Distantly-Supervised Named Entity Recognition via Uncertainty-Aware Teacher Learning and Student-Student Collaborative Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2311.08010",
        "HTML": "https://arxiv.org/html/2311.08010v3",
        "PDF": "https://arxiv.org/pdf/2311.08010"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper addresses label noise in named entity recognition, it does not propose new processing methods specifically for LLM training data."
      },
      "tasks": [
        "named-entity-recognition",
        "Named Entity Recognition",
        "NER"
      ],
      "repo_urls": [
        "https://github.com/pkunlp-icler/censor"
      ],
      "source": "arXiv"
    },
    {
      "id": "2311.09511",
      "abstract": "The investigation reported in this document focuses on identifying systems with symmetries using equivariant autoregressive reservoir computers. General results in structured matrix approximation theory are presented, exploring a two-fold approach. Firstly, a comprehensive examination of generic symmetry-preserving nonlinear time delay embedding is conducted. This involves analyzing time series data sampled from an equivariant system under study. Secondly, sparse least-squares methods are applied to discern approximate representations of the output coupling matrices. These matrices play a critical role in determining the nonlinear autoregressive representation of an equivariant system. The structural characteristics of these matrices are dictated by the set of symmetries inherent in the system. The document outlines prototypical algorithms derived from the described techniques, offering insight into their practical applications. Emphasis is placed on the significant improvement on structured identification precision when compared to classical reservoir computing methods for the simulation of equivariant dynamical systems.",
      "authors": [
        "Fredy Vides",
        "Idelfonso B. R. Nogueira",
        "Gabriela Lopez Gutierrez",
        "Lendy Banegas",
        "Evelyn Flores"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2023-11-16T02:32:26+00:00",
          "link": "https://arxiv.org/abs/2311.09511v1",
          "size": "301kb",
          "version": "v1"
        },
        {
          "date": "2023-11-28T22:59:41+00:00",
          "link": "https://arxiv.org/abs/2311.09511v2",
          "size": "301kb",
          "version": "v2"
        },
        {
          "date": "2025-06-30T19:14:09+00:00",
          "link": "https://arxiv.org/abs/2311.09511v3",
          "size": "1405kb",
          "version": "v3"
        },
        {
          "date": "2025-07-02T20:23:07+00:00",
          "link": "https://arxiv.org/abs/2311.09511v4",
          "size": "1405kb",
          "version": "v4"
        }
      ],
      "title": "Identifying Systems with Symmetries using Equivariant Autoregressive Reservoir Computers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2311.09511",
        "HTML": "https://arxiv.org/html/2311.09511v4",
        "PDF": "https://arxiv.org/pdf/2311.09511"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on identifying systems with symmetries using equivariant autoregressive reservoir computers, which is unrelated to LLM training data processing."
      },
      "tasks": [
        "Time Series"
      ],
      "source": "arXiv"
    },
    {
      "id": "2311.14727",
      "abstract": "The rising influence of social media platforms in various domains, including tourism, has highlighted the growing need for efficient and automated Natural Language Processing (NLP) strategies to take advantage of this valuable resource. However, the transformation of multilingual, unstructured, and informal texts into structured knowledge still poses significant challenges, most notably the never-ending requirement for manually annotated data to train deep learning classifiers. In this work, we study different NLP techniques to establish the best ones to obtain competitive performances while keeping the need for training annotated data to a minimum. To do so, we built the first publicly available multilingual dataset (French, English, and Spanish) for the tourism domain, composed of tourism-related tweets. The dataset includes multilayered, manually revised annotations for Named Entity Recognition (NER) for Locations and Fine-grained Thematic Concepts Extraction mapped to the Thesaurus of Tourism and Leisure Activities of the World Tourism Organization, as well as for Sentiment Analysis at the tweet level. Extensive experimentation comparing various few-shot and fine-tuning techniques with modern language models demonstrate that modern few-shot techniques allow us to obtain competitive results for all three tasks with very little annotation data: 5 tweets per label (15 in total) for Sentiment Analysis, 30 tweets for Named Entity Recognition of Locations and 1K tweets annotated with fine-grained thematic concepts, a highly fine-grained sequence labeling task based on an inventory of 315 classes. We believe that our results, grounded in a novel dataset, pave the way for applying NLP to new domain-specific applications, reducing the need for manual annotations and circumventing the complexities of rule-based, ad-hoc solutions.",
      "authors": [
        "Maxime Masson",
        "Rodrigo Agerri",
        "Christian Sallaberry",
        "Marie-Noelle Bessagnet",
        "Annig Le Parc Lacayrelle and Philippe Roose"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2023-11-20T13:08:21+00:00",
          "link": "https://arxiv.org/abs/2311.14727v1",
          "size": "1647kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T03:54:21+00:00",
          "link": "https://arxiv.org/abs/2311.14727v2",
          "size": "1799kb",
          "version": "v2"
        }
      ],
      "title": "Optimal strategies to perform multilingual analysis of social content for a novel dataset in the tourism domain",
      "links": {
        "Abstract": "https://arxiv.org/abs/2311.14727",
        "HTML": "https://arxiv.org/html/2311.14727v2",
        "PDF": "https://arxiv.org/pdf/2311.14727"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper involves the creation of a multilingual dataset for NLP in the tourism domain, mentioning data collection and annotation but does not focus on LLM training data processing innovations."
      },
      "tasks": [
        "Few-Shot Learning",
        "named-entity-recognition",
        "Named Entity Recognition",
        "Sentiment Analysis"
      ],
      "source": "arXiv"
    },
    {
      "id": "2312.04789",
      "abstract": "Modern workloads are demanding increasingly larger memory capacity. Compute Express Link (CXL)-based memory tiering has emerged as a promising solution for addressing this problem by utilizing traditional DRAM alongside slow-tier CXL memory devices. We analyze prior tiering systems and observe two challenges for high-performance memory tiering: adapting to skewed but dynamically varying data hotness distributions while minimizing memory and cache overhead due to tiering.\n  To address these challenges, we propose HybridTier, an adaptive and lightweight tiering system for CXL memory. HybridTier tracks both long-term data access frequency and short-term access momentum \\emph{simultaneously} to accurately capture and adapt to shifting hotness distributions. HybridTier reduces the metadata memory overhead by tracking data accesses \\emph{probabilistically}, obtaining higher memory efficiency by trading off a small amount of tracking inaccuracy that has a negligible impact on application performance. To reduce cache overhead, HybridTier uses lightweight data structures that optimize for data locality to track data hotness. Our evaluations show that HybridTier outperforms prior systems by up to $91\\%$ ($19\\%$ geomean), incurring $2.0-7.8\\times$ less memory overhead and $1.7-3.5\\times$ less cache misses.",
      "authors": [
        "Kevin Song",
        "Jiacheng Yang",
        "Zixuan Wang",
        "Jishen Zhao",
        "Sihang Liu",
        "Gennady Pekhimenko"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Operating Systems (cs.OS)"
      ],
      "submission_historys": [
        {
          "date": "2023-12-08T02:03:55+00:00",
          "link": "https://arxiv.org/abs/2312.04789v1",
          "size": "3070kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T17:11:28+00:00",
          "link": "https://arxiv.org/abs/2312.04789v2",
          "size": "1906kb",
          "version": "v2"
        }
      ],
      "title": "HybridTier: an Adaptive and Lightweight CXL-Memory Tiering System",
      "links": {
        "Abstract": "https://arxiv.org/abs/2312.04789",
        "HTML": "https://arxiv.org/html/2312.04789v2",
        "PDF": "https://arxiv.org/pdf/2312.04789"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on an adaptive memory tiering system for enhancing memory capacity using CXL technologies. It addresses issues related to hardware memory management rather than the processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2402.08062",
      "abstract": "Most learning algorithms with formal regret guarantees assume that all mistakes are recoverable and essentially rely on trying all possible behaviors. This approach is problematic when some mistakes are \"catastrophic\", i.e., irreparable. We propose an online learning problem where the goal is to minimize the chance of catastrophe. Specifically, we assume that the payoff in each round represents the chance of avoiding catastrophe in that round and try to maximize the product of payoffs (the overall chance of avoiding catastrophe) while allowing a limited number of queries to a mentor. We also assume that the agent can transfer knowledge between similar inputs. We first show that in general, any algorithm either queries the mentor at a linear rate or is nearly guaranteed to cause catastrophe. However, in settings where the mentor policy class is learnable in the standard online model, we provide an algorithm whose regret and rate of querying the mentor both approach 0 as the time horizon grows. Although our focus is the product of payoffs, we provide matching bounds for the typical additive regret. Conceptually, if a policy class is learnable in the absence of catastrophic risk, it is learnable in the presence of catastrophic risk if the agent can ask for help.",
      "authors": [
        "Benjamin Plaut",
        "Hanlin Zhu",
        "Stuart Russell"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-12T21:12:11+00:00",
          "link": "https://arxiv.org/abs/2402.08062v1",
          "size": "50kb",
          "version": "v1"
        },
        {
          "date": "2024-05-26T16:55:07+00:00",
          "link": "https://arxiv.org/abs/2402.08062v2",
          "size": "53kb",
          "version": "v2"
        },
        {
          "date": "2024-10-04T15:23:43+00:00",
          "link": "https://arxiv.org/abs/2402.08062v3",
          "size": "82kb",
          "version": "v3"
        },
        {
          "date": "2025-01-22T22:10:55+00:00",
          "link": "https://arxiv.org/abs/2402.08062v4",
          "size": "87kb",
          "version": "v4"
        },
        {
          "date": "2025-07-03T16:32:32+00:00",
          "link": "https://arxiv.org/abs/2402.08062v5",
          "size": "103kb",
          "version": "v5"
        }
      ],
      "title": "Avoiding Catastrophe in Online Learning by Asking for Help",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.08062",
        "HTML": "https://arxiv.org/html/2402.08062v5",
        "PDF": "https://arxiv.org/pdf/2402.08062"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about online learning algorithms minimizing catastrophic mistakes through mentorship and transferring knowledge, rather than focusing on LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2402.09919",
      "abstract": "We propose a new method for inferring roads from GPS trajectories to map construction sites. This task presents a unique challenge due to the erratic and non-standard movement patterns of construction machinery, which significantly diverge from typical vehicular traffic on established roads. Our proposed method first identifies intersections in the road network that serve as critical decision points, and then connects them with edges to produce a graph, which can subsequently be used for planning and task-allocation. We demonstrate the approach by mapping roads at a real-life construction site in Norway. The method is validated on four increasingly complex segments of the map. In our tests, the method achieved perfect accuracy in detecting intersections and inferring roads in data with no or low noise, while its performance was reduced in areas with significant noise and consistently missing GPS updates.",
      "authors": [
        "Katarzyna Micha{\\l}owska",
        "Helga Margrete Bodahl Holmestad",
        "Signe Riemer-S{\\o}rensen"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-15T12:53:25+00:00",
          "link": "https://arxiv.org/abs/2402.09919v1",
          "size": "1883kb",
          "version": "v1"
        },
        {
          "date": "2024-04-09T11:41:21+00:00",
          "link": "https://arxiv.org/abs/2402.09919v2",
          "size": "2585kb",
          "version": "v2"
        },
        {
          "date": "2024-10-08T18:36:43+00:00",
          "link": "https://arxiv.org/abs/2402.09919v3",
          "size": "2403kb",
          "version": "v3"
        },
        {
          "date": "2025-07-02T22:21:58+00:00",
          "link": "https://arxiv.org/abs/2402.09919v4",
          "size": "2382kb",
          "version": "v4"
        }
      ],
      "title": "Road Graph Generator: Mapping roads at construction sites from GPS data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.09919",
        "HTML": "https://arxiv.org/html/2402.09919v4",
        "PDF": "https://arxiv.org/pdf/2402.09919"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a method for inferring roads from GPS data, tailored specifically for construction sites, without any relevance to LLM training data processing."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/katarzynamichalowska/road-graph-generator"
      ],
      "source": "arXiv"
    },
    {
      "id": "2403.00155",
      "abstract": "Despite the impressive performance of deep neural networks (DNNs), their computational complexity and storage space consumption have led to the concept of network compression. While DNN compression techniques such as pruning and low-rank decomposition have been extensively studied, there has been insufficient attention paid to their theoretical explanation. In this paper, we propose a novel theoretical framework that leverages a probabilistic latent space of DNN weights and explains the optimal network sparsity by using the information-theoretic divergence measures. We introduce new analogous projected patterns (AP2) and analogous-in-probability projected patterns (AP3) notions for DNNs and prove that there exists a relationship between AP3/AP2 property of layers in the network and its performance. Further, we provide a theoretical analysis that explains the training process of the compressed network. The theoretical results are empirically validated through experiments conducted on standard pre-trained benchmarks, including AlexNet, ResNet50, and VGG16, using CIFAR10 and CIFAR100 datasets. Through our experiments, we highlight the relationship of AP3 and AP2 properties with fine-tuning pruned DNNs and sparsity levels.",
      "authors": [
        "Mahsa Mozafari-Nia and Salimeh Yasaei Sekeh"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-29T22:13:12+00:00",
          "link": "https://arxiv.org/abs/2403.00155v1",
          "size": "8517kb",
          "version": "v1"
        },
        {
          "date": "2025-05-20T17:50:21+00:00",
          "link": "https://arxiv.org/abs/2403.00155v2",
          "size": "4990kb",
          "version": "v2"
        },
        {
          "date": "2025-07-02T18:37:53+00:00",
          "link": "https://arxiv.org/abs/2403.00155v3",
          "size": "4990kb",
          "version": "v3"
        }
      ],
      "title": "Towards Explaining Deep Neural Network Compression Through a Probabilistic Latent Space",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.00155",
        "HTML": "https://arxiv.org/html/2403.00155v3",
        "PDF": "https://arxiv.org/pdf/2403.00155"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper focuses on explaining DNN compression techniques and discusses fine-tuning pruned DNNs, which is related to processing pretrained models but does not introduce novel LLM training data methodologies."
      },
      "tasks": [
        "Neural Network Compression"
      ],
      "source": "arXiv"
    },
    {
      "id": "2403.12335",
      "abstract": "Absence of sufficiently high-quality data often poses a key challenge in data-driven modeling of high-dimensional spatio-temporal dynamical systems. Koopman Autoencoders (KAEs) harness the expressivity of deep neural networks (DNNs), the dimension reduction capabilities of autoencoders, and the spectral properties of the Koopman operator to learn a reduced-order feature space with simpler, linear dynamics. However, the effectiveness of KAEs is hindered by limited and noisy training datasets, leading to poor generalizability. To address this, we introduce the temporally consistent Koopman autoencoder (tcKAE), designed to generate accurate long-term predictions even with limited and noisy training data. This is achieved through a consistency regularization term that enforces prediction coherence across different time steps, thus enhancing the robustness and generalizability of tcKAE over existing models. We provide analytical justification for this approach based on Koopman spectral theory and empirically demonstrate tcKAE's superior performance over state-of-the-art KAE models across a variety of test cases, including simple pendulum oscillations, kinetic plasma, and fluid flow data.",
      "authors": [
        "Indranil Nayak",
        "Ananda Chakrabarty",
        "Mrinal Kumar",
        "Fernando Teixeira",
        "Debdipta Goswami"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-19T00:48:25+00:00",
          "link": "https://arxiv.org/abs/2403.12335v1",
          "size": "2440kb",
          "version": "v1"
        },
        {
          "date": "2025-01-08T04:53:52+00:00",
          "link": "https://arxiv.org/abs/2403.12335v2",
          "size": "8971kb",
          "version": "v2"
        },
        {
          "date": "2025-07-02T23:12:52+00:00",
          "link": "https://arxiv.org/abs/2403.12335v3",
          "size": "8391kb",
          "version": "v3"
        }
      ],
      "title": "Temporally Consistent Koopman Autoencoders for Forecasting Dynamical Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.12335",
        "HTML": "https://arxiv.org/html/2403.12335v3",
        "PDF": "https://arxiv.org/pdf/2403.12335"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses improving forecasting in dynamical systems using KAEs. While it addresses handling noisy data, it does not contribute directly to LLM training data processing."
      },
      "tasks": [
        "Dimensionality Reduction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2403.13836",
      "abstract": "Model-free forecasting of the temporal evolution of chaotic systems is crucial but challenging. Existing solutions require hyperparameter tuning, significantly hindering their wider adoption. In this work, we introduce a tree-based approach not requiring hyperparameter tuning: TreeDOX. It uses time delay overembedding as explicit short-term memory and Extra-Trees Regressors to perform feature reduction and forecasting. We demonstrate the state-of-the-art performance of TreeDOX using the Henon map, Lorenz and Kuramoto-Sivashinsky systems, and the real-world Southern Oscillation Index.",
      "authors": [
        "Adam Giammarese",
        "Kamal Rana",
        "Erik M. Bollt",
        "Nishant Malik"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Dynamical Systems (math.DS)",
        "Chaotic Dynamics (nlin.CD)",
        "Data Analysis, Statistics and Probability (physics.data-an)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-12T01:16:29+00:00",
          "link": "https://arxiv.org/abs/2403.13836v1",
          "size": "6439kb",
          "version": "v1"
        },
        {
          "date": "2025-07-02T22:20:54+00:00",
          "link": "https://arxiv.org/abs/2403.13836v2",
          "size": "22647kb",
          "version": "v2"
        }
      ],
      "title": "Tree-based Learning for High-Fidelity Prediction of Chaos",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.13836",
        "HTML": "https://arxiv.org/html/2403.13836v2",
        "PDF": "https://arxiv.org/pdf/2403.13836"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on tree-based learning for predicting chaotic systems, with no connection to LLM training data collection, processing, or engineering."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2404.05563",
      "abstract": "As part of Mathematical Research Data Initiative (MaRDI), we have developed a way to preserve a software package into an easy to deploy and use sandbox environment we call a \"runtime\", via a program we developed called MaPS : MaRDI Packaging System. The program relies on Linux user namespaces to isolate a library environment from the host system, making the sandboxed software reproducible on other systems, with minimal effort. Moreover an overlay filesystem makes local edits persistent. This project will aid reproducibility efforts of research papers: both mathematical and from other disciplines. As a proof of concept, we provide runtimes for the OSCAR Computer Algebra System, polymake software for research in polyhedral geometry, and VIBRANT Virus Identification By iteRative ANnoTation. The software is in a prerelease state: the interface for creating, deploying, and executing runtimes is final, and an interface for easily publishing runtimes is under active development. We thus propose publishing predefined, distributable software environment runtimes along with research papers in an effort to make research with software based results reproducible.",
      "authors": [
        "Aaruni Kaushik"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Mathematical Software (cs.MS)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-08T14:36:45+00:00",
          "link": "https://arxiv.org/abs/2404.05563v1",
          "size": "26kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T07:52:29+00:00",
          "link": "https://arxiv.org/abs/2404.05563v2",
          "size": "27kb",
          "version": "v2"
        }
      ],
      "title": "Predefined Software Environment Runtimes As A Measure For Reproducibility",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.05563",
        "HTML": "https://arxiv.org/html/2404.05563v2",
        "PDF": "https://arxiv.org/pdf/2404.05563"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses preserving software environments for reproducibility using a packaging system. It does not relate to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2404.10666",
      "abstract": "This paper provides new bounds on the size of spheres in any coordinate-additive metric with a particular focus on improving existing bounds in the sum-rank metric. We derive improved upper and lower bounds based on the entropy of a distribution related to the Boltzmann distribution, which work for any coordinate-additive metric. Additionally, we derive new closed-form upper and lower bounds specifically for the sum-rank metric that outperform existing closed-form bounds.",
      "authors": [
        "Hugo Beeloo-Sauerbier Couv\\'ee",
        "Thomas Jerkovits and Jessica Bariffi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Combinatorics (math.CO)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-16T15:43:02+00:00",
          "link": "https://arxiv.org/abs/2404.10666v1",
          "size": "586kb",
          "version": "v1"
        },
        {
          "date": "2024-10-11T15:38:37+00:00",
          "link": "https://arxiv.org/abs/2404.10666v2",
          "size": "636kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T12:13:17+00:00",
          "link": "https://arxiv.org/abs/2404.10666v3",
          "size": "89kb",
          "version": "v3"
        }
      ],
      "title": "Bounds on Sphere Sizes in the Sum-Rank Metric and Coordinate-Additive Metrics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.10666",
        "PDF": "https://arxiv.org/pdf/2404.10666"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with mathematical bounds in coordinate-additive metrics. It does not address LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2405.02599",
      "abstract": "When we think of model ensembling or ensemble modeling, there are many possibilities that come to mind in different disciplines. For example, one might think of a set of descriptions of a phenomenon in the world, perhaps a time series or a snapshot of multivariate space, and perhaps that set is comprised of data-independent descriptions, or perhaps it is quite intentionally fit *to* data, or even a suite of data sets with a common theme or intention. The very meaning of 'ensemble' - a collection together - conjures different ideas across and even within disciplines approaching phenomena. In this paper, we present a typology of the scope of these potential perspectives. It is not our goal to present a review of terms and concepts, nor is it to convince all disciplines to adopt a common suite of terms, which we view as futile. Rather, our goal is to disambiguate terms, concepts, and processes associated with 'ensembles' and 'ensembling' in order to facilitate communication, awareness, and possible adoption of tools across disciplines.",
      "authors": [
        "Amanda Bleichrodt",
        "Lydia Bourouiba",
        "Gerardo Chowell",
        "Eric T. Lofgren",
        "J. Michael Reed",
        "Sadie J. Ryan",
        "and Nina H. Fefferman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Digital Libraries (cs.DL)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-04T07:49:41+00:00",
          "link": "https://arxiv.org/abs/2405.02599v1",
          "size": "1319kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T09:00:52+00:00",
          "link": "https://arxiv.org/abs/2405.02599v2",
          "size": "685kb",
          "version": "v2"
        }
      ],
      "title": "Assembling ensembling: An adventure in approaches across disciplines",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.02599",
        "PDF": "https://arxiv.org/pdf/2405.02599"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a typology of ensemble modeling across disciplines and focuses on disambiguating related terms. It does not relate to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2405.03449",
      "abstract": "Distributed learning has many computational benefits but is vulnerable to attacks from a subset of devices transmitting incorrect information. This paper investigates Byzantine-resilient algorithms in a decentralized setting, where devices communicate directly in a peer-to-peer manner within a communication network. We leverage the so-called dual approach for decentralized optimization and propose a Byzantine-robust algorithm. We provide convergence guarantees in the average consensus subcase, discuss the potential of the dual approach beyond this subcase, and re-interpret existing algorithms using the dual framework. Lastly, we experimentally show the soundness of our method.",
      "authors": [
        "Renaud Gaucher",
        "Aymeric Dieuleveut",
        "Hadrien Hendrikx"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-06T13:22:54+00:00",
          "link": "https://arxiv.org/abs/2405.03449v1",
          "size": "189kb",
          "version": "v1"
        },
        {
          "date": "2025-07-02T18:12:55+00:00",
          "link": "https://arxiv.org/abs/2405.03449v2",
          "size": "315kb",
          "version": "v2"
        }
      ],
      "title": "Byzantine-Robust Gossip: Insights from a Dual Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.03449",
        "HTML": "https://arxiv.org/html/2405.03449v2",
        "PDF": "https://arxiv.org/pdf/2405.03449"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about Byzantine-robust algorithms in distributed learning, interpreting algorithms using a dual approach. It does not address LLM training data processing or engineering."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2405.05766",
      "abstract": "The increasing reliance on Deep Learning models, combined with their inherent lack of transparency, has spurred the development of a novel field of study known as eXplainable AI (XAI) methods. These methods seek to enhance the trust of end-users in automated systems by providing insights into the rationale behind their decisions. This paper presents a novel trust measure in XAI systems, allowing their refinement. Our proposed metric combines both performance metrics and trust indicators from an objective perspective. To validate this novel methodology, we conducted three case studies showing an improvement respect the state-of-the-art, with an increased sensitiviy to different scenarios.",
      "authors": [
        "Miquel Mir\\'o-Nicolau",
        "Gabriel Moy\\`a-Alcover",
        "Antoni Jaume-i-Cap\\'o",
        "Manuel Gonz\\'alez-Hidalgo",
        "Adel Ghazel",
        "Maria Gemma Sempere Campello",
        "Juan Antonio Palmer Sancho"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-09T13:42:54+00:00",
          "link": "https://arxiv.org/abs/2405.05766v1",
          "size": "33511kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T16:05:44+00:00",
          "link": "https://arxiv.org/abs/2405.05766v2",
          "size": "10052kb",
          "version": "v2"
        }
      ],
      "title": "Towards a Novel Measure of User Trust in XAI Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.05766",
        "HTML": "https://arxiv.org/html/2405.05766v2",
        "PDF": "https://arxiv.org/pdf/2405.05766"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on developing a novel measure of user trust in eXplainable AI systems rather than on training data processing for LLMs."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2405.17435",
      "abstract": "Autonomous systems are becoming increasingly prevalent in new vehicles. Due to their environmental friendliness and their remarkable capability to significantly enhance road safety, these vehicles have gained widespread recognition and acceptance in recent years. Automated Driving Systems (ADS) are intricate systems that incorporate a multitude of sensors and actuators to interact with the environment autonomously, pervasively, and interactively. Consequently, numerous studies are currently underway to keep abreast of these rapid developments. This paper aims to provide a comprehensive overview of recent advancements in ADS technologies. It provides in-depth insights into the detailed information about how data and information flow in the distributed system, including autonomous vehicles and other various supporting services and entities. Data validation and system requirements are emphasised, such as security, privacy, scalability, and data ownership, in accordance with regulatory standards. Finally, several current research directions in the AVs field will be discussed.",
      "authors": [
        "Reem Alhabib",
        "and Poonam Yadav"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-10T10:10:33+00:00",
          "link": "https://arxiv.org/abs/2405.17435v1",
          "size": "1123kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T11:19:09+00:00",
          "link": "https://arxiv.org/abs/2405.17435v2",
          "size": "799kb",
          "version": "v2"
        }
      ],
      "title": "Data Authorisation and Validation in Autonomous Vehicles: A Critical Review",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.17435",
        "HTML": "https://arxiv.org/html/2405.17435v2",
        "PDF": "https://arxiv.org/pdf/2405.17435"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper reviews data authorisation and validation in the context of autonomous vehicles, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2406.07016",
      "abstract": "Large language models (LLMs) like ChatGPT can generate and revise text with human-level performance. These models come with clear limitations: they can produce inaccurate information, reinforce existing biases, and be easily misused. Yet, many scientists use them for their scholarly writing. But how wide-spread is such LLM usage in the academic literature? To answer this question for the field of biomedical research, we present an unbiased, large-scale approach: we study vocabulary changes in over 15 million biomedical abstracts from 2010--2024 indexed by PubMed, and show how the appearance of LLMs led to an abrupt increase in the frequency of certain style words. This excess word analysis suggests that at least 13.5% of 2024 abstracts were processed with LLMs. This lower bound differed across disciplines, countries, and journals, reaching 40% for some subcorpora. We show that LLMs have had an unprecedented impact on scientific writing in biomedical research, surpassing the effect of major world events such as the Covid pandemic.",
      "authors": [
        "Dmitry Kobak",
        "Rita Gonz\\'alez-M\\'arquez",
        "Em\\H{o}ke-\\'Agnes Horv\\'at",
        "Jan Lause"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)",
        "Digital Libraries (cs.DL)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-11T07:16:34+00:00",
          "link": "https://arxiv.org/abs/2406.07016v1",
          "size": "416kb",
          "version": "v1"
        },
        {
          "date": "2024-07-03T09:53:27+00:00",
          "link": "https://arxiv.org/abs/2406.07016v2",
          "size": "424kb",
          "version": "v2"
        },
        {
          "date": "2025-02-14T11:01:27+00:00",
          "link": "https://arxiv.org/abs/2406.07016v3",
          "size": "4199kb",
          "version": "v3"
        },
        {
          "date": "2025-02-19T22:15:24+00:00",
          "link": "https://arxiv.org/abs/2406.07016v4",
          "size": "424kb",
          "version": "v4"
        },
        {
          "date": "2025-07-03T08:26:13+00:00",
          "link": "https://arxiv.org/abs/2406.07016v5",
          "size": "4199kb",
          "version": "v5"
        }
      ],
      "title": "Delving into LLM-assisted writing in biomedical publications through excess vocabulary",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.07016",
        "HTML": "https://arxiv.org/html/2406.07016v5",
        "PDF": "https://arxiv.org/pdf/2406.07016"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper investigates the use of LLMs in modifying biomedical writing, with a focus on identifying LLM-processed texts, highlighting data processing aspects related to LLMs."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/berenslab/chatgpt-excess-words"
      ],
      "source": "arXiv"
    },
    {
      "id": "2406.10576",
      "abstract": "Recent Large-Language Models (LLMs) pruning methods typically operate at the post-training phase without the expensive weight finetuning, however, their pruning criteria often rely on heuristically hand-crafted metrics, potentially leading to suboptimal performance. We instead propose a novel optimization-based structural pruning that learns the pruning masks in a probabilistic space directly by optimizing the loss of the pruned model. To preserve efficiency, our method eliminates the back-propagation through the LLM per se during optimization, requiring only the forward pass of the LLM. We achieve this by learning an underlying Bernoulli distribution to sample binary pruning masks, where we decouple the Bernoulli parameters from LLM loss, facilitating efficient optimization via policy gradient estimator without back-propagation. Thus, our method can 1) support global and heterogeneous pruning (i.e., automatically determine different redundancy for different layers), and 2) optionally initialize with a metric-based method (for our Bernoulli distributions). Extensive experiments conducted on LLaMA, LLaMA-2, LLaMA-3, Vicuna, and Mistral models using the C4 and WikiText2 datasets demonstrate the promising performance of our method in efficiency and effectiveness. Code is available at https://github.com/ethanygao/backprop-free_LLM_pruning.",
      "authors": [
        "Yuan Gao",
        "Zujing Liu",
        "Weizhong Zhang",
        "Bo Du",
        "Gui-Song Xia"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-15T09:31:03+00:00",
          "link": "https://arxiv.org/abs/2406.10576v1",
          "size": "1078kb",
          "version": "v1"
        },
        {
          "date": "2024-10-21T13:39:32+00:00",
          "link": "https://arxiv.org/abs/2406.10576v2",
          "size": "2065kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T04:28:09+00:00",
          "link": "https://arxiv.org/abs/2406.10576v3",
          "size": "220kb",
          "version": "v3"
        }
      ],
      "title": "Bypass Back-propagation: Optimization-based Structural Pruning for Large Language Models via Policy Gradient",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.10576",
        "HTML": "https://arxiv.org/html/2406.10576v3",
        "PDF": "https://arxiv.org/pdf/2406.10576"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on structural pruning of large language models to optimize pruning masks using policy gradient methods, which is unrelated to the processing of LLM training data."
      },
      "tasks": [
        "Network Pruning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.03133",
      "abstract": "The growing interest in fair AI development is evident. The ''Leave No One Behind'' initiative urges us to address multiple and intersecting forms of inequality in accessing services, resources, and opportunities, emphasising the significance of fairness in AI. This is particularly relevant as an increasing number of AI tools are applied to decision-making processes, such as resource allocation and service scheme development, across various sectors such as health, energy, and housing. Therefore, exploring joint inequalities in these sectors is significant and valuable for thoroughly understanding overall inequality and unfairness. This research introduces an innovative approach to quantify cross-sectoral intersecting discrepancies among user-defined groups using latent class analysis. These discrepancies can be used to approximate inequality and provide valuable insights to fairness issues. We validate our approach using both proprietary and public datasets, including both EVENS and Census 2021 (England & Wales) datasets, to examine cross-sectoral intersecting discrepancies among different ethnic groups. We also verify the reliability of the quantified discrepancy by conducting a correlation analysis with a government public metric. Our findings reveal significant discrepancies both among minority ethnic groups and between minority ethnic groups and non-minority ethnic groups, emphasising the need for targeted interventions in policy-making processes. Furthermore, we demonstrate how the proposed approach can provide valuable insights into ensuring fairness in machine learning systems.",
      "authors": [
        "Yingfang Yuan",
        "Kefan Chen",
        "Mehdi Rizvi",
        "Lynne Baillie",
        "Wei Pang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-24T08:10:31+00:00",
          "link": "https://arxiv.org/abs/2407.03133v1",
          "size": "1382kb",
          "version": "v1"
        },
        {
          "date": "2024-07-11T09:19:11+00:00",
          "link": "https://arxiv.org/abs/2407.03133v2",
          "size": "1382kb",
          "version": "v2"
        },
        {
          "date": "2025-02-08T19:28:05+00:00",
          "link": "https://arxiv.org/abs/2407.03133v3",
          "size": "2150kb",
          "version": "v3"
        },
        {
          "date": "2025-07-03T16:18:29+00:00",
          "link": "https://arxiv.org/abs/2407.03133v4",
          "size": "496kb",
          "version": "v4"
        }
      ],
      "title": "Quantifying the Cross-sectoral Intersecting Discrepancies within Multiple Groups Using Latent Class Analysis Towards Fairness",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.03133",
        "HTML": "https://arxiv.org/html/2407.03133v4",
        "PDF": "https://arxiv.org/pdf/2407.03133"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses fairness in AI through latent class analysis of cross-sectoral discrepancies, focusing on inequalities, which does not pertain to LLM data processing."
      },
      "tasks": [
        "Decision Making",
        "Fairness"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.16206",
      "abstract": "Haptic sciences and technologies benefit greatly from comprehensive datasets that capture tactile stimuli under controlled, systematic conditions. However, existing haptic databases collect data through uncontrolled exploration, which hinders the systematic analysis of how motion parameters (e.g., motion direction and velocity) influence tactile perception. This paper introduces Cluster Haptic Texture Database, a multimodal dataset recorded using a 3-axis machine with an artificial finger to precisely control sliding velocity and direction. The dataset encompasses 118 textured surfaces across 9 material categories, with recordings at 5 velocity levels (20-60 mm/s) and 8 directions. Each surface was tested under 160 conditions, yielding 18,880 synchronized recordings of audio, acceleration, force, position, and visual data. Validation using convolutional neural networks demonstrates classification accuracies of 96% for texture recognition, 88.76% for velocity estimation, and 78.79% for direction estimation, confirming the dataset's utility for machine learning applications. This resource enables research in haptic rendering, texture recognition algorithms, and human tactile perception mechanisms, supporting the development of realistic haptic interfaces for virtual reality systems and robotic applications.",
      "authors": [
        "Michikuni Eguchi",
        "Tomohiro Hayase",
        "Yuichi Hiroi",
        "Takefumi Hiraki"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-23T06:18:10+00:00",
          "link": "https://arxiv.org/abs/2407.16206v1",
          "size": "5360kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T04:46:19+00:00",
          "link": "https://arxiv.org/abs/2407.16206v2",
          "size": "10562kb",
          "version": "v2"
        }
      ],
      "title": "Cluster Haptic Texture Database: Haptic Texture Database with Varied Velocity-Direction Sliding Contacts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.16206",
        "HTML": "https://arxiv.org/html/2407.16206v2",
        "PDF": "https://arxiv.org/pdf/2407.16206"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a dataset for haptic texture recognition, focusing on tactile data with varied velocity-direction scenarios. It targets machine learning applications in haptics, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2407.16985",
      "abstract": "Recently, introducing Tensor Decomposition (TD) techniques into unsupervised feature selection (UFS) has been an emerging research topic. A tensor structure is beneficial for mining the relations between different modes and helps relieve the computation burden. However, while existing methods exploit TD to preserve the data tensor structure, they do not consider the influence of data orientation and thus have difficulty in handling orientation-specific data such as time series. To solve the above problem, we utilize the orientation-dependent tensor-tensor product from Tensor Singular Value Decomposition based on *M-product (T-SVDM) and extend the one-dimensional Sparse Principal Component Analysis (SPCA) to a tensor form. The proposed sparse tensor PCA model can constrain sparsity at the specified mode and yield sparse tensor principal components, enhancing flexibility and accuracy in learning feature relations. To ensure fast convergence and a flexible description of feature correlation, we develop a convex version specially designed for general UFS tasks and propose an efficient slice-by-slice algorithm that performs dual optimization in the transform domain. Experimental results on real-world datasets demonstrate the effectiveness and remarkable computational efficiency of the proposed method for tensor data of diverse structures over the state-of-the-art. When transform axes align with feature distribution patterns, our method is promising for various applications. The codes related to our proposed methods and the experiments are available at https://github.com/zjj20212035/STPCA.git.",
      "authors": [
        "Junjing Zheng",
        "Xinyu Zhang",
        "Weidong Jiang",
        "Xiangfeng Qiu",
        "Mingjian Ren"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-24T04:04:56+00:00",
          "link": "https://arxiv.org/abs/2407.16985v1",
          "size": "3743kb",
          "version": "v1"
        },
        {
          "date": "2025-03-24T09:55:59+00:00",
          "link": "https://arxiv.org/abs/2407.16985v2",
          "size": "8018kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T13:34:01+00:00",
          "link": "https://arxiv.org/abs/2407.16985v3",
          "size": "6934kb",
          "version": "v3"
        }
      ],
      "title": "Orientation-Aware Sparse Tensor PCA for Efficient Unsupervised Feature Selection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.16985",
        "HTML": "https://arxiv.org/html/2407.16985v3",
        "PDF": "https://arxiv.org/pdf/2407.16985"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on sparse tensor PCA for feature selection and tensor decomposition, which pertains to unsupervised learning and feature analysis, not directly to LLM training data engineering or processing."
      },
      "tasks": [
        "feature selection",
        "Tensor Decomposition"
      ],
      "repo_urls": [
        "https://github.com/zjj20212035/stpca"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.18038",
      "abstract": "Semantic segmentation and stereo matching, respectively analogous to the ventral and dorsal streams in our human brain, are two key components of autonomous driving perception systems. Addressing these two tasks with separate networks is no longer the mainstream direction in developing computer vision algorithms, particularly with the recent advances in large vision models and embodied artificial intelligence. The trend is shifting towards combining them within a joint learning framework, especially emphasizing feature sharing between the two tasks. The major contributions of this study lie in comprehensively tightening the coupling between semantic segmentation and stereo matching. Specifically, this study introduces three novelties: (1) a tightly coupled, gated feature fusion strategy, (2) a hierarchical deep supervision strategy, and (3) a coupling tightening loss function. The combined use of these technical contributions results in TiCoSS, a state-of-the-art joint learning framework that simultaneously tackles semantic segmentation and stereo matching. Through extensive experiments on the KITTI and vKITTI2 datasets, along with qualitative and quantitative analyses, we validate the effectiveness of our developed strategies and loss function, and demonstrate its superior performance compared to prior arts, with a notable increase in mIoU by over 9%. Our source code will be publicly available at mias.group/TiCoSS upon publication.",
      "authors": [
        "Guanfeng Tang",
        "Zhiyuan Wu",
        "Jiahang Li",
        "Ping Zhong",
        "We Ye",
        "Xieyuanli Chen",
        "Huiming Lu and Rui Fan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-25T13:31:55+00:00",
          "link": "https://arxiv.org/abs/2407.18038v1",
          "size": "11694kb",
          "version": "v1"
        },
        {
          "date": "2024-08-29T02:05:04+00:00",
          "link": "https://arxiv.org/abs/2407.18038v2",
          "size": "17030kb",
          "version": "v2"
        },
        {
          "date": "2024-09-10T13:48:23+00:00",
          "link": "https://arxiv.org/abs/2407.18038v3",
          "size": "16532kb",
          "version": "v3"
        },
        {
          "date": "2025-07-03T07:04:05+00:00",
          "link": "https://arxiv.org/abs/2407.18038v4",
          "size": "3939kb",
          "version": "v4"
        }
      ],
      "title": "TiCoSS: Tightening the Coupling between Semantic Segmentation and Stereo Matching within A Joint Learning Framework",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.18038",
        "HTML": "https://arxiv.org/html/2407.18038v4",
        "PDF": "https://arxiv.org/pdf/2407.18038"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research centers on semantic segmentation and stereo matching within computer vision, addressing perception in autonomous systems, not on LLM training data methods or processes."
      },
      "tasks": [
        "Autonomous Driving",
        "Segmentation",
        "Semantic Segmentation",
        "Stereo Matching"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.01119",
      "abstract": "Prompt tuning is an efficient solution for training large language models (LLMs). However, current soft-prompt-based methods often sacrifice multi-task modularity, requiring the training process to be fully or partially repeated for each newly added task. While recent work on task vectors applied arithmetic operations on full model weights to achieve the desired multi-task performance, a similar approach for soft-prompts is still missing. To this end, we introduce Task Prompt Vectors, created by element-wise difference between weights of tuned soft-prompts and their random initialization. Experimental results on 12 NLU datasets show that task prompt vectors can be used in low-resource settings to effectively initialize prompt tuning on similar tasks. In addition, we show that task prompt vectors are independent of the random initialization of prompt tuning on 2 different language model architectures. This allows prompt arithmetics with the pre-trained vectors from different tasks. In this way, we provide a competitive alternative to state-of-the-art baselines by arithmetic addition of task prompt vectors from multiple tasks.",
      "authors": [
        "Robert Belanec",
        "Simon Ostermann",
        "Ivan Srba",
        "Maria Bielikova"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-02T09:00:03+00:00",
          "link": "https://arxiv.org/abs/2408.01119v1",
          "size": "3406kb",
          "version": "v1"
        },
        {
          "date": "2024-10-23T14:37:50+00:00",
          "link": "https://arxiv.org/abs/2408.01119v2",
          "size": "3410kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T09:32:20+00:00",
          "link": "https://arxiv.org/abs/2408.01119v3",
          "size": "1438kb",
          "version": "v3"
        }
      ],
      "title": "Task Prompt Vectors: Effective Initialization through Multi-Task Soft-Prompt Transfer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.01119",
        "HTML": "https://arxiv.org/html/2408.01119v3",
        "PDF": "https://arxiv.org/pdf/2408.01119"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses prompt tuning for LLMs, focusing on a novel method (Task Prompt Vectors) to improve prompt initialization across tasks. While it addresses the use of pre-trained vectors for data processing, it does not focus primarily on the construction or processing of training data itself."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.01152",
      "abstract": "Vertical Take-Off and Landing (VTOL) vehicles are gaining traction in both the delivery drone market and passenger transportation, driving the development of Urban Air Mobility (UAM) systems. UAM seeks to alleviate road congestion in dense urban areas by leveraging urban airspace. To handle UAM traffic, vertiport terminals (vertiminals) play a critical role in supporting VTOL vehicle operations such as take-offs, landings, taxiing, passenger boarding, refueling or charging, and maintenance. Efficient scheduling algorithms are essential to manage these operations and optimize vertiminal throughput while ensuring safety protocols. Unlike fixed-wing aircraft, which rely on runways for take-off and climbing in fixed directions, VTOL vehicles can utilize multiple surface directions for climbing and approach. This flexibility necessitates specialized scheduling methods. We propose a Mixed Integer Linear Program (MILP) formulation to holistically optimize vertiminal operations, including taxiing, climbing (or approach) using multiple directions, and turnaround at gates. The proposed MILP reduces delays by up to 50%. Additionally, we derive equations to compute upper bounds of the throughput capacity of vertiminals, considering its core elements: the TLOF pad system, taxiway system, and gate system. Our results demonstrate that the MILP achieves throughput levels consistent with the theoretical maximum derived from these equations. We also validate our framework through a case study using a well-established vertiminal topology from the literature. Our MILP can be used to find the optimal configuration of vertiminal. This dual approach, MILP and throughput analysis, allows for comprehensive capacity analysis without requiring simulations while enabling efficient scheduling through the MILP formulation.",
      "authors": [
        "Ravi Raj Saxena",
        "T.V. Prabhakar",
        "Joy Kuri",
        "Manogna Yadav"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Emerging Technologies (cs.ET)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-02T10:11:41+00:00",
          "link": "https://arxiv.org/abs/2408.01152v1",
          "size": "8102kb",
          "version": "v1"
        },
        {
          "date": "2024-08-05T08:00:01+00:00",
          "link": "https://arxiv.org/abs/2408.01152v2",
          "size": "8102kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T14:52:30+00:00",
          "link": "https://arxiv.org/abs/2408.01152v3",
          "size": "3452kb",
          "version": "v3"
        }
      ],
      "title": "Vertiport Terminal Scheduling and Throughput Analysis for Multiple Surface Directions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.01152",
        "HTML": "https://arxiv.org/html/2408.01152v3",
        "PDF": "https://arxiv.org/pdf/2408.01152"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on scheduling and throughput analysis for VTOL vehicles in urban air mobility systems using a Mixed Integer Linear Program (MILP). It is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2408.05920",
      "abstract": "Urban region representation is crucial for various urban downstream tasks. However, despite the proliferation of methods and their success, acquiring general urban region knowledge and adapting to different tasks remains challenging. Existing work pays limited attention to the fine-grained functional layout semantics in urban regions, limiting their ability to capture transferable knowledge across regions. Further, inadequate handling of the unique features and relationships required for different downstream tasks may also hinder effective task adaptation. In this paper, we propose a $\\textbf{G}$raph-based $\\textbf{U}$rban $\\textbf{R}$egion $\\textbf{P}$re-training and $\\textbf{P}$rompting framework ($\\textbf{GURPP}$) for region representation learning. Specifically, we first construct an urban region graph and develop a subgraph-centric urban region pre-training model to capture the heterogeneous and transferable patterns of entity interactions. This model pre-trains knowledge-rich region embeddings using contrastive learning and multi-view learning methods. To further refine these representations, we design two graph-based prompting methods: a manually-defined prompt to incorporate explicit task knowledge and a task-learnable prompt to discover hidden knowledge, which enhances the adaptability of these embeddings to different tasks. Extensive experiments on various urban region prediction tasks and different cities demonstrate the superior performance of our framework.",
      "authors": [
        "Jiahui Jin",
        "Yifan Song",
        "Dong Kan",
        "Haojia Zhu",
        "Xiangguo Sun",
        "Zhicheng Li",
        "Xigang Sun and Jinghui Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-12T05:00:23+00:00",
          "link": "https://arxiv.org/abs/2408.05920v1",
          "size": "1791kb",
          "version": "v1"
        },
        {
          "date": "2024-08-22T15:56:34+00:00",
          "link": "https://arxiv.org/abs/2408.05920v2",
          "size": "1772kb",
          "version": "v2"
        },
        {
          "date": "2024-08-26T11:41:28+00:00",
          "link": "https://arxiv.org/abs/2408.05920v3",
          "size": "1772kb",
          "version": "v3"
        },
        {
          "date": "2025-07-03T17:57:36+00:00",
          "link": "https://arxiv.org/abs/2408.05920v4",
          "size": "3573kb",
          "version": "v4"
        }
      ],
      "title": "Urban Region Pre-training and Prompting: A Graph-based Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.05920",
        "HTML": "https://arxiv.org/html/2408.05920v4",
        "PDF": "https://arxiv.org/pdf/2408.05920"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a graph-based framework for urban region representation learning, which involves pre-training and prompting methods for capturing urban region knowledge. It does not relate to LLM training data."
      },
      "tasks": [
        "Representation Learning"
      ],
      "repo_urls": [
        "https://github.com/sheldonresearch/ProG"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.05945",
      "abstract": "The rise of autonomous vehicles has significantly increased the demand for robust 3D object detection systems. While cameras and LiDAR sensors each offer unique advantages--cameras provide rich texture information and LiDAR offers precise 3D spatial data--relying on a single modality often leads to performance limitations. This paper introduces MV2DFusion, a multi-modal detection framework that integrates the strengths of both worlds through an advanced query-based fusion mechanism. By introducing an image query generator to align with image-specific attributes and a point cloud query generator, MV2DFusion effectively combines modality-specific object semantics without biasing toward one single modality. Then the sparse fusion process can be accomplished based on the valuable object semantics, ensuring efficient and accurate object detection across various scenarios. Our framework's flexibility allows it to integrate with any image and point cloud-based detectors, showcasing its adaptability and potential for future advancements. Extensive evaluations on the nuScenes and Argoverse2 datasets demonstrate that MV2DFusion achieves state-of-the-art performance, particularly excelling in long-range detection scenarios.",
      "authors": [
        "Zitian Wang",
        "Zehao Huang",
        "Yulu Gao",
        "Naiyan Wang",
        "Si Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-12T06:46:05+00:00",
          "link": "https://arxiv.org/abs/2408.05945v1",
          "size": "2374kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T05:37:48+00:00",
          "link": "https://arxiv.org/abs/2408.05945v2",
          "size": "2073kb",
          "version": "v2"
        }
      ],
      "title": "MV2DFusion: Leveraging Modality-Specific Object Semantics for Multi-Modal 3D Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.05945",
        "HTML": "https://arxiv.org/html/2408.05945v2",
        "PDF": "https://arxiv.org/pdf/2408.05945"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a multi-modal 3D detection framework (MV2DFusion) for autonomous vehicles, combining image and LiDAR data. It is unrelated to LLM training data processing."
      },
      "tasks": [
        "3D Object Detection",
        "Autonomous Vehicles",
        "Object",
        "object-detection",
        "Object Detection",
        "Robust 3D Object Detection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.13819",
      "abstract": "In this paper, we study the Eulerian Strong Component Arc Deletion problem, where the input is a directed multigraph and the goal is to delete the minimum number of arcs to ensure every strongly connected component of the resulting digraph is Eulerian. This problem is a natural extension of the Directed Feedback Arc Set problem and is also known to be motivated by certain scenarios arising in the study of housing markets. The complexity of the problem, when parameterized by solution size (i.e., size of the deletion set), has remained unresolved and has been highlighted in several papers. In this work, we answer this question by ruling out (subject to the usual complexity assumptions) a fixed-parameter tractable (FPT) algorithm for this parameter and conduct a broad analysis of the problem with respect to other natural parameterizations. We prove both positive and negative results. Among these, we demonstrate that the problem is also hard (W[1]-hard or even para-NP-hard) when parameterized by either treewidth or maximum degree alone. Complementing our lower bounds, we establish that the problem is in XP when parameterized by treewidth and FPT when parameterized either by both treewidth and maximum degree or by both treewidth and solution size. We show that these algorithms have near-optimal asymptotic dependence on the treewidth assuming the Exponential Time Hypothesis.",
      "authors": [
        "V\\'aclav Bla\\v{z}ej",
        "Satyabrata Jana",
        "M. S. Ramanujan",
        "Peter Strulo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-25T12:23:06+00:00",
          "link": "https://arxiv.org/abs/2408.13819v1",
          "size": "268kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T15:25:57+00:00",
          "link": "https://arxiv.org/abs/2408.13819v2",
          "size": "184kb",
          "version": "v2"
        }
      ],
      "title": "On the Parameterized Complexity of Eulerian Strong Component Arc Deletion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.13819",
        "HTML": "https://arxiv.org/html/2408.13819v2",
        "PDF": "https://arxiv.org/pdf/2408.13819"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses the complexity of the Eulerian Strong Component Arc Deletion problem, a graph theory problem, which is not related to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2408.15026",
      "abstract": "Echocardiography is an essential medical technique for diagnosing cardiovascular diseases, but its high operational complexity has led to a shortage of trained professionals. To address this issue, we introduce a novel probe movement guidance algorithm that has the potential to be applied in guiding robotic systems or novices with probe pose adjustment for high-quality standard plane image acquisition.Cardiac ultrasound faces two major challenges: (1) the inherently complex structure of the heart, and (2) significant individual variations. Previous works have only learned the population-averaged structure of the heart rather than personalized cardiac structures, leading to a performance bottleneck. Clinically, we observe that sonographers dynamically adjust their interpretation of a patient's cardiac anatomy based on prior scanning sequences, consequently refining their scanning strategies. Inspired by this, we propose a novel sequence-aware self-supervised pre-training method. Specifically, our approach learns personalized three-dimensional cardiac structural features by predicting the masked-out image features and probe movement actions in a scanning sequence. We hypothesize that if the model can predict the missing content it has acquired a good understanding of personalized cardiac structure. Extensive experiments on a large-scale expert scanning dataset with 1.31 million samples demonstrate that our proposed sequence-aware paradigm can effectively reduce probe guidance errors compared to other advanced baseline methods. Our code will be released after acceptance.",
      "authors": [
        "Haojun Jiang",
        "Teng Wang",
        "Zhenguo Sun",
        "Yulin Wang",
        "Yang Yue",
        "Yu Sun",
        "Ning Jia",
        "Meng Li",
        "Shaqi Luo",
        "Shiji Song",
        "Gao Huang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-27T12:55:54+00:00",
          "link": "https://arxiv.org/abs/2408.15026v1",
          "size": "22165kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T08:38:13+00:00",
          "link": "https://arxiv.org/abs/2408.15026v2",
          "size": "12461kb",
          "version": "v2"
        }
      ],
      "title": "Sequence-aware Pre-training for Echocardiography Probe Movement Guidance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.15026",
        "HTML": "https://arxiv.org/html/2408.15026v2",
        "PDF": "https://arxiv.org/pdf/2408.15026"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a sequence-aware pre-training technique for echocardiography, mentioning large-scale data usage. However, it does not propose new methods for LLM training data processing or engineering."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2409.00034",
      "abstract": "This work introduces Neural CRNs, a general-purpose chemical neural network framework that embeds learning directly into mass-action chemical reaction systems. Unlike prior approaches that chemically implement and compose discrete neural computations, Neural CRNs adopt an analog computing approach, where both forward and backward passes of learning are implemented as continuous-time evolutions of molecular concentrations. Such an analog formulation naturally aligns with the analog nature of chemical kinetics, yielding concise circuits and practicable reactions. We demonstrate this efficiency by constructing a streamlined supervised learning procedure executable in just two sequential stages. We then implement several learning circuits to demonstrate the framework's linear and nonlinear modeling capabilities and to validate its learning procedure. These circuits are implemented entirely using unimolecular and bimolecular reactions, avoiding the complexity of higher-order chemistries. In summary, Neural CRNs offer a compact, scalable, and autonomous framework for biochemical learning, opening new avenues for adaptive computing in synthetic biology, bioengineering, and biomedicine.",
      "authors": [
        "Rajiv Teja Nagipogu",
        "John H. Reif"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-18T01:43:26+00:00",
          "link": "https://arxiv.org/abs/2409.00034v1",
          "size": "7441kb",
          "version": "v1"
        },
        {
          "date": "2025-02-27T16:18:40+00:00",
          "link": "https://arxiv.org/abs/2409.00034v2",
          "size": "14832kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T04:34:00+00:00",
          "link": "https://arxiv.org/abs/2409.00034v3",
          "size": "11120kb",
          "version": "v3"
        }
      ],
      "title": "Neural CRNs: A Natural Implementation of Learning in Chemical Reaction Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.00034",
        "HTML": "https://arxiv.org/html/2409.00034v3",
        "PDF": "https://arxiv.org/pdf/2409.00034"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes Neural CRNs, a framework for embedding learning into chemical reaction networks, with no focus on LLM training data processing."
      },
      "tasks": [
        "Multi-class Classification"
      ],
      "repo_urls": [
        "https://github.com/rajiv256/NeuralCRNGen"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.03782",
      "abstract": "Refurbishing laptops extends their lives while contributing to reducing electronic waste, which promotes building a sustainable future. To this end, the Danish Technological Institute (DTI) focuses on the research and development of several robotic applications empowered with software, including laptop refurbishing. Cleaning represents a major step in refurbishing and involves identifying and removing stickers from laptop surfaces. Software plays a crucial role in the cleaning process. For instance, the software integrates various object detection models to identify and remove stickers from laptops automatically. However, given the diversity in types of stickers (e.g., shapes, colors, locations), identification of the stickers is highly uncertain, thereby requiring explicit quantification of uncertainty associated with the identified stickers. Such uncertainty quantification can help reduce risks in removing stickers, which, for example, could otherwise result in software faults damaging laptop surfaces. For uncertainty quantification, we adopted the Monte Carlo Dropout method to evaluate six sticker detection models (SDMs) from DTI using three datasets: the original image dataset from DTI and two datasets generated with vision language models, i.e., DALL-E-3 and Stable Diffusion-3. In addition, we presented novel robustness metrics concerning detection accuracy and uncertainty to assess the robustness of the SDMs based on adversarial datasets generated from the three datasets using a dense adversary method.\n  Our evaluation results show that different SDMs perform differently regarding different metrics. Based on the results, we provide SDM selection guidelines and lessons learned from various perspectives.",
      "authors": [
        "Chengjie Lu",
        "Jiahui Wu",
        "Shaukat Ali",
        "Mikkel Labori Olsen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-22T12:36:09+00:00",
          "link": "https://arxiv.org/abs/2409.03782v1",
          "size": "1024kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T07:32:14+00:00",
          "link": "https://arxiv.org/abs/2409.03782v2",
          "size": "2820kb",
          "version": "v2"
        }
      ],
      "title": "Assessing the Uncertainty and Robustness of the Laptop Refurbishing Software",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.03782",
        "HTML": "https://arxiv.org/html/2409.03782v2",
        "PDF": "https://arxiv.org/pdf/2409.03782"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses software for refurbishing laptops with emphasis on object detection and uncertainty quantification, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.06416",
      "abstract": "Much of the cost and effort required during the software testing process is invested in performing test maintenance - the addition, removal, or modification of test cases to keep the test suite in sync with the system-under-test or to otherwise improve its quality. Tool support could reduce the cost - and improve the quality - of test maintenance by automating aspects of the process or by providing guidance and support to developers.\n  In this study, we explore the capabilities and applications of large language models (LLMs) - complex machine learning models adapted to textual analysis - to support test maintenance. We conducted a case study at Ericsson AB where we explore the triggers that indicate the need for test maintenance, the actions that LLMs can take, and the considerations that must be made when deploying LLMs in an industrial setting. We also propose and demonstrate a multi-agent architecture that can predict which tests require maintenance following a change to the source code. Collectively, these contributions advance our theoretical and practical understanding of how LLMs can be deployed to benefit industrial test maintenance processes.",
      "authors": [
        "Jingxiong Liu",
        "Ludvig Lemner",
        "Linnea Wahlgren",
        "Gregory Gay",
        "Nasser Mohammadiha",
        "Joakim Wennerberg"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-10T10:55:48+00:00",
          "link": "https://arxiv.org/abs/2409.06416v1",
          "size": "2537kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T07:06:08+00:00",
          "link": "https://arxiv.org/abs/2409.06416v2",
          "size": "1352kb",
          "version": "v2"
        }
      ],
      "title": "Exploring the Integration of Large Language Models in Industrial Test Maintenance Processes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.06416",
        "HTML": "https://arxiv.org/html/2409.06416v2",
        "PDF": "https://arxiv.org/pdf/2409.06416"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The study explores the use of LLMs in industrial test maintenance, mentioning textual analysis but not specifically detailing LLM training data processing innovations."
      },
      "tasks": [
        "software testing"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.07167",
      "abstract": "The combination of Oblivious RAM (ORAM) with Trusted Execution Environments (TEE) has found numerous real-world applications due to their complementary nature. TEEs alleviate the performance bottlenecks of ORAM, such as network bandwidth and roundtrip latency, and ORAM provides general-purpose protection for TEE applications against attacks exploiting memory access patterns. The defining property of this combination, which sets it apart from traditional ORAM designs, is its ability to ensure that memory accesses, both inside and outside of TEEs, are made oblivious, thus termed doubly oblivious RAM (O$_2$RAM). Efforts to develop O$_2$RAM with enhanced performance are ongoing.\n  In this work, we propose H$_2$O$_2$RAM, a high-performance doubly oblivious RAM construction. The distinguishing feature of our approach, compared to the existing tree-based doubly oblivious designs, is its first adoption of the hierarchical framework that enjoys inherently better data locality and parallelization. While the latest hierarchical solution, FutORAMa, achieves concrete efficiency in the classic client-server model by leveraging a relaxed assumption of sublinear-sized client-side private memory, adapting it to our scenario poses challenges due to the conflict between this relaxed assumption and our doubly oblivious requirement. To this end, we introduce several new efficient oblivious components to build a high-performance hierarchical O$_2$RAM (H$_2$O$_2$RAM). We implement our design and evaluate it on various scenarios. The results indicate that H$_2$O$_2$RAM reduces execution time by up to $\\sim 10^3$ times and saves memory usage by $5\\sim44$ times compared to state-of-the-art solutions.",
      "authors": [
        "Leqian Zheng",
        "Zheng Zhang",
        "Wentao Dong",
        "Yao Zhang",
        "Ye Wu",
        "Cong Wang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-11T10:31:14+00:00",
          "link": "https://arxiv.org/abs/2409.07167v1",
          "size": "577kb",
          "version": "v1"
        },
        {
          "date": "2025-01-31T04:28:30+00:00",
          "link": "https://arxiv.org/abs/2409.07167v2",
          "size": "119kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T13:00:57+00:00",
          "link": "https://arxiv.org/abs/2409.07167v3",
          "size": "94kb",
          "version": "v3"
        }
      ],
      "title": "H$_2$O$_2$RAM: A High-Performance Hierarchical Doubly Oblivious RAM",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.07167",
        "PDF": "https://arxiv.org/pdf/2409.07167"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about a hierarchical doubly oblivious RAM construction, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.08290",
      "abstract": "Spiking Neural Networks (SNNs) promise higher energy efficiency over conventional Quantized Artificial Neural Networks (QNNs) due to their event-driven, spike-based computation. However, prevailing energy evaluations often oversimplify, focusing on computational aspects while neglecting critical overheads like comprehensive data movement and memory access. Such simplifications can lead to misleading conclusions regarding the true energy benefits of SNNs. This paper presents a rigorous re-evaluation. We establish a fair baseline by mapping rate-encoded SNNs with $T$ timesteps to functionally equivalent QNNs with $\\lceil \\log_2(T+1) \\rceil$ bits. This ensures both models have comparable representational capacities, as well has similar hardware requirement, enabling meaningful energy comparisons. We introduce a detailed analytical energy model encompassing core computation and data movement (sparse and dense activations, weights). Using this model, we systematically explore a wide parameter space, including intrinsic network characteristics ($T$, spike rate $s_r$, QNN sparsity $\\gamma$, model size $N$, weight bit-level) and hardware characteristics (memory system and network-on-chip). Our analysis identifies specific operational regimes where SNNs genuinely offer superior energy efficiency. For example, under typical neuromorphic hardware conditions, SNNs with moderate time windows ($T \\in [5,10]$) require an average spike rate ($s_r$) below 6.4% to outperform equivalent QNNs. These insights guide the design of genuinely energy-efficient neural network solutions.",
      "authors": [
        "Zhanglu Yan",
        "Zhenyu Bai",
        "Weng-Fai Wong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-29T07:00:35+00:00",
          "link": "https://arxiv.org/abs/2409.08290v1",
          "size": "2765kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T10:37:52+00:00",
          "link": "https://arxiv.org/abs/2409.08290v2",
          "size": "12391kb",
          "version": "v2"
        }
      ],
      "title": "Reconsidering the energy efficiency of spiking neural networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.08290",
        "PDF": "https://arxiv.org/pdf/2409.08290"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on comparing the energy efficiency of Spiking Neural Networks (SNNs) and Quantized Neural Networks (QNNs), with no mention or contribution towards LLM training data processing or data engineering."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2409.09676",
      "abstract": "We present \\textit{Nebula}, a system for differentially private histogram estimation on data distributed among clients. \\textit{Nebula} allows clients to independently decide whether to participate in the system, and locally encode their data so that an untrusted server only learns data values whose multiplicity exceeds a predefined aggregation threshold, with $(\\varepsilon,\\delta)$ differential privacy guarantees. Compared to existing systems, \\textit{Nebula} uniquely achieves: \\textit{i)} a strict upper bound on client privacy leakage; \\textit{ii)} significantly higher utility than standard local differential privacy systems; and \\textit{iii)} no requirement for trusted third-parties, multi-party computation, or trusted hardware. We provide a formal evaluation of \\textit{Nebula}'s privacy, utility and efficiency guarantees, along with an empirical assessment on three real-world datasets. On the United States Census dataset, clients can submit their data in just 0.0036 seconds and 0.0016 MB (\\textbf{efficient}), under strong $(\\varepsilon=1,\\delta=10^{-8})$ differential privacy guarantees (\\textbf{private}), enabling \\textit{Nebula}'s untrusted aggregation server to estimate histograms with over 88\\% better utility than existing local differential privacy deployments (\\textbf{accurate}). Additionally, we describe a variant that allows clients to submit multi-dimensional data, with similar privacy, utility, and performance. Finally, we provide an implementation of \\textit{Nebula}.",
      "authors": [
        "Ali Shahin Shamsabadi",
        "Peter Snyder",
        "Ralph Giles",
        "Aur\\'elien Bellet",
        "Hamed Haddadi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-15T09:55:18+00:00",
          "link": "https://arxiv.org/abs/2409.09676v1",
          "size": "244kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T14:13:44+00:00",
          "link": "https://arxiv.org/abs/2409.09676v2",
          "size": "129kb",
          "version": "v2"
        }
      ],
      "title": "Nebula: Efficient, Private and Accurate Histogram Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.09676",
        "PDF": "https://arxiv.org/pdf/2409.09676"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper describes a system for differentially private histogram estimation, which does not involve the processing of training data for LLMs or relate to data engineering or training-stage processing tasks specific to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.10589",
      "abstract": "The Job Shop Scheduling Problem (JSSP) is a complex combinatorial optimization problem. While online Reinforcement Learning (RL) has shown promise by quickly finding acceptable solutions for JSSP, it faces key limitations: it requires extensive training interactions from scratch leading to sample inefficiency, cannot leverage existing high-quality solutions from traditional methods like Constraint Programming (CP), and require simulated environments to train in, which are impracticable to build for complex scheduling environments. We introduce Offline Learned Dispatching (Offline-LD), an offline reinforcement learning approach for JSSP, which addresses these limitations by learning from historical scheduling data. Our approach is motivated by scenarios where historical scheduling data and expert solutions are available or scenarios where online training of RL approaches with simulated environments is impracticable. Offline-LD introduces maskable variants of two Q-learning methods, namely, Maskable Quantile Regression DQN (mQRDQN) and discrete maskable Soft Actor-Critic (d-mSAC), that are able to learn from historical data, through Conservative Q-Learning (CQL). Moreover, we present a novel entropy bonus modification for d-mSAC, for maskable action spaces. Moreover, we introduce a novel reward normalization method for JSSP in an offline RL setting. Our experiments demonstrate that Offline-LD outperforms online RL on both generated and benchmark instances when trained on only 100 solutions generated by CP. Notably, introducing noise to the expert dataset yields comparable or superior results to using the expert dataset, with the same amount of instances, a promising finding for real-world applications, where data is inherently noisy and imperfect.",
      "authors": [
        "Jesse van Remmerden",
        "Zaharah Bukhsh and Yingqian Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-16T15:18:10+00:00",
          "link": "https://arxiv.org/abs/2409.10589v1",
          "size": "6677kb",
          "version": "v1"
        },
        {
          "date": "2025-01-08T15:41:04+00:00",
          "link": "https://arxiv.org/abs/2409.10589v2",
          "size": "6789kb",
          "version": "v2"
        },
        {
          "date": "2025-04-13T14:52:43+00:00",
          "link": "https://arxiv.org/abs/2409.10589v3",
          "size": "3176kb",
          "version": "v3"
        },
        {
          "date": "2025-07-03T11:41:37+00:00",
          "link": "https://arxiv.org/abs/2409.10589v4",
          "size": "2649kb",
          "version": "v4"
        }
      ],
      "title": "Offline Reinforcement Learning for Learning to Dispatch for Job Shop Scheduling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.10589",
        "HTML": "https://arxiv.org/html/2409.10589v4",
        "PDF": "https://arxiv.org/pdf/2409.10589"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research focuses on offline reinforcement learning for job shop scheduling, with no connection to LLM training data or related data processing activities for language models."
      },
      "tasks": [
        "Combinatorial Optimization",
        "counterfactual",
        "Job Shop Scheduling",
        "Q-Learning",
        "reinforcement-learning",
        "Reinforcement Learning",
        "Reinforcement Learning (RL)",
        "Scheduling"
      ],
      "repo_urls": [
        "https://github.com/jesserem/Offline-LD"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.12850",
      "abstract": "Universal Serial Bus (USB)-based attacks have increased in complexity in recent years. Modern attacks incorporate a wide range of attack vectors, from social engineering to signal injection. The security community is addressing these challenges using a growing set of fragmented defenses. Regardless of the vector of a USB-based attack, the most important risks concerning most people and enterprises are service crashes and data loss. The host OS manages USB peripherals, and malicious USB peripherals, such as those infected with BadUSB, can crash a service or steal data from the OS. Although USB firewalls have been proposed to thwart malicious USB peripherals, such as USBFilter and USBGuard, their effect is limited for preventing real-world intrusions. This paper focuses on building a security framework called USBIPS within Windows OSs to defend against malicious USB peripherals. This includes major efforts to explore the nature of malicious behavior and achieve persistent protection from USB-based intrusions. Herein, we first introduce an allowlisting-based method for USB access control. We then present a behavior-based detection mechanism focusing on attacks integrated into USB peripherals. Finally, we propose a novel approach that combines cross-layer methods to build the first generic security framework that thwarts USB-based intrusions. Within a centralized threat analysis framework, the approach provides persistent protection and may detect unknown malicious behavior. By addressing key security and performance challenges, these efforts help modern OSs against attacks from untrusted USB peripherals.",
      "authors": [
        "Chun-Yi Wang and Fu-Hau Hsu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-19T15:48:52+00:00",
          "link": "https://arxiv.org/abs/2409.12850v1",
          "size": "531kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T05:23:52+00:00",
          "link": "https://arxiv.org/abs/2409.12850v2",
          "size": "2748kb",
          "version": "v2"
        }
      ],
      "title": "USBIPS Framework: Protecting Hosts from Malicious USB Peripherals",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.12850",
        "PDF": "https://arxiv.org/pdf/2409.12850"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is concerned with USB security on host systems, focusing on protection mechanisms against malicious peripherals, and does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.14052",
      "abstract": "Solving two-variable linear Diophantine equations has applications in many cryptographic protocols such as RSA and Elliptic curve cryptography. The Extended Euclid's algorithm is the most widely used algorithm to solve these equations. We revisit two algorithms to solve two-variable linear Diophantine equations. We write the iterative version of one of the revisited algorithms. For another, we do a fine-grained analysis of the number of recursive calls and arrive at a periodic function that represents the number of recursive calls. We find the period and use it to derive an accurate closed-form expression for the average number of recursive calls incurred by that algorithm. We find multiple loose upper bounds on the average number of recursive calls in different cases based on whether a solution exists or not. We find that for a fixed value of $a,b$ and a varying $c$, such that the equation $ax+by=c$ (where $a > b$) is solvable, we can find the solution in $O\\left(\\frac{\\log b}{gcd(a,b)}\\right)$ average number of recursions or steps. We computationally evaluate this bound as well as one more upper bound and compare them with the average number of recursive calls in Extended Euclid's algorithm on a number of random $512$-bit inputs. We observe that the average number of iterations in the analyzed algorithm decreases with an increase in $gcd(a,b)$. We propose an iterative version of the algorithm. We implement this algorithm and find that the average number of iterations by our algorithm is less than that of two existing algorithms.",
      "authors": [
        "Mayank Deora",
        "Pinakpani Pal"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Data Structures and Algorithms (cs.DS)",
        "Number Theory (math.NT)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-21T07:51:12+00:00",
          "link": "https://arxiv.org/abs/2409.14052v1",
          "size": "36kb",
          "version": "v1"
        },
        {
          "date": "2025-04-29T07:05:41+00:00",
          "link": "https://arxiv.org/abs/2409.14052v2",
          "size": "105kb",
          "version": "v2"
        },
        {
          "date": "2025-05-21T07:04:11+00:00",
          "link": "https://arxiv.org/abs/2409.14052v3",
          "size": "643kb",
          "version": "v3"
        },
        {
          "date": "2025-05-27T07:31:15+00:00",
          "link": "https://arxiv.org/abs/2409.14052v4",
          "size": "630kb",
          "version": "v4"
        },
        {
          "date": "2025-07-03T07:08:25+00:00",
          "link": "https://arxiv.org/abs/2409.14052v5",
          "size": "631kb",
          "version": "v5"
        }
      ],
      "title": "An average case efficient algorithm for solving two-variable linear Diophantine equations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.14052",
        "HTML": "https://arxiv.org/html/2409.14052v5",
        "PDF": "https://arxiv.org/pdf/2409.14052"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on algorithms for solving two-variable linear Diophantine equations, which is unrelated to LLM training data processing and construction."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.18624",
      "abstract": "Unsupervised learning methods have a soft inspiration in cognition models. To this day, the most successful unsupervised learning methods revolve around clustering samples in a mathematical space. In this paper we propose a primitive-based, unsupervised learning approach for decision-making inspired by a novel cognition framework. This representation-centric approach models the input space constructively as a distributed hierarchical structure in an input-agnostic way. We compared our approach with both current state-of-the-art unsupervised learning classification, with current state-of-the-art small and incomplete datasets classification, and with current state-of-the-art cancer type classification. We show how our proposal outperforms previous state-of-the-art. We also evaluate some cognition-like properties of our proposal where it not only outperforms the compared algorithms (even supervised learning ones), but it also shows a different, more cognition-like, behaviour.",
      "authors": [
        "Alfredo Ibias",
        "Hector Antona",
        "Guillem Ramirez-Miranda",
        "Enric Guinovart",
        "Eduard Alarcon"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-27T10:50:49+00:00",
          "link": "https://arxiv.org/abs/2409.18624v1",
          "size": "517kb",
          "version": "v1"
        },
        {
          "date": "2024-11-07T14:36:04+00:00",
          "link": "https://arxiv.org/abs/2409.18624v2",
          "size": "694kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T08:53:17+00:00",
          "link": "https://arxiv.org/abs/2409.18624v3",
          "size": "1035kb",
          "version": "v3"
        }
      ],
      "title": "Unsupervised Cognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.18624",
        "HTML": "https://arxiv.org/html/2409.18624v3",
        "PDF": "https://arxiv.org/pdf/2409.18624"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on unsupervised learning methods inspired by cognition models, without mention of LLM data processing or data engineering."
      },
      "tasks": [
        "Cancer type classification",
        "Decision Making"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.05451",
      "abstract": "Large language models (LLMs) are becoming increasingly prevalent in modern software systems, interfacing between the user and the Internet to assist with tasks that require advanced language understanding. To accomplish these tasks, the LLM often uses external data sources such as user documents, web retrieval, results from API calls, etc. This opens up new avenues for attackers to manipulate the LLM via prompt injection. Adversarial prompts can be injected into external data sources to override the system's intended instruction and instead execute a malicious instruction. To mitigate this vulnerability, we propose a new defense called SecAlign based on the technique of preference optimization. Our defense first constructs a preference dataset with prompt-injected inputs, secure outputs (ones that respond to the legitimate instruction), and insecure outputs (ones that respond to the injection). We then perform preference optimization on this dataset to teach the LLM to prefer the secure output over the insecure one. This provides the first known method that reduces the success rates of various prompt injections to <10%, even against attacks much more sophisticated than ones seen during training. This indicates our defense generalizes well against unknown and yet-to-come attacks. Also, SecAlign models are still practical with similar utility to the one before defensive training in our evaluations. Our code is at https://github.com/facebookresearch/SecAlign",
      "authors": [
        "Sizhe Chen",
        "Arman Zharmagambetov",
        "Saeed Mahloujifar",
        "Kamalika Chaudhuri",
        "David Wagner",
        "Chuan Guo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-07T19:34:35+00:00",
          "link": "https://arxiv.org/abs/2410.05451v1",
          "size": "193kb",
          "version": "v1"
        },
        {
          "date": "2025-01-13T18:45:57+00:00",
          "link": "https://arxiv.org/abs/2410.05451v2",
          "size": "273kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T05:45:41+00:00",
          "link": "https://arxiv.org/abs/2410.05451v3",
          "size": "230kb",
          "version": "v3"
        }
      ],
      "title": "SecAlign: Defending Against Prompt Injection with Preference Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.05451",
        "HTML": "https://arxiv.org/html/2410.05451v3",
        "PDF": "https://arxiv.org/pdf/2410.05451"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper involves constructing a preference dataset for training LLMs to defend against prompt injections, its primary contribution focuses on adversarial defense mechanisms, not on data engineering or LLM training data processing."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/facebookresearch/secalign"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.08500",
      "abstract": "Aerial Vision-and-Language Navigation (VLN) is a novel task enabling Unmanned Aerial Vehicles (UAVs) to navigate in outdoor environments through natural language instructions and visual cues. It remains challenging due to the complex spatial relationships in outdoor aerial scenes. In this paper, we propose an end-to-end zero-shot framework for aerial VLN tasks, where the large language model (LLM) is introduced as our agent for action prediction. Specifically, we develop a novel Semantic-Topo-Metric Representation (STMR) to enhance the spatial reasoning ability of LLMs. This is achieved by extracting and projecting instruction-related semantic masks of landmarks into a top-down map that contains the location information of surrounding landmarks. Further, this map is transformed into a matrix representation with distance metrics as the text prompt to the LLM, for action prediction according to the instruction. Experiments conducted in real and simulation environments have successfully proved the effectiveness and robustness of our method, achieving 15.9% and 12.5% improvements (absolute) in Oracle Success Rate (OSR) on AerialVLN-S dataset.",
      "authors": [
        "Yunpeng Gao",
        "Zhigang Wang",
        "Linglin Jing",
        "Dong Wang",
        "Xuelong Li",
        "Bin Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-11T03:54:48+00:00",
          "link": "https://arxiv.org/abs/2410.08500v1",
          "size": "3406kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T11:55:43+00:00",
          "link": "https://arxiv.org/abs/2410.08500v2",
          "size": "2691kb",
          "version": "v2"
        }
      ],
      "title": "Aerial Vision-and-Language Navigation via Semantic-Topo-Metric Representation Guided LLM Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.08500",
        "HTML": "https://arxiv.org/html/2410.08500v2",
        "PDF": "https://arxiv.org/pdf/2410.08500"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses navigation tasks involving LLM reasoning and spatial representation for UAVs, not on the training data processing or data engineering for LLMs."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Large Language Model",
        "Navigate",
        "Spatial Reasoning",
        "Vision and Language Navigation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.08723",
      "abstract": "Natural language generation (NLG) models have emerged as a focal point of research within natural language processing (NLP), exhibiting remarkable performance in tasks such as text composition and dialogue generation. However, their intricate architectures and extensive model parameters pose significant challenges to interpretability, limiting their applicability in high-stakes decision-making scenarios. To address this issue, human-computer interaction (HCI) and visualization techniques offer promising avenues to enhance the transparency and usability of NLG models by making their decision-making processes more interpretable. In this paper, we provide a comprehensive investigation into the roles, limitations, and impact of HCI and visualization in facilitating human understanding and control over NLG systems. We introduce a taxonomy of interaction methods and visualization techniques, categorizing three major research domains and their corresponding six key tasks in the application of NLG models. Finally, we summarize the shortcomings in the existing work and investigate the key challenges and emerging opportunities in the era of large language models (LLMs).",
      "authors": [
        "Yunchao Wang",
        "Guodao Sun",
        "Zihang Fu",
        "Ronghua Liang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-11T11:23:26+00:00",
          "link": "https://arxiv.org/abs/2410.08723v1",
          "size": "6917kb",
          "version": "v1"
        },
        {
          "date": "2025-03-28T04:38:44+00:00",
          "link": "https://arxiv.org/abs/2410.08723v2",
          "size": "4107kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T05:25:23+00:00",
          "link": "https://arxiv.org/abs/2410.08723v3",
          "size": "3855kb",
          "version": "v3"
        }
      ],
      "title": "Human-Computer Interaction and Visualization in Natural Language Generation Models: Applications, Challenges, and Opportunities",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.08723",
        "HTML": "https://arxiv.org/html/2410.08723v3",
        "PDF": "https://arxiv.org/pdf/2410.08723"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on human-computer interaction and visualization in NLG models, rather than on constructing or processing training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.10530",
      "abstract": "Despite substantial progress in recent years, probabilistic solvers with adaptive step sizes can still not solve memory-demanding differential equations -- unless we care only about a single point in time (which is far too restrictive; we want the whole time series). Counterintuitively, the culprit is the adaptivity itself: Its unpredictable memory demands easily exceed our machine's capabilities, making our simulations fail unexpectedly and without warning. Still, dropping adaptivity would abandon years of progress, which can't be the answer. In this work, we solve this conundrum. We develop an adaptive probabilistic solver with fixed memory demands building on recent developments in robust state estimation. Switching to our method (i) eliminates memory issues for long time series, (ii) accelerates simulations by orders of magnitude through unlocking just-in-time compilation, and (iii) makes adaptive probabilistic solvers compatible with scientific computing in JAX.",
      "authors": [
        "Nicholas Kr\\\"amer"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Machine Learning (cs.LG)",
        "Numerical Analysis (cs.NA)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-14T14:10:47+00:00",
          "link": "https://arxiv.org/abs/2410.10530v1",
          "size": "846kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T12:07:20+00:00",
          "link": "https://arxiv.org/abs/2410.10530v2",
          "size": "811kb",
          "version": "v2"
        }
      ],
      "title": "Adaptive Probabilistic ODE Solvers Without Adaptive Memory Requirements",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.10530",
        "HTML": "https://arxiv.org/html/2410.10530v2",
        "PDF": "https://arxiv.org/pdf/2410.10530"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is centered on developing probabilistic ODE solvers with adaptive memory requirements, which is unrelated to LLM training data processing or data engineering."
      },
      "tasks": [
        "State Estimation",
        "Time Series"
      ],
      "repo_urls": [
        "https://github.com/pnkraemer/probdiffeq"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.12532",
      "abstract": "In healthcare intelligence, the ability to fuse heterogeneous, multi-intent information from diverse clinical sources is fundamental to building reliable decision-making systems. Large Language Model (LLM)-driven information interaction systems currently showing potential promise in the healthcare domain. Nevertheless, they often suffer from information redundancy and coupling when dealing with complex medical intents, leading to severe hallucinations and performance bottlenecks. To this end, we propose MedAide, an LLM-based medical multi-agent collaboration framework designed to enable intent-aware information fusion and coordinated reasoning across specialized healthcare domains. Specifically, we introduce a regularization-guided module that combines syntactic constraints with retrieval augmented generation to decompose complex queries into structured representations, facilitating fine-grained clinical information fusion and intent resolution. Additionally, a dynamic intent prototype matching module is proposed to utilize dynamic prototype representation with a semantic similarity matching mechanism to achieve adaptive recognition and updating of the agent's intent in multi-round healthcare dialogues. Ultimately, we design a rotation agent collaboration mechanism that introduces dynamic role rotation and decision-level information fusion across specialized medical agents. Extensive experiments are conducted on four medical benchmarks with composite intents. Experimental results from automated metrics and expert doctor evaluations show that MedAide outperforms current LLMs and improves their medical proficiency and strategic reasoning.",
      "authors": [
        "Dingkang Yang",
        "Jinjie Wei",
        "Mingcheng Li",
        "Jiyao Liu",
        "Lihao Liu",
        "Ming Hu",
        "Junjun He",
        "Yakun Ju",
        "Wei Zhou",
        "Yang Liu",
        "Lihua Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-16T13:10:27+00:00",
          "link": "https://arxiv.org/abs/2410.12532v1",
          "size": "1105kb",
          "version": "v1"
        },
        {
          "date": "2024-10-17T09:22:41+00:00",
          "link": "https://arxiv.org/abs/2410.12532v2",
          "size": "1105kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T13:02:30+00:00",
          "link": "https://arxiv.org/abs/2410.12532v3",
          "size": "7415kb",
          "version": "v3"
        }
      ],
      "title": "MedAide: Information Fusion and Anatomy of Medical Intents via LLM-based Agent Collaboration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.12532",
        "HTML": "https://arxiv.org/html/2410.12532v3",
        "PDF": "https://arxiv.org/pdf/2410.12532"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes MedAide for information fusion and intent resolution in healthcare scenarios, focusing on model interactions rather than on LLM training data processing or engineering."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Large Language Model",
        "Retrieval",
        "Retrieval-augmented Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.12537",
      "abstract": "Complex query answering (CQA) on knowledge graphs (KGs) is gaining momentum as a challenging reasoning task. In this paper, we show that the current benchmarks for CQA might not be as complex as we think, as the way they are built distorts our perception of progress in this field. For example, we find that in these benchmarks, most queries (up to 98% for some query types) can be reduced to simpler problems, e.g., link prediction, where only one link needs to be predicted. The performance of state-of-the-art CQA models decreases significantly when such models are evaluated on queries that cannot be reduced to easier types. Thus, we propose a set of more challenging benchmarks composed of queries that require models to reason over multiple hops and better reflect the construction of real-world KGs. In a systematic empirical investigation, the new benchmarks show that current methods leave much to be desired from current CQA methods.",
      "authors": [
        "Cosimo Gregucci",
        "Bo Xiong",
        "Daniel Hernandez",
        "Lorenzo Loconte",
        "Pasquale Minervini",
        "Steffen Staab",
        "Antonio Vergari"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-16T13:19:03+00:00",
          "link": "https://arxiv.org/abs/2410.12537v1",
          "size": "384kb",
          "version": "v1"
        },
        {
          "date": "2025-02-18T12:40:13+00:00",
          "link": "https://arxiv.org/abs/2410.12537v2",
          "size": "483kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T08:36:22+00:00",
          "link": "https://arxiv.org/abs/2410.12537v3",
          "size": "486kb",
          "version": "v3"
        }
      ],
      "title": "Is Complex Query Answering Really Complex?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.12537",
        "HTML": "https://arxiv.org/html/2410.12537v3",
        "PDF": "https://arxiv.org/pdf/2410.12537"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on complex query answering on knowledge graphs and proposes new benchmarks for evaluating CQA models, not on LLM training data processing or engineering."
      },
      "tasks": [
        "Complex Query Answering",
        "Knowledge Graphs",
        "Link Prediction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.13808",
      "abstract": "Watermarking techniques offer a promising way to identify machine-generated content via embedding covert information into the contents generated from language models (LMs). However, the robustness of the watermarking schemes has not been well explored. In this paper, we present De-mark, an advanced framework designed to remove n-gram-based watermarks effectively. Our method utilizes a novel querying strategy, termed random selection probing, which aids in assessing the strength of the watermark and identifying the red-green list within the n-gram watermark. Experiments on popular LMs, such as Llama3 and ChatGPT, demonstrate the efficiency and effectiveness of De-mark in watermark removal and exploitation tasks.",
      "authors": [
        "Ruibo Chen",
        "Yihan Wu",
        "Junfeng Guo",
        "Heng Huang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-17T17:42:10+00:00",
          "link": "https://arxiv.org/abs/2410.13808v1",
          "size": "914kb",
          "version": "v1"
        },
        {
          "date": "2025-07-02T20:37:50+00:00",
          "link": "https://arxiv.org/abs/2410.13808v2",
          "size": "613kb",
          "version": "v2"
        }
      ],
      "title": "De-mark: Watermark Removal in Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.13808",
        "HTML": "https://arxiv.org/html/2410.13808v2",
        "PDF": "https://arxiv.org/pdf/2410.13808"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses removing watermarks from the outputs of language models, which is unrelated to the processing or engineering of training data for LLMs."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2410.16236",
      "abstract": "The success of Large Language Models (LLMs) has inspired the development of Multimodal Large Language Models (MLLMs) for unified understanding of vision and language. However, the increasing model size and computational complexity of large-scale MLLMs (l-MLLMs) limit their use in resource-constrained scenarios. Although small-scale MLLMs (s-MLLMs) are designed to reduce computational costs, they typically suffer from performance degradation. To mitigate this limitation, we propose a novel LLaVA-KD framework to transfer knowledge from l-MLLMs to s-MLLMs. Specifically, we introduce Multimodal Distillation (MDist) to transfer teacher model's robust representations across both visual and linguistic modalities, and Relation Distillation (RDist) to transfer teacher model's ability to capture visual token relationships. Additionally, we propose a three-stage training scheme to fully exploit the potential of the proposed distillation strategy: 1) Distilled Pre-Training to strengthen the alignment between visual-linguistic representations in s-MLLMs, 2) Supervised Fine-Tuning to equip the s-MLLMs with multimodal understanding capacity, and 3) Distilled Fine-Tuning to refine s-MLLM's knowledge. Our approach significantly improves s-MLLMs performance without altering the model architecture. Extensive experiments and ablation studies validate the effectiveness of each proposed component. Code will be available at https://github.com/Fantasyele/LLaVA-KD.",
      "authors": [
        "Yuxuan Cai",
        "Jiangning Zhang",
        "Haoyang He",
        "Xinwei He",
        "Ao Tong",
        "Zhenye Gan",
        "Chengjie Wang",
        "Zhucun Xue",
        "Yong Liu",
        "Xiang Bai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-21T17:41:28+00:00",
          "link": "https://arxiv.org/abs/2410.16236v1",
          "size": "1250kb",
          "version": "v1"
        },
        {
          "date": "2024-10-25T06:19:13+00:00",
          "link": "https://arxiv.org/abs/2410.16236v2",
          "size": "1250kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T06:59:56+00:00",
          "link": "https://arxiv.org/abs/2410.16236v3",
          "size": "845kb",
          "version": "v3"
        }
      ],
      "title": "LLaVA-KD: A Framework of Distilling Multimodal Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.16236",
        "HTML": "https://arxiv.org/html/2410.16236v3",
        "PDF": "https://arxiv.org/pdf/2410.16236"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes a distillation framework for transferring knowledge from large to small multimodal models and includes stages like distilled pre-training and fine-tuning, but it does not primarily focus on novel training data processing techniques for LLMs."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/Fantasyele/LLaVA-KD"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.16428",
      "abstract": "Modern speaker verification systems primarily rely on speaker embeddings, followed by verification based on cosine similarity between the embedding vectors of the enrollment and test utterances. While effective, these methods struggle with multi-talker speech due to the unidentifiability of embedding vectors. In this paper, we propose Neural Scoring (NS), a refreshed end-to-end framework that directly estimates verification posterior probabilities without relying on test-side embeddings, making it more robust to complex conditions, e.g., with multiple talkers. To make the training of such an end-to-end model more efficient, we introduce a large-scale trial e2e training (LtE2E) strategy, where each test utterance pairs with a set of enrolled speakers, thus enabling the processing of large-scale verification trials per batch. Experiments on the VoxCeleb dataset demonstrate that NS consistently outperforms both the baseline and competitive methods across various conditions, achieving an overall 70.36% reduction in EER compared to the baseline.",
      "authors": [
        "Wan Lin and Junhui Chen and Tianhao Wang and Zhenyu Zhou and Lantian Li and Dong Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-21T18:48:54+00:00",
          "link": "https://arxiv.org/abs/2410.16428v1",
          "size": "391kb",
          "version": "v1"
        },
        {
          "date": "2025-06-03T23:35:07+00:00",
          "link": "https://arxiv.org/abs/2410.16428v2",
          "size": "477kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T16:36:28+00:00",
          "link": "https://arxiv.org/abs/2410.16428v3",
          "size": "487kb",
          "version": "v3"
        }
      ],
      "title": "Neural Scoring: A Refreshed End-to-End Approach for Speaker Recognition in Complex Conditions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.16428",
        "HTML": "https://arxiv.org/html/2410.16428v3",
        "PDF": "https://arxiv.org/pdf/2410.16428"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a new framework for speaker recognition, focusing on verification processes rather than training data processing or engineering for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.20160",
      "abstract": "Vibration-based damage detection relies on identifying modal parameters, such as natural frequencies and mode shapes, to be used as structural integrity indicators. However, traditional comparisons of these parameters are often ambiguous in complex systems, complicating damage detection and assessment. The modified total modal assurance criterion (MTMAC), a metric well-known in the field of finite element model updating, is extended to address this challenge and is proposed as a metric for damage identification and severity assessment. To support the requirement for precise and robust modal identification of Structural Health Monitoring (SHM), the improved Loewner Framework (iLF), known for its reliability and computational performance, is pioneeringly employed within SHM. Since the MTMAC is proposed solely as a damage identification and severity assessment metric, the coordinate modal assurance criterion (COMAC), also a well-established tool, but for damage localisation using mode shapes, is used for completeness. The iLF SHM capabilities are validated through comparisons with traditional methods, including least-squares complex exponential (LSCE) and stochastic subspace identification with canonical variate analysis (SSI-CVA) on a numerical case study of a cantilever beam. Furthermore, the MTMAC is validated against the traditional vibration-based approach, which involves directly comparing natural frequencies and mode shapes. Finally, an experimental dataset from a BAE Systems Hawk T1A trainer jet ground vibration tests is used to demonstrate the iLF and MTMAC capabilities on real-life, real-size SHM problem, showing their effectiveness in detecting and assessing damage.",
      "authors": [
        "Gabriele Dessena",
        "Marco Civera",
        "Andr\\'es Marcos",
        "Bernardino Chiaia and Oscar E. Bonilla-Manrique"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-26T12:22:14+00:00",
          "link": "https://arxiv.org/abs/2410.20160v1",
          "size": "6575kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T10:49:12+00:00",
          "link": "https://arxiv.org/abs/2410.20160v2",
          "size": "6767kb",
          "version": "v2"
        }
      ],
      "title": "Vibration-based damage detection of a trainer jet via multiple input tangential interpolation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.20160",
        "PDF": "https://arxiv.org/pdf/2410.20160"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on vibration-based damage detection using various metrics and frameworks for structural health monitoring and does not mention any methodologies related to LLM training data processing."
      },
      "tasks": [
        "Benchmarking",
        "Cantilever Beam",
        "Structural Health Monitoring"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.21553",
      "abstract": "Diffusion bridge models and stochastic interpolants enable high-quality image-to-image (I2I) translation by creating paths between distributions in pixel space. However, the proliferation of techniques based on incompatible mathematical assumptions have impeded progress. In this work, we unify and expand the space of bridge models by extending Stochastic Interpolants (SIs) with preconditioning, endpoint conditioning, and an optimized sampling algorithm. These enhancements expand the design space of diffusion bridge models, leading to state-of-the-art performance in both image quality and sampling efficiency across diverse I2I tasks. Furthermore, we identify and address a previously overlooked issue of low sample diversity under fixed conditions. We introduce a quantitative analysis for output diversity and demonstrate how we can modify the base distribution for further improvements.",
      "authors": [
        "Shaorong Zhang",
        "Yuanbin Cheng",
        "Greg Ver Steeg"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-28T21:30:59+00:00",
          "link": "https://arxiv.org/abs/2410.21553v1",
          "size": "5098kb",
          "version": "v1"
        },
        {
          "date": "2025-07-02T18:24:40+00:00",
          "link": "https://arxiv.org/abs/2410.21553v2",
          "size": "14519kb",
          "version": "v2"
        }
      ],
      "title": "Exploring the Design Space of Diffusion Bridge Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.21553",
        "HTML": "https://arxiv.org/html/2410.21553v2",
        "PDF": "https://arxiv.org/pdf/2410.21553"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses diffusion bridge models for image translation and does not involve any aspects of LLM training data processing or data engineering."
      },
      "tasks": [
        "Diversity"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.00863",
      "abstract": "In the field of large language model (LLM)-based proof generation, despite extensive training on large datasets such as ArXiv, LLMs still exhibit only modest performance on proving tasks of moderate difficulty. We believe that this is partly due to the widespread presence of suboptimal ordering within the data for each proof used in training. For example, published proofs often follow a purely logical order, where each step logically proceeds from the previous steps based on the deductive rules. This order is designed to facilitate the verification of the proof's soundness, rather than to help people and models learn the discovery process of the proof. In proof generation, we argue that the optimal order for one training data sample occurs when the relevant intermediate supervision for a particular proof step in the proof is always positioned to the left of that proof step. We call such order the intuitively sequential order. We validate our claims using two tasks: intuitionistic propositional logic theorem-proving and digit multiplication. Our experiments verify the order effect and provide support for our explanations. We demonstrate that training is most effective when the proof is in the intuitively sequential order. Moreover, the order effect and the performance gap between models trained on different data orders can be substantial -- with an 11 percent improvement in proof success rate observed in the propositional logic theorem-proving task, between models trained on the optimal order compared to the worst order. Lastly, we define a common type of order issue in advanced math proofs and find that 17.3 percent of theorems with nontrivial proofs in the first two chapters of a widely used graduate-level mathematics textbook suffer from this issue. A detailed list of those proofs is provided in the appendix.",
      "authors": [
        "Chenyang An",
        "Shima Imani",
        "Feng Yao",
        "Chengyu Dong",
        "Ali Abbasi",
        "Harsh Shrivastava",
        "Samuel Buss",
        "Jingbo Shang",
        "Gayathri Mahalingam",
        "Pramod Sharma",
        "Maurice Diesendruck"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-30T18:00:04+00:00",
          "link": "https://arxiv.org/abs/2411.00863v1",
          "size": "308kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T15:14:51+00:00",
          "link": "https://arxiv.org/abs/2411.00863v2",
          "size": "271kb",
          "version": "v2"
        }
      ],
      "title": "Next-Token Prediction Task Assumes Optimal Data Ordering for LLM Training in Proof Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.00863",
        "HTML": "https://arxiv.org/html/2411.00863v2",
        "PDF": "https://arxiv.org/pdf/2411.00863"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper's primary contribution involves the ordering of training data for LLMs in the specific context of proof generation, directly impacting the effectiveness of LLM training. It addresses optimal data ordering, a critical data processing aspect in training LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.05197",
      "abstract": "It is now a common business practice to buy access to large language model (LLM) inference rather than self-host, because of significant upfront hardware infrastructure and energy costs. However, as a buyer, there is no mechanism to verify the authenticity of the advertised service including the serving hardware platform, e.g. that it is actually being served using an NVIDIA H100. Furthermore, there are reports suggesting that model providers may deliver models that differ slightly from the advertised ones, often to make them run on less expensive hardware. That way, a client pays premium for a capable model access on more expensive hardware, yet ends up being served by a (potentially less capable) cheaper model on cheaper hardware. In this paper we introduce hardware and software platform inference (HSPI) -- a method for identifying the underlying GPU architecture and software stack of a (black-box) machine learning model solely based on its input-output behavior. Our method leverages the inherent differences of various GPU architectures and compilers to distinguish between different GPU types and software stacks. By analyzing the numerical patterns in the model's outputs, we propose a classification framework capable of accurately identifying the GPU used for model inference as well as the underlying software configuration. Our findings demonstrate the feasibility of inferring GPU type from black-box models. We evaluate HSPI against models served on different real hardware and find that in a white-box setting we can distinguish between different GPUs with between $83.9\\%$ and $100\\%$ accuracy. Even in a black-box setting we achieve results that are up to 3x higher than random guess accuracy. Our code is available at https://github.com/ChengZhang-98/HSPI.",
      "authors": [
        "Cheng Zhang",
        "Hanna Foerster",
        "Robert D. Mullins",
        "Yiren Zhao",
        "Ilia Shumailov"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-07T21:44:04+00:00",
          "link": "https://arxiv.org/abs/2411.05197v1",
          "size": "1477kb",
          "version": "v1"
        },
        {
          "date": "2025-07-02T22:14:13+00:00",
          "link": "https://arxiv.org/abs/2411.05197v2",
          "size": "927kb",
          "version": "v2"
        }
      ],
      "title": "Hardware and Software Platform Inference",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.05197",
        "HTML": "https://arxiv.org/html/2411.05197v2",
        "PDF": "https://arxiv.org/pdf/2411.05197"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on hardware and software platform inference for identifying GPU architectures used in LLM inference, which is unrelated to the processing of training data for LLMs."
      },
      "tasks": [
        "Large Language Model"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.07618",
      "abstract": "The alignment of large language models (LLMs) with human preferences remains a key challenge. While post-training techniques like Reinforcement Learning from Human Feedback (RLHF) and Direct Preference Optimization (DPO) have achieved notable success, they often introduce computational inefficiencies and training instability. In this paper, we propose Feature-level constrained Preference Optimization (FPO), a novel method designed to simplify the alignment process while ensuring stability. FPO leverages pre-trained Sparse Autoencoders (SAEs) and introduces feature-level constraints, allowing for efficient, sparsity-enforced alignment. Our approach enjoys efficiency by using sparse features activated in a well-trained sparse autoencoder and the quality of sequential KL divergence by using the feature-level offline reference. Experimental results on benchmark datasets demonstrate that FPO achieves a 5.08% absolute improvement in win rate with much lower computational cost compared to state-of-the-art baselines, making it a promising solution for efficient and controllable LLM alignments.",
      "authors": [
        "Qingyu Yin",
        "Chak Tou Leong",
        "Hongbo Zhang",
        "Minjun Zhu",
        "Hanqi Yan",
        "Qiang Zhang",
        "Yulan He",
        "Wenjie Li",
        "Jun Wang",
        "Yue Zhang",
        "Linyi Yang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-12T07:54:13+00:00",
          "link": "https://arxiv.org/abs/2411.07618v1",
          "size": "1287kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T13:18:23+00:00",
          "link": "https://arxiv.org/abs/2411.07618v2",
          "size": "321kb",
          "version": "v2"
        }
      ],
      "title": "Direct Preference Optimization Using Sparse Feature-Level Constraints",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.07618",
        "HTML": "https://arxiv.org/html/2411.07618v2",
        "PDF": "https://arxiv.org/pdf/2411.07618"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses a novel method for aligning LLMs with human preferences, involving data processing aspects like feature-level constraints. However, it does not primarily focus on training data processing, collection, or engineering for LLMs."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2411.08777",
      "abstract": "Accurately determining the shape of deformable objects and the location of their internal structures is crucial for medical tasks that require precise targeting, such as robotic biopsies. We introduce LUDO, a method for accurate low-latency understanding of deformable objects. LUDO reconstructs objects in their deformed state, including their internal structures, from a single-view point cloud observation in under 30 ms using occupancy networks. LUDO provides uncertainty estimates for its predictions. Additionally, it provides explainability by highlighting key features in its input observations. Both uncertainty and explainability are important for safety-critical applications such as surgery. We evaluate LUDO in real-world robotic experiments, achieving a success rate of 98.9% for puncturing various regions of interest (ROIs) inside deformable objects. We compare LUDO to a popular baseline and show its superior ROI localization accuracy, training time, and memory requirements. LUDO demonstrates the potential to interact with deformable objects without the need for deformable registration methods.",
      "authors": [
        "Pit Henrich",
        "Franziska Mathis-Ullrich",
        "Paul Maria Scheikl"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-13T17:02:46+00:00",
          "link": "https://arxiv.org/abs/2411.08777v1",
          "size": "27486kb",
          "version": "v1"
        },
        {
          "date": "2025-04-09T17:47:52+00:00",
          "link": "https://arxiv.org/abs/2411.08777v2",
          "size": "40109kb",
          "version": "v2"
        },
        {
          "date": "2025-04-19T12:33:15+00:00",
          "link": "https://arxiv.org/abs/2411.08777v3",
          "size": "15107kb",
          "version": "v3"
        },
        {
          "date": "2025-05-08T07:18:17+00:00",
          "link": "https://arxiv.org/abs/2411.08777v4",
          "size": "15107kb",
          "version": "v4"
        },
        {
          "date": "2025-07-03T15:01:00+00:00",
          "link": "https://arxiv.org/abs/2411.08777v5",
          "size": "17151kb",
          "version": "v5"
        }
      ],
      "title": "LUDO: Low-Latency Understanding of Deformable Objects using Point Cloud Occupancy Functions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.08777",
        "PDF": "https://arxiv.org/pdf/2411.08777"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a method (LUDO) for understanding deformable objects using point cloud data, which is unrelated to LLM training data processing or data engineering."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2411.14441",
      "abstract": "With the proliferation of devices on the Internet of Things (IoT), ensuring their security has become paramount. Device identification (DI), which distinguishes IoT devices based on their traffic patterns, plays a crucial role in both differentiating devices and identifying vulnerable ones, closing a serious security gap. However, existing approaches to DI that build machine learning models often overlook the challenge of model generalizability across diverse network environments. In this study, we propose a novel framework to address this limitation and to evaluate the generalizability of DI models across data sets collected within different network environments. Our approach involves a two-step process: first, we develop a feature and model selection method that is more robust to generalization issues by using a genetic algorithm with external feedback and datasets from distinct environments to refine the selections. Second, the resulting DI models are then tested on further independent datasets to robustly assess their generalizability. We demonstrate the effectiveness of our method by empirically comparing it to alternatives, highlighting how fundamental limitations of commonly employed techniques such as sliding window and flow statistics limit their generalizability. Moreover, we show that statistical methods, widely used in the literature, are unreliable for device identification due to their dependence on network-specific characteristics rather than device-intrinsic properties, challenging the validity of a significant portion of existing research. Our findings advance research in IoT security and device identification, offering insight into improving model effectiveness and mitigating risks in IoT networks.",
      "authors": [
        "Kahraman Kostas",
        "Rabia Yasa Kostas",
        "Mike Just",
        "Michael A. Lones"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-05T17:09:43+00:00",
          "link": "https://arxiv.org/abs/2411.14441v1",
          "size": "7268kb",
          "version": "v1"
        },
        {
          "date": "2025-07-02T21:26:35+00:00",
          "link": "https://arxiv.org/abs/2411.14441v2",
          "size": "4585kb",
          "version": "v2"
        }
      ],
      "title": "GeMID: Generalizable Models for IoT Device Identification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.14441",
        "HTML": "https://arxiv.org/html/2411.14441v2",
        "PDF": "https://arxiv.org/pdf/2411.14441"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses IoT device identification through a newly proposed framework but does not mention any processes or methodologies related to LLM training data."
      },
      "tasks": [
        "Classification",
        "feature selection",
        "IoT Device Identification",
        "Model Selection"
      ],
      "repo_urls": [
        "https://github.com/kahramankostas/GeMID"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.16765",
      "abstract": "Sign language processing has traditionally relied on task-specific models, limiting the potential for transfer learning across tasks. Pre-training methods for sign language have typically focused on either supervised pre-training, which cannot take advantage of unlabeled data, or context-independent (frame or video segment) representations, which ignore the effects of relationships across time in sign language. We introduce SHuBERT (Sign Hidden-Unit BERT), a self-supervised contextual representation model learned from approximately 1,000 hours of American Sign Language video. SHuBERT adapts masked token prediction objectives to multi-stream visual sign language input, learning to predict multiple targets corresponding to clustered hand, face, and body pose streams. SHuBERT achieves state-of-the-art performance across multiple tasks including sign language translation, isolated sign language recognition, and fingerspelling detection.",
      "authors": [
        "Shester Gueuwou",
        "Xiaodan Du",
        "Greg Shakhnarovich",
        "Karen Livescu",
        "Alexander H. Liu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-25T03:13:08+00:00",
          "link": "https://arxiv.org/abs/2411.16765v1",
          "size": "1831kb",
          "version": "v1"
        },
        {
          "date": "2025-06-03T01:30:30+00:00",
          "link": "https://arxiv.org/abs/2411.16765v2",
          "size": "2063kb",
          "version": "v2"
        },
        {
          "date": "2025-07-02T23:43:36+00:00",
          "link": "https://arxiv.org/abs/2411.16765v3",
          "size": "2083kb",
          "version": "v3"
        }
      ],
      "title": "SHuBERT: Self-Supervised Sign Language Representation Learning via Multi-Stream Cluster Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.16765",
        "HTML": "https://arxiv.org/html/2411.16765v3",
        "PDF": "https://arxiv.org/pdf/2411.16765"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on sign language representation learning and does not address any aspects of LLM training data processing or engineering."
      },
      "tasks": [
        "Representation Learning",
        "Sign Language Recognition",
        "Sign Language Translation",
        "Transfer Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.19688",
      "abstract": "Vision-Language Models (VLMs) have great potential in medical tasks, like Visual Question Answering (VQA), where they could act as interactive assistants for both patients and clinicians. Yet their robustness to distribution shifts on unseen data remains a key concern for safe deployment. Evaluating such robustness requires a controlled experimental setup that allows for systematic insights into the model's behavior. However, we demonstrate that current setups fail to offer sufficiently thorough evaluations. To address this gap, we introduce a novel framework, called SURE-VQA, centered around three key requirements to overcome current pitfalls and systematically analyze VLM robustness: 1) Since robustness on synthetic shifts does not necessarily translate to real-world shifts, it should be measured on real-world shifts that are inherent to the VQA data; 2) Traditional token-matching metrics often fail to capture underlying semantics, necessitating the use of large language models (LLMs) for more accurate semantic evaluation; 3) Model performance often lacks interpretability due to missing sanity baselines, thus meaningful baselines should be reported that allow assessing the multimodal impact on the VLM. To demonstrate the relevance of this framework, we conduct a study on the robustness of various Fine-Tuning (FT) methods across three medical datasets with four types of distribution shifts. Our study highlights key insights into robustness: 1) No FT method consistently outperforms others in robustness, and 2) robustness trends are more stable across FT methods than across distribution shifts. Additionally, we find that simple sanity baselines that do not use the image data can perform surprisingly well and confirm LoRA as the best-performing FT method on in-distribution data. Code is provided at https://github.com/IML-DKFZ/sure-vqa.",
      "authors": [
        "Kim-Celine Kahl",
        "Selen Erkan",
        "Jeremias Traub",
        "Carsten T. L\\\"uth",
        "Klaus Maier-Hein",
        "Lena Maier-Hein",
        "Paul F. Jaeger"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-29T13:22:52+00:00",
          "link": "https://arxiv.org/abs/2411.19688v1",
          "size": "23604kb",
          "version": "v1"
        },
        {
          "date": "2025-07-02T14:30:53+00:00",
          "link": "https://arxiv.org/abs/2411.19688v2",
          "size": "23819kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T13:07:30+00:00",
          "link": "https://arxiv.org/abs/2411.19688v3",
          "size": "23819kb",
          "version": "v3"
        }
      ],
      "title": "SURE-VQA: Systematic Understanding of Robustness Evaluation in Medical VQA Tasks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.19688",
        "HTML": "https://arxiv.org/html/2411.19688v3",
        "PDF": "https://arxiv.org/pdf/2411.19688"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper touches on robustness evaluation in Medical VQA tasks and uses large language models for semantic evaluation, mentioning fine-tuning, which is a form of training-stage data processing. However, it does not propose new methods for LLM training data processing."
      },
      "tasks": [
        "Question Answering",
        "Visual Question Answering",
        "Visual Question Answering (VQA)"
      ],
      "repo_urls": [
        "https://github.com/iml-dkfz/sure-vqa"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.00420",
      "abstract": "We propose TAROT, a targeted data selection framework grounded in optimal transport theory. Previous targeted data selection methods primarily rely on influence-based greedy heuristics to enhance domain-specific performance. While effective on limited, unimodal data (i.e., data following a single pattern), these methods struggle as target data complexity increases. Specifically, in multimodal distributions, these heuristics fail to account for multiple inherent patterns, leading to suboptimal data selection. This work identifies two primary factors contributing to this limitation: (i) the disproportionate impact of dominant feature components in high-dimensional influence estimation, and (ii) the restrictive linear additive assumptions inherent in greedy selection strategies. To address these challenges, TAROT incorporates whitened feature distance to mitigate dominant feature bias, providing a more reliable measure of data influence. Building on this, TAROT uses whitened feature distance to quantify and minimize the optimal transport distance between the selected data and target domains. Notably, this minimization also facilitates the estimation of optimal selection ratios. We evaluate TAROT across multiple tasks, including semantic segmentation, motion prediction, and instruction tuning. Results consistently show that TAROT outperforms state-of-the-art methods, highlighting its versatility across various deep learning tasks. Code is available at https://github.com/vita-epfl/TAROT.",
      "authors": [
        "Lan Feng",
        "Fan Nie",
        "Yuejiang Liu",
        "Alexandre Alahi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-30T10:19:51+00:00",
          "link": "https://arxiv.org/abs/2412.00420v1",
          "size": "9760kb",
          "version": "v1"
        },
        {
          "date": "2025-07-02T19:48:29+00:00",
          "link": "https://arxiv.org/abs/2412.00420v2",
          "size": "8766kb",
          "version": "v2"
        }
      ],
      "title": "TAROT: Targeted Data Selection via Optimal Transport",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.00420",
        "HTML": "https://arxiv.org/html/2412.00420v2",
        "PDF": "https://arxiv.org/pdf/2412.00420"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper proposes TAROT, a targeted data selection framework, which is a new method for data processing, including instruction tuning; demonstrating a direct contribution to data preparation methods for LLM training."
      },
      "tasks": [
        "motion prediction",
        "Semantic Segmentation"
      ],
      "repo_urls": [
        "https://github.com/vita-epfl/tarot"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.01940",
      "abstract": "Driven by recent breakthrough advances in neural representation learning, approximate near-neighbor (ANN) search over vector embeddings has emerged as a critical computational workload. With the introduction of the seminal Hierarchical Navigable Small World (HNSW) algorithm, graph-based indexes have established themselves as the overwhelmingly dominant paradigm for efficient and scalable ANN search. As the name suggests, HNSW searches a layered hierarchical graph to quickly identify neighborhoods of similar points to a given query vector. But is this hierarchy even necessary? A rigorous experimental analysis to answer this question would provide valuable insights into the nature of algorithm design for ANN search and motivate directions for future work in this increasingly crucial domain. We conduct an extensive benchmarking study covering more large-scale datasets than prior investigations of this question. We ultimately find that a flat navigable small world graph graph retains all of the benefits of HNSW on high-dimensional datasets, with latency and recall performance essentially \\emph{identical} to the original algorithm but with less memory overhead. Furthermore, we go a step further and study \\emph{why} the hierarchy of HNSW provides no benefit in high dimensions, hypothesizing that navigable small world graphs contain a well-connected, frequently traversed ``highway\" of hub nodes that maintain the same purported function as the hierarchical layers. We present compelling empirical evidence that the \\emph{Hub Highway Hypothesis} holds for real datasets and investigate the mechanisms by which the highway forms. The implications of this hypothesis may also provide future research directions in developing enhancements to graph-based ANN search.",
      "authors": [
        "Blaise Munyampirwa",
        "Vihan Lakshman",
        "Benjamin Coleman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Databases (cs.DB)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-02T20:04:06+00:00",
          "link": "https://arxiv.org/abs/2412.01940v1",
          "size": "6320kb",
          "version": "v1"
        },
        {
          "date": "2025-02-02T19:25:13+00:00",
          "link": "https://arxiv.org/abs/2412.01940v2",
          "size": "10297kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T13:32:02+00:00",
          "link": "https://arxiv.org/abs/2412.01940v3",
          "size": "5564kb",
          "version": "v3"
        }
      ],
      "title": "Down with the Hierarchy: The 'H' in HNSW Stands for \"Hubs\"",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.01940",
        "HTML": "https://arxiv.org/html/2412.01940v3",
        "PDF": "https://arxiv.org/pdf/2412.01940"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on approximate near-neighbor search over vector embeddings and hierarchical graph structures, which is related to algorithm design rather than LLM training data processing or engineering."
      },
      "tasks": [
        "Benchmarking",
        "Representation Learning"
      ],
      "repo_urls": [
        "https://github.com/BlaiseMuhirwa/flatnav"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.03349",
      "abstract": "Face recognition and verification are two computer vision tasks whose performances have advanced with the introduction of deep representations. However, ethical, legal, and technical challenges due to the sensitive nature of face data and biases in real-world training datasets hinder their development. Generative AI addresses privacy by creating fictitious identities, but fairness problems remain. Using the existing DCFace SOTA framework, we introduce a new controlled generation pipeline that improves fairness. Through classical fairness metrics and a proposed in-depth statistical analysis based on logit models and ANOVA, we show that our generation pipeline improves fairness more than other bias mitigation approaches while slightly improving raw performance.",
      "authors": [
        "Alexandre Fournier-Montgieux",
        "Michael Soumm",
        "Adrian Popescu",
        "Bertrand Luvison",
        "Herv\\'e Le Borgne"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-04T14:30:19+00:00",
          "link": "https://arxiv.org/abs/2412.03349v1",
          "size": "7962kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T12:42:44+00:00",
          "link": "https://arxiv.org/abs/2412.03349v2",
          "size": "7962kb",
          "version": "v2"
        }
      ],
      "title": "Fairer Analysis and Demographically Balanced Face Generation for Fairer Face Verification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.03349",
        "HTML": "https://arxiv.org/html/2412.03349v2",
        "PDF": "https://arxiv.org/pdf/2412.03349"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper addresses demographic balance in face data generation for verification tasks, mentioning data generation and fairness improvement, but does not focus on LLM-specific training data processing."
      },
      "tasks": [
        "Face Generation",
        "Face Recognition",
        "Face Verification",
        "Fairness"
      ],
      "repo_urls": [
        "https://github.com/afm215/FaVGen",
        "https://github.com/MSoumm/FaVFA",
        "https://github.com/Recognito-Vision/Linux-FaceRecognition-FaceLivenessDetection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.04795",
      "abstract": "For lengths $36$, $48$ and $60$, we construct new ternary near-extremal self-dual codes with weight enumerators for which no ternary near-extremal self-dual codes were previously known to exist.",
      "authors": [
        "Masaaki Harada"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Combinatorics (math.CO)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-06T06:06:59+00:00",
          "link": "https://arxiv.org/abs/2412.04795v1",
          "size": "9kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T07:24:10+00:00",
          "link": "https://arxiv.org/abs/2412.04795v2",
          "size": "10kb",
          "version": "v2"
        }
      ],
      "title": "Ternary near-extremal self-dual codes of lengths $36$, $48$ and $60$",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.04795",
        "HTML": "https://arxiv.org/html/2412.04795v2",
        "PDF": "https://arxiv.org/pdf/2412.04795"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the construction of ternary near-extremal self-dual codes, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.05693",
      "abstract": "Several works have developed eviction policies to remove key-value (KV) pairs from the KV cache for more efficient inference. The focus has been on compressing the KV cache after the input prompt has been processed for faster token generation. In settings with limited GPU memory, and when the input context is longer than the generation length, we show that by also compressing the KV cache during the input processing phase, larger batch sizes can be used resulting in significantly higher throughput while still maintaining the original model's accuracy.",
      "authors": [
        "Michael R. Metel",
        "Boxing Chen",
        "Mehdi Rezagholizadeh"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-07T16:41:54+00:00",
          "link": "https://arxiv.org/abs/2412.05693v1",
          "size": "26kb",
          "version": "v1"
        },
        {
          "date": "2025-06-17T02:24:51+00:00",
          "link": "https://arxiv.org/abs/2412.05693v2",
          "size": "28kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T16:06:35+00:00",
          "link": "https://arxiv.org/abs/2412.05693v3",
          "size": "28kb",
          "version": "v3"
        }
      ],
      "title": "Batch-Max: Higher LLM Throughput using Larger Batch Sizes and KV Cache Compression",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.05693",
        "HTML": "https://arxiv.org/html/2412.05693v3",
        "PDF": "https://arxiv.org/pdf/2412.05693"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses improvements in LLM inference efficiency through KV cache compression, which is not directly related to the processing of training data for LLMs."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2412.05827",
      "abstract": "Proper guidance strategies are essential to achieve high-quality generation results without retraining diffusion and flow-based text-to-image models. Existing guidance either requires specific training or strong inductive biases of diffusion model networks, potentially limiting their applications. Motivated by the observation that artifact outliers can be detected by a significant decline in the density from a noisier to a cleaner noise level, we propose Self-Guidance (SG), which improves the image quality by suppressing the generation of low-quality samples. SG only relies on the sampling probabilities of its own diffusion model at different noise levels with no need of any guidance-specific training. This makes it flexible to be used in a plug-and-play manner with other sampling algorithms. We also introduce a more efficient approximation of SG, named SG-prev, which reuses the output from the immediately previous diffusion step to avoid doubling sampling time. We conduct experiments on text-to-image and text-to-video generation with different architectures, including UNet and transformer models. With open-sourced diffusion models such as Stable Diffusion 3.5 and FLUX, SG exceeds existing algorithms on multiple metrics, including both FID and Human Preference Score. SG-prev also achieves strong results over both the baseline and the SG with only one forward pass. Moreover, we find that SG and SG-prev both have a surprisingly positive effect on the generation of physiologically correct human body structures such as hands, faces, and arms, showing their ability of eliminating human body artifacts with minimal efforts. We will release our code along with this paper.",
      "authors": [
        "Tiancheng Li",
        "Weijian Luo",
        "Zhiyang Chen",
        "Liyuan Ma",
        "Guo-Jun Qi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-08T06:32:27+00:00",
          "link": "https://arxiv.org/abs/2412.05827v1",
          "size": "8469kb",
          "version": "v1"
        },
        {
          "date": "2025-03-08T13:10:47+00:00",
          "link": "https://arxiv.org/abs/2412.05827v2",
          "size": "8278kb",
          "version": "v2"
        },
        {
          "date": "2025-05-25T05:42:43+00:00",
          "link": "https://arxiv.org/abs/2412.05827v3",
          "size": "8281kb",
          "version": "v3"
        },
        {
          "date": "2025-07-03T04:33:09+00:00",
          "link": "https://arxiv.org/abs/2412.05827v4",
          "size": "7746kb",
          "version": "v4"
        }
      ],
      "title": "Self-Guidance: Boosting Flow and Diffusion Generation on Their Own",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.05827",
        "HTML": "https://arxiv.org/html/2412.05827v4",
        "PDF": "https://arxiv.org/pdf/2412.05827"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes Self-Guidance for improving the quality of image generation in diffusion models, unrelated to LLM training data processing."
      },
      "tasks": [
        "Image Generation",
        "Text to Image Generation",
        "Text-to-Image Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.10435",
      "abstract": "Recently, with the emergence of recent Multimodal Large Language Model (MLLM) technology, it has become possible to exploit its video understanding capability on different classification tasks. In practice, we face the difficulty of huge requirements for GPU resource if we need to deploy MLLMs online. In this paper, we propose COEF-VQ, a novel cascaded MLLM framework designed to enhance video quality understanding on the short-video platform while optimizing computational efficiency. Our approach integrates an entropy-based pre-filtering stage, where a lightweight model assesses uncertainty and selectively filters cases before passing them to the more computationally intensive MLLM for final evaluation. By prioritizing high-uncertainty samples for deeper analysis, our framework significantly reduces GPU usage while maintaining the strong classification performance of a full MLLM deployment. To demonstrate the effectiveness of COEF-VQ, we deploy this new framework onto the video management platform (VMP) at the short-video platform, and perform a series of detailed experiments on two in-house tasks related to video quality understanding. We show that COEF-VQ leads to substantial performance gains from the offline evaluation in these two tasks and effectively enhances platform safety with limit resource consumption, significantly reducing inappropriate content video view rate by 9.9% in a online A/B test without affecting engagement. Post-launch monitoring confirmed sustained improvements, validating its real-world impact.",
      "authors": [
        "Xin Dong",
        "Sen Jia",
        "Ming Rui Wang",
        "Yan Li",
        "Zhenheng Yang",
        "Bingfeng Deng",
        "Hongyu Xiong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-11T08:10:32+00:00",
          "link": "https://arxiv.org/abs/2412.10435v1",
          "size": "148kb",
          "version": "v1"
        },
        {
          "date": "2025-07-02T21:50:59+00:00",
          "link": "https://arxiv.org/abs/2412.10435v2",
          "size": "144kb",
          "version": "v2"
        }
      ],
      "title": "COEF-VQ: Cost-Efficient Video Quality Understanding through a Cascaded Multimodal LLM Framework",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.10435",
        "HTML": "https://arxiv.org/html/2412.10435v2",
        "PDF": "https://arxiv.org/pdf/2412.10435"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a framework for video quality understanding through MLLMs and computational efficiency, with no mention of LLM training data processing or data engineering stages."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Large Language Model",
        "Multimodal Large Language Model",
        "Video Understanding"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.11074",
      "abstract": "Continual learning (CL) enables models to adapt to evolving data streams. A major challenge of CL is catastrophic forgetting, where new knowledge will overwrite previously acquired knowledge. Traditional methods usually retain the past data for replay or add additional branches in the model to learn new knowledge, which has high memory requirements. In this paper, we propose a novel lightweight CL framework, Adapter-Enhanced Semantic Prompting (AESP), which integrates prompt tuning and adapter techniques. Specifically, we design semantic-guided prompts to enhance the generalization ability of visual features and utilize adapters to efficiently fuse the semantic information, aiming to learn more adaptive features for the continual learning task. Furthermore, to choose the right task prompt for feature adaptation, we have developed a novel matching mechanism for prompt selection. Extensive experiments on three CL datasets demonstrate that our approach achieves favorable performance across multiple metrics, showing its potential for advancing CL.",
      "authors": [
        "Baocai Yin",
        "Ji Zhao",
        "Huajie Jiang",
        "Ningning Hou",
        "Yongli Hu",
        "Amin Beheshti",
        "Ming-Hsuan Yang",
        "Yuankai Qi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-15T06:14:55+00:00",
          "link": "https://arxiv.org/abs/2412.11074v1",
          "size": "794kb",
          "version": "v1"
        },
        {
          "date": "2025-04-23T14:44:27+00:00",
          "link": "https://arxiv.org/abs/2412.11074v2",
          "size": "5705kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T03:00:36+00:00",
          "link": "https://arxiv.org/abs/2412.11074v3",
          "size": "1002kb",
          "version": "v3"
        }
      ],
      "title": "Adapter-Enhanced Semantic Prompting for Continual Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.11074",
        "HTML": "https://arxiv.org/html/2412.11074v3",
        "PDF": "https://arxiv.org/pdf/2412.11074"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a continual learning framework using adapters and semantic prompting, but does not address LLM training data processing or data engineering concepts."
      },
      "tasks": [
        "Continual Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.11556",
      "abstract": "Extracting sentence embeddings from large language models (LLMs) is a promising direction, as LLMs have demonstrated stronger semantic understanding capabilities. Previous studies typically focus on prompt engineering to elicit sentence embeddings from LLMs by prompting the model to encode sentence information into the embedding of the last token. However, LLMs are mostly decoder-only models with causal attention and the earlier tokens in the sentence cannot attend to the latter tokens, resulting in biased encoding of sentence information and cascading effects on the final decoded token. To this end, we propose a novel Token Prepending (TP) technique that prepends each layer's decoded sentence embedding to the beginning of the sentence in the next layer's input, allowing earlier tokens to attend to the complete sentence information under the causal attention mechanism. The proposed TP technique is a plug-and-play and training-free technique, which means it can be seamlessly integrated with various prompt-based sentence embedding methods and autoregressive LLMs. Extensive experiments on various Semantic Textual Similarity (STS) tasks and downstream classification tasks demonstrate that our proposed TP technique can significantly improve the performance of existing prompt-based sentence embedding methods across different LLMs, while incurring negligible additional inference cost.",
      "authors": [
        "Yuchen Fu",
        "Zifeng Cheng",
        "Zhiwei Jiang",
        "Zhonghui Wang",
        "Yafeng Yin",
        "Zhengliang Li",
        "Qing Gu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-16T08:42:00+00:00",
          "link": "https://arxiv.org/abs/2412.11556v1",
          "size": "372kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T06:24:49+00:00",
          "link": "https://arxiv.org/abs/2412.11556v2",
          "size": "267kb",
          "version": "v2"
        }
      ],
      "title": "Token Prepending: A Training-Free Approach for Eliciting Better Sentence Embeddings from LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.11556",
        "HTML": "https://arxiv.org/html/2412.11556v2",
        "PDF": "https://arxiv.org/pdf/2412.11556"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes a technique for improving sentence embeddings in LLMs, touching on data processing at the execution stage, but does not introduce new LLM training data processing or engineering methods."
      },
      "tasks": [
        "Prompt Engineering",
        "Semantic Textual Similarity",
        "Sentence",
        "Sentence Embedding",
        "Sentence-Embedding",
        "Sentence Embeddings",
        "STS"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.14171",
      "abstract": "Humans possess the visual-spatial intelligence to remember spaces from sequential visual observations. However, can Multimodal Large Language Models (MLLMs) trained on million-scale video datasets also ``think in space'' from videos? We present a novel video-based visual-spatial intelligence benchmark (VSI-Bench) of over 5,000 question-answer pairs, and find that MLLMs exhibit competitive - though subhuman - visual-spatial intelligence. We probe models to express how they think in space both linguistically and visually and find that while spatial reasoning capabilities remain the primary bottleneck for MLLMs to reach higher benchmark performance, local world models and spatial awareness do emerge within these models. Notably, prevailing linguistic reasoning techniques (e.g., chain-of-thought, self-consistency, tree-of-thoughts) fail to improve performance, whereas explicitly generating cognitive maps during question-answering enhances MLLMs' spatial distance ability.",
      "authors": [
        "Jihan Yang",
        "Shusheng Yang",
        "Anjali W. Gupta",
        "Rilyn Han",
        "Li Fei-Fei",
        "Saining Xie"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-18T18:59:54+00:00",
          "link": "https://arxiv.org/abs/2412.14171v1",
          "size": "9432kb",
          "version": "v1"
        },
        {
          "date": "2025-07-02T21:00:36+00:00",
          "link": "https://arxiv.org/abs/2412.14171v2",
          "size": "9553kb",
          "version": "v2"
        }
      ],
      "title": "Thinking in Space: How Multimodal Large Language Models See, Remember, and Recall Spaces",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.14171",
        "HTML": "https://arxiv.org/html/2412.14171v2",
        "PDF": "https://arxiv.org/pdf/2412.14171"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on evaluating multimodal large language models' spatial reasoning capabilities rather than on training data processing, highlighting their performance on a novel benchmark related to visual-spatial intelligence."
      },
      "datasets": [
        {
          "dataset_name": "nyu-visionx/VSI-Bench",
          "downloads": "2199",
          "likes": "41",
          "link": "https://huggingface.co/datasets/nyu-visionx/VSI-Bench"
        }
      ],
      "conference_url_abs": "http://openaccess.thecvf.com//content/CVPR2025/html/Yang_Thinking_in_Space_How_Multimodal_Large_Language_Models_See_Remember_CVPR_2025_paper.html",
      "tasks": [
        "Question Answering",
        "Spatial Reasoning"
      ],
      "repo_urls": [
        "https://github.com/vision-x-nyu/thinking-in-space"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.18530",
      "abstract": "We study language generation in the limit - introduced by Kleinberg and Mullainathan [KM24] - building on classical works of Gold [Gol67] and Angluin [Ang79]. [KM24]'s main result is an algorithm for generating from any countable language collection in the limit. While their algorithm eventually generates unseen strings from the target language $K$, it sacrifices coverage or breadth, i.e., its ability to generate a rich set of strings. Recent work introduces different notions of breadth and explores when generation with breadth is possible, leaving a full characterization of these notions open. Our first set of results settles this by characterizing generation for existing notions of breadth and their natural extensions. Interestingly, our lower bounds are very flexible and hold for many performance metrics beyond breadth - for instance, showing that, in general, it is impossible to train generators which achieve a higher perplexity or lower hallucination rate for $K$ compared to other languages. Next, we study language generation with breadth and stable generators - algorithms that eventually stop changing after seeing an arbitrary but finite number of strings - and prove unconditional lower bounds for such generators, strengthening the results of [KMV25] and demonstrating that generation with many existing notions of breadth becomes equally hard, when stability is required. This gives a separation for generation with approximate breadth, between stable and unstable generators, highlighting the rich interplay between breadth, stability, and consistency in language generation.",
      "authors": [
        "Alkis Kalavasis",
        "Anay Mehrotra",
        "Grigoris Velegkas"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Data Structures and Algorithms (cs.DS)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-24T16:24:43+00:00",
          "link": "https://arxiv.org/abs/2412.18530v1",
          "size": "308kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T15:39:41+00:00",
          "link": "https://arxiv.org/abs/2412.18530v2",
          "size": "310kb",
          "version": "v2"
        }
      ],
      "title": "On Characterizations for Language Generation: Interplay of Hallucinations, Breadth, and Stability",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.18530",
        "HTML": "https://arxiv.org/html/2412.18530v2",
        "PDF": "https://arxiv.org/pdf/2412.18530"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study is centered around language generation algorithms and their properties like breadth and stability, without specific contributions to LLM training data collection or preprocessing methods."
      },
      "tasks": [
        "Text Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.18716",
      "abstract": "Mobile Money (MoMo), a technology that allows users to complete financial transactions using a mobile phone without requiring a bank account, is a common method for processing financial transactions in Africa and other developing regions. Users can deposit and withdraw money with the help of human agents. During deposit and withdraw operations, know-your-customer (KYC) processes require agents to access and verify customer information such as name and ID number, which can introduce privacy and security risks. In this work, we design alternative protocols for MoMo deposits/withdrawals that protect users' privacy while enabling KYC checks by redirecting the flow of sensitive information from the agent to the MoMo provider. We evaluate the usability and efficiency of our proposed protocols in a role-play and semi-structured interview study with 32 users and 15 agents in Kenya. We find that users and agents prefer the new protocols, due in part to convenient and efficient verification using biometrics as well as better data privacy and access control. However, our study also surfaced challenges that need to be addressed before these protocols can be deployed.",
      "authors": [
        "Karen Sowon",
        "Collins W. Munyendo",
        "Lily Klucinec",
        "Eunice Maingi",
        "Gerald Suleh",
        "Lorrie Faith Cranor",
        "Giulia Fanti",
        "Conrad Tucker",
        "and Assane Gueye"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-25T00:27:13+00:00",
          "link": "https://arxiv.org/abs/2412.18716v1",
          "size": "6973kb",
          "version": "v1"
        },
        {
          "date": "2025-07-02T21:57:06+00:00",
          "link": "https://arxiv.org/abs/2412.18716v2",
          "size": "6146kb",
          "version": "v2"
        }
      ],
      "title": "Design and Evaluation of Privacy-Preserving Protocols for Agent-Facilitated Mobile Money Services in Kenya",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.18716",
        "PDF": "https://arxiv.org/pdf/2412.18716"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on designing privacy-preserving protocols for mobile money services, which is unrelated to the training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.01717",
      "abstract": "The compression of real-world scanned 3D human dynamic meshes is an emerging research area, driven by applications such as telepresence, virtual reality, and 3D digital streaming. Unlike synthesized dynamic meshes with fixed topology, scanned dynamic meshes often not only have varying topology across frames but also scan defects such as holes and outliers, increasing the complexity of prediction and compression. Additionally, human meshes often combine rigid and non-rigid motions, making accurate prediction and encoding significantly more difficult compared to objects that exhibit purely rigid motion. To address these challenges, we propose a compression method designed for real-world scanned human dynamic meshes, leveraging embedded key nodes. The temporal motion of each vertex is formulated as a distance-weighted combination of transformations from neighboring key nodes, requiring the transmission of solely the key nodes' transformations. To enhance the quality of the KeyNode-driven prediction, we introduce an octree-based residual coding scheme and a Dual-direction prediction mode, which uses I-frames from both directions. Extensive experiments demonstrate that our method achieves significant improvements over the state-of-the-art, with an average bitrate savings of 58.43% across the evaluated sequences, particularly excelling at low bitrates.",
      "authors": [
        "Huong Hoang",
        "Truong Nguyen",
        "Pamela Cosman"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Multimedia (cs.MM)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-03T09:22:16+00:00",
          "link": "https://arxiv.org/abs/2501.01717v1",
          "size": "4482kb",
          "version": "v1"
        },
        {
          "date": "2025-07-02T18:40:08+00:00",
          "link": "https://arxiv.org/abs/2501.01717v2",
          "size": "3870kb",
          "version": "v2"
        }
      ],
      "title": "KeyNode-Driven Geometry Coding for Real-World Scanned Human Dynamic Mesh Compression",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.01717",
        "HTML": "https://arxiv.org/html/2501.01717v2",
        "PDF": "https://arxiv.org/pdf/2501.01717"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work is focused on the compression of 3D human dynamic meshes, which is outside the scope of data processing for LLM training."
      },
      "tasks": [
        "Prediction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.03262",
      "abstract": "Large Language Models (LLMs) fine-tuned via Reinforcement Learning from Human Feedback (RLHF) and Reinforcement Learning with Verifiable Rewards (RLVR) significantly improve the alignment of human-AI values and further raise the upper bound of AI capabilities, particularly in reasoning-intensive, long-context Chain-of-Thought (long-CoT) tasks. However, existing RLHF (or RLVR) frameworks commonly face challenges such as inference bottlenecks and complexity barriers, restricting their accessibility for newcomers. To bridge this gap, we introduce \\textbf{OpenRLHF}, a user-friendly, scalable, and easy-to-learn open-source RLHF framework built upon Ray, vLLM, DeepSpeed, and HuggingFace Transformers, featuring a simplified design, clear code structure, and comprehensive documentation to facilitate entry for researchers and practitioners. Experimental results show that OpenRLHF achieves superior training efficiency with speedups ranging from 1.22x to 1.68x across different model sizes compared to state-of-the-art frameworks, while requiring significantly fewer lines of code for implementation. OpenRLHF is publicly available at https://github.com/OpenRLHF/OpenRLHF, and has already been adopted by leading institutions to accelerate RLHF research and learning.",
      "authors": [
        "Jian Hu",
        "Xibin Wu",
        "Wei Shen",
        "Jason Klein Liu",
        "Zilin Zhu",
        "Weixun Wang",
        "Songlin Jiang",
        "Haoran Wang",
        "Hao Chen",
        "Bin Chen",
        "Weikai Fang",
        "Xianyu",
        "Yu Cao",
        "Haotian Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-04T02:08:06+00:00",
          "link": "https://arxiv.org/abs/2501.03262v1",
          "size": "1283kb",
          "version": "v1"
        },
        {
          "date": "2025-04-03T03:20:56+00:00",
          "link": "https://arxiv.org/abs/2501.03262v2",
          "size": "2387kb",
          "version": "v2"
        },
        {
          "date": "2025-04-06T02:23:29+00:00",
          "link": "https://arxiv.org/abs/2501.03262v3",
          "size": "2387kb",
          "version": "v3"
        },
        {
          "date": "2025-07-03T04:17:04+00:00",
          "link": "https://arxiv.org/abs/2501.03262v4",
          "size": "2596kb",
          "version": "v4"
        }
      ],
      "title": "REINFORCE++: An Efficient RLHF Algorithm with Robustness to Both Prompt and Reward Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.03262",
        "HTML": "https://arxiv.org/html/2501.03262v4",
        "PDF": "https://arxiv.org/pdf/2501.03262"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces an RLHF framework for fine-tuning LLMs, mentioning training efficiency but not primarily focusing on training data processing or engineering."
      },
      "tasks": [
        "Computational Efficiency"
      ],
      "repo_urls": [
        "https://github.com/theeighthday/seekworld",
        "https://github.com/gair-nlp/maye",
        "https://github.com/openrlhf/openrlhf",
        "https://github.com/OpenLLMAI/OpenLLaMA2",
        "https://github.com/OpenLLMAI/OpenRLHF"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.04011",
      "abstract": "Cholesky linear solvers are a critical bottleneck in challenging applications within computer graphics and scientific computing. These applications include but are not limited to elastodynamic barrier methods such as Incremental Potential Contact (IPC), and geometric operations such as remeshing and morphology. In these contexts, the sparsity patterns of the linear systems frequently change across successive calls to the Cholesky solver, necessitating repeated symbolic analyses that dominate the overall solver runtime.\n  To address this bottleneck, we evaluate our method on over 150,000 linear systems generated from diverse nonlinear problems with dynamic sparsity changes in Incremental Potential Contact (IPC) and patch remeshing on a wide range of triangular meshes of various sizes. Our analysis using three leading sparse Cholesky libraries, Intel MKL Pardiso, SuiteSparse CHOLMOD, and Apple Accelerate, reveals that the primary performance constraint lies in the symbolic re-ordering phase of the solver. Recognizing this, we introduce Parth, an innovative re-ordering method designed to update ordering vectors only where local connectivity changes occur adaptively. Parth employs a novel hierarchical graph decomposition algorithm to break down the dual graph of the input matrix into fine-grained subgraphs, facilitating the selective reuse of fill-reducing orderings when sparsity patterns exhibit temporal coherence.\n  Our extensive evaluation demonstrates that Parth achieves up to a 255x and 13x speedup in fill-reducing ordering for our IPC and remeshing benchmark and a 6.85x and 10.7x acceleration in symbolic analysis. These enhancements translate to up to 2.95x and 5.89x reduction in overall solver runtime. Additionally, Parth's integration requires only three lines of code, resulting in significant computational savings without the requirement of changes to the computational stack.",
      "authors": [
        "Behrooz Zarebavani",
        "Danny M. Kaufman",
        "David I.W. Levin",
        "Maryam Mehri Dehnavi"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Graphics (cs.GR)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-16T23:04:30+00:00",
          "link": "https://arxiv.org/abs/2501.04011v1",
          "size": "33378kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T16:09:51+00:00",
          "link": "https://arxiv.org/abs/2501.04011v2",
          "size": "18202kb",
          "version": "v2"
        }
      ],
      "title": "Adaptive Algebraic Reuse of Reordering in Cholesky Factorization with Dynamic Sparsity Pattern",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.04011",
        "HTML": "https://arxiv.org/html/2501.04011v2",
        "PDF": "https://arxiv.org/pdf/2501.04011"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a method for optimizing the symbolic re-ordering phase in Cholesky factorization, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.04614",
      "abstract": "The adoption of Artificial Intelligence in medical imaging holds great promise, yet it remains hindered by challenges such as data scarcity, privacy concerns, and the need for robust multimodal integration. While recent advances in generative modeling have enabled high-quality synthetic data generation, existing approaches are often limited to unimodal, unidirectional synthesis and therefore lack the ability to jointly synthesize multiple modalities while preserving clinical consistency. To address this challenge, we introduce XGeM, a 6.77-billion-parameter multimodal generative model designed to support flexible, any-to-any synthesis between medical data modalities. XGeM constructs a shared latent space via contrastive learning and introduces a novel Multi-Prompt Training strategy, enabling conditioning on arbitrary subsets of input modalities. This design allows the model to adapt to heterogeneous clinical inputs and generate multiple outputs jointly, preserving both semantic and structural coherence. We extensively validate XGeM: first we benchmark it against five competitors on the MIMIC-CXR dataset, a state-of-the-art dataset for multi-view Chest X-ray and radiological report generation. Secondly, we perform a Visual Turing Test with expert radiologists to assess the realism and clinical relevance of the generated data, ensuring alignment with real-world scenarios. Finally, we show how XGeM can support key medical data challenges such as anonymization, class imbalance, and data scarcity, underscoring its utility as a foundation model for medical data synthesis. Project page is at https://cosbidev.github.io/XGeM/.",
      "authors": [
        "Daniele Molino and Francesco Di Feola and Eliodoro Faiella and Deborah Fazzini and Domiziana Santucci and Linlin Shen and Valerio Guarrasi and Paolo Soda"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-08T16:53:56+00:00",
          "link": "https://arxiv.org/abs/2501.04614v1",
          "size": "1094kb",
          "version": "v1"
        },
        {
          "date": "2025-01-09T08:42:56+00:00",
          "link": "https://arxiv.org/abs/2501.04614v2",
          "size": "1094kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T07:57:05+00:00",
          "link": "https://arxiv.org/abs/2501.04614v3",
          "size": "7290kb",
          "version": "v3"
        }
      ],
      "title": "XGeM: A Multi-Prompt Foundation Model for Multimodal Medical Data Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.04614",
        "HTML": "https://arxiv.org/html/2501.04614v3",
        "PDF": "https://arxiv.org/pdf/2501.04614"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The abstract mentions data generation for medical imaging, which can be tangentially related to training data preparation, though it primarily focuses on model capabilities and validation rather than data processing strategies for LLMs."
      },
      "tasks": [
        "Contrastive Learning",
        "Diagnostic"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.08496",
      "abstract": "Contrary to the conventional emphasis on dataset size, we explore the role of data alignment -- an often overlooked aspect of data quality -- in training capable Large Language Models (LLMs). To do so, we use the Task2Vec-based alignment coefficient, a quantitative measure of the similarity between two datasets, to quantify the impact of alignment between training data and evaluation data on downstream performance. In particular, we conduct controlled \\textit{interventional} experiments for two settings: 1. the impact of increased alignment coefficients between various pre-training (pt) against evaluation datasets, and 2. the impact of increased alignment coefficients between domain specific fine-tuning (ft) against domain specific evaluation. The domain specific task we explore is Autoformalization -- the machine translation task between natural language and code for formal verification. In both settings, we find a strong, predictable negative correlation between the alignment coefficient of a model's training and evaluation data and the model's loss/perplexity on the respective downstream task. These findings suggest a re-evaluation of LLM training approaches, demonstrating the relevance of data alignment compared to data quantity, especially in specialized downstream tasks such as Autoformalization.",
      "authors": [
        "Krrish Chawla",
        "Aryan Sahai",
        "Mario DePavia",
        "Sudharsan Sundar",
        "Brando Miranda",
        "Elyas Obbad",
        "Sanmi Koyejo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-14T23:59:23+00:00",
          "link": "https://arxiv.org/abs/2501.08496v1",
          "size": "1817kb",
          "version": "v1"
        },
        {
          "date": "2025-01-21T01:01:37+00:00",
          "link": "https://arxiv.org/abs/2501.08496v2",
          "size": "1836kb",
          "version": "v2"
        },
        {
          "date": "2025-07-02T21:19:42+00:00",
          "link": "https://arxiv.org/abs/2501.08496v3",
          "size": "358kb",
          "version": "v3"
        }
      ],
      "title": "Quantifying the Importance of Data Alignment in Downstream Model Performance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.08496",
        "HTML": "https://arxiv.org/html/2501.08496v3",
        "PDF": "https://arxiv.org/pdf/2501.08496"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper's primary focus is on the effect of data alignment in LLM training, highlighting data alignment's impact on downstream task performance and proposing quantitative measures to improve LLM training data quality by altering data alignment."
      },
      "tasks": [
        "Machine Translation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.08654",
      "abstract": "State-of-the-art supervised stereo matching methods have achieved remarkable performance on various benchmarks. However, their generalization to real-world scenarios remains challenging due to the scarcity of annotated real-world stereo data. In this paper, we propose ZeroStereo, a novel stereo image generation pipeline for zero-shot stereo matching. Our approach synthesizes high-quality right images from arbitrary single images by leveraging pseudo disparities generated by a monocular depth estimation model. Unlike previous methods that address occluded regions by filling missing areas with neighboring pixels or random backgrounds, we fine-tune a diffusion inpainting model to recover missing details while preserving semantic structure. Additionally, we propose Training-Free Confidence Generation, which mitigates the impact of unreliable pseudo labels without additional training, and Adaptive Disparity Selection, which ensures a diverse and realistic disparity distribution while preventing excessive occlusion and foreground distortion. Experiments demonstrate that models trained with our pipeline achieve state-of-the-art zero-shot generalization across multiple datasets with only a dataset volume comparable to Scene Flow. Code: https://github.com/Windsrain/ZeroStereo.",
      "authors": [
        "Xianqi Wang",
        "Hao Yang",
        "Gangwei Xu",
        "Junda Cheng",
        "Min Lin",
        "Yong Deng",
        "Jinliang Zang",
        "Yurui Chen",
        "Xin Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-15T08:43:48+00:00",
          "link": "https://arxiv.org/abs/2501.08654v1",
          "size": "7755kb",
          "version": "v1"
        },
        {
          "date": "2025-03-08T09:29:56+00:00",
          "link": "https://arxiv.org/abs/2501.08654v2",
          "size": "9614kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T08:29:39+00:00",
          "link": "https://arxiv.org/abs/2501.08654v3",
          "size": "9610kb",
          "version": "v3"
        }
      ],
      "title": "ZeroStereo: Zero-Shot Stereo Matching from Single Images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.08654",
        "HTML": "https://arxiv.org/html/2501.08654v3",
        "PDF": "https://arxiv.org/pdf/2501.08654"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses stereo image generation and zero-shot stereo matching, focusing on computer vision tasks not related to LLM training data processing."
      },
      "tasks": [
        "Depth Estimation",
        "Image Generation",
        "Monocular Depth Estimation",
        "Stereo Matching",
        "Zero-shot Generalization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.10382",
      "abstract": "The past decade has seen a surge in public and private applications of life cycle assessment (LCA), accelerated by emerging policies and disclosure practices mandating its use for sustainability impact reporting. Simultaneously, the magnitude and diversity of stakeholder groups affected by decisions informed by LCA have expanded rapidly. This has intensified the need for LCA to be conducted more quickly, accurately, and--crucially--earlier in the technology development cycle, when products and materials can still be readily modified, replaced, or optimized. When applied early, LCA has the potential to guide design choices, steer innovation, and avoid \"lock-in\" of adverse environmental impacts. However, this growing demand has surfaced several unresolved challenges around best practices for assessing sustainability at early stages of technology development. In this paper, we examine six such controversial topics--(1) appropriate use of LCA, (2) uncertainty assessment, (3) comparison with incumbents, (4) methodological standardization, (5) scale-up from laboratory or pilot data, and (6) stakeholder engagement--selected to highlight key debates from a series of workshop-style discussions convened by the LCA of Emerging Technologies Research Network. Rather than a comprehensive review with definitive conclusions, this paper adopts a Faraday Discussion-style approach to spotlight areas of agreement and disagreement among our network of LCA experts. For each issue, we present a declarative resolution, summarize key arguments for and against it, identify points of consensus, and provide recommendations. We aim to raise awareness of shared challenges in emerging technology assessment and foster more transparent, evidence-based, and context-informed approaches within the LCA community.",
      "authors": [
        "Rachel Woods-Robinson",
        "Mik Carbajales-Dale",
        "Anthony Cheng",
        "Gregory Cooney",
        "Abby Kirchofer",
        "Heather P. H. Liddell",
        "Lisa Peterson",
        "I. Daniel Posen",
        "Sheikh Moni",
        "Sylvia Sleep",
        "Liz Wachs",
        "Shiva Zargar",
        "Joule Bergerson"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-17T20:30:02+00:00",
          "link": "https://arxiv.org/abs/2501.10382v1",
          "size": "3047kb",
          "version": "v1"
        },
        {
          "date": "2025-01-22T21:36:00+00:00",
          "link": "https://arxiv.org/abs/2501.10382v2",
          "size": "3047kb",
          "version": "v2"
        },
        {
          "date": "2025-07-02T23:48:03+00:00",
          "link": "https://arxiv.org/abs/2501.10382v3",
          "size": "3918kb",
          "version": "v3"
        }
      ],
      "title": "Controversy and consensus: common ground and best practices for life cycle assessment of emerging technologies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.10382",
        "PDF": "https://arxiv.org/pdf/2501.10382"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses life cycle assessment methods and challenges related to sustainability in emerging technologies, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.10768",
      "abstract": "Pre-trained on extensive text and image corpora, current Multi-Modal Large Language Models (MLLM) have shown strong capabilities in general visual reasoning tasks. However, their performance is still lacking in physical domains that require understanding diagrams with complex physical structures and quantitative analysis based on multi-modal information. To address this, we develop a new framework, named Multi-Modal Scientific Reasoning with Physics Perception and Simulation (MAPS) based on an MLLM. MAPS decomposes expert-level multi-modal reasoning task into physical diagram understanding via a Physical Perception Model (PPM) and reasoning with physical knowledge via a simulator. The PPM module is obtained by fine-tuning a visual language model using carefully designed synthetic data with paired physical diagrams and corresponding simulation language descriptions. At the inference stage, MAPS integrates the simulation language description of the input diagram provided by PPM and results obtained through a Chain-of-Simulation process with MLLM to derive the underlying rationale and the final answer. Validated using our collected college-level circuit analysis problems, MAPS significantly improves reasoning accuracy of MLLM and outperforms all existing models. The results confirm MAPS offers a promising direction for enhancing multi-modal scientific reasoning ability of MLLMs. We will release our code, model and dataset used for our experiments upon publishing of this paper.",
      "authors": [
        "Erle Zhu",
        "Yadi Liu",
        "Zhe Zhang",
        "Xujun Li",
        "Jin Zhou",
        "Xinjie Yu",
        "Minlie Huang",
        "Hongning Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-18T13:54:00+00:00",
          "link": "https://arxiv.org/abs/2501.10768v1",
          "size": "18283kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T15:57:20+00:00",
          "link": "https://arxiv.org/abs/2501.10768v2",
          "size": "13172kb",
          "version": "v2"
        }
      ],
      "title": "MAPS: Advancing Multi-Modal Reasoning in Expert-Level Physical Science",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.10768",
        "HTML": "https://arxiv.org/html/2501.10768v2",
        "PDF": "https://arxiv.org/pdf/2501.10768"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses fine-tuning a visual language model with synthetic data for a module in their framework, which relates to training-stage data processing, but the primary focus is on multi-modal reasoning rather than on creating or processing LLM training data."
      },
      "tasks": [
        "Visual Reasoning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.12073",
      "abstract": "Drones are increasingly used in forestry to capture high-resolution remote sensing data, supporting enhanced monitoring, assessment, and decision-making processes. While operations above the forest canopy are already highly automated, flying inside forests remains challenging, primarily relying on manual piloting. Inside dense forests, reliance on the Global Navigation Satellite System (GNSS) for localization is not feasible. Additionally, the drone must autonomously adjust its flight path to avoid collisions. Recently, advancements in robotics have enabled autonomous drone flights in GNSS-denied obstacle-rich areas. In this article, a step towards autonomous forest data collection is taken by building a prototype of a robotic under-canopy drone utilizing state-of-the-art open-source methods and validating its performance for data collection inside forests. Specifically, the study focused on camera-based autonomous flight under the forest canopy and photogrammetric post-processing of the data collected with the low-cost onboard stereo camera. The autonomous flight capability of the prototype was evaluated through multiple test flights at boreal forests. The tree parameter estimation capability was studied by performing diameter at breast height (DBH) estimation. The prototype successfully carried out flights in selected challenging forest environments, and the experiments showed excellent performance in forest 3D modeling with a miniaturized stereoscopic photogrammetric system. The DBH estimation achieved a root mean square error (RMSE) of 3.33 cm (12.79 \\%) across all trees. For trees with a DBH less than 30 cm, the RMSE was 1.16 cm (5.74 \\%). The results provide valuable insights into autonomous under-canopy forest mapping and highlight the critical next steps for advancing lightweight robotic drone systems for mapping complex forest environments.",
      "authors": [
        "V\\\"ain\\\"o Karjalainen",
        "Niko Koivum\\\"aki",
        "Teemu Hakala",
        "Jesse Muhojoki",
        "Eric Hyypp\\\"a",
        "Anand George",
        "Juha Suomalainen",
        "Eija Honkavaara"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-21T11:59:07+00:00",
          "link": "https://arxiv.org/abs/2501.12073v1",
          "size": "34922kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T17:49:02+00:00",
          "link": "https://arxiv.org/abs/2501.12073v2",
          "size": "32193kb",
          "version": "v2"
        }
      ],
      "title": "Towards autonomous photogrammetric forest inventory using a lightweight under-canopy robotic drone",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.12073",
        "HTML": "https://arxiv.org/html/2501.12073v2",
        "PDF": "https://arxiv.org/pdf/2501.12073"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about using drones for forest inventory and does not address any aspect of LLM training data processing or preparation, focusing instead on autonomous flight and forest mapping."
      },
      "tasks": [
        "parameter estimation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.12370",
      "abstract": "Scaling the capacity of language models has consistently proven to be a reliable approach for improving performance and unlocking new capabilities. Capacity can be primarily defined by two dimensions: the number of model parameters and the compute per example. While scaling typically involves increasing both, the precise interplay between these factors and their combined contribution to overall capacity remains not fully understood. We explore this relationship in the context of sparse Mixture-of-Experts (MoEs), which allow scaling the number of parameters without proportionally increasing the FLOPs per example. We investigate how varying the sparsity level, i.e., the fraction of inactive parameters, impacts model's performance during pretraining and downstream few-shot evaluation. We find that under different constraints (e.g., parameter size and total training compute), there is an optimal level of sparsity that improves both training efficiency and model performance. These results provide a better understanding of the impact of sparsity in scaling laws for MoEs and complement existing works in this area, offering insights for designing more efficient architectures.",
      "authors": [
        "Samira Abnar",
        "Harshay Shah",
        "Dan Busbridge",
        "Alaaeldin Mohamed Elnouby Ali",
        "Josh Susskind",
        "and Vimal Thilak"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-21T18:51:15+00:00",
          "link": "https://arxiv.org/abs/2501.12370v1",
          "size": "7677kb",
          "version": "v1"
        },
        {
          "date": "2025-01-25T02:41:24+00:00",
          "link": "https://arxiv.org/abs/2501.12370v2",
          "size": "7600kb",
          "version": "v2"
        },
        {
          "date": "2025-07-02T20:37:41+00:00",
          "link": "https://arxiv.org/abs/2501.12370v3",
          "size": "1322kb",
          "version": "v3"
        }
      ],
      "title": "Parameters vs FLOPs: Scaling Laws for Optimal Sparsity for Mixture-of-Experts Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.12370",
        "HTML": "https://arxiv.org/html/2501.12370v3",
        "PDF": "https://arxiv.org/pdf/2501.12370"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The study explores sparsity levels in Mixture-of-Experts models, focusing on pretraining and evaluation performances. While it touches on training efficiency, it does not primarily contribute to novel methods of LLM training data processing."
      },
      "tasks": [
        "Mixture-of-Experts"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.15248",
      "abstract": "Ultrasound imaging is widely used in medical diagnosis, especially for fetal health assessment. However, the availability of high-quality annotated ultrasound images is limited, which restricts the training of machine learning models. In this paper, we investigate the use of diffusion models to generate synthetic ultrasound images to improve the performance on fetal plane classification. We train different classifiers first on synthetic images and then fine-tune them with real images. Extensive experimental results demonstrate that incorporating generated images into training pipelines leads to better classification accuracy than training with real images alone. The findings suggest that generating synthetic data using diffusion models can be a valuable tool in overcoming the challenges of data scarcity in ultrasound medical imaging.",
      "authors": [
        "Yueying Tian",
        "Elif Ucurum",
        "Xudong Han",
        "Rupert Young",
        "Chris Chatwin",
        "Philip Birch"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-25T15:33:13+00:00",
          "link": "https://arxiv.org/abs/2501.15248v1",
          "size": "4771kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T15:01:39+00:00",
          "link": "https://arxiv.org/abs/2501.15248v2",
          "size": "1886kb",
          "version": "v2"
        }
      ],
      "title": "Enhancing Fetal Plane Classification Accuracy with Data Augmentation Using Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.15248",
        "HTML": "https://arxiv.org/html/2501.15248v2",
        "PDF": "https://arxiv.org/pdf/2501.15248"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper explores using synthetic data for training classifiers, which involves data augmentation\u2014a form of data preparation\u2014but focuses on ultrasound imaging rather than LLMs or language model training data processes."
      },
      "tasks": [
        "Data Augmentation",
        "Medical Diagnosis"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.15880",
      "abstract": "Movable antenna (MA) and intelligent reflecting surface (IRS) are considered promising technologies for the next-generation wireless communication systems due to their shared channel reconfiguration capabilities. This, however, raises a fundamental question: Does the performance gain of MAs over conventional fixed-position antennas (FPAs) still exist in the presence of the IRS? To answer this question, we investigate in this paper an IRS-assisted multi-user multiple-input single-output (MISO) MA system, where a multi-MA base station (BS) transmits to multiple single-FPA users. We formulate a sum-rate maximization problem by jointly optimizing the active/passive beamforming of the BS/IRS and the MA positions within a one-dimensional transmit region, which is challenging to be optimally solved. To drive essential insights, we first study a simplified case with a single user. Then, we analyze the performance gain of MAs over FPAs in the light-of-sight (LoS) BS-IRS channel and derive the conditions under which this gain becomes more or less significant. In addition, we propose an alternating optimization (AO) algorithm to solve the signal-to-noise ratio (SNR) maximization problem in the single-user case by combining the block coordinate descent (BCD) method and the graph-based method. For the general multi-user case, our performance analysis unveils that the performance gain of MAs over FPAs diminishes with typical transmit precoding strategies at the BS under certain conditions. We also propose a high-quality suboptimal solution to the sum-rate maximization problem by applying the AO algorithm that combines the weighted minimum mean square error (WMMSE) algorithm, manifold optimization method and discrete sampling method. Numerical results validate our theoretical analyses and demonstrate that the performance gain of MAs over FPAs may be reduced if the IRS passive beamforming is optimized.",
      "authors": [
        "Xin Wei",
        "Weidong Mei",
        "Qingqing Wu",
        "Qiaoran Jia",
        "Boyu Ning",
        "Zhi Chen",
        "Jun Fang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-27T09:05:46+00:00",
          "link": "https://arxiv.org/abs/2501.15880v1",
          "size": "239kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T13:52:40+00:00",
          "link": "https://arxiv.org/abs/2501.15880v2",
          "size": "291kb",
          "version": "v2"
        }
      ],
      "title": "Movable Antennas Meet Intelligent Reflecting Surface: Friends or Foes?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.15880",
        "HTML": "https://arxiv.org/html/2501.15880v2",
        "PDF": "https://arxiv.org/pdf/2501.15880"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research examines performance enhancements in wireless communication systems using antennas and does not engage with LLM training data creation or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.17168",
      "abstract": "Tree-based Genetic Programming (TGP) is a widely used evolutionary algorithm for tasks such as symbolic regression, classification, and robotic control. Due to the intensive computational demands of running TGP, GPU acceleration is crucial for achieving scalable performance. However, efficient GPU-based execution of TGP still remains challenging, primarily due to three core issues: (1) the structural heterogeneity of program individuals, (2) the complexity of integrating multiple levels of parallelism, and (3) the incompatibility between high-performance CUDA execution and flexible Python-based environments. To address these issues, we propose EvoGP, a high-performance framework tailored for comprehensive GPU acceleration of TGP via population-level parallel execution. First, EvoGP introduces a tensorized representation that encodes variable-sized trees into fixed-shape, memory-aligned arrays, enabling uniform memory access and parallel computation across diverse individuals. Second, EvoGP adopts an adaptive parallelism strategy that dynamically combines intra- and inter-individual parallelism based on dataset size, ensuring high GPU utilization across a broad spectrum of tasks. Third, EvoGP embeds custom CUDA kernels into the PyTorch runtime, achieving seamless integration with Python-based environments such as Gym, MuJoCo, Brax, and Genesis. Comprehensive experiments show that EvoGP achieves up to 140x speedup over state-of-the-art GPU-based TGP implementations, while maintaining competitive accuracy and significantly improving scalability under large population sizes. EvoGP is open source and accessible at: https://github.com/EMI-Group/evogp.",
      "authors": [
        "Zhihong Wu",
        "Lishuang Wang",
        "Kebin Sun",
        "Zhuozhao Li",
        "Ran Cheng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-21T07:42:54+00:00",
          "link": "https://arxiv.org/abs/2501.17168v1",
          "size": "2194kb",
          "version": "v1"
        },
        {
          "date": "2025-01-30T03:48:10+00:00",
          "link": "https://arxiv.org/abs/2501.17168v2",
          "size": "2193kb",
          "version": "v2"
        },
        {
          "date": "2025-02-02T17:03:07+00:00",
          "link": "https://arxiv.org/abs/2501.17168v3",
          "size": "2194kb",
          "version": "v3"
        },
        {
          "date": "2025-07-03T15:50:57+00:00",
          "link": "https://arxiv.org/abs/2501.17168v4",
          "size": "1278kb",
          "version": "v4"
        }
      ],
      "title": "Enabling Population-Level Parallelism in Tree-Based Genetic Programming for Comprehensive GPU Acceleration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.17168",
        "HTML": "https://arxiv.org/html/2501.17168v4",
        "PDF": "https://arxiv.org/pdf/2501.17168"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on GPU acceleration techniques for Tree-based Genetic Programming, and does not address LLM training data processing or data engineering."
      },
      "tasks": [
        "Feature Engineering",
        "regression",
        "Symbolic Regression"
      ],
      "repo_urls": [
        "https://github.com/emi-group/evogp",
        "https://github.com/emi-group/evox"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.01391",
      "abstract": "Accurate detection of traffic anomalies is crucial for effective urban traffic management and congestion mitigation. We use the Spatiotemporal Generative Adversarial Network (STGAN) framework combining Graph Neural Networks and Long Short-Term Memory networks to capture complex spatial and temporal dependencies in traffic data. We apply STGAN to real-time, minute-by-minute observations from 42 traffic cameras across Gothenburg, Sweden, collected over several months in 2020. The images are processed to compute a flow metric representing vehicle density, which serves as input for the model. Training is conducted on data from April to November 2020, and validation is performed on a separate dataset from November 14 to 23, 2020. Our results demonstrate that the model effectively detects traffic anomalies with high precision and low false positive rates. The detected anomalies include camera signal interruptions, visual artifacts, and extreme weather conditions affecting traffic flow.",
      "authors": [
        "Fotis I. Giasemis",
        "Alexandros Sopasakis"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-03T14:23:23+00:00",
          "link": "https://arxiv.org/abs/2502.01391v1",
          "size": "538kb",
          "version": "v1"
        },
        {
          "date": "2025-05-14T09:00:33+00:00",
          "link": "https://arxiv.org/abs/2502.01391v2",
          "size": "538kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T14:53:32+00:00",
          "link": "https://arxiv.org/abs/2502.01391v3",
          "size": "465kb",
          "version": "v3"
        }
      ],
      "title": "Learning Traffic Anomalies from Generative Models on Real-Time Observations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.01391",
        "HTML": "https://arxiv.org/html/2502.01391v3",
        "PDF": "https://arxiv.org/pdf/2502.01391"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about detecting traffic anomalies using generative models and does not pertain to the creation or processing of training data for LLMs."
      },
      "tasks": [
        "Generative Adversarial Network",
        "Management"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.03997",
      "abstract": "Computer Aided Design (CAD) is indispensable across various industries. \\emph{Text-based CAD editing}, which automates the modification of CAD models based on textual instructions, holds great potential but remains underexplored. Existing methods primarily focus on design variation generation or text-based CAD generation, either lacking support for text-based control or neglecting existing CAD models as constraints. We introduce \\emph{CAD-Editor}, the first framework for text-based CAD editing. To address the challenge of demanding triplet data with accurate correspondence for training, we propose an automated data synthesis pipeline. This pipeline utilizes design variation models to generate pairs of original and edited CAD models and employs Large Vision-Language Models (LVLMs) to summarize their differences into editing instructions. To tackle the composite nature of text-based CAD editing, we propose a locate-then-infill framework that decomposes the task into two focused sub-tasks: locating regions requiring modification and infilling these regions with appropriate edits. Large Language Models (LLMs) serve as the backbone for both sub-tasks, leveraging their capabilities in natural language understanding and CAD knowledge. Experiments show that CAD-Editor achieves superior performance both quantitatively and qualitatively. The code is available at \\url {https://github.com/microsoft/CAD-Editor}.",
      "authors": [
        "Yu Yuan",
        "Shizhao Sun",
        "Qi Liu",
        "Jiang Bian"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-06T11:57:14+00:00",
          "link": "https://arxiv.org/abs/2502.03997v1",
          "size": "3915kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T15:54:50+00:00",
          "link": "https://arxiv.org/abs/2502.03997v2",
          "size": "7393kb",
          "version": "v2"
        }
      ],
      "title": "CAD-Editor: A Locate-then-Infill Framework with Automated Training Data Synthesis for Text-Based CAD Editing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.03997",
        "HTML": "https://arxiv.org/html/2502.03997v2",
        "PDF": "https://arxiv.org/pdf/2502.03997"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper proposes a novel pipeline for automated training data synthesis, specifically generating data for text-based CAD editing, which involves data engineering pertinent to LLM training."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2502.04700",
      "abstract": "The rapid growth of large models has raised concerns about their environmental impact and equity in accessibility due to significant computational costs. Low-Rank Adapters (LoRA) offer a lightweight solution for finetuning large models, resulting in an abundance of publicly available adapters tailored to diverse domains. We ask: Can these pretrained adapters be leveraged to further streamline adaptation to new tasks while addressing these challenges? We introduce EigenLoRAx, a parameter-efficient finetuning method that recycles existing adapters to create a principal subspace aligned with their shared domain knowledge which can be further augmented with orthogonal basis vectors in low-resource scenarios. This enables rapid adaptation to new tasks by learning only lightweight coefficients on the principal components of the subspace-eliminating the need to finetune entire adapters. EigenLoRAx requires significantly fewer parameters and memory, improving efficiency for both training and inference. Our method demonstrates strong performance across diverse domains and tasks, offering a scalable for edge-based applications, personalization, and equitable deployment of large models in resource-constrained environments.",
      "authors": [
        "Prakhar Kaushik and Ankit Vaidya and Shravan Chaudhari and Alan Yuille"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-07T07:07:04+00:00",
          "link": "https://arxiv.org/abs/2502.04700v1",
          "size": "38214kb",
          "version": "v1"
        },
        {
          "date": "2025-02-18T19:41:19+00:00",
          "link": "https://arxiv.org/abs/2502.04700v2",
          "size": "16134kb",
          "version": "v2"
        },
        {
          "date": "2025-02-28T01:25:58+00:00",
          "link": "https://arxiv.org/abs/2502.04700v3",
          "size": "16110kb",
          "version": "v3"
        },
        {
          "date": "2025-07-03T02:34:41+00:00",
          "link": "https://arxiv.org/abs/2502.04700v4",
          "size": "16039kb",
          "version": "v4"
        }
      ],
      "title": "EigenLoRAx: Recycling Adapters to Find Principal Subspaces for Resource-Efficient Adaptation and Inference",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.04700",
        "HTML": "https://arxiv.org/html/2502.04700v4",
        "PDF": "https://arxiv.org/pdf/2502.04700"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper focuses on fine-tuning large models using pre-existing adapters, which is related to training-stage data processing but does not introduce new methods for data preparation or processing specifically for LLMs."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/toshi2k2/EigenLoRA"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.05673",
      "abstract": "Dataset distillation, which condenses large-scale datasets into compact synthetic representations, has emerged as a critical solution for training modern deep learning models efficiently. While prior surveys focus on developments before 2023, this work comprehensively reviews recent advances, emphasizing scalability to large-scale datasets such as ImageNet-1K and ImageNet-21K. We categorize progress into a few key methodologies: trajectory matching, gradient matching, distribution matching, scalable generative approaches, and decoupling optimization mechanisms. As a comprehensive examination of recent dataset distillation advances, this survey highlights breakthrough innovations: the SRe2L framework for efficient and effective condensation, soft label strategies that significantly enhance model accuracy, and lossless distillation techniques that maximize compression while maintaining performance. Beyond these methodological advancements, we address critical challenges, including robustness against adversarial and backdoor attacks, effective handling of non-IID data distributions. Additionally, we explore emerging applications in video and audio processing, multi-modal learning, medical imaging, and scientific computing, highlighting its domain versatility. By offering extensive performance comparisons and actionable research directions, this survey equips researchers and practitioners with practical insights to advance efficient and generalizable dataset distillation, paving the way for future innovations.",
      "authors": [
        "Ping Liu and Jiawei Du"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-08T19:37:33+00:00",
          "link": "https://arxiv.org/abs/2502.05673v1",
          "size": "11057kb",
          "version": "v1"
        },
        {
          "date": "2025-02-27T18:16:08+00:00",
          "link": "https://arxiv.org/abs/2502.05673v2",
          "size": "11062kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T14:56:22+00:00",
          "link": "https://arxiv.org/abs/2502.05673v3",
          "size": "2421kb",
          "version": "v3"
        }
      ],
      "title": "The Evolution of Dataset Distillation: Toward Scalable and Generalizable Solutions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.05673",
        "HTML": "https://arxiv.org/html/2502.05673v3",
        "PDF": "https://arxiv.org/pdf/2502.05673"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This survey reviews dataset distillation techniques, which relates indirectly to LLM training data by discussing data efficiency but does not propose new methods for data processing in the context of LLMs."
      },
      "tasks": [
        "Dataset Distillation",
        "Survey"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.05989",
      "abstract": "In this work, we investigate the computational aspects of asynchronous cellular automata (ACAs), a modification of cellular automata in which cells update independently, following an asynchronous schedule. We introduce flip automata networks (FAN), a simple modification of automata networks that remain robust under any asynchronous update schedule. We show that asynchronous automata can efficiently simulate their synchronous counterparts with a linear memory overhead, which improves upon the previously established quadratic bound. Additionally, we address the universality gap for (a)synchronous cellular automata -- the boundary separating universal and non-universal automata, which is still not fully understood. We tighten this boundary by proving that all one-way asynchronous automata lack universal computational power. Conversely, we establish the existence of a universal 6-state first-neighbor automaton in one dimension and a 3-state von Neumann automaton in two dimensions, which represent the smallest known universal constructions to date.",
      "authors": [
        "Ivan Baburin",
        "Matthew Cook",
        "Florian Gr\\\"otschla",
        "Andreas Plesner",
        "Roger Wattenhofer"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Formal Languages and Automata Theory (cs.FL)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-09T18:43:28+00:00",
          "link": "https://arxiv.org/abs/2502.05989v1",
          "size": "1788kb",
          "version": "v1"
        },
        {
          "date": "2025-04-15T20:23:16+00:00",
          "link": "https://arxiv.org/abs/2502.05989v2",
          "size": "1792kb",
          "version": "v2"
        },
        {
          "date": "2025-07-02T20:16:00+00:00",
          "link": "https://arxiv.org/abs/2502.05989v3",
          "size": "389kb",
          "version": "v3"
        }
      ],
      "title": "Universality Frontier for Asynchronous Cellular Automata",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.05989",
        "PDF": "https://arxiv.org/pdf/2502.05989"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses computational aspects of asynchronous cellular automata, which does not relate to the processing or engineering of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.06106",
      "abstract": "The study of mechanistic interpretability aims to reverse-engineer a model to explain its behaviors. While recent studies have focused on the static mechanism of a certain behavior, the learning dynamics inside a model remain to be explored. In this work, we develop an interpretable fine-tuning method for analyzing the mechanism behind learning. We first introduce the concept of node-level intrinsic dimensionality to describe the learning process of a model in a computational graph. Based on our theory, we propose circuit-tuning, a two-stage algorithm that iteratively builds the minimal subgraph for a specific task and updates the key parameters in a heuristic way. Experimental results confirm the existence of the intrinsic dimensionality at the node level and demonstrate the effectiveness of our method for transparent and interpretable fine-tuning. We visualize and analyze the circuits before, during, and after fine-tuning, providing new insights into the self-organization mechanism of a neural network in the learning process.",
      "authors": [
        "Yueyan Li",
        "Wenhao Gao",
        "Caixia Yuan",
        "Xiaojie Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-10T02:35:53+00:00",
          "link": "https://arxiv.org/abs/2502.06106v1",
          "size": "309kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T03:07:00+00:00",
          "link": "https://arxiv.org/abs/2502.06106v2",
          "size": "337kb",
          "version": "v2"
        }
      ],
      "title": "Circuit-tuning: A Mechanistic Approach for Identifying Parameter Redundancy and Fine-tuning Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.06106",
        "HTML": "https://arxiv.org/html/2502.06106v2",
        "PDF": "https://arxiv.org/pdf/2502.06106"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While this paper presents a method for fine-tuning neural networks, it focuses on interpretability and parameter redundancy, not directly on LLM data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.06477",
      "abstract": "ARRIVAL is the problem of deciding which out of two possible destinations will be reached first by a token that moves deterministically along the edges of a directed graph, according to so-called switching rules. It is known to lie in NP $\\cap$ CoNP, but not known to lie in P. The state-of-the-art algorithm due to G\\\"artner et al. (ICALP `21) runs in time $2^{O(\\sqrt{n} \\log n)}$ on an $n$-vertex graph.\n  We prove that ARRIVAL can be solved in time $2^{O(k \\log^2 n)}$ on $n$-vertex graphs of treewidth $k$. Our algorithm is derived by adapting a simple recursive algorithm for a generalization of ARRIVAL called G-ARRIVAL. This simple recursive algorithm acts as a framework from which we can also rederive the subexponential upper bound of G\\\"artner et al.\n  Our second result is a reduction from G-ARRIVAL to the problem of finding an approximate fixed point of an $\\ell_1$-contracting function $f : [0, 1]^n \\rightarrow [0, 1]^n$. Finding such fixed points is a well-studied problem in the case of the $\\ell_2$-metric and the $\\ell_\\infty$-metric, but little is known about the $\\ell_1$-case.\n  Both of our results highlight parallels between ARRIVAL and the Simple Stochastic Games (SSG) problem. Concretely, Chatterjee et al. (SODA `23) gave an algorithm for SSG parameterized by treewidth that achieves a similar bound as we do for ARRIVAL, and SSG is known to reduce to $\\ell_\\infty$-contraction.",
      "authors": [
        "Sebastian Haslebacher"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-10T13:55:59+00:00",
          "link": "https://arxiv.org/abs/2502.06477v1",
          "size": "409kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T11:46:26+00:00",
          "link": "https://arxiv.org/abs/2502.06477v2",
          "size": "287kb",
          "version": "v2"
        }
      ],
      "title": "ARRIVAL: Recursive Framework & $\\ell_1$-Contraction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.06477",
        "HTML": "https://arxiv.org/html/2502.06477v2",
        "PDF": "https://arxiv.org/pdf/2502.06477"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research addresses a problem related to graph theory and algorithm complexity, with no connection to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.06684",
      "abstract": "Recent foundational models for tabular data, such as TabPFN, excel at adapting to new tasks via in-context learning, but remain constrained to a fixed, pre-defined number of target dimensions-often necessitating costly ensembling strategies. We trace this constraint to a deeper architectural shortcoming: these models lack target equivariance, so that permuting target dimension orderings alters their predictions. This deficiency gives rise to an irreducible \"equivariance gap\", an error term that introduces instability in predictions. We eliminate this gap by designing a fully target-equivariant architecture-ensuring permutation invariance via equivariant encoders, decoders, and a bi-attention mechanism. Empirical evaluation on standard classification benchmarks shows that, on datasets with more classes than those seen during pre-training, our model matches or surpasses existing methods while incurring lower computational overhead.",
      "authors": [
        "Michael Arbel",
        "David Salinas",
        "Frank Hutter"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-10T17:11:20+00:00",
          "link": "https://arxiv.org/abs/2502.06684v1",
          "size": "455kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T08:22:46+00:00",
          "link": "https://arxiv.org/abs/2502.06684v2",
          "size": "541kb",
          "version": "v2"
        }
      ],
      "title": "EquiTabPFN: A Target-Permutation Equivariant Prior Fitted Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.06684",
        "HTML": "https://arxiv.org/html/2502.06684v2",
        "PDF": "https://arxiv.org/pdf/2502.06684"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper primarily discusses architectural improvements in tabular data models for target equivariance rather than LLMs or their training data processing."
      },
      "tasks": [
        "In-Context Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.11268",
      "abstract": "As artificial intelligence surpasses human capabilities in text generation, the necessity to authenticate the origins of AI-generated content has become paramount. Unbiased watermarks offer a powerful solution by embedding statistical signals into language model-generated text without distorting the quality. In this paper, we introduce MCmark, a family of unbiased, Multi-Channel-based watermarks. MCmark works by partitioning the model's vocabulary into segments and promoting token probabilities within a selected segment based on a watermark key. We demonstrate that MCmark not only preserves the original distribution of the language model but also offers significant improvements in detectability and robustness over existing unbiased watermarks. Our experiments with widely-used language models demonstrate an improvement in detectability of over 10% using MCmark, compared to existing state-of-the-art unbiased watermarks. This advancement underscores MCmark's potential in enhancing the practical application of watermarking in AI-generated texts.",
      "authors": [
        "Ruibo Chen",
        "Yihan Wu",
        "Junfeng Guo",
        "Heng Huang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-16T21:02:36+00:00",
          "link": "https://arxiv.org/abs/2502.11268v1",
          "size": "570kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T17:51:44+00:00",
          "link": "https://arxiv.org/abs/2502.11268v2",
          "size": "403kb",
          "version": "v2"
        }
      ],
      "title": "Improved Unbiased Watermark for Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.11268",
        "HTML": "https://arxiv.org/html/2502.11268v2",
        "PDF": "https://arxiv.org/pdf/2502.11268"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on watermarking techniques for LLM-generated text to improve detectability, with no substantial focus on the processing of training data for LLMs."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Text Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.11853",
      "abstract": "In this work, we present a series of structure transformation attacks on LLM alignment, where we encode natural language intent using diverse syntax spaces, ranging from simple structure formats and basic query languages (e.g., SQL) to new novel spaces and syntaxes created entirely by LLMs. Our extensive evaluation shows that our simplest attacks can achieve close to a 90% success rate, even on strict LLMs (such as Claude 3.5 Sonnet) using SOTA alignment mechanisms. We improve the attack performance further by using an adaptive scheme that combines structure transformations along with existing content transformations, resulting in over 96% ASR with 0% refusals.\n  To generalize our attacks, we explore numerous structure formats, including syntaxes purely generated by LLMs. Our results indicate that such novel syntaxes are easy to generate and result in a high ASR, suggesting that defending against our attacks is not a straightforward process. Finally, we develop a benchmark and evaluate existing safety-alignment defenses against it, showing that most of them fail with 100% ASR. Our results show that existing safety alignment mostly relies on token-level patterns without recognizing harmful concepts, highlighting and motivating the need for serious research efforts in this direction. As a case study, we demonstrate how attackers can use our attack to easily generate a sample malware and a corpus of fraudulent SMS messages, which perform well in bypassing detection.",
      "authors": [
        "Shehel Yoosuf",
        "Temoor Ali",
        "Ahmed Lekssays",
        "Mashael AlSabah",
        "Issa Khalil"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-17T14:46:38+00:00",
          "link": "https://arxiv.org/abs/2502.11853v1",
          "size": "2564kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T13:25:12+00:00",
          "link": "https://arxiv.org/abs/2502.11853v2",
          "size": "479kb",
          "version": "v2"
        }
      ],
      "title": "StructTransform: A Scalable Attack Surface for Safety-Aligned Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.11853",
        "HTML": "https://arxiv.org/html/2502.11853v2",
        "PDF": "https://arxiv.org/pdf/2502.11853"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with attack strategies on LLMs and safety alignment, not on the processing or preparation of training data for these models."
      },
      "tasks": [
        "Safety Alignment"
      ],
      "repo_urls": [
        "https://github.com/structtransform/benchmark"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.13450",
      "abstract": "We introduce Interleaved Gibbs Diffusion (IGD), a novel generative modeling framework for discrete-continuous data, focusing on problems with important, implicit and unspecified constraints in the data. Most prior works on discrete and discrete-continuous diffusion assume a factorized denoising distribution, which can hinder the modeling of strong dependencies between random variables in such problems. We empirically demonstrate a significant improvement in 3-SAT performance out of the box by switching to a Gibbs-sampling style discrete diffusion model which does not assume factorizability. Motivated by this, we introduce IGD which generalizes discrete time Gibbs sampling type Markov chain for the case of discrete-continuous generation. IGD allows for seamless integration between discrete and continuous denoisers while theoretically guaranteeing exact reversal of a suitable forward process. Further, it provides flexibility in the choice of denoisers, allows conditional generation via state-space doubling and inference time refinement. Empirical evaluations on three challenging generation tasks - molecule structures, layouts and tabular data - demonstrate state-of-the-art performance. Notably, IGD achieves state-of-the-art results without relying on domain-specific inductive biases like equivariant diffusion or auxiliary losses. We explore a wide range of modeling, and interleaving strategies along with hyperparameters in each of these problems.",
      "authors": [
        "Gautham Govind Anil",
        "Sachin Yadav",
        "Dheeraj Nagaraj",
        "Karthikeyan Shanmugam",
        "Prateek Jain"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-19T05:51:24+00:00",
          "link": "https://arxiv.org/abs/2502.13450v1",
          "size": "344kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T12:02:01+00:00",
          "link": "https://arxiv.org/abs/2502.13450v2",
          "size": "354kb",
          "version": "v2"
        }
      ],
      "title": "Interleaved Gibbs Diffusion: Generating Discrete-Continuous Data with Implicit Constraints",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.13450",
        "HTML": "https://arxiv.org/html/2502.13450v2",
        "PDF": "https://arxiv.org/pdf/2502.13450"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research introduces a framework for generative modeling of discrete-continuous data but does not focus on training data processing for LLMs."
      },
      "tasks": [
        "Denoising"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.16025",
      "abstract": "The feature maps of vision encoders are fundamental to myriad modern AI tasks, ranging from core perception algorithms (e.g. semantic segmentation, object detection, depth perception, etc.) to modern multimodal understanding in vision-language models (VLMs). Currently, in computer vision, the frontier of general purpose vision backbones is Vision Transformers (ViT), typically trained using contrastive loss (e.g. CLIP). A key problem with most off-the-shelf ViTs, particularly CLIP, is that these models are inflexibly low resolution. Most run at $224 \\times 224$px, while the \"high-resolution\" versions are around $378-448$px, but still inflexible. We introduce a novel method to coherently and cheaply upsample the feature maps of low-resolution vision encoders while picking up on fine-grained details that would otherwise be lost due to resolution. We demonstrate the effectiveness of this approach on core perception tasks as well as within agglomerative model training using RADIO as a way of providing richer targets for distillation. Code available at https://github.com/NVlabs/FeatSharp .",
      "authors": [
        "Mike Ranzinger",
        "Greg Heinrich",
        "Pavlo Molchanov",
        "Jan Kautz",
        "Bryan Catanzaro",
        "Andrew Tao"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-22T00:54:49+00:00",
          "link": "https://arxiv.org/abs/2502.16025v1",
          "size": "28296kb",
          "version": "v1"
        },
        {
          "date": "2025-07-02T18:32:05+00:00",
          "link": "https://arxiv.org/abs/2502.16025v2",
          "size": "16506kb",
          "version": "v2"
        }
      ],
      "title": "FeatSharp: Your Vision Model Features, Sharper",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.16025",
        "HTML": "https://arxiv.org/html/2502.16025v2",
        "PDF": "https://arxiv.org/pdf/2502.16025"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving the resolution of feature maps in vision models and does not pertain to the processing or engineering of training data for LLMs."
      },
      "tasks": [
        "model",
        "object-detection",
        "Object Detection",
        "Semantic Segmentation"
      ],
      "repo_urls": [
        "https://github.com/nvlabs/radio"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.16095",
      "abstract": "Remote Sensing Image Captioning (RSIC) is the process of generating meaningful descriptions from remote sensing images. Recently, it has gained significant attention, with encoder-decoder models serving as the backbone for generating meaningful captions. The encoder extracts essential visual features from the input image, transforming them into a compact representation, while the decoder utilizes this representation to generate coherent textual descriptions. Recently, transformer-based models have gained significant popularity due to their ability to capture long-range dependencies and contextual information. The decoder has been well explored for text generation, whereas the encoder remains relatively unexplored. However, optimizing the encoder is crucial as it directly influences the richness of extracted features, which in turn affects the quality of generated captions. To address this gap, we systematically evaluate twelve different convolutional neural network (CNN) architectures within a transformer-based encoder framework to assess their effectiveness in RSIC. The evaluation consists of two stages: first, a numerical analysis categorizes CNNs into different clusters, based on their performance. The best performing CNNs are then subjected to human evaluation from a human-centric perspective by a human annotator. Additionally, we analyze the impact of different search strategies, namely greedy search and beam search, to ensure the best caption. The results highlight the critical role of encoder selection in improving captioning performance, demonstrating that specific CNN architectures significantly enhance the quality of generated descriptions for remote sensing images. By providing a detailed comparison of multiple encoders, this study offers valuable insights to guide advances in transformer-based image captioning models.",
      "authors": [
        "Swadhin Das and Saarthak Gupta and Kamal Kumar and Raksha Sharma"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-22T05:36:28+00:00",
          "link": "https://arxiv.org/abs/2502.16095v1",
          "size": "1991kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T07:07:36+00:00",
          "link": "https://arxiv.org/abs/2502.16095v2",
          "size": "3926kb",
          "version": "v2"
        }
      ],
      "title": "Good Representation, Better Explanation: Role of Convolutional Neural Networks in Transformer-Based Remote Sensing Image Captioning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.16095",
        "HTML": "https://arxiv.org/html/2502.16095v2",
        "PDF": "https://arxiv.org/pdf/2502.16095"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study evaluates CNN architectures within a transformer-based encoder for remote sensing image captioning, unrelated to training data processing for LLMs."
      },
      "tasks": [
        "Decoder",
        "Image Captioning",
        "Text Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.17874",
      "abstract": "Molecular machine learning has gained popularity with the advancements of geometric deep learning. In parallel, retrieval-augmented generation has become a principled approach commonly used with language models. However, the optimal integration of retrieval augmentation into molecular machine learning remains unclear. Graph neural networks stand to benefit from clever matching to understand the structural alignment of retrieved molecules to a query molecule. Neural graph matching offers a compelling solution by explicitly modeling node and edge affinities between two structural graphs while employing a noise-robust, end-to-end neural network to learn affinity metrics. We apply this approach to mass spectrum simulation and introduce MARASON, a novel model that incorporates neural graph matching to enhance a fragmentation-based neural network. Experimental results highlight the effectiveness of our design, with MARASON achieving 28% top-1 accuracy, a substantial improvement over the non-retrieval state-of-the-art accuracy of 19%. Moreover, MARASON outperforms both naive retrieval-augmented generation methods and traditional graph matching approaches. Code is publicly available at https://github.com/coleygroup/ms-pred",
      "authors": [
        "Runzhong Wang",
        "Rui-Xi Wang",
        "Mrunali Manjrekar",
        "Connor W. Coley"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Quantitative Methods (q-bio.QM)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-25T05:59:14+00:00",
          "link": "https://arxiv.org/abs/2502.17874v1",
          "size": "2217kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T03:15:08+00:00",
          "link": "https://arxiv.org/abs/2502.17874v2",
          "size": "2356kb",
          "version": "v2"
        }
      ],
      "title": "Neural Graph Matching Improves Retrieval Augmented Generation in Molecular Machine Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.17874",
        "HTML": "https://arxiv.org/html/2502.17874v2",
        "PDF": "https://arxiv.org/pdf/2502.17874"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on graph matching for molecular machine learning, which does not relate to processing or engineering training data for LLMs."
      },
      "tasks": [
        "Graph Matching",
        "Retrieval",
        "Retrieval-augmented Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.18437",
      "abstract": "A number of recent studies have focused on developing surgical simulation platforms to train machine learning (ML) agents or models with synthetic data for surgical assistance. While existing platforms excel at tasks such as rigid body manipulation and soft body deformation, they struggle to simulate more complex soft body behaviors like cutting and suturing. A key challenge lies in modeling soft body fracture and splitting using the finite-element method (FEM), which is the predominant approach in current platforms. Additionally, the two-way suture needle/thread contact inside a soft body is further complicated when using FEM. In this work, we use the material point method (MPM) for such challenging simulations and propose new rigid geometries and soft-rigid contact methods specifically designed for them. We introduce CRESSim-MPM, a GPU-accelerated MPM library that integrates multiple MPM solvers and incorporates surgical geometries for cutting and suturing, serving as a specialized physics engine for surgical applications. It is further integrated into Unity, requiring minimal modifications to existing projects for soft body simulation. We demonstrate the simulator's capabilities in real-time simulation of cutting and suturing on soft tissue and provide an initial performance evaluation of different MPM solvers when simulating varying numbers of particles. The source code is available at https://github.com/yafei-ou/CRESSim-MPM.",
      "authors": [
        "Yafei Ou",
        "Mahdi Tavakoli"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-25T18:31:03+00:00",
          "link": "https://arxiv.org/abs/2502.18437v1",
          "size": "1763kb",
          "version": "v1"
        },
        {
          "date": "2025-03-01T18:44:59+00:00",
          "link": "https://arxiv.org/abs/2502.18437v2",
          "size": "1763kb",
          "version": "v2"
        },
        {
          "date": "2025-07-02T18:52:33+00:00",
          "link": "https://arxiv.org/abs/2502.18437v3",
          "size": "1569kb",
          "version": "v3"
        }
      ],
      "title": "CRESSim-MPM: A Material Point Method Library for Surgical Soft Body Simulation with Cutting and Suturing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.18437",
        "HTML": "https://arxiv.org/html/2502.18437v3",
        "PDF": "https://arxiv.org/pdf/2502.18437"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a simulation library for surgical applications using the Material Point Method, with no relation to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.19617",
      "abstract": "This work presents a motion planning framework for robotic manipulators that computes collision-free paths directly in image space. The generated paths can then be tracked using vision-based control, eliminating the need for an explicit robot model or proprioceptive sensing. At the core of our approach is the construction of a roadmap entirely in image space. To achieve this, we explicitly define sampling, nearest-neighbor selection, and collision checking based on visual features rather than geometric models. We first collect a set of image-space samples by moving the robot within its workspace, capturing keypoints along its body at different configurations. These samples serve as nodes in the roadmap, which we construct using either learned or predefined distance metrics. At runtime, the roadmap generates collision-free paths directly in image space, removing the need for a robot model or joint encoders. We validate our approach through an experimental study in which a robotic arm follows planned paths using an adaptive vision-based control scheme to avoid obstacles. The results show that paths generated with the learned-distance roadmap achieved 100% success in control convergence, whereas the predefined image-space distance roadmap enabled faster transient responses but had a lower success rate in convergence.",
      "authors": [
        "Sreejani Chatterjee",
        "Abhinav Gandhi",
        "Berk Calli",
        "Constantinos Chamzas"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-26T23:09:17+00:00",
          "link": "https://arxiv.org/abs/2502.19617v1",
          "size": "2020kb",
          "version": "v1"
        },
        {
          "date": "2025-05-30T17:57:07+00:00",
          "link": "https://arxiv.org/abs/2502.19617v2",
          "size": "1038kb",
          "version": "v2"
        },
        {
          "date": "2025-07-02T19:00:55+00:00",
          "link": "https://arxiv.org/abs/2502.19617v3",
          "size": "846kb",
          "version": "v3"
        }
      ],
      "title": "Image-Based Roadmaps for Vision-Only Planning and Control of Robotic Manipulators",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.19617",
        "HTML": "https://arxiv.org/html/2502.19617v3",
        "PDF": "https://arxiv.org/pdf/2502.19617"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a motion planning framework for robotic manipulators utilizing image space paths, which is unrelated to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.19707",
      "abstract": "Weakly supervised segmentation methods can delineate thyroid nodules in ultrasound images efficiently using training data with coarse labels, but suffer from: 1) low-confidence pseudo-labels that follow topological priors, introducing significant label noise, and 2) low-rationality loss functions that rigidly compare segmentation with labels, ignoring discriminative information for nodules with diverse and complex shapes. To solve these issues, we clarify the objective and references for weakly supervised ultrasound image segmentation, presenting a framework with high-confidence pseudo-labels to represent topological and anatomical information and high-rationality losses to capture multi-level discriminative features. Specifically, we fuse geometric transformations of four-point annotations and MedSAM model results prompted by specific annotations to generate high-confidence box, foreground, and background labels. Our high-rationality learning strategy includes: 1) Alignment loss measuring spatial consistency between segmentation and box label, and topological continuity within the foreground label, guiding the network to perceive nodule location; 2) Contrastive loss pulling features from labeled foreground regions while pushing features from labeled foreground and background regions, guiding the network to learn nodule and background feature distribution; 3) Prototype correlation loss measuring consistency between correlation maps derived by comparing features with foreground and background prototypes, refining uncertain regions to accurate nodule edges. Experimental results show that our method achieves state-of-the-art performance on the TN3K and DDTI datasets. The code is available at https://github.com/bluehenglee/MLI-MSC.",
      "authors": [
        "Jianning Chi",
        "Zelan Li",
        "Geng Lin",
        "MingYang Sun",
        "and Xiaosheng Yu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-27T02:48:00+00:00",
          "link": "https://arxiv.org/abs/2502.19707v1",
          "size": "9034kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T13:11:45+00:00",
          "link": "https://arxiv.org/abs/2502.19707v2",
          "size": "17992kb",
          "version": "v2"
        }
      ],
      "title": "Weakly Supervised Segmentation Framework for Thyroid Nodule Based on High-confidence Labels and High-rationality Losses",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.19707",
        "HTML": "https://arxiv.org/html/2502.19707v2",
        "PDF": "https://arxiv.org/pdf/2502.19707"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses weakly supervised segmentation of thyroid nodules in ultrasound images, without any connection to LLM training data processing or engineering."
      },
      "tasks": [
        "Image Segmentation",
        "Segmentation",
        "Semantic Segmentation",
        "Weakly supervised segmentation"
      ],
      "repo_urls": [
        "https://github.com/bluehenglee/mli-msc"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.20323",
      "abstract": "Speech-driven 3D facial animation aims to generate realistic lip movements and facial expressions for 3D head models from arbitrary audio clips. Although existing diffusion-based methods are capable of producing natural motions, their slow generation speed limits their application potential. In this paper, we introduce a novel autoregressive model that achieves real-time generation of highly synchronized lip movements and realistic head poses and eye blinks by learning a mapping from speech to a multi-scale motion codebook. Furthermore, our model can adapt to unseen speaking styles, enabling the creation of 3D talking avatars with unique personal styles beyond the identities seen during training. Extensive evaluations and user studies demonstrate that our method outperforms existing approaches in lip synchronization accuracy and perceived quality.",
      "authors": [
        "Xuangeng Chu",
        "Nabarun Goswami",
        "Ziteng Cui",
        "Hanqin Wang",
        "Tatsuya Harada"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-27T17:49:01+00:00",
          "link": "https://arxiv.org/abs/2502.20323v1",
          "size": "3820kb",
          "version": "v1"
        },
        {
          "date": "2025-02-28T13:25:53+00:00",
          "link": "https://arxiv.org/abs/2502.20323v2",
          "size": "3820kb",
          "version": "v2"
        },
        {
          "date": "2025-06-26T06:10:09+00:00",
          "link": "https://arxiv.org/abs/2502.20323v3",
          "size": "4093kb",
          "version": "v3"
        },
        {
          "date": "2025-07-03T11:32:51+00:00",
          "link": "https://arxiv.org/abs/2502.20323v4",
          "size": "4120kb",
          "version": "v4"
        }
      ],
      "title": "ARTalk: Speech-Driven 3D Head Animation via Autoregressive Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.20323",
        "HTML": "https://arxiv.org/html/2502.20323v4",
        "PDF": "https://arxiv.org/pdf/2502.20323"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses speech-driven 3D facial animation and the development of an autoregressive model for it, which does not pertain to LLM training data processing."
      },
      "models": [
        {
          "model_path": "xg-chu/ARTalk",
          "downloads": "51",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/xg-chu/ARTalk"
        }
      ],
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2503.00027",
      "abstract": "Online extrinsic calibration is crucial for building \"power-on-and-go\" moving platforms, like robots and AR devices. However, blindly performing online calibration for unobservable parameter may lead to unpredictable results. In the literature, extensive studies have been conducted on the extrinsic calibration between IMU and camera, from theory to practice. It is well-known that the observability of extrinsic parameter can be guaranteed under sufficient motion excitation. Furthermore, the impacts of degenerate motions are also investigated. Despite these successful analyses, we identify an issue with respect to the existing observability conclusion. This paper focuses on the observability investigation for straight line motion, which is a common-seen and fundamental degenerate motion in applications. We analytically prove that pure translational straight line motion can lead to the unobservability of the rotational extrinsic parameter between IMU and camera (at least one degree of freedom). By correcting the existing observability conclusion, our novel theoretical finding disseminates more precise principle to the research community and provides explainable calibration guideline for practitioners. Our analysis is validated by rigorous theory and experiments.",
      "authors": [
        "Junlin Song",
        "Antoine Richard",
        "and Miguel Olivares-Mendez"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-24T18:55:48+00:00",
          "link": "https://arxiv.org/abs/2503.00027v1",
          "size": "6939kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T15:41:22+00:00",
          "link": "https://arxiv.org/abs/2503.00027v2",
          "size": "6938kb",
          "version": "v2"
        }
      ],
      "title": "Observability Investigation for Rotational Calibration of (Global-pose aided) VIO under Straight Line Motion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.00027",
        "HTML": "https://arxiv.org/html/2503.00027v2",
        "PDF": "https://arxiv.org/pdf/2503.00027"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on the observability investigation for straight line motion in online extrinsic calibration, unrelated to LLM training data processing or engineering."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2503.00545",
      "abstract": "Challenges in remote sensing object detection(RSOD), such as high interclass similarity, imbalanced foreground-background distribution, and the small size of objects in remote sensing images, significantly hinder detection accuracy. Moreover, the tradeoff between model accuracy and computational complexity poses additional constraints on the application of RSOD algorithms. To address these issues, this study proposes an efficient and lightweight RSOD algorithm integrating multiscale receptive fields and foreground focus mechanism, named robust foreground weighted network(RFWNet). Specifically, we proposed a lightweight backbone network receptive field adaptive selection network (RFASNet), leveraging the rich context information of remote sensing images to enhance class separability. Additionally, we developed a foreground-background separation module(FBSM)consisting of a background redundant information filtering module (BRIFM) and a foreground information enhancement module (FIEM) to emphasize critical regions within images while filtering redundant background information. Finally, we designed a loss function, the weighted CIoU-Wasserstein loss (LWCW),which weights the IoU-based loss by using the normalized Wasserstein distance to mitigate model sensitivity to small object position deviations. The comprehensive experimental results demonstrate that RFWNet achieved 95.3% and 73.2% mean average precision (mAP) with 6.0 M parameters on the DOTA V1.0 and NWPU VHR-10 datasets, respectively, with an inference speed of 52 FPS.",
      "authors": [
        "Yujie Lei",
        "Wenjie Sun",
        "Sen Jia",
        "Qingquan Li",
        "Jie Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-01T16:02:15+00:00",
          "link": "https://arxiv.org/abs/2503.00545v1",
          "size": "874kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T14:01:54+00:00",
          "link": "https://arxiv.org/abs/2503.00545v2",
          "size": "613kb",
          "version": "v2"
        }
      ],
      "title": "RFWNet: A Lightweight Remote Sensing Object Detector Integrating Multiscale Receptive Fields and Foreground Focus Mechanism",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.00545",
        "PDF": "https://arxiv.org/pdf/2503.00545"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study explores remote sensing object detection with a focus on lightweight models, and does not involve LLM training data collection, processing, or engineering."
      },
      "tasks": [
        "object-detection",
        "Object Detection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.00958",
      "abstract": "We propose a new approach for the authorship attribution task that leverages the various linguistic representations learned at different layers of pre-trained transformer-based models. We evaluate our approach on three datasets, comparing it to a state-of-the-art baseline in in-domain and out-of-domain scenarios. We found that utilizing various transformer layers improves the robustness of authorship attribution models when tested on out-of-domain data, resulting in new state-of-the-art results. Our analysis gives further insights into how our model's different layers get specialized in representing certain stylistic features that benefit the model when tested out of the domain.",
      "authors": [
        "Milad Alshomary",
        "Nikhil Reddy Varimalla",
        "Vishal Anand",
        "Smaranda Muresan",
        "and Kathleen McKeown"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-02T16:47:31+00:00",
          "link": "https://arxiv.org/abs/2503.00958v1",
          "size": "8936kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T06:07:21+00:00",
          "link": "https://arxiv.org/abs/2503.00958v2",
          "size": "6976kb",
          "version": "v2"
        }
      ],
      "title": "Layered Insights: Generalizable Analysis of Authorial Style by Leveraging All Transformer Layers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.00958",
        "HTML": "https://arxiv.org/html/2503.00958v2",
        "PDF": "https://arxiv.org/pdf/2503.00958"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on authorship attribution using transformer layers, which does not directly involve the processing of training data for LLMs related to data engineering or training-stage data processing."
      },
      "models": [
        {
          "model_path": "miladalsh/light-luar-reddit",
          "downloads": "4",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/miladalsh/light-luar-reddit"
        }
      ],
      "tasks": [
        "All",
        "Authorship Attribution"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.03259",
      "abstract": "State-of-the-art stereo matching methods typically use costly 3D convolutions to aggregate a full cost volume, but their computational demands make mobile deployment challenging. Directly applying 2D convolutions for cost aggregation often results in edge blurring, detail loss, and mismatches in textureless regions. Some complex operations, like deformable convolutions and iterative warping, can partially alleviate this issue; however, they are not mobile-friendly, limiting their deployment on mobile devices. In this paper, we present a novel bilateral aggregation network (BANet) for mobile stereo matching that produces high-quality results with sharp edges and fine details using only 2D convolutions. Specifically, we first separate the full cost volume into detailed and smooth volumes using a spatial attention map, then perform detailed and smooth aggregations accordingly, ultimately fusing both to obtain the final disparity map. Experimental results demonstrate that our BANet-2D significantly outperforms other mobile-friendly methods, achieving 35.3\\% higher accuracy on the KITTI 2015 leaderboard than MobileStereoNet-2D, with faster runtime on mobile devices. Code: \\textcolor{magenta}{https://github.com/gangweix/BANet}.",
      "authors": [
        "Gangwei Xu",
        "Jiaxin Liu",
        "Xianqi Wang",
        "Junda Cheng",
        "Yong Deng",
        "Jinliang Zang",
        "Yurui Chen",
        "Xin Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-05T08:33:08+00:00",
          "link": "https://arxiv.org/abs/2503.03259v1",
          "size": "6061kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T11:56:07+00:00",
          "link": "https://arxiv.org/abs/2503.03259v2",
          "size": "6063kb",
          "version": "v2"
        }
      ],
      "title": "BANet: Bilateral Aggregation Network for Mobile Stereo Matching",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.03259",
        "HTML": "https://arxiv.org/html/2503.03259v2",
        "PDF": "https://arxiv.org/pdf/2503.03259"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a method for mobile stereo matching using a bilateral aggregation network. It does not address any aspects related to LLM training data."
      },
      "tasks": [
        "Stereo Matching"
      ],
      "repo_urls": [
        "https://github.com/gangweix/banet"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.03935",
      "abstract": "Postprandial hyperglycemia, marked by the blood glucose level exceeding the normal range after consuming a meal, is a critical indicator of progression toward type 2 diabetes in people with prediabetes and in healthy individuals. A key metric for understanding blood glucose dynamics after eating is the postprandial area under the curve (AUC). Predicting postprandial AUC in advance based on a person's lifestyle factors, such as diet and physical activity level, and explaining the factors that affect postprandial blood glucose could allow an individual to adjust their lifestyle accordingly to maintain normal glucose levels. In this study, we developed an explainable machine learning solution, GlucoLens, that takes sensor-driven inputs and uses advanced data processing, large language models, and trainable machine learning models to predict postprandial AUC and hyperglycemia from diet, physical activity, and recent glucose patterns. We used data obtained from wearables in a five-week clinical trial of 10 adults who worked full-time to develop and evaluate the proposed computational model that integrates wearable sensing, multimodal data, and machine learning. Our machine learning model takes multimodal data from wearable activity and glucose monitoring sensors, along with food and work logs, and provides an interpretable prediction of the postprandial glucose pattern. Our GlucoLens system achieves a normalized root mean squared error (NRMSE) of 0.123 in its best configuration. On average, the proposed technology provides a 16% better performance level compared to the comparison models. Additionally, our technique predicts hyperglycemia with an accuracy of 73.3% and an F1 score of 0.716 and recommends different treatment options to help avoid hyperglycemia through diverse counterfactual explanations. Code available: https://github.com/ab9mamun/GlucoLens.",
      "authors": [
        "Abdullah Mamun",
        "Asiful Arefeen",
        "Susan B. Racette",
        "Dorothy D. Sears",
        "Corrie M. Whisner",
        "Matthew P. Buman",
        "Hassan Ghasemzadeh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-05T22:10:14+00:00",
          "link": "https://arxiv.org/abs/2503.03935v1",
          "size": "2108kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T16:39:21+00:00",
          "link": "https://arxiv.org/abs/2503.03935v2",
          "size": "4559kb",
          "version": "v2"
        }
      ],
      "title": "LLM-Powered Prediction of Hyperglycemia and Discovery of Behavioral Treatment Pathways from Wearables and Diet",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.03935",
        "HTML": "https://arxiv.org/html/2503.03935v2",
        "PDF": "https://arxiv.org/pdf/2503.03935"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper uses large language models and machine learning to predict glucose levels based on data from wearable sensors. Although it mentions data processing, the focus is not on LLM training data collection or processing but rather on application-specific data modeling."
      },
      "tasks": [
        "counterfactual"
      ],
      "repo_urls": [
        "https://github.com/ab9mamun/GlucoLens"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.04174",
      "abstract": "As modern networks grow increasingly complex--driven by diverse devices, encrypted protocols, and evolving threats--network traffic analysis has become critically important. Existing machine learning models often rely only on a single representation of packets or flows, limiting their ability to capture the contextual relationships essential for robust analysis. Furthermore, task-specific architectures for supervised, semi-supervised, and unsupervised learning lead to inefficiencies in adapting to varying data formats and security tasks. To address these gaps, we propose UniNet, a unified framework that introduces a novel multi-granular traffic representation (T-Matrix), integrating session, flow, and packet-level features to provide comprehensive contextual information. Combined with T-Attent, a lightweight attention-based model, UniNet efficiently learns latent embeddings for diverse security tasks. Extensive evaluations across four key network security and privacy problems--anomaly detection, attack classification, IoT device identification, and encrypted website fingerprinting--demonstrate UniNet's significant performance gain over state-of-the-art methods, achieving higher accuracy, lower false positive rates, and improved scalability. By addressing the limitations of single-level models and unifying traffic analysis paradigms, UniNet sets a new benchmark for modern network security.",
      "authors": [
        "Binghui Wu",
        "Dinil Mon Divakaran",
        "Mohan Gurusamy"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)",
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-06T07:39:37+00:00",
          "link": "https://arxiv.org/abs/2503.04174v1",
          "size": "5998kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T06:09:01+00:00",
          "link": "https://arxiv.org/abs/2503.04174v2",
          "size": "890kb",
          "version": "v2"
        }
      ],
      "title": "UniNet: A Unified Multi-granular Traffic Modeling Framework for Network Security",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.04174",
        "HTML": "https://arxiv.org/html/2503.04174v2",
        "PDF": "https://arxiv.org/pdf/2503.04174"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "UniNet is a framework for network traffic modeling and does not address LLM training data processing. Its focus is on network traffic analysis, not LLM data engineering or processing."
      },
      "tasks": [
        "Anomaly Detection",
        "IoT Device Identification"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.04564",
      "abstract": "Secure aggregation is motivated by federated learning (FL) where a cloud server aims to compute an averaged model (i.e., weights of deep neural networks) of the locally-trained models of numerous clients, while adhering to data security requirements. Hierarchical secure aggregation (HSA) extends this concept to a three-layer hierarchical network, where clustered users communicate with the server through an intermediate layer of relays. In HSA, beyond conventional server security, relay security is also enforced to ensure that the relays remain oblivious to the users' inputs (an abstraction of the local models in FL). Existing study on HSA assumes that each user is associated with only one relay, limiting opportunities for coding across inter-cluster users to achieve efficient communication and key generation. In this paper, we consider HSA with a cyclic association pattern where each user is connected to $B$ consecutive relays in a wrap-around manner. We propose an efficient aggregation scheme which includes a message design for the inputs inspired by gradient coding-a well-known technique for efficient communication in distributed computing-along with a highly non-trivial security key design. We also derive novel converse bounds on the minimum achievable communication and key rates using information-theoretic arguments.",
      "authors": [
        "Xiang Zhang",
        "Zhou Li",
        "Kai Wan",
        "Hua Sun",
        "Mingyue Ji",
        "Giuseppe Caire"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Artificial Intelligence (cs.AI)",
        "Cryptography and Security (cs.CR)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-06T15:53:37+00:00",
          "link": "https://arxiv.org/abs/2503.04564v1",
          "size": "459kb",
          "version": "v1"
        },
        {
          "date": "2025-03-07T10:01:49+00:00",
          "link": "https://arxiv.org/abs/2503.04564v2",
          "size": "459kb",
          "version": "v2"
        },
        {
          "date": "2025-05-21T20:35:06+00:00",
          "link": "https://arxiv.org/abs/2503.04564v3",
          "size": "475kb",
          "version": "v3"
        },
        {
          "date": "2025-07-02T21:12:22+00:00",
          "link": "https://arxiv.org/abs/2503.04564v4",
          "size": "568kb",
          "version": "v4"
        }
      ],
      "title": "Fundamental Limits of Hierarchical Secure Aggregation with Cyclic User Association",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.04564",
        "HTML": "https://arxiv.org/html/2503.04564v4",
        "PDF": "https://arxiv.org/pdf/2503.04564"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses hierarchical secure aggregation in federated learning, focusing on secure communication and key generation, which is not related to LLM training data processing."
      },
      "tasks": [
        "Distributed Computing",
        "Federated Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.05020",
      "abstract": "Grasping is fundamental to robotic manipulation, and recent advances in large-scale grasping datasets have provided essential training data and evaluation benchmarks, accelerating the development of learning-based methods for robust object grasping. However, most existing datasets exclude deformable bodies due to the lack of scalable, robust simulation pipelines, limiting the development of generalizable models for compliant grippers and soft manipulands. To address these challenges, we present GRIP, a General Robotic Incremental Potential contact simulation dataset for universal grasping. GRIP leverages an optimized Incremental Potential Contact (IPC)-based simulator for multi-environment data generation, achieving up to 48x speedup while ensuring efficient, intersection- and inversion-free simulations for compliant grippers and deformable objects. Our fully automated pipeline generates and evaluates diverse grasp interactions across 1,200 objects and 100,000 grasp poses, incorporating both soft and rigid grippers. The GRIP dataset enables applications such as neural grasp generation and stress field prediction.",
      "authors": [
        "Siyu Ma",
        "Wenxin Du",
        "Chang Yu",
        "Ying Jiang",
        "Zeshun Zong",
        "Tianyi Xie",
        "Yunuo Chen",
        "Yin Yang",
        "Xuchen Han",
        "Chenfanfu Jiang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-06T22:46:13+00:00",
          "link": "https://arxiv.org/abs/2503.05020v1",
          "size": "8161kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T12:20:11+00:00",
          "link": "https://arxiv.org/abs/2503.05020v2",
          "size": "4850kb",
          "version": "v2"
        }
      ],
      "title": "GRIP: A General Robotic Incremental Potential Contact Simulation Dataset for Unified Deformable-Rigid Coupled Grasping",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.05020",
        "HTML": "https://arxiv.org/html/2503.05020v2",
        "PDF": "https://arxiv.org/pdf/2503.05020"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on creating a dataset for robotic grasping simulations, especially involving deformable bodies, using a specific method. It doesn't relate to the processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.05511",
      "abstract": "Novel view synthesis (NVS) from multiple captured photos of an object is a widely studied problem. Achieving high quality typically requires dense sampling of input views, which can lead to frustrating manual labor. Manually positioning cameras to maintain an optimal desired distribution can be difficult for humans, and if a good distribution is found, it is not easy to replicate. Additionally, the captured data can suffer from motion blur and defocus due to human error. In this paper, we use a lightweight object capture pipeline to reduce the manual workload and standardize the acquisition setup, with a consumer turntable to carry the object and a tripod to hold the camera. Of course, turntables and gantry systems have been frequently used to automatically capture dense samples under various views and lighting conditions; the key difference is that we use a turntable under natural environment lighting. This way, we can easily capture hundreds of valid images in several minutes without hands-on effort. However, in the object reference frame, the light conditions vary (rotate); this does not match the assumptions of standard NVS methods like 3D Gaussian splatting (3DGS). We design a neural radiance representation conditioned on light rotations, which addresses this issue and allows rendering with novel light rotations as an additional benefit. We further study the behavior of rotations and find optimal capturing strategies. We demonstrate our pipeline using 3DGS as the underlying framework, achieving higher quality and showcasing the method's potential for novel lighting and harmonization tasks.",
      "authors": [
        "Jiahui Fan",
        "Fujun Luan",
        "Jian Yang",
        "Milo\\v{s} Ha\\v{s}an",
        "Beibei Wang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-07T15:27:44+00:00",
          "link": "https://arxiv.org/abs/2503.05511v1",
          "size": "12343kb",
          "version": "v1"
        },
        {
          "date": "2025-03-12T03:23:16+00:00",
          "link": "https://arxiv.org/abs/2503.05511v2",
          "size": "22001kb",
          "version": "v2"
        },
        {
          "date": "2025-04-15T03:51:46+00:00",
          "link": "https://arxiv.org/abs/2503.05511v3",
          "size": "22002kb",
          "version": "v3"
        },
        {
          "date": "2025-06-14T12:50:32+00:00",
          "link": "https://arxiv.org/abs/2503.05511v4",
          "size": "36439kb",
          "version": "v4"
        },
        {
          "date": "2025-07-03T15:08:46+00:00",
          "link": "https://arxiv.org/abs/2503.05511v5",
          "size": "36439kb",
          "version": "v5"
        }
      ],
      "title": "Free Your Hands: Lightweight Turntable-Based Object Capture Pipeline",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.05511",
        "HTML": "https://arxiv.org/html/2503.05511v5",
        "PDF": "https://arxiv.org/pdf/2503.05511"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper describes an object capture pipeline for novel view synthesis using cameras and a turntable, primarily addressing data acquisition for image synthesis rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.05549",
      "abstract": "This paper introduces Stereo Any Video, a powerful framework for video stereo matching. It can estimate spatially accurate and temporally consistent disparities without relying on auxiliary information such as camera poses or optical flow. The strong capability is driven by rich priors from monocular video depth models, which are integrated with convolutional features to produce stable representations. To further enhance performance, key architectural innovations are introduced: all-to-all-pairs correlation, which constructs smooth and robust matching cost volumes, and temporal convex upsampling, which improves temporal coherence. These components collectively ensure robustness, accuracy, and temporal consistency, setting a new standard in video stereo matching. Extensive experiments demonstrate that our method achieves state-of-the-art performance across multiple datasets both qualitatively and quantitatively in zero-shot settings, as well as strong generalization to real-world indoor and outdoor scenarios.",
      "authors": [
        "Junpeng Jing",
        "Weixun Luo",
        "Ye Mao",
        "Krystian Mikolajczyk"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-07T16:20:36+00:00",
          "link": "https://arxiv.org/abs/2503.05549v1",
          "size": "14519kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T11:29:20+00:00",
          "link": "https://arxiv.org/abs/2503.05549v2",
          "size": "2111kb",
          "version": "v2"
        }
      ],
      "title": "Stereo Any Video: Temporally Consistent Stereo Matching",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.05549",
        "HTML": "https://arxiv.org/html/2503.05549v2",
        "PDF": "https://arxiv.org/pdf/2503.05549"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The work is centered on stereo video processing, specifically making advancements in video stereo matching, without any focus on LLM training data or its processing stages."
      },
      "tasks": [
        "Optical Flow Estimation",
        "Stereo Matching"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.07813",
      "abstract": "The development of artificial intelligence (AI) and machine learning (ML) based tools for 3D phenotyping, especially for maize, has been limited due to the lack of large and diverse 3D datasets. 2D image datasets fail to capture essential structural details such as leaf architecture, plant volume, and spatial arrangements that 3D data provide. To address this limitation, we present MaizeField3D (https://baskargroup.github.io/MaizeField3D/), a curated dataset of 3D point clouds of field-grown maize plants from a diverse genetic panel, designed to be AI-ready for advancing agricultural research. Our dataset includes 1,045 high-quality point clouds of field-grown maize collected using a terrestrial laser scanner (TLS). Point clouds of 520 plants from this dataset were segmented and annotated using a graph-based segmentation method to isolate individual leaves and stalks, ensuring consistent labeling across all samples. This labeled data was then used for fitting procedural models that provide a structured parametric representation of the maize plants. The leaves of the maize plants in the procedural models are represented using Non-Uniform Rational B-Spline (NURBS) surfaces that were generated using a two-step optimization process combining gradient-free and gradient-based methods. We conducted rigorous manual quality control on all datasets, correcting errors in segmentation, ensuring accurate leaf ordering, and validating metadata annotations. The dataset also includes metadata detailing plant morphology and quality, alongside multi-resolution subsampled point cloud data (100k, 50k, 10k points), which can be readily used for different downstream computational tasks. MaizeField3D will serve as a comprehensive foundational dataset for AI-driven phenotyping, plant structural analysis, and 3D applications in agricultural research.",
      "authors": [
        "Elvis Kimara",
        "Mozhgan Hadadi",
        "Jackson Godbersen",
        "Aditya Balu",
        "Talukder Jubery",
        "Yawei Li",
        "Adarsh Krishnamurthy",
        "Patrick S. Schnable",
        "and Baskar Ganapathysubramanian"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-10T19:53:20+00:00",
          "link": "https://arxiv.org/abs/2503.07813v1",
          "size": "48332kb",
          "version": "v1"
        },
        {
          "date": "2025-06-24T20:04:30+00:00",
          "link": "https://arxiv.org/abs/2503.07813v2",
          "size": "44161kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T16:22:27+00:00",
          "link": "https://arxiv.org/abs/2503.07813v3",
          "size": "44164kb",
          "version": "v3"
        }
      ],
      "title": "MaizeField3D: A Curated 3D Point Cloud and Procedural Model Dataset of Field-Grown Maize from a Diversity Panel",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.07813",
        "HTML": "https://arxiv.org/html/2503.07813v3",
        "PDF": "https://arxiv.org/pdf/2503.07813"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a dataset for 3D phenotyping in agriculture, focusing on maize plant modeling. It does not address data processing for training large language models."
      },
      "datasets": [
        {
          "dataset_name": "BGLab/MaizeField3D",
          "downloads": "69",
          "likes": "2",
          "link": "https://huggingface.co/datasets/BGLab/MaizeField3D"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.07967",
      "abstract": "While large language models (LLMs) have demonstrated promise in software engineering tasks like code completion and generation, their support for the maintenance of complex software systems remains limited. These models often struggle with understanding the tacit knowledge embedded in systems, such as responsibility allocation and collaboration across different modules. To address this gap, we introduce the concept and framework of \\textbf{Code Digital Twin}, a conceptual representation of tacit knowledge that captures the concepts, functionalities, and design rationales behind code elements, co-evolving with the software. A code digital twin is constructed using a methodology that combines knowledge extraction from both structured and unstructured sources--such as source code, documentation, and change histories--leveraging LLMs, static analysis tools, and human expertise. This framework can empower LLMs for software maintenance tasks such as issue localization and repository-level code generation by providing tacit knowledge as contexts. Based on the proposed methodology, we explore the key challenges and opportunities involved in the continuous construction and refinement of code digital twin.",
      "authors": [
        "Xin Peng",
        "Chong Wang",
        "Mingwei Liu",
        "Yiling Lou",
        "Yijian Wu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-11T01:46:58+00:00",
          "link": "https://arxiv.org/abs/2503.07967v1",
          "size": "974kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T07:29:35+00:00",
          "link": "https://arxiv.org/abs/2503.07967v2",
          "size": "499kb",
          "version": "v2"
        }
      ],
      "title": "Code Digital Twin: Empowering LLMs with Tacit Knowledge for Complex Software Maintenance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.07967",
        "HTML": "https://arxiv.org/html/2503.07967v2",
        "PDF": "https://arxiv.org/pdf/2503.07967"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses using LLMs for knowledge extraction to aid in software maintenance, which involves building a 'Code Digital Twin'. While it leverages LLMs for data extraction, it does not directly propose methods for processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.08061",
      "abstract": "Realistic Hand manipulation is a key component of immersive virtual reality (VR), yet existing methods often rely on kinematic approach or motion-capture datasets that omit crucial physical attributes such as contact forces and finger torques. Consequently, these approaches prioritize tight, one-size-fits-all grips rather than reflecting users' intended force levels. We present ForceGrip, a deep learning agent that synthesizes realistic hand manipulation motions, faithfully reflecting the user's grip force intention. Instead of mimicking predefined motion datasets, ForceGrip uses generated training scenarios-randomizing object shapes, wrist movements, and trigger input flows-to challenge the agent with a broad spectrum of physical interactions. To effectively learn from these complex tasks, we employ a three-phase curriculum learning framework comprising Finger Positioning, Intention Adaptation, and Dynamic Stabilization. This progressive strategy ensures stable hand-object contact, adaptive force control based on user inputs, and robust handling under dynamic conditions. Additionally, a proximity reward function enhances natural finger motions and accelerates training convergence. Quantitative and qualitative evaluations reveal ForceGrip's superior force controllability and plausibility compared to state-of-the-art methods. Demo videos are available as supplementary material and the code is provided at https://han-dongheun.github.io/ForceGrip.",
      "authors": [
        "DongHeun Han",
        "Byungmin Kim",
        "RoUn Lee",
        "KyeongMin Kim",
        "Hyoseok Hwang",
        "HyeongYeop Kang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Graphics (cs.GR)",
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-11T05:39:07+00:00",
          "link": "https://arxiv.org/abs/2503.08061v1",
          "size": "3156kb",
          "version": "v1"
        },
        {
          "date": "2025-03-13T06:35:25+00:00",
          "link": "https://arxiv.org/abs/2503.08061v2",
          "size": "3156kb",
          "version": "v2"
        },
        {
          "date": "2025-04-30T14:03:25+00:00",
          "link": "https://arxiv.org/abs/2503.08061v3",
          "size": "4958kb",
          "version": "v3"
        },
        {
          "date": "2025-07-03T08:24:20+00:00",
          "link": "https://arxiv.org/abs/2503.08061v4",
          "size": "5003kb",
          "version": "v4"
        }
      ],
      "title": "ForceGrip: Reference-Free Curriculum Learning for Realistic Grip Force Control in VR Hand Manipulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.08061",
        "HTML": "https://arxiv.org/html/2503.08061v4",
        "PDF": "https://arxiv.org/pdf/2503.08061"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on realistic grip force control in VR via curriculum learning. It involves generating training scenarios unrelated to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2503.17046",
      "abstract": "Automatic robotic facial expression generation is crucial for human-robot interaction, as handcrafted methods based on fixed joint configurations often yield rigid and unnatural behaviors. Although recent automated techniques reduce the need for manual tuning, they tend to fall short by not adequately bridging the gap between human preferences and model predictions-resulting in a deficiency of nuanced and realistic expressions due to limited degrees of freedom and insufficient perceptual integration. In this work, we propose a novel learning-to-rank framework that leverages human feedback to address this discrepancy and enhanced the expressiveness of robotic faces. Specifically, we conduct pairwise comparison annotations to collect human preference data and develop the Human Affective Pairwise Impressions (HAPI) model, a Siamese RankNet-based approach that refines expression evaluation. Results obtained via Bayesian Optimization and online expression survey on a 35-DOF android platform demonstrate that our approach produces significantly more realistic and socially resonant expressions of Anger, Happiness, and Surprise than those generated by baseline and expert-designed methods. This confirms that our framework effectively bridges the gap between human preferences and model predictions while robustly aligning robotic expression generation with human affective responses.",
      "authors": [
        "Dongsheng Yang",
        "Qianying Liu",
        "Wataru Sato",
        "Takashi Minato",
        "Chaoran Liu",
        "Shin'ya Nishida"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-21T11:04:01+00:00",
          "link": "https://arxiv.org/abs/2503.17046v1",
          "size": "17709kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T14:55:55+00:00",
          "link": "https://arxiv.org/abs/2503.17046v2",
          "size": "17452kb",
          "version": "v2"
        }
      ],
      "title": "HAPI: A Model for Learning Robot Facial Expressions from Human Preferences",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.17046",
        "HTML": "https://arxiv.org/html/2503.17046v2",
        "PDF": "https://arxiv.org/pdf/2503.17046"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a model for robot facial expressions based on human feedback to refine expression evaluation. It does not discuss LLM training data processing or related methodologies."
      },
      "tasks": [
        "Bayesian Optimization",
        "Facial expression generation",
        "Learning-To-Rank"
      ],
      "repo_urls": [
        "https://github.com/KUCognitiveInformaticsLab/PairwiseExpressionAnnotator"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.17902",
      "abstract": "Approximating nonlinear systems as linear ones is a common workaround to apply control tools tailored for linear systems. This motivates our present work where we developed a data-driven model predictive controller (MPC) based on the Koopman operator framework, allowing the embedding of nonlinear dynamics in a higher dimensional, but linear function space. The controller, termed adaptive Koopman model predictive control (KMPC), uses online closed-loop feedback to learn and incrementally update a linear representation of nonlinear system dynamics, without the prior knowledge of a model. Adaptive KMPC differs from most other Koopman-based control frameworks that aim to identify high-validity-range models in advance and then enter closed-loop control without further model adaptations. To validate the controller, trajectory tracking experiments are conducted with 1R and 2R robots under force disturbances and changing model parameters. We compare the controller to classical linearization MPC and Koopman-based MPC without model updates, denoted static KMPC. The results show that adaptive KMPC can, opposed to static KMPC, generalize over unforeseen force disturbances and can, opposed to linearization MPC, handle varying dynamic parameters, while using a small set of basis functions to approximate the Koopman operator.",
      "authors": [
        "Adriano del R\\'io and Christoph Stoeffler"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-23T02:29:21+00:00",
          "link": "https://arxiv.org/abs/2503.17902v1",
          "size": "1292kb",
          "version": "v1"
        },
        {
          "date": "2025-07-02T18:35:18+00:00",
          "link": "https://arxiv.org/abs/2503.17902v2",
          "size": "1274kb",
          "version": "v2"
        }
      ],
      "title": "Adaptive Koopman Model Predictive Control of Simple Serial Robots",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.17902",
        "HTML": "https://arxiv.org/html/2503.17902v2",
        "PDF": "https://arxiv.org/pdf/2503.17902"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with adaptive control of robots using a data-driven model predictive controller. It does not pertain to LLM training data processing."
      },
      "tasks": [
        "Model Predictive Control"
      ],
      "repo_urls": [
        "https://github.com/adrianodelr/adaptive-koopman-mpc"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.18681",
      "abstract": "Sarcasm detection, as a crucial research direction in the field of Natural Language Processing (NLP), has attracted widespread attention. Traditional sarcasm detection tasks have typically focused on single-modal approaches (e.g., text), but due to the implicit and subtle nature of sarcasm, such methods often fail to yield satisfactory results. In recent years, researchers have shifted the focus of sarcasm detection to multi-modal approaches. However, effectively leveraging multi-modal information to accurately identify sarcastic content remains a challenge that warrants further exploration. Leveraging the powerful integrated processing capabilities of Multi-Modal Large Language Models (MLLMs) for various information sources, we propose an innovative multi-modal Commander-GPT framework. Inspired by military strategy, we first decompose the sarcasm detection task into six distinct sub-tasks. A central commander (decision-maker) then assigns the best-suited large language model to address each specific sub-task. Ultimately, the detection results from each model are aggregated to identify sarcasm. We conducted extensive experiments on MMSD and MMSD 2.0, utilizing four multi-modal large language models and six prompting strategies. Our experiments demonstrate that our approach achieves state-of-the-art performance, with a 19.3% improvement in F1 score, without necessitating fine-tuning or ground-truth rationales.",
      "authors": [
        "Yazhou Zhang",
        "Chunwang Zou",
        "Bo Wang",
        "Jing Qin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-24T13:53:00+00:00",
          "link": "https://arxiv.org/abs/2503.18681v1",
          "size": "3185kb",
          "version": "v1"
        },
        {
          "date": "2025-03-25T04:33:15+00:00",
          "link": "https://arxiv.org/abs/2503.18681v2",
          "size": "1747kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T04:04:04+00:00",
          "link": "https://arxiv.org/abs/2503.18681v3",
          "size": "0kb",
          "version": "v3"
        }
      ],
      "title": "Commander-GPT: Fully Unleashing the Sarcasm Detection Capability of Multi-Modal Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.18681",
        "PDF": "https://arxiv.org/pdf/2503.18681"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper focuses on sarcasm detection using multi-modal large language models, employing existing datasets (MMSD and MMSD 2.0) and multi-modal approaches. While it utilizes data, it does not propose new methods for processing or engineering training data for LLMs."
      },
      "tasks": [
        "Large Language Model",
        "Sarcasm Detection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.19228",
      "abstract": "To address the computational challenges of Model Predictive Control (MPC), recent research has studied using imitation learning to approximate the MPC to a computationally efficient Deep Neural Network (DNN). However, this introduces a common issue in learning-based control, the simulation-to-reality (sim-to-real) gap, and Domain Randomization (DR) has been widely used to mitigate this gap by introducing perturbations in the source domain. However, DR inevitably leads to low data collection efficiency and an overly conservative control strategy. This study proposes a new control framework that addresses this issue from a control perspective inspired by Robust Tube MPC. The framework ensures the DNN operates in the same environment as the source domain, handling the sim-to-real gap with great data collection efficiency. Moreover, a parameter governor is introduced to address the DNN's inability to adapt to variations in model parameters, enabling the system to satisfy MPC constraints more robustly under changing conditions. The proposed framework was validated through two case studies: cart-pole control and vehicle collision avoidance control, which analyzed the principles of the proposed framework in detail and demonstrated its application to a vehicle control case.",
      "authors": [
        "Seungtaek Kim",
        "Jonghyup Lee",
        "Kyoungseok Han",
        "and Seibum B. Choi"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-25T00:30:08+00:00",
          "link": "https://arxiv.org/abs/2503.19228v1",
          "size": "565kb",
          "version": "v1"
        },
        {
          "date": "2025-05-21T00:38:45+00:00",
          "link": "https://arxiv.org/abs/2503.19228v2",
          "size": "0kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T11:21:48+00:00",
          "link": "https://arxiv.org/abs/2503.19228v3",
          "size": "2253kb",
          "version": "v3"
        }
      ],
      "title": "Bridging the Sim-to-real Gap: A Control Framework for Imitation Learning of Model Predictive Control",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.19228",
        "HTML": "https://arxiv.org/html/2503.19228v3",
        "PDF": "https://arxiv.org/pdf/2503.19228"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper centers on a control framework for imitation learning and Model Predictive Control, which does not relate to the processing or preparation of training data for LLMs."
      },
      "tasks": [
        "Imitation Learning",
        "Model Predictive Control"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.20767",
      "abstract": "Algorithms for machine learning-guided design, or design algorithms, use machine learning-based predictions to propose novel objects with desired property values. Given a new design task -- for example, to design novel proteins with high binding affinity to a therapeutic target -- one must choose a design algorithm and specify any hyperparameters and predictive and/or generative models involved. How can these decisions be made such that the resulting designs are successful? This paper proposes a method for design algorithm selection, which aims to select design algorithms that will produce a distribution of design labels satisfying a user-specified success criterion -- for example, that at least ten percent of designs' labels exceed a threshold. It does so by combining designs' predicted property values with held-out labeled data to reliably forecast characteristics of the label distributions produced by different design algorithms, building upon techniques from prediction-powered inference. The method is guaranteed with high probability to return design algorithms that yield successful label distributions (or the null set if none exist), if the density ratios between the design and labeled data distributions are known. We demonstrate the method's effectiveness in simulated protein and RNA design tasks, in settings with either known or estimated density ratios.",
      "authors": [
        "Clara Fannjiang and Ji Won Park"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Quantitative Methods (q-bio.QM)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-26T17:52:19+00:00",
          "link": "https://arxiv.org/abs/2503.20767v1",
          "size": "2297kb",
          "version": "v1"
        },
        {
          "date": "2025-07-02T21:17:20+00:00",
          "link": "https://arxiv.org/abs/2503.20767v2",
          "size": "3165kb",
          "version": "v2"
        }
      ],
      "title": "Reliable algorithm selection for machine learning-guided design",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.20767",
        "HTML": "https://arxiv.org/html/2503.20767v2",
        "PDF": "https://arxiv.org/pdf/2503.20767"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses algorithm selection for machine learning-guided design, which involves predictive modeling and design algorithm application, without dealing with LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2503.21817",
      "abstract": "Transformer-based models have driven significant advancements in Multimodal Large Language Models (MLLMs), yet their computational costs surge drastically when scaling resolution, training data, and model parameters. A key bottleneck stems from the proliferation of visual tokens required for fine-grained image understanding. We propose Skip-Vision, a unified framework addressing both training and inference inefficiencies in vision-language models. On top of conventional token compression approaches, our method introduces two complementary acceleration strategies. For training acceleration, we observe that Feed-Forward Network (FFN) computations on visual tokens induce marginal feature updates. This motivates our Skip-FFN strategy, which bypasses FFN layers for redundant visual tokens. For inference acceleration, we design a selective KV-cache removal mechanism that prunes the skipped key-value pairs during decoding while preserving model performance. Experimental results demonstrate that Skip-Vision reduces training time by up to 35\\%, inference FLOPs by 75\\%, and latency by 45\\%, while achieving comparable or superior performance to existing methods. Our work provides a practical solution for scaling high-performance MLLMs with enhanced efficiency.",
      "authors": [
        "Weili Zeng and Ziyuan Huang and Kaixiang Ji and Yichao Yan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-26T04:16:48+00:00",
          "link": "https://arxiv.org/abs/2503.21817v1",
          "size": "22266kb",
          "version": "v1"
        },
        {
          "date": "2025-03-31T02:19:29+00:00",
          "link": "https://arxiv.org/abs/2503.21817v2",
          "size": "22266kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T08:22:27+00:00",
          "link": "https://arxiv.org/abs/2503.21817v3",
          "size": "11512kb",
          "version": "v3"
        }
      ],
      "title": "Skip-Vision: Efficient and Scalable Acceleration of Vision-Language Models via Adaptive Token Skipping",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.21817",
        "HTML": "https://arxiv.org/html/2503.21817v3",
        "PDF": "https://arxiv.org/pdf/2503.21817"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper deals with efficiency improvements in vision-language models using token skipping strategies, impacting training and inference. However, it does not introduce new methodologies for the fundamental processing of training data."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2503.21843",
      "abstract": "Human Activity Recognition (HAR) is a fundamental technology for numerous human - centered intelligent applications. Although deep learning methods have been utilized to accelerate feature extraction, issues such as multimodal data mixing, activity heterogeneity, and complex model deployment remain largely unresolved. The aim of this paper is to address issues such as multimodal data mixing, activity heterogeneity, and complex model deployment in sensor-based human activity recognition. We propose a spatiotemporal attention modal decomposition alignment fusion strategy to tackle the problem of the mixed distribution of sensor data. Key discriminative features of activities are captured through cross-modal spatio-temporal disentangled representation, and gradient modulation is combined to alleviate data heterogeneity. In addition, a wearable deployment simulation system is constructed. We conducted experiments on a large number of public datasets, demonstrating the effectiveness of the model.",
      "authors": [
        "Hanyu Liu",
        "Siyao Li",
        "Ying Yu",
        "Yixuan Jiang",
        "Hang Xiao",
        "Jingxi Long",
        "Haotian Tang",
        "Chao Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-27T15:21:49+00:00",
          "link": "https://arxiv.org/abs/2503.21843v1",
          "size": "3447kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T16:44:45+00:00",
          "link": "https://arxiv.org/abs/2503.21843v2",
          "size": "3447kb",
          "version": "v2"
        }
      ],
      "title": "CMD-HAR: Cross-Modal Disentanglement for Wearable Human Activity Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.21843",
        "HTML": "https://arxiv.org/html/2503.21843v2",
        "PDF": "https://arxiv.org/pdf/2503.21843"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses human activity recognition using deep learning and multimodal decomposition for sensor data, unrelated to LLM training data processing or engineering."
      },
      "tasks": [
        "Activity Recognition",
        "Disentanglement",
        "Human Activity Recognition"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.24100",
      "abstract": "Mutation testing can help minimize the delivery of faulty software. Therefore, it is a recommended practice for developing embedded software in safety-critical cyber-physical systems (CPS). However, state-of-the-art mutation testing techniques for C and C++ software, which are common languages for CPS, depend on symbolic execution. Unfortunately, symbolic execution's limitations hinder its applicability (e.g., systems with black-box components).\n  We propose relying on fuzz testing, which has demonstrated its effectiveness for C and C++ software. Fuzz testing tools automatically create test inputs that explore program branches in various ways, exercising statements in different program states, and thus enabling the detection of mutants, which is our objective.\n  We empirically evaluated our approach using software components from operational satellite systems. Our assessment shows that our approach can detect between 40% and 90% of the mutants not detected by developers' test suites. Further, we empirically determined that the best results are obtained by integrating the Clang compiler, a memory address sanitizer, and relying on laf-intel instrumentation to collect coverage and guide fuzzing. Our approach detects a significantly higher percentage of live mutants compared to symbolic execution, with an increase of up to 50 percentage points; further, we observed that although the combination of fuzzing and symbolic execution leads to additional mutants being killed, the benefits are minimal (a gain of less than one percentage point).",
      "authors": [
        "Jaekwon Lee",
        "Fabrizio Pastore",
        "Lionel Briand"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-31T13:55:27+00:00",
          "link": "https://arxiv.org/abs/2503.24100v1",
          "size": "608kb",
          "version": "v1"
        },
        {
          "date": "2025-06-21T05:57:49+00:00",
          "link": "https://arxiv.org/abs/2503.24100v2",
          "size": "719kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T15:23:17+00:00",
          "link": "https://arxiv.org/abs/2503.24100v3",
          "size": "719kb",
          "version": "v3"
        }
      ],
      "title": "Fuzzing-based Mutation Testing of C/C++ Software in Cyber-Physical Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.24100",
        "HTML": "https://arxiv.org/html/2503.24100v3",
        "PDF": "https://arxiv.org/pdf/2503.24100"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on fuzzing-based mutation testing for C/C++ software in cyber-physical systems, which is not related to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.00560",
      "abstract": "We present a variational integrator based on the Lobatto quadrature for the time integration of dynamical systems issued from the least action principle. This numerical method uses a cubic interpolation of the states and the action is approximated at each time step by Lobatto's formula. Numerical analysis is performed on both a harmonic oscillator and a nonlinear pendulum. The geometric scheme is conditionally stable, sixth-order accurate, and symplectic. It preserves an approximate energy quantity. Simulation results illustrate the performance and the superconvergence of the proposed method.",
      "authors": [
        "Fran\\c{c}ois Dubois (LMSSC",
        "LMO)",
        "Juan Antonio Rojas-Quintero (TecNM)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-01T09:13:48+00:00",
          "link": "https://arxiv.org/abs/2504.00560v1",
          "size": "217kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T09:20:26+00:00",
          "link": "https://arxiv.org/abs/2504.00560v2",
          "size": "409kb",
          "version": "v2"
        }
      ],
      "title": "A variational symplectic scheme based on Lobatto's quadrature",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.00560",
        "PDF": "https://arxiv.org/pdf/2504.00560"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study presents a variational symplectic scheme for dynamical systems, which is unrelated to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.02545",
      "abstract": "Existing makeup techniques often require designing multiple models to handle different inputs and align features across domains for different makeup tasks, e.g., beauty filter, makeup transfer, and makeup removal, leading to increased complexity. Another limitation is the absence of text-guided makeup try-on, which is more user-friendly without needing reference images. In this study, we make the first attempt to use a single model for various makeup tasks. Specifically, we formulate different makeup tasks as cross-domain translations and leverage a cross-domain diffusion model to accomplish all tasks. Unlike existing methods that rely on separate encoder-decoder configurations or cycle-based mechanisms, we propose using different domain embeddings to facilitate domain control. This allows for seamless domain switching by merely changing embeddings with a single model, thereby reducing the reliance on additional modules for different tasks. Moreover, to support precise text-to-makeup applications, we introduce the MT-Text dataset by extending the MT dataset with textual annotations, advancing the practicality of makeup technologies.",
      "authors": [
        "Bo-Kai Ruan",
        "Hong-Han Shuai"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-03T12:52:31+00:00",
          "link": "https://arxiv.org/abs/2504.02545v1",
          "size": "3710kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T06:22:29+00:00",
          "link": "https://arxiv.org/abs/2504.02545v2",
          "size": "3714kb",
          "version": "v2"
        }
      ],
      "title": "MAD: Makeup All-in-One with Cross-Domain Diffusion Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.02545",
        "HTML": "https://arxiv.org/html/2504.02545v2",
        "PDF": "https://arxiv.org/pdf/2504.02545"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper introduces the MT-Text dataset with textual annotations for makeup applications, which slightly touches on data collection for cross-domain diffusion models but lacks focus on LLM-specific data processing or engineering."
      },
      "tasks": [
        "All",
        "Decoder"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.03693",
      "abstract": "With the rise of generative AI, industry interest in software agents is growing. Given the stochastic nature of generative AI-based agents, their effective and safe deployment in organizations requires robust governance, which can be facilitated by agentic business process management. However, given the nascence of this new-generation agent notion, it is not clear what BPM practitioners consider to be an agent, and what benefits, risks and governance challenges they associate with agent deployments. To investigate how organizations can effectively govern AI agents, we conducted a qualitative study involving semi-structured interviews with 22 BPM practitioners from diverse industries. They anticipate that agents will enhance efficiency, improve data quality, ensure better compliance, and boost scalability through automation, while also cautioning against risks such as bias, over-reliance, cybersecurity threats, job displacement, and ambiguous decision-making. To address these challenges, the study presents six key recommendations for the responsible adoption of AI agents: define clear business goals, set legal and ethical guardrails, establish human-agent collaboration, customize agent behavior, manage risks, and ensure safe integration with fallback options. Additionally, the paper outlines actions to align traditional BPM with agentic AI, including balancing human and agent roles, redefining human involvement, adapting process structures, and introducing performance metrics. These insights provide a practical foundation for integrating AI agents into business processes while preserving oversight, flexibility, and trust.",
      "authors": [
        "Hoang Vu",
        "Nataliia Klievtsova",
        "Henrik Leopold",
        "Stefanie Rinderle-Ma",
        "Timotheus Kampik"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-23T20:15:24+00:00",
          "link": "https://arxiv.org/abs/2504.03693v1",
          "size": "115kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T17:43:38+00:00",
          "link": "https://arxiv.org/abs/2504.03693v2",
          "size": "107kb",
          "version": "v2"
        }
      ],
      "title": "Agentic Business Process Management: Practitioner Perspectives on Agent Governance in Business Processes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.03693",
        "HTML": "https://arxiv.org/html/2504.03693v2",
        "PDF": "https://arxiv.org/pdf/2504.03693"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper examines governance and integration of AI agents in business processes, without focusing on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.04164",
      "abstract": "Existing visual model-based reinforcement learning (MBRL) algorithms with observation reconstruction often suffer from information conflicts, making it difficult to learn compact representations and hence result in less robust policies, especially in the presence of task-irrelevant visual distractions. In this paper, we first reveal that the information conflicts in current visual MBRL algorithms stem from visual representation learning and latent dynamics modeling with an information-theoretic perspective. Based on this finding, we present a new algorithm to resolve information conflicts for visual MBRL, named MInCo, which mitigates information conflicts by leveraging negative-free contrastive learning, aiding in learning invariant representation and robust policies despite noisy observations. To prevent the dominance of visual representation learning, we introduce time-varying reweighting to bias the learning towards dynamics modeling as training proceeds. We evaluate our method on several robotic control tasks with dynamic background distractions. Our experiments demonstrate that MInCo learns invariant representations against background noise and consistently outperforms current state-of-the-art visual MBRL methods. Code is available at https://github.com/ShiguangSun/minco.",
      "authors": [
        "Shiguang Sun",
        "Hanbo Zhang",
        "Zeyang Liu",
        "Xinrui Yang",
        "Lipeng Wan",
        "Xingyu Chen",
        "Xuguang Lan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-05T12:57:31+00:00",
          "link": "https://arxiv.org/abs/2504.04164v1",
          "size": "1365kb",
          "version": "v1"
        },
        {
          "date": "2025-05-17T13:18:42+00:00",
          "link": "https://arxiv.org/abs/2504.04164v2",
          "size": "1363kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T07:41:07+00:00",
          "link": "https://arxiv.org/abs/2504.04164v3",
          "size": "1158kb",
          "version": "v3"
        }
      ],
      "title": "MInCo: Mitigating Information Conflicts in Distracted Visual Model-based Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.04164",
        "HTML": "https://arxiv.org/html/2504.04164v3",
        "PDF": "https://arxiv.org/pdf/2504.04164"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents an algorithm for mitigating information conflicts in visual model-based reinforcement learning, not related to LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.05983",
      "abstract": "With the increasing demand for human-computer interaction (HCI), flexible wearable gloves have emerged as a promising solution in virtual reality, medical rehabilitation, and industrial automation. However, the current technology still has problems like insufficient sensitivity and limited durability, which hinder its wide application. This paper presents a highly sensitive, modular, and flexible capacitive sensor based on line-shaped electrodes and liquid metal (EGaIn), integrated into a sensor module tailored to the human hand's anatomy. The proposed system independently captures bending information from each finger joint, while additional measurements between adjacent fingers enable the recording of subtle variations in inter-finger spacing. This design enables accurate gesture recognition and dynamic hand morphological reconstruction of complex movements using point clouds. Experimental results demonstrate that our classifier based on Convolution Neural Network (CNN) and Multilayer Perceptron (MLP) achieves an accuracy of 99.15% across 30 gestures. Meanwhile, a transformer-based Deep Neural Network (DNN) accurately reconstructs dynamic hand shapes with an Average Distance (AD) of 2.076\\pm3.231 mm, with the reconstruction accuracy at individual key points surpassing SOTA benchmarks by 9.7% to 64.9%. The proposed glove shows excellent accuracy, robustness and scalability in gesture recognition and hand reconstruction, making it a promising solution for next-generation HCI systems.",
      "authors": [
        "Huazhi Dong",
        "Chunpeng Wang",
        "Mingyuan Jiang",
        "Francesco Giorgio-Serchi",
        "Yunjie Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-08T12:39:59+00:00",
          "link": "https://arxiv.org/abs/2504.05983v1",
          "size": "2733kb",
          "version": "v1"
        },
        {
          "date": "2025-07-02T19:09:10+00:00",
          "link": "https://arxiv.org/abs/2504.05983v2",
          "size": "2229kb",
          "version": "v2"
        }
      ],
      "title": "Modular Soft Wearable Glove for Real-Time Gesture Recognition and Dynamic 3D Shape Reconstruction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.05983",
        "HTML": "https://arxiv.org/html/2504.05983v2",
        "PDF": "https://arxiv.org/pdf/2504.05983"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research is centered on gesture recognition and 3D shape reconstruction using wearable technology, unrelated to LLM training data processes."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.07139",
      "abstract": "Welcome to the eighth edition of the AI Index report. The 2025 Index is our most comprehensive to date and arrives at an important moment, as AI's influence across society, the economy, and global governance continues to intensify. New in this year's report are in-depth analyses of the evolving landscape of AI hardware, novel estimates of inference costs, and new analyses of AI publication and patenting trends. We also introduce fresh data on corporate adoption of responsible AI practices, along with expanded coverage of AI's growing role in science and medicine. Since its founding in 2017 as an offshoot of the One Hundred Year Study of Artificial Intelligence, the AI Index has been committed to equipping policymakers, journalists, executives, researchers, and the public with accurate, rigorously validated, and globally sourced data. Our mission has always been to help these stakeholders make better-informed decisions about the development and deployment of AI. In a world where AI is discussed everywhere - from boardrooms to kitchen tables - this mission has never been more essential. The AI Index continues to lead in tracking and interpreting the most critical trends shaping the field - from the shifting geopolitical landscape and the rapid evolution of underlying technologies, to AI's expanding role in business, policymaking, and public life. Longitudinal tracking remains at the heart of our mission. In a domain advancing at breakneck speed, the Index provides essential context - helping us understand where AI stands today, how it got here, and where it may be headed next. Recognized globally as one of the most authoritative resources on artificial intelligence, the AI Index has been cited in major media outlets such as The New York Times, Bloomberg, and The Guardian; referenced in hundreds of academic papers; and used by policymakers and government agencies around the world.",
      "authors": [
        "Nestor Maslej",
        "Loredana Fattorini",
        "Raymond Perrault",
        "Yolanda Gil",
        "Vanessa Parli",
        "Njenga Kariuki",
        "Emily Capstick",
        "Anka Reuel",
        "Erik Brynjolfsson",
        "John Etchemendy",
        "Katrina Ligett",
        "Terah Lyons",
        "James Manyika",
        "Juan Carlos Niebles",
        "Yoav Shoham",
        "Russell Wald",
        "Tobi Walsh",
        "Armin Hamrah",
        "Lapo Santarlasci",
        "Julia Betts Lotufo",
        "Alexandra Rome",
        "Andrew Shi",
        "Sukrut Oak"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-08T02:01:37+00:00",
          "link": "https://arxiv.org/abs/2504.07139v1",
          "size": "53237kb",
          "version": "v1"
        },
        {
          "date": "2025-07-02T17:28:08+00:00",
          "link": "https://arxiv.org/abs/2504.07139v2",
          "size": "22532kb",
          "version": "v2"
        }
      ],
      "title": "Artificial Intelligence Index Report 2025",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.07139",
        "PDF": "https://arxiv.org/pdf/2504.07139"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The abstract focuses on providing an in-depth analysis of AI trends and resource utilization, rather than on the processing of training data for large language models."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2504.07283",
      "abstract": "Deep Reinforcement Learning (DRL) has emerged as a powerful model-free paradigm for learning optimal policies. However, in navigation tasks with cluttered environments, DRL methods often suffer from insufficient exploration, especially under sparse rewards or complex dynamics with system disturbances. To address this challenge, we bridge general graph-based motion planning with DRL, enabling agents to explore cluttered spaces more effectively and achieve desired navigation performance. Specifically, we design a dense reward function grounded in a graph structure that spans the entire state space. This graph provides rich guidance, steering the agent toward optimal strategies. We validate our approach in challenging environments, demonstrating substantial improvements in exploration efficiency and task success rates.",
      "authors": [
        "Licheng Luo and Mingyu Cai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-09T21:19:51+00:00",
          "link": "https://arxiv.org/abs/2504.07283v1",
          "size": "4398kb",
          "version": "v1"
        },
        {
          "date": "2025-05-01T03:32:31+00:00",
          "link": "https://arxiv.org/abs/2504.07283v2",
          "size": "6491kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T05:17:02+00:00",
          "link": "https://arxiv.org/abs/2504.07283v3",
          "size": "2125kb",
          "version": "v3"
        }
      ],
      "title": "Bridging Deep Reinforcement Learning and Motion Planning for Model-Free Navigation in Cluttered Environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.07283",
        "HTML": "https://arxiv.org/html/2504.07283v3",
        "PDF": "https://arxiv.org/pdf/2504.07283"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses improvements in navigation tasks using deep reinforcement learning and motion planning, without discussing training data processing or data engineering for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.08136",
      "abstract": "In this article we develop a Physics Informed Neural Network (PINN) approach to simulate ice sheet dynamics governed by the Shallow Ice Approximation. This problem takes the form of a time-dependent parabolic obstacle problem. Prior work has used this approach to address the stationary obstacle problem and here we extend it to the time dependent problem. Through comprehensive 1D and 2D simulations, we validate the model's effectiveness in capturing complex free-boundary conditions. By merging traditional mathematical modeling with cutting-edge deep learning methods, this approach provides a scalable and robust solution for predicting temporal variations in ice thickness. To illustrate this approach in a real world setting, we simulate the dynamics of the Devon Ice Cap, incorporating aerogeophysical data from 2000 and 2018.",
      "authors": [
        "Kapil Chawla and William Holmes"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)",
        "Atmospheric and Oceanic Physics (physics.ao-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-10T21:32:03+00:00",
          "link": "https://arxiv.org/abs/2504.08136v1",
          "size": "10787kb",
          "version": "v1"
        },
        {
          "date": "2025-07-02T22:11:34+00:00",
          "link": "https://arxiv.org/abs/2504.08136v2",
          "size": "10788kb",
          "version": "v2"
        }
      ],
      "title": "A physics informed neural network approach to simulating ice dynamics governed by the shallow ice approximation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.08136",
        "HTML": "https://arxiv.org/html/2504.08136v2",
        "PDF": "https://arxiv.org/pdf/2504.08136"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper describes a physics-informed neural network approach to simulating ice dynamics. It does not focus on the processing of training data for LLMs."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2504.08948",
      "abstract": "Panel proposal for an open forum to discuss and debate the future of database research in the context of industry, other research communities, and AI. Includes summaries of past panels, positions from panelists, as well as positions from a sample of the data management community.",
      "authors": [
        "Eugene Wu",
        "Raul Castro Fernandez"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-11T20:00:40+00:00",
          "link": "https://arxiv.org/abs/2504.08948v1",
          "size": "609kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T05:04:18+00:00",
          "link": "https://arxiv.org/abs/2504.08948v2",
          "size": "623kb",
          "version": "v2"
        }
      ],
      "title": "Where Does Academic Database Research Go From Here?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.08948",
        "HTML": "https://arxiv.org/html/2504.08948v2",
        "PDF": "https://arxiv.org/pdf/2504.08948"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The panel proposal discusses the future of database research and does not address the processing or engineering of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.12215",
      "abstract": "Reliable tumor segmentation in thoracic computed tomography (CT) remains challenging due to boundary ambiguity, class imbalance, and anatomical variability. We propose an uncertainty-guided, coarse-to-fine segmentation framework that combines full-volume tumor localization with refined region-of-interest (ROI) segmentation, enhanced by anatomically aware post-processing. The first-stage model generates a coarse prediction, followed by anatomically informed filtering based on lung overlap, proximity to lung surfaces, and component size. The resulting ROIs are segmented by a second-stage model trained with uncertainty-aware loss functions to improve accuracy and boundary calibration in ambiguous regions. Experiments on private and public datasets demonstrate improvements in Dice and Hausdorff scores, with fewer false positives and enhanced spatial interpretability. These results highlight the value of combining uncertainty modeling and anatomical priors in cascaded segmentation pipelines for robust and clinically meaningful tumor delineation. On the Orlando dataset, our framework improved Swin UNETR Dice from 0.4690 to 0.6447. Reduction in spurious components was strongly correlated with segmentation gains, underscoring the value of anatomically informed post-processing.",
      "authors": [
        "Ilkin Sevgi Isler",
        "David Mohaisen",
        "Curtis Lisle",
        "Damla Turgut",
        "Ulas Bagci"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-16T16:08:38+00:00",
          "link": "https://arxiv.org/abs/2504.12215v1",
          "size": "1676kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T03:50:40+00:00",
          "link": "https://arxiv.org/abs/2504.12215v2",
          "size": "1676kb",
          "version": "v2"
        }
      ],
      "title": "Uncertainty-Guided Coarse-to-Fine Tumor Segmentation with Anatomy-Aware Post-Processing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.12215",
        "HTML": "https://arxiv.org/html/2504.12215v2",
        "PDF": "https://arxiv.org/pdf/2504.12215"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper covers a segmentation framework for tumor detection in CT images, focusing on methods and accuracy improvements rather than training data processing for LLMs."
      },
      "tasks": [
        "Anatomy",
        "Computed Tomography (CT)",
        "Segmentation",
        "Tumor Segmentation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.12552",
      "abstract": "The operating room (OR) is a complex environment where optimizing workflows is critical to reduce costs and improve patient outcomes. While computer vision approaches for automatic recognition of perioperative events can identify bottlenecks for OR optimization, privacy concerns limit the use of OR videos for automated event detection. We propose a two-stage pipeline for privacy-preserving OR video analysis and event detection. First, we leverage vision foundation models for depth estimation and semantic segmentation to generate de-identified Digital Twins (DT) of the OR from conventional RGB videos. Second, we employ the SafeOR model, a fused two-stream approach that processes segmentation masks and depth maps for OR event detection. Evaluation on an internal dataset of 38 simulated surgical trials with five event classes shows that our DT-based approach achieves performance on par with -- and sometimes better than -- raw RGB video-based models for OR event detection. Digital Twins enable privacy-preserving OR workflow analysis, facilitating the sharing of de-identified data across institutions and potentially enhancing model generalizability by mitigating domain-specific appearance differences.",
      "authors": [
        "Alejandra Perez",
        "Han Zhang",
        "Yu-Chun Ku",
        "Lalithkumar Seenivasan",
        "Roger Soberanis",
        "Jose L. Porras",
        "Richard Day",
        "Jeff Jopling",
        "Peter Najjar",
        "Mathias Unberath"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-17T00:46:06+00:00",
          "link": "https://arxiv.org/abs/2504.12552v1",
          "size": "637kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T06:11:55+00:00",
          "link": "https://arxiv.org/abs/2504.12552v2",
          "size": "467kb",
          "version": "v2"
        }
      ],
      "title": "Privacy-Preserving Operating Room Workflow Analysis using Digital Twins",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.12552",
        "HTML": "https://arxiv.org/html/2504.12552v2",
        "PDF": "https://arxiv.org/pdf/2504.12552"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on privacy-preserving video analysis and event detection in operating room workflows, with no mention of LLM training data processing."
      },
      "tasks": [
        "Depth Estimation",
        "Event Detection",
        "Privacy Preserving",
        "Semantic Segmentation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.12753",
      "abstract": "Vision Foundation Models (VFMs) have delivered remarkable performance in Domain Generalized Semantic Segmentation (DGSS). However, recent methods often overlook the fact that visual cues are susceptible, whereas the underlying geometry remains stable, rendering depth information more robust. In this paper, we investigate the potential of integrating depth information with features from VFMs, to improve the geometric consistency within an image and boost the generalization performance of VFMs. We propose a novel fine-tuning DGSS framework, named DepthForge, which integrates the visual cues from frozen DINOv2 or EVA02 and depth cues from frozen Depth Anything V2. In each layer of the VFMs, we incorporate depth-aware learnable tokens to continuously decouple domain-invariant visual and spatial information, thereby enhancing depth awareness and attention of the VFMs. Finally, we develop a depth refinement decoder and integrate it into the model architecture to adaptively refine multi-layer VFM features and depth-aware learnable tokens. Extensive experiments are conducted based on various DGSS settings and five different datsets as unseen target domains. The qualitative and quantitative results demonstrate that our method significantly outperforms alternative approaches with stronger performance, steadier visual-spatial attention, and superior generalization ability. In particular, DepthForge exhibits outstanding performance under extreme conditions (e.g., night and snow). Code is available at https://github.com/anonymouse-xzrptkvyqc/DepthForge.",
      "authors": [
        "Siyu Chen",
        "Ting Han",
        "Changshe Zhang",
        "Xin Luo",
        "Meiliu Wu",
        "Guorong Cai",
        "Jinhe Su"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-17T08:45:33+00:00",
          "link": "https://arxiv.org/abs/2504.12753v1",
          "size": "8746kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T10:17:05+00:00",
          "link": "https://arxiv.org/abs/2504.12753v2",
          "size": "8743kb",
          "version": "v2"
        }
      ],
      "title": "Stronger, Steadier & Superior: Geometric Consistency in Depth VFM Forges Domain Generalized Semantic Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.12753",
        "HTML": "https://arxiv.org/html/2504.12753v2",
        "PDF": "https://arxiv.org/pdf/2504.12753"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses domain generalized semantic segmentation using vision foundation models with depth information, not related to LLM training data."
      },
      "tasks": [
        "Semantic Segmentation"
      ],
      "repo_urls": [
        "https://github.com/anonymouse-xzrptkvyqc/depthforge"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.12816",
      "abstract": "Relational Triple Extraction (RTE) is a fundamental task in Natural Language Processing (NLP). However, prior research has primarily focused on optimizing model performance, with limited efforts to understand the internal mechanisms driving these models. Many existing methods rely on complex preprocessing to induce specific interactions, often resulting in opaque systems that may not fully align with their theoretical foundations. To address these limitations, we propose SMARTe: a Slot-based Method for Accountable Relational Triple extraction. SMARTe introduces intrinsic interpretability through a slot attention mechanism and frames the task as a set prediction problem. Slot attention consolidates relevant information into distinct slots, ensuring all predictions can be explicitly traced to learned slot representations and the tokens contributing to each predicted relational triple. While emphasizing interpretability, SMARTe achieves performance comparable to state-of-the-art models. Evaluations on the NYT and WebNLG datasets demonstrate that adding interpretability does not compromise performance. Furthermore, we conducted qualitative assessments to showcase the explanations provided by SMARTe, using attention heatmaps that map to their respective tokens. We conclude with a discussion of our findings and propose directions for future research. Our code is available at https://github.com/Chen-XueWen/SMARTe.",
      "authors": [
        "Xue Wen Tan",
        "Stanley Kok"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-17T10:21:15+00:00",
          "link": "https://arxiv.org/abs/2504.12816v1",
          "size": "5359kb",
          "version": "v1"
        },
        {
          "date": "2025-05-22T15:28:30+00:00",
          "link": "https://arxiv.org/abs/2504.12816v2",
          "size": "8559kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T03:25:07+00:00",
          "link": "https://arxiv.org/abs/2504.12816v3",
          "size": "8559kb",
          "version": "v3"
        }
      ],
      "title": "SMARTe: Slot-based Method for Accountable Relational Triple extraction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.12816",
        "HTML": "https://arxiv.org/html/2504.12816v3",
        "PDF": "https://arxiv.org/pdf/2504.12816"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on relational triple extraction using a slot-based method, which does not discuss LLM training data collection or processing."
      },
      "tasks": [
        "RTE"
      ],
      "repo_urls": [
        "https://github.com/Chen-XueWen/SMARTe"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.12971",
      "abstract": "Neural architecture search (NAS) faces a challenge in balancing the exploration of expressive, broad search spaces that enable architectural innovation with the need for efficient evaluation of architectures to effectively search such spaces. We investigate surrogate model training for improving search in highly expressive NAS search spaces based on context-free grammars. We show that i) surrogate models trained either using zero-cost-proxy metrics and neural graph features (GRAF) or by fine-tuning an off-the-shelf LM have high predictive power for the performance of architectures both within and across datasets, ii) these surrogates can be used to filter out bad architectures when searching on novel datasets, thereby significantly speeding up search and achieving better final performances, and iii) the surrogates can be further used directly as the search objective for huge speed-ups.",
      "authors": [
        "Shiwen Qin",
        "Gabriela Kadlecov\\'a",
        "Martin Pil\\'at",
        "Shay B. Cohen",
        "Roman Neruda",
        "Elliot J. Crowley",
        "Jovita Lukasik and Linus Ericsson"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-17T14:22:28+00:00",
          "link": "https://arxiv.org/abs/2504.12971v1",
          "size": "264kb",
          "version": "v1"
        },
        {
          "date": "2025-04-18T17:49:14+00:00",
          "link": "https://arxiv.org/abs/2504.12971v2",
          "size": "258kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T17:06:23+00:00",
          "link": "https://arxiv.org/abs/2504.12971v3",
          "size": "252kb",
          "version": "v3"
        }
      ],
      "title": "Transferrable Surrogates in Expressive Neural Architecture Search Spaces",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.12971",
        "HTML": "https://arxiv.org/html/2504.12971v3",
        "PDF": "https://arxiv.org/pdf/2504.12971"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses neural architecture search using surrogate models, with no context on LLM training data processing or enhancement."
      },
      "tasks": [
        "Neural Architecture Search"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.15325",
      "abstract": "Agreement measures, such as Cohen's kappa or intraclass correlation, gauge the matching between two or more classifiers. They are used in a wide range of contexts from medicine, where they evaluate the effectiveness of medical treatments and clinical trials, to artificial intelligence, where they can quantify the approximation due to the reduction of a classifier. The consistency of different classifiers to a golden standard can be compared simply by using the order induced by their agreement measure with respect to the golden standard itself. Nevertheless, labelling an approach as good or bad exclusively by using the value of an agreement measure requires a scale or a significativity index. Some quality scales have been proposed in the literature for Cohen's kappa, but they are mainly na\\\"ive, and their boundaries are arbitrary. This work proposes a general approach to evaluate the significativity of any agreement value between two classifiers and introduces two significativity indices: one dealing with finite data sets, the other one handling classification probability distributions. Moreover, this manuscript addresses the computational challenges of evaluating such indices and proposes some efficient algorithms for their evaluation.",
      "authors": [
        "Alberto Casagrande",
        "Francesco Fabris",
        "Rossano Girometti",
        "Roberto Pagliarini"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-21T09:47:53+00:00",
          "link": "https://arxiv.org/abs/2504.15325v1",
          "size": "118kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T08:21:25+00:00",
          "link": "https://arxiv.org/abs/2504.15325v2",
          "size": "119kb",
          "version": "v2"
        }
      ],
      "title": "Significativity Indices for Agreement Values",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.15325",
        "PDF": "https://arxiv.org/pdf/2504.15325"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on agreement measures and significativity indices for classifiers, which is related to evaluation methodologies rather than LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2504.17460",
      "abstract": "Meta-compiler frameworks, such as RPython and Graal/Truffle, generate high-performance virtual machines (VMs) from interpreter definitions. Although they generate VMs with high-quality just-in-time (JIT) compilers, they still lack an important feature that dedicated VMs (i.e., VMs that are developed for specific languages) have, namely \\emph{multi-tier compilation}. Multi-tier compilation uses light-weight compilers at early stages and highly-optimizing compilers at later stages in order to balance between compilation overheads and code quality.\n  We propose a novel approach to enabling multi-tier compilation in the VMs generated by a meta-compiler framework. Instead of extending the JIT compiler backend of the framework, our approach drives an existing (heavyweight) compiler backend in the framework to quickly generate unoptimized native code by merely embedding directives and compile-time operations into interpreter definitions.\n  As a validation of the approach, we developed 2SOM, a Simple Object Machine with a two-tier JIT compiler based on RPython. 2SOM first applies the tier-1 threaded code generator that is generated by our proposed technique, then, to the loops that exceed a threshold, applies the tier-2 tracing JIT compiler that is generated by the original RPython framework. Our performance evaluation that runs a program with a realistic workload showed that 2SOM improved, when compared against an RPython-based VM, warm-up performance by 15\\%, with merely a 5\\% reduction in peak performance.",
      "authors": [
        "Yusuke Izawa",
        "Hidehiko Masuhara",
        "Carl Friedrich Bolz-Tereick"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-24T11:51:28+00:00",
          "link": "https://arxiv.org/abs/2504.17460v1",
          "size": "750kb",
          "version": "v1"
        },
        {
          "date": "2025-04-26T15:49:43+00:00",
          "link": "https://arxiv.org/abs/2504.17460v2",
          "size": "5641kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T10:02:51+00:00",
          "link": "https://arxiv.org/abs/2504.17460v3",
          "size": "479kb",
          "version": "v3"
        }
      ],
      "title": "A Lightweight Method for Generating Multi-Tier JIT Compilation Virtual Machine in a Meta-Tracing Compiler Framework",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.17460",
        "HTML": "https://arxiv.org/html/2504.17460v3",
        "PDF": "https://arxiv.org/pdf/2504.17460"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses virtual machine optimizations in meta-compiler frameworks, which is unrelated to the processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.17857",
      "abstract": "This work presents an overview of the technical details behind a high performance reinforcement learning policy deployment with the Spot RL Researcher Development Kit for low level motor access on Boston Dynamics Spot. This represents the first public demonstration of an end to end end reinforcement learning policy deployed on Spot hardware with training code publicly available through Nvidia IsaacLab and deployment code available through Boston Dynamics. We utilize Wasserstein Distance and Maximum Mean Discrepancy to quantify the distributional dissimilarity of data collected on hardware and in simulation to measure our sim2real gap. We use these measures as a scoring function for the Covariance Matrix Adaptation Evolution Strategy to optimize simulated parameters that are unknown or difficult to measure from Spot. Our procedure for modeling and training produces high quality reinforcement learning policies capable of multiple gaits, including a flight phase. We deploy policies capable of over 5.2ms locomotion, more than triple Spots default controller maximum speed, robustness to slippery surfaces, disturbance rejection, and overall agility previously unseen on Spot. We detail our method and release our code to support future work on Spot with the low level API.",
      "authors": [
        "AJ Miller",
        "Fangzhou Yu",
        "Michael Brauckmann",
        "Farbod Farshidian"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-24T18:01:36+00:00",
          "link": "https://arxiv.org/abs/2504.17857v1",
          "size": "25822kb",
          "version": "v1"
        },
        {
          "date": "2025-04-29T13:13:48+00:00",
          "link": "https://arxiv.org/abs/2504.17857v2",
          "size": "25822kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T05:14:46+00:00",
          "link": "https://arxiv.org/abs/2504.17857v3",
          "size": "2400kb",
          "version": "v3"
        }
      ],
      "title": "High-Performance Reinforcement Learning on Spot: Optimizing Simulation Parameters with Distributional Measures",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.17857",
        "HTML": "https://arxiv.org/html/2504.17857v3",
        "PDF": "https://arxiv.org/pdf/2504.17857"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses reinforcement learning policy deployment on Boston Dynamics Spot robots, focusing on sim2real optimization, which is not relevant to LLM training data processing."
      },
      "tasks": [
        "reinforcement-learning",
        "Reinforcement Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.19136",
      "abstract": "The fusion of Synthetic Aperture Radar (SAR) and RGB imagery for land cover classification remains challenging due to modality heterogeneity and underutilized spectral complementarity. Existing methods often fail to decouple shared structural features from modality-complementary radiometric attributes, causing feature conflicts and information loss. To address this, we propose Phase-Amplitude Decoupling (PAD), a frequency-aware framework that separates phase (modality-shared) and amplitude (modality-complementary) components in the Fourier domain, thus reinforcing shared structures while preserving complementary characteristics to improve fusion quality. Unlike prior approaches that overlook the distinct physical properties encoded in frequency spectra, PAD is the first to introduce explicit amplitude-phase decoupling for multi-modal fusion. Specifically, PAD comprises two key components: 1) Phase Spectrum Correction (PSC), which aligns cross-modal phase features via convolution-guided scaling to enhance geometric consistency; and 2) Amplitude Spectrum Fusion (ASF), which dynamically integrates high-frequency and low-frequency patterns using frequency-adaptive multilayer perceptrons, leveraging SAR's morphological sensitivity and RGB's spectral richness. Extensive experiments on WHU-OPT-SAR and DDHR-SK datasets demonstrate state-of-the-art performance. Our work establishes a new paradigm for physics-aware multi-modal fusion in remote sensing. The code will be available at https://github.com/RanFeng2/PAD.",
      "authors": [
        "Huiling Zheng",
        "Xian Zhong",
        "Bin Liu",
        "Yi Xiao",
        "Bihan Wen",
        "Xiaofeng Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-27T07:21:42+00:00",
          "link": "https://arxiv.org/abs/2504.19136v1",
          "size": "6813kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T16:45:10+00:00",
          "link": "https://arxiv.org/abs/2504.19136v2",
          "size": "6793kb",
          "version": "v2"
        }
      ],
      "title": "PAD: Phase-Amplitude Decoupling Fusion for Multi-Modal Land Cover Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.19136",
        "HTML": "https://arxiv.org/html/2504.19136v2",
        "PDF": "https://arxiv.org/pdf/2504.19136"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study presents phase-amplitude decoupling for multi-modal land cover classification, which is not concerned with LLM training data engineering or processing."
      },
      "tasks": [
        "Land Cover Classification"
      ],
      "repo_urls": [
        "https://github.com/ranfeng2/pad"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.20808",
      "abstract": "This paper introduces SoccerDiffusion, a transformer-based diffusion model designed to learn end-to-end control policies for humanoid robot soccer directly from real-world gameplay recordings. Using data collected from RoboCup competitions, the model predicts joint command trajectories from multi-modal sensor inputs, including vision, proprioception, and game state. We employ a distillation technique to enable real-time inference on embedded platforms that reduces the multi-step diffusion process to a single step. Our results demonstrate the model's ability to replicate complex motion behaviors such as walking, kicking, and fall recovery both in simulation and on physical robots. Although high-level tactical behavior remains limited, this work provides a robust foundation for subsequent reinforcement learning or preference optimization methods. We release the dataset, pretrained models, and code under: https://bit-bots.github.io/SoccerDiffusion",
      "authors": [
        "Florian Vahl",
        "J\\\"orn Griepenburg",
        "Jan Gutsche",
        "Jasper G\\\"uldenstein",
        "Jianwei Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-29T14:21:08+00:00",
          "link": "https://arxiv.org/abs/2504.20808v1",
          "size": "2576kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T12:26:15+00:00",
          "link": "https://arxiv.org/abs/2504.20808v2",
          "size": "1230kb",
          "version": "v2"
        }
      ],
      "title": "SoccerDiffusion: Toward Learning End-to-End Humanoid Robot Soccer from Gameplay Recordings",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.20808",
        "HTML": "https://arxiv.org/html/2504.20808v2",
        "PDF": "https://arxiv.org/pdf/2504.20808"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper involves learning control policies from gameplay recordings, which involves some level of data processing, but it does not focus on LLM-specific training data processing methodologies."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2505.00307",
      "abstract": "There has been a recent surge of interest in time series modeling using the Transformer architecture. However, forecasting multivariate time series with Transformer presents a unique challenge as it requires modeling both temporal (cross-time) and variate (cross-variate) dependencies. While Transformer-based models have gained popularity for their flexibility in capturing both sequential and cross-variate relationships, it is unclear how to best integrate these two sources of information in the context of the Transformer architecture while optimizing for both performance and efficiency. We re-purpose the Transformer architecture to effectively model both cross-time and cross-variate dependencies. Our approach begins by embedding each variate independently into a variate-wise representation that captures its cross-time dynamics, and then models cross-variate dependencies through attention mechanisms on these learned embeddings. Gating operations in both cross-time and cross-variate modeling phases regulate information flow, allowing the model to focus on the most relevant features for accurate predictions. Our method achieves state-of-the-art performance across 13 real-world datasets and can be seamlessly integrated into other Transformer-based and LLM-based forecasters, delivering performance improvements up to 20.7\\% over original models. Code is available at this repository: https://github.com/nyuolab/Gateformer.",
      "authors": [
        "Yu-Hsiang Lan and Eric K. Oermann"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-01T04:59:05+00:00",
          "link": "https://arxiv.org/abs/2505.00307v1",
          "size": "1536kb",
          "version": "v1"
        },
        {
          "date": "2025-05-09T15:45:00+00:00",
          "link": "https://arxiv.org/abs/2505.00307v2",
          "size": "1536kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T07:13:52+00:00",
          "link": "https://arxiv.org/abs/2505.00307v3",
          "size": "1527kb",
          "version": "v3"
        }
      ],
      "title": "Gateformer: Advancing Multivariate Time Series Forecasting through Temporal and Variate-Wise Attention with Gated Representations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.00307",
        "HTML": "https://arxiv.org/html/2505.00307v3",
        "PDF": "https://arxiv.org/pdf/2505.00307"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on time series forecasting using the Transformer architecture, with no mention of LLM training data processing tasks such as collection, cleaning, or format transformation."
      },
      "tasks": [
        "Multivariate Time Series Forecasting",
        "Time Series",
        "Time Series Forecasting"
      ],
      "repo_urls": [
        "https://github.com/nyuolab/gateformer"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.01420",
      "abstract": "Recent work has demonstrated the plausibility of frontier AI models scheming -- knowingly and covertly pursuing an objective misaligned with its developer's intentions. Such behavior could be very hard to detect, and if present in future advanced systems, could pose severe loss of control risk. It is therefore important for AI developers to rule out harm from scheming prior to model deployment. In this paper, we present a suite of scheming reasoning evaluations measuring two types of reasoning capabilities that we believe are prerequisites for successful scheming: First, we propose five evaluations of ability to reason about and circumvent oversight (stealth). Second, we present eleven evaluations for measuring a model's ability to instrumentally reason about itself, its environment and its deployment (situational awareness). We demonstrate how these evaluations can be used as part of a scheming inability safety case: a model that does not succeed on these evaluations is almost certainly incapable of causing severe harm via scheming in real deployment. We run our evaluations on current frontier models and find that none of them show concerning levels of either situational awareness or stealth.",
      "authors": [
        "Mary Phuong",
        "Roland S. Zimmermann",
        "Ziyue Wang",
        "David Lindner",
        "Victoria Krakovna",
        "Sarah Cogan",
        "Allan Dafoe",
        "Lewis Ho",
        "Rohin Shah"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-02T17:57:14+00:00",
          "link": "https://arxiv.org/abs/2505.01420v1",
          "size": "320kb",
          "version": "v1"
        },
        {
          "date": "2025-05-06T08:40:17+00:00",
          "link": "https://arxiv.org/abs/2505.01420v2",
          "size": "319kb",
          "version": "v2"
        },
        {
          "date": "2025-05-20T15:20:09+00:00",
          "link": "https://arxiv.org/abs/2505.01420v3",
          "size": "320kb",
          "version": "v3"
        },
        {
          "date": "2025-07-03T17:52:47+00:00",
          "link": "https://arxiv.org/abs/2505.01420v4",
          "size": "315kb",
          "version": "v4"
        }
      ],
      "title": "Evaluating Frontier Models for Stealth and Situational Awareness",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.01420",
        "HTML": "https://arxiv.org/html/2505.01420v4",
        "PDF": "https://arxiv.org/pdf/2505.01420"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses scheming reasoning evaluations in AI models and does not address any aspects related to LLM training data processing or engineering."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2505.01597",
      "abstract": "Particle Flow Filters perform the measurement update by moving particles to a different location rather than modifying the particles' weight based on the likelihood. Their movement (flow) is dictated by a drift term, which continuously pushes the particle toward the posterior distribution, and a diffusion term, which guarantees the spread of particles. This work presents a novel derivation of these terms based on high-order polynomial expansions, where the common techniques based on linearization reduce to a simpler version of the new methodology. Thanks to differential algebra, the high-order particle flow is derived directly onto the polynomials representation of the distribution, embedded with differentiation and evaluation. The resulting technique proposes two new particle flow filters, whose difference relies on the selection of the expansion center for the Taylor polynomial evaluation. Numerical applications show the improvement gained by the inclusion of high-order terms, especially when comparing performance with the Gromov flow and the \"exact\" flow.",
      "authors": [
        "Simone Servadio"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-02T21:43:59+00:00",
          "link": "https://arxiv.org/abs/2505.01597v1",
          "size": "2366kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T15:09:40+00:00",
          "link": "https://arxiv.org/abs/2505.01597v2",
          "size": "2367kb",
          "version": "v2"
        }
      ],
      "title": "Advances in Particle Flow Filters with Taylor Expansion Series",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.01597",
        "HTML": "https://arxiv.org/html/2505.01597v2",
        "PDF": "https://arxiv.org/pdf/2505.01597"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research presents improvements in Particle Flow Filters, which is unrelated to LLM training data tasks like data collection or preparation."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.06002",
      "abstract": "Large-scale pre-trained models have achieved remarkable success in language and image tasks, leading an increasing number of studies to explore the application of pre-trained image models, such as CLIP, in the domain of few-shot action recognition (FSAR). However, current methods generally suffer from several problems: 1) Direct fine-tuning often undermines the generalization capability of the pre-trained model; 2) The exploration of task-specific information is insufficient in the visual tasks; 3) The semantic order information is typically overlooked during text modeling; 4) Existing cross-modal alignment techniques ignore the temporal coupling of multimodal information. To address these, we propose Task-Adapter++, a parameter-efficient dual adaptation method for both image and text encoders. Specifically, to make full use of the variations across different few-shot learning tasks, we design a task-specific adaptation for the image encoder so that the most discriminative information can be well noticed during feature extraction. Furthermore, we leverage large language models (LLMs) to generate detailed sequential sub-action descriptions for each action class, and introduce semantic order adapters into the text encoder to effectively model the sequential relationships between these sub-actions. Finally, we develop an innovative fine-grained cross-modal alignment strategy that actively maps visual features to reside in the same temporal stage as semantic descriptions. Extensive experiments fully demonstrate the effectiveness and superiority of the proposed method, which achieves state-of-the-art performance on 5 benchmarks consistently. The code is open-sourced at https://github.com/Jaulin-Bage/Task-Adapter-pp.",
      "authors": [
        "Congqi Cao",
        "Peiheng Han",
        "Yueran zhang",
        "Yating Yu",
        "Qinyi Lv",
        "Lingtong Min and Yanning zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-09T12:34:10+00:00",
          "link": "https://arxiv.org/abs/2505.06002v1",
          "size": "2545kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T03:25:01+00:00",
          "link": "https://arxiv.org/abs/2505.06002v2",
          "size": "4381kb",
          "version": "v2"
        }
      ],
      "title": "Task-Adapter++: Task-specific Adaptation with Order-aware Alignment for Few-shot Action Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.06002",
        "HTML": "https://arxiv.org/html/2505.06002v2",
        "PDF": "https://arxiv.org/pdf/2505.06002"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper explores task-specific adaptation using large language models but does not propose new methodologies for LLM training data processing or data engineering."
      },
      "tasks": [
        "Action Recognition",
        "cross-modal alignment",
        "Few-Shot action recognition",
        "Few Shot Action Recognition",
        "Few-Shot Learning"
      ],
      "repo_urls": [
        "https://github.com/jaulin-bage/task-adapter-pp"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.06315",
      "abstract": "Recent advances in AI are transforming AI's ubiquitous presence in our world from that of standalone AI-applications into deeply integrated AI-agents. These changes have been driven by agents' increasing capability to autonomously make decisions and initiate actions, using existing applications; whether those applications are AI-based or not. This evolution enables unprecedented levels of AI integration, with agents now able to take actions on behalf of systems and users -- including, in some cases, the powerful ability for the AI to write and execute scripts as it deems necessary. With AI systems now able to autonomously execute code, interact with external systems, and operate without human oversight, traditional security approaches fall short.\n  This paper introduces an asset-centric methodology for threat modeling AI systems that addresses the unique security challenges posed by integrated AI agents. Unlike existing top-down frameworks that analyze individual attacks within specific product contexts, our bottom-up approach enables defenders to systematically identify how vulnerabilities -- both conventional and AI-specific -- impact critical AI assets across distributed infrastructures used to develop and deploy these agents. This methodology allows security teams to: (1) perform comprehensive analysis that communicates effectively across technical domains, (2) quantify security assumptions about third-party AI components without requiring visibility into their implementation, and (3) holistically identify AI-based vulnerabilities relevant to their specific product context. This approach is particularly relevant for securing agentic systems with complex autonomous capabilities. By focusing on assets rather than attacks, our approach scales with the rapidly evolving threat landscape while accommodating increasingly complex and distributed AI development pipelines.",
      "authors": [
        "Jose Sanchez Vicarte",
        "Marcin Spoczynski",
        "Mostafa Elsaid"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-08T18:57:08+00:00",
          "link": "https://arxiv.org/abs/2505.06315v1",
          "size": "1239kb",
          "version": "v1"
        },
        {
          "date": "2025-07-02T22:04:43+00:00",
          "link": "https://arxiv.org/abs/2505.06315v2",
          "size": "1367kb",
          "version": "v2"
        }
      ],
      "title": "Threat Modeling for AI: The Case for an Asset-Centric Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.06315",
        "HTML": "https://arxiv.org/html/2505.06315v2",
        "PDF": "https://arxiv.org/pdf/2505.06315"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a methodology for AI system threat modeling, focusing on security challenges without contributing to LLM training data processing or engineering."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2505.07635",
      "abstract": "Inference queries have been routinely issued to graph machine learning models such as graph neural networks (GNNs) for various network analytical tasks. Nevertheless, GNNs outputs are often hard to interpret comprehensively. Existing methods typically compromise to individual pre-defined explainability measures (such as fidelity), which often leads to biased, ``one-sided'' interpretations. This paper introduces skyline explanation, a new paradigm that interprets GNN output by simultaneously optimizing multiple explainability measures of users' interests. (1) We propose skyline explanations as a Pareto set of explanatory subgraphs that dominate others over multiple explanatory measures. We formulate skyline explanation as a multi-criteria optimization problem, and establish its hardness results. (2) We design efficient algorithms with an onion-peeling approach, which strategically prioritizes nodes and removes unpromising edges to incrementally assemble skyline explanations. (3) We also develop an algorithm to diversify the skyline explanations to enrich the comprehensive interpretation. (4) We introduce efficient parallel algorithms with load-balancing strategies to scale skyline explanation for large-scale GNN-based inference. Using real-world and synthetic graphs, we experimentally verify our algorithms' effectiveness and scalability.",
      "authors": [
        "Dazhuo Qiu",
        "Haolai Che",
        "Arijit Khan",
        "Yinghui Wu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-12T15:05:46+00:00",
          "link": "https://arxiv.org/abs/2505.07635v1",
          "size": "975kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T13:40:49+00:00",
          "link": "https://arxiv.org/abs/2505.07635v2",
          "size": "1098kb",
          "version": "v2"
        }
      ],
      "title": "Interpreting Graph Inference with Skyline Explanations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.07635",
        "HTML": "https://arxiv.org/html/2505.07635v2",
        "PDF": "https://arxiv.org/pdf/2505.07635"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on interpreting graph neural network outputs and proposes skyline explanation for graph inference queries. It does not address training data processing for LLMs."
      },
      "tasks": [
        "Explanation Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.08601",
      "abstract": "Bamboo slips are a crucial medium for recording ancient civilizations in East Asia, and offers invaluable archaeological insights for reconstructing the Silk Road, studying material culture exchanges, and global history. However, many excavated bamboo slips have been fragmented into thousands of irregular pieces, making their rejoining a vital yet challenging step for understanding their content. Here we introduce WisePanda, a physics-driven deep learning framework designed to rejoin fragmented bamboo slips. Based on the physics of fracture and material deterioration, WisePanda automatically generates synthetic training data that captures the physical properties of bamboo fragmentations. This approach enables the training of a matching network without requiring manually paired samples, providing ranked suggestions to facilitate the rejoining process. Compared to the leading curve matching method, WisePanda increases Top-50 matching accuracy from 36% to 52% among more than one thousand candidate fragments. Archaeologists using WisePanda have experienced substantial efficiency improvements (approximately 20 times faster) when rejoining fragmented bamboo slips. This research demonstrates that incorporating physical principles into deep learning models can significantly enhance their performance, transforming how archaeologists restore and study fragmented artifacts. WisePanda provides a new paradigm for addressing data scarcity in ancient artifact restoration through physics-driven machine learning.",
      "authors": [
        "Jinchi Zhu",
        "Zhou Zhao",
        "Hailong Lei",
        "Xiaoguang Wang",
        "Jialiang Lu",
        "Jing Li",
        "Qianqian Tang",
        "Jiachen Shen",
        "Gui-Song Xia",
        "Bo Du and Yongchao Xu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Materials Science (cond-mat.mtrl-sci)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-13T14:16:53+00:00",
          "link": "https://arxiv.org/abs/2505.08601v1",
          "size": "8529kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T02:44:45+00:00",
          "link": "https://arxiv.org/abs/2505.08601v2",
          "size": "10182kb",
          "version": "v2"
        }
      ],
      "title": "Rejoining fragmented ancient bamboo slips with physics-driven deep learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.08601",
        "HTML": "https://arxiv.org/html/2505.08601v2",
        "PDF": "https://arxiv.org/pdf/2505.08601"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a physics-driven deep learning framework for rejoining fragmented ancient bamboo slips using synthetic data, not related to LLM training data processing."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/zhujinchi/wisepanda"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.13886",
      "abstract": "Visual-language Chain-of-Thought (CoT) data resources are relatively scarce compared to text-only counterparts, limiting the improvement of reasoning capabilities in Vision Language Models (VLMs). However, high-quality vision-language reasoning data is expensive and labor-intensive to annotate. To address this issue, we leverage a promising resource: game code, which naturally contains logical structures and state transition processes. Therefore, we propose Code2Logic, a novel game-code-driven approach for multimodal reasoning data synthesis. Our approach leverages Large Language Models (LLMs) to adapt game code, enabling automatic acquisition of reasoning processes and results through code execution. Using the Code2Logic approach, we developed the GameQA dataset to train and evaluate VLMs. GameQA is cost-effective and scalable, offers controllable difficulty gradation and is diverse with 30 games and 158 tasks. Surprisingly, despite training solely on game data, VLMs demonstrated out of domain generalization, specifically Qwen2.5-VL-7B improving performance by 2.33% across 7 diverse vision-language benchmarks. Our code, dataset and models are available at https://github.com/tongjingqi/Code2Logic.",
      "authors": [
        "Jingqi Tong",
        "Jixin Tang",
        "Hangcheng Li",
        "Yurong Mou",
        "Ming Zhang",
        "Jun Zhao",
        "Yanbo Wen",
        "Fan Song",
        "Jiahao Zhan",
        "Yuyang Lu",
        "Chaoran Tao",
        "Zhiyuan Guo",
        "Jizhou Yu",
        "Tianhao Cheng",
        "Changhao Jiang",
        "Zhen Wang",
        "Tao Liang",
        "Zhihui Fei",
        "Mingyang Wan",
        "Guojun Ma",
        "Weifeng Ge",
        "Guanhua Chen",
        "Tao Gui",
        "Xipeng Qiu",
        "Qi Zhang",
        "Xuanjing Huang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-20T03:47:44+00:00",
          "link": "https://arxiv.org/abs/2505.13886v1",
          "size": "4532kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T14:30:25+00:00",
          "link": "https://arxiv.org/abs/2505.13886v2",
          "size": "10414kb",
          "version": "v2"
        }
      ],
      "title": "Code2Logic: Game-Code-Driven Data Synthesis for Enhancing VLMs General Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.13886",
        "PDF": "https://arxiv.org/pdf/2505.13886"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces Code2Logic, which synthesizes game-code-driven multimodal reasoning data using LLMs. It constructs a GameQA dataset for training Vision Language Models, directly impacting LLMs' training data processing."
      },
      "models": [
        {
          "model_path": "Code2Logic/GameQA-InternVL3-8B",
          "downloads": "25",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/Code2Logic/GameQA-InternVL3-8B"
        },
        {
          "model_path": "Code2Logic/GameQA-Qwen2.5-VL-7B",
          "downloads": "24",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/Code2Logic/GameQA-Qwen2.5-VL-7B"
        },
        {
          "model_path": "Code2Logic/GameQA-llava-onevision-qwen2-7b-ov-hf",
          "downloads": "20",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/Code2Logic/GameQA-llava-onevision-qwen2-7b-ov-hf"
        }
      ],
      "datasets": [
        {
          "dataset_name": "Code2Logic/GameQA-140K",
          "downloads": "517",
          "likes": "9",
          "link": "https://huggingface.co/datasets/Code2Logic/GameQA-140K"
        },
        {
          "dataset_name": "Code2Logic/GameQA-5K",
          "downloads": "109",
          "likes": "0",
          "link": "https://huggingface.co/datasets/Code2Logic/GameQA-5K"
        }
      ],
      "tasks": [
        "Domain Generalization",
        "Multimodal Reasoning"
      ],
      "repo_urls": [
        "https://github.com/tongjingqi/code2logic"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.15053",
      "abstract": "Whereas an extension with non-interference of Hoare logic for sequential programs Owicki--Gries logic ensures the correctness of concurrent programs on strict consistency, it is unsound to weak memory models adopted by modern computer architectures and specifications of programming languages. This paper proposes a novel non-interference notion and provides concurrent program logic sound to timestamp semantics corresponding to a weak memory model that allows delays in the effects of store instructions. This paper reports three theoretically interesting techniques for modifying non-interference to support delays in the effects of store instructions. The techniques contribute to a better understanding of constructing concurrent program logic.",
      "authors": [
        "Tatsuya Abe"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-21T03:20:16+00:00",
          "link": "https://arxiv.org/abs/2505.15053v1",
          "size": "16kb",
          "version": "v1"
        },
        {
          "date": "2025-05-25T11:01:54+00:00",
          "link": "https://arxiv.org/abs/2505.15053v2",
          "size": "50kb",
          "version": "v2"
        },
        {
          "date": "2025-06-04T00:37:33+00:00",
          "link": "https://arxiv.org/abs/2505.15053v3",
          "size": "16kb",
          "version": "v3"
        },
        {
          "date": "2025-07-03T00:46:49+00:00",
          "link": "https://arxiv.org/abs/2505.15053v4",
          "size": "17kb",
          "version": "v4"
        }
      ],
      "title": "Owicki--Gries Logic for Timestamp Semantics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.15053",
        "HTML": "https://arxiv.org/html/2505.15053v4",
        "PDF": "https://arxiv.org/pdf/2505.15053"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes Owicki--Gries Logic for concurrent programs with timestamp semantics, which is unrelated to the processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.15075",
      "abstract": "The rapid evolution of multimodal large language models (MLLMs) has significantly enhanced their real-world applications. However, achieving consistent performance across languages, especially when integrating cultural knowledge, remains a significant challenge. To better assess this issue, we introduce two new benchmarks: KnowRecall and VisRecall, which evaluate cross-lingual consistency in MLLMs. KnowRecall is a visual question answering benchmark designed to measure factual knowledge consistency in 15 languages, focusing on cultural and historical questions about global landmarks. VisRecall assesses visual memory consistency by asking models to describe landmark appearances in 9 languages without access to images. Experimental results reveal that state-of-the-art MLLMs, including proprietary ones, still struggle to achieve cross-lingual consistency. This underscores the need for more robust approaches that produce truly multilingual and culturally aware models.",
      "authors": [
        "Hao Wang",
        "Pinzhi Huang",
        "Jihan Yang",
        "Saining Xie",
        "Daisuke Kawahara"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-21T03:43:37+00:00",
          "link": "https://arxiv.org/abs/2505.15075v1",
          "size": "19624kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T10:35:35+00:00",
          "link": "https://arxiv.org/abs/2505.15075v2",
          "size": "5625kb",
          "version": "v2"
        }
      ],
      "title": "Traveling Across Languages: Benchmarking Cross-Lingual Consistency in Multimodal LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.15075",
        "HTML": "https://arxiv.org/html/2505.15075v2",
        "PDF": "https://arxiv.org/pdf/2505.15075"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper involves benchmarking multimodal LLMs for cross-lingual consistency, mentioning data sources and benchmarks, but does not propose new methods for LLM training data processing."
      },
      "datasets": [
        {
          "dataset_name": "nlp-waseda/KnowRecall",
          "downloads": "80",
          "likes": "0",
          "link": "https://huggingface.co/datasets/nlp-waseda/KnowRecall"
        },
        {
          "dataset_name": "nlp-waseda/VisRecall",
          "downloads": "57",
          "likes": "0",
          "link": "https://huggingface.co/datasets/nlp-waseda/VisRecall"
        }
      ],
      "tasks": [
        "Benchmarking",
        "Question Answering",
        "Visual Question Answering"
      ],
      "repo_urls": [
        "https://github.com/nlp-waseda/traveling-across-languages"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.15621",
      "abstract": "We introduce DSCodeBench, a new benchmark designed to evaluate large language models (LLMs) on complicated and realistic data science code generation tasks. DSCodeBench consists of 1,000 carefully constructed problems sourced from realistic problems from GitHub across ten widely used Python data science libraries. Compared to the current state-of-the-art benchmark DS-1000, DSCodeBench offers a more challenging and representative testbed, longer code solutions, more comprehensive data science libraries, clearer and better structured problem descriptions, and stronger test suites. To construct the DSCodeBench, we develop a robust pipeline that combines task scope selection, code construction, test case generation, and problem description synthesis. The process is paired with rigorous manual editing to ensure alignment and enhance evaluation reliability. Experimental result shows that DSCodeBench exhibits robust scaling behavior, where larger models systematically outperform smaller ones, validating its ability to distinguish model capabilities. The best LLM we test, GPT-4o, has a pass@1 of 0.202, indicating that LLMs still have a large room to improve for realistic data science code generation tasks. We believe DSCodeBench will serve as a rigorous and trustworthy foundation for advancing LLM-based data science programming.",
      "authors": [
        "Shuyin Ouyang",
        "Dong Huang",
        "Jingwen Guo",
        "Zeyu Sun",
        "Qihao Zhu",
        "Jie M. Zhang"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-21T15:11:26+00:00",
          "link": "https://arxiv.org/abs/2505.15621v1",
          "size": "1745kb",
          "version": "v1"
        },
        {
          "date": "2025-07-02T20:43:52+00:00",
          "link": "https://arxiv.org/abs/2505.15621v2",
          "size": "1745kb",
          "version": "v2"
        }
      ],
      "title": "DSCodeBench: A Realistic Benchmark for Data Science Code Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.15621",
        "PDF": "https://arxiv.org/pdf/2505.15621"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces DSCodeBench, a benchmark for evaluating LLMs in data science code generation, involving novel data construction and preparation methods as part of the benchmark's development essential for LLM training data processing."
      },
      "repo_urls": [
        "https://github.com/shuyinouyang/ds_bench"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.16341",
      "abstract": "This paper studies the long-tailed semi-supervised learning (LTSSL) with distribution mismatch, where the class distribution of the labeled training data follows a long-tailed distribution and mismatches with that of the unlabeled training data. Most existing methods introduce auxiliary classifiers (experts) to model various unlabeled data distributions and produce pseudo-labels, but the expertises of various experts are not fully utilized. We observe that different experts are good at predicting different intervals of samples, e.g., long-tailed expert is skilled in samples located in the head interval and uniform expert excels in samples located in the medium interval. Therefore, we propose a dynamic expert assignment module that can estimate the class membership (i.e., head, medium, or tail class) of samples, and dynamically assigns suitable expert to each sample based on the estimated membership to produce high-quality pseudo-label in the training phase and produce prediction in the testing phase. We also theoretically reveal that integrating different experts' strengths will lead to a smaller generalization error bound. Moreover, we find that the deeper features are more biased toward the head class but with more discriminative ability, while the shallower features are less biased but also with less discriminative ability. We, therefore, propose a multi-depth feature fusion module to utilize different depth features to mitigate the model bias. Our method demonstrates its effectiveness through comprehensive experiments on the CIFAR-10-LT, STL-10-LT, and SVHN-LT datasets across various settings. The code is available at https://github.com/yaxinhou/Meta-Expert.",
      "authors": [
        "Yaxin Hou",
        "Yuheng Jia"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-22T07:56:44+00:00",
          "link": "https://arxiv.org/abs/2505.16341v1",
          "size": "180kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T11:12:29+00:00",
          "link": "https://arxiv.org/abs/2505.16341v2",
          "size": "181kb",
          "version": "v2"
        }
      ],
      "title": "A Square Peg in a Square Hole: Meta-Expert for Long-Tailed Semi-Supervised Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.16341",
        "HTML": "https://arxiv.org/html/2505.16341v2",
        "PDF": "https://arxiv.org/pdf/2505.16341"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on semi-supervised learning with distribution mismatch and expert integration, unrelated to processing or engineering of LLM training data specifically."
      },
      "tasks": [
        "Pseudo Label"
      ],
      "repo_urls": [
        "https://github.com/yaxinhou/meta-expert"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.18422",
      "abstract": "According to several empirical investigations, despite enhancing human capabilities, human-AI cooperation frequently falls short of expectations and fails to reach true synergy. We propose a task-driven framework that reverses prevalent approaches by assigning AI roles according to how the task's requirements align with the capabilities of AI technology. Three major AI roles are identified through task analysis across risk and complexity dimensions: autonomous, assistive/collaborative, and adversarial. We show how proper human-AI integration maintains meaningful agency while improving performance by methodically mapping these roles to various task types based on current empirical findings. This framework lays the foundation for practically effective and morally sound human-AI collaboration that unleashes human potential by aligning task attributes to AI capabilities. It also provides structured guidance for context-sensitive automation that complements human strengths rather than replacing human judgment.",
      "authors": [
        "Saleh Afroogh",
        "Kush R. Varshney",
        "Jason D'Cruz"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-23T23:19:15+00:00",
          "link": "https://arxiv.org/abs/2505.18422v1",
          "size": "1469kb",
          "version": "v1"
        },
        {
          "date": "2025-05-27T02:30:11+00:00",
          "link": "https://arxiv.org/abs/2505.18422v2",
          "size": "1488kb",
          "version": "v2"
        },
        {
          "date": "2025-05-28T18:22:17+00:00",
          "link": "https://arxiv.org/abs/2505.18422v3",
          "size": "1488kb",
          "version": "v3"
        },
        {
          "date": "2025-07-03T13:59:14+00:00",
          "link": "https://arxiv.org/abs/2505.18422v4",
          "size": "1488kb",
          "version": "v4"
        }
      ],
      "title": "A Task-Driven Human-AI Collaboration: When to Automate, When to Collaborate, When to Challenge",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.18422",
        "PDF": "https://arxiv.org/pdf/2505.18422"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a framework for task-driven human-AI collaboration, not involving any specific contributions to LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.20127",
      "abstract": "AI agents that leverage Large Language Models (LLMs) are increasingly becoming core building blocks of modern software systems. A wide range of frameworks is now available to support the specification of such applications. These frameworks enable the definition of agent setups using natural language prompting, which specifies the roles, goals, and tools assigned to the various agents involved. Within such setups, agent behavior is non-deterministic for any given input, highlighting the critical need for robust debugging and observability tools. In this work, we explore the use of process and causal discovery applied to agent execution trajectories as a means of enhancing developer observability. This approach aids in monitoring and understanding the emergent variability in agent behavior. Additionally, we complement this with LLM-based static analysis techniques to distinguish between intended and unintended behavioral variability. We argue that such instrumentation is essential for giving developers greater control over evolving specifications and for identifying aspects of functionality that may require more precise and explicit definitions.",
      "authors": [
        "Fabiana Fournier",
        "Lior Limonad",
        "Yuval David"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-26T15:26:07+00:00",
          "link": "https://arxiv.org/abs/2505.20127v1",
          "size": "2620kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T10:05:46+00:00",
          "link": "https://arxiv.org/abs/2505.20127v2",
          "size": "2059kb",
          "version": "v2"
        }
      ],
      "title": "Agentic AI Process Observability: Discovering Behavioral Variability",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.20127",
        "PDF": "https://arxiv.org/pdf/2505.20127"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on AI agents using LLMs in software systems and their behavior variability, with no mention or implications of LLM training data processing, engineering, or enhancement."
      },
      "tasks": [
        "Causal Discovery"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.20697",
      "abstract": "The field of hypothesis generation promises to reduce costs in neuroscience by narrowing the range of interventional studies needed to study various phenomena. Existing machine learning methods can generate scientific hypotheses from complex datasets, but many approaches assume causal relationships are static over time, limiting their applicability to systems with dynamic, state-dependent behavior, such as the brain. While some techniques attempt dynamic causal discovery through factor models, they often restrict relationships to linear patterns or impose other simplifying assumptions. We propose a novel method that models dynamic graphs as a conditionally weighted superposition of static graphs, where each static graph can capture nonlinear relationships. This approach enables the detection of complex, time-varying interactions between variables beyond linear limitations. Our method improves f1-scores of predicted dynamic causal patterns by roughly 22-28% on average over baselines in some of our experiments, with some improvements reaching well over 60%. A case study on real brain data demonstrates our method's ability to uncover relationships linked to specific behavioral states, offering valuable insights into neural dynamics.",
      "authors": [
        "Zachary C. Brown and David Carlson"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Applications (stat.AP)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-27T04:06:47+00:00",
          "link": "https://arxiv.org/abs/2505.20697v1",
          "size": "6518kb",
          "version": "v1"
        },
        {
          "date": "2025-05-30T14:13:47+00:00",
          "link": "https://arxiv.org/abs/2505.20697v2",
          "size": "6518kb",
          "version": "v2"
        },
        {
          "date": "2025-07-02T20:42:02+00:00",
          "link": "https://arxiv.org/abs/2505.20697v3",
          "size": "6519kb",
          "version": "v3"
        }
      ],
      "title": "Generating Hypotheses of Dynamic Causal Graphs in Neuroscience: Leveraging Generative Factor Models of Observed Time Series",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.20697",
        "HTML": "https://arxiv.org/html/2505.20697v3",
        "PDF": "https://arxiv.org/pdf/2505.20697"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses hypothesis generation using generative factor models in neuroscience and does not address LLM training data processing or data engineering."
      },
      "tasks": [
        "Causal Discovery",
        "Time Series"
      ],
      "repo_urls": [
        "https://github.com/carlson-lab/redcliff-s-hypothesizing-dynamic-causal-graphs"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.21880",
      "abstract": "This study presents an innovative approach to urban mobility simulation by integrating a Large Language Model (LLM) with Agent-Based Modeling (ABM). Unlike traditional rule-based ABM, the proposed framework leverages LLM to enhance agent diversity and realism by generating synthetic population profiles, allocating routine and occasional locations, and simulating personalized routes. Using real-world data, the simulation models individual behaviors and large-scale mobility patterns in Taipei City. Key insights, such as route heat maps and mode-specific indicators, provide urban planners with actionable information for policy-making. Future work focuses on establishing robust validation frameworks to ensure accuracy and reliability in urban planning applications.",
      "authors": [
        "Yu-Lun Song",
        "Chung-En Tsern",
        "Che-Cheng Wu",
        "Yu-Ming Chang",
        "Syuan-Bo Huang",
        "Wei-Chu Chen",
        "Michael Chia-Liang Lin",
        "Yu-Ta Lin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-28T01:54:28+00:00",
          "link": "https://arxiv.org/abs/2505.21880v1",
          "size": "4323kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T06:38:34+00:00",
          "link": "https://arxiv.org/abs/2505.21880v2",
          "size": "4323kb",
          "version": "v2"
        }
      ],
      "title": "Incorporating LLMs for Large-Scale Urban Complex Mobility Simulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.21880",
        "PDF": "https://arxiv.org/pdf/2505.21880"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper incorporates LLMs for urban mobility simulation by generating synthetic data, involving some aspects of data use but does not contribute to novel methods in LLM training data processing."
      },
      "tasks": [
        "Diversity",
        "Language Modeling",
        "Language Modelling",
        "Large Language Model"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.22618",
      "abstract": "Diffusion-based large language models (Diffusion LLMs) have shown promise for non-autoregressive text generation with parallel decoding capabilities. However, the practical inference speed of open-sourced Diffusion LLMs often lags behind autoregressive models due to the lack of Key-Value (KV) Cache and quality degradation when decoding multiple tokens simultaneously. To bridge this gap, we introduce a novel block-wise approximate KV Cache mechanism tailored for bidirectional diffusion models, enabling cache reuse with negligible performance drop. Additionally, we identify the root cause of generation quality degradation in parallel decoding as the disruption of token dependencies under the conditional independence assumption. To address this, we propose a confidence-aware parallel decoding strategy that selectively decodes tokens exceeding a confidence threshold, mitigating dependency violations and maintaining generation quality. Experimental results on LLaDA and Dream models across multiple LLM benchmarks demonstrate up to \\textbf{27.6$\\times$ throughput} improvement with minimal accuracy loss, closing the performance gap with autoregressive models and paving the way for practical deployment of Diffusion LLMs.",
      "authors": [
        "Chengyue Wu",
        "Hao Zhang",
        "Shuchen Xue",
        "Zhijian Liu",
        "Shizhe Diao",
        "Ligeng Zhu",
        "Ping Luo",
        "Song Han",
        "Enze Xie"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-28T17:39:15+00:00",
          "link": "https://arxiv.org/abs/2505.22618v1",
          "size": "271kb",
          "version": "v1"
        },
        {
          "date": "2025-07-02T05:11:54+00:00",
          "link": "https://arxiv.org/abs/2505.22618v2",
          "size": "501kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T04:51:05+00:00",
          "link": "https://arxiv.org/abs/2505.22618v3",
          "size": "541kb",
          "version": "v3"
        }
      ],
      "title": "Fast-dLLM: Training-free Acceleration of Diffusion LLM by Enabling KV Cache and Parallel Decoding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.22618",
        "HTML": "https://arxiv.org/html/2505.22618v3",
        "PDF": "https://arxiv.org/pdf/2505.22618"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses acceleration techniques for Diffusion LLMs, specifically focusing on inference speed enhancements. There is no mention of novel data processing methods during LLM training stages."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.22768",
      "abstract": "Time series forecasting remains a challenging task for foundation models due to temporal heterogeneity, high dimensionality, and the lack of inherent symbolic structure. In this work, we propose DRAGON (Discrete Representation and Augmented Graph encoding Over de BruijN Graphs), a novel encoder that introduces Multivariate de Bruijn Graphs (MdBGs) to bridge the gap between symbolic representations and neural modeling. DRAGON discretizes continuous input sequences and maps them onto a fixed graph structure, enabling dynamic context recovery via graph-based attention. Integrated as an auxiliary module within a dual-branch architecture, DRAGON augments conventional CNN-based encoders with symbolic, structure-aware representations. All code developed for this study is available at: https://github.com/KurbanIntelligenceLab/MultdBG-Time-Series-Library",
      "authors": [
        "Mert Onur Cakiroglu",
        "Idil Bilge Altun",
        "Mehmet Dalkilic",
        "Elham Buxton and Hasan Kurban"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-28T18:36:26+00:00",
          "link": "https://arxiv.org/abs/2505.22768v1",
          "size": "761kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T04:29:45+00:00",
          "link": "https://arxiv.org/abs/2505.22768v2",
          "size": "349kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T00:58:49+00:00",
          "link": "https://arxiv.org/abs/2505.22768v3",
          "size": "349kb",
          "version": "v3"
        }
      ],
      "title": "Multivariate de Bruijn Graphs: A Symbolic Graph Framework for Time Series Forecasting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.22768",
        "HTML": "https://arxiv.org/html/2505.22768v3",
        "PDF": "https://arxiv.org/pdf/2505.22768"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a new method for time series forecasting using a symbolic graph framework, which does not relate to the processing of LLM training data."
      },
      "tasks": [
        "Time Series",
        "Time Series Forecasting"
      ],
      "repo_urls": [
        "https://github.com/kurbanintelligencelab/multdbg-time-series-library"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.23115",
      "abstract": "Accurately predicting 3D occupancy grids from visual inputs is critical for autonomous driving, but current discriminative methods struggle with noisy data, incomplete observations, and the complex structures inherent in 3D scenes. In this work, we reframe 3D occupancy prediction as a generative modeling task using diffusion models, which learn the underlying data distribution and incorporate 3D scene priors. This approach enhances prediction consistency, noise robustness, and better handles the intricacies of 3D spatial structures. Our extensive experiments show that diffusion-based generative models outperform state-of-the-art discriminative approaches, delivering more realistic and accurate occupancy predictions, especially in occluded or low-visibility regions. Moreover, the improved predictions significantly benefit downstream planning tasks, highlighting the practical advantages of our method for real-world autonomous driving applications.",
      "authors": [
        "Yunshen Wang",
        "Yicheng Liu",
        "Tianyuan Yuan",
        "Yingshi Liang",
        "Xiuyu Yang",
        "Honggang Zhang",
        "Hang Zhao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-29T05:34:22+00:00",
          "link": "https://arxiv.org/abs/2505.23115v1",
          "size": "5196kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T06:55:33+00:00",
          "link": "https://arxiv.org/abs/2505.23115v2",
          "size": "5196kb",
          "version": "v2"
        }
      ],
      "title": "Diffusion-Based Generative Models for 3D Occupancy Prediction in Autonomous Driving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.23115",
        "HTML": "https://arxiv.org/html/2505.23115v2",
        "PDF": "https://arxiv.org/pdf/2505.23115"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work deals with 3D occupancy prediction for autonomous driving and does not address the processing or engineering of LLM training data."
      },
      "tasks": [
        "Autonomous Driving"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.23486",
      "abstract": "Autoformalization, the process of transforming informal mathematical propositions into verifiable formal representations, is a foundational task in automated theorem proving, offering a new perspective on the use of mathematics in both theoretical and applied domains. Driven by the rapid progress in artificial intelligence, particularly large language models (LLMs), this field has witnessed substantial growth, bringing both new opportunities and unique challenges. In this survey, we provide a comprehensive overview of recent advances in autoformalization from both mathematical and LLM-centric perspectives. We examine how autoformalization is applied across various mathematical domains and levels of difficulty, and analyze the end-to-end workflow from data preprocessing to model design and evaluation. We further explore the emerging role of autoformalization in enhancing the verifiability of LLM-generated outputs, highlighting its potential to improve both the trustworthiness and reasoning capabilities of LLMs. Finally, we summarize key open-source models and datasets supporting current research, and discuss open challenges and promising future directions for the field.",
      "authors": [
        "Ke Weng",
        "Lun Du",
        "Sirui Li",
        "Wangyue Lu",
        "Haozhe Sun",
        "Hengyu Liu",
        "Tiancheng Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-29T14:34:54+00:00",
          "link": "https://arxiv.org/abs/2505.23486v1",
          "size": "163kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T06:03:07+00:00",
          "link": "https://arxiv.org/abs/2505.23486v2",
          "size": "163kb",
          "version": "v2"
        }
      ],
      "title": "Autoformalization in the Era of Large Language Models: A Survey",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.23486",
        "HTML": "https://arxiv.org/html/2505.23486v2",
        "PDF": "https://arxiv.org/pdf/2505.23486"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper surveys the use of LLMs in autoformalization but primarily focuses on the applications and advancements in the field rather than specifics of data processing for LLM training, though it does mention data preprocessing in the workflow."
      },
      "tasks": [
        "Automated Theorem Proving"
      ],
      "repo_urls": [
        "https://github.com/hendrycks/math"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.23772",
      "abstract": "In 2022, Persianom, Phan and Yung outlined the creation of Anamorphic Cryptography. With this, we can create a public key to encrypt data, and then have two secret keys. These secret keys are used to decrypt the cipher into different messages. So, one secret key is given to the Dictator (who must be able to decrypt all the messages), and the other is given to Alice. Alice can then decrypt the ciphertext to a secret message that the Dictator cannot see. This paper outlines the implementation of Anamorphic Cryptography using ECC (Elliptic Curve Cryptography), such as with the secp256k1 curve. This gives considerable performance improvements over discrete logarithm-based methods with regard to security for a particular bit length. Overall, it outlines how the secret message sent to Alice is hidden within the random nonce value, which is used within the encryption process, and which is cancelled out when the Dictator decrypts the ciphertext. It also shows that the BSGS (Baby-step Giant-step) variant significantly outperforms unoptimised elliptic curve methods.",
      "authors": [
        "William J Buchanan and Jamie Gilchrist"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-21T12:53:32+00:00",
          "link": "https://arxiv.org/abs/2505.23772v1",
          "size": "238kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T14:52:27+00:00",
          "link": "https://arxiv.org/abs/2505.23772v2",
          "size": "480kb",
          "version": "v2"
        }
      ],
      "title": "Anamorphic Cryptography using Baby-Step Giant-Step Recovery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.23772",
        "HTML": "https://arxiv.org/html/2505.23772v2",
        "PDF": "https://arxiv.org/pdf/2505.23772"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improvements in cryptographic methods using elliptic curve cryptography and does not concern itself with LLM training data processing or related data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.00612",
      "abstract": "Clinical tasks such as diagnosis and treatment require strong decision-making abilities, highlighting the importance of rigorous evaluation benchmarks to assess the reliability of large language models (LLMs). In this work, we introduce a knowledge-guided data augmentation framework that enhances the difficulty of clinical multiple-choice question (MCQ) datasets by generating distractors (i.e., incorrect choices that are similar to the correct one and may confuse existing LLMs). Using our KG-based pipeline, the generated choices are both clinically plausible and deliberately misleading. Our approach involves multi-step, semantically informed walks on a medical knowledge graph to identify distractor paths-associations that are medically relevant but factually incorrect-which then guide the LLM in crafting more deceptive distractors. We apply the designed knowledge graph guided distractor generation (KGGDG) pipline, to six widely used medical QA benchmarks and show that it consistently reduces the accuracy of state-of-the-art LLMs. These findings establish KGGDG as a powerful tool for enabling more robust and diagnostic evaluations of medical LLMs.",
      "authors": [
        "Running Yang",
        "Wenlong Deng",
        "Minghui Chen",
        "Yuyin Zhou",
        "Xiaoxiao Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-31T15:51:09+00:00",
          "link": "https://arxiv.org/abs/2506.00612v1",
          "size": "1608kb",
          "version": "v1"
        },
        {
          "date": "2025-06-03T05:28:26+00:00",
          "link": "https://arxiv.org/abs/2506.00612v2",
          "size": "1608kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T16:50:12+00:00",
          "link": "https://arxiv.org/abs/2506.00612v3",
          "size": "1610kb",
          "version": "v3"
        }
      ],
      "title": "Enhancing Clinical Multiple-Choice Questions Benchmarks with Knowledge Graph Guided Distractor Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.00612",
        "HTML": "https://arxiv.org/html/2506.00612v3",
        "PDF": "https://arxiv.org/pdf/2506.00612"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces a framework for data augmentation by generating complex distractors using a knowledge graph for clinical MCQ datasets, directly contributing to training data enhancement for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.01631",
      "abstract": "As Large Language Models (LLMs) become integral software components in modern applications, unauthorized model derivations through fine-tuning, merging, and redistribution have emerged as critical software engineering challenges. Unlike traditional software where clone detection and license compliance are well-established, the LLM ecosystem lacks effective mechanisms to detect model lineage and enforce licensing agreements. This gap is particularly problematic when open-source model creators, such as Meta's LLaMA, require derivative works to maintain naming conventions for attribution, yet no technical means exist to verify compliance.\n  To fill this gap, treating LLMs as software artifacts requiring provenance tracking, we present TensorGuard, a gradient-based fingerprinting framework for LLM similarity detection and family classification. Our approach extracts model-intrinsic behavioral signatures by analyzing gradient responses to random input perturbations across tensor layers, operating independently of training data, watermarks, or specific model formats. TensorGuard supports the widely-adopted safetensors format and constructs high-dimensional fingerprints through statistical analysis of gradient features. These fingerprints enable two complementary capabilities: direct pairwise similarity assessment between arbitrary models through distance computation, and systematic family classification of unknown models via the K-Means clustering algorithm with domain-informed centroid initialization using known base models. Experimental evaluation on 58 models comprising 8 base models and 50 derivatives across five model families (Llama, Qwen, Gemma, Phi, Mistral) demonstrates 94% classification accuracy under our centroid-initialized K-Means clustering.",
      "authors": [
        "Zehao Wu",
        "Yanjie Zhao",
        "Haoyu Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-02T13:08:01+00:00",
          "link": "https://arxiv.org/abs/2506.01631v1",
          "size": "1537kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T15:36:23+00:00",
          "link": "https://arxiv.org/abs/2506.01631v2",
          "size": "1537kb",
          "version": "v2"
        }
      ],
      "title": "Gradient-Based Model Fingerprinting for LLM Similarity Detection and Family Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.01631",
        "HTML": "https://arxiv.org/html/2506.01631v2",
        "PDF": "https://arxiv.org/pdf/2506.01631"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a method for fingerprinting LLMs to detect model derivations and does not address any aspect of LLM training data collection, construction, or processing."
      },
      "tasks": [
        "Clone Detection",
        "Clustering"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.02453",
      "abstract": "Continual Test-Time Adaptation (CTTA) aims to online adapt a pre-trained model to changing environments during inference. Most existing methods focus on exploiting target data, while overlooking another crucial source of information, the pre-trained weights, which encode underutilized domain-invariant priors. This paper takes the geometric attributes of pre-trained weights as a starting point, systematically analyzing three key components: magnitude, absolute angle, and pairwise angular structure. We find that the pairwise angular structure remains stable across diverse corrupted domains and encodes domain-invariant semantic information, suggesting it should be preserved during adaptation. Based on this insight, we propose PAID (Pairwise Angular-Invariant Decomposition), a prior-driven CTTA method that decomposes weight into magnitude and direction, and introduces a learnable orthogonal matrix via Householder reflections to globally rotate direction while preserving the pairwise angular structure. During adaptation, only the magnitudes and the orthogonal matrices are updated. PAID achieves consistent improvements over recent SOTA methods on four widely used CTTA benchmarks, demonstrating that preserving pairwise angular structure offers a simple yet effective principle for CTTA.",
      "authors": [
        "Kunyu Wang",
        "Xueyang Fu",
        "Yuanfei Bao",
        "Chengjie Ge",
        "Chengzhi Cao",
        "Wei Zhai",
        "Zheng-Jun Zha"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-03T05:18:15+00:00",
          "link": "https://arxiv.org/abs/2506.02453v1",
          "size": "2482kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T06:22:46+00:00",
          "link": "https://arxiv.org/abs/2506.02453v2",
          "size": "2483kb",
          "version": "v2"
        }
      ],
      "title": "PAID: Pairwise Angular-Invariant Decomposition for Continual Test-Time Adaptation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.02453",
        "HTML": "https://arxiv.org/html/2506.02453v2",
        "PDF": "https://arxiv.org/pdf/2506.02453"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on adapting pre-trained models at inference time and does not involve any significant discussion on LLM training data processing or enhancement."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.03997",
      "abstract": "In this paper we introduce a Conditional Answer Set Programming framework (Conditional ASP) for the definition of conditional extensions of Answer Set Programming (ASP). The approach builds on a conditional logic with typicality, and on the combination of a conditional knowledge base with an ASP program, and allows for conditional reasoning over the answer sets of the program. The formalism relies on a multi-preferential semantics (and on the KLM preferential semantics, as a special case) to provide an interpretation of conditionals.",
      "authors": [
        "Mario Alviano",
        "Laura Giordano and Daniele Theseider Dupr\\'e"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-04T14:25:34+00:00",
          "link": "https://arxiv.org/abs/2506.03997v1",
          "size": "51kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T12:50:18+00:00",
          "link": "https://arxiv.org/abs/2506.03997v2",
          "size": "44kb",
          "version": "v2"
        }
      ],
      "title": "A framework for Conditional Reasoning in Answer Set Programming",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.03997",
        "HTML": "https://arxiv.org/html/2506.03997v2",
        "PDF": "https://arxiv.org/pdf/2506.03997"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a framework for Conditional Reasoning in Answer Set Programming, which does not address any aspect of LLM training data processing or data engineering."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2506.06231",
      "abstract": "While several feature embedding models have been developed in the literature, comparisons of these embeddings have largely focused on their numerical performance in classification-related downstream applications. However, an interpretable comparison of different embeddings requires identifying and analyzing mismatches between sample groups clustered within the embedding spaces. In this work, we propose the \\emph{Spectral Pairwise Embedding Comparison (SPEC)} framework to compare embeddings and identify their differences in clustering a reference dataset. Our approach examines the kernel matrices derived from two embeddings and leverages the eigendecomposition of the difference kernel matrix to detect sample clusters that are captured differently by the two embeddings. We present a scalable implementation of this kernel-based approach, with computational complexity that grows linearly with the sample size. Furthermore, we introduce an optimization problem using this framework to align two embeddings, ensuring that clusters identified in one embedding are also captured in the other model. We provide numerical results demonstrating the SPEC's application to compare and align embeddings on large-scale datasets such as ImageNet and MS-COCO. The project page is available at https://mjalali.github.io/SPEC/.",
      "authors": [
        "Mohammad Jalali",
        "Bahar Dibaei Nia",
        "Farzan Farnia"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Spectral Theory (math.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-06T16:50:37+00:00",
          "link": "https://arxiv.org/abs/2506.06231v1",
          "size": "14784kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T12:12:39+00:00",
          "link": "https://arxiv.org/abs/2506.06231v2",
          "size": "14294kb",
          "version": "v2"
        }
      ],
      "title": "Towards an Explainable Comparison and Alignment of Feature Embeddings",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.06231",
        "HTML": "https://arxiv.org/html/2506.06231v2",
        "PDF": "https://arxiv.org/pdf/2506.06231"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus here is on the comparison and alignment of feature embeddings, specifically through the SPEC framework, which is not connected to LLM training data processing activities."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/mjalali/embedding-comparison"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.08320",
      "abstract": "Generative AI technologies, particularly Large Language Models (LLMs), are rapidly being adopted across industry, academia, and government sectors, owing to their remarkable capabilities in natural language processing. However, despite their strengths, the inconsistency and unpredictability of LLM outputs present substantial challenges, especially in security-critical domains such as access control. One critical issue that emerges prominently is the consistency of LLM-generated responses, which is paramount for ensuring secure and reliable operations.\n  In this paper, we study the application of LLMs within the context of Cybersecurity Access Control Systems. Specifically, we investigate the consistency and accuracy of LLM-generated password policies, translating natural language prompts into executable pwquality.conf configuration files. Our experimental methodology adopts two distinct approaches: firstly, we utilize pre-trained LLMs to generate configuration files purely from natural language prompts without additional guidance. Secondly, we provide these models with official pwquality.conf documentation to serve as an informative baseline. We systematically assess the soundness, accuracy, and consistency of these AI-generated configurations. Our findings underscore significant challenges in the current generation of LLMs and contribute valuable insights into refining the deployment of LLMs in Access Control Systems.",
      "authors": [
        "Vivek Vaidya",
        "Aditya Patwardhan",
        "Ashish Kundu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-10T01:12:31+00:00",
          "link": "https://arxiv.org/abs/2506.08320v1",
          "size": "297kb",
          "version": "v1"
        },
        {
          "date": "2025-07-02T23:34:36+00:00",
          "link": "https://arxiv.org/abs/2506.08320v2",
          "size": "297kb",
          "version": "v2"
        }
      ],
      "title": "How Good LLM-Generated Password Policies Are?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.08320",
        "HTML": "https://arxiv.org/html/2506.08320v2",
        "PDF": "https://arxiv.org/pdf/2506.08320"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The study involves using LLMs to generate password policies from natural language prompts, touching on LLMs' capabilities and output consistency. It briefly engages with data generated by LLMs, but doesn't focus on training data preparation or processing for LLMs."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2506.08713",
      "abstract": "Ensuring complex systems meet regulations typically requires checking the validity of assurance cases through a claim-argument-evidence framework. Some challenges in this process include the complicated nature of legal and technical texts, the need for model explanations, and limited access to assurance case data. We propose a compliance detection approach based on Natural Language Inference (NLI): EXplainable CompLiance detection with Argumentative Inference of Multi-hop reasoning (EXCLAIM). We formulate the claim-argument-evidence structure of an assurance case as a multi-hop inference for explainable and traceable compliance detection. We address the limited number of assurance cases by generating them using large language models (LLMs). We introduce metrics that measure the coverage and structural consistency. We demonstrate the effectiveness of the generated assurance case from GDPR requirements in a multi-hop inference task as a case study. Our results highlight the potential of NLI-based approaches in automating the regulatory compliance process.",
      "authors": [
        "Fariz Ikhwantri",
        "Dusica Marijan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-10T11:56:06+00:00",
          "link": "https://arxiv.org/abs/2506.08713v1",
          "size": "10453kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T13:39:37+00:00",
          "link": "https://arxiv.org/abs/2506.08713v2",
          "size": "2657kb",
          "version": "v2"
        }
      ],
      "title": "Explainable Compliance Detection with Multi-Hop Natural Language Inference on Assurance Case Structure",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.08713",
        "HTML": "https://arxiv.org/html/2506.08713v2",
        "PDF": "https://arxiv.org/pdf/2506.08713"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper describes generating assurance case data using LLMs for compliance detection, which is related to LLM data usage but does not focus on the broader aspects of data engineering or LLM training data processing."
      },
      "tasks": [
        "Natural Language Inference"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.09612",
      "abstract": "Text-to-image generation models have made significant progress in producing high-quality images from textual descriptions, yet they continue to struggle with maintaining subject consistency across multiple images, a fundamental requirement for visual storytelling. Existing methods attempt to address this by either fine-tuning models on large-scale story visualization datasets, which is resource-intensive, or by using training-free techniques that share information across generations, which still yield limited success. In this paper, we introduce a novel training-free sampling strategy called Zigzag Sampling with Asymmetric Prompts and Visual Sharing to enhance subject consistency in visual story generation. Our approach proposes a zigzag sampling mechanism that alternates between asymmetric prompting to retain subject characteristics, while a visual sharing module transfers visual cues across generated images to %further enforce consistency. Experimental results, based on both quantitative metrics and qualitative evaluations, demonstrate that our method significantly outperforms previous approaches in generating coherent and consistent visual stories. The code is available at https://github.com/Mingxiao-Li/Asymmetry-Zigzag-StoryDiffusion.",
      "authors": [
        "Mingxiao Li",
        "Mang Ning",
        "Marie-Francine Moens"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-11T11:14:27+00:00",
          "link": "https://arxiv.org/abs/2506.09612v1",
          "size": "36560kb",
          "version": "v1"
        },
        {
          "date": "2025-06-12T13:02:01+00:00",
          "link": "https://arxiv.org/abs/2506.09612v2",
          "size": "36560kb",
          "version": "v2"
        },
        {
          "date": "2025-07-02T20:03:42+00:00",
          "link": "https://arxiv.org/abs/2506.09612v3",
          "size": "36560kb",
          "version": "v3"
        }
      ],
      "title": "Consistent Story Generation with Asymmetry Zigzag Sampling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.09612",
        "HTML": "https://arxiv.org/html/2506.09612v3",
        "PDF": "https://arxiv.org/pdf/2506.09612"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on visual story generation with a training-free sampling strategy and does not address any aspect of LLM training data processing or data engineering."
      },
      "tasks": [
        "Image Generation",
        "Story Generation",
        "Story Visualization",
        "Text to Image Generation",
        "Text-to-Image Generation",
        "Visual Storytelling"
      ],
      "repo_urls": [
        "https://github.com/mingxiao-li/asymmetry-zigzag-storydiffusion"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.09993",
      "abstract": "Image restoration aims to recover degraded images. However, existing diffusion-based restoration methods, despite great success in natural image restoration, often struggle to faithfully reconstruct textual regions in degraded images. Those methods frequently generate plausible but incorrect text-like patterns, a phenomenon we refer to as text-image hallucination. In this paper, we introduce Text-Aware Image Restoration (TAIR), a novel restoration task that requires the simultaneous recovery of visual contents and textual fidelity. To tackle this task, we present SA-Text, a large-scale benchmark of 100K high-quality scene images densely annotated with diverse and complex text instances. Furthermore, we propose a multi-task diffusion framework, called TeReDiff, that integrates internal features from diffusion models into a text-spotting module, enabling both components to benefit from joint training. This allows for the extraction of rich text representations, which are utilized as prompts in subsequent denoising steps. Extensive experiments demonstrate that our approach consistently outperforms state-of-the-art restoration methods, achieving significant gains in text recognition accuracy. See our project page: https://cvlab-kaist.github.io/TAIR/",
      "authors": [
        "Jaewon Min",
        "Jin Hyeon Kim",
        "Paul Hyunbin Cho",
        "Jaeeun Lee",
        "Jihye Park",
        "Minkyu Park",
        "Sangpil Kim",
        "Hyunhee Park",
        "Seungryong Kim"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-11T17:59:46+00:00",
          "link": "https://arxiv.org/abs/2506.09993v1",
          "size": "6141kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T06:39:43+00:00",
          "link": "https://arxiv.org/abs/2506.09993v2",
          "size": "4183kb",
          "version": "v2"
        }
      ],
      "title": "Text-Aware Image Restoration with Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.09993",
        "HTML": "https://arxiv.org/html/2506.09993v2",
        "PDF": "https://arxiv.org/pdf/2506.09993"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper centers on image restoration with diffusion models and a benchmark for text-image restoration but does not involve LLMs or their training data processing."
      },
      "datasets": [
        {
          "dataset_name": "Min-Jaewon/Real-Text",
          "downloads": "88",
          "likes": "2",
          "link": "https://huggingface.co/datasets/Min-Jaewon/Real-Text"
        },
        {
          "dataset_name": "Min-Jaewon/SA-Text",
          "downloads": "221",
          "likes": "7",
          "link": "https://huggingface.co/datasets/Min-Jaewon/SA-Text"
        }
      ],
      "tasks": [
        "Denoising",
        "Hallucination",
        "Image Restoration",
        "Text Spotting"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.10374",
      "abstract": "The group testing problem consists of determining a sparse subset of defective items from within a larger set of items via a series of tests, where each test outcome indicates whether at least one defective item is included in the test. We study the approximate recovery setting, where the recovery criterion of the defective set is relaxed to allow a small number of items to be misclassified. In particular, we consider one-sided approximate recovery criteria, where we allow either only false negative or only false positive misclassifications. Under false negatives only (i.e., finding a subset of defectives), we show that there exists an algorithm matching the optimal threshold of two-sided approximate recovery. Under false positives only (i.e., finding a superset of the defectives), we provide a converse bound showing that the better of two existing algorithms is optimal.",
      "authors": [
        "Daniel McMorrow and Jonathan Scarlett"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)",
        "Statistics Theory (math.ST)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-12T05:53:53+00:00",
          "link": "https://arxiv.org/abs/2506.10374v1",
          "size": "89kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T02:13:31+00:00",
          "link": "https://arxiv.org/abs/2506.10374v2",
          "size": "89kb",
          "version": "v2"
        }
      ],
      "title": "Optimal Non-Adaptive Group Testing with One-Sided Error Guarantees",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.10374",
        "HTML": "https://arxiv.org/html/2506.10374v2",
        "PDF": "https://arxiv.org/pdf/2506.10374"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research addresses group testing algorithms with error guarantees, with no relation to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.10471",
      "abstract": "Two of the most prominent unresolved conjectures in graph theory, the Albertson-Berman conjecture and the Matheson-Tarjan conjecture, have been extensively studied by many researchers.\n  (AB) Every planar graph of order $n$ has an induced forest of order at least $\\frac{n}{2}$.\n  (MT) Every plane triangulation of sufficiently large order $n$ has a dominating set of cardinality at most $\\frac{n}{4}$.\n  Although partial progress and weaker bounds are known, both conjectures remain unsolved. To shed further light on them, researchers have explored a variety of related notions and generalizations. In this paper, we clarify relations among several of these notions, most notably connected domination and induced outerplanar subgraphs, and investigate the corresponding open problems. Furthermore, we construct an infinite family of plane triangulations of order $n$ whose connected domination number exceeds $n/3$. This construction gives a negative answer to a question of Bradshaw et al. [SIAM J. Discrete Math. 36 (2022) 1416-1435], who asked whether the maxleaf number of every plane triangulation of order $n$ is at least $2n/3$. We also obtain new results on induced subgraphs with bounded treewidth and induced outerplanar subgraphs.",
      "authors": [
        "Kengo Enami",
        "Naoki Matsumoto",
        "Takamasa Yashima"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Discrete Mathematics (cs.DM)",
        "Combinatorics (math.CO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-12T08:22:57+00:00",
          "link": "https://arxiv.org/abs/2506.10471v1",
          "size": "46kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T14:30:26+00:00",
          "link": "https://arxiv.org/abs/2506.10471v2",
          "size": "47kb",
          "version": "v2"
        }
      ],
      "title": "Contributions to conjectures in planar graphs: Induced Subgraphs, Treewidth, and Dominating Sets",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.10471",
        "HTML": "https://arxiv.org/html/2506.10471v2",
        "PDF": "https://arxiv.org/pdf/2506.10471"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study deals with conjectures in planar graphs, having no connection to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.10931",
      "abstract": "Raw signal genome analysis (RSGA) has emerged as a promising approach to enable real-time genome analysis by directly analyzing raw electrical signals. However, rapid advancements in sequencing technologies make it increasingly difficult for software-based RSGA to match the throughput of raw signal generation. This paper demonstrates that while hardware acceleration techniques can significantly accelerate RSGA, the high volume of genomic data shifts the performance and energy bottleneck from computation to I/O data movement. As sequencing throughput increases, I/O overhead becomes the main contributor to both runtime and energy consumption. Therefore, there is a need to design a high-performance, energy-efficient system for RSGA that can both alleviate the data movement bottleneck and provide large acceleration capabilities. We propose MARS, a storage-centric system that leverages the heterogeneous resources within modern storage systems (e.g., storage-internal DRAM, storage controller, flash chips) alongside their large storage capacity to tackle both data movement and computational overheads of RSGA in an area-efficient and low-cost manner. MARS accelerates RSGA through a novel hardware/software co-design approach. First, MARS modifies the RSGA pipeline via two filtering mechanisms and a quantization scheme, reducing hardware demands and optimizing for in-storage execution. Second, MARS accelerates the RSGA steps directly within the storage by leveraging both Processing-Near-Memory and Processing-Using-Memory paradigms. Third, MARS orchestrates the execution of all steps to fully exploit in-storage parallelism and minimize data movement. Our evaluation shows that MARS outperforms basecalling-based software and hardware-accelerated state-of-the-art read mapping pipelines by 93x and 40x, on average across different datasets, while reducing their energy consumption by 427x and 72x.",
      "authors": [
        "Melina Soysal",
        "Konstantina Koliogeorgi",
        "Can Firtina",
        "Nika Mansouri Ghiasi",
        "Rakesh Nadig",
        "Haiyu Mao",
        "Geraldo F. Oliveira",
        "Yu Liang",
        "Klea Zambaku",
        "Mohammad Sadrosadati",
        "Onur Mutlu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)",
        "Genomics (q-bio.GN)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-12T17:38:12+00:00",
          "link": "https://arxiv.org/abs/2506.10931v1",
          "size": "2112kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T13:48:25+00:00",
          "link": "https://arxiv.org/abs/2506.10931v2",
          "size": "2112kb",
          "version": "v2"
        }
      ],
      "title": "MARS: Processing-In-Memory Acceleration of Raw Signal Genome Analysis Inside the Storage Subsystem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.10931",
        "HTML": "https://arxiv.org/html/2506.10931v2",
        "PDF": "https://arxiv.org/pdf/2506.10931"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on processing-in-memory techniques for genome analysis, addressing hardware acceleration and data movement challenges in genomic data, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.12479",
      "abstract": "Pioneered by the foundational information theory by Claude Shannon and the visionary framework of machine intelligence by Alan Turing, the convergent evolution of information and communication technologies (IT/CT) has created an unbroken wave of connectivity and computation. This synergy has sparked a technological revolution, now reaching its peak with large artificial intelligence (AI) models that are reshaping industries and redefining human-machine collaboration. However, the realization of ubiquitous intelligence faces considerable challenges due to substantial resource consumption in large models and high communication bandwidth demands. To address these challenges, AI Flow has been introduced as a multidisciplinary framework that integrates cutting-edge IT and CT advancements, with a particular emphasis on the following three key points. First, device-edge-cloud framework serves as the foundation, which integrates end devices, edge servers, and cloud clusters to optimize scalability and efficiency for low-latency model inference. Second, we introduce the concept of familial models, which refers to a series of different-sized models with aligned hidden features, enabling effective collaboration and the flexibility to adapt to varying resource constraints and dynamic scenarios. Third, connectivity- and interaction-based intelligence emergence is a novel paradigm of AI Flow. By leveraging communication networks to enhance connectivity, the collaboration among AI models across heterogeneous nodes achieves emergent intelligence that surpasses the capability of any single model. The innovations of AI Flow provide enhanced intelligence, timely responsiveness, and ubiquitous accessibility to AI services, paving the way for the tighter fusion of AI techniques and communication systems.",
      "authors": [
        "Hongjun An",
        "Wenhan Hu",
        "Sida Huang",
        "Siqi Huang",
        "Ruanjun Li",
        "Yuanzhi Liang",
        "Jiawei Shao",
        "Yiliang Song",
        "Zihan Wang",
        "Cheng Yuan",
        "Chi Zhang",
        "Hongyuan Zhang",
        "Wenhao Zhuang",
        "Xuelong Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-14T12:43:07+00:00",
          "link": "https://arxiv.org/abs/2506.12479v1",
          "size": "2544kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T12:11:34+00:00",
          "link": "https://arxiv.org/abs/2506.12479v2",
          "size": "2543kb",
          "version": "v2"
        }
      ],
      "title": "AI Flow: Perspectives, Scenarios, and Approaches",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.12479",
        "HTML": "https://arxiv.org/html/2506.12479v2",
        "PDF": "https://arxiv.org/pdf/2506.12479"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses AI Flow, a framework integrating IT and CT for improving AI model performance across devices and networks, without addressing LLM training data processing."
      },
      "models": [
        {
          "model_path": "TeleAI-AI-Flow/AI-Flow-Ruyi-7B-Preview0704",
          "downloads": "2",
          "likes": "3",
          "trending_score": "3.0",
          "link": "https://huggingface.co/TeleAI-AI-Flow/AI-Flow-Ruyi-7B-Preview0704"
        }
      ],
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2506.13972",
      "abstract": "Membership inference attacks (MIAs) pose a significant threat to the privacy of machine learning models and are widely used as tools for privacy assessment, auditing, and machine unlearning. While prior MIA research has primarily focused on performance metrics such as AUC, accuracy, and TPR@low FPR - either by developing new methods to enhance these metrics or using them to evaluate privacy solutions - we found that it overlooks the disparities among different attacks. These disparities, both between distinct attack methods and between multiple instantiations of the same method, have crucial implications for the reliability and completeness of MIAs as privacy evaluation tools. In this paper, we systematically investigate these disparities through a novel framework based on coverage and stability analysis. Extensive experiments reveal significant disparities in MIAs, their potential causes, and their broader implications for privacy evaluation. To address these challenges, we propose an ensemble framework with three distinct strategies to harness the strengths of state-of-the-art MIAs while accounting for their disparities. This framework not only enables the construction of more powerful attacks but also provides a more robust and comprehensive methodology for privacy evaluation.",
      "authors": [
        "Zhiqi Wang",
        "Chengyu Zhang",
        "Yuetian Chen",
        "Nathalie Baracaldo",
        "Swanand Kadhe",
        "Lei Yu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-16T20:22:07+00:00",
          "link": "https://arxiv.org/abs/2506.13972v1",
          "size": "1372kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T17:45:38+00:00",
          "link": "https://arxiv.org/abs/2506.13972v2",
          "size": "1353kb",
          "version": "v2"
        }
      ],
      "title": "Membership Inference Attacks as Privacy Tools: Reliability, Disparity and Ensemble",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.13972",
        "HTML": "https://arxiv.org/html/2506.13972v2",
        "PDF": "https://arxiv.org/pdf/2506.13972"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is concerned with membership inference attacks and privacy assurance in machine learning, which doesn't pertain to the processing of LLM training data."
      },
      "tasks": [
        "Machine Unlearning"
      ],
      "repo_urls": [
        "https://github.com/RPI-DSPlab/mia-disparity"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.14634",
      "abstract": "The recent development and wider accessibility of LLMs have spurred discussions about how they can be used in survey research, including classifying open-ended survey responses. Due to their linguistic capacities, it is possible that LLMs are an efficient alternative to time-consuming manual coding and the pre-training of supervised machine learning models. As most existing research on this topic has focused on English-language responses relating to non-complex topics or on single LLMs, it is unclear whether its findings generalize and how the quality of these classifications compares to established methods. In this study, we investigate to what extent different LLMs can be used to code open-ended survey responses in other contexts, using German data on reasons for survey participation as an example. We compare several state-of-the-art LLMs and several prompting approaches, and evaluate the LLMs' performance by using human expert codings. Overall performance differs greatly between LLMs, and only a fine-tuned LLM achieves satisfactory levels of predictive performance. Performance differences between prompting approaches are conditional on the LLM used. Finally, LLMs' unequal classification performance across different categories of reasons for survey participation results in different categorical distributions when not using fine-tuning. We discuss the implications of these findings, both for methodological research on coding open-ended responses and for their substantive analysis, and for practitioners processing or substantively analyzing such data. Finally, we highlight the many trade-offs researchers need to consider when choosing automated methods for open-ended response classification in the age of LLMs. In doing so, our study contributes to the growing body of research about the conditions under which LLMs can be efficiently, accurately, and reliably leveraged in survey research.",
      "authors": [
        "Leah von der Heyde",
        "Anna-Carolina Haensch",
        "Bernd Wei{\\ss}",
        "Jessica Daikeler"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-17T15:28:53+00:00",
          "link": "https://arxiv.org/abs/2506.14634v1",
          "size": "4976kb",
          "version": "v1"
        },
        {
          "date": "2025-06-18T09:56:49+00:00",
          "link": "https://arxiv.org/abs/2506.14634v2",
          "size": "4976kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T07:58:18+00:00",
          "link": "https://arxiv.org/abs/2506.14634v3",
          "size": "4904kb",
          "version": "v3"
        }
      ],
      "title": "AIn't Nothing But a Survey? Using Large Language Models for Coding German Open-Ended Survey Responses on Survey Motivation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.14634",
        "PDF": "https://arxiv.org/pdf/2506.14634"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper explores using LLMs for coding survey responses, with some focus on data processing for fine-tuning. However, it doesn't significantly contribute new methods for LLM training data processing."
      },
      "tasks": [
        "Survey"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.15830",
      "abstract": "Optimization in large language models (LLMs) unfolds over high-dimensional parameter spaces with non-Euclidean structure. Information geometry frames this landscape using the Fisher information metric, enabling more principled learning via natural gradient descent. Though often impractical, this geometric lens clarifies phenomena such as sharp minima, generalization, and observed scaling laws. We argue that curvature-aware approaches deepen our understanding of LLM training. Finally, we speculate on quantum analogies based on the Fubini-Study metric and Quantum Fisher Information, hinting at efficient optimization in quantum-enhanced systems.",
      "authors": [
        "Riccardo Di Sipio"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-18T19:17:47+00:00",
          "link": "https://arxiv.org/abs/2506.15830v1",
          "size": "140kb",
          "version": "v1"
        },
        {
          "date": "2025-06-26T16:14:42+00:00",
          "link": "https://arxiv.org/abs/2506.15830v2",
          "size": "141kb",
          "version": "v2"
        },
        {
          "date": "2025-07-02T21:36:55+00:00",
          "link": "https://arxiv.org/abs/2506.15830v3",
          "size": "141kb",
          "version": "v3"
        }
      ],
      "title": "Rethinking LLM Training through Information Geometry and Quantum Metrics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.15830",
        "HTML": "https://arxiv.org/html/2506.15830v3",
        "PDF": "https://arxiv.org/pdf/2506.15830"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores optimization in LLMs using information geometry and quantum metrics, not focusing on LLM training data processing or data engineering tasks."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2506.15854",
      "abstract": "Connected and Autonomous Vehicles (CAVs) rely on a range of devices that often process privacy-sensitive data. Among these, roadside units play a critical role particularly through the use of AI-equipped (AIE) cameras for applications such as violation detection. However, the privacy risks associated with captured imagery remain a major concern, as such data can be misused for identity theft, profiling, or unauthorized commercial purposes. While traditional techniques such as face blurring and obfuscation have been applied to mitigate privacy risks, individual privacy remains at risk, as individuals can still be tracked using other features such as their clothing. This paper introduces a novel privacy-preserving framework that leverages feedback-based reinforcement learning (RL) and vision-language models (VLMs) to protect sensitive visual information captured by AIE cameras. The main idea is to convert images into semantically equivalent textual descriptions, ensuring that scene-relevant information is retained while visual privacy is preserved. A hierarchical RL strategy is employed to iteratively refine the generated text, enhancing both semantic accuracy and privacy. Evaluation results demonstrate significant improvements in both privacy protection and textual quality, with the Unique Word Count increasing by approximately 77\\% and Detail Density by around 50\\% compared to existing approaches.",
      "authors": [
        "Abdolazim Rezaei",
        "Mehdi Sookhak",
        "Ahmad Patooghy"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-18T20:02:24+00:00",
          "link": "https://arxiv.org/abs/2506.15854v1",
          "size": "4972kb",
          "version": "v1"
        },
        {
          "date": "2025-07-02T18:31:53+00:00",
          "link": "https://arxiv.org/abs/2506.15854v2",
          "size": "4958kb",
          "version": "v2"
        }
      ],
      "title": "Privacy-Preserving in Connected and Autonomous Vehicles Through Vision to Text Transformation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.15854",
        "HTML": "https://arxiv.org/html/2506.15854v2",
        "PDF": "https://arxiv.org/pdf/2506.15854"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a privacy-preserving framework using reinforcement learning and vision-language models for transforming images into text, but it is not related to the processing of training data for LLMs."
      },
      "tasks": [
        "Autonomous Vehicles",
        "Privacy Preserving",
        "Reinforcement Learning (RL)"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.16889",
      "abstract": "Music mastering style transfer aims to model and apply the mastering characteristics of a reference track to a target track, simulating the professional mastering process. However, existing methods apply fixed processing based on a reference track, limiting users' ability to fine-tune the results to match their artistic intent. In this paper, we introduce the ITO-Master framework, a reference-based mastering style transfer system that integrates Inference-Time Optimization (ITO) to enable finer user control over the mastering process. By optimizing the reference embedding during inference, our approach allows users to refine the output dynamically, making micro-level adjustments to achieve more precise mastering results. We explore both black-box and white-box methods for modeling mastering processors and demonstrate that ITO improves mastering performance across different styles. Through objective evaluation, subjective listening tests, and qualitative analysis using text-based conditioning with CLAP embeddings, we validate that ITO enhances mastering style similarity while offering increased adaptability. Our framework provides an effective and user-controllable solution for mastering style transfer, allowing users to refine their results beyond the initial style transfer.",
      "authors": [
        "Junghyun Koo",
        "Marco A. Mart\\'inez-Ram\\'irez",
        "Wei-Hsiang Liao",
        "Giorgio Fabbro",
        "Michele Mancusi",
        "and Yuki Mitsufuji"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-20T10:21:56+00:00",
          "link": "https://arxiv.org/abs/2506.16889v1",
          "size": "594kb",
          "version": "v1"
        },
        {
          "date": "2025-06-26T08:38:02+00:00",
          "link": "https://arxiv.org/abs/2506.16889v2",
          "size": "595kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T03:36:09+00:00",
          "link": "https://arxiv.org/abs/2506.16889v3",
          "size": "595kb",
          "version": "v3"
        }
      ],
      "title": "ITO-Master: Inference-Time Optimization for Audio Effects Modeling of Music Mastering Processors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.16889",
        "HTML": "https://arxiv.org/html/2506.16889v3",
        "PDF": "https://arxiv.org/pdf/2506.16889"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on music mastering style transfer and optimizing audio effects modeling, with no relevance to LLM training data processing stages."
      },
      "repo_urls": [
        "https://github.com/sonyresearch/ito-master"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.17347",
      "abstract": "Over the past decade, policymakers have developed a set of regulatory tools to ensure AI development aligns with key societal goals. Many of these tools were initially developed in response to concerns with predictive AI and therefore encode certain assumptions about the nature of AI systems and the utility of certain regulatory approaches. With the advent of generative AI, however, some of these assumptions no longer hold, even as policymakers attempt to maintain a single regulatory target that covers both types of AI. In this paper, we identify four distinct aspects of generative AI that call for meaningfully different policy responses. These are the generality and adaptability of generative AI that make it a poor regulatory target, the difficulty of designing effective evaluations, new legal concerns that change the ecosystem of stakeholders and sources of expertise, and the distributed structure of the generative AI value chain. In light of these distinctions, policymakers will need to evaluate where the past decade of policy work remains relevant and where new policies, designed to address the unique risks posed by generative AI, are necessary. We outline three recommendations for policymakers to more effectively identify regulatory targets and leverage constraints across the broader ecosystem to govern generative AI.",
      "authors": [
        "Jennifer Wang",
        "Andrew Selbst",
        "Solon Barocas",
        "Suresh Venkatasubramanian"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-19T17:17:55+00:00",
          "link": "https://arxiv.org/abs/2506.17347v1",
          "size": "119kb",
          "version": "v1"
        },
        {
          "date": "2025-07-02T22:50:44+00:00",
          "link": "https://arxiv.org/abs/2506.17347v2",
          "size": "128kb",
          "version": "v2"
        }
      ],
      "title": "Distinguishing Predictive and Generative AI in Regulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.17347",
        "HTML": "https://arxiv.org/html/2506.17347v2",
        "PDF": "https://arxiv.org/pdf/2506.17347"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the regulatory aspects of AI, distinguishing predictive and generative AI, without addressing training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.17828",
      "abstract": "Aligning large language models (LLMs) with human preferences usually requires fine-tuning methods such as RLHF and DPO. These methods directly optimize the model parameters, so they cannot be used in test-time to improve model performance, nor are they applicable when the model weights are not accessible. In contrast, test-time methods sidestep weight updates by leveraging reward functions to guide and improve output quality. However, they incur high inference costs, and their one-shot guidance is often based on imperfect reward or value functions, leading to suboptimal outputs. In this work, we present a method named Iterative Reweight-then-Optimize (IRO), a reinforcement learning (RL) framework that performs RL-style alignment of the (frozen) base model without touching its parameters. During training, each iteration (i) samples candidates from the base model, (ii) resamples using current value functions, and (iii) trains a new lightweight value function that guides the next decoding pass. At test time, the value functions are used to guide the base model generation via a search-based optimization process. Notably, users can apply IRO to align a model on their own dataset, similar to OpenAI's reinforcement fine-tuning (RFT), but without requiring access to the model weights.",
      "authors": [
        "Xinnan Zhang",
        "Chenliang Li",
        "Siliang Zeng",
        "Jiaxiang Li",
        "Zhongruo Wang",
        "Kaixiang Lin",
        "Songtao Lu",
        "Alfredo Garcia",
        "Mingyi Hong"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-21T21:49:02+00:00",
          "link": "https://arxiv.org/abs/2506.17828v1",
          "size": "1939kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T05:12:51+00:00",
          "link": "https://arxiv.org/abs/2506.17828v2",
          "size": "1967kb",
          "version": "v2"
        }
      ],
      "title": "Aligning Frozen LLMs by Reinforcement Learning: An Iterative Reweight-then-Optimize Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.17828",
        "PDF": "https://arxiv.org/pdf/2506.17828"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper involves aligning frozen large language models using reinforcement learning, it briefly touches on model alignment methods with user datasets, which tangentially relates to data processing in the context of model fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.18248",
      "abstract": "Generative adversarial attacks train a perturbation generator on a white-box surrogate model and subsequently apply the crafted perturbations to unseen black-box victim models. In contrast to iterative attacks, these methods deliver superior inference-time efficiency, scalability, and transferability; however, up until now, existing studies have not fully exploited the representational capacity of generative models to preserve and harness semantic information. Specifically, the intermediate activations of the generator encode rich semantic features--object boundaries and coarse shapes--that remain under-exploited, thereby limiting the alignment of perturbations with object-salient regions which are critical for adversarial transferability. To remedy this, we introduce a semantic structure-aware attack framework based on the Mean Teacher, which serves as a temporally smoothed feature reference. With this smoothed reference, we further direct semantic consistency between the early-layer activations in the student and those of the semantically rich teacher by feature distillation. By anchoring perturbation synthesis to the semantically salient early intermediate blocks within the generator based on empirical findings, our method guides progressive adversarial perturbation on regions that substantially enhance adversarial transferability. We conduct extensive experiments over diverse models, domains and tasks to demonstrate consistent improvements relative to state-of-the-art generative attacks, comprehensively evaluated using conventional metrics and our newly proposed Accidental Correction Rate (ACR).",
      "authors": [
        "Jongoh Jeong",
        "Hunmin Yang",
        "Jaeseok Jeong",
        "Kuk-Jin Yoon"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T02:35:09+00:00",
          "link": "https://arxiv.org/abs/2506.18248v1",
          "size": "14609kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T03:17:52+00:00",
          "link": "https://arxiv.org/abs/2506.18248v2",
          "size": "14610kb",
          "version": "v2"
        }
      ],
      "title": "Semantic Structure-Aware Generative Attacks for Enhanced Adversarial Transferability",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18248",
        "HTML": "https://arxiv.org/html/2506.18248v2",
        "PDF": "https://arxiv.org/pdf/2506.18248"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on generative adversarial attacks and adversarial transferability, which are unrelated to LLM training data processing stages such as data collection or processing for pre-training or fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.18482",
      "abstract": "Experience replay enables data-efficient learning from past experiences in online reinforcement learning agents. Traditionally, experiences were sampled uniformly from a replay buffer, regardless of differences in experience-specific learning potential. In an effort to sample more efficiently, researchers introduced Prioritized Experience Replay (PER). In this paper, we propose an extension to PER by introducing a novel measure of temporal difference error reliability. We theoretically show that the resulting transition selection algorithm, Reliability-adjusted Prioritized Experience Replay (ReaPER), enables more efficient learning than PER. We further present empirical results showing that ReaPER outperforms PER across various environment types, including the Atari-10 benchmark.",
      "authors": [
        "Leonard S. Pleiss",
        "Tobias Sutter",
        "Maximilian Schiffer"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T10:35:36+00:00",
          "link": "https://arxiv.org/abs/2506.18482v1",
          "size": "1439kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T09:55:57+00:00",
          "link": "https://arxiv.org/abs/2506.18482v2",
          "size": "1574kb",
          "version": "v2"
        }
      ],
      "title": "Reliability-Adjusted Prioritized Experience Replay",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18482",
        "HTML": "https://arxiv.org/html/2506.18482v2",
        "PDF": "https://arxiv.org/pdf/2506.18482"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is concerned with enhancements in reinforcement learning sampling strategies, specifically Reliability-Adjusted Prioritized Experience Replay, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.18959",
      "abstract": "Information retrieval is a cornerstone of modern knowledge acquisition, enabling billions of queries each day across diverse domains. However, traditional keyword-based search engines are increasingly inadequate for handling complex, multi-step information needs. Our position is that Large Language Models (LLMs), endowed with reasoning and agentic capabilities, are ushering in a new paradigm termed Agentic Deep Research. These systems transcend conventional information search techniques by tightly integrating autonomous reasoning, iterative retrieval, and information synthesis into a dynamic feedback loop. We trace the evolution from static web search to interactive, agent-based systems that plan, explore, and learn. We also introduce a test-time scaling law to formalize the impact of computational depth on reasoning and search. Supported by benchmark results and the rise of open-source implementations, we demonstrate that Agentic Deep Research not only significantly outperforms existing approaches, but is also poised to become the dominant paradigm for future information seeking. All the related resources, including industry products, research papers, benchmark datasets, and open-source implementations, are collected for the community in https://github.com/DavidZWZ/Awesome-Deep-Research.",
      "authors": [
        "Weizhi Zhang",
        "Yangning Li",
        "Yuanchen Bei",
        "Junyu Luo",
        "Guancheng Wan",
        "Liangwei Yang",
        "Chenxuan Xie",
        "Yuyao Yang",
        "Wei-Chieh Huang",
        "Chunyu Miao",
        "Henry Peng Zou",
        "Xiao Luo",
        "Yusheng Zhao",
        "Yankai Chen",
        "Chunkit Chan",
        "Peilin Zhou",
        "Xinyang Zhang",
        "Chenwei Zhang",
        "Jingbo Shang",
        "Ming Zhang",
        "Yangqiu Song",
        "Irwin King",
        "Philip S. Yu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T17:27:19+00:00",
          "link": "https://arxiv.org/abs/2506.18959v1",
          "size": "2851kb",
          "version": "v1"
        },
        {
          "date": "2025-06-26T17:18:00+00:00",
          "link": "https://arxiv.org/abs/2506.18959v2",
          "size": "2850kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T17:48:36+00:00",
          "link": "https://arxiv.org/abs/2506.18959v3",
          "size": "2851kb",
          "version": "v3"
        }
      ],
      "title": "From Web Search towards Agentic Deep Research: Incentivizing Search with Reasoning Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18959",
        "HTML": "https://arxiv.org/html/2506.18959v3",
        "PDF": "https://arxiv.org/pdf/2506.18959"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper discusses the use of LLMs in information retrieval, there is no direct contribution towards data processing techniques for LLMs. It focuses on the application of LLMs rather than improvements to training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.19283",
      "abstract": "While multi-vehicular collaborative driving demonstrates clear advantages over single-vehicle autonomy, traditional infrastructure-based V2X systems remain constrained by substantial deployment costs and the creation of \"uncovered danger zones\" in rural and suburban areas. We present AirV2X-Perception, a large-scale dataset that leverages Unmanned Aerial Vehicles (UAVs) as a flexible alternative or complement to fixed Road-Side Units (RSUs). Drones offer unique advantages over ground-based perception: complementary bird's-eye-views that reduce occlusions, dynamic positioning capabilities that enable hovering, patrolling, and escorting navigation rules, and significantly lower deployment costs compared to fixed infrastructure. Our dataset comprises 6.73 hours of drone-assisted driving scenarios across urban, suburban, and rural environments with varied weather and lighting conditions. The AirV2X-Perception dataset facilitates the development and standardized evaluation of Vehicle-to-Drone (V2D) algorithms, addressing a critical gap in the rapidly expanding field of aerial-assisted autonomous driving systems. The dataset and development kits are open-sourced at https://github.com/taco-group/AirV2X-Perception.",
      "authors": [
        "Xiangbo Gao",
        "Yuheng Wu",
        "Fengze Yang",
        "Xuewen Luo",
        "Keshu Wu",
        "Xinghao Chen",
        "Yuping Wang",
        "Chenxi Liu",
        "Yang Zhou",
        "Zhengzhong Tu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-24T03:34:39+00:00",
          "link": "https://arxiv.org/abs/2506.19283v1",
          "size": "5605kb",
          "version": "v1"
        },
        {
          "date": "2025-07-01T01:20:24+00:00",
          "link": "https://arxiv.org/abs/2506.19283v2",
          "size": "5605kb",
          "version": "v2"
        },
        {
          "date": "2025-07-02T23:07:24+00:00",
          "link": "https://arxiv.org/abs/2506.19283v3",
          "size": "5605kb",
          "version": "v3"
        }
      ],
      "title": "AirV2X: Unified Air-Ground Vehicle-to-Everything Collaboration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19283",
        "HTML": "https://arxiv.org/html/2506.19283v3",
        "PDF": "https://arxiv.org/pdf/2506.19283"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study introduces a dataset related to vehicle and aerial drone interactions for autonomous driving, which is unrelated to the data processing stages for Large Language Model training."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.19660",
      "abstract": "As flash-based Solid State Drive (SSD) arrays become essential to modern data centers, scaling these arrays to meet explosive data growth is a frequent and critical operation. However, the conventional wear-leveling (WL) paradigm applied during scaling suffers from a fundamental flaw: it ignores the non-linear relationship between wear and failure probability, potentially pushing the most vulnerable, aged disks towards premature failure. To address this critical issue at its root, we propose the Probability-Sensitive Wear Leveling (PS-WL) scheme, which shifts the optimization goal from balancing wear to directly balancing failure risk. At its core, PS-WL introduces an \"effective lifetime\" model derived from a realistic failure probability to more accurately assess disk lifetime. This model guides a PID controller for wear leveling operation, with a conservative zone minimizes performance overhead by restricting warm data migration. Comprehensive simulations validate the superiority of PS-WL over state-of-the-art methods. The results demonstrate that our approach significantly reduces performance overhead while, most critically, consistently and effectively lowering the aggregated array failure risk across diverse system configurations and workloads. This proves that by directly optimizing for reliability, PS-WL builds a scalable storage system that is, by design, fundamentally safer, more efficient, and more stable.",
      "authors": [
        "Shuhang Xu",
        "Yunfei Gu",
        "Linhui Liu",
        "Chentao Wu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-24T14:22:56+00:00",
          "link": "https://arxiv.org/abs/2506.19660v1",
          "size": "197kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T15:00:42+00:00",
          "link": "https://arxiv.org/abs/2506.19660v2",
          "size": "2462kb",
          "version": "v2"
        }
      ],
      "title": "PS-WL: A Probability-Sensitive Wear Leveling scheme for SSD array scaling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19660",
        "HTML": "https://arxiv.org/html/2506.19660v2",
        "PDF": "https://arxiv.org/pdf/2506.19660"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about improving wear leveling in SSD arrays, a topic not related to LLM training data processing, so it does not address any relevant concepts in data engineering or training-stage data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21191",
      "abstract": "Turn-taking prediction models are essential components in spoken dialogue systems and conversational robots. Recent approaches leverage transformer-based architectures to predict speech activity continuously and in real-time. In this study, we propose a novel model that enables turn-taking prediction to be dynamically controlled via textual prompts. This approach allows intuitive and explicit control through instructions such as \"faster\" or \"calmer\" adapting dynamically to conversational partners and contexts. The proposed model builds upon a transformer-based voice activity projection (VAP) model, incorporating textual prompt embeddings into both channel-wise transformers and a cross-channel transformer. We evaluated the feasibility of our approach using over 950 hours of human-human spoken dialogue data. Since textual prompt data for the proposed approach was not available in existing datasets, we utilized a large language model (LLM) to generate synthetic prompt sentences. Experimental results demonstrated that the proposed model improved prediction accuracy and effectively varied turn-taking timing behaviors according to the textual prompts.",
      "authors": [
        "Koji Inoue",
        "Mikey Elmers",
        "Yahui Fu",
        "Zi Haur Pang",
        "Divesh Lala",
        "Keiko Ochi",
        "Tatsuya Kawahara"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T12:49:07+00:00",
          "link": "https://arxiv.org/abs/2506.21191v1",
          "size": "518kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T04:01:44+00:00",
          "link": "https://arxiv.org/abs/2506.21191v2",
          "size": "518kb",
          "version": "v2"
        }
      ],
      "title": "Prompt-Guided Turn-Taking Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21191",
        "PDF": "https://arxiv.org/pdf/2506.21191"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper uses a large language model to generate synthetic prompt sentences, which involves data preparation for training, but it does not propose new methods or insights into LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21506",
      "abstract": "Agentic search such as Deep Research systems-where agents autonomously browse the web, synthesize information, and return comprehensive citation-backed answers-represents a major shift in how users interact with web-scale information. While promising greater efficiency and cognitive offloading, the growing complexity and open-endedness of agentic search have outpaced existing evaluation benchmarks and methodologies, which largely assume short search horizons and static answers. In this paper, we introduce Mind2Web 2, a benchmark of 130 realistic, high-quality, and long-horizon tasks that require real-time web browsing and extensive information synthesis, constructed with over 1000 hours of human labor. To address the challenge of evaluating time-varying and complex answers, we propose a novel Agent-as-a-Judge framework. Our method constructs task-specific judge agents based on a tree-structured rubric design to automatically assess both answer correctness and source attribution. We conduct a comprehensive evaluation of ten frontier agentic search systems and human performance, along with a detailed error analysis to draw insights for future development. The best-performing system, OpenAI Deep Research, can already achieve 50-70% of human performance while spending half the time, highlighting its great potential. Altogether, Mind2Web 2 provides a rigorous foundation for developing and benchmarking the next generation of agentic search systems.",
      "authors": [
        "Boyu Gou",
        "Zanming Huang",
        "Yuting Ning",
        "Yu Gu",
        "Michael Lin",
        "Weijian Qi",
        "Andrei Kopanev",
        "Botao Yu",
        "Bernal Jim\\'enez Guti\\'errez",
        "Yiheng Shu",
        "Chan Hee Song",
        "Jiaman Wu",
        "Shijie Chen",
        "Hanane Nour Moussa",
        "Tianshu Zhang",
        "Jian Xie",
        "Yifei Li",
        "Tianci Xue",
        "Zeyi Liao",
        "Kai Zhang",
        "Boyuan Zheng",
        "Zhaowei Cai",
        "Viktor Rozgic",
        "Morteza Ziyadi",
        "Huan Sun",
        "Yu Su"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T17:32:50+00:00",
          "link": "https://arxiv.org/abs/2506.21506v1",
          "size": "8157kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T15:47:40+00:00",
          "link": "https://arxiv.org/abs/2506.21506v2",
          "size": "8157kb",
          "version": "v2"
        }
      ],
      "title": "Mind2Web 2: Evaluating Agentic Search with Agent-as-a-Judge",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21506",
        "PDF": "https://arxiv.org/pdf/2506.21506"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces an evaluation benchmark for agentic search systems without addressing any LLM training data processing aspects."
      },
      "datasets": [
        {
          "dataset_name": "osunlp/Mind2Web-2",
          "downloads": "0",
          "likes": "11",
          "link": "https://huggingface.co/datasets/osunlp/Mind2Web-2"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.21551",
      "abstract": "Grokking, i.e., test performance keeps improving long after training loss converged, has been recently witnessed in neural network training, making the mechanism of generalization and other emerging capabilities such as reasoning mysterious. While prior studies usually train small models on a few toy or highly-specific tasks for thousands of epochs, we conduct the first study of grokking on checkpoints during one-pass pretraining of a 7B large language model (LLM), i.e., OLMoE. We compute the training loss and evaluate generalization on diverse benchmark tasks, including math reasoning, code generation, and commonsense/domain-specific knowledge retrieval tasks.\n  Our study, for the first time, verifies that grokking still happens in the pretraining of large-scale foundation models, though different data may enter grokking stages asynchronously. We further demystify grokking's \"emergence of generalization\" by investigating LLM internal dynamics. Specifically, we find that training samples' pathways (i.e., expert choices across layers) evolve from random, instance-specific to more structured and shareable between samples. Also, the complexity of a sample's pathway reduces despite the converged loss. These indicate a memorization-to-generalization \"knowledge digestion\", providing a mechanistic explanation of delayed generalization. In the study, we develop two novel metrics to quantify pathway distance and the complexity of a single pathway. We show their ability to predict the generalization improvement on diverse downstream tasks. They are efficient, simple to compute and solely dependent on training data. Hence, they have practical value for pretraining, enabling us to monitor the generalization performance without finetuning and test. Theoretically, we show that more structured pathways reduce model complexity and improve the generalization bound.",
      "authors": [
        "Ziyue Li",
        "Chenrui Fan",
        "Tianyi Zhou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T17:59:58+00:00",
          "link": "https://arxiv.org/abs/2506.21551v1",
          "size": "252kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T01:00:21+00:00",
          "link": "https://arxiv.org/abs/2506.21551v2",
          "size": "252kb",
          "version": "v2"
        }
      ],
      "title": "Where to find Grokking in LLM Pretraining? Monitor Memorization-to-Generalization without Test",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21551",
        "HTML": "https://arxiv.org/html/2506.21551v2",
        "PDF": "https://arxiv.org/pdf/2506.21551"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "Though it studies pretraining dynamics of an LLM, it mainly focuses on monitoring generalization performance over time, rather than on data engineering or processing methods for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21714",
      "abstract": "Recently, continuous normalizing flows (CNFs) and diffusion models (DMs) have been studied using the unified theoretical framework. Although such models can generate high-quality data points from a noise distribution, the sampling demands multiple iterations to solve an ordinary differential equation (ODE) with high computational complexity. Most existing methods focus on reducing the number of time steps during the sampling process to improve efficiency. In this work, we explore a complementary direction in which the quality-complexity tradeoff can be dynamically controlled in terms of time steps and in the length of the neural network. We achieve this by rewiring the blocks in the transformer-based architecture to solve an inner discretized ODE w.r.t. its length. Then, we employ time- and length-wise consistency terms during flow matching training, and as a result, the sampling can be performed with an arbitrary number of time steps and transformer blocks. Unlike others, our ODE$_t$(ODE$_l$) approach is solver-agnostic in time dimension and decreases both latency and memory usage. Compared to the previous state of the art, image generation experiments on CelebA-HQ and ImageNet show a latency reduction of up to 3$\\times$ in the most efficient sampling mode, and a FID score improvement of up to 3.5 points for high-quality sampling. We release our code and model weights with fully reproducible experiments.",
      "authors": [
        "Denis Gudovskiy",
        "Wenzhao Zheng",
        "Tomoyuki Okuno",
        "Yohei Nakata",
        "Kurt Keutzer"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T18:59:59+00:00",
          "link": "https://arxiv.org/abs/2506.21714v1",
          "size": "12892kb",
          "version": "v1"
        },
        {
          "date": "2025-07-02T20:53:10+00:00",
          "link": "https://arxiv.org/abs/2506.21714v2",
          "size": "12892kb",
          "version": "v2"
        }
      ],
      "title": "ODE$_t$(ODE$_l$): Shortcutting the Time and Length in Diffusion and Flow Models for Faster Sampling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21714",
        "HTML": "https://arxiv.org/html/2506.21714v2",
        "PDF": "https://arxiv.org/pdf/2506.21714"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses techniques for faster image generation in diffusion models, which does not involve LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22015",
      "abstract": "The rapid growth in complexity and size of modern deep neural networks (DNNs) has increased challenges related to computational costs and memory usage, spurring a growing interest in efficient model compression techniques. Previous state-of-the-art approach proposes using a Torque-inspired regularization which forces the weights of neural modules around a selected pivot point. Whereas, we observe that the pruning effect of this approach is far from perfect, as the post-trained network is still dense and also suffers from high accuracy drop. In this work, we attribute such ineffectiveness to the default linear force application scheme, which imposes inappropriate force on neural module of different distances. To efficiently prune the redundant and distant modules while retaining those that are close and necessary for effective inference, in this work, we propose Exponential Torque Pruning (ETP), which adopts an exponential force application scheme for regularization. Experimental results on a broad range of domains demonstrate that, though being extremely simple, ETP manages to achieve significantly higher compression rate than the previous state-of-the-art pruning strategies with negligible accuracy drop.",
      "authors": [
        "Sarthak Ketanbhai Modi",
        "Zi Pong Lim",
        "Shourya Kuchhal",
        "Yushi Cao",
        "Yupeng Cheng",
        "Yon Shin Teo",
        "Shang-Wei Lin",
        "Zhiming Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T08:28:21+00:00",
          "link": "https://arxiv.org/abs/2506.22015v1",
          "size": "1740kb",
          "version": "v1"
        },
        {
          "date": "2025-07-02T03:00:54+00:00",
          "link": "https://arxiv.org/abs/2506.22015v2",
          "size": "1732kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T07:20:35+00:00",
          "link": "https://arxiv.org/abs/2506.22015v3",
          "size": "1703kb",
          "version": "v3"
        }
      ],
      "title": "Towards Universal & Efficient Model Compression via Exponential Torque Pruning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22015",
        "HTML": "https://arxiv.org/html/2506.22015v3",
        "PDF": "https://arxiv.org/pdf/2506.22015"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on model compression techniques for neural networks, specifically Exponential Torque Pruning (ETP), which is unrelated to the data processing aspects of LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22049",
      "abstract": "Modern Large Language Models, such as the LLaMA, Qwen and DeepSeek series, predominantly adopt the Pre-LayerNorm (Pre-LN) Transformer architecture. While being stable during pretraining and scalable to large model sizes, Pre-LN suffers from an exponential growth in activation variance across layers, causing the shortcut to dominate over sub-layer outputs in the residual connection and limiting the learning capacity of deeper layers. To mitigate this issue, we propose Gradient-Preserving Activation Scaling (GPAS), a simple technique that can be used in combination with existing approaches. GPAS works by scaling down the intermediate activations while keeping their gradients unchanged. This leaves information in the activations intact, and avoids the gradient vanishing problem associated with gradient downscaling. Extensive experiments across various model sizes from 71M to 1B show that GPAS achieves consistent performance gains. Beyond enhancing Pre-LN Transformers, GPAS also shows promise in improving alternative architectures such as Sandwich-LN and DeepNorm, demonstrating its versatility and potential for improving training dynamics in a wide range of settings. Our code is available at https://github.com/dandingsky/GPAS.",
      "authors": [
        "Tianhao Chen",
        "Xin Xu",
        "Zijing Liu",
        "Pengxiang Li",
        "Xinyuan Song",
        "Ajay Kumar Jaiswal",
        "Fan Zhang",
        "Jishan Hu",
        "Yang Wang",
        "Hao Chen",
        "Shizhe Diao",
        "Shiwei Liu",
        "Yu Li",
        "Lu Yin",
        "Can Yang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T09:45:15+00:00",
          "link": "https://arxiv.org/abs/2506.22049v1",
          "size": "949kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T16:54:09+00:00",
          "link": "https://arxiv.org/abs/2506.22049v2",
          "size": "943kb",
          "version": "v2"
        }
      ],
      "title": "GPAS: Accelerating Convergence of LLM Pretraining via Gradient-Preserving Activation Scaling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22049",
        "HTML": "https://arxiv.org/html/2506.22049v2",
        "PDF": "https://arxiv.org/pdf/2506.22049"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses Gradient-Preserving Activation Scaling (GPAS) to improve training dynamics of transformers, focusing on architecture and learning dynamics rather than data processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22355",
      "abstract": "This paper describes our research on AI agents embodied in visual, virtual or physical forms, enabling them to interact with both users and their environments. These agents, which include virtual avatars, wearable devices, and robots, are designed to perceive, learn and act within their surroundings, which makes them more similar to how humans learn and interact with the environments as compared to disembodied agents. We propose that the development of world models is central to reasoning and planning of embodied AI agents, allowing these agents to understand and predict their environment, to understand user intentions and social contexts, thereby enhancing their ability to perform complex tasks autonomously. World modeling encompasses the integration of multimodal perception, planning through reasoning for action and control, and memory to create a comprehensive understanding of the physical world. Beyond the physical world, we also propose to learn the mental world model of users to enable better human-agent collaboration.",
      "authors": [
        "Pascale Fung",
        "Yoram Bachrach",
        "Asli Celikyilmaz",
        "Kamalika Chaudhuri",
        "Delong Chen",
        "Willy Chung",
        "Emmanuel Dupoux",
        "Hongyu Gong",
        "Herv\\'e J\\'egou",
        "Alessandro Lazaric",
        "Arjun Majumdar",
        "Andrea Madotto",
        "Franziska Meier",
        "Florian Metze",
        "Louis-Philippe Morency",
        "Th\\'eo Moutakanni",
        "Juan Pino",
        "Basile Terver",
        "Joseph Tighe",
        "Paden Tomasello",
        "Jitendra Malik"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T16:05:34+00:00",
          "link": "https://arxiv.org/abs/2506.22355v1",
          "size": "13238kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T11:47:50+00:00",
          "link": "https://arxiv.org/abs/2506.22355v2",
          "size": "22364kb",
          "version": "v2"
        }
      ],
      "title": "Embodied AI Agents: Modeling the World",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22355",
        "HTML": "https://arxiv.org/html/2506.22355v2",
        "PDF": "https://arxiv.org/pdf/2506.22355"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with embodied AI and world modeling, which involves reasoning and interaction in environments, not related to LLM training data processing or engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22523",
      "abstract": "Background: Generative artificial intelligence (AI) deployment in academic medical settings raises copyright compliance concerns. Dana-Farber Cancer Institute implemented GPT4DFCI, an internal generative AI tool utilizing OpenAI models, that is approved for enterprise use in research and operations. Given (1) the exceptionally broad adoption of the tool in our organization, (2) our research mission, and (3) the shared responsibility model required to benefit from Customer Copyright Commitment in Azure OpenAI Service products, we deemed rigorous copyright compliance testing necessary.\n  Case Description: We conducted a structured red teaming exercise in Nov. 2024, with 42 participants from academic, industry, and government institutions. Four teams attempted to extract copyrighted content from GPT4DFCI across four domains: literary works, news articles, scientific publications, and access-restricted clinical notes. Teams successfully extracted verbatim book dedications and near-exact passages through various strategies. News article extraction failed despite jailbreak attempts. Scientific article reproduction yielded only high-level summaries. Clinical note testing revealed appropriate privacy safeguards.\n  Discussion: The successful extraction of literary content indicates potential copyrighted material presence in training data, necessitating inference-time filtering. Differential success rates across content types suggest varying protective mechanisms. The event led to implementation of a copyright-specific meta-prompt in GPT4DFCI; this mitigation has been in production since Jan. 2025.\n  Conclusion: Systematic red teaming revealed specific vulnerabilities in generative AI copyright compliance, leading to concrete mitigation strategies. Academic medical institutions deploying generative AI should implement continuous testing protocols to ensure legal and ethical compliance.",
      "authors": [
        "James Wen",
        "Sahil Nalawade",
        "Zhiwei Liang",
        "Catherine Bielick",
        "Marisa Ferrara Boston",
        "Alexander Chowdhury",
        "Adele Collin",
        "Luigi De Angelis",
        "Jacob Ellen",
        "Heather Frase",
        "Rodrigo R. Gameiro",
        "Juan Manuel Gutierrez",
        "Pooja Kadam",
        "Murat Keceli",
        "Srikanth Krishnamurthy",
        "Anne Kwok",
        "Yanan Lance Lu",
        "Heather Mattie",
        "Liam G. McCoy",
        "Katherine Miller",
        "Allison C. Morgan",
        "Marlene Louisa Moerig",
        "Trang Nguyen",
        "Alexander Owen-Post",
        "Alex D. Ruiz",
        "Sreekar Reddy Puchala",
        "Soujanya Samineni",
        "Takeshi Tohyama",
        "Varun Ullanat",
        "Carmine Valenza",
        "Camilo Velez",
        "Pengcheng Wang",
        "Anna Wuest",
        "Yuxiang Zhou",
        "Yingde Zhu",
        "Jason M. Johnson",
        "Naomi Lenane",
        "Jennifer Willcox",
        "Francis J. Vitiello",
        "Leo Anthony G. Celi",
        "Renato Umeton"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T23:11:49+00:00",
          "link": "https://arxiv.org/abs/2506.22523v1",
          "size": "159kb",
          "version": "v1"
        },
        {
          "date": "2025-07-01T03:17:10+00:00",
          "link": "https://arxiv.org/abs/2506.22523v2",
          "size": "195kb",
          "version": "v2"
        },
        {
          "date": "2025-07-02T21:04:41+00:00",
          "link": "https://arxiv.org/abs/2506.22523v3",
          "size": "289kb",
          "version": "v3"
        }
      ],
      "title": "Red Teaming for Generative AI, Report on a Copyright-Focused Exercise Completed in an Academic Medical Center",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22523",
        "PDF": "https://arxiv.org/pdf/2506.22523"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper mentions concerns about the presence of copyrighted material in LLM training data and suggests the need for inference-time filtering to ensure compliance, but does not contribute to fundamental data processing methods for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22619",
      "abstract": "Given an undirected weighted graph $G$ and an integer $k$, Exact-Weight Perfect Matching (EWPM) is the problem of finding a perfect matching of weight exactly $k$ in $G$. In this paper, we study EWPM and its variants. The EWPM problem is famous, since in the case of unary encoded weights, Mulmuley, Vazirani, and Vazirani showed almost 40 years ago that the problem can be solved in randomized polynomial time. However, up to this date no derandomization is known.\n  Our first result is a simple deterministic algorithm for EWPM that runs in time $n^{O(\\ell)}$, where $\\ell$ is the number of distinct weights that perfect matchings in $G$ can take. In fact, we show how to find an $\\ell$-th smallest perfect matching in any weighted graph (even if the weights are encoded in binary, in which case EWPM in general is known to be NP-complete) in time $n^{O(\\ell)}$ for any integer $\\ell$. Similar next-to-optimal variants have also been studied recently for the shortest path problem.\n  For our second result, we extend the list of problems that are known to be equivalent to EWPM. We show that EWPM is equivalent under a weight-preserving reduction to the Exact Cycle Sum problem (ECS) in undirected graphs with a conservative (i.e. no negative cycles) weight function. To the best of our knowledge, we are the first to study this problem. As a consequence, the latter problem is contained in RP if the weights are encoded in unary. Finally, we identify a special case of EWPM, called BCPM, which was recently studied by El Maalouly, Steiner and Wulf. We show that BCPM is equivalent under a weight-preserving transformation to another problem recently studied by Schlotter and Seb\\H{o} as well as Geelen and Kapadia: the Shortest Odd Cycle problem (SOC) in undirected graphs with conservative weights.",
      "authors": [
        "Nicolas El Maalouly",
        "Sebastian Haslebacher",
        "Adrian Taubner",
        "Lasse Wulf"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T20:31:35+00:00",
          "link": "https://arxiv.org/abs/2506.22619v1",
          "size": "131kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T12:13:34+00:00",
          "link": "https://arxiv.org/abs/2506.22619v2",
          "size": "56kb",
          "version": "v2"
        }
      ],
      "title": "On Finding $\\ell$-th Smallest Perfect Matchings",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22619",
        "HTML": "https://arxiv.org/html/2506.22619v2",
        "PDF": "https://arxiv.org/pdf/2506.22619"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on graph theory and algorithms related to perfect matchings in weighted graphs, with no mention of LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22800",
      "abstract": "A single-pass driving clip frequently results in incomplete scanning of the road structure, making reconstructed scene expanding a critical requirement for sensor simulators to effectively regress driving actions. Although contemporary 3D Gaussian Splatting (3DGS) techniques achieve remarkable reconstruction quality, their direct extension through the integration of diffusion priors often introduces cumulative physical inconsistencies and compromises training efficiency. To address these limitations, we present RGE-GS, a novel expansive reconstruction framework that synergizes diffusion-based generation with reward-guided Gaussian integration. The RGE-GS framework incorporates two key innovations: First, we propose a reward network that learns to identify and prioritize consistently generated patterns prior to reconstruction phases, thereby enabling selective retention of diffusion outputs for spatial stability. Second, during the reconstruction process, we devise a differentiated training strategy that automatically adjust Gaussian optimization progress according to scene converge metrics, which achieving better convergence than baseline methods. Extensive evaluations of publicly available datasets demonstrate that RGE-GS achieves state-of-the-art performance in reconstruction quality. Our source-code will be made publicly available at https://github.com/CN-ADLab/RGE-GS.",
      "authors": [
        "Sicong Du",
        "Jiarun Liu",
        "Qifeng Chen",
        "Hao-Xiang Chen",
        "Tai-Jiang Mu",
        "Sheng Yang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T08:02:54+00:00",
          "link": "https://arxiv.org/abs/2506.22800v1",
          "size": "3895kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T12:07:19+00:00",
          "link": "https://arxiv.org/abs/2506.22800v2",
          "size": "5544kb",
          "version": "v2"
        }
      ],
      "title": "RGE-GS: Reward-Guided Expansive Driving Scene Reconstruction via Diffusion Priors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22800",
        "HTML": "https://arxiv.org/html/2506.22800v2",
        "PDF": "https://arxiv.org/pdf/2506.22800"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on scene reconstruction in driving simulations using diffusion models, which does not pertain to any aspect of LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22821",
      "abstract": "We present a novel and detailed dataset on origin-destination annual migration flows and stocks between 230 countries and regions, spanning the period from 1990 to the present. Our flow estimates are further disaggregated by country of birth, providing a comprehensive picture of migration over the last 35 years. The estimates are obtained by training a deep recurrent neural network to learn flow patterns from 18 covariates for all countries, including geographic, economic, cultural, societal, and political information. The recurrent architecture of the neural network means that the entire past can influence current migration patterns, allowing us to learn long-range temporal correlations. By training an ensemble of neural networks and additionally pushing uncertainty on the covariates through the trained network, we obtain confidence bounds for all our estimates, allowing researchers to pinpoint the geographic regions most in need of additional data collection. We validate our approach on various test sets of unseen data, demonstrating that it significantly outperforms traditional methods estimating five-year flows while delivering a significant increase in temporal resolution. The model is fully open source: all training data, neural network weights, and training code are made public alongside the migration estimates, providing a valuable resource for future studies of human migration.",
      "authors": [
        "Thomas Gaskin and Guy J. Abel"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T09:05:34+00:00",
          "link": "https://arxiv.org/abs/2506.22821v1",
          "size": "11522kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T10:46:56+00:00",
          "link": "https://arxiv.org/abs/2506.22821v2",
          "size": "11522kb",
          "version": "v2"
        }
      ],
      "title": "Deep learning four decades of human migration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22821",
        "HTML": "https://arxiv.org/html/2506.22821v2",
        "PDF": "https://arxiv.org/pdf/2506.22821"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While this paper involves training a neural network on a dataset and mentions the creation of a novel dataset on migration, it does not specifically address LLM training data processing or propose new methods for such data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22918",
      "abstract": "We develop a framework for the compression of reversible Markov chains with rigorous error control. Given a subset of selected states, we construct reduced dynamics that can be lifted to an approximation of the full dynamics, and we prove simple spectral and nuclear norm bounds on the recovery error in terms of a suitably interpreted Nystr\\\"{o}m approximation error. We introduce two compression schemes: a projective compression based on committor functions and a structure-preserving compression defined in terms of an induced Markov chain over the selected states. The Nystr\\\"{o}m error appearing in our bounds can be controlled using recent results on column subset selection by nuclear maximization. Numerical experiments validate our theory and demonstrate the scalability of our approach.",
      "authors": [
        "Mark Fornace and Michael Lindsey"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Probability (math.PR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T15:02:48+00:00",
          "link": "https://arxiv.org/abs/2506.22918v1",
          "size": "861kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T06:51:49+00:00",
          "link": "https://arxiv.org/abs/2506.22918v2",
          "size": "854kb",
          "version": "v2"
        }
      ],
      "title": "An approximation theory for Markov chain compression",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22918",
        "HTML": "https://arxiv.org/html/2506.22918v2",
        "PDF": "https://arxiv.org/pdf/2506.22918"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research explores compression of Markov chains, focusing on theoretical foundations and error bounds for dynamic approximation, which is unrelated to processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23351",
      "abstract": "Embodied Artificial Intelligence (Embodied AI) is an emerging frontier in robotics, driven by the need for autonomous systems that can perceive, reason, and act in complex physical environments. While single-arm systems have shown strong task performance, collaborative dual-arm systems are essential for handling more intricate tasks involving rigid, deformable, and tactile-sensitive objects. To advance this goal, we launched the RoboTwin Dual-Arm Collaboration Challenge at the 2nd MEIS Workshop, CVPR 2025. Built on the RoboTwin Simulation platform (1.0 and 2.0) and the AgileX COBOT-Magic Robot platform, the competition consisted of three stages: Simulation Round 1, Simulation Round 2, and a final Real-World Round. Participants totally tackled 17 dual-arm manipulation tasks, covering rigid, deformable, and tactile-based scenarios. The challenge attracted 64 global teams and over 400 participants, producing top-performing solutions like SEM and AnchorDP3 and generating valuable insights into generalizable bimanual policy learning. This report outlines the competition setup, task design, evaluation methodology, key findings and future direction, aiming to support future research on robust and generalizable bimanual manipulation policies. The Challenge Webpage is available at https://robotwin-benchmark.github.io/cvpr-2025-challenge/.",
      "authors": [
        "Tianxing Chen",
        "Kaixuan Wang",
        "Zhaohui Yang",
        "Yuhao Zhang",
        "Zanxin Chen",
        "Baijun Chen",
        "Wanxi Dong",
        "Ziyuan Liu",
        "Dong Chen",
        "Tianshuo Yang",
        "Haibao Yu",
        "Xiaokang Yang",
        "Yusen Qin",
        "Zhiqiang Xie",
        "Yao Mu",
        "Ping Luo",
        "Tian Nian",
        "Weiliang Deng",
        "Yiheng Ge",
        "Yibin Liu",
        "Zixuan Li",
        "Dehui Wang",
        "Zhixuan Liang",
        "Haohui Xie",
        "Rijie Zeng",
        "Yunfei Ge",
        "Peiqing Cong",
        "Guannan He",
        "Zhaoming Han",
        "Ruocheng Yin",
        "Jingxiang Guo",
        "Lunkai Lin",
        "Tianling Xu",
        "Hongzhe Bi",
        "Xuewu Lin",
        "Tianwei Lin",
        "Shujie Luo",
        "Keyu Li",
        "Ziyan Zhao",
        "Ke Fan",
        "Heyang Xu",
        "Bo Peng",
        "Wenlong Gao",
        "Dongjiang Li",
        "Feng Jin",
        "Hui Shen",
        "Jinming Li",
        "Chaowei Cui",
        "Yu Chen",
        "Yaxin Peng",
        "Lingdong Zeng",
        "Wenlong Dong",
        "Tengfei Li",
        "Weijie Ke",
        "Jun Chen",
        "Erdemt Bao",
        "Tian Lan",
        "Tenglong Liu",
        "Jin Yang",
        "Huiping Zhuang",
        "Baozhi Jia",
        "Shuai Zhang",
        "Zhengfeng Zou",
        "Fangheng Guan",
        "Tianyi Jia",
        "Ke Zhou",
        "Hongjiu Zhang",
        "Yating Han",
        "Cheng Fang",
        "Yixian Zou",
        "Chongyang Xu",
        "Qinglun Zhang",
        "Shen Cheng",
        "Xiaohe Wang",
        "Ping Tan",
        "Haoqiang Fan",
        "Shuaicheng Liu",
        "Jiaheng Chen",
        "Chuxuan Huang",
        "Chengliang Lin",
        "Kaijun Luo",
        "Boyu Yue",
        "Yi Liu",
        "Jinyu Chen",
        "Zichang Tan",
        "Liming Deng",
        "Shuo Xu",
        "Zijian Cai",
        "Shilong Yin",
        "Hao Wang",
        "Hongshan Liu",
        "Tianyang Li",
        "Long Shi",
        "Ran Xu",
        "Huilin Xu",
        "Zhengquan Zhang",
        "Congsheng Xu",
        "Jinchang Yang",
        "and Feng Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T17:56:41+00:00",
          "link": "https://arxiv.org/abs/2506.23351v1",
          "size": "5055kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T03:30:42+00:00",
          "link": "https://arxiv.org/abs/2506.23351v2",
          "size": "4459kb",
          "version": "v2"
        }
      ],
      "title": "Benchmarking Generalizable Bimanual Manipulation: RoboTwin Dual-Arm Collaboration Challenge at CVPR 2025 MEIS Workshop",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23351",
        "HTML": "https://arxiv.org/html/2506.23351v2",
        "PDF": "https://arxiv.org/pdf/2506.23351"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on the RoboTwin Dual-Arm Collaboration Challenge, which is centered around robotics and bimanual manipulation, rather than on the processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23661",
      "abstract": "We extend BeamAttack, an adversarial attack algorithm designed to evaluate the robustness of text classification systems through word-level modifications guided by beam search. Our extensions include support for word deletions and the option to skip substitutions, enabling the discovery of minimal modifications that alter model predictions. We also integrate LIME to better prioritize word replacements. Evaluated across multiple datasets and victim models (BiLSTM, BERT, and adversarially trained RoBERTa) within the BODEGA framework, our approach achieves over a 99\\% attack success rate while preserving the semantic and lexical similarity of the original texts. Through both quantitative and qualitative analysis, we highlight BeamAttack's effectiveness and its limitations. Our implementation is available at https://github.com/LucK1Y/BeamAttack",
      "authors": [
        "Arnisa Fazla",
        "Lucas Krauter",
        "David Guzman Piedrahita",
        "Andrianos Michail"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T09:37:19+00:00",
          "link": "https://arxiv.org/abs/2506.23661v1",
          "size": "1456kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T09:46:05+00:00",
          "link": "https://arxiv.org/abs/2506.23661v2",
          "size": "1456kb",
          "version": "v2"
        }
      ],
      "title": "Robustness of Misinformation Classification Systems to Adversarial Examples Through BeamAttack",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23661",
        "HTML": "https://arxiv.org/html/2506.23661v2",
        "PDF": "https://arxiv.org/pdf/2506.23661"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper extends BeamAttack for adversarial attacks on text classification systems, unrelated to the processing of LLM training data for tasks like data collection or filtering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23799",
      "abstract": "Training data increasingly shapes not only model accuracy but also regulatory compliance and market valuation of AI assets. Yet existing valuation methods remain inadequate: model-based techniques depend on a single fitted model and inherit its biases, while algorithm-based approaches such as Data Shapley require costly retrainings at web scale. Recent Wasserstein-based model-agnostic methods rely on approximations that misrank examples relative to their true leave-one-out (LOO) utility. We introduce KAIROS, a scalable, model-agnostic valuation framework that assigns each example a distributional influence score: its contribution to the Maximum Mean Discrepancy (MMD) between the empirical training distribution and a clean reference set. Unlike Wasserstein surrogates, our MMD-based influence admits a closed-form solution that faithfully approximates the exact LOO ranking within $O(1/N^2)$ error, requires no retraining, and naturally extends to conditional kernels for unified label- and feature-error detection. Moreover, KAIROS supports efficient online updates: when a new batch of size m arrives, all scores can be updated in $O(mN)$ time, delivering up to 50x speedup without compromising ranking quality. Empirical evaluations on noise, mislabeling, and poisoning benchmarks show that KAIROS consistently outperforms state-of-the-art model-, Shapley-, and Wasserstein-based baselines in both accuracy and runtime. We provide rigorous theoretical guarantees, including symmetry for reproducible rankings and density-separation for interpretable thresholds.",
      "authors": [
        "Jiongli Zhu",
        "Parjanya Prajakta Prashant",
        "Alex Cloninger",
        "Babak Salimi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T12:44:28+00:00",
          "link": "https://arxiv.org/abs/2506.23799v1",
          "size": "317kb",
          "version": "v1"
        },
        {
          "date": "2025-07-02T22:50:21+00:00",
          "link": "https://arxiv.org/abs/2506.23799v2",
          "size": "320kb",
          "version": "v2"
        }
      ],
      "title": "KAIROS: Scalable Model-Agnostic Data Valuation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23799",
        "HTML": "https://arxiv.org/html/2506.23799v2",
        "PDF": "https://arxiv.org/pdf/2506.23799"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "KAIROS presents a model-agnostic valuation framework that directly relates to improving data quality by assigning influence scores to training examples, making it highly relevant to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23852",
      "abstract": "As camera-equipped robotic platforms become increasingly integrated into daily life, robotic-generated videos have begun to appear on streaming media platforms, enabling us to envision a future where humans and robots coexist. We innovatively propose the concept of Robotic-Generated Content (RGC) to term these videos generated from egocentric perspective of robots. The perceptual quality of RGC videos is critical in human-robot interaction scenarios, and RGC videos exhibit unique distortions and visual requirements that differ markedly from those of professionally-generated content (PGC) videos and user-generated content (UGC) videos. However, dedicated research on quality assessment of RGC videos is still lacking. To address this gap and to support broader robotic applications, we establish the first Robotic-Generated Content Database (RGCD), which contains a total of 2,100 videos drawn from three robot categories and sourced from diverse platforms. A subjective VQA experiment is conducted subsequently to assess human visual perception of robotic-generated videos. Finally, we conduct a benchmark experiment to evaluate the performance of 11 state-of-the-art VQA models on our database. Experimental results reveal significant limitations in existing VQA models when applied to complex, robotic-generated content, highlighting a critical need for RGC-specific VQA models. Our RGCD is publicly available at: https://github.com/IntMeGroup/RGC-VQA.",
      "authors": [
        "Jianing Jin",
        "Jiangyong Ying",
        "Huiyu Duan",
        "Liu Yang",
        "Sijing Wu",
        "Yunhao Li",
        "Yushuo Zheng",
        "Xiongkuo Min",
        "Guangtao Zhai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T13:44:30+00:00",
          "link": "https://arxiv.org/abs/2506.23852v1",
          "size": "1075kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T07:51:05+00:00",
          "link": "https://arxiv.org/abs/2506.23852v2",
          "size": "1075kb",
          "version": "v2"
        }
      ],
      "title": "RGC-VQA: An Exploration Database for Robotic-Generated Video Quality Assessment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23852",
        "HTML": "https://arxiv.org/html/2506.23852v2",
        "PDF": "https://arxiv.org/pdf/2506.23852"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses video quality assessment for robotic-generated content, which does not pertain to LLM training data processing or engineering stages."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23897",
      "abstract": "Panoramic optical flow enables a comprehensive understanding of temporal dynamics across wide fields of view. However, severe distortions caused by sphere-to-plane projections, such as the equirectangular projection (ERP), significantly degrade the performance of conventional perspective-based optical flow methods, especially in polar regions. To address this challenge, we propose PriOr-Flow, a novel dual-branch framework that leverages the low-distortion nature of the orthogonal view to enhance optical flow estimation in these regions. Specifically, we introduce the Dual-Cost Collaborative Lookup (DCCL) operator, which jointly retrieves correlation information from both the primitive and orthogonal cost volumes, effectively mitigating distortion noise during cost volume construction. Furthermore, our Ortho-Driven Distortion Compensation (ODDC) module iteratively refines motion features from both branches, further suppressing polar distortions. Extensive experiments demonstrate that PriOr-Flow is compatible with various perspective-based iterative optical flow methods and consistently achieves state-of-the-art performance on publicly available panoramic optical flow datasets, setting a new benchmark for wide-field motion estimation. The code is publicly available at: https://github.com/longliangLiu/PriOr-Flow.",
      "authors": [
        "Longliang Liu",
        "Miaojie Feng",
        "Junda Cheng",
        "Jijun Xiang",
        "Xuan Zhu",
        "Xin Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T14:30:25+00:00",
          "link": "https://arxiv.org/abs/2506.23897v1",
          "size": "1535kb",
          "version": "v1"
        },
        {
          "date": "2025-07-01T02:59:12+00:00",
          "link": "https://arxiv.org/abs/2506.23897v2",
          "size": "1535kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T12:44:27+00:00",
          "link": "https://arxiv.org/abs/2506.23897v3",
          "size": "1487kb",
          "version": "v3"
        }
      ],
      "title": "PriOr-Flow: Enhancing Primitive Panoramic Optical Flow with Orthogonal View",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23897",
        "HTML": "https://arxiv.org/html/2506.23897v3",
        "PDF": "https://arxiv.org/pdf/2506.23897"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on panoramic optical flow and enhancing the accuracy of wide-field motion estimation. It does not address LLM training data processing or data engineering stages relevant to language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23918",
      "abstract": "Recent progress in multimodal reasoning has been significantly advanced by textual Chain-of-Thought (CoT), a paradigm where models conduct reasoning within language. This text-centric approach, however, treats vision as a static, initial context, creating a fundamental \"semantic gap\" between rich perceptual data and discrete symbolic thought. Human cognition often transcends language, utilizing vision as a dynamic mental sketchpad. A similar evolution is now unfolding in AI, marking a fundamental paradigm shift from models that merely think about images to those that can truly think with images. This emerging paradigm is characterized by models leveraging visual information as intermediate steps in their thought process, transforming vision from a passive input into a dynamic, manipulable cognitive workspace. In this survey, we chart this evolution of intelligence along a trajectory of increasing cognitive autonomy, which unfolds across three key stages: from external tool exploration, through programmatic manipulation, to intrinsic imagination. To structure this rapidly evolving field, our survey makes four key contributions. (1) We establish the foundational principles of the think with image paradigm and its three-stage framework. (2) We provide a comprehensive review of the core methods that characterize each stage of this roadmap. (3) We analyze the critical landscape of evaluation benchmarks and transformative applications. (4) We identify significant challenges and outline promising future directions. By providing this structured overview, we aim to offer a clear roadmap for future research towards more powerful and human-aligned multimodal AI.",
      "authors": [
        "Zhaochen Su",
        "Peng Xia",
        "Hangyu Guo",
        "Zhenhua Liu",
        "Yan Ma",
        "Xiaoye Qu",
        "Jiaqi Liu",
        "Yanshu Li",
        "Kaide Zeng",
        "Zhengyuan Yang",
        "Linjie Li",
        "Yu Cheng",
        "Heng Ji",
        "Junxian He",
        "Yi R. Fung"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T14:48:35+00:00",
          "link": "https://arxiv.org/abs/2506.23918v1",
          "size": "14543kb",
          "version": "v1"
        },
        {
          "date": "2025-07-01T03:46:27+00:00",
          "link": "https://arxiv.org/abs/2506.23918v2",
          "size": "14543kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T16:49:39+00:00",
          "link": "https://arxiv.org/abs/2506.23918v3",
          "size": "14537kb",
          "version": "v3"
        }
      ],
      "title": "Thinking with Images for Multimodal Reasoning: Foundations, Methods, and Future Frontiers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23918",
        "HTML": "https://arxiv.org/html/2506.23918v3",
        "PDF": "https://arxiv.org/pdf/2506.23918"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This survey paper discusses the evolution and future of multimodal reasoning with images and text, but does not focus on training data processing or data engineering related to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.00337",
      "abstract": "Delay-based protocols rely on end-to-end delay measurements to detect network congestion. However, in cellular networks, Radio Access Network (RAN) buffers introduce significant delays unrelated to congestion, fundamentally challenging these protocols' assumptions. We identify two major types of RAN buffers - retransmission buffers and uplink scheduling buffers - that can introduce delays comparable to congestion-induced delays, severely degrading protocol performance. We present CellNinjia, a software-based system providing real-time visibility into RAN operations, and Gandalf, which leverages this visibility to systematically handle RAN-induced delays. Unlike existing approaches that treat these delays as random noise, Gandalf identifies specific RAN operations and compensates for their effects. Our evaluation in commercial 4G LTE and 5G networks shows that Gandalf enables substantial performance improvements - up to 7.49x for Copa and 9.53x for PCC Vivace - without modifying the protocols' core algorithms, demonstrating that delay-based protocols can realize their full potential in cellular networks.",
      "authors": [
        "Yuxin Liu",
        "Tianyang Zhang",
        "Kyle Jamieson",
        "Yaxiong Xie"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T00:28:05+00:00",
          "link": "https://arxiv.org/abs/2507.00337v1",
          "size": "3496kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T03:05:03+00:00",
          "link": "https://arxiv.org/abs/2507.00337v2",
          "size": "3496kb",
          "version": "v2"
        }
      ],
      "title": "Seeing Through the Fog: Empowering Mobile Devices to Expose and Mitigate RAN Buffer Effects on Delay-Sensitive Protocols",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.00337",
        "HTML": "https://arxiv.org/html/2507.00337v2",
        "PDF": "https://arxiv.org/pdf/2507.00337"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with mitigating RAN buffer effects in mobile networks to improve protocol performance. It is unrelated to LLM training data processing or data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.00373",
      "abstract": "Region of Interest (ROI)-based image compression optimizes bit allocation by prioritizing ROI for higher-quality reconstruction. However, as the users (including human clients and downstream machine tasks) become more diverse, ROI-based image compression needs to be customizable to support various preferences. For example, different users may define distinct ROI or require different quality trade-offs between ROI and non-ROI. Existing ROI-based image compression schemes predefine the ROI, making it unchangeable, and lack effective mechanisms to balance reconstruction quality between ROI and non-ROI. This work proposes a paradigm for customizable ROI-based deep image compression. First, we develop a Text-controlled Mask Acquisition (TMA) module, which allows users to easily customize their ROI for compression by just inputting the corresponding semantic \\emph{text}. It makes the encoder controlled by text. Second, we design a Customizable Value Assign (CVA) mechanism, which masks the non-ROI with a changeable extent decided by users instead of a constant one to manage the reconstruction quality trade-off between ROI and non-ROI. Finally, we present a Latent Mask Attention (LMA) module, where the latent spatial prior of the mask and the latent Rate-Distortion Optimization (RDO) prior of the image are extracted and fused in the latent space, and further used to optimize the latent representation of the source image. Experimental results demonstrate that our proposed customizable ROI-based deep image compression paradigm effectively addresses the needs of customization for ROI definition and mask acquisition as well as the reconstruction quality trade-off management between the ROI and non-ROI.",
      "authors": [
        "Jian Jin",
        "Fanxin Xia",
        "Feng Ding",
        "Xinfeng Zhang",
        "Meiqin Liu",
        "Yao Zhao",
        "Weisi Lin",
        "Lili Meng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T02:03:09+00:00",
          "link": "https://arxiv.org/abs/2507.00373v1",
          "size": "7715kb",
          "version": "v1"
        },
        {
          "date": "2025-07-02T02:38:22+00:00",
          "link": "https://arxiv.org/abs/2507.00373v2",
          "size": "7715kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T03:31:28+00:00",
          "link": "https://arxiv.org/abs/2507.00373v3",
          "size": "7715kb",
          "version": "v3"
        }
      ],
      "title": "Customizable ROI-Based Deep Image Compression",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.00373",
        "HTML": "https://arxiv.org/html/2507.00373v3",
        "PDF": "https://arxiv.org/pdf/2507.00373"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about customizable ROI-based deep image compression, which focuses on image processing, not on LLM training data or any aspect related to language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.00505",
      "abstract": "The architecture of multimodal large language models (MLLMs) commonly connects a vision encoder, often based on CLIP-ViT, to a large language model. While CLIP-ViT works well for capturing global image features, it struggles to model local relationships between adjacent patches, leading to weaker visual representation, which in turn affects the detailed understanding ability of MLLMs. To solve this, we propose LLaVA-SP, which \\textbf{ only adds six spatial visual tokens} to the original visual tokens to enhance the visual representation. Our approach offers three key advantages: 1)We propose a novel Projector, which uses convolutional kernels to derive visual spatial tokens from ViT patch features, simulating two visual spatial ordering approaches: ``from central region to global\" and ``from abstract to specific\". Then, a cross-attention mechanism is applied to fuse fine-grained visual information, enriching the overall visual representation. 2) We present two model variants: LLaVA-SP-Cropping, which focuses on detail features through progressive cropping, and LLaVA-SP-Pooling, which captures global semantics through adaptive pooling, enabling the model to handle diverse visual understanding tasks. 3) Extensive experiments show that LLaVA-SP, fine-tuned with LoRA, achieves significant performance improvements across various multimodal benchmarks, outperforming the state-of-the-art LLaVA-1.5 model in multiple tasks with nearly identical inference latency. The code and models are available at https://github.com/CnFaker/LLaVA-SP.",
      "authors": [
        "Haoran Lou",
        "Chunxiao Fan",
        "Ziyan Liu",
        "Yuexin Wu",
        "Xinliang Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T07:20:11+00:00",
          "link": "https://arxiv.org/abs/2507.00505v1",
          "size": "2917kb",
          "version": "v1"
        },
        {
          "date": "2025-07-02T19:10:32+00:00",
          "link": "https://arxiv.org/abs/2507.00505v2",
          "size": "2917kb",
          "version": "v2"
        }
      ],
      "title": "LLaVA-SP: Enhancing Visual Representation with Visual Spatial Tokens for MLLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.00505",
        "HTML": "https://arxiv.org/html/2507.00505v2",
        "PDF": "https://arxiv.org/pdf/2507.00505"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper improves visual representation in multimodal large language models by enhancing visual tokens, but it does not address LLM training or data processing directly related to the data engineering stages for LLMs."
      },
      "models": [
        {
          "model_path": "Levideus/llava-sp-cropping-lora",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/Levideus/llava-sp-cropping-lora"
        },
        {
          "model_path": "Levideus/llava-sp-pooling-lora",
          "downloads": "7",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/Levideus/llava-sp-pooling-lora"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.00585",
      "abstract": "In recent years, it has been found that \"grandmother cells\" in the primary visual cortex (V1) of macaques can directly recognize visual input with complex shapes. This inspires us to examine the value of these cells in promoting the research of medical image segmentation. In this paper, we design a Similarity Memory Prior Network (Sim-MPNet) for medical image segmentation. Specifically, we propose a Dynamic Memory Weights-Loss Attention (DMW-LA), which matches and remembers the category features of specific lesions or organs in medical images through the similarity memory prior in the prototype memory bank, thus helping the network to learn subtle texture changes between categories. DMW-LA also dynamically updates the similarity memory prior in reverse through Weight-Loss Dynamic (W-LD) update strategy, effectively assisting the network directly extract category features. In addition, we propose the Double-Similarity Global Internal Enhancement Module (DS-GIM) to deeply explore the internal differences in the feature distribution of input data through cosine similarity and euclidean distance. Extensive experiments on four public datasets show that Sim-MPNet has better segmentation performance than other state-of-the-art methods. Our code is available on https://github.com/vpsg-research/Sim-MPNet.",
      "authors": [
        "Tang Hao",
        "Guo ZhiQing",
        "Wang LieJun",
        "Liu Chao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T09:06:40+00:00",
          "link": "https://arxiv.org/abs/2507.00585v1",
          "size": "2565kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T13:49:51+00:00",
          "link": "https://arxiv.org/abs/2507.00585v2",
          "size": "1978kb",
          "version": "v2"
        }
      ],
      "title": "Similarity Memory Prior is All You Need for Medical Image Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.00585",
        "HTML": "https://arxiv.org/html/2507.00585v2",
        "PDF": "https://arxiv.org/pdf/2507.00585"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on medical image segmentation with a method involving a memory prior network and does not discuss LLMs or any training data processing related to them."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.00606",
      "abstract": "Large language models (LLMs) excel in complex tasks through advanced prompting techniques like Chain-of-Thought (CoT) and Tree-of-Thought (ToT), but their reliance on manually crafted, task-specific prompts limits adaptability and efficiency. We introduce Mixture of Reasoning (MoR), a training framework that embeds diverse reasoning strategies into LLMs for autonomous, task-adaptive reasoning without external prompt engineering. MoR has two phases: Thought Generation, creating reasoning chain templates with models like GPT-4o, and SFT Dataset Construction, pairing templates with benchmark datasets for supervised fine-tuning. Our experiments show that MoR significantly enhances performance, with MoR150 achieving 0.730 (2.2% improvement) using CoT prompting and 0.734 (13.5% improvement) compared to baselines. MoR eliminates the need for task-specific prompts, offering a generalizable solution for robust reasoning across diverse tasks.",
      "authors": [
        "Tao Xiong",
        "Xavier Hu",
        "Wenyan Fan",
        "Shengyu Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T09:39:04+00:00",
          "link": "https://arxiv.org/abs/2507.00606v1",
          "size": "268kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T02:30:05+00:00",
          "link": "https://arxiv.org/abs/2507.00606v2",
          "size": "265kb",
          "version": "v2"
        }
      ],
      "title": "Mixture of Reasonings: Teach Large Language Models to Reason with Adaptive Strategies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.00606",
        "HTML": "https://arxiv.org/html/2507.00606v2",
        "PDF": "https://arxiv.org/pdf/2507.00606"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces a training framework (MoR) for large language models, specifically addressing the creation of reasoning chain templates and the construction of SFT datasets, which directly relates to training-stage data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.00609",
      "abstract": "We study the rank weight hierarchy of linear codes which are stable under a linear endomorphism defined over the base field, in particular when the endomorphism is cyclic. In this last case, we give a necessary and sufficient condition for such a code to have first rank weight equal to $1$ in terms of its generator polynomial, as well as an explicit formula for its last rank weight.",
      "authors": [
        "G. Berhuy",
        "J. Molina"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T09:41:29+00:00",
          "link": "https://arxiv.org/abs/2507.00609v1",
          "size": "26kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T12:08:53+00:00",
          "link": "https://arxiv.org/abs/2507.00609v2",
          "size": "26kb",
          "version": "v2"
        }
      ],
      "title": "On the rank weight hierarchy of $M$-codes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.00609",
        "HTML": "https://arxiv.org/html/2507.00609v2",
        "PDF": "https://arxiv.org/pdf/2507.00609"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the mathematical properties of linear codes, focusing on rank weight hierarchy, and does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.00631",
      "abstract": "Correctness is an emergent property of systems where exposing error is cheaper than committing it. In dynamic, low-trust environments, autonomous AI agents benefit from delegating work to sub-agents, yet correctness cannot be assured through upfront specification or centralized oversight. We propose a protocol that enforces correctness through collateralized claims in a recursive verification game. Tasks are published as intents, and solvers compete to fulfill them. Selected solvers carry out tasks under risk, with correctness checked post hoc by verifiers. Any challenger can challenge a result by staking against it to trigger the verification process. Incorrect agents are slashed and correct opposition is rewarded, with an escalation path that penalizes erroneous verifiers themselves. When incentives are aligned across solvers, challengers, and verifiers, falsification conditions make correctness the Nash equilibrium.",
      "authors": [
        "David Shi",
        "Kevin Joo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)",
        "Artificial Intelligence (cs.AI)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T10:22:35+00:00",
          "link": "https://arxiv.org/abs/2507.00631v1",
          "size": "10kb",
          "version": "v1"
        },
        {
          "date": "2025-07-02T00:53:41+00:00",
          "link": "https://arxiv.org/abs/2507.00631v2",
          "size": "10kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T01:26:57+00:00",
          "link": "https://arxiv.org/abs/2507.00631v3",
          "size": "10kb",
          "version": "v3"
        }
      ],
      "title": "Horus: A Protocol for Trustless Delegation Under Uncertainty",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.00631",
        "HTML": "https://arxiv.org/html/2507.00631v3",
        "PDF": "https://arxiv.org/pdf/2507.00631"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a protocol for correctness in systems with autonomous agents and does not pertain to processing or engineering training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.00736",
      "abstract": "Recent years have seen growing interest in Question Difficulty Estimation (QDE) using natural language processing techniques. Question difficulty is often represented using discrete levels, framing the task as ordinal regression due to the inherent ordering from easiest to hardest. However, the literature has neglected the ordinal nature of the task, relying on classification or discretized regression models, with specialized ordinal regression methods remaining unexplored. Furthermore, evaluation metrics are tightly coupled to the modeling paradigm, hindering cross-study comparability. While some metrics fail to account for the ordinal structure of difficulty levels, none adequately address class imbalance, resulting in biased performance assessments. This study addresses these limitations by benchmarking three types of model outputs -- discretized regression, classification, and ordinal regression -- using the balanced Discrete Ranked Probability Score (DRPS), a novel metric that jointly captures ordinality and class imbalance. In addition to using popular ordinal regression methods, we propose OrderedLogitNN, extending the ordered logit model from econometrics to neural networks. We fine-tune BERT on the RACE++ and ARC datasets and find that OrderedLogitNN performs considerably better on complex tasks. The balanced DRPS offers a robust and fair evaluation metric for discrete-level QDE, providing a principled foundation for future research.",
      "authors": [
        "Arthur Thuy",
        "Ekaterina Loginova",
        "Dries F. Benoit"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T13:38:33+00:00",
          "link": "https://arxiv.org/abs/2507.00736v1",
          "size": "851kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T11:23:04+00:00",
          "link": "https://arxiv.org/abs/2507.00736v2",
          "size": "891kb",
          "version": "v2"
        }
      ],
      "title": "Ordinality in Discrete-level Question Difficulty Estimation: Introducing Balanced DRPS and OrderedLogitNN",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.00736",
        "HTML": "https://arxiv.org/html/2507.00736v2",
        "PDF": "https://arxiv.org/pdf/2507.00736"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on question difficulty estimation using NLP techniques and introduces a metric and a model for ordinal regression. There is no mention of LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.00847",
      "abstract": "Bluetooth is a pervasive wireless communication technology used by billions of devices for short-range connectivity. The security of Bluetooth relies on the pairing process, where devices establish shared long-term keys for secure communications. However, many commercial Bluetooth devices implement automatic pairing functions to improve user convenience, creating a previously unexplored attack surface.\n  We present Stealtooth, a novel attack that abuses unknown vulnerabilities in the automatic pairing functions in commercial Bluetooth devices to achieve completely silent device link key overwriting. The Stealtooth attack leverages the fact that Bluetooth audio devices automatically transition to pairing mode under specific conditions, enabling attackers to hijack pairing processes without user awareness or specialized tools. We also extend the attack into the MitM Stealtooth attack, combining automatic pairing abuse with power-saving mode techniques to enable man-in-the-middle attacks.\n  We evaluate the attacks against 10 commercial Bluetooth devices from major manufacturers, demonstrating widespread vulnerabilities across diverse device types and manufacturers. Our practical implementation requires only commodity hardware and open-source software, highlighting the low barrier to entry for attackers.\n  We propose defenses both device and protocol levels, including enhanced user notifications and standardized automatic pairing guidelines. Our findings reveal a critical tension between security and usability, showing that current automatic pairing implementations create systematic vulnerabilities. We responsibly disclosed our findings to affected vendors, with several already releasing patches.",
      "authors": [
        "Keiichiro Kimura",
        "Hiroki Kuzuno",
        "Yoshiaki Shiraishi",
        "and Masakatu Morii"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T15:18:37+00:00",
          "link": "https://arxiv.org/abs/2507.00847v1",
          "size": "382kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T13:14:41+00:00",
          "link": "https://arxiv.org/abs/2507.00847v2",
          "size": "382kb",
          "version": "v2"
        }
      ],
      "title": "Stealtooth: Breaking Bluetooth Security Abusing Silent Automatic Pairing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.00847",
        "HTML": "https://arxiv.org/html/2507.00847v2",
        "PDF": "https://arxiv.org/pdf/2507.00847"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses Bluetooth security vulnerabilities and proposes an attack method, Stealtooth. It does not relate to the processing or engineering of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.00896",
      "abstract": "A new congestion and delay control algorithm named QUIC Delay Control (QUIC-DC) is proposed for controlling not only congestion but also the queueing delay encountered along the forward communication path. The core idea is to estimate the one-way queueing delay of a connection to trigger an early reaction to congestion. This idea, along with a the TCP Westwood+ congestion control algorithm, has been implemented in QUIC-DC and compared with QUIC Cubic, BBRv2, NewReno, Westwood+. The results obtained in the emulated and real network environments show that QUIC-DC can significantly reduce packet losses along with end-to-end communication delays, while preserving network utilization, features that are both very useful for real-time applications.",
      "authors": [
        "Saverio Mascolo",
        "Andrea Vittorio Balillo",
        "Gioacchino Manfredi",
        "Davide D'Agostino",
        "Luca De Cicco"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T16:00:11+00:00",
          "link": "https://arxiv.org/abs/2507.00896v1",
          "size": "1135kb",
          "version": "v1"
        },
        {
          "date": "2025-07-02T15:01:02+00:00",
          "link": "https://arxiv.org/abs/2507.00896v2",
          "size": "724kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T09:26:16+00:00",
          "link": "https://arxiv.org/abs/2507.00896v3",
          "size": "724kb",
          "version": "v3"
        }
      ],
      "title": "QUIC Delay Control: an implementation of congestion and delay control",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.00896",
        "HTML": "https://arxiv.org/html/2507.00896v3",
        "PDF": "https://arxiv.org/pdf/2507.00896"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper outlines a congestion and delay control algorithm for network communications, unrelated to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.00920",
      "abstract": "Federated learning (FL) has emerged as a promising paradigm for distributed machine learning, enabling collaborative training of a global model across multiple local devices without requiring them to share raw data. Despite its advancements, FL is limited by factors such as: (i) privacy risks arising from the unprotected transmission of local model updates to the fusion center (FC) and (ii) decreased learning utility caused by heterogeneity in model quantization resolution across participating devices. Prior work typically addresses only one of these challenges because maintaining learning utility under both privacy risks and quantization heterogeneity is a non-trivial task. In this paper, our aim is therefore to improve the learning utility of a privacy-preserving FL that allows clusters of devices with different quantization resolutions to participate in each FL round. Specifically, we introduce a novel stochastic quantizer (SQ) that is designed to simultaneously achieve differential privacy (DP) and minimum quantization error. Notably, the proposed SQ guarantees bounded distortion, unlike other DP approaches. To address quantization heterogeneity, we introduce a cluster size optimization technique combined with a linear fusion approach to enhance model aggregation accuracy. Numerical simulations validate the benefits of our approach in terms of privacy protection and learning utility compared to the conventional LaplaceSQ-FL algorithm.",
      "authors": [
        "Dang Qua Nguyen",
        "Morteza Hashemi",
        "Erik Perrins",
        "Sergiy A. Vorobyov",
        "David J. Love",
        "and Taejoon Kim"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T16:26:20+00:00",
          "link": "https://arxiv.org/abs/2507.00920v1",
          "size": "558kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T01:49:31+00:00",
          "link": "https://arxiv.org/abs/2507.00920v2",
          "size": "558kb",
          "version": "v2"
        }
      ],
      "title": "Privacy-Preserving Quantized Federated Learning with Diverse Precision",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.00920",
        "HTML": "https://arxiv.org/html/2507.00920v2",
        "PDF": "https://arxiv.org/pdf/2507.00920"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses federated learning and quantization but focuses on privacy and quantization heterogeneity rather than the training data engineering or processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.00981",
      "abstract": "Recent years have witnessed substantial progress on monocular depth estimation, particularly as measured by the success of large models on standard benchmarks. However, performance on standard benchmarks does not offer a complete assessment, because most evaluate accuracy but not robustness. In this work, we introduce PDE (Procedural Depth Evaluation), a new benchmark which enables systematic robustness evaluation. PDE uses procedural generation to create 3D scenes that test robustness to various controlled perturbations, including object, camera, material and lighting changes. Our analysis yields interesting findings on what perturbations are challenging for state-of-the-art depth models, which we hope will inform further research. Code and data are available at https://github.com/princeton-vl/proc-depth-eval.",
      "authors": [
        "Jack Nugent",
        "Siyang Wu",
        "Zeyu Ma",
        "Beining Han",
        "Meenal Parakh",
        "Abhishek Joshi",
        "Lingjie Mei",
        "Alexander Raistrick",
        "Xinyuan Li",
        "Jia Deng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T17:33:48+00:00",
          "link": "https://arxiv.org/abs/2507.00981v1",
          "size": "24344kb",
          "version": "v1"
        },
        {
          "date": "2025-07-02T18:22:59+00:00",
          "link": "https://arxiv.org/abs/2507.00981v2",
          "size": "29638kb",
          "version": "v2"
        }
      ],
      "title": "Evaluating Robustness of Monocular Depth Estimation with Procedural Scene Perturbations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.00981",
        "HTML": "https://arxiv.org/html/2507.00981v2",
        "PDF": "https://arxiv.org/pdf/2507.00981"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a benchmark for assessing robustness in monocular depth estimation models, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.01041",
      "abstract": "Split learning (SL) has emerged as a computationally efficient approach for artificial intelligence (AI) model training, which can alleviate device-side computational workloads. However, complex AI model architectures pose high computational complexity to obtain the optimal model splitting. In this paper, we represent an arbitrary AI model as a directed acyclic graph (DAG), and then reformulate the optimal model splitting problem as a minimum s-t cut search problem. To solve the problem, we propose a fast DAG-based model splitting algorithm, which restructures the DAG to enable the optimal model splitting identification via a maximum flow method. Theoretical analysis indicates that the proposed algorithm is optimal. Furthermore, considering AI models with block structures, we propose a block-wise model splitting algorithm to reduce computational complexity. The algorithm abstracts each block, i.e., a component consisting of multiple layers, into a single vertex, thereby obtaining the optimal model splitting via a simplified DAG. Extensive experimental results demonstrate that the proposed algorithms can determine the optimal model splitting within milliseconds, as well as reduce training delay by 24.62%-38.95% in dynamic edge networks as compared to the state-of-the-art benchmarks.",
      "authors": [
        "Zuguang Li",
        "Wen Wu",
        "Shaohua Wu",
        "Songge Zhang",
        "Ye Wang",
        "and Xuemin (Sherman) Shen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T07:14:04+00:00",
          "link": "https://arxiv.org/abs/2507.01041v1",
          "size": "6936kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T02:01:58+00:00",
          "link": "https://arxiv.org/abs/2507.01041v2",
          "size": "6936kb",
          "version": "v2"
        }
      ],
      "title": "Fast AI Model Splitting over Edge Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01041",
        "HTML": "https://arxiv.org/html/2507.01041v2",
        "PDF": "https://arxiv.org/pdf/2507.01041"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with AI model splitting over edge networks and does not involve any aspect of training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.01201",
      "abstract": "Independently trained vision and language models inhabit disjoint representational spaces, shaped by their respective modalities, objectives, and architectures. Yet an emerging hypothesis - the Platonic Representation Hypothesis - suggests that such models may nonetheless converge toward a shared statistical model of reality. This compatibility, if it exists, raises a fundamental question: can we move beyond post-hoc statistical detection of alignment and explicitly optimize for it between such disjoint representations? We cast this Platonic alignment problem as a multi-objective optimization task - preserve each modality's native structure while aligning for mutual coherence. We introduce the Joint Autoencoder Modulator (JAM) framework that jointly trains modality-specific autoencoders on the latent representations of pre-trained single modality models, encouraging alignment through both reconstruction and cross-modal objectives. By analogy, this framework serves as a method to escape Plato's Cave, enabling the emergence of shared structure from disjoint inputs. We evaluate this framework across three critical design axes: (i) the alignment objective - comparing contrastive loss (Con), its hard-negative variant (NegCon), and our Spread loss, (ii) the layer depth at which alignment is most effective, and (iii) the impact of foundation model scale on representational convergence. Our findings show that our lightweight Pareto-efficient framework reliably induces alignment, even across frozen, independently trained representations, offering both theoretical insight and practical pathways for transforming generalist unimodal foundations into specialist multimodal models.",
      "authors": [
        "Hyoseo (Lauren) Yoon",
        "Yisong Yue",
        "Been Kim"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T21:43:50+00:00",
          "link": "https://arxiv.org/abs/2507.01201v1",
          "size": "1651kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T02:07:36+00:00",
          "link": "https://arxiv.org/abs/2507.01201v2",
          "size": "1651kb",
          "version": "v2"
        }
      ],
      "title": "Escaping Platos Cave: JAM for Aligning Independently Trained Vision and Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01201",
        "HTML": "https://arxiv.org/html/2507.01201v2",
        "PDF": "https://arxiv.org/pdf/2507.01201"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores aligning disjoint vision and language models, with no discussion on the training data processing for LLMs specifically."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.01304",
      "abstract": "Artificial intelligence (AI) offers incredible possibilities for patient care, but raises significant ethical issues, such as the potential for bias. Powerful ethical frameworks exist to minimize these issues, but are often developed for academic or regulatory environments and tend to be comprehensive but overly prescriptive, making them difficult to operationalize within fast-paced, resource-constrained environments. We introduce the Scalable Agile Framework for Execution in AI (SAFE-AI) designed to balance ethical rigor with business priorities by embedding ethical oversight into standard Agile-based product development workflows. The framework emphasizes the early establishment of testable acceptance criteria, fairness metrics, and transparency metrics to manage model uncertainty, while also promoting continuous monitoring and re-evaluation of these metrics across the AI lifecycle. A core component of this framework are responsibility metrics using scenario-based probability analogy mapping designed to enhance transparency and stakeholder trust. This ensures that retraining or tuning activities are subject to lightweight but meaningful ethical review. By focusing on the minimum necessary requirements for responsible development, our framework offers a scalable, business-aligned approach to ethical AI suitable for organizations without dedicated ethics teams.",
      "authors": [
        "Ion Nemteanu",
        "Adir Mancebo Jr.",
        "Leslie Joe",
        "Ryan Lopez",
        "Patricia Lopez",
        "Warren Woodrich Pettine"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T02:45:26+00:00",
          "link": "https://arxiv.org/abs/2507.01304v1",
          "size": "931kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T14:23:46+00:00",
          "link": "https://arxiv.org/abs/2507.01304v2",
          "size": "931kb",
          "version": "v2"
        }
      ],
      "title": "A Practical SAFE-AI Framework for Small and Medium-Sized Enterprises Developing Medical Artificial Intelligence Ethics Policies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01304",
        "PDF": "https://arxiv.org/pdf/2507.01304"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a framework for ethical AI development rather than on the processing of large language model training data. It discusses embedding ethical oversight, not data engineering or preprocessing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.01334",
      "abstract": "Navigating the complexities of physics reasoning has long been a difficult task for Large Language Models (LLMs), requiring a synthesis of profound conceptual understanding and adept problem-solving techniques. In this study, we investigate the application of advanced instruction-tuned reasoning models, such as Deepseek-R1, to address a diverse spectrum of physics problems curated from the challenging SciBench benchmark. Our comprehensive experimental evaluation reveals the remarkable capabilities of reasoning models. Not only do they achieve state-of-the-art accuracy in answering intricate physics questions, but they also generate distinctive reasoning patterns that emphasize on symbolic derivation. Furthermore, our findings indicate that even for these highly sophisticated reasoning models, the strategic incorporation of few-shot prompting can still yield measurable improvements in overall accuracy, highlighting the potential for continued performance gains.",
      "authors": [
        "Nifu Dan",
        "Yujun Cai",
        "Yiwei Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T03:51:16+00:00",
          "link": "https://arxiv.org/abs/2507.01334v1",
          "size": "195kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T13:15:11+00:00",
          "link": "https://arxiv.org/abs/2507.01334v2",
          "size": "198kb",
          "version": "v2"
        }
      ],
      "title": "Symbolic or Numerical? Understanding Physics Problem Solving in Reasoning LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01334",
        "HTML": "https://arxiv.org/html/2507.01334v2",
        "PDF": "https://arxiv.org/pdf/2507.01334"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper centers on LLM capabilities in physics problem solving and uses instruction-tuned models to improve reasoning, without addressing the data processing tasks involved in LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.01352",
      "abstract": "Despite the critical role of reward models (RMs) in reinforcement learning from human feedback (RLHF), current state-of-the-art open RMs perform poorly on most existing evaluation benchmarks, failing to capture the spectrum of nuanced and sophisticated human preferences. Even approaches that incorporate advanced training techniques have not yielded meaningful performance improvements. We hypothesize that this brittleness stems primarily from limitations in preference datasets, which are often narrowly scoped, synthetically labeled, or lack rigorous quality control. To address these challenges, we present a large-scale preference dataset comprising 40 million preference pairs, named SynPref-40M. To enable data curation at scale, we design a human-AI synergistic two-stage pipeline that leverages the complementary strengths of human annotation quality and AI scalability. In this pipeline, humans provide verified annotations, while large language models perform automatic curation based on human guidance. Training on this preference mixture, we introduce Skywork-Reward-V2, a suite of eight reward models ranging from 0.6B to 8B parameters, trained on a carefully curated subset of 26 million preference pairs from SynPref-40M. We demonstrate that Skywork-Reward-V2 is versatile across a wide range of capabilities, including alignment with human preferences, objective correctness, safety, resistance to stylistic biases, and best-of-N scaling, achieving state-of-the-art performance across seven major reward model benchmarks. Ablation studies confirm that the effectiveness of our approach stems not only from data scale but also from high-quality curation. The Skywork-Reward-V2 series represents substantial progress in open reward models, highlighting the untapped potential of existing preference datasets and demonstrating how human-AI curation synergy can unlock significantly higher data quality.",
      "authors": [
        "Chris Yuhao Liu",
        "Liang Zeng",
        "Yuzhen Xiao",
        "Jujie He",
        "Jiacai Liu",
        "Chaojie Wang",
        "Rui Yan",
        "Wei Shen",
        "Fuxiang Zhang",
        "Jiacheng Xu",
        "Yang Liu",
        "Yahui Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T04:40:29+00:00",
          "link": "https://arxiv.org/abs/2507.01352v1",
          "size": "1006kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T05:58:40+00:00",
          "link": "https://arxiv.org/abs/2507.01352v2",
          "size": "1006kb",
          "version": "v2"
        }
      ],
      "title": "Skywork-Reward-V2: Scaling Preference Data Curation via Human-AI Synergy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01352",
        "PDF": "https://arxiv.org/pdf/2507.01352"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper's primary contribution is the creation of a large-scale preference dataset and a human-AI synergistic pipeline for data curation. This directly relates to data engineering for training-stage data processing."
      },
      "models": [
        {
          "model_path": "Skywork/Skywork-Reward-V2-Llama-3.1-8B-40M",
          "downloads": "29",
          "likes": "3",
          "trending_score": "3.0",
          "link": "https://huggingface.co/Skywork/Skywork-Reward-V2-Llama-3.1-8B-40M"
        },
        {
          "model_path": "Skywork/Skywork-Reward-V2-Qwen3-1.7B",
          "downloads": "11",
          "likes": "2",
          "trending_score": "2.0",
          "link": "https://huggingface.co/Skywork/Skywork-Reward-V2-Qwen3-1.7B"
        },
        {
          "model_path": "Skywork/Skywork-Reward-V2-Qwen3-4B",
          "downloads": "7",
          "likes": "2",
          "trending_score": "2.0",
          "link": "https://huggingface.co/Skywork/Skywork-Reward-V2-Qwen3-4B"
        },
        {
          "model_path": "Skywork/Skywork-Reward-V2-Qwen3-8B",
          "downloads": "13",
          "likes": "2",
          "trending_score": "2.0",
          "link": "https://huggingface.co/Skywork/Skywork-Reward-V2-Qwen3-8B"
        },
        {
          "model_path": "Skywork/Skywork-Reward-V2-Llama-3.1-8B",
          "downloads": "17",
          "likes": "2",
          "trending_score": "2.0",
          "link": "https://huggingface.co/Skywork/Skywork-Reward-V2-Llama-3.1-8B"
        },
        {
          "model_path": "Skywork/Skywork-Reward-V2-Qwen3-0.6B",
          "downloads": "17",
          "likes": "1",
          "trending_score": "1.0",
          "link": "https://huggingface.co/Skywork/Skywork-Reward-V2-Qwen3-0.6B"
        },
        {
          "model_path": "Skywork/Skywork-Reward-V2-Llama-3.2-1B",
          "downloads": "6",
          "likes": "1",
          "trending_score": "1.0",
          "link": "https://huggingface.co/Skywork/Skywork-Reward-V2-Llama-3.2-1B"
        },
        {
          "model_path": "Skywork/Skywork-Reward-V2-Llama-3.2-3B",
          "downloads": "43",
          "likes": "1",
          "trending_score": "1.0",
          "link": "https://huggingface.co/Skywork/Skywork-Reward-V2-Llama-3.2-3B"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.01381",
      "abstract": "Reinforcement learning has been proven to be highly effective in handling complex control tasks. Traditional methods typically use unimodal distributions, such as Gaussian distributions, to model the output of value distributions. However, unimodal distribution often and easily causes bias in value function estimation, leading to poor algorithm performance. This paper proposes a distributional reinforcement learning algorithm called DSAC-D (Distributed Soft Actor Critic with Diffusion Policy) to address the challenges of estimating bias in value functions and obtaining multimodal policy representations. A multimodal distributional policy iteration framework that can converge to the optimal policy was established by introducing policy entropy and value distribution function. A diffusion value network that can accurately characterize the distribution of multi peaks was constructed by generating a set of reward samples through reverse sampling using a diffusion model. Based on this, a distributional reinforcement learning algorithm with dual diffusion of the value network and the policy network was derived. MuJoCo testing tasks demonstrate that the proposed algorithm not only learns multimodal policy, but also achieves state-of-the-art (SOTA) performance in all 9 control tasks, with significant suppression of estimation bias and total average return improvement of over 10% compared to existing mainstream algorithms. The results of real vehicle testing show that DSAC-D can accurately characterize the multimodal distribution of different driving styles, and the diffusion policy network can characterize multimodal trajectories.",
      "authors": [
        "Tong Liu",
        "Yinuo Wang",
        "Xujie Song",
        "Wenjun Zou",
        "Liangfa Chen",
        "Likun Wang",
        "Bin Shuai",
        "Jingliang Duan",
        "Shengbo Eben Li"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T05:50:10+00:00",
          "link": "https://arxiv.org/abs/2507.01381v1",
          "size": "9125kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T04:38:33+00:00",
          "link": "https://arxiv.org/abs/2507.01381v2",
          "size": "7149kb",
          "version": "v2"
        }
      ],
      "title": "Distributional Soft Actor-Critic with Diffusion Policy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01381",
        "HTML": "https://arxiv.org/html/2507.01381v2",
        "PDF": "https://arxiv.org/pdf/2507.01381"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is focused on improving reinforcement learning through a distributional algorithm, which does not involve LLM training data processing tasks like data curation or preprocessing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.01424",
      "abstract": "Recent advancements in vision-language models (VLMs) for common-sense reasoning have led to the development of vision-language-action (VLA) models, enabling robots to perform generalized manipulation. Although existing autoregressive VLA methods design a specific architecture like dual-system to leverage large-scale pretrained knowledge, they tend to capture static information, often neglecting the dynamic aspects vital for embodied tasks. To this end, we propose TriVLA, a unified Vision-Language-Action model with a triple-system architecture for general robot control. The vision-language module (System 2) interprets the environment through vision and language instructions. The dynamics perception module (System 3) inherently produces visual representations that encompass both current static information and predicted future dynamics, thereby providing valuable guidance for policy learning. TriVLA utilizes pre-trained VLM model and fine-tunes pre-trained video foundation model on robot datasets along with internet human manipulation data. The subsequent policy learning module (System 1) generates fluid motor actions in real time. Experimental evaluation demonstrates that TriVLA operates at approximately 36 Hz and surpasses state-of-the-art imitation learning baselines on standard simulation benchmarks as well as challenging real-world manipulation tasks.",
      "authors": [
        "Zhenyang Liu",
        "Yongchong Gu",
        "Sixiao Zheng",
        "Xiangyang Xue",
        "Yanwei Fu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T07:24:44+00:00",
          "link": "https://arxiv.org/abs/2507.01424v1",
          "size": "3218kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T14:23:34+00:00",
          "link": "https://arxiv.org/abs/2507.01424v2",
          "size": "3218kb",
          "version": "v2"
        }
      ],
      "title": "TriVLA: A Triple-System-Based Unified Vision-Language-Action Model for General Robot Control",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01424",
        "HTML": "https://arxiv.org/html/2507.01424v2",
        "PDF": "https://arxiv.org/pdf/2507.01424"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses fine-tuning pre-trained models on combined datasets, including robot and internet manipulation data, which touches on training-stage data processing, albeit not extensively."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.01439",
      "abstract": "Robust estimation is essential in correspondence-based Point Cloud Registration (PCR). Existing methods using maximal clique search in compatibility graphs achieve high recall but suffer from exponential time complexity, limiting their use in time-sensitive applications. To address this challenge, we propose a fast and robust estimator, TurboReg, built upon a novel lightweight clique, TurboClique, and a highly parallelizable Pivot-Guided Search (PGS) algorithm. First, we define the TurboClique as a 3-clique within a highly-constrained compatibility graph. The lightweight nature of the 3-clique allows for efficient parallel searching, and the highly-constrained compatibility graph ensures robust spatial consistency for stable transformation estimation. Next, PGS selects matching pairs with high SC$^2$ scores as pivots, effectively guiding the search toward TurboCliques with higher inlier ratios. Moreover, the PGS algorithm has linear time complexity and is significantly more efficient than the maximal clique search with exponential time complexity. Extensive experiments show that TurboReg achieves state-of-the-art performance across multiple real-world datasets, with substantial speed improvements. For example, on the 3DMatch+FCGF dataset, TurboReg (1K) operates $208.22\\times$ faster than 3DMAC while also achieving higher recall. Our code is accessible at \\href{https://github.com/Laka-3DV/TurboReg}{\\texttt{TurboReg}}.",
      "authors": [
        "Shaocheng Yan",
        "Pengcheng Shi",
        "Zhenjun Zhao",
        "Kaixin Wang",
        "Kuang Cao",
        "Ji Wu",
        "Jiayuan Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T07:50:24+00:00",
          "link": "https://arxiv.org/abs/2507.01439v1",
          "size": "41786kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T13:46:01+00:00",
          "link": "https://arxiv.org/abs/2507.01439v2",
          "size": "27168kb",
          "version": "v2"
        }
      ],
      "title": "TurboReg: TurboClique for Robust and Efficient Point Cloud Registration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01439",
        "HTML": "https://arxiv.org/html/2507.01439v2",
        "PDF": "https://arxiv.org/pdf/2507.01439"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a method for robust and efficient point cloud registration, which does not involve any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.01548",
      "abstract": "This paper explores how older adults, particularly aging migrants in urban China, can engage AI-assisted co-creation to express personal narratives that are often fragmented, underrepresented, or difficult to verbalize. Through a pilot workshop combining oral storytelling and the symbolic reconstruction of Hanzi, participants shared memories of migration and recreated new character forms using Xiaozhuan glyphs, suggested by the Large Language Model (LLM), together with physical materials. Supported by human facilitation and a soft AI presence, participants transformed lived experience into visual and tactile expressions without requiring digital literacy. This approach offers new perspectives on human-AI collaboration and aging by repositioning AI not as a content producer but as a supportive mechanism, and by supporting narrative agency within sociotechnical systems.",
      "authors": [
        "Wen Zhan",
        "Ziqun Hua",
        "Peiyue Lin",
        "Yunfei Chen"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T10:00:12+00:00",
          "link": "https://arxiv.org/abs/2507.01548v1",
          "size": "1052kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T08:45:46+00:00",
          "link": "https://arxiv.org/abs/2507.01548v2",
          "size": "1058kb",
          "version": "v2"
        }
      ],
      "title": "Crafting Hanzi as Narrative Bridges: An AI Co-Creation Workshop for Elderly Migrants",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01548",
        "PDF": "https://arxiv.org/pdf/2507.01548"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses using LLMs in a workshop setting for AI-assisted co-creation, potentially involving data preparation methods, but does not introduce new methods for LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.01551",
      "abstract": "Process Reinforcement Learning~(PRL) has demonstrated considerable potential in enhancing the reasoning capabilities of Large Language Models~(LLMs). However, introducing additional process reward models incurs substantial computational overhead, and there is no unified theoretical framework for process-level advantage estimation. To bridge this gap, we propose \\textbf{S}elf-Guided \\textbf{P}rocess \\textbf{R}eward \\textbf{O}ptimization~(\\textbf{SPRO}), a novel framework that enables process-aware RL through two key innovations: (1) we first theoretically demonstrate that process rewards can be derived intrinsically from the policy model itself, and (2) we introduce well-defined cumulative process rewards and \\textbf{M}asked \\textbf{S}tep \\textbf{A}dvantage (\\textbf{MSA}), which facilitates rigorous step-wise action advantage estimation within shared-prompt sampling groups. Our experimental results demonstrate that SPRO outperforms vaniila GRPO with 3.4x higher training efficiency and a 17.5\\% test accuracy improvement. Furthermore, SPRO maintains a stable and elevated policy entropy throughout training while reducing the average response length by approximately $1/3$, evidencing sufficient exploration and prevention of reward hacking. Notably, SPRO incurs no additional computational overhead compared to outcome-supervised RL methods such as GRPO, which benefit industrial implementation.",
      "authors": [
        "Wu Fei",
        "Hao Kong",
        "Shuxian Liang",
        "Yang Lin",
        "Yibo Yang",
        "Jing Tang",
        "Lei Chen",
        "Xiansheng Hua"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T10:05:14+00:00",
          "link": "https://arxiv.org/abs/2507.01551v1",
          "size": "448kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T10:33:08+00:00",
          "link": "https://arxiv.org/abs/2507.01551v2",
          "size": "689kb",
          "version": "v2"
        }
      ],
      "title": "Self-Guided Process Reward Optimization with Redefined Step-wise Advantage for Process Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01551",
        "HTML": "https://arxiv.org/html/2507.01551v2",
        "PDF": "https://arxiv.org/pdf/2507.01551"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on enhancing LLM reasoning capabilities through process reinforcement learning, but does not address LLM training data construction or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.01641",
      "abstract": "Reconfigurable intelligent surfaces (RISs) offer the unique capability to reshape the radio environment, thereby simplifying transmission schemes traditionally contingent on channel conditions. Joint spatial division and multiplexing (JSDM) emerges as a low-overhead transmission scheme for multi-user equipment (UE) scenarios, typically requiring complex matrix decomposition to achieve block-diagonalization of the effective channel matrix. In this study, we introduce an innovative JSDM design that leverages RISs to customize channels, thereby streamlining the overall procedures. By strategically positioning RISs at the discrete Fourier transform (DFT) directions of the base station (BS), we establish orthogonal line-of-sight links within the BS-RIS channel, enabling a straightforward pre-beamforming design. Based on UE grouping, we devise reflected beams of the RIS with optimized directions to mitigate inter-group interference in the RISs-UEs channel. An approximation of the channel cross-correlation coefficient is derived and serves as a foundation for the RISs-UEs association, further diminishing inter-group interference. Numerical results substantiate the efficacy of our RIS-customized JSDM in not only achieving effective channel block-diagonalization but also in significantly enhancing the sum spectral efficiency for multi-UE transmissions.",
      "authors": [
        "Weicong Chen",
        "Chao-Kai Wen",
        "Wankai Tang",
        "Xiao Li",
        "and Shi Jin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T12:15:00+00:00",
          "link": "https://arxiv.org/abs/2507.01641v1",
          "size": "725kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T09:10:05+00:00",
          "link": "https://arxiv.org/abs/2507.01641v2",
          "size": "725kb",
          "version": "v2"
        }
      ],
      "title": "Joint Spatial Division and Multiplexing with Customized Orthogonal Group Channels in Multi-RIS-Assisted Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01641",
        "HTML": "https://arxiv.org/html/2507.01641v2",
        "PDF": "https://arxiv.org/pdf/2507.01641"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on communication systems and introduces a design for joint spatial division and multiplexing using reconfigurable intelligent surfaces, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.01685",
      "abstract": "This paper presents a new class of spatially coupled turbo-like codes (SC-TCs), namely half spatially coupled braided convolutional codes (HSC-BCCs) and half spatially coupled parallel concatenated codes (HSC-PCCs). Different from the conventional SC-TCs, the proposed codes have simpler and deterministic coupling structures. Most notably, the coupling of HSC-BCCs is performed by re-encoding the whole coupling sequence in the component encoder of one time instant, rather than spreading the coupling bits to component encoders of multiple time instants. This simplification not only addresses the window decoding threshold loss issue in existing BCCs, but also allows the proposed codes to attain very close-to-capacity performance with a coupling memory as small as 2. Both theoretical and numerical results are provided to demonstrate the performance advantages of the proposed codes over existing spatially coupled codes.",
      "authors": [
        "Xiaowei Wu",
        "Lei Yang",
        "Min Qiu",
        "Chong Han",
        "Jinhong Yuan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T13:11:34+00:00",
          "link": "https://arxiv.org/abs/2507.01685v1",
          "size": "803kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T02:00:16+00:00",
          "link": "https://arxiv.org/abs/2507.01685v2",
          "size": "488kb",
          "version": "v2"
        }
      ],
      "title": "Half Spatially Coupled Turbo-Like Codes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01685",
        "HTML": "https://arxiv.org/html/2507.01685v2",
        "PDF": "https://arxiv.org/pdf/2507.01685"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a new class of spatially coupled turbo-like codes and their performance advantages, which has no connection to the processing or engineering of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.01737",
      "abstract": "Generating realistic 3D human-object interactions (HOIs) remains a challenging task due to the difficulty of modeling detailed interaction dynamics. Existing methods treat human and object motions independently, resulting in physically implausible and causally inconsistent behaviors. In this work, we present HOI-Dyn, a novel framework that formulates HOI generation as a driver-responder system, where human actions drive object responses. At the core of our method is a lightweight transformer-based interaction dynamics model that explicitly predicts how objects should react to human motion. To further enforce consistency, we introduce a residual-based dynamics loss that mitigates the impact of dynamics prediction errors and prevents misleading optimization signals. The dynamics model is used only during training, preserving inference efficiency. Through extensive qualitative and quantitative experiments, we demonstrate that our approach not only enhances the quality of HOI generation but also establishes a feasible metric for evaluating the quality of generated interactions.",
      "authors": [
        "Lin Wu",
        "Zhixiang Chen",
        "Jianglin Lan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T14:13:48+00:00",
          "link": "https://arxiv.org/abs/2507.01737v1",
          "size": "11251kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T14:52:12+00:00",
          "link": "https://arxiv.org/abs/2507.01737v2",
          "size": "11226kb",
          "version": "v2"
        }
      ],
      "title": "HOI-Dyn: Learning Interaction Dynamics for Human-Object Motion Diffusion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01737",
        "HTML": "https://arxiv.org/html/2507.01737v2",
        "PDF": "https://arxiv.org/pdf/2507.01737"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a novel framework for human-object interaction generation using a transformer-based model, lacking any focus on LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.01755",
      "abstract": "PathDB is a Java-based graph database designed for in-memory data loading and querying. By utilizing Regular Path Queries (RPQ) and a closed path algebra, PathDB processes paths through its three main components: the parser, the logical plan, and the physical plan. This modular design allows for targeted optimizations and modifications without impacting overall functionality. Benchmark experiments illustrate PathDB's execution times and flexibility in handling dynamic and complex path queries, compared to baseline methods like Depth-First Search (DFS) and Breadth-First Search (BFS) guided by an automaton, highlighting PathDB optimizations that contribute to its performance. PathDB was also evaluated against leading commercial graph systems, including Neo4j, Memgraph, and K\\`uzu. Benchmark experiments demonstrated PathDB competitive execution times and its ability to support a wide range of path query types.",
      "authors": [
        "Roberto Garc\\'ia",
        "Renzo Angles",
        "Vicente Rojas",
        "Sebasti\\'an Ferrada"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T14:33:05+00:00",
          "link": "https://arxiv.org/abs/2507.01755v1",
          "size": "155kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T15:30:27+00:00",
          "link": "https://arxiv.org/abs/2507.01755v2",
          "size": "156kb",
          "version": "v2"
        }
      ],
      "title": "PathDB: A system for evaluating regular path queries",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01755",
        "HTML": "https://arxiv.org/html/2507.01755v2",
        "PDF": "https://arxiv.org/pdf/2507.01755"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on a graph database system for evaluating regular path queries, which does not involve LLM training data processing or data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.01878",
      "abstract": "The integrability problem of rational first-order ODEs $y^{\\prime}=\\frac{M(x,y)}{N(x,y)}$, where $M,N \\in \\mathbb{R}[x,y]$ is a long-term research focus in the area of dynamical systems, physics, etc. Although the computer algebra system such as Mathematica, Maple has developed standard algorithms to tackle its first integral expressed by Liouvillian or special function, this problem is quite difficult and the general method requires specifying a tight degree bound for the Darboux polynomial. Computing the bounded degree first integral, in general, is very expensive for a computer algebra system\\cite{duarte2021efficient}\\cite{cheze2020symbolic} and becomes impractical for ODE of large size. In \\cite{huang2025algorithm}, we have proposed an algorithm to find the inverse of a local rational transformation $y \\to \\frac{A(x,y)}{B(x,y)}$ that transforms a rational ODE to a simpler and more tractable structure $y^{\\prime}=\\sum_{i=0}^nf_i(x)y^i$, whose integrability under linear transformation $\\left\\{x \\to F(x),y \\to P(x)y+Q(x)\\right\\}$ can be detected by Maple efficiently \\cite{CHEBTERRAB2000204}\\cite{cheb2000first}. In that paper we have also mentioned when $M(x,y),N(x,y)$ of the reducible structure are not coprime, canceling the common factors in $y$ will alter the structure which makes that algorithm fail. In this paper, we consider this issue. We conclude that with the exact tight degree bound for the polynomial $A(x,y)$ given, we have an efficient algorithm to compute such transformation and the reduced ODE for \"quite a lot of\" cases where $M,N$ are not coprime. We have also implemented this algorithm in Maple and the code is available in researchgate.",
      "authors": [
        "Shaoxuan Huang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Symbolic Computation (cs.SC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T16:48:13+00:00",
          "link": "https://arxiv.org/abs/2507.01878v1",
          "size": "316kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T16:00:23+00:00",
          "link": "https://arxiv.org/abs/2507.01878v2",
          "size": "316kb",
          "version": "v2"
        }
      ],
      "title": "Generalized ODE reduction algorithm for bounded degree transformation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01878",
        "HTML": "https://arxiv.org/html/2507.01878v2",
        "PDF": "https://arxiv.org/pdf/2507.01878"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses an algorithm concerning the integrability of rational first-order ODEs and its implementation, without any mention of LLM training data processes."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.01909",
      "abstract": "Objective: Clinical implementation of deformable image registration (DIR) requires voxel-based spatial accuracy metrics such as manually identified landmarks, which are challenging to implement for highly mobile gastrointestinal (GI) organs. To address this, patient-specific digital twins (DT) modeling temporally varying motion were created to assess the accuracy of DIR methods. Approach: 21 motion phases simulating digestive GI motion as 4D sequences were generated from static 3D patient scans using published analytical GI motion models through a semi-automated pipeline. Eleven datasets, including six T2w FSE MRI (T2w MRI), two T1w 4D golden-angle stack-of-stars, and three contrast-enhanced CT scans. The motion amplitudes of the DTs were assessed against real patient stomach motion amplitudes extracted from independent 4D MRI datasets. The generated DTs were then used to assess six different DIR methods using target registration error, Dice similarity coefficient, and the 95th percentile Hausdorff distance using summary metrics and voxel-level granular visualizations. Finally, for a subset of T2w MRI scans from patients treated with MR-guided radiation therapy, dose distributions were warped and accumulated to assess dose warping errors, including evaluations of DIR performance in both low- and high-dose regions for patient-specific error estimation. Main results: Our proposed pipeline synthesized DTs modeling realistic GI motion, achieving mean and maximum motion amplitudes and a mean log Jacobian determinant within 0.8 mm and 0.01, respectively, similar to published real-patient gastric motion data. It also enables the extraction of detailed quantitative DIR performance metrics and rigorous validation of dose mapping accuracy. Significance: The pipeline enables rigorously testing DIR tools for dynamic, anatomically complex regions enabling granular spatial and dosimetric accuracies.",
      "authors": [
        "Jorge Tapias Gomez",
        "Nishant Nadkarni",
        "Lando S. Bosma",
        "Jue Jiang",
        "Ergys D. Subashi",
        "William P. Segars",
        "James M. Balter",
        "Mert R Sabuncu",
        "Neelam Tyagi and Harini Veeraraghavan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T17:22:47+00:00",
          "link": "https://arxiv.org/abs/2507.01909v1",
          "size": "14067kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T15:55:53+00:00",
          "link": "https://arxiv.org/abs/2507.01909v2",
          "size": "14067kb",
          "version": "v2"
        }
      ],
      "title": "Modality-agnostic, patient-specific digital twins modeling temporally varying digestive motion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01909",
        "PDF": "https://arxiv.org/pdf/2507.01909"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on modeling digestive motion using patient-specific digital twins for medical imaging evaluation and error estimation, unrelated to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.01923",
      "abstract": "Natural language generation (NLG) is increasingly deployed in high-stakes domains, yet common intrinsic evaluation methods, such as n-gram overlap or sentence plausibility, weakly correlate with actual decision-making efficacy. We propose a decision-oriented framework for evaluating generated text by directly measuring its influence on human and large language model (LLM) decision outcomes. Using market digest texts--including objective morning summaries and subjective closing-bell analyses--as test cases, we assess decision quality based on the financial performance of trades executed by human investors and autonomous LLM agents informed exclusively by these texts. Our findings reveal that neither humans nor LLM agents consistently surpass random performance when relying solely on summaries. However, richer analytical commentaries enable collaborative human-LLM teams to outperform individual human or agent baselines significantly. Our approach underscores the importance of evaluating generated text by its ability to facilitate synergistic decision-making between humans and LLMs, highlighting critical limitations of traditional intrinsic metrics.",
      "authors": [
        "Yu-Shiang Huang",
        "Chuan-Ju Wang",
        "Chung-Chi Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T17:32:35+00:00",
          "link": "https://arxiv.org/abs/2507.01923v1",
          "size": "32kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T06:29:26+00:00",
          "link": "https://arxiv.org/abs/2507.01923v2",
          "size": "47kb",
          "version": "v2"
        }
      ],
      "title": "Decision-Oriented Text Evaluation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01923",
        "HTML": "https://arxiv.org/html/2507.01923v2",
        "PDF": "https://arxiv.org/pdf/2507.01923"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses the evaluation of generated text based on decision outcomes rather than intrinsic metrics, which may involve some preprocessing or usage of LLM text outputs, but it does not propose novel methods for LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.01930",
      "abstract": "Recent advances in large Language Models (LLMs) have revolutionized mobile robots, including unmanned aerial vehicles (UAVs), enabling their intelligent operation within Internet of Things (IoT) ecosystems. However, LLMs still face challenges from logical reasoning and complex decision-making, leading to concerns about the reliability of LLM-driven UAV operations in IoT applications. In this paper, we propose a LLM-driven closed-loop control framework that enables reliable UAV operations powered by effective feedback and refinement using two LLM modules, i.e., a Code Generator and an Evaluator. Our framework transforms numerical state observations from UAV operations into natural language trajectory descriptions to enhance the evaluator LLM's understanding of UAV dynamics for precise feedback generation. Our framework also enables a simulation-based refinement process, and hence eliminates the risks to physical UAVs caused by incorrect code execution during the refinement. Extensive experiments on UAV control tasks with different complexities are conducted. The experimental results show that our framework can achieve reliable UAV operations using LLMs, which significantly outperforms baseline approaches in terms of success rate and completeness with the increase of task complexity.",
      "authors": [
        "Wenhao Wang",
        "Yanyan Li",
        "Long Jiao",
        "Jiawei Yuan"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T17:44:17+00:00",
          "link": "https://arxiv.org/abs/2507.01930v1",
          "size": "484kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T17:36:59+00:00",
          "link": "https://arxiv.org/abs/2507.01930v2",
          "size": "483kb",
          "version": "v2"
        }
      ],
      "title": "Large Language Model-Driven Closed-Loop UAV Operation with Semantic Observations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01930",
        "HTML": "https://arxiv.org/html/2507.01930v2",
        "PDF": "https://arxiv.org/pdf/2507.01930"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a framework for UAV operations using LLMs, focusing on control and feedback processes rather than any aspect of training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.01961",
      "abstract": "Recently, mobile manipulation has attracted increasing attention for enabling language-conditioned robotic control in household tasks. However, existing methods still face challenges in coordinating mobile base and manipulator, primarily due to two limitations. On the one hand, they fail to explicitly model the influence of the mobile base on manipulator control, which easily leads to error accumulation under high degrees of freedom. On the other hand, they treat the entire mobile manipulation process with the same visual observation modality (e.g., either all 2D or all 3D), overlooking the distinct multimodal perception requirements at different stages during mobile manipulation. To address this, we propose the Adaptive Coordination Diffusion Transformer (AC-DiT), which enhances mobile base and manipulator coordination for end-to-end mobile manipulation. First, since the motion of the mobile base directly influences the manipulator's actions, we introduce a mobility-to-body conditioning mechanism that guides the model to first extract base motion representations, which are then used as context prior for predicting whole-body actions. This enables whole-body control that accounts for the potential impact of the mobile base's motion. Second, to meet the perception requirements at different stages of mobile manipulation, we design a perception-aware multimodal conditioning strategy that dynamically adjusts the fusion weights between various 2D visual images and 3D point clouds, yielding visual features tailored to the current perceptual needs. This allows the model to, for example, adaptively rely more on 2D inputs when semantic information is crucial for action prediction, while placing greater emphasis on 3D geometric information when precise spatial understanding is required. We validate AC-DiT through extensive experiments on both simulated and real-world mobile manipulation tasks.",
      "authors": [
        "Sixiang Chen",
        "Jiaming Liu",
        "Siyuan Qian",
        "Han Jiang",
        "Lily Li",
        "Renrui Zhang",
        "Zhuoyang Liu",
        "Chenyang Gu",
        "Chengkai Hou",
        "Pengwei Wang",
        "Zhongyuan Wang",
        "Shanghang Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T17:59:54+00:00",
          "link": "https://arxiv.org/abs/2507.01961v1",
          "size": "18193kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T15:28:58+00:00",
          "link": "https://arxiv.org/abs/2507.01961v2",
          "size": "18193kb",
          "version": "v2"
        }
      ],
      "title": "AC-DiT: Adaptive Coordination Diffusion Transformer for Mobile Manipulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01961",
        "HTML": "https://arxiv.org/html/2507.01961v2",
        "PDF": "https://arxiv.org/pdf/2507.01961"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about robotic control and manipulation using adaptive coordination techniques, without discussing any LLM training data processing methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2105.13440",
      "abstract": "We report on the potential for using algorithms for non-negative matrix factorization (NMF) to improve parameter estimation in topic models. While several papers have studied connections between NMF and topic models, none have suggested leveraging these connections to develop new algorithms for fitting topic models. NMF avoids the \"sum-to-one\" constraints on the topic model parameters, resulting in an optimization problem with simpler structure and more efficient computations. Building on recent advances in optimization algorithms for NMF, we show that first solving the NMF problem then recovering the topic model fit can produce remarkably better fits, and in less time, than standard algorithms for topic models. While we focus primarily on maximum likelihood estimation, we show that this approach also has the potential to improve variational inference for topic models. Our methods are implemented in the R package fastTopics.",
      "authors": [
        "Peter Carbonetto",
        "Abhishek Sarkar",
        "Zihao Wang",
        "Matthew Stephens"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Computation (stat.CO)"
      ],
      "submission_historys": [
        {
          "date": "2021-05-27T20:34:46+00:00",
          "link": "https://arxiv.org/abs/2105.13440v1",
          "size": "22307kb",
          "version": "v1"
        },
        {
          "date": "2022-01-21T14:20:56+00:00",
          "link": "https://arxiv.org/abs/2105.13440v2",
          "size": "22346kb",
          "version": "v2"
        },
        {
          "date": "2025-07-02T18:57:42+00:00",
          "link": "https://arxiv.org/abs/2105.13440v3",
          "size": "15943kb",
          "version": "v3"
        }
      ],
      "title": "Non-negative matrix factorization algorithms generally improve topic model fits",
      "links": {
        "Abstract": "https://arxiv.org/abs/2105.13440",
        "HTML": "https://arxiv.org/html/2105.13440v3",
        "PDF": "https://arxiv.org/pdf/2105.13440"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on using non-negative matrix factorization (NMF) algorithms to improve topic model parameter estimation, with no mention of LLM training data processing or contributions to data engineering tasks for LLMs."
      },
      "tasks": [
        "parameter estimation",
        "Topic Models",
        "Variational Inference"
      ],
      "repo_urls": [
        "https://github.com/stephenslab/fastTopics"
      ],
      "source": "arXiv"
    },
    {
      "id": "2201.03962",
      "abstract": "This paper considers the problem of minimizing a differentiable function with locally Lipschitz continuous gradient on the algebraic variety of real matrices of upper-bounded rank. This problem is known to enable the formulation of various machine learning or signal processing tasks such as dimensionality reduction, collaborative filtering, and signal recovery. Several definitions of stationarity exist for this nonconvex problem. Among them, Bouligand stationarity is the strongest necessary condition for local optimality. This paper proposes two first-order methods that generate a sequence in the variety whose accumulation points are Bouligand stationary. The first method combines the well-known projected-projected gradient descent map with a rank reduction mechanism. The second method is a hybrid of projected gradient descent and projected-projected gradient descent. Both methods stand out in the field of low-rank optimization methods when considering their convergence properties, their streamlined design, their typical computational cost per iteration, and their empirically observed numerical performance. The theoretical framework used to analyze the proposed methods is of independent interest.",
      "authors": [
        "Guillaume Olikier",
        "Kyle A. Gallivan",
        "P.-A. Absil"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2022-01-11T14:18:54+00:00",
          "link": "https://arxiv.org/abs/2201.03962v1",
          "size": "41kb",
          "version": "v1"
        },
        {
          "date": "2024-06-27T20:54:08+00:00",
          "link": "https://arxiv.org/abs/2201.03962v2",
          "size": "808kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T12:11:37+00:00",
          "link": "https://arxiv.org/abs/2201.03962v3",
          "size": "1136kb",
          "version": "v3"
        }
      ],
      "title": "Low-rank optimization methods based on projected-projected gradient descent that accumulate at Bouligand stationary points",
      "links": {
        "Abstract": "https://arxiv.org/abs/2201.03962",
        "HTML": "https://arxiv.org/html/2201.03962v3",
        "PDF": "https://arxiv.org/pdf/2201.03962"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses low-rank optimization methods in the context of machine learning and signal processing tasks, but it does not address LLM data processing or data engineering for training processes."
      },
      "repo_urls": [
        "https://github.com/golikier/bouligandstationaritylowrankoptimization",
        "https://github.com/golikier/apocalypsefreelowrankoptimization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2203.02607",
      "abstract": "In this paper, we study the \\emph{sparse integer least squares problem} (SILS), an NP-hard variant of least squares with sparse $\\{0, \\pm 1\\}$-vectors. We propose an $\\ell_1$-based SDP relaxation, and a randomized algorithm for SILS, which computes feasible solutions with high probability with an asymptotic approximation ratio $1/T^2$ as long as the sparsity constant $\\sigma \\ll T$. Our algorithm handles large-scale problems, delivering high-quality approximate solutions for dimensions up to $d = 10,000$. The proposed randomized algorithm applies broadly to binary quadratic programs with a cardinality constraint, even for non-convex objectives. For fixed sparsity, we provide sufficient conditions for our SDP relaxation to solve SILS, meaning that any optimal solution to the SDP relaxation yields an optimal solution to SILS. The class of data input which guarantees that SDP solves SILS is broad enough to cover many cases in real-world applications, such as privacy preserving identification and multiuser detection. We validate these conditions in two application-specific cases: the \\emph{feature extraction problem}, where our relaxation solves the problem for sub-Gaussian data with weak covariance conditions, and the \\emph{integer sparse recovery problem}, where our relaxation solves the problem in both high and low coherence settings under certain conditions.",
      "authors": [
        "Alberto Del Pia and Dekun Zhou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2022-03-04T23:21:38+00:00",
          "link": "https://arxiv.org/abs/2203.02607v1",
          "size": "1938kb",
          "version": "v1"
        },
        {
          "date": "2023-01-06T01:26:35+00:00",
          "link": "https://arxiv.org/abs/2203.02607v2",
          "size": "1428kb",
          "version": "v2"
        },
        {
          "date": "2025-07-02T22:39:56+00:00",
          "link": "https://arxiv.org/abs/2203.02607v3",
          "size": "214kb",
          "version": "v3"
        }
      ],
      "title": "An SDP Relaxation for the Sparse Integer Least Squares Problem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2203.02607",
        "HTML": "https://arxiv.org/html/2203.02607v3",
        "PDF": "https://arxiv.org/pdf/2203.02607"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study focuses on the sparse integer least squares problem, proposing an SDP relaxation for optimization, with no connection to LLM training data processing or data engineering methods related to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2208.02468",
      "abstract": "Fully homomorphic encryption (FHE) enables an entity to perform arbitrary computation on encrypted data without decrypting the ciphertexts. An ongoing group-theoretical approach to construct an FHE scheme uses a certain \"compression\" function $F(x)$ implemented by group operations on a given finite group $G$, which satisfies that $F(1) = 1$ and $F(\\sigma) = F(\\sigma^2) = \\sigma$ where $\\sigma \\in G$ is some element of order $3$. The previous work gave an example of such a function over the symmetric group $G = S_5$ by just a heuristic approach. In this paper, we systematically study the possibilities of such a function over various groups. We show that such a function does not exist over any solvable group $G$ (such as an Abelian group and a smaller symmetric group $S_n$ with $n \\leq 4$). We also construct such a function over the alternating group $G = A_5$ that has a shortest possible expression. Moreover, by using this new function, we give a reduction of a construction of an FHE scheme to a construction of a homomorphic encryption scheme over the group $A_5$, which is more efficient than the previously known reductions.",
      "authors": [
        "Koji Nuida"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Group Theory (math.GR)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2022-08-04T05:29:40+00:00",
          "link": "https://arxiv.org/abs/2208.02468v1",
          "size": "11kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T03:39:00+00:00",
          "link": "https://arxiv.org/abs/2208.02468v2",
          "size": "16kb",
          "version": "v2"
        }
      ],
      "title": "On Compression Functions over Groups with Applications to Homomorphic Encryption",
      "links": {
        "Abstract": "https://arxiv.org/abs/2208.02468",
        "HTML": "https://arxiv.org/html/2208.02468v2",
        "PDF": "https://arxiv.org/pdf/2208.02468"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on compression functions in group theory and their application to homomorphic encryption schemes, which are unrelated to the processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2212.05050",
      "abstract": "This paper is about the surprising interaction of a foundational result from model theory, about stability of theories, with algorithmic stability in learning. First, in response to gaps in existing learning models, we introduce a new statistical learning model, called ``Probably Eventually Correct'' or PEC. We characterize Littlestone (stable) classes in terms of this model. As a corollary, Littlestone classes have frequent short definitions in a natural statistical sense. In order to obtain a characterization of Littlestone classes in terms of frequent definitions, we build an equivalence theorem highlighting what is common to many existing approximation algorithms, and to the new PEC. This is guided by an analogy to definability of types in model theory, but has its own character. Drawing on these theorems and on other recent work, we present a complete algorithmic analogue of Shelah's celebrated Unstable Formula Theorem, with algorithmic properties taking the place of the infinite.",
      "authors": [
        "Maryanthe Malliaris",
        "Shay Moran"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Logic (math.LO)",
        "Discrete Mathematics (cs.DM)",
        "Machine Learning (cs.LG)",
        "Logic in Computer Science (cs.LO)",
        "Combinatorics (math.CO)"
      ],
      "submission_historys": [
        {
          "date": "2022-12-09T18:53:34+00:00",
          "link": "https://arxiv.org/abs/2212.05050v1",
          "size": "529kb",
          "version": "v1"
        },
        {
          "date": "2023-04-17T18:09:38+00:00",
          "link": "https://arxiv.org/abs/2212.05050v2",
          "size": "543kb",
          "version": "v2"
        },
        {
          "date": "2025-07-02T22:11:09+00:00",
          "link": "https://arxiv.org/abs/2212.05050v3",
          "size": "530kb",
          "version": "v3"
        }
      ],
      "title": "The unstable formula theorem revisited via algorithms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2212.05050",
        "HTML": "https://arxiv.org/html/2212.05050v3",
        "PDF": "https://arxiv.org/pdf/2212.05050"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with a statistical learning model related to model theory but does not address any aspect of data processing for LLM training."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2403.01658",
      "abstract": "We show that on every affine Weyl group natural random walks are noise sensitive in total variation.",
      "authors": [
        "Ryokichi Tanaka"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Probability (math.PR)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-04T00:44:07+00:00",
          "link": "https://arxiv.org/abs/2403.01658v1",
          "size": "36kb",
          "version": "v1"
        },
        {
          "date": "2024-04-25T03:23:04+00:00",
          "link": "https://arxiv.org/abs/2403.01658v2",
          "size": "29kb",
          "version": "v2"
        },
        {
          "date": "2024-05-08T05:50:53+00:00",
          "link": "https://arxiv.org/abs/2403.01658v3",
          "size": "30kb",
          "version": "v3"
        },
        {
          "date": "2025-05-09T04:04:37+00:00",
          "link": "https://arxiv.org/abs/2403.01658v4",
          "size": "30kb",
          "version": "v4"
        },
        {
          "date": "2025-07-03T04:34:04+00:00",
          "link": "https://arxiv.org/abs/2403.01658v5",
          "size": "30kb",
          "version": "v5"
        }
      ],
      "title": "Noise sensitivity on affine Weyl groups",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.01658",
        "HTML": "https://arxiv.org/html/2403.01658v5",
        "PDF": "https://arxiv.org/pdf/2403.01658"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses noise sensitivity on affine Weyl groups, with no mention of LLM training, data collection, or processing techniques pertinent to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2407.06902",
      "abstract": "One of the primary catalysts fueling advances in artificial intelligence (AI) and machine learning (ML) is the availability of massive, curated datasets. A commonly used technique to curate such massive datasets is crowdsourcing, where data are dispatched to multiple annotators. The annotator-produced labels are then fused to serve downstream learning and inference tasks. This annotation process often creates noisy labels due to various reasons, such as the limited expertise, or unreliability of annotators, among others. Therefore, a core objective in crowdsourcing is to develop methods that effectively mitigate the negative impact of such label noise on learning tasks. This feature article introduces advances in learning from noisy crowdsourced labels. The focus is on key crowdsourcing models and their methodological treatments, from classical statistical models to recent deep learning-based approaches, emphasizing analytical insights and algorithmic developments. In particular, this article reviews the connections between signal processing (SP) theory and methods, such as identifiability of tensor and nonnegative matrix factorization, and novel, principled solutions of longstanding challenges in crowdsourcing -- showing how SP perspectives drive the advancements of this field. Furthermore, this article touches upon emerging topics that are critical for developing cutting-edge AI/ML systems, such as crowdsourcing in reinforcement learning with human feedback (RLHF) and direct preference optimization (DPO) that are key techniques for fine-tuning large language models (LLMs).",
      "authors": [
        "Shahana Ibrahim",
        "Panagiotis A. Traganitis",
        "Xiao Fu",
        "Georgios B. Giannakis"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-09T14:34:40+00:00",
          "link": "https://arxiv.org/abs/2407.06902v1",
          "size": "3418kb",
          "version": "v1"
        },
        {
          "date": "2025-07-02T19:06:48+00:00",
          "link": "https://arxiv.org/abs/2407.06902v2",
          "size": "829kb",
          "version": "v2"
        }
      ],
      "title": "Learning From Crowdsourced Noisy Labels: A Signal Processing Perspective",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.06902",
        "HTML": "https://arxiv.org/html/2407.06902v2",
        "PDF": "https://arxiv.org/pdf/2407.06902"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses learning from noisy crowdsourced labels and touches upon fine-tuning LLMs with RLHF and DPO, which relates to training-stage data processing for LLMs, but it does not introduce new methods specifically for data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2407.16627",
      "abstract": "We show that two related classes of algorithms, stable algorithms and Boolean circuits with bounded depth, cannot produce an approximate sample from the uniform measure over the set of solutions to the symmetric binary perceptron model at any constraint-to-variable density. This result is in contrast to the question of finding \\emph{a} solution to the same problem, where efficient (and stable) algorithms are known to succeed at sufficiently low density. This result suggests that the solutions found efficiently -- whenever this task is possible -- must be highly atypical, and therefore provides an example of a problem where search is efficiently possible but approximate sampling from the set of solutions is not, at least within these two classes of algorithms.",
      "authors": [
        "Ahmed El Alaoui and David Gamarnik"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Probability (math.PR)",
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-23T16:37:58+00:00",
          "link": "https://arxiv.org/abs/2407.16627v1",
          "size": "19kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T16:00:09+00:00",
          "link": "https://arxiv.org/abs/2407.16627v2",
          "size": "20kb",
          "version": "v2"
        }
      ],
      "title": "Hardness of sampling solutions from the Symmetric Binary Perceptron",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.16627",
        "HTML": "https://arxiv.org/html/2407.16627v2",
        "PDF": "https://arxiv.org/pdf/2407.16627"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study discusses the complexity of sampling solutions in the Symmetric Binary Perceptron model, related to algorithmic theory rather than any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2408.04318",
      "abstract": "Incurable diseases continue to pose major challenges to global healthcare systems, with their prevalence shaped by lifestyle, economic, social, and genetic factors. Among these, kidney disease remains a critical global health issue, requiring ongoing research to improve early diagnosis and treatment. In recent years, deep learning (DL) has shown promise in medical imaging and diagnostics, driving significant progress in automatic kidney cancer (KC) detection. However, the success of DL models depends heavily on the availability of high-quality, domain-specific datasets, which are often limited and expensive to acquire. Moreover, DL models demand substantial computational power and storage, restricting their real-world clinical use. To overcome these barriers, transfer learning (TL) has emerged as an effective approach, enabling the reuse of pre-trained models from related domains to enhance KC diagnosis. This paper presents a comprehensive survey of DL-based TL frameworks for KC detection, systematically reviewing key methodologies, their advantages, and limitations, and analyzing their practical performance. It further discusses challenges in applying TL to medical imaging and highlights emerging trends that could influence future research. This review demonstrates the transformative role of TL in precision medicine, particularly oncology, by improving diagnostic accuracy, lowering computational demands, and supporting the integration of AI-powered tools in healthcare. The insights provided offer valuable guidance for researchers and practitioners, paving the way for future advances in KC diagnostics and personalized treatment strategies.",
      "authors": [
        "Yassine Habchi",
        "Hamza Kheddar",
        "Yassine Himeur",
        "Mohamed Chahine Ghanem",
        "Abdelkrim Boukabou",
        "Shadi Atalla",
        "Wathiq Mansoor and Hussain Al-Ahmad"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-08T08:52:29+00:00",
          "link": "https://arxiv.org/abs/2408.04318v1",
          "size": "10246kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T09:49:15+00:00",
          "link": "https://arxiv.org/abs/2408.04318v2",
          "size": "12241kb",
          "version": "v2"
        }
      ],
      "title": "Deep Transfer Learning for Kidney Cancer Diagnosis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.04318",
        "HTML": "https://arxiv.org/html/2408.04318v2",
        "PDF": "https://arxiv.org/pdf/2408.04318"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about using deep transfer learning for kidney cancer diagnosis and touches upon dataset limitations and transfer learning frameworks. It is not related to LLM training data processing."
      },
      "tasks": [
        "Diagnostic",
        "Transfer Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.07079",
      "abstract": "Deep Learning (DL) in neuroimaging has become increasingly relevant for detecting neurological conditions and neurodegenerative disorders. One of the most predominant biomarkers in neuroimaging is represented by brain age, which has been shown to be a good indicator for different conditions, such as Alzheimer's Disease. Using brain age for weakly supervised pre-training of DL models in transfer learning settings has also recently shown promising results, especially when dealing with data scarcity of different conditions. On the other hand, anatomical information of brain MRIs (e.g. cortical thickness) can provide important information for learning good representations that can be transferred to many downstream tasks. In this work, we propose AnatCL, an anatomical foundation model for brain MRIs that i.) leverages anatomical information in a weakly contrastive learning approach, and ii.) achieves state-of-the-art performances across many different downstream tasks. To validate our approach we consider 12 different downstream tasks for the diagnosis of different conditions such as Alzheimer's Disease, autism spectrum disorder, and schizophrenia. Furthermore, we also target the prediction of 10 different clinical assessment scores using structural MRI data. Our findings show that incorporating anatomical information during pre-training leads to more robust and generalizable representations. Pre-trained models can be found at: https://github.com/EIDOSLAB/AnatCL.",
      "authors": [
        "Carlo Alberto Barbano",
        "Matteo Brunello",
        "Benoit Dufumier",
        "Marco Grangetto"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-07T14:04:50+00:00",
          "link": "https://arxiv.org/abs/2408.07079v1",
          "size": "1966kb",
          "version": "v1"
        },
        {
          "date": "2024-11-05T19:44:03+00:00",
          "link": "https://arxiv.org/abs/2408.07079v2",
          "size": "1974kb",
          "version": "v2"
        },
        {
          "date": "2024-11-29T10:04:17+00:00",
          "link": "https://arxiv.org/abs/2408.07079v3",
          "size": "806kb",
          "version": "v3"
        },
        {
          "date": "2025-07-03T08:51:54+00:00",
          "link": "https://arxiv.org/abs/2408.07079v4",
          "size": "565kb",
          "version": "v4"
        }
      ],
      "title": "Anatomical Foundation Models for Brain MRIs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.07079",
        "HTML": "https://arxiv.org/html/2408.07079v4",
        "PDF": "https://arxiv.org/pdf/2408.07079"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper briefly discusses leveraging anatomical information during pre-training in a specific domain (brain MRIs) which is a type of data preparation for model training, but it does not focus on LLM training data processing."
      },
      "tasks": [
        "Contrastive Learning",
        "Transfer Learning"
      ],
      "repo_urls": [
        "https://github.com/eidoslab/anatcl"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.07386",
      "abstract": "Several topological and analytical notions of continuity and fading memory for causal and time-invariant filters are introduced, and the relations between them are analyzed. A significant generalization of the convolution theorem that establishes the equivalence between the fading memory property and the availability of convolution representations of linear filters is proved. This result extends a previous similar characterization to a complete array of weighted norms in the definition of the fading memory property. Additionally, the main theorem shows that the availability of convolution representations can be characterized, at least when the codomain is finite-dimensional, not only by the fading memory property but also by the reunion of two purely topological notions that are called minimal continuity and minimal fading memory property. Finally, when the input space and the codomain of a linear functional are Hilbert spaces, it is shown that minimal continuity and the minimal fading memory property guarantee the existence of interesting embeddings of the associated reproducing kernel Hilbert spaces.",
      "authors": [
        "Juan-Pablo Ortega and Florian Rossmannek"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Machine Learning (cs.LG)",
        "Functional Analysis (math.FA)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-14T09:06:25+00:00",
          "link": "https://arxiv.org/abs/2408.07386v1",
          "size": "26kb",
          "version": "v1"
        },
        {
          "date": "2025-02-28T10:56:33+00:00",
          "link": "https://arxiv.org/abs/2408.07386v2",
          "size": "30kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T12:08:58+00:00",
          "link": "https://arxiv.org/abs/2408.07386v3",
          "size": "30kb",
          "version": "v3"
        }
      ],
      "title": "Fading memory and the convolution theorem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.07386",
        "HTML": "https://arxiv.org/html/2408.07386v3",
        "PDF": "https://arxiv.org/pdf/2408.07386"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on topological and analytical notions of continuity and fading memory for linear filters, unrelated to any aspect of LLM training data collection or processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2409.03977",
      "abstract": "Recently, medical image synthesis gains more and more popularity, along with the rapid development of generative models. Medical image synthesis aims to generate an unacquired image modality, often from other observed data modalities. Synthesized images can be used for clinical diagnostic assistance, data augmentation for model training and validation or image quality improving. In the meanwhile, the flow-based models are among the successful generative models for the ability of generating realistic and high-quality synthetic images. However, most flow-based models require to calculate flow ordinary different equation (ODE) evolution steps in synthesis process, for which the performances are significantly limited by heavy computation time due to a large number of time iterations. In this paper, we propose a novel flow-based model, namely bi-directional Discrete Process Matching (Bi-DPM) to accomplish the bi-modality image synthesis tasks. Different to other flow matching based models, we propose to utilize both forward and backward ODE flows and enhance the consistency on the intermediate images over a few discrete time steps, resulting in a synthesis process maintaining high-quality generations for both modalities under the guidance of paired data. Our experiments on three datasets of MRI T1/T2 and CT/MRI demonstrate that Bi-DPM outperforms other state-of-the-art flow-based methods for bi-modality image synthesis, delivering higher image quality with accurate anatomical regions.",
      "authors": [
        "Zhe Xiong",
        "Qiaoqiao Ding",
        "Xiaoqun Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-06T01:54:35+00:00",
          "link": "https://arxiv.org/abs/2409.03977v1",
          "size": "13789kb",
          "version": "v1"
        },
        {
          "date": "2024-09-23T10:17:45+00:00",
          "link": "https://arxiv.org/abs/2409.03977v2",
          "size": "0kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T02:25:06+00:00",
          "link": "https://arxiv.org/abs/2409.03977v3",
          "size": "9333kb",
          "version": "v3"
        }
      ],
      "title": "Bi-modality medical images synthesis by a bi-directional discrete process matching method",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.03977",
        "PDF": "https://arxiv.org/pdf/2409.03977"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on bi-modality medical image synthesis techniques, without reference to LLM training data processing methods."
      },
      "tasks": [
        "Data Augmentation",
        "Diagnostic",
        "Image Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.15582",
      "abstract": "Machine learning models are often brittle under distribution shift, i.e., when data distributions at test time differ from those during training. Understanding this failure mode is central to identifying and mitigating safety risks of mass adoption of machine learning. Here we analyze ridge regression under concept shift -- a form of distribution shift in which the input-label relationship changes at test time. We derive an exact expression for prediction risk in the thermodynamic limit. Our results reveal nontrivial effects of concept shift on generalization performance, including a phase transition between weak and strong concept shift regimes and nonmonotonic data dependence of test performance even when double descent is absent. Our theoretical results are in good agreement with experiments based on transformers pretrained to solve linear regression; under concept shift, too long context length can be detrimental to generalization performance of next token prediction. Finally, our experiments on MNIST and FashionMNIST suggest that this intriguing behavior is present also in classification problems.",
      "authors": [
        "Alex Nguyen",
        "David J. Schwab",
        "Vudtiwat Ngampruetikorn"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
        "Statistical Mechanics (cond-mat.stat-mech)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-23T22:30:28+00:00",
          "link": "https://arxiv.org/abs/2409.15582v1",
          "size": "683kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T05:05:13+00:00",
          "link": "https://arxiv.org/abs/2409.15582v2",
          "size": "1203kb",
          "version": "v2"
        }
      ],
      "title": "Generalization vs. Specialization under Concept Shift",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.15582",
        "HTML": "https://arxiv.org/html/2409.15582v2",
        "PDF": "https://arxiv.org/pdf/2409.15582"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper examines the effects of concept shift on generalization performance in machine learning, specifically relating to ridge regression and transformer models, without addressing LLM training data processes."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2410.00903",
      "abstract": "In this paper, we demonstrate how to enhance the validity of causal inference with unstructured high-dimensional treatments like texts, by leveraging the power of generative Artificial Intelligence (GenAI). Specifically, we propose to use a deep generative model such as large language models (LLMs) to efficiently generate treatments and use their internal representation for subsequent causal effect estimation. We show that the knowledge of this true internal representation helps disentangle the treatment features of interest, such as specific sentiments and certain topics, from other possibly unknown confounding features. Unlike existing methods, the proposed GenAI-Powered Inference (GPI) methodology eliminates the need to learn causal representation from the data, and hence produces more accurate and efficient estimates. We formally establish the conditions required for the nonparametric identification of the average treatment effect, propose an estimation strategy that avoids the violation of the overlap assumption, and derive the asymptotic properties of the proposed estimator through the application of double machine learning. Finally, using an instrumental variables approach, we extend the proposed methodology to the settings in which the treatment feature is based on human perception. The proposed GPI methodology is also applicable to text reuse where an LLM is used to regenerate existing texts. We conduct simulation and empirical studies, using the generated text data from an open-source LLM, Llama 3, to illustrate the advantages of our estimator over state-of-the-art causal representation learning algorithms.",
      "authors": [
        "Kosuke Imai",
        "Kentaro Nakamura"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Applications (stat.AP)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-01T17:46:21+00:00",
          "link": "https://arxiv.org/abs/2410.00903v1",
          "size": "1367kb",
          "version": "v1"
        },
        {
          "date": "2024-11-22T16:31:25+00:00",
          "link": "https://arxiv.org/abs/2410.00903v2",
          "size": "4228kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T03:31:52+00:00",
          "link": "https://arxiv.org/abs/2410.00903v3",
          "size": "1282kb",
          "version": "v3"
        }
      ],
      "title": "Causal Representation Learning with Generative Artificial Intelligence: Application to Texts as Treatments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.00903",
        "HTML": "https://arxiv.org/html/2410.00903v3",
        "PDF": "https://arxiv.org/pdf/2410.00903"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper mentions using LLMs for generating treatments, it focuses on causal inference and representation learning with generative AI, rather than detailed LLM training data processing or construction."
      },
      "tasks": [
        "Causal Inference",
        "Representation Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.19075",
      "abstract": "This paper addresses the problem of parallelizing computations to study non-linear dynamics in large networks of non-locally coupled oscillators using heterogeneous computing resources. The proposed approach can be applied to a variety of non-linear dynamics models with runtime specification of parameters and network topologies. Parallelizing the solution of equations for different network elements is performed transparently and, in contrast to available tools, does not require parallel programming from end-users. The runtime scheduler takes into account the performance of computing and communication resources to reduce downtime and to achieve a quasi-optimal parallelizing speed-up. The proposed approach was implemented, and its efficiency is proven by numerous applications for simulating large dynamical networks with 10^3-10^8 elements described by Hodgkin-Huxley, FitzHugh-Nagumo, and Kuramoto models, for investigating pathological synchronization during Parkinson's disease, analyzing multi-stability, for studying chimera and solitary states in 3D networks, etc. All the above computations may be performed using symmetrical multiprocessors, graphic processing units, and a network of workstations within the same run and it was demonstrated that near-linear speed-up can be achieved for large networks. The proposed approach is promising for extension to new hardware like edge-computing devices.",
      "authors": [
        "Oleksandr Sudakov and Volodymyr Maistrenko"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Chaotic Dynamics (nlin.CD)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Pattern Formation and Solitons (nlin.PS)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-24T18:32:04+00:00",
          "link": "https://arxiv.org/abs/2410.19075v1",
          "size": "2751kb",
          "version": "v1"
        },
        {
          "date": "2025-07-02T18:41:43+00:00",
          "link": "https://arxiv.org/abs/2410.19075v2",
          "size": "3092kb",
          "version": "v2"
        }
      ],
      "title": "Parallelization of Network Dynamics Computations in Heterogeneous Distributed Environment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.19075",
        "PDF": "https://arxiv.org/pdf/2410.19075"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses parallelizing network dynamics computations, which is outside the scope of LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.10860",
      "abstract": "Many computational problems can be modelled as the class of all finite structures $\\mathbb A$ that satisfy a fixed first-order sentence $\\phi$ hereditarily, i.e., we require that every (induced) substructure of $\\mathbb A$ satisfies $\\phi$. We call the corresponding computational problem the hereditary model checking problem for $\\phi$, and denote it by Her$(\\phi)$.\n  We present a complete description of the quantifier prefixes for $\\phi$ such that Her$(\\phi)$ is in P; we show that for every other quantifier prefix there exists a formula $\\phi$ with this prefix such that Her$(\\phi)$ is coNP-complete. Specifically, we show that if $Q$ is of the form $\\forall^\\ast\\exists\\forall^\\ast$ or of the form $\\forall^\\ast\\exists^\\ast$, then Her$(\\phi)$ can be solved in polynomial time whenever the quantifier prefix of $\\phi$ is $Q$. Otherwise, $Q$ contains $\\exists \\exists \\forall$ or $\\exists \\forall \\exists$ as a subword, and in this case, there is a first-order formula $\\phi$ whose quantifier prefix is $Q$ and Her$(\\phi)$ is coNP-complete. Moreover, we show that there is no algorithm that decides for a given first-order formula $\\phi$ whether Her$(\\phi)$ is in P (unless P$=$NP).",
      "authors": [
        "Manuel Bodirsky and Santiago Guzm\\'an-Pro"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Logic (math.LO)",
        "Computational Complexity (cs.CC)",
        "Discrete Mathematics (cs.DM)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-16T18:50:15+00:00",
          "link": "https://arxiv.org/abs/2411.10860v1",
          "size": "79kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T08:14:16+00:00",
          "link": "https://arxiv.org/abs/2411.10860v2",
          "size": "27kb",
          "version": "v2"
        }
      ],
      "title": "Hereditary First-Order Logic: the tractable quantifier prefix classes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.10860",
        "HTML": "https://arxiv.org/html/2411.10860v2",
        "PDF": "https://arxiv.org/pdf/2411.10860"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper provides a theoretical exploration of first-order logic for model checking problems, which is unrelated to any practical aspects of LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.18339",
      "abstract": "We propose a natural intrinsic extension of the ridge regression from Euclidean spaces to general manifolds, which relies on Riemannian least-squares fitting, empirical covariance, and Mahalanobis distance. We utilize it for time-series prediction and apply the approach to forecast hurricane tracks and their wind speeds.",
      "authors": [
        "Esfandiar Nava-Yazdani"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Differential Geometry (math.DG)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)",
        "Applications (stat.AP)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-27T13:36:43+00:00",
          "link": "https://arxiv.org/abs/2411.18339v1",
          "size": "787kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T15:03:23+00:00",
          "link": "https://arxiv.org/abs/2411.18339v2",
          "size": "661kb",
          "version": "v2"
        }
      ],
      "title": "Ridge Regression for Manifold-valued Time-Series with Application to Meteorological Forecast",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.18339",
        "HTML": "https://arxiv.org/html/2411.18339v2",
        "PDF": "https://arxiv.org/pdf/2411.18339"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper extends ridge regression to manifolds for time-series prediction, which is unrelated to any LLM training data tasks."
      },
      "tasks": [
        "regression",
        "Time Series",
        "Time Series Prediction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.18849",
      "abstract": "This paper investigates logical consequence defined in terms of probability distributions, for a classical propositional language using a standard notion of probability. We examine three distinct probabilistic consequence notions, which we call material consequence, preservation consequence, and symmetric consequence. While material consequence is fully classical for any threshold, preservation consequence and symmetric consequence are subclassical, with only symmetric consequence gradually approaching classical logic at the limit threshold equal to 1. Our results extend earlier results obtained by J. Paris in a SET-FMLA setting to the SET-SET setting, and consider open thresholds beside closed ones. In the SET-SET setting, in particular, they reveal that probability 1 preservation does not yield classical logic, but supervaluationism, and conversely positive probability preservation yields subvaluationism.",
      "authors": [
        "Paul \\'Egr\\'e and Ellie Ripley"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Logic (math.LO)",
        "Logic in Computer Science (cs.LO)",
        "Probability (math.PR)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-28T01:32:22+00:00",
          "link": "https://arxiv.org/abs/2411.18849v1",
          "size": "34kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T02:18:42+00:00",
          "link": "https://arxiv.org/abs/2411.18849v2",
          "size": "34kb",
          "version": "v2"
        }
      ],
      "title": "Probabilistic consequence relations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.18849",
        "HTML": "https://arxiv.org/html/2411.18849v2",
        "PDF": "https://arxiv.org/pdf/2411.18849"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses probabilistic consequence relations in logic and does not mention or address LLM training data processing or data engineering stages."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.06946",
      "abstract": "Gravitational-wave approximants are essential for gravitational-wave astronomy, allowing the coverage binary black hole parameter space for inference or match filtering without costly numerical relativity (NR) simulations, but generally trading some accuracy for computational efficiency. To reduce this trade-off, NR surrogate models can be constructed using interpolation within NR waveform space. We present a 2-stage training approach for neural network-based NR surrogate models. Initially trained on approximant-generated waveforms and then fine-tuned with NR data, these dual-stage artificial neural surrogate (\\texttt{DANSur}) models offer rapid and competitively accurate waveform generation, generating millions in under 20ms on a GPU while keeping mean mismatches with NR around $10^{-4}$. Implemented in the \\textsc{bilby} framework, we show they can be used for parameter estimation tasks.",
      "authors": [
        "Osvaldo Gramaxo Freitas",
        "Anastasios Theodoropoulos",
        "Nino Villanueva",
        "Tiago Fernandes",
        "Solange Nunes",
        "Jos\\'e A. Font",
        "Antonio Onofre",
        "Alejandro Torres-Forn\\'e",
        "Jos\\'e D. Martin-Guerrero"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "General Relativity and Quantum Cosmology (gr-qc)",
        "High Energy Astrophysical Phenomena (astro-ph.HE)",
        "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-09T19:45:30+00:00",
          "link": "https://arxiv.org/abs/2412.06946v1",
          "size": "2322kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T08:56:15+00:00",
          "link": "https://arxiv.org/abs/2412.06946v2",
          "size": "4009kb",
          "version": "v2"
        }
      ],
      "title": "A Deep Learning Powered Numerical Relativity Surrogate for Binary Black Hole Waveforms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.06946",
        "HTML": "https://arxiv.org/html/2412.06946v2",
        "PDF": "https://arxiv.org/pdf/2412.06946"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a neural network-based surrogate model for generating gravitational waveforms, which does not pertain to LLM training data processing."
      },
      "tasks": [
        "Astronomy",
        "parameter estimation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.08589",
      "abstract": "The Solar Ultraviolet Imaging Telescope(SUIT) onboard Aditya-L1 is an imager that observes the solar photosphere and chromosphere through observations in the wavelength range of 200-400 nm. A comprehensive understanding of the plasma and thermodynamic properties of chromospheric and photospheric morphological structures requires a large sample statistical study, necessitating the development of automatic feature detection methods. To this end, we develop the feature detection algorithm SPACE-SUIT: Solar Phenomena Analysis and Classification using Enhanced vision techniques for SUIT, to detect and classify the solar chromospheric features to be observed from SUIT's Mg II k filter. Specifically, we target plage regions, sunspots, filaments, and off-limb structures. SPACE uses YOLO, a neural network-based model to identify regions of interest. We train and validate SPACE using mock-SUIT images developed from Interface Region Imaging Spectrometer(IRIS) full-disk mosaic images in Mg II k line, while we also perform detection on Level-1 SUIT data. SPACE achieves an approximate precision of 0.788, recall 0.863 and MAP of 0.874 on the validation mock SUIT FITS dataset. Given the manual labeling of our dataset, we perform \"self-validation\" by applying statistical measures and Tamura features on the ground truth and predicted bounding boxes. We find the distributions of entropy, contrast, dissimilarity, and energy to show differences in the features. These differences are qualitatively captured by the detected regions predicted by SPACE and validated with the observed SUIT images, even in the absence of labeled ground truth. This work not only develops a chromospheric feature extractor but also demonstrates the effectiveness of statistical metrics and Tamura features for distinguishing chromospheric features, offering independent validation for future detection schemes.",
      "authors": [
        "Pranava Seth",
        "Vishal Upendran",
        "Megha Anand",
        "Janmejoy Sarkar",
        "Soumya Roy",
        "Priyadarshan Chaki",
        "Pratyay Chowdhury",
        "Borishan Ghosh",
        "Durgesh Tripathi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Solar and Stellar Astrophysics (astro-ph.SR)",
        "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-11T18:08:06+00:00",
          "link": "https://arxiv.org/abs/2412.08589v1",
          "size": "17306kb",
          "version": "v1"
        },
        {
          "date": "2025-07-02T18:01:19+00:00",
          "link": "https://arxiv.org/abs/2412.08589v2",
          "size": "20855kb",
          "version": "v2"
        }
      ],
      "title": "SPACE-SUIT: An Artificial Intelligence Based Chromospheric Feature Extractor and Classifier for SUIT",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.08589",
        "HTML": "https://arxiv.org/html/2412.08589v2",
        "PDF": "https://arxiv.org/pdf/2412.08589"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes an AI-based algorithm for feature extraction from solar images, which is not relevant to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2412.11554",
      "abstract": "Graphical model estimation from multi-omics data requires a balance between statistical estimation performance and computational scalability. We introduce a novel pseudolikelihood-based graphical model framework that reparameterizes the target precision matrix while preserving the sparsity pattern and estimates it by minimizing an $\\ell_1$-penalized empirical risk based on a new loss function. The proposed estimator maintains estimation and selection consistency in various metrics under high-dimensional assumptions. The associated optimization problem allows for a provably fast computation algorithm using a novel operator-splitting approach and communication-avoiding distributed matrix multiplication. A high-performance computing implementation of our framework was tested using simulated data with up to one million variables, demonstrating complex dependency structures similar to those found in biological networks. Leveraging this scalability, we estimated a partial correlation network from a dual-omic liver cancer data set. The co-expression network estimated from the ultrahigh-dimensional data demonstrated superior specificity in prioritizing key transcription factors and co-activators by excluding the impact of epigenetic regulation, thereby highlighting the value of computational scalability in multi-omic data analysis.",
      "authors": [
        "Sungdong Lee",
        "Joshua Bang",
        "Youngrae Kim",
        "Hyungwon Choi",
        "Sang-Yun Oh",
        "Joong-Ho Won"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Statistics Theory (math.ST)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-16T08:38:02+00:00",
          "link": "https://arxiv.org/abs/2412.11554v1",
          "size": "3102kb",
          "version": "v1"
        },
        {
          "date": "2024-12-20T17:56:10+00:00",
          "link": "https://arxiv.org/abs/2412.11554v2",
          "size": "3052kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T09:46:23+00:00",
          "link": "https://arxiv.org/abs/2412.11554v3",
          "size": "2333kb",
          "version": "v3"
        }
      ],
      "title": "Learning Massive-scale Partial Correlation Networks in Clinical Multi-omics Studies with HP-ACCORD",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.11554",
        "HTML": "https://arxiv.org/html/2412.11554v3",
        "PDF": "https://arxiv.org/pdf/2412.11554"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a method for graphical model estimation in multi-omics studies, which does not pertain to LLM training data or preprocessing tasks."
      },
      "tasks": [
        "Specificity"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.21171",
      "abstract": "Recent progress in quantum computing has enabled systems with tens of reliable logical qubits, built from thousands of noisy physical qubits. However, many impactful applications demand quantum computations with millions of logical qubits, necessitating highly scalable quantum error correction. In classical information theory, low-density parity-check (LDPC) codes can approach channel capacity efficiently. Yet, no quantum error-correcting codes with efficient decoding have been shown to approach the hashing bound - a fundamental limit on quantum capacity - despite decades of research. Here, we present quantum LDPC codes that not only approach the hashing bound but also allow decoding with computational cost linear in the number of physical qubits. This breakthrough paves the way for large-scale, fault-tolerant quantum computation. Combined with emerging hardware that manages many qubits, our approach brings quantum solutions to important real-world problems significantly closer to reality.",
      "authors": [
        "Daiki Komoto and Kenta Kasai"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-30T18:48:54+00:00",
          "link": "https://arxiv.org/abs/2412.21171v1",
          "size": "1896kb",
          "version": "v1"
        },
        {
          "date": "2025-01-23T17:49:13+00:00",
          "link": "https://arxiv.org/abs/2412.21171v2",
          "size": "1896kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T17:36:07+00:00",
          "link": "https://arxiv.org/abs/2412.21171v3",
          "size": "147kb",
          "version": "v3"
        }
      ],
      "title": "Quantum Error Correction near the Coding Theoretical Bound",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.21171",
        "HTML": "https://arxiv.org/html/2412.21171v3",
        "PDF": "https://arxiv.org/pdf/2412.21171"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research on quantum error correction and quantum LDPC codes does not involve processing training data for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.03383",
      "abstract": "Increasing HPC cluster sizes and large-scale simulations that produce petabytes of data per run, create massive IO and storage challenges for analysis. Deep learning-based techniques, in particular, make use of these amounts of domain data to extract patterns that help build scientific understanding. Here, we demonstrate a streaming workflow in which simulation data is streamed directly to a machine-learning (ML) framework, circumventing the file system bottleneck. Data is transformed in transit, asynchronously to the simulation and the training of the model. With the presented workflow, data operations can be performed in common and easy-to-use programming languages, freeing the application user from adapting the application output routines. As a proof-of-concept we consider a GPU accelerated particle-in-cell (PIConGPU) simulation of the Kelvin- Helmholtz instability (KHI). We employ experience replay to avoid catastrophic forgetting in learning from this non-steady process in a continual manner. We detail challenges addressed while porting and scaling to Frontier exascale system.",
      "authors": [
        "Jeffrey Kelling",
        "Vicente Bolea",
        "Michael Bussmann",
        "Ankush Checkervarty",
        "Alexander Debus",
        "Jan Ebert",
        "Greg Eisenhauer",
        "Vineeth Gutta",
        "Stefan Kesselheim",
        "Scott Klasky",
        "Vedhas Pandit",
        "Richard Pausch",
        "Norbert Podhorszki",
        "Franz Poschel",
        "David Rogers",
        "Jeyhun Rustamov",
        "Steve Schmerler",
        "Ulrich Schramm",
        "Klaus Steiniger",
        "Rene Widera",
        "Anna Willmann",
        "Sunita Chandrasekaran"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computational Physics (physics.comp-ph)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-06T20:58:27+00:00",
          "link": "https://arxiv.org/abs/2501.03383v1",
          "size": "3318kb",
          "version": "v1"
        },
        {
          "date": "2025-01-15T19:16:18+00:00",
          "link": "https://arxiv.org/abs/2501.03383v2",
          "size": "3319kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T08:40:46+00:00",
          "link": "https://arxiv.org/abs/2501.03383v3",
          "size": "2642kb",
          "version": "v3"
        }
      ],
      "title": "The Artificial Scientist -- in-transit Machine Learning of Plasma Simulations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.03383",
        "HTML": "https://arxiv.org/html/2501.03383v3",
        "PDF": "https://arxiv.org/pdf/2501.03383"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses machine learning applications in processing data from plasma simulations, which is not related to the training data processing for LLMs."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2501.03821",
      "abstract": "Regularized models are often sensitive to the scales of the features in the data and it has therefore become standard practice to normalize (center and scale) the features before fitting the model. But there are many different ways to normalize the features and the choice may have dramatic effects on the resulting model. In spite of this, there has so far been no research on this topic. In this paper, we begin to bridge this knowledge gap by studying normalization in the context of lasso, ridge, and elastic net regression. We focus on binary features and show that their class balances (proportions of ones) directly influences the regression coefficients and that this effect depends on the combination of normalization and regularization methods used. We demonstrate that this effect can be mitigated by scaling binary features with their variance in the case of the lasso and standard deviation in the case of ridge regression, but that this comes at the cost of increased variance of the coefficient estimates. For the elastic net, we show that scaling the penalty weights, rather than the features, can achieve the same effect. Finally, we also tackle mixes of binary and normal features as well as interactions and provide some initial results on how to normalize features in these cases.",
      "authors": [
        "Johan Larsson and Jonas Wallin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Methodology (stat.ME)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-07T14:35:09+00:00",
          "link": "https://arxiv.org/abs/2501.03821v1",
          "size": "12706kb",
          "version": "v1"
        },
        {
          "date": "2025-01-21T18:42:42+00:00",
          "link": "https://arxiv.org/abs/2501.03821v2",
          "size": "13130kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T10:16:05+00:00",
          "link": "https://arxiv.org/abs/2501.03821v3",
          "size": "9154kb",
          "version": "v3"
        }
      ],
      "title": "The Choice of Normalization Influences Shrinkage in Regularized Regression",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.03821",
        "HTML": "https://arxiv.org/html/2501.03821v3",
        "PDF": "https://arxiv.org/pdf/2501.03821"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the choice of normalization methods in regularized regression, such as lasso and ridge, with no connection to LLMs or their training data processing."
      },
      "tasks": [
        "regression"
      ],
      "repo_urls": [
        "https://github.com/jolars/normreg"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.05007",
      "abstract": "The discovery of causal relations from observed data has attracted significant interest from disciplines such as economics, social sciences, and biology. In practical applications, considerable knowledge of the underlying systems is often unavailable, and real data are usually associated with nonlinear causal structures, which makes the direct use of most conventional causality analysis methods difficult. This study proposes a novel quantum Peter-Clark (qPC) algorithm for causal discovery that does not require any assumptions about the underlying model structures. Based on conditional independence tests in a class of reproducing kernel Hilbert spaces characterized by quantum circuits, the proposed algorithm can explore causal relations from the observed data drawn from arbitrary distributions. We conducted systematic experiments on fundamental graphs of causal structures, demonstrating that the qPC algorithm exhibits better performance, particularly with smaller sample sizes compared to its classical counterpart. Furthermore, we proposed a novel optimization approach based on Kernel Target Alignment (KTA) for determining hyperparameters of quantum kernels. This method effectively reduced the risk of false positives in causal discovery, enabling more reliable inference. Our theoretical and experimental results demonstrate that the quantum algorithm can empower classical algorithms for accurate inference in causal discovery, supporting them in regimes where classical algorithms typically fail. In addition, the effectiveness of this method was validated using the datasets on Boston housing prices, heart disease, and biological signaling systems as real-world applications. These findings highlight the potential of quantum-based causal discovery methods in addressing practical challenges, particularly in small-sample scenarios, where traditional approaches have shown significant limitations.",
      "authors": [
        "Yu Terada",
        "Ken Arai",
        "Yu Tanaka",
        "Yota Maeda",
        "Hiroshi Ueno",
        "Hiroyuki Tezuka"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Methodology (stat.ME)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-09T07:05:22+00:00",
          "link": "https://arxiv.org/abs/2501.05007v1",
          "size": "2181kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T09:15:45+00:00",
          "link": "https://arxiv.org/abs/2501.05007v2",
          "size": "3945kb",
          "version": "v2"
        }
      ],
      "title": "Quantum-enhanced causal discovery for a small number of samples",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.05007",
        "HTML": "https://arxiv.org/html/2501.05007v2",
        "PDF": "https://arxiv.org/pdf/2501.05007"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study focuses on causal discovery using a quantum algorithm, which does not concern processing training data for LLMs directly."
      },
      "tasks": [
        "Causal Discovery",
        "Epidemiology"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.17772",
      "abstract": "Recent developments in Self-Supervised Learning (SSL) have demonstrated significant potential for Speaker Verification (SV), but closing the performance gap with supervised systems remains an ongoing challenge. SSL frameworks rely on anchor-positive pairs, constructed from segments of the same audio utterance. Hence, positives have channel characteristics similar to those of their corresponding anchors, even with extensive data-augmentation. Therefore, this positive sampling strategy is a fundamental limitation as it encodes too much information regarding the recording source in the learned representations. This article introduces Self-Supervised Positive Sampling (SSPS), a bootstrapped technique for sampling appropriate and diverse positives in SSL frameworks for SV. SSPS samples positives close to their anchor in the representation space, assuming that these pseudo-positives belong to the same speaker identity but correspond to different recording conditions. This method consistently demonstrates improvements in SV performance on VoxCeleb benchmarks when applied to major SSL frameworks, including SimCLR, SwAV, VICReg, and DINO. Using SSPS, SimCLR and DINO achieve 2.57% and 2.53% EER on VoxCeleb1-O, respectively. SimCLR yields a 58% relative reduction in EER, getting comparable performance to DINO with a simpler training framework. Furthermore, SSPS lowers intra-class variance and reduces channel information in speaker representations while exhibiting greater robustness without data-augmentation.",
      "authors": [
        "Theo Lepage",
        "Reda Dehak"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Machine Learning (cs.LG)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-29T17:08:01+00:00",
          "link": "https://arxiv.org/abs/2501.17772v1",
          "size": "1415kb",
          "version": "v1"
        },
        {
          "date": "2025-05-20T16:14:45+00:00",
          "link": "https://arxiv.org/abs/2501.17772v2",
          "size": "2499kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T10:38:50+00:00",
          "link": "https://arxiv.org/abs/2501.17772v3",
          "size": "1714kb",
          "version": "v3"
        }
      ],
      "title": "Self-Supervised Frameworks for Speaker Verification via Bootstrapped Positive Sampling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.17772",
        "HTML": "https://arxiv.org/html/2501.17772v3",
        "PDF": "https://arxiv.org/pdf/2501.17772"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a self-supervised learning framework for speaker verification and does not relate to LLM training data processing or engineering."
      },
      "tasks": [
        "Data Augmentation",
        "Self-Supervised Learning",
        "Speaker Verification"
      ],
      "repo_urls": [
        "https://github.com/theolepage/sslsv"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.17597",
      "abstract": "We parametrically solve the Boltzmann equations governing freeze-in dark matter (DM) in alternative cosmologies with Physics-Informed Neural Networks (PINNs), a mesh-free method. Through inverse PINNs, using a single DM experimental point -- observed relic density -- we determine the physical attributes of the theory, namely power-law cosmologies, inspired by braneworld scenarios, and particle interaction cross sections. The expansion of the Universe in such alternative cosmologies has been parameterized through a switch-like function reproducing the Hubble law at later times. Without loss of generality, we model more realistically this transition with a smooth function. We predict a distinct pair-wise relationship between power-law exponent and particle interactions: for a given cosmology with negative (positive) exponent, smaller (larger) cross sections are required to reproduce the data. Lastly, via Bayesian methods, we quantify the epistemic uncertainty of theoretical parameters found in inverse problems.",
      "authors": [
        "M.P. Bento",
        "H.B. C\\^amara",
        "J.F. Seabra"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "High Energy Physics - Phenomenology (hep-ph)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-24T19:27:33+00:00",
          "link": "https://arxiv.org/abs/2502.17597v1",
          "size": "5176kb",
          "version": "v1"
        },
        {
          "date": "2025-07-02T18:41:25+00:00",
          "link": "https://arxiv.org/abs/2502.17597v2",
          "size": "5226kb",
          "version": "v2"
        }
      ],
      "title": "Unraveling particle dark matter with Physics-Informed Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.17597",
        "HTML": "https://arxiv.org/html/2502.17597v2",
        "PDF": "https://arxiv.org/pdf/2502.17597"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses using Physics-Informed Neural Networks for solving cosmological equations, which is unrelated to LLM training data processing or engineering."
      },
      "repo_urls": [
        "https://github.com/MPedraBento/pinn-freeze-in"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.05802",
      "abstract": "Illumination estimation remains a pivotal challenge in image processing, particularly for robotics, where robust environmental perception is essential under varying lighting conditions. Traditional approaches, such as RGB histograms and GIST descriptors, often fail in complex scenarios due to their sensitivity to illumination changes. This study introduces a novel method utilizing the Wasserstein distance, rooted in optimal transport theory, to estimate illuminant and light direction in images. Experiments on diverse images indoor scenes, black-and-white photographs, and night images demonstrate the method's efficacy in detecting dominant light sources and estimating their directions, outperforming traditional statistical methods in complex lighting environments. The approach shows promise for applications in light source localization, image quality assessment, and object detection enhancement. Future research may explore adaptive thresholding and integrate gradient analysis to enhance accuracy, offering a scalable solution for real-world illumination challenges in robotics and beyond.",
      "authors": [
        "Selcuk Yazar"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-03T19:20:09+00:00",
          "link": "https://arxiv.org/abs/2503.05802v1",
          "size": "1258kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T07:28:48+00:00",
          "link": "https://arxiv.org/abs/2503.05802v2",
          "size": "1256kb",
          "version": "v2"
        }
      ],
      "title": "Illuminant and light direction estimation using Wasserstein distance method",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.05802",
        "PDF": "https://arxiv.org/pdf/2503.05802"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a method for estimating lighting in images, which is related to image processing and does not discuss LLM data processing or training related tasks."
      },
      "tasks": [
        "Image Quality Assessment",
        "object-detection",
        "Object Detection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.17089",
      "abstract": "Artificial intelligence (AI) is increasingly being used for medical imaging tasks. However, there can be biases in AI models, particularly when they are trained using imbalanced training datasets. One such example has been the strong ethnicity bias effect in cardiac magnetic resonance (CMR) image segmentation models. Although this phenomenon has been reported in a number of publications, little is known about the effectiveness of bias mitigation algorithms in this domain. We aim to investigate the impact of common bias mitigation methods to address bias between Black and White subjects in AI-based CMR segmentation models. Specifically, we use oversampling, importance reweighing and Group DRO as well as combinations of these techniques to mitigate the ethnicity bias. Second, motivated by recent findings on the root causes of AI-based CMR segmentation bias, we evaluate the same methods using models trained and evaluated on cropped CMR images. We find that bias can be mitigated using oversampling, significantly improving performance for the underrepresented Black subjects whilst not significantly reducing the majority White subjects' performance. Using cropped images increases performance for both ethnicities and reduces the bias, whilst adding oversampling as a bias mitigation technique with cropped images reduces the bias further. When testing the models on an external clinical validation set, we find high segmentation performance and no statistically significant bias.",
      "authors": [
        "Tiarna Lee",
        "Esther Puyol-Ant\\'on",
        "Bram Ruijsink",
        "Pier-Giorgio Masci",
        "Louise Keehn",
        "Phil Chowienczyk",
        "Emily Haseler",
        "Miaojing Shi",
        "Andrew P. King"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-21T12:17:43+00:00",
          "link": "https://arxiv.org/abs/2503.17089v1",
          "size": "608kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T12:11:58+00:00",
          "link": "https://arxiv.org/abs/2503.17089v2",
          "size": "601kb",
          "version": "v2"
        }
      ],
      "title": "Understanding-informed Bias Mitigation for Fair CMR Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.17089",
        "HTML": "https://arxiv.org/html/2503.17089v2",
        "PDF": "https://arxiv.org/pdf/2503.17089"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The study addresses bias mitigation in AI models for medical imaging. Though it discusses dataset handling (e.g., oversampling), it does not focus on LLM training data processing techniques."
      },
      "tasks": [
        "All",
        "Image Segmentation",
        "Semantic Segmentation"
      ],
      "repo_urls": [
        "https://github.com/tiarnaleeKCL/nnUNet-bias-mitigation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.00494",
      "abstract": "Flow Matching (FM) is a recent generative modelling technique: we aim to learn how to sample from distribution $\\mathfrak{X}_1$ by flowing samples from some distribution $\\mathfrak{X}_0$ that is easy to sample from. The key trick is that this flow field can be trained while conditioning on the end point in $\\mathfrak{X}_1$: given an end point, simply move along a straight line segment to the end point (Lipman et al. 2022). However, straight line segments are only well-defined on Euclidean space. Consequently, Chen and Lipman (2023) generalised the method to FM on Riemannian manifolds, replacing line segments with geodesics or their spectral approximations. We take an alternative point of view: we generalise to FM on Lie groups by instead substituting exponential curves for line segments. This leads to a simple, intrinsic, and fast implementation for many matrix Lie groups, since the required Lie group operations (products, inverses, exponentials, logarithms) are simply given by the corresponding matrix operations. FM on Lie groups could then be used for generative modelling with data consisting of sets of features (in $\\mathbb{R}^n$) and poses (in some Lie group), e.g. the latent codes of Equivariant Neural Fields (Wessels et al. 2025).",
      "authors": [
        "Finn M. Sherry and Bart M.N. Smets"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Differential Geometry (math.DG)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-01T07:35:46+00:00",
          "link": "https://arxiv.org/abs/2504.00494v1",
          "size": "1672kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T12:03:48+00:00",
          "link": "https://arxiv.org/abs/2504.00494v2",
          "size": "1654kb",
          "version": "v2"
        }
      ],
      "title": "Flow Matching on Lie Groups",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.00494",
        "HTML": "https://arxiv.org/html/2504.00494v2",
        "PDF": "https://arxiv.org/pdf/2504.00494"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses flow matching in Lie groups for generative modeling, without any mention of LLM training data processing or data engineering tasks."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/finnsherry/FlowMatching"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.03031",
      "abstract": "Neuronal circuits of the cerebral cortex are the structural basis of mammalian cognition. The same qualitative components and connectivity motifs are repeated across functionally specialized cortical areas and mammalian species, suggesting a single underlying algorithmic motif. Here, we propose a perspective on current knowledge of the cortical structure, from which we extract two core principles for computational modeling. The first principle is that cortical cell types fulfill distinct computational roles. The second principle is that cortical connectivity can be efficiently characterized by only a few canonical blueprints of connectivity between cell types. Starting with these two foundational principles, we outline a general framework for building functional and mechanistic models of cortical circuits.",
      "authors": [
        "Arno Granier and Katharina A Wilmes and Mihai A Petrovici and Walter Senn"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Neurons and Cognition (q-bio.NC)",
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-03T21:08:12+00:00",
          "link": "https://arxiv.org/abs/2504.03031v1",
          "size": "3475kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T10:31:41+00:00",
          "link": "https://arxiv.org/abs/2504.03031v2",
          "size": "3245kb",
          "version": "v2"
        }
      ],
      "title": "Building functional and mechanistic models of cortical computation based on canonical cell type connectivity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.03031",
        "HTML": "https://arxiv.org/html/2504.03031v2",
        "PDF": "https://arxiv.org/pdf/2504.03031"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with building models of cortical computation based on cell type connectivity, which does not pertain to LLM training data processing or data engineering."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2504.03299",
      "abstract": "Euclidean E(3) equivariant neural networks that employ scalar fields on position-orientation space M(3) have been effectively applied to tasks such as predicting molecular dynamics and properties. To perform equivariant convolutional-like operations in these architectures one needs Euclidean invariant kernels on M(3) x M(3). In practice, a handcrafted collection of invariants is selected, and this collection is then fed into multilayer perceptrons to parametrize the kernels. We rigorously describe an optimal collection of 4 smooth scalar invariants on the whole of M(3) x M(3). With optimal we mean that the collection is independent and universal, meaning that all invariants are pertinent, and any invariant kernel is a function of them. We evaluate two collections of invariants, one universal and one not, using the PONITA neural network architecture. Our experiments show that using a collection of invariants that is universal positively impacts the accuracy of PONITA significantly.",
      "authors": [
        "Gijs Bellaard",
        "Bart M. N. Smets",
        "and Remco Duits"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Differential Geometry (math.DG)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-04T09:25:59+00:00",
          "link": "https://arxiv.org/abs/2504.03299v1",
          "size": "32kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T09:08:24+00:00",
          "link": "https://arxiv.org/abs/2504.03299v2",
          "size": "33kb",
          "version": "v2"
        }
      ],
      "title": "Universal Collection of Euclidean Invariants between Pairs of Position-Orientations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.03299",
        "HTML": "https://arxiv.org/html/2504.03299v2",
        "PDF": "https://arxiv.org/pdf/2504.03299"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on Euclidean invariants for neural network architectures in molecular dynamics, without addressing the processing of training data for LLMs."
      },
      "tasks": [
        "Position"
      ],
      "repo_urls": [
        "https://gitlab.com/gijsbel/ponita_invariants"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.03309",
      "abstract": "Riemannian metrics on the position-orientation space M(3) that are roto-translation group SE(3) invariant play a key role in image analysis tasks like enhancement, denoising, and segmentation. These metrics enable roto-translation equivariant algorithms, with the associated Riemannian distance often used in implementation.\n  However, computing the Riemannian distance is costly, which makes it unsuitable in situations where constant recomputation is needed. We propose the mav (minimal angular velocity) distance, defined as the Riemannian length of a geometrically meaningful curve, as a practical alternative.\n  We see an application of the mav distance in geometric deep learning. Namely, neural networks architectures such as PONITA, relies on geometric invariants to create their roto-translation equivariant model. The mav distance offers a trainable invariant, with the parameters that determine the Riemannian metric acting as learnable weights.\n  In this paper we: 1) classify and parametrize all SE(3) invariant metrics on M(3), 2) describes how to efficiently calculate the mav distance, and 3) investigate if including the mav distance within PONITA can positively impact its accuracy in predicting molecular properties.",
      "authors": [
        "Gijs Bellaard and Bart M. N. Smets"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Differential Geometry (math.DG)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-04T09:36:11+00:00",
          "link": "https://arxiv.org/abs/2504.03309v1",
          "size": "31kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T09:03:48+00:00",
          "link": "https://arxiv.org/abs/2504.03309v2",
          "size": "31kb",
          "version": "v2"
        }
      ],
      "title": "Roto-Translation Invariant Metrics on Position-Orientation Space",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.03309",
        "HTML": "https://arxiv.org/html/2504.03309v2",
        "PDF": "https://arxiv.org/pdf/2504.03309"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work discusses roto-translation invariant metrics for image analysis tasks and does not involve LLM training data processing."
      },
      "tasks": [
        "Denoising",
        "Position",
        "Translation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.14557",
      "abstract": "Multi-agent frameworks with Large Language Models (LLMs) have become promising tools for generating general-purpose programming languages using test-driven development, allowing developers to create more accurate and robust code. However, their potential has not been fully unleashed for domain-specific programming languages, where specific domain exhibits unique optimization opportunities for customized improvement. In this paper, we take the first step in exploring multi-agent code generation for quantum programs. By identifying the unique optimizations in quantum designs such as quantum error correction, we introduce a novel multi-agent framework tailored to generating accurate, fault-tolerant quantum code. Each agent in the framework focuses on distinct optimizations, iteratively refining the code using a semantic analyzer with multi-pass inference, alongside an error correction code decoder. We also examine the effectiveness of inference-time techniques, like Chain-of-Thought (CoT) and Retrieval-Augmented Generation (RAG) in the context of quantum programming, uncovering observations that are different from general-purpose code generation. To evaluate our approach, we develop a test suite to measure the impact each optimization has on the accuracy of the generated code. Our findings indicate that techniques such as structured CoT significantly improve the generation of quantum algorithms by up to 50%. In contrast, we have also found that certain techniques such as RAG show limited improvement, yielding an accuracy increase of only 4%. Moreover, we showcase examples of AI-assisted quantum error prediction and correction, demonstrating the effectiveness of our multi-agent framework in reducing the quantum errors of generated quantum programs.",
      "authors": [
        "Charlie Campbell",
        "Hao Mark Chen",
        "Wayne Luk",
        "Hongxiang Fan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-20T10:06:37+00:00",
          "link": "https://arxiv.org/abs/2504.14557v1",
          "size": "881kb",
          "version": "v1"
        },
        {
          "date": "2025-07-02T20:14:19+00:00",
          "link": "https://arxiv.org/abs/2504.14557v2",
          "size": "280kb",
          "version": "v2"
        }
      ],
      "title": "Enhancing LLM-based Quantum Code Generation with Multi-Agent Optimization and Quantum Error Correction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.14557",
        "HTML": "https://arxiv.org/html/2504.14557v2",
        "PDF": "https://arxiv.org/pdf/2504.14557"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research explores quantum code generation with LLMs, focusing on programming optimizations, not involving LLM training data processing stages."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.13112",
      "abstract": "Transformers have emerged as a powerful neural network architecture capable of tackling a wide range of learning tasks. In this work, we provide a theoretical analysis of their ability to automatically extract structure from data in an unsupervised setting. In particular, we demonstrate their suitability for clustering when the input data is generated from a Gaussian mixture model. To this end, we study a simplified two-head attention layer and define a population risk whose minimization with unlabeled data drives the head parameters to align with the true mixture centroids. This phenomenon highlights the ability of attention-based layers to capture underlying distributional structure. We further examine an attention layer with key, query, and value matrices fixed to the identity, and show that, even without any trainable parameters, it can perform in-context quantization, revealing the surprising capacity of transformer-based methods to adapt dynamically to input-specific distributions.",
      "authors": [
        "Rodrigo Maulen-Soto (SU",
        "LPSM (UMR\\_8001))",
        "Claire Boyer (IUF)",
        "Pierre Marion (EPFL)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-19T13:39:56+00:00",
          "link": "https://arxiv.org/abs/2505.13112v1",
          "size": "5390kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T08:04:46+00:00",
          "link": "https://arxiv.org/abs/2505.13112v2",
          "size": "5399kb",
          "version": "v2"
        }
      ],
      "title": "Attention-based clustering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.13112",
        "PDF": "https://arxiv.org/pdf/2505.13112"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work analyzes the clustering abilities of transformers with Gaussian mixture models in unsupervised settings, which is not related to LLM training data processing."
      },
      "tasks": [
        "Clustering"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.15057",
      "abstract": "Magnetic Resonance Imaging (MRI) is highly susceptible to motion artifacts due to the extended acquisition times required for k-space sampling. These artifacts can compromise diagnostic utility, particularly for dynamic imaging. We propose a novel alternating minimization framework that leverages a bespoke diffusion model to jointly reconstruct and correct non-rigid motion-corrupted k-space data. The diffusion model uses a coarse-to-fine denoising strategy to capture large overall motion and reconstruct the lower frequencies of the image first, providing a better inductive bias for motion estimation than that of standard diffusion models. We demonstrate the performance of our approach on both real-world cine cardiac MRI datasets and complex simulated rigid and non-rigid deformations, even when each motion state is undersampled by a factor of 64x. Additionally, our method is agnostic to sampling patterns, anatomical variations, and MRI scanning protocols, as long as some low frequency components are sampled during each motion state.",
      "authors": [
        "Frederic Wang",
        "Jonathan I. Tamir"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-21T03:27:21+00:00",
          "link": "https://arxiv.org/abs/2505.15057v1",
          "size": "2597kb",
          "version": "v1"
        },
        {
          "date": "2025-05-29T06:38:03+00:00",
          "link": "https://arxiv.org/abs/2505.15057v2",
          "size": "2597kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T04:39:51+00:00",
          "link": "https://arxiv.org/abs/2505.15057v3",
          "size": "2597kb",
          "version": "v3"
        }
      ],
      "title": "Non-rigid Motion Correction for MRI Reconstruction via Coarse-To-Fine Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.15057",
        "HTML": "https://arxiv.org/html/2505.15057v3",
        "PDF": "https://arxiv.org/pdf/2505.15057"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a framework for MRI reconstruction using diffusion models, focusing on motion correction, which is unrelated to LLM training data processing."
      },
      "tasks": [
        "Denoising",
        "Diagnostic",
        "Inductive Bias",
        "Motion Estimation",
        "MRI Reconstruction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.21290",
      "abstract": "Let $G_{n,p}^{[\\kappa]}$ denote the space of $n$-vertex edge coloured graphs, where each edge occurs independently with probability $p$. The colour of each existing edge is chosen independently and uniformly at random from the set $[\\kappa]$. We consider the threshold for the existence of rainbow colored copies of a spanning subgraph $H$. We provide lower bounds on $p$ and $\\kappa$ sufficient to prove the existence of such copies w.h.p.",
      "authors": [
        "Colin Cooper",
        "Alan Frieze"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-27T14:54:32+00:00",
          "link": "https://arxiv.org/abs/2505.21290v1",
          "size": "6kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T00:47:13+00:00",
          "link": "https://arxiv.org/abs/2505.21290v2",
          "size": "0kb",
          "version": "v2"
        }
      ],
      "title": "Rainbow copies of spanning subgraphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.21290",
        "PDF": "https://arxiv.org/pdf/2505.21290"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is purely mathematical and focuses on rainbow colored graphs and spanning subgraphs, unrelated to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.22343",
      "abstract": "Low-altitude economy (LAE) represents an emerging economic paradigm that redefines commercial and social aerial activities. Large artificial intelligence models (LAIMs) offer transformative potential to further enhance the intelligence of LAE services. However, deploying LAIMs in LAE poses several challenges, including the significant gap between their computational/storage demands and the limited onboard resources of LAE entities, the mismatch between lab-trained LAIMs and dynamic physical environments, and the inefficiencies of traditional decoupled designs for sensing, communication, and computation. To address these issues, we first propose a hierarchical system architecture tailored for LAIM deployment and present representative LAE application scenarios. Next, we explore key enabling techniques that facilitate the mutual co-evolution of LAIMs and low-altitude systems, and introduce a task-oriented execution pipeline for scalable and adaptive service delivery. Then, the proposed framework is validated through real-world case studies. Finally, we outline open challenges to inspire future research.",
      "authors": [
        "Zhonghao Lyu",
        "Yulan Gao",
        "Junting Chen",
        "Hongyang Du",
        "Jie Xu",
        "Kaibin Huang",
        "and Dong In Kim"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-28T13:27:07+00:00",
          "link": "https://arxiv.org/abs/2505.22343v1",
          "size": "13000kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T14:03:18+00:00",
          "link": "https://arxiv.org/abs/2505.22343v2",
          "size": "13879kb",
          "version": "v2"
        }
      ],
      "title": "Empowering Intelligent Low-altitude Economy with Large AI Model Deployment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.22343",
        "HTML": "https://arxiv.org/html/2505.22343v2",
        "PDF": "https://arxiv.org/pdf/2505.22343"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses deployment challenges of large AI models in low-altitude economy contexts but does not discuss LLM training data processing or engineering."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2505.22502",
      "abstract": "Gaussian Process Regression is a well-known machine learning technique for which several quantum algorithms have been proposed. We show here that in a wide range of scenarios these algorithms show no exponential speedup. We achieve this by rigorously proving that the condition number of a kernel matrix scales at least linearly with the matrix size under general assumptions on the data and kernel. We additionally prove that the sparsity and Frobenius norm of a kernel matrix scale linearly under similar assumptions. The implications for the quantum algorithms runtime are independent of the complexity of loading classical data on a quantum computer and also apply to dequantised algorithms. We supplement our theoretical analysis with numerical verification for popular kernels in machine learning.",
      "authors": [
        "Dominic Lowe",
        "M.S. Kim",
        "Roberto Bondesan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-28T15:50:56+00:00",
          "link": "https://arxiv.org/abs/2505.22502v1",
          "size": "176kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T11:27:35+00:00",
          "link": "https://arxiv.org/abs/2505.22502v2",
          "size": "232kb",
          "version": "v2"
        }
      ],
      "title": "Assessing Quantum Advantage for Gaussian Process Regression",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.22502",
        "HTML": "https://arxiv.org/html/2505.22502v2",
        "PDF": "https://arxiv.org/pdf/2505.22502"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on Gaussian Process Regression and quantum algorithms, which are not related to the processing of training data for LLMs."
      },
      "tasks": [
        "regression"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.02825",
      "abstract": "We present the OmniMatch algorithm for seeded multiple graph matching. In the setting of $d$-dimensional Random Dot Product Graphs (RDPG), we prove that under mild assumptions, OmniMatch with $s$ seeds asymptotically and efficiently perfectly aligns $O(s^{\\alpha})$ unseeded vertices -- for $\\alpha<2\\wedge d/4$ -- across multiple networks even in the presence of no edge correlation. We demonstrate the effectiveness of our algorithm across numerous simulations and in the context of shuffled graph hypothesis testing. In the shuffled testing setting, testing power is lost due to the misalignment/shuffling of vertices across graphs, and we demonstrate the capacity of OmniMatch to correct for misaligned vertices prior to testing and hence recover the lost testing power. We further demonstrate the algorithm on a pair of data examples from connectomics and machine translation.",
      "authors": [
        "Tong Qi",
        "Vera Andersson",
        "Peter Viechnicki",
        "Vince Lyzinski"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-03T12:54:24+00:00",
          "link": "https://arxiv.org/abs/2506.02825v1",
          "size": "2207kb",
          "version": "v1"
        },
        {
          "date": "2025-07-02T19:19:46+00:00",
          "link": "https://arxiv.org/abs/2506.02825v2",
          "size": "2207kb",
          "version": "v2"
        }
      ],
      "title": "Asymptotically perfect seeded graph matching without edge correlation (and applications to inference)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.02825",
        "HTML": "https://arxiv.org/html/2506.02825v2",
        "PDF": "https://arxiv.org/pdf/2506.02825"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the OmniMatch algorithm for graph matching and its applications in shuffled graph hypothesis testing, which is unrelated to LLM training data processing or data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.03764",
      "abstract": "We present a theoretical framework for deriving the general $n$-th order Fr\\'echet derivatives of singular values in real rectangular matrices, by leveraging reduced resolvent operators from Kato's analytic perturbation theory for self-adjoint operators. Deriving closed-form expressions for higher-order derivatives of singular values is notoriously challenging through standard matrix-analysis techniques. To overcome this, we treat a real rectangular matrix as a compact operator on a finite-dimensional Hilbert space, and embed the rectangular matrix into a block self-adjoint operator so that non-symmetric perturbations are captured. Applying Kato's asymptotic eigenvalue expansion to this construction, we obtain a general, closed-form expression for the infinitesimal $n$-th order spectral variations. Specializing to $n=2$ and deploying on a Kronecker-product representation with matrix convention yield the Hessian of a singular value, not found in literature. By bridging abstract operator-theoretic perturbation theory with matrices, our framework equips researchers with a practical toolkit for higher-order spectral sensitivity studies in random matrix applications (e.g., adversarial perturbation in deep learning).",
      "authors": [
        "R\\'ois\\'in Luo",
        "James McDermott",
        "Colm O'Riordan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-04T09:28:35+00:00",
          "link": "https://arxiv.org/abs/2506.03764v1",
          "size": "199kb",
          "version": "v1"
        },
        {
          "date": "2025-06-05T07:40:31+00:00",
          "link": "https://arxiv.org/abs/2506.03764v2",
          "size": "200kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T11:36:31+00:00",
          "link": "https://arxiv.org/abs/2506.03764v3",
          "size": "207kb",
          "version": "v3"
        }
      ],
      "title": "Higher-Order Singular-Value Derivatives of Rectangular Real Matrices",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.03764",
        "HTML": "https://arxiv.org/html/2506.03764v3",
        "PDF": "https://arxiv.org/pdf/2506.03764"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper provides a theoretical framework for deriving higher-order derivatives of singular values in matrices, which does not pertain to LLM training data collection, construction, or processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2506.16676",
      "abstract": "This work begins the development of fast, scalable solvers for scientific and engineering-relevant magnetohydrodynamics (MHD) models of tokamaks using multigrid methods. These tokamak models are characterized by a distinguished direction in the toroidal coordinate that is partially aligned with the magnetic guide field, which dominates the plasma dynamics. All tokamak models exploit this structure, for example, NIMROD at https://nimrodteam.org uses $2D$, unstructured, high-order finite elements in the poloidal plane with Fourier modes in the toroidal coordinate, and the $3D$, extended MHD code \\textit{M3D-C1}\\footnote{https://m3dc1.pppl.gov} uses $2D$, unstructured $C^1$ elements in the poloidal plane with cubic Hermite functions in the toroidal direction. This structure suggests addressing the toroidal coordinate first, which \\textit{NIMROD} does at the formulation level, but the \\textit{M3D-C1} approach leaves in the algebraic system to be solved at each time step in an implicit time integrator. This work addressed the toroidal coordinate in the \\textit{M3D-C1} velocity solve by adding semi-coarsening multigrid to the existing PETSC at https://petsc.org -- Portable, Extensible Toolkit for Scientific Computation -- block Jacobi solver, with the addition of little new code that allows for smaller Jacobi subdomains that are better suited to contemporary, highly parallel, hardware. Competitive performance of this new solver configuration is demonstrated on a self-consistent runaway electron model of a SPARC at https://cfs.energy/technology/sparc disruption, and the next steps in the development of this new approach are outlined.",
      "authors": [
        "Mark F. Adams",
        "Jin Chen",
        "Benjamin Sturdevant"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Plasma Physics (physics.plasm-ph)",
        "Performance (cs.PF)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-20T01:36:08+00:00",
          "link": "https://arxiv.org/abs/2506.16676v1",
          "size": "5044kb",
          "version": "v1"
        },
        {
          "date": "2025-07-02T19:08:22+00:00",
          "link": "https://arxiv.org/abs/2506.16676v2",
          "size": "5018kb",
          "version": "v2"
        }
      ],
      "title": "Fast solvers for Tokamak fluid models with PETSC -- Part I",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.16676",
        "HTML": "https://arxiv.org/html/2506.16676v2",
        "PDF": "https://arxiv.org/pdf/2506.16676"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on developing fast solvers for tokamak fluid models using multigrid methods and PETSC, which is not related to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.20589",
      "abstract": "Recent developments in the Internet of Bio-Nano Things (IoBNT) are laying the groundwork for innovative applications across the healthcare sector. Nanodevices designed to operate within the body, managed remotely via the internet, are envisioned to promptly detect and actuate on potential diseases. In this vision, an inherent challenge arises due to the limited capabilities of individual nanosensors; specifically, nanosensors must communicate with one another to collaborate as a cluster. Aiming to research the boundaries of the clustering capabilities, this survey emphasizes data-driven communication strategies in molecular communication (MC) channels as a means of linking nanosensors. Relying on the flexibility and robustness of machine learning (ML) methods to tackle the dynamic nature of MC channels, the MC research community frequently refers to neural network (NN) architectures. This interdisciplinary research field encompasses various aspects, including the use of NNs to facilitate communication in MC environments, their implementation at the nanoscale, explainable approaches for NNs, and dataset generation for training. Within this survey, we provide a comprehensive analysis of fundamental perspectives on recent trends in NN architectures for MC, the feasibility of their implementation at the nanoscale, applied explainable artificial intelligence (XAI) techniques, and the accessibility of datasets along with best practices for their generation. Additionally, we offer open-source code repositories that illustrate NN-based methods to support reproducible research for key MC scenarios. Finally, we identify emerging research challenges, such as robust NN architectures, biologically integrated NN modules, and scalable training strategies.",
      "authors": [
        "Jorge Torres G\\'omez and Pit Hofmann and Lisa Y. Debus and Osman Tugay Ba\\c{s}aran and Sebastian Lotter and Roya Khanzadeh and Stefan Angerbauer and Bige Deniz Unluturk and Sergi Abadal and Werner Haselmayr and Frank H.P. Fitzek and Robert Schober and Falko Dressler"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Emerging Technologies (cs.ET)",
        "Other Quantitative Biology (q-bio.OT)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T16:28:30+00:00",
          "link": "https://arxiv.org/abs/2506.20589v1",
          "size": "4111kb",
          "version": "v1"
        },
        {
          "date": "2025-06-26T15:09:32+00:00",
          "link": "https://arxiv.org/abs/2506.20589v2",
          "size": "4279kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T14:47:17+00:00",
          "link": "https://arxiv.org/abs/2506.20589v3",
          "size": "4279kb",
          "version": "v3"
        }
      ],
      "title": "Communicating Smartly in Molecular Communication Environments: Neural Networks in the Internet of Bio-Nano Things",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20589",
        "HTML": "https://arxiv.org/html/2506.20589v3",
        "PDF": "https://arxiv.org/pdf/2506.20589"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on neural networks in the Internet of Bio-Nano Things and communication strategies, which are unrelated to LLM training data processing tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22675",
      "abstract": "Invariant prediction [Peters et al., 2016] analyzes feature/outcome data from multiple environments to identify invariant features - those with a stable predictive relationship to the outcome. Such features support generalization to new environments and help reveal causal mechanisms. Previous methods have primarily tackled this problem through hypothesis testing or regularized optimization. Here we develop Bayesian Invariant Prediction (BIP), a probabilistic model for invariant prediction. BIP encodes the indices of invariant features as a latent variable and recover them by posterior inference. Under the assumptions of Peters et al. [2016], the BIP posterior targets the true invariant features. We prove that the posterior is consistent and that greater environment heterogeneity leads to faster posterior contraction. To handle many features, we design an efficient variational approximation called VI-BIP. In simulations and real data, we find that BIP and VI-BIP are more accurate and scalable than existing methods for invariant prediction.",
      "authors": [
        "Luhuan Wu",
        "Mingzhang Yin",
        "Yixin Wang",
        "John P. Cunningham",
        "David M. Blei"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T22:58:37+00:00",
          "link": "https://arxiv.org/abs/2506.22675v1",
          "size": "170kb",
          "version": "v1"
        },
        {
          "date": "2025-07-02T22:33:39+00:00",
          "link": "https://arxiv.org/abs/2506.22675v2",
          "size": "169kb",
          "version": "v2"
        }
      ],
      "title": "Bayesian Invariance Modeling of Multi-Environment Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22675",
        "HTML": "https://arxiv.org/html/2506.22675v2",
        "PDF": "https://arxiv.org/pdf/2506.22675"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is centered around invariant prediction for generalization in machine learning using Bayesian approaches, without addressing any aspects of data processing specifically related to LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23767",
      "abstract": "Every publicly traded U.S. company files an annual 10-K report containing critical insights into financial health and risk. We propose Tiny eXplainable Risk Assessor (TinyXRA), a lightweight and explainable transformer-based model that automatically assesses company risk from these reports. Unlike prior work that relies solely on the standard deviation of excess returns (adjusted for the Fama-French model), which indiscriminately penalizes both upside and downside risk, TinyXRA incorporates skewness, kurtosis, and the Sortino ratio for more comprehensive risk assessment. We leverage TinyBERT as our encoder to efficiently process lengthy financial documents, coupled with a novel dynamic, attention-based word cloud mechanism that provides intuitive risk visualization while filtering irrelevant terms. This lightweight design ensures scalable deployment across diverse computing environments with real-time processing capabilities for thousands of financial documents which is essential for production systems with constrained computational resources. We employ triplet loss for risk quartile classification, improving over pairwise loss approaches in existing literature by capturing both the direction and magnitude of risk differences. Our TinyXRA achieves state-of-the-art predictive accuracy across seven test years on a dataset spanning 2013-2024, while providing transparent and interpretable risk assessments. We conduct comprehensive ablation studies to evaluate our contributions and assess model explanations both quantitatively by systematically removing highly attended words and sentences, and qualitatively by examining explanation coherence. The paper concludes with findings, practical implications, limitations, and future research directions. Our code is available at https://github.com/Chen-XueWen/TinyXRA.",
      "authors": [
        "Xue Wen Tan",
        "Stanley Kok"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Risk Management (q-fin.RM)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T12:13:35+00:00",
          "link": "https://arxiv.org/abs/2506.23767v1",
          "size": "29340kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T03:15:52+00:00",
          "link": "https://arxiv.org/abs/2506.23767v2",
          "size": "29340kb",
          "version": "v2"
        }
      ],
      "title": "Explainable AI for Comprehensive Risk Assessment for Financial Reports: A Lightweight Hierarchical Transformer Network Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23767",
        "PDF": "https://arxiv.org/pdf/2506.23767"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a transformer-based model for risk assessment in financial reports, focusing on model architecture and interpretation rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.00660",
      "abstract": "Mitral regurgitation is one of the most prevalent cardiac disorders. Four-dimensional (4D) ultrasound has emerged as the primary imaging modality for assessing dynamic valvular morphology. However, 4D mitral valve (MV) analysis remains challenging due to limited phase annotations, severe motion artifacts, and poor imaging quality. Yet, the absence of inter-phase dependency in existing methods hinders 4D MV analysis. To bridge this gap, we propose a Motion-Topology guided consistency network (MTCNet) for accurate 4D MV ultrasound segmentation in semi-supervised learning (SSL). MTCNet requires only sparse end-diastolic and end-systolic annotations. First, we design a cross-phase motion-guided consistency learning strategy, utilizing a bi-directional attention memory bank to propagate spatio-temporal features. This enables MTCNet to achieve excellent performance both per- and inter-phase. Second, we devise a novel topology-guided correlation regularization that explores physical prior knowledge to maintain anatomically plausible. Therefore, MTCNet can effectively leverage structural correspondence between labeled and unlabeled phases. Extensive evaluations on the first largest 4D MV dataset, with 1408 phases from 160 patients, show that MTCNet performs superior cross-phase consistency compared to other advanced methods (Dice: 87.30%, HD: 1.75mm). Both the code and the dataset are available at https://github.com/crs524/MTCNet.",
      "authors": [
        "Rusi Chen",
        "Yuanting Yang",
        "Jiezhi Yao",
        "Hongning Song",
        "Ji Zhang",
        "Yongsong Zhou",
        "Yuhao Huang",
        "Ronghao Yang",
        "Dan Jia",
        "Yuhan Zhang",
        "Xing Tao",
        "Haoran Dou",
        "Qing Zhou",
        "Xin Yang",
        "Dong Ni"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T10:58:51+00:00",
          "link": "https://arxiv.org/abs/2507.00660v1",
          "size": "21767kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T07:56:43+00:00",
          "link": "https://arxiv.org/abs/2507.00660v2",
          "size": "21771kb",
          "version": "v2"
        }
      ],
      "title": "MTCNet: Motion and Topology Consistency Guided Learning for Mitral Valve Segmentationin 4D Ultrasound",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.00660",
        "HTML": "https://arxiv.org/html/2507.00660v2",
        "PDF": "https://arxiv.org/pdf/2507.00660"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research addresses a network model for mitral valve segmentation in ultrasound images and does not relate to LLMs or their training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.00953",
      "abstract": "The paradigm of large language models in natural language processing (NLP) has also shown promise in modeling biological languages, including proteins, RNA, and DNA. Both the auto-regressive generation paradigm and evaluation metrics have been transferred from NLP to biological sequence modeling. However, the intrinsic structural correlations in natural and biological languages differ fundamentally. Therefore, we revisit the notion of language in biological systems to better understand how NLP successes can be effectively translated to biological domains. By treating the 3D structure of biomolecules as the semantic content of a sentence and accounting for the strong correlations between residues or bases, we highlight the importance of structural evaluation and demonstrate the applicability of the auto-regressive paradigm in biological language modeling. Code can be found at \\href{https://github.com/zjuKeLiu/RiFold}{github.com/zjuKeLiu/RiFold}",
      "authors": [
        "Ke Liu and Shuaike Shen and Hao Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Biomolecules (q-bio.BM)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T16:57:39+00:00",
          "link": "https://arxiv.org/abs/2507.00953v1",
          "size": "3608kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T10:33:16+00:00",
          "link": "https://arxiv.org/abs/2507.00953v2",
          "size": "3613kb",
          "version": "v2"
        }
      ],
      "title": "From Sentences to Sequences: Rethinking Languages in Biological System",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.00953",
        "PDF": "https://arxiv.org/pdf/2507.00953"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on applying NLP paradigms to biological sequences rather than discussing the processing of training data for large language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.01433",
      "abstract": "Mild Cognitive Impairment (MCI) is a critical transitional stage between normal cognitive aging and dementia, making its early detection essential. This study investigates the neural mechanisms of distractor suppression in MCI patients using EEG and behavioral data during an attention-cueing Eriksen flanker task. A cohort of 56 MCIs and 26 healthy controls (HCs) performed tasks with congruent and incongruent stimuli of varying saliency levels. During these tasks, EEG data were analyzed for alpha band coherence's functional connectivity, focusing on Global Efficiency (GE), while Reaction Time (RT) and Hit Rate (HR) were also collected.\n  Our findings reveal significant interactions between congruency, saliency, and cognitive status on GE, RT, and HR. In HCs, congruent conditions resulted in higher GE (p = 0.0114, multivariate t-distribution correction, MVT), faster RTs (p < 0.0001, MVT), and higher HRs (p < 0.0001, MVT) compared to incongruent conditions. HCs also showed increased GE in salient conditions for incongruent trials (p = 0.0406, MVT). MCIs exhibited benefits from congruent conditions with shorter RTs and higher HRs (both p < 0.0001, MVT) compared to incongruent conditions but showed reduced adaptability in GE, with no significant GE differences between conditions.\n  These results highlight the potential of alpha band coherence and GE as early markers for cognitive impairment. By integrating GE, RT, and HR, this study provides insights into the interplay between neural efficiency, processing speed, and task accuracy. This approach offers valuable insights into cognitive load management and interference effects, indicating benefits for interventions aimed at improving attentional control and processing speed in MCIs.",
      "authors": [
        "Jatupong Oboun",
        "Piyanon Charoenpoonpanich",
        "Anna Raksapatcharawong",
        "Chaipat Chunharas",
        "Itthi Chatnuntawech",
        "Chainarong Amornbunchornvej",
        "Sirawaj Itthipuripat"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Neurons and Cognition (q-bio.NC)",
        "Social and Information Networks (cs.SI)",
        "Applications (stat.AP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T07:35:48+00:00",
          "link": "https://arxiv.org/abs/2507.01433v1",
          "size": "2346kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T07:47:18+00:00",
          "link": "https://arxiv.org/abs/2507.01433v2",
          "size": "2346kb",
          "version": "v2"
        }
      ],
      "title": "Reduced Efficiency in the Attentional Network During Distractor Suppression in Mild Cognitive Impairment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01433",
        "HTML": "https://arxiv.org/html/2507.01433v2",
        "PDF": "https://arxiv.org/pdf/2507.01433"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on investigating neural mechanisms of distractor suppression in MCI patients using EEG data, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2405.17728",
      "abstract": "Workshop courses designed to foster creativity are gaining popularity. However, even experienced faculty teams find it challenging to realize a holistic evaluation that accommodates diverse perspectives. Adequate deliberation is essential to integrate varied assessments, but faculty often lack the time for such exchanges. Deriving an average score without discussion undermines the purpose of a holistic evaluation. Therefore, this paper explores the use of a Large Language Model (LLM) as a facilitator to integrate diverse faculty assessments. Scenario-based experiments were conducted to determine if the LLM could integrate diverse evaluations and explain the underlying pedagogical theories to faculty. The results were noteworthy, showing that the LLM can effectively facilitate faculty discussions. Additionally, the LLM demonstrated the capability to create evaluation criteria by generalizing a single scenario-based experiment, leveraging its already acquired pedagogical domain knowledge.",
      "authors": [
        "Toru Ishida",
        "Tongxi Liu",
        "Hailong Wang and William K. Cheunga"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-28T01:07:06+00:00",
          "link": "https://arxiv.org/abs/2405.17728v1",
          "size": "634kb",
          "version": "v1"
        },
        {
          "date": "2024-08-12T00:54:28+00:00",
          "link": "https://arxiv.org/abs/2405.17728v2",
          "size": "638kb",
          "version": "v2"
        }
      ],
      "title": "Facilitating Holistic Evaluations with LLMs: Insights from Scenario-Based Experiments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.17728",
        "PDF": "https://arxiv.org/pdf/2405.17728"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper discusses the use of LLMs for evaluation integration, it does not propose new methods for LLM training data processing but uses existing LLM capabilities."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Large Language Model"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.13295",
      "abstract": "The development of 6G wireless technologies is rapidly advancing, with the 3rd Generation Partnership Project (3GPP) entering the pre-standardization phase and aiming to deliver the first specifications by 2028. This paper explores the OpenAirInterface (OAI) project, an open-source initiative that plays a crucial role in the evolution of 5G and future 6G networks. OAI provides a comprehensive implementation of 3GPP and O-RAN compliant networks, including Radio Access Network (RAN), Core Network (CN), and software-defined User Equipment (UE) components. This paper details the history and evolution of OAI, its licensing model, and the various projects under its umbrella, such as RAN, the CN, and the Operations, Administration and Maintenance (OAM) projects. It also highlights the development methodology, Continuous Integration/Continuous Delivery (CI/CD) processes, and end-to-end systems powered by OAI. Furthermore, the paper discusses the potential of OAI for 6G research, focusing on spectrum, reflective intelligent surfaces, and Artificial Intelligence (AI)/Machine Learning (ML) integration. The open-source approach of OAI is emphasized as essential for tackling the challenges of 6G, fostering community collaboration, and driving innovation in next-generation wireless technologies.",
      "authors": [
        "Florian Kaltenberger",
        "Tommaso Melodia",
        "Irfan Ghauri",
        "Michele Polese",
        "Raymond Knopp",
        "Tien Thinh Nguyen",
        "Sakthivel Velumani",
        "Davide Villa",
        "Leonardo Bonati",
        "Robert Schmidt",
        "Sagar Arora",
        "Mikel Irazabal",
        "Navid Nikaein"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-17T19:48:09+00:00",
          "link": "https://arxiv.org/abs/2412.13295v1",
          "size": "403kb",
          "version": "v1"
        },
        {
          "date": "2025-01-06T19:51:53+00:00",
          "link": "https://arxiv.org/abs/2412.13295v2",
          "size": "403kb",
          "version": "v2"
        },
        {
          "date": "2025-04-18T20:37:02+00:00",
          "link": "https://arxiv.org/abs/2412.13295v3",
          "size": "577kb",
          "version": "v3"
        }
      ],
      "title": "Driving Innovation in 6G Wireless Technologies: The OpenAirInterface Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.13295",
        "HTML": "https://arxiv.org/html/2412.13295",
        "PDF": "https://arxiv.org/pdf/2412.13295"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on 6G wireless technologies development and the OAI project, without any connection to LLM training data or related processing methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.14513",
      "abstract": "Local communities by concentration of nodes connected with short links are widely observed in spatial networks. However, how such structure affects robustness of connectivity against malicious attacks remains unclear. This study investigates the impact of local communities on the robustness by modeling planar infrastructure reveals that the robustness is weakened by strong local communities in spatial networks. These results highlight the potential of long-distance links in mitigating the negative effects of local community on the robustness.",
      "authors": [
        "Yingzhou Mou",
        "Yukio Hayashi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Physics and Society (physics.soc-ph)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-19T04:26:11+00:00",
          "link": "https://arxiv.org/abs/2412.14513v1",
          "size": "37746kb",
          "version": "v1"
        },
        {
          "date": "2025-01-30T08:29:49+00:00",
          "link": "https://arxiv.org/abs/2412.14513v2",
          "size": "38468kb",
          "version": "v2"
        },
        {
          "date": "2025-02-03T06:45:17+00:00",
          "link": "https://arxiv.org/abs/2412.14513v3",
          "size": "38468kb",
          "version": "v3"
        },
        {
          "date": "2025-04-23T04:44:12+00:00",
          "link": "https://arxiv.org/abs/2412.14513v4",
          "size": "6205kb",
          "version": "v4"
        }
      ],
      "title": "Vulnerable Connectivity Caused by Local Communities in Spatial Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.14513",
        "HTML": "https://arxiv.org/html/2412.14513",
        "PDF": "https://arxiv.org/pdf/2412.14513"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses the robustness of spatial networks against malicious attacks and does not involve any aspect of LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.14120",
      "abstract": "Rotorcraft engines are highly complex, nonlinear thermodynamic systems that operate under varying environmental and flight conditions. Simulating their dynamics is crucial for design, fault diagnostics, and deterioration control phases, and requires robust and reliable control systems to estimate engine performance throughout flight envelope. However, the development of detailed physical models of the engine based on numerical simulations is a very challenging task due to the complex and entangled physics driving the engine. In this scenario, data-driven machine-learning techniques are of great interest to the aircraft engine community, due to their ability to describe nonlinear systems' dynamic behavior and enable online performance estimation, achieving excellent results with accuracy competitive with the state of the art. In this work, we explore different Neural Network architectures to model the turboshaft engine of Leonardo's AW189P4 prototype, aiming to predict the engine torque. The models are trained on an extensive database of real flight tests featuring a variety of operational maneuvers performed under different flight conditions, providing a comprehensive representation of the engine's performance. To complement the neural network approach, we apply Sparse Identification of Nonlinear Dynamics (SINDy) to derive a low-dimensional dynamical model from the available data, describing the relationship between fuel flow and engine torque. The resulting model showcases SINDy's capability to recover the actual physics underlying the engine dynamics and demonstrates its potential for investigating more complex aspects of the engine. The results prove that data-driven engine models can exploit a wider range of parameters than standard transfer function-based approaches, enabling the use of trained schemes to simulate nonlinear effects in different engines and helicopters.",
      "authors": [
        "Damiano Paniccia",
        "Francesco Aldo Tucci",
        "Joel Guerrero",
        "Luigi Capone",
        "Nicoletta Sanguini",
        "Tommaso Benacchio",
        "Luigi Bottasso"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-19T21:45:53+00:00",
          "link": "https://arxiv.org/abs/2502.14120v1",
          "size": "2104kb",
          "version": "v1"
        },
        {
          "date": "2025-02-23T17:24:18+00:00",
          "link": "https://arxiv.org/abs/2502.14120v2",
          "size": "2104kb",
          "version": "v2"
        }
      ],
      "title": "A Supervised Machine-Learning Approach For Turboshaft Engine Dynamic Modeling Under Real Flight Conditions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.14120",
        "HTML": "https://arxiv.org/html/2502.14120",
        "PDF": "https://arxiv.org/pdf/2502.14120"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with neural network approaches for turboshaft engine modeling under real flight conditions rather than addressing LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2403.16557",
      "abstract": "Federated Learning (FL) is a distributed machine learning framework in communication network systems. However, the systems' Non-Independent and Identically Distributed (Non-IID) data negatively affect the convergence efficiency of the global model, since only a subset of these data samples are beneficial for model convergence. In pursuit of this subset, a reliable approach involves determining a measure of validity to rank the samples within the dataset. In this paper, We propose the BHerd strategy which selects a beneficial herd of local gradients to accelerate the convergence of the FL model. Specifically, we map the distribution of the local dataset to the local gradients and use the Herding strategy to obtain a permutation of the set of gradients, where the more advanced gradients in the permutation are closer to the average of the set of gradients. These top portion of the gradients will be selected and sent to the server for global aggregation. We conduct experiments on different datasets, models and scenarios by building a prototype system, and experimental results demonstrate that our BHerd strategy is effective in selecting beneficial local gradients to mitigate the effects brought by the Non-IID dataset, thus accelerating model convergence.",
      "authors": [
        "Ping Luo",
        "Xiaoge Deng",
        "Ziqing Wen",
        "Tao Sun",
        "Dongsheng Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-25T09:16:59+00:00",
          "link": "https://arxiv.org/abs/2403.16557v1",
          "size": "7561kb",
          "version": "v1"
        }
      ],
      "title": "Accelerating Federated Learning by Selecting Beneficial Herd of Local Gradients",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.16557",
        "HTML": "https://arxiv.org/html/2403.16557",
        "PDF": "https://arxiv.org/pdf/2403.16557"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on Federated Learning and improving model convergence by selecting beneficial local gradients. It does not address LLM training data processing or engineering."
      },
      "tasks": [
        "Federated Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.02136",
      "abstract": "This paper presents a framework for extracting georeferenced vehicle trajectories from high-altitude drone imagery, addressing key challenges in urban traffic monitoring and the limitations of traditional ground-based systems. Our approach integrates several novel contributions, including a tailored object detector optimized for high-altitude bird's-eye view perspectives, a unique track stabilization method that uses detected vehicle bounding boxes as exclusion masks during image registration, and an orthophoto and master frame-based georeferencing strategy that enhances consistent alignment across multiple drone viewpoints. Additionally, our framework features robust vehicle dimension estimation and detailed road segmentation, enabling comprehensive traffic analysis. Conducted in the Songdo International Business District, South Korea, the study utilized a multi-drone experiment covering 20 intersections, capturing approximately 12TB of 4K video data over four days. The framework produced two high-quality datasets: the Songdo Traffic dataset, comprising approximately 700,000 unique vehicle trajectories, and the Songdo Vision dataset, containing over 5,000 human-annotated images with about 300,000 vehicle instances in four classes. Comparisons with high-precision sensor data from an instrumented probe vehicle highlight the accuracy and consistency of our extraction pipeline in dense urban environments. The public release of Songdo Traffic and Songdo Vision, and the complete source code for the extraction pipeline, establishes new benchmarks in data quality, reproducibility, and scalability in traffic research. Results demonstrate the potential of integrating drone technology with advanced computer vision for precise and cost-effective urban traffic monitoring, providing valuable resources for developing intelligent transportation systems and enhancing traffic management strategies.",
      "authors": [
        "Robert Fonod and Haechan Cho and Hwasoo Yeo and Nikolas Geroliminis"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-04T14:49:01+00:00",
          "link": "https://arxiv.org/abs/2411.02136v1",
          "size": "33059kb",
          "version": "v1"
        },
        {
          "date": "2025-03-17T09:25:50+00:00",
          "link": "https://arxiv.org/abs/2411.02136v2",
          "size": "34768kb",
          "version": "v2"
        },
        {
          "date": "2025-06-25T20:45:19+00:00",
          "link": "https://arxiv.org/abs/2411.02136v3",
          "size": "34769kb",
          "version": "v3"
        }
      ],
      "title": "Advanced computer vision for extracting georeferenced vehicle trajectories from drone imagery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.02136",
        "HTML": "https://arxiv.org/html/2411.02136",
        "PDF": "https://arxiv.org/pdf/2411.02136"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a computer vision framework for extracting georeferenced vehicle trajectories from drone imagery and does not relate to the processing or engineering of training data for LLMs."
      },
      "tasks": [
        "4k",
        "geo-localization",
        "Image Registration",
        "Keypoint detection and image matching",
        "Object Detection",
        "Object Tracking",
        "vehicle detection",
        "Video Stabilization"
      ],
      "repo_urls": [
        "https://github.com/rfonod/stabilo",
        "https://github.com/rfonod/geo-trax",
        "https://github.com/aixmobility/the-drift",
        "https://github.com/rfonod/stabilo-optimize"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.22461",
      "abstract": "Groundwater supports ecosystems, agriculture, and drinking water supplies worldwide, yet effective monitoring remains challenging due to sparse data, computational constraints, and delayed outputs from traditional approaches. We develop a machine learning pipeline that predicts groundwater level categories using climate data, hydro-meteorological records, and physiographic attributes processed through AutoGluon's automated ensemble framework. Our approach integrates geospatial preprocessing, domain-driven feature engineering, and automated model selection to overcome conventional monitoring limitations. Applied to a large-scale French dataset (n $>$ 3,440,000 observations from 1,500+ wells), the model achieves weighted F\\_1 scores of 0.927 on validation data and 0.67 on temporally distinct test data. Scenario-based evaluations demonstrate practical utility for early warning systems and water allocation decisions under changing climate conditions. The open-source implementation provides a scalable framework for integrating machine learning into national groundwater monitoring networks, enabling more responsive and data-driven water management strategies.",
      "authors": [
        "Chuan Li",
        "Ruoxuan Yang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-18T00:41:04+00:00",
          "link": "https://arxiv.org/abs/2506.22461v1",
          "size": "1538kb",
          "version": "v1"
        }
      ],
      "title": "Machine Learning for Proactive Groundwater Management: Early Warning and Resource Allocation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22461",
        "HTML": "https://arxiv.org/html/2506.22461",
        "PDF": "https://arxiv.org/pdf/2506.22461"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on using machine learning for groundwater management, which involves geospatial data processing but does not pertain to LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2406.13272",
      "abstract": "Animating stylized avatars with dynamic poses and expressions has attracted increasing attention for its broad range of applications. Previous research has made significant progress by training controllable generative models to synthesize animations based on reference characteristics, pose, and expression conditions. However, the mechanisms used in these methods to control pose and expression often inadvertently introduce unintended features from the target motion, while also causing a loss of expression-related details, particularly when applied to stylized animation. This paper proposes a new method based on Stable Diffusion, called AniFaceDiff, incorporating a new conditioning module for animating stylized avatars. First, we propose a refined spatial conditioning approach by Facial Alignment to prevent the inclusion of identity characteristics from the target motion. Then, we introduce an Expression Adapter that incorporates additional cross-attention layers to address the potential loss of expression-related information. Our approach effectively preserves pose and expression from the target video while maintaining input image consistency. Extensive experiments demonstrate that our method achieves state-of-the-art results, showcasing superior image quality, preservation of reference features, and expression accuracy, particularly for out-of-domain animation across diverse styles, highlighting its versatility and strong generalization capabilities. This work aims to enhance the quality of virtual stylized animation for positive applications. To promote responsible use in virtual environments, we contribute to the advancement of detection for generative content by evaluating state-of-the-art detectors, highlighting potential areas for improvement, and suggesting solutions.",
      "authors": [
        "Ken Chen",
        "Sachith Seneviratne",
        "Wei Wang",
        "Dongting Hu",
        "Sanjay Saha",
        "Md. Tarek Hasan",
        "Sanka Rasnayaka",
        "Tamasha Malepathirana",
        "Mingming Gong",
        "Saman Halgamuge"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-19T07:08:48+00:00",
          "link": "https://arxiv.org/abs/2406.13272v1",
          "size": "16934kb",
          "version": "v1"
        },
        {
          "date": "2024-12-02T12:18:12+00:00",
          "link": "https://arxiv.org/abs/2406.13272v2",
          "size": "14283kb",
          "version": "v2"
        }
      ],
      "title": "AniFaceDiff: Animating Stylized Avatars via Parametric Conditioned Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.13272",
        "HTML": "https://arxiv.org/html/2406.13272",
        "PDF": "https://arxiv.org/pdf/2406.13272"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses animating stylized avatars through a parametric conditioned diffusion model and does not involve any aspect of LLM training data processing or data engineering."
      },
      "tasks": [
        "Image Animation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2312.03430",
      "abstract": "Multimodal semantic segmentation is developing rapidly, but the modality of RGB-Polarization remains underexplored. To delve into this problem, we construct a UPLight RGB-P segmentation benchmark with 12 typical underwater semantic classes. In this work, we design the ShareCMP, an RGB-P semantic segmentation framework with a shared dual-branch architecture, which reduces the number of parameters by about 26-33% compared to previous dual-branch models. It encompasses a Polarization Generate Attention (PGA) module designed to generate polarization modal images with richer polarization properties for the encoder. In addition, we introduce the Class Polarization-Aware Loss (CPALoss) to improve the learning and understanding of the encoder for polarization modal information and to optimize the PGA module. With extensive experiments on a total of three RGB-P benchmarks, our ShareCMP achieves state-of-the-art performance in mIoU with fewer parameters on the UPLight (92.45(+0.32)%), ZJU (92.7(+0.1)%), and MCubeS (50.99(+1.51)%) datasets compared to the previous best methods. The code is available at https://github.com/LEFTeyex/ShareCMP.",
      "authors": [
        "Zhuoyan Liu",
        "Bo Wang",
        "Lizhi Wang",
        "Chenyu Mao",
        "Ye Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2023-12-06T11:25:40+00:00",
          "link": "https://arxiv.org/abs/2312.03430v1",
          "size": "22436kb",
          "version": "v1"
        },
        {
          "date": "2023-12-10T03:02:22+00:00",
          "link": "https://arxiv.org/abs/2312.03430v2",
          "size": "23526kb",
          "version": "v2"
        }
      ],
      "title": "ShareCMP: Polarization-Aware RGB-P Semantic Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2312.03430",
        "HTML": "https://arxiv.org/html/2312.03430",
        "PDF": "https://arxiv.org/pdf/2312.03430"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The work introduces an RGB-P semantic segmentation framework, which does not pertain to the processing of training data for LLMs."
      },
      "tasks": [
        "Semantic Segmentation"
      ],
      "repo_urls": [
        "https://github.com/lefteyex/sharecmp"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.18644",
      "abstract": "This paper examines the output of cultural items generated by Chat Generative PreTrained Transformer Pro in response to three structured prompts to translate three anthologies of African poetry. The first prompt was broad, the second focused on poetic structure, and the third prompt emphasized cultural specificity. To support this analysis, four comparative tables were created. The first table presents the results of the cultural items produced after the three prompts, the second categorizes these outputs based on Aixela framework of Proper nouns and Common expressions, the third table summarizes the cultural items generated by human translators, a custom translation engine, and a Large Language Model. The final table outlines the strategies employed by Chat Generative PreTrained Transformer Pro following the culture specific prompt. Compared to the outputs of cultural items from reference human translation and the custom translation engine in prior studies the findings indicate that the culture oriented prompts used with Chat Generative PreTrained Transformer Pro did not yield significant enhancements of cultural items during the translation of African poetry from English to French. Among the fifty four cultural items, the human translation produced thirty three cultural items in repetition, the custom translation engine generated Thirty eight cultural items in repetition while Chat Generative PreTrained Transformer Pro produced forty one cultural items in repetition. The untranslated cultural items revealed inconsistencies in Large language models approach to translating cultural items in African poetry from English to French.",
      "authors": [
        "Adeyola Opaluwah"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-29T09:00:19+00:00",
          "link": "https://arxiv.org/abs/2501.18644v1",
          "size": "398kb",
          "version": "v1"
        },
        {
          "date": "2025-02-04T12:12:06+00:00",
          "link": "https://arxiv.org/abs/2501.18644v2",
          "size": "388kb",
          "version": "v2"
        }
      ],
      "title": "Prompt-oriented Output of Culture-Specific Items in Translated African Poetry by Large Language Model: An Initial Multi-layered Tabular Review",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.18644",
        "PDF": "https://arxiv.org/pdf/2501.18644"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper analyzes cultural translation in LLMs, mentioning the input prompts influencing the output, which could relate to fine-tuning processes but does not focus on core LLM data engineering or data processing methods."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Large Language Model",
        "Specificity",
        "Translation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.01123",
      "abstract": "Landslides pose severe threats to infrastructure, economies, and human lives, necessitating accurate detection and predictive mapping across diverse geographic regions. With advancements in deep learning and remote sensing, automated landslide detection has become increasingly effective. This study presents a comprehensive approach integrating multi-source satellite imagery and deep learning models to enhance landslide identification and prediction. We leverage Sentinel-2 multispectral data and ALOS PALSAR-derived slope and Digital Elevation Model (DEM) layers to capture critical environmental features influencing landslide occurrences. Various geospatial analysis techniques are employed to assess the impact of terra in characteristics, vegetation cover, and rainfall on detection accuracy. Additionally, we evaluate the performance of multiple stateof-the-art deep learning segmentation models, including U-Net, DeepLabV3+, and Res-Net, to determine their effectiveness in landslide detection. The proposed framework contributes to the development of reliable early warning systems, improved disaster risk management, and sustainable land-use planning. Our findings provide valuable insights into the potential of deep learning and multi-source remote sensing in creating robust, scalable, and transferable landslide prediction models.",
      "authors": [
        "Rahul A. Burange",
        "Harsh K. Shinde",
        "and Omkar Mutyalwar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T18:34:42+00:00",
          "link": "https://arxiv.org/abs/2507.01123v1",
          "size": "4330kb",
          "version": "v1"
        }
      ],
      "title": "Landslide Detection and Mapping Using Deep Learning Across Multi-Source Satellite Data and Geographic Regions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01123",
        "PDF": "https://arxiv.org/pdf/2507.01123"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study focuses on landslide detection using deep learning and satellite data integration, without mention of LLM training data processes."
      },
      "source": "arXiv"
    },
    {
      "id": "2401.12248",
      "abstract": "This work proposes a multi-circuit quantum lattice Boltzmann method (QLBM) algorithm that leverages parallel quantum computing to reduce quantum resource requirements. Computational fluid dynamics (CFD) simulations often entail a large computational burden on classical computers. At present, these simulations can require up to trillions of grid points and millions of time steps. To reduce costs, novel architectures like quantum computers may be intrinsically more efficient for these computations. Current quantum algorithms for solving CFD problems are based on single quantum circuits and, in many cases, use lattice-based methods. Current quantum devices are adorned with sufficient noise to make large and deep circuits untenable. We introduce a multiple-circuit algorithm for a quantum lattice Boltzmann method (QLBM) solve of the incompressible Navier--Stokes equations. The method, called QLBM-frugal, aims to create more practical quantum circuits and strategies for differential equation-based problems. The presented method is validated and demonstrated for 2D lid-driven cavity flow. The two-circuit algorithm shows a marked reduction in CNOT gates, which consume the majority of the runtime on quantum devices. Compared to the baseline QLBM technique, a two-circuit strategy shows increasingly large improvements in gate counts as the qubit size, or problem size, increases. For 64 lattice sites, the CNOT count was reduced by 35%, and the gate depth decreased by 16%. This strategy also enables concurrent circuit execution, further halving the seen gate depth.",
      "authors": [
        "Melody Lee",
        "Zhixin Song",
        "Sriharsha Kocherla",
        "Austin Adams",
        "Alexander Alexeev",
        "Spencer H. Bryngelson"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Emerging Technologies (cs.ET)",
        "Computational Physics (physics.comp-ph)",
        "Fluid Dynamics (physics.flu-dyn)"
      ],
      "submission_historys": [
        {
          "date": "2024-01-20T15:32:01+00:00",
          "link": "https://arxiv.org/abs/2401.12248v1",
          "size": "1166kb",
          "version": "v1"
        },
        {
          "date": "2024-04-11T16:48:07+00:00",
          "link": "https://arxiv.org/abs/2401.12248v2",
          "size": "1172kb",
          "version": "v2"
        },
        {
          "date": "2024-12-30T17:04:56+00:00",
          "link": "https://arxiv.org/abs/2401.12248v3",
          "size": "1402kb",
          "version": "v3"
        }
      ],
      "title": "A multiple-circuit approach to quantum resource reduction with application to the quantum lattice Boltzmann method",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.12248",
        "HTML": "https://arxiv.org/html/2401.12248",
        "PDF": "https://arxiv.org/pdf/2401.12248"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with quantum computing and a method for solving computational fluid dynamics problems. It does not address any aspect of LLM training data collection or processing."
      },
      "repo_urls": [
        "https://github.com/comp-physics/QLBM-frugal"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.22868",
      "abstract": "In this paper, we propose the CrossNAS framework, an automated approach for exploring a vast, multidimensional search space that spans various design abstraction layers-circuits, architecture, and systems-to optimize the deployment of machine learning workloads on analog processing-in-memory (PIM) systems. CrossNAS leverages the single-path one-shot weight-sharing strategy combined with the evolutionary search for the first time in the context of PIM system mapping and optimization. CrossNAS sets a new benchmark for PIM neural architecture search (NAS), outperforming previous methods in both accuracy and energy efficiency while maintaining comparable or shorter search times.",
      "authors": [
        "Md Hasibul Amin",
        "Mohammadreza Mohammadi",
        "Jason D. Bakos",
        "and Ramtin Zand"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Emerging Technologies (cs.ET)",
        "Hardware Architecture (cs.AR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-28T21:00:49+00:00",
          "link": "https://arxiv.org/abs/2505.22868v1",
          "size": "3063kb",
          "version": "v1"
        }
      ],
      "title": "CrossNAS: A Cross-Layer Neural Architecture Search Framework for PIM Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.22868",
        "HTML": "https://arxiv.org/html/2505.22868",
        "PDF": "https://arxiv.org/pdf/2505.22868"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a neural architecture search framework for PIM systems, which is unrelated to LLM training data processing."
      },
      "tasks": [
        "Neural Architecture Search"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.17015",
      "abstract": "There is a class of entropy-coding methods which do not substitute symbols by code words (such as Huffman coding), but operate on intervals or ranges. This class includes three prominent members: conventional arithmetic coding, range coding, and coding based on asymmetric numeral systems. To determine the correct symbol in the decoder, each of these methods requires the comparison of a state variable with subinterval boundaries. In adaptive operation, considering varying symbol statistics, an array of interval boundaries must additionally be kept up to date. The larger the symbol alphabet, the more time-consuming both the search for the correct subinterval and the updating of interval borders become.\n  Detailed pseudo-code is used to discuss different approaches to speed up the symbol search in the decoder and the adaptation of the array of interval borders, both depending on the chosen alphabet size. It is shown that reducing the $\\mathcal{O}$-complexity does not lead to an acceleration in practical implementations if the alphabet size is too small. In adaptive compression mode, the binary indexing method proves to be superior when considering the overall processing time. Although the symbol search (in the decoder) takes longer than with other algorithms, the faster updating of the array of interval borders more than compensates for this disadvantage. A variant of the binary indexing method is proposed, which is more flexible and has a partially lower complexity than the original approach.",
      "authors": [
        "Tilo Strutz and Nico Schreiber"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Data Structures and Algorithms (cs.DS)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-25T15:17:40+00:00",
          "link": "https://arxiv.org/abs/2409.17015v1",
          "size": "211kb",
          "version": "v1"
        }
      ],
      "title": "Investigations on Algorithm Selection for Interval-Based Coding Methods",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.17015",
        "HTML": "https://arxiv.org/html/2409.17015",
        "PDF": "https://arxiv.org/pdf/2409.17015"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses methods for interval-based entropy coding, which does not relate to LLM training data processing or data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.05329",
      "abstract": "We propose an efficient knowledge transfer approach for model-based reinforcement learning, addressing the challenge of deploying large world models in resource-constrained environments. Our method distills a high-capacity multi-task agent (317M parameters) into a compact 1M parameter model, achieving state-of-the-art performance on the MT30 benchmark with a normalized score of 28.45, a substantial improvement over the original 1M parameter model's score of 18.93. This demonstrates the ability of our distillation technique to consolidate complex multi-task knowledge effectively. Additionally, we apply FP16 post-training quantization, reducing the model size by 50% while maintaining performance. Our work bridges the gap between the power of large models and practical deployment constraints, offering a scalable solution for efficient and accessible multi-task reinforcement learning in robotics and other resource-limited domains.",
      "authors": [
        "Dmytro Kuzmenko",
        "Nadiya Shvai"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-09T15:55:08+00:00",
          "link": "https://arxiv.org/abs/2501.05329v1",
          "size": "137kb",
          "version": "v1"
        }
      ],
      "title": "Knowledge Transfer in Model-Based Reinforcement Learning Agents for Efficient Multi-Task Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.05329",
        "HTML": "https://arxiv.org/html/2501.05329",
        "PDF": "https://arxiv.org/pdf/2501.05329"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses reinforcement learning and model distillation techniques for efficient multi-task learning, unrelated to LLM training data processing."
      },
      "tasks": [
        "Model-based Reinforcement Learning",
        "Multi-Task Learning",
        "Quantization",
        "reinforcement-learning",
        "Reinforcement Learning",
        "Transfer Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2311.13155",
      "abstract": "We propose a thresholding algorithm to Willmore-type flows in $\\mathbb{R}^N$. This algorithm is constructed based on the asymptotic expansion of the solution to the initial value problem for a fourth order linear parabolic partial differential equation whose initial data is the indicator function on the compact set $\\Omega_0$. The main results of this paper demonstrate that the boundary $\\partial\\Omega(t)$ of the new set $\\Omega(t)$, generated by our algorithm, is included in $O(t)$-neighborhood of $\\partial\\Omega_0$ for small $t>0$ and that the normal velocity from $ \\partial\\Omega_0 $ to $ \\partial\\Omega(t) $ is nearly equal to the $L^2$-gradient of Willmore-type energy for small $ t>0 $. Finally, numerical examples of planar curves governed by the Willmore flow are provided by using our thresholding algorithm.",
      "authors": [
        "Katsuyuki Ishii",
        "Yoshihito Kohsaka",
        "Nobuhito Miyake",
        "Koya Sakakibara"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Analysis of PDEs (math.AP)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2023-11-22T04:35:02+00:00",
          "link": "https://arxiv.org/abs/2311.13155v1",
          "size": "144kb",
          "version": "v1"
        },
        {
          "date": "2023-11-25T02:21:34+00:00",
          "link": "https://arxiv.org/abs/2311.13155v2",
          "size": "144kb",
          "version": "v2"
        },
        {
          "date": "2023-12-17T03:27:27+00:00",
          "link": "https://arxiv.org/abs/2311.13155v3",
          "size": "144kb",
          "version": "v3"
        },
        {
          "date": "2024-02-17T03:47:59+00:00",
          "link": "https://arxiv.org/abs/2311.13155v4",
          "size": "144kb",
          "version": "v4"
        },
        {
          "date": "2024-11-30T05:34:25+00:00",
          "link": "https://arxiv.org/abs/2311.13155v5",
          "size": "171kb",
          "version": "v5"
        }
      ],
      "title": "A thresholding algorithm to Willmore-type flows via fourth order linear parabolic equation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2311.13155",
        "HTML": "https://arxiv.org/html/2311.13155",
        "PDF": "https://arxiv.org/pdf/2311.13155"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a thresholding algorithm for Willmore-type flows and does not address any aspect of LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.02697",
      "abstract": "Artificial neural networks (ANNs) have fundamentally transformed the field of computer vision, providing unprecedented performance. However, these ANNs for image processing demand substantial computational resources, often hindering real-time operation. In this paper, we demonstrate an optical encoder that can perform convolution simultaneously in three color channels during the image capture, effectively implementing several initial convolutional layers of a ANN. Such an optical encoding results in ~24,000 times reduction in computational operations, with a state-of-the art classification accuracy (~73.2%) in free-space optical system. In addition, our analog optical encoder, trained for CIFAR-10 data, can be transferred to the ImageNet subset, High-10, without any modifications, and still exhibits moderate accuracy. Our results evidence the potential of hybrid optical/digital computer vision system in which the optical frontend can pre-process an ambient scene to reduce the energy and latency of the whole computer vision system.",
      "authors": [
        "Minho Choi",
        "Jinlin Xiang",
        "Anna Wirth-Singh",
        "Seung-Hwan Baek",
        "Eli Shlizerman",
        "and Arka Majumdar"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Optics (physics.optics)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-05T00:49:47+00:00",
          "link": "https://arxiv.org/abs/2411.02697v1",
          "size": "47536kb",
          "version": "v1"
        }
      ],
      "title": "Transferable polychromatic optical encoder for neural networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.02697",
        "HTML": "https://arxiv.org/html/2411.02697",
        "PDF": "https://arxiv.org/pdf/2411.02697"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes an optical encoder for neural networks to reduce computational operations for image processing, without addressing any LLM training data processing topics."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2202.13652",
      "abstract": "This paper considers the problem of cost-aware downlink sum-rate maximization via joint optimal radio access technologies (RATs) assignment and power allocation in next-generation heterogeneous wireless networks (HetNets). We consider a future HetNet comprised of multi-RATs and serving multi-connectivity edge devices (EDs), and we formulate the problem as mixed-integer non-linear programming (MINP) problem. Due to the high complexity and combinatorial nature of this problem and the difficulty to solve it using conventional methods, we propose a hierarchical multi-agent deep reinforcement learning (DRL)-based framework, called DeepRAT, to solve it efficiently and learn system dynamics. In particular, the DeepRAT framework decomposes the problem into two main stages; the RATs-EDs assignment stage, which implements a single-agent Deep Q Network (DQN) algorithm, and the power allocation stage, which utilizes a multi-agent Deep Deterministic Policy Gradient (DDPG) algorithm. Using simulations, we demonstrate how the various DRL agents efficiently interact to learn system dynamics and derive the global optimal policy. Furthermore, our simulation results show that the proposed DeepRAT algorithm outperforms existing state-of-the-art heuristic approaches in terms of network utility. Finally, we quantitatively show the ability of the DeepRAT model to quickly and dynamically adapt to abrupt changes in network dynamics, such as EDs mobility.",
      "authors": [
        "Abdulmalik Alwarafy",
        "Bekir Sait Ciftler",
        "Mohamed Abdallah",
        "Mounir Hamdi",
        "and Naofal Al-Dhahir"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2022-02-28T09:49:44+00:00",
          "link": "https://arxiv.org/abs/2202.13652v1",
          "size": "4656kb",
          "version": "v1"
        }
      ],
      "title": "Hierarchical Multi-Agent DRL-Based Framework for Joint Multi-RAT Assignment and Dynamic Resource Allocation in Next-Generation HetNets",
      "links": {
        "Abstract": "https://arxiv.org/abs/2202.13652",
        "PDF": "https://arxiv.org/pdf/2202.13652"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research addresses joint multi-RAT assignment and dynamic resource allocation using DRL for wireless networks, not involving LLM training data processing or related data engineering tasks."
      },
      "tasks": [
        "Deep Reinforcement Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2403.02240",
      "abstract": "The recent development of quantum computing, which uses entanglement, superposition, and other quantum fundamental concepts, can provide substantial processing advantages over traditional computing. These quantum features help solve many complex problems that cannot be solved otherwise with conventional computing methods. These problems include modeling quantum mechanics, logistics, chemical-based advances, drug design, statistical science, sustainable energy, banking, reliable communication, and quantum chemical engineering. The last few years have witnessed remarkable progress in quantum software and algorithm creation and quantum hardware research, which has significantly advanced the prospect of realizing quantum computers. It would be helpful to have comprehensive literature research on this area to grasp the current status and find outstanding problems that require considerable attention from the research community working in the quantum computing industry. To better understand quantum computing, this paper examines the foundations and vision based on current research in this area. We discuss cutting-edge developments in quantum computer hardware advancement and subsequent advances in quantum cryptography, quantum software, and high-scalability quantum computers. Many potential challenges and exciting new trends for quantum technology research and development are highlighted in this paper for a broader debate.",
      "authors": [
        "Sukhpal Singh Gill",
        "Oktay Cetinkaya",
        "Stefano Marrone",
        "Daniel Claudino",
        "David Haunschild",
        "Leon Schlote",
        "Huaming Wu",
        "Carlo Ottaviani",
        "Xiaoyuan Liu",
        "Sree Pragna Machupalli",
        "Kamalpreet Kaur",
        "Priyansh Arora",
        "Ji Liu",
        "Ahmed Farouk",
        "Houbing Herbert Song",
        "Steve Uhlig and Kotagiri Ramamohanarao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Emerging Technologies (cs.ET)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-04T17:33:18+00:00",
          "link": "https://arxiv.org/abs/2403.02240v1",
          "size": "438kb",
          "version": "v1"
        },
        {
          "date": "2024-04-24T16:38:14+00:00",
          "link": "https://arxiv.org/abs/2403.02240v2",
          "size": "396kb",
          "version": "v2"
        },
        {
          "date": "2024-06-05T15:30:26+00:00",
          "link": "https://arxiv.org/abs/2403.02240v3",
          "size": "396kb",
          "version": "v3"
        },
        {
          "date": "2024-09-06T11:11:25+00:00",
          "link": "https://arxiv.org/abs/2403.02240v4",
          "size": "399kb",
          "version": "v4"
        },
        {
          "date": "2025-04-07T15:07:51+00:00",
          "link": "https://arxiv.org/abs/2403.02240v5",
          "size": "400kb",
          "version": "v5"
        }
      ],
      "title": "Quantum Computing: Vision and Challenges",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.02240",
        "HTML": "https://arxiv.org/html/2403.02240",
        "PDF": "https://arxiv.org/pdf/2403.02240"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper provides an overview of quantum computing developments and challenges, without addressing any aspects specific to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.09851",
      "abstract": "We introduce SymbolFit, a framework that automates parametric modeling by using symbolic regression to perform a machine-search for functions that fit the data while simultaneously providing uncertainty estimates in a single run. Traditionally, constructing a parametric model to accurately describe binned data has been a manual and iterative process, requiring an adequate functional form to be determined before the fit can be performed. The main challenge arises when the appropriate functional forms cannot be derived from first principles, especially when there is no underlying true closed-form function for the distribution. In this work, we develop a framework that automates and streamlines the process by utilizing symbolic regression, a machine learning technique that explores a vast space of candidate functions without requiring a predefined functional form because the functional form itself is treated as a trainable parameter, making the process far more efficient and effortless than traditional regression methods. We demonstrate the framework in high-energy physics experiments at the CERN Large Hadron Collider (LHC) using five real proton-proton collision datasets from new physics searches, including background modeling in resonance searches for high-mass dijet, trijet, paired-dijet, diphoton, and dimuon events. We show that our framework can flexibly and efficiently generate a wide range of candidate functions that fit a nontrivial distribution well using a simple fit configuration that varies only by random seed, and that the same fit configuration, which defines a vast function space, can also be applied to distributions of different shapes, whereas achieving a comparable result with traditional methods would have required extensive manual effort.",
      "authors": [
        "Ho Fung Tsoi",
        "Dylan Rankin",
        "Cecile Caillol",
        "Miles Cranmer",
        "Sridhara Dasu",
        "Javier Duarte",
        "Philip Harris",
        "Elliot Lipeles",
        "Vladimir Loncar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "High Energy Physics - Experiment (hep-ex)",
        "Machine Learning (cs.LG)",
        "Data Analysis, Statistics and Probability (physics.data-an)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-15T00:09:37+00:00",
          "link": "https://arxiv.org/abs/2411.09851v1",
          "size": "6848kb",
          "version": "v1"
        },
        {
          "date": "2025-02-11T02:11:22+00:00",
          "link": "https://arxiv.org/abs/2411.09851v2",
          "size": "8120kb",
          "version": "v2"
        },
        {
          "date": "2025-03-02T23:29:50+00:00",
          "link": "https://arxiv.org/abs/2411.09851v3",
          "size": "8121kb",
          "version": "v3"
        },
        {
          "date": "2025-05-11T02:19:58+00:00",
          "link": "https://arxiv.org/abs/2411.09851v4",
          "size": "8125kb",
          "version": "v4"
        }
      ],
      "title": "SymbolFit: Automatic Parametric Modeling with Symbolic Regression",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.09851",
        "PDF": "https://arxiv.org/pdf/2411.09851"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a symbolic regression framework for parametric modeling in high-energy physics, which does not relate to the processing or engineering of training data for LLMs."
      },
      "tasks": [
        "Form",
        "regression",
        "Symbolic Regression"
      ],
      "repo_urls": [
        "https://github.com/hftsoi/symbolfit"
      ],
      "source": "arXiv"
    },
    {
      "id": "2103.01831",
      "abstract": "In collaborative robotic applications, human and robot have to work together during a whole shift for executing a sequence of jobs. The performance of the human robot team can be enhanced by scheduling the right tasks to the human and the robot. The scheduling should consider the task execution constraints, the variability in the task execution by the human, and the job quality of the human. Therefore, it is necessary to dynamically schedule the assigned tasks. In this paper, we propose a two-layered architecture for task allocation and scheduling in a collaborative cell. Job quality is explicitly considered during the allocation of the tasks and over a sequence of jobs. The tasks are dynamically scheduled based on the real time monitoring of the human's activities. The effectiveness of the proposed architecture is experimentally validated.",
      "authors": [
        "Andrea Pupa",
        "Wietse Van Dijk and Cristian Secchi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2021-03-02T16:12:46+00:00",
          "link": "https://arxiv.org/abs/2103.01831v1",
          "size": "2550kb",
          "version": "v1"
        },
        {
          "date": "2021-03-03T05:45:48+00:00",
          "link": "https://arxiv.org/abs/2103.01831v2",
          "size": "2550kb",
          "version": "v2"
        }
      ],
      "title": "A Human-Centered Dynamic Scheduling Architecture for Collaborative Application",
      "links": {
        "Abstract": "https://arxiv.org/abs/2103.01831",
        "PDF": "https://arxiv.org/pdf/2103.01831"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses task allocation and scheduling in collaborative robotics, with no discussion related to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2408.08664",
      "abstract": "In the field of operational modal analysis (OMA), obtained modal information is frequently used to assess the current state of aerospace, mechanical, offshore and civil structures. However, the stochasticity of operational systems and the lack of forcing information can lead to inconsistent results. Quantifying the uncertainty of the recovered modal parameters through OMA is therefore of significant value. In this article, a new perspective on Bayesian OMA is proposed: a Bayesian stochastic subspace identification (SSI) algorithm. Distinct from existing approaches to Bayesian OMA, a hierarchical probabilistic model is embedded at the core of covariance-driven SSI. Through substitution of canonical correlation analysis with a Bayesian equivalent, posterior distributions over the modal properties are obtained. Two inference schemes are presented for the proposed Bayesian formulation: Markov Chain Monte Carlo and variational Bayes. Two case studies are then explored. The first is benchmark study using data from a simulated, multi degree-of-freedom, linear system. Following application of Bayesian SSI, it is shown that the same posterior is targeted and recovered by both inference schemes, with good agreement between the posterior mean and the conventional SSI result. The second study applies the variational form to data obtained from an in-service structure: The Z24 bridge. The results of this study are presented at single model orders, and then using a stabilisation diagram. The recovered posterior uncertainty is presented and compared to the classic SSI result. It is observed that the posterior distributions with mean values coinciding with the natural frequencies exhibit lower variance than values situated away from the natural frequencies.",
      "authors": [
        "Brandon J. O'Connell",
        "Max D. Champneys",
        "Timothy J. Rogers"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-16T11:11:56+00:00",
          "link": "https://arxiv.org/abs/2408.08664v1",
          "size": "6175kb",
          "version": "v1"
        },
        {
          "date": "2024-08-19T12:20:26+00:00",
          "link": "https://arxiv.org/abs/2408.08664v2",
          "size": "4183kb",
          "version": "v2"
        }
      ],
      "title": "A new perspective on Bayesian Operational Modal Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.08664",
        "HTML": "https://arxiv.org/html/2408.08664",
        "PDF": "https://arxiv.org/pdf/2408.08664"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is concerned with Bayesian operational modal analysis and stochastic subspace identification, with no connection to LLM training data processing or engineering."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2501.09635",
      "abstract": "Face recognition technology has dramatically transformed the landscape of security, surveillance, and authentication systems, offering a user-friendly and non-invasive biometric solution. However, despite its significant advantages, face recognition systems face increasing threats from physical and digital spoofing attacks. Current research typically treats face recognition and attack detection as distinct classification challenges. This approach necessitates the implementation of separate models for each task, leading to considerable computational complexity, particularly on devices with limited resources. Such inefficiencies can stifle scalability and hinder performance. In response to these challenges, this paper introduces an innovative unified model designed for face recognition and detection of physical and digital attacks. By leveraging the advanced Swin Transformer backbone and incorporating HiLo attention in a convolutional neural network framework, we address unified face recognition and spoof attack detection more effectively. Moreover, we introduce augmentation techniques that replicate the traits of physical and digital spoofing cues, significantly enhancing our model robustness. Through comprehensive experimental evaluation across various datasets, we showcase the effectiveness of our model in unified face recognition and spoof detection. Additionally, we confirm its resilience against unseen physical and digital spoofing attacks, underscoring its potential for real-world applications.",
      "authors": [
        "Arun Kunwar and Ajita Rattani"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-16T16:24:21+00:00",
          "link": "https://arxiv.org/abs/2501.09635v1",
          "size": "1766kb",
          "version": "v1"
        }
      ],
      "title": "Unified Face Matching and Physical-Digital Spoofing Attack Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.09635",
        "HTML": "https://arxiv.org/html/2501.09635",
        "PDF": "https://arxiv.org/pdf/2501.09635"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on face recognition and spoofing attack detection, and although it mentions innovative model design, it does not address LLM training data processing."
      },
      "tasks": [
        "Face Recognition"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.17926",
      "abstract": "The extensive development of the field of spiking neural networks has led to many areas of research that have a direct impact on people's lives. As the most bio-similar of all neural networks, spiking neural networks not only allow the solution of recognition and clustering problems (including dynamics), but also contribute to the growing knowledge of the human nervous system. Our analysis has shown that the hardware implementation is of great importance, since the specifics of the physical processes in the network cells affect their ability to simulate the neural activity of living neural tissue, the efficiency of certain stages of information processing, storage and transmission. This survey reviews existing hardware neuromorphic implementations of bio-inspired spiking networks in the \"semiconductor\", \"superconductor\" and \"optical\" domains. Special attention is given to the possibility of effective \"hybrids\" of different approaches",
      "authors": [
        "Andrey E. Schegolev",
        "Marina V. Bastrakova",
        "Michael A. Sergeev",
        "Anastasia A. Maksimovskaya",
        "Nikolay V. Klenov",
        "Igor I. Soloviev"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)",
        "Mesoscale and Nanoscale Physics (cond-mat.mes-hall)",
        "Superconductivity (cond-mat.supr-con)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-23T19:33:43+00:00",
          "link": "https://arxiv.org/abs/2412.17926v1",
          "size": "24850kb",
          "version": "v1"
        }
      ],
      "title": "Contemporary implementations of spiking bio-inspired neural networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.17926",
        "HTML": "https://arxiv.org/html/2412.17926",
        "PDF": "https://arxiv.org/pdf/2412.17926"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper surveys hardware implementations of spiking neural networks and their potential, without involving LLM training data processing or engineering activities."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2407.16581",
      "abstract": "We say that a matrix $P$ with non-negative entries majorizes another such matrix $Q$ if there is a stochastic matrix $T$ such that $Q=TP$. We study matrix majorization in large samples and in the catalytic regime in the case where the columns of the matrices need not have equal support, as has been assumed in earlier works. We focus on two cases: either there are no support restrictions (except for requiring a non-empty intersection for the supports) or the final column dominates the others. Using real-algebraic methods, we identify sufficient and almost necessary conditions for majorization in large samples or when using catalytic states under these support conditions. These conditions are given in terms of multi-partite divergences that generalize the R\\'enyi divergences. We notice that varying support conditions dramatically affect the relevant set of divergences. Our results find an application in the theory of catalytic state transformation in quantum thermodynamics.",
      "authors": [
        "Frits Verhagen",
        "Marco Tomamichel",
        "Erkka Haapasalo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Statistics Theory (math.ST)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)",
        "Probability (math.PR)",
        "Quantum Physics (quant-ph)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-23T15:37:17+00:00",
          "link": "https://arxiv.org/abs/2407.16581v1",
          "size": "278kb",
          "version": "v1"
        }
      ],
      "title": "Matrix majorization in large samples with varying support restrictions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.16581",
        "HTML": "https://arxiv.org/html/2407.16581",
        "PDF": "https://arxiv.org/pdf/2407.16581"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses matrix majorization in mathematical contexts, particularly in quantum thermodynamics, with no relevance to LLM training data processing methods or applications."
      },
      "source": "arXiv"
    },
    {
      "id": "2103.01818",
      "abstract": "The new paradigm of human-robot collaboration has led to the creation of shared work environments in which humans and robots work in close contact with each other. Consequently, the safety regulations have been updated addressing these new scenarios. The mere application of these regulations may lead to a very inefficient behavior of the robot. In order to preserve safety for the human operators and allow the robot to reach a desired configuration in a safe and efficient way, a two layers architecture for trajectory planning and scaling is proposed. The first layer calculates the nominal trajectory and continuously adapts it based on the human behavior. The second layer, which explicitly considers the safety regulations, scales the robot velocity and requests for a new trajectory if the robot speed drops. The proposed architecture is experimentally validated on a Pilz PRBT manipulator.",
      "authors": [
        "Andrea Pupa",
        "Mohammad Arrfou",
        "Gildo Andreoni and Cristian Secchi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2021-03-02T15:57:37+00:00",
          "link": "https://arxiv.org/abs/2103.01818v1",
          "size": "14833kb",
          "version": "v1"
        }
      ],
      "title": "A Safety-Aware Kinodynamic Architecture for Human-Robot Collaboration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2103.01818",
        "PDF": "https://arxiv.org/pdf/2103.01818"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes an architecture for human-robot collaboration focusing on safety and trajectory planning. It is unrelated to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2209.10517",
      "abstract": "In this paper, we obtain the following equally important new results:\n  We first extend the notion of {\\em probabilistic pushdown automaton} to {\\em probabilistic $\\omega$-pushdown automaton} for the first time and study the model-checking question of {\\em stateless probabilistic $\\omega$-pushdown system ($\\omega$-pBPA)} against $\\omega$-PCTL (defined by Chatterjee, Sen, and Henzinger in \\cite{CSH08}), showing that model-checking of {\\em stateless probabilistic $\\omega$-pushdown systems ($\\omega$-pBPA)} against $\\omega$-PCTL is generally undecidable. Our approach is to construct $\\omega$-PCTL formulas encoding the {\\em Post Correspondence Problem}.\n  We study and analyze the soundness and completeness of {\\em weak bisimulation} for {\\em $\\omega$ probabilistic computational tree logic ($\\omega$-PCTL$^*$)}, showing that it is sound and complete. Our models are probabilistic labelled transition systems induced by probabilistic $\\omega$-pushdown automata defined in this paper.",
      "authors": [
        "Deren Lin",
        "Tianrong Lin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Formal Languages and Automata Theory (cs.FL)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "2022-09-21T17:33:48+00:00",
          "link": "https://arxiv.org/abs/2209.10517v1",
          "size": "105kb",
          "version": "v1"
        },
        {
          "date": "2022-09-22T13:59:51+00:00",
          "link": "https://arxiv.org/abs/2209.10517v2",
          "size": "109kb",
          "version": "v2"
        },
        {
          "date": "2022-10-28T10:37:35+00:00",
          "link": "https://arxiv.org/abs/2209.10517v3",
          "size": "109kb",
          "version": "v3"
        },
        {
          "date": "2023-03-28T12:38:45+00:00",
          "link": "https://arxiv.org/abs/2209.10517v4",
          "size": "109kb",
          "version": "v4"
        },
        {
          "date": "2023-06-07T15:51:37+00:00",
          "link": "https://arxiv.org/abs/2209.10517v5",
          "size": "147kb",
          "version": "v5"
        },
        {
          "date": "2023-06-11T02:07:30+00:00",
          "link": "https://arxiv.org/abs/2209.10517v6",
          "size": "147kb",
          "version": "v6"
        },
        {
          "date": "2023-08-08T00:42:01+00:00",
          "link": "https://arxiv.org/abs/2209.10517v7",
          "size": "153kb",
          "version": "v7"
        },
        {
          "date": "2024-07-07T12:14:42+00:00",
          "link": "https://arxiv.org/abs/2209.10517v8",
          "size": "145kb",
          "version": "v8"
        },
        {
          "date": "2024-07-21T17:27:23+00:00",
          "link": "https://arxiv.org/abs/2209.10517v9",
          "size": "66kb",
          "version": "v9"
        },
        {
          "date": "2024-08-05T08:42:58+00:00",
          "link": "https://arxiv.org/abs/2209.10517v10",
          "size": "76kb",
          "version": "v10"
        },
        {
          "date": "2024-08-19T01:48:55+00:00",
          "link": "https://arxiv.org/abs/2209.10517v11",
          "size": "80kb",
          "version": "v11"
        },
        {
          "date": "2025-06-16T13:21:53+00:00",
          "link": "https://arxiv.org/abs/2209.10517v12",
          "size": "44kb",
          "version": "v12"
        },
        {
          "date": "2025-07-03T13:41:03+00:00",
          "link": "https://arxiv.org/abs/2209.10517v13",
          "size": "40kb",
          "version": "v13"
        }
      ],
      "title": "On Model-Checking Probabilistic $\\omega$-Pushdown Systems, and $\\omega$-PCTL$^*$ Characterization of Weak Bisimulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2209.10517",
        "HTML": "https://arxiv.org/html/2209.10517",
        "PDF": "https://arxiv.org/pdf/2209.10517"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses theoretical aspects of probabilistic automata and model-checking, which are unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2407.11861",
      "abstract": "Warning: This paper contains memes that may be offensive to some readers.\n  Multimodal Internet Memes are now a ubiquitous fixture in online discourse. One strand of meme-based research is the classification of memes according to various affects, such as sentiment and hate, supported by manually compiled meme datasets. Understanding the unique characteristics of memes is crucial for meme classification. Unlike other user-generated content, memes spread via memetics, i.e. the process by which memes are imitated and transformed into symbols used to create new memes. In effect, there exists an ever-evolving pool of visual and linguistic symbols that underpin meme culture and are crucial to interpreting the meaning of individual memes. The current approach of training supervised learning models on static datasets, without taking memetics into account, limits the depth and accuracy of meme interpretation. We argue that meme datasets must contain genuine memes, as defined via memetics, so that effective meme classifiers can be built. In this work, we develop a meme identification protocol which distinguishes meme from non-memetic content by recognising the memetics within it. We apply our protocol to random samplings of the leading 7 meme classification datasets and observe that more than half (50. 4\\%) of the evaluated samples were found to contain no signs of memetics. Our work also provides a meme typology grounded in memetics, providing the basis for more effective approaches to the interpretation of memes and the creation of meme datasets.",
      "authors": [
        "Muzhaffar Hazman",
        "Susan McKeever",
        "Josephine Griffith"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-16T15:48:36+00:00",
          "link": "https://arxiv.org/abs/2407.11861v1",
          "size": "9979kb",
          "version": "v1"
        }
      ],
      "title": "What Makes a Meme a Meme? Identifying Memes for Memetics-Aware Dataset Creation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.11861",
        "HTML": "https://arxiv.org/html/2407.11861",
        "PDF": "https://arxiv.org/pdf/2407.11861"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes a protocol for identifying genuine memes for dataset creation, which is indirectly related to data engineering as it involves dataset creation, but not specifically for LLMs."
      },
      "tasks": [
        "Meme Classification"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.11382",
      "abstract": "Haptic affection plays a crucial role in user experience, particularly in the automotive industry where the tactile quality of components can influence customer satisfaction. This study aims to accurately predict the affective property of a car door by only watching the force or torque profile of it when opening. To this end, a deep learning model is designed to capture the underlying relationships between force profiles and user-defined adjective ratings, providing insights into the door-opening experience. The dataset employed in this research includes force profiles and user adjective ratings collected from six distinct car models, reflecting a diverse set of door-opening characteristics and tactile feedback. The model's performance is assessed using Leave-One-Out Cross-Validation, a method that measures its generalization capability on unseen data. The results demonstrate that the proposed model achieves a high level of prediction accuracy, indicating its potential in various applications related to haptic affection and design optimization in the automotive industry.",
      "authors": [
        "Mudassir Ibrahim Awan",
        "Ahsan Raza",
        "Waseem Hassan",
        "Ki-Uk Kyung",
        "and Seokhee Jeon"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-18T08:58:53+00:00",
          "link": "https://arxiv.org/abs/2411.11382v1",
          "size": "4686kb",
          "version": "v1"
        },
        {
          "date": "2025-05-02T05:49:56+00:00",
          "link": "https://arxiv.org/abs/2411.11382v2",
          "size": "4212kb",
          "version": "v2"
        },
        {
          "date": "2025-05-22T08:11:09+00:00",
          "link": "https://arxiv.org/abs/2411.11382v3",
          "size": "4440kb",
          "version": "v3"
        }
      ],
      "title": "Quantifying Haptic Affection of Car Door through Data-Driven Analysis of Force Profile",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.11382",
        "HTML": "https://arxiv.org/html/2411.11382",
        "PDF": "https://arxiv.org/pdf/2411.11382"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study focuses on predicting haptic affection of car doors using force profiles and a deep learning model, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.11823",
      "abstract": "In-wheel drive (IWD) systems enhance the responsiveness, traction, and maintenance efficiency of vehicles by enabling each wheel to operate independently. This paper proposes a novel robust torque-observed valve-based control (RTOVC) framework to address velocity tracking in hydraulic IWDs that actuate heavy-duty wheeled mobile robots (HWMRs), considering such challenges as wheel slippages, sensor limitations, rough terrains, and modeling uncertainties. To overcome the sensor-dependent control systems associated with the closed-loop torque/pressure in hydraulic IWD-actuated HWMRs, a robust observer network based on an adaptive barrier Lyapunov function (BLF) is proposed to estimate the required in-wheel motor torque to track the velocity references. Then, another adaptive BLF for valve control signals is employed to modulate the hydraulic fluid to generate the estimated torque for each IWD. The RTOVC strategy ensures user-defined safety within the logarithmic BLF framework by constraining the valve control signal, actual velocity, velocity tracking error, and torque of each hydraulic IWD in an HWMR to avoid exceeding specified limits. Despite its safety constraints, external disturbances, and modeling uncertainties, robustness and uniformly exponential stability of the RTOVC-applied hydraulic IWD mechanism are ensured in HWMRs. Experimental investigations using a 6,500-kg HWMR, actuated by four independent IWDs under intense disturbances and safety-defined constraints, validate the performance of the RTOVC.",
      "authors": [
        "Mehdi Heydari Shahna",
        "Pauli Mustalahti",
        "Jouni Mattila"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-18T09:16:03+00:00",
          "link": "https://arxiv.org/abs/2409.11823v1",
          "size": "4849kb",
          "version": "v1"
        },
        {
          "date": "2024-12-04T16:30:07+00:00",
          "link": "https://arxiv.org/abs/2409.11823v2",
          "size": "13663kb",
          "version": "v2"
        }
      ],
      "title": "Robust Sensor-Limited Control with Safe Input-Output Constraints for Hydraulic In-Wheel Motor Drive Mobility Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.11823",
        "PDF": "https://arxiv.org/pdf/2409.11823"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study proposes a control framework for hydraulic in-wheel motor drive systems in mobile robots, unrelated to the processing or engineering of LLM training data."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2103.12355",
      "abstract": "The role of symmetry in Boolean functions $f:\\{0,1\\}^n \\to \\{0,1\\}$ has been extensively studied in complexity theory. For example, symmetric functions, that is, functions that are invariant under the action of $S_n$, is an important class of functions in the study of Boolean functions. A function $f:\\{0,1\\}^n \\to \\{0,1\\}$ is called transitive (or weakly-symmetric) if there exists a transitive group $G$ of $S_n$ such that $f$ is invariant under the action of $G$ - that is the function value remains unchanged even after the bits of the input of $f$ are moved around according to some permutation $\\sigma \\in G$. Understanding various complexity measures of transitive functions has been a rich area of research for the past few decades.\n  In this work, we study transitive functions in light of several combinatorial measures. We look at the maximum separation between various pairs of measures for transitive functions. Such study for general Boolean functions has been going on for past many years. The best-known results for general Boolean functions have been nicely compiled by Aaronson et. al (STOC, 2021).\n  The separation between a pair of combinatorial measures is shown by constructing interesting functions that demonstrate the separation. But many of the celebrated separation results are via the construction of functions (like \"pointer functions\" from Ambainis et al. (JACM, 2017) and \"cheat-sheet functions\" Aaronson et al. (STOC, 2016)) that are not transitive. Hence, we don't have such separation between the pairs of measures for transitive functions.\n  In this paper we show how to modify some of these functions to construct transitive functions that demonstrate similar separations between pairs of combinatorial measures.",
      "authors": [
        "Sourav Chakraborty",
        "Chandrima Kayal",
        "Manaswi Paraashar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Complexity (cs.CC)"
      ],
      "submission_historys": [
        {
          "date": "2021-03-23T07:31:24+00:00",
          "link": "https://arxiv.org/abs/2103.12355v1",
          "size": "43kb",
          "version": "v1"
        },
        {
          "date": "2022-05-08T16:16:39+00:00",
          "link": "https://arxiv.org/abs/2103.12355v2",
          "size": "51kb",
          "version": "v2"
        },
        {
          "date": "2023-03-29T17:56:52+00:00",
          "link": "https://arxiv.org/abs/2103.12355v3",
          "size": "188kb",
          "version": "v3"
        },
        {
          "date": "2024-10-08T02:42:46+00:00",
          "link": "https://arxiv.org/abs/2103.12355v4",
          "size": "191kb",
          "version": "v4"
        },
        {
          "date": "2025-05-20T10:49:23+00:00",
          "link": "https://arxiv.org/abs/2103.12355v5",
          "size": "188kb",
          "version": "v5"
        },
        {
          "date": "2025-07-03T14:15:24+00:00",
          "link": "https://arxiv.org/abs/2103.12355v6",
          "size": "112kb",
          "version": "v6"
        }
      ],
      "title": "Separations between Combinatorial Measures for Transitive Functions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2103.12355",
        "HTML": "https://arxiv.org/html/2103.12355",
        "PDF": "https://arxiv.org/pdf/2103.12355"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores combinatorial measures for transitive Boolean functions, unrelated to any aspect of LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.01615",
      "abstract": "This paper proposes a new decentralized framework, named EDGChain-E (Encrypted-Data-Git Chain for Energy), designed to manage version-controlled, encrypted energy data using blockchain and the InterPlanetary File System. The framework incorporates a Decentralized Autonomous Organization (DAO) to orchestrate collaborative data governance across the lifecycle of energy research and operations, such as smart grid monitoring, demand forecasting, and peer-to-peer energy trading. In EDGChain-E, initial commits capture the full encrypted datasets-such as smart meter readings or grid telemetry-while subsequent updates are tracked as encrypted Git patches, ensuring integrity, traceability, and privacy. This versioning mechanism supports secure collaboration across multiple stakeholders (e.g., utilities, researchers, regulators) without compromising sensitive or regulated information. We highlight the framework's capability to maintain FAIR-compliant (Findable, Accessible, Interoperable, Reusable) provenance of encrypted data. By embedding hash-based content identifiers in Merkle trees, the system enables transparent, auditable, and immutable tracking of data changes, thereby supporting reproducibility and trust in decentralized energy applications.",
      "authors": [
        "Alper Alimoglu",
        "Kamil Erdayandi",
        "Mustafa A. Mustafa",
        "\\\"Umit Cali"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T11:33:12+00:00",
          "link": "https://arxiv.org/abs/2507.01615v1",
          "size": "2277kb",
          "version": "v1"
        }
      ],
      "title": "EDGChain-E: A Decentralized Git-Based Framework for Versioning Encrypted Energy Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01615",
        "HTML": "https://arxiv.org/html/2507.01615",
        "PDF": "https://arxiv.org/pdf/2507.01615"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a framework for managing encrypted energy data using blockchain and Git, which is unrelated to any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2406.00260",
      "abstract": "Learning to optimize is an approach that leverages training data to accelerate the solution of optimization problems. Many approaches use unrolling to parametrize the update step and learn optimal parameters. Although L2O has shown empirical advantages over classical optimization algorithms, memory restrictions often greatly limit the unroll length and learned algorithms usually do not provide convergence guarantees. In contrast, we introduce a novel method employing a greedy strategy that learns iteration-specific parameters by minimizing the function value at the next iteration. This enables training over significantly more iterations while maintaining constant device memory usage. We parameterize the update such that parameter learning is convex when the objective function is convex. In particular, we explore preconditioned gradient descent and an extension of Polyak's Heavy Ball Method with multiple parametrizations including a novel convolutional preconditioner. With our learned algorithms, convergence in the training set is proved even when the preconditioners are not necessarily symmetric nor positive definite. Convergence on a class of unseen functions is also obtained under certain assumptions, ensuring robust performance and generalization beyond the training data. We test our learned algorithms on two inverse problems, image deblurring and Computed Tomography, on which learned convolutional preconditioners demonstrate improved empirical performance over classical optimization algorithms such as Nesterov's Accelerated Gradient Method and the quasi-Newton method L-BFGS.",
      "authors": [
        "Patrick Fahy",
        "Mohammad Golbabaee",
        "Matthias J. Ehrhardt"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-01T01:49:37+00:00",
          "link": "https://arxiv.org/abs/2406.00260v1",
          "size": "11888kb",
          "version": "v1"
        },
        {
          "date": "2024-10-15T16:22:52+00:00",
          "link": "https://arxiv.org/abs/2406.00260v2",
          "size": "16483kb",
          "version": "v2"
        },
        {
          "date": "2024-11-11T13:15:58+00:00",
          "link": "https://arxiv.org/abs/2406.00260v3",
          "size": "16483kb",
          "version": "v3"
        },
        {
          "date": "2024-11-30T02:32:31+00:00",
          "link": "https://arxiv.org/abs/2406.00260v4",
          "size": "34023kb",
          "version": "v4"
        },
        {
          "date": "2024-12-05T01:21:47+00:00",
          "link": "https://arxiv.org/abs/2406.00260v5",
          "size": "34023kb",
          "version": "v5"
        },
        {
          "date": "2025-02-06T00:00:53+00:00",
          "link": "https://arxiv.org/abs/2406.00260v6",
          "size": "34019kb",
          "version": "v6"
        },
        {
          "date": "2025-06-25T22:04:46+00:00",
          "link": "https://arxiv.org/abs/2406.00260v7",
          "size": "4132kb",
          "version": "v7"
        },
        {
          "date": "2025-07-03T11:20:40+00:00",
          "link": "https://arxiv.org/abs/2406.00260v8",
          "size": "4135kb",
          "version": "v8"
        }
      ],
      "title": "Greedy Learning to Optimize with Convergence Guarantees",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.00260",
        "HTML": "https://arxiv.org/html/2406.00260",
        "PDF": "https://arxiv.org/pdf/2406.00260"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The work focuses on optimization algorithms and not on any aspect of LLM training data management or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.08779",
      "abstract": "Ensemble Kalman inversion (EKI) is a derivative-free, particle-based optimization method for solving inverse problems. It can be shown that EKI approximates a gradient flow, which allows the application of methods for accelerating gradient descent. Here, we show that Nesterov acceleration is effective in speeding up the reduction of the EKI cost function on a variety of inverse problems. We also implement Nesterov acceleration for two EKI variants, unscented Kalman inversion and ensemble transform Kalman inversion. Our specific implementation takes the form of a particle-level nudge that is demonstrably simple to couple in a black-box fashion with any existing EKI variant algorithms, comes with no additional computational expense, and with no additional tuning hyperparameters. This work shows a pathway for future research to translate advances in gradient-based optimization into advances in gradient-free Kalman optimization.",
      "authors": [
        "Sydney Vernon",
        "Eviatar Bach",
        "and Oliver R. A. Dunbar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Machine Learning (cs.LG)",
        "Computation (stat.CO)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-15T13:01:34+00:00",
          "link": "https://arxiv.org/abs/2501.08779v1",
          "size": "382kb",
          "version": "v1"
        },
        {
          "date": "2025-05-19T17:47:46+00:00",
          "link": "https://arxiv.org/abs/2501.08779v2",
          "size": "386kb",
          "version": "v2"
        }
      ],
      "title": "Nesterov Acceleration for Ensemble Kalman Inversion and Variants",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.08779",
        "HTML": "https://arxiv.org/html/2501.08779",
        "PDF": "https://arxiv.org/pdf/2501.08779"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses optimization methods for inverse problems, specifically Nesterov acceleration in ensemble Kalman inversion, which is unrelated to LLM data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2208.10241",
      "abstract": "Weak labeling is a popular weak supervision strategy for Named Entity Recognition (NER) tasks, with the goal of reducing the necessity for hand-crafted annotations. Although there are numerous remarkable annotation tools for NER labeling, the subject of integrating weak labeling sources is still unexplored. We introduce a web-based tool for text annotation called SciAnnotate, which stands for scientific annotation tool. Compared to frequently used text annotation tools, our annotation tool allows for the development of weak labels in addition to providing a manual annotation experience. Our tool provides users with multiple user-friendly interfaces for creating weak labels. SciAnnotate additionally allows users to incorporate their own language models and visualize the output of their model for evaluation. In this study, we take multi-source weak label denoising as an example, we utilized a Bertifying Conditional Hidden Markov Model to denoise the weak label generated by our tool. We also evaluate our annotation tool against the dataset provided by Mysore which contains 230 annotated materials synthesis procedures. The results shows that a 53.7% reduction in annotation time obtained AND a 1.6\\% increase in recall using weak label denoising. Online demo is available at https://sciannotate.azurewebsites.net/(demo account can be found in README), but we don't host a model server with it, please check the README in supplementary material for model server usage.",
      "authors": [
        "Mengyang Liu",
        "Haozheng Luo",
        "Leonard Thong",
        "Yinghao Li",
        "Chao Zhang",
        "Le Song"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2022-08-07T19:18:13+00:00",
          "link": "https://arxiv.org/abs/2208.10241v1",
          "size": "305kb",
          "version": "v1"
        }
      ],
      "title": "SciAnnotate: A Tool for Integrating Weak Labeling Sources for Sequence Labeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2208.10241",
        "PDF": "https://arxiv.org/pdf/2208.10241"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses a tool for text annotation and weak label integration, which may be tangentially relevant for data pre-processing but does not primarily focus on training data processing for LLMs."
      },
      "tasks": [
        "Denoising",
        "named-entity-recognition",
        "Named Entity Recognition",
        "Named Entity Recognition (NER)",
        "NER",
        "text annotation"
      ],
      "repo_urls": [
        "https://github.com/dreamyang-liu/SciAnnotate"
      ],
      "source": "arXiv"
    },
    {
      "id": "2103.09360",
      "abstract": "There is growing interest in data-driven weather prediction (DDWP), for example using convolutional neural networks such as U-NETs that are trained on data from models or reanalysis. Here, we propose 3 components to integrate with commonly used DDWP models in order to improve their physical consistency and forecast accuracy. These components are 1) a deep spatial transformer added to the latent space of the U-NETs to preserve a property called equivariance, which is related to correctly capturing rotations and scalings of features in spatio-temporal data, 2) a data-assimilation (DA) algorithm to ingest noisy observations and improve the initial conditions for next forecasts, and 3) a multi-time-step algorithm, which combines forecasts from DDWP models with different time steps through DA, improving the accuracy of forecasts at short intervals. To show the benefit/feasibility of each component, we use geopotential height at 500~hPa (Z500) from ERA5 reanalysis and examine the short-term forecast accuracy of specific setups of the DDWP framework. Results show that the equivariance-preserving networks (U-STNs) clearly outperform the U-NETs, for example improving the forecast skill by $45\\%$. Using a sigma-point ensemble Kalman (SPEnKF) algorithm for DA and U-STN as the forward model, we show that stable, accurate DA cycles are achieved even with high observation noise. The DDWP+DA framework substantially benefits from large ($O(1000)$) ensembles that are inexpensively generated with the data-driven forward model in each DA cycle. The multi-time-step DDWP+DA framework also shows promises, e.g., it reduces the average error by factors of 2-3.",
      "authors": [
        "Ashesh Chattopadhyay",
        "Mustafa Mustafa",
        "Pedram Hassanzadeh",
        "Eviatar Bach",
        "Karthik Kashinath"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Atmospheric and Oceanic Physics (physics.ao-ph)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Computational Physics (physics.comp-ph)"
      ],
      "submission_historys": [
        {
          "date": "2021-03-16T23:15:00+00:00",
          "link": "https://arxiv.org/abs/2103.09360v1",
          "size": "2703kb",
          "version": "v1"
        }
      ],
      "title": "Towards physically consistent data-driven weather forecasting: Integrating data assimilation with equivariance-preserving deep spatial transformers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2103.09360",
        "PDF": "https://arxiv.org/pdf/2103.09360"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses data-driven weather prediction and involves data assimilation, which is a form of data processing. However, it applies to weather data models rather than LLM data processing directly."
      },
      "tasks": [
        "Weather Forecasting"
      ],
      "repo_urls": [
        "https://github.com/ashesh6810/DDWP-DA"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.16100",
      "abstract": "As software development increasingly adopts automation, bot-driven development (BotDD) represents a transformative shift where bots assume proactive roles in coding, testing, and project management. In bot-driven development, bots go beyond support tasks, actively driving development workflows by making autonomous decisions, performing independent assessments, and managing code quality and dependencies. This paper explores how bot-driven development impacts traditional development roles, particularly in redefining driver-navigator dynamics, and aligns with DevOps goals for faster feedback, continuous learning, and efficiency. We propose a research agenda addressing challenges in bot-driven development, including skill development for developers, human-bot trust dynamics, optimal interruption frequency, and ethical considerations. Through empirical studies and prototype systems, our aim is to define best practices and governance structures for integrating bot-driven development into modern software engineering.",
      "authors": [
        "Christoph Treude and Christopher M. Poskitt"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-25T05:21:23+00:00",
          "link": "https://arxiv.org/abs/2411.16100v1",
          "size": "77kb",
          "version": "v1"
        }
      ],
      "title": "Bot-Driven Development: From Simple Automation to Autonomous Software Development Bots",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.16100",
        "HTML": "https://arxiv.org/html/2411.16100",
        "PDF": "https://arxiv.org/pdf/2411.16100"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses bot-driven development in software engineering, focusing on automation in coding and project management, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2312.03147",
      "abstract": "The recent COVID-19 pandemic has thrown the importance of accurately forecasting contagion dynamics and learning infection parameters into sharp focus. At the same time, effective policy-making requires knowledge of the uncertainty on such predictions, in order, for instance, to be able to ready hospitals and intensive care units for a worst-case scenario without needlessly wasting resources. In this work, we apply a novel and powerful computational method to the problem of learning probability densities on contagion parameters and providing uncertainty quantification for pandemic projections. Using a neural network, we calibrate an ODE model to data of the spread of COVID-19 in Berlin in 2020, achieving both a significantly more accurate calibration and prediction than Markov-Chain Monte Carlo (MCMC)-based sampling schemes. The uncertainties on our predictions provide meaningful confidence intervals e.g. on infection figures and hospitalisation rates, while training and running the neural scheme takes minutes where MCMC takes hours. We show convergence of our method to the true posterior on a simplified SIR model of epidemics, and also demonstrate our method's learning capabilities on a reduced dataset, where a complex model is learned from a small number of compartments for which data is available.",
      "authors": [
        "Thomas Gaskin",
        "Tim Conrad",
        "Grigorios A. Pavliotis",
        "Christof Sch\\\"utte"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)",
        "Physics and Society (physics.soc-ph)"
      ],
      "submission_historys": [
        {
          "date": "2023-12-05T21:34:59+00:00",
          "link": "https://arxiv.org/abs/2312.03147v1",
          "size": "518kb",
          "version": "v1"
        }
      ],
      "title": "Neural parameter calibration and uncertainty quantification for epidemic forecasting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2312.03147",
        "HTML": "https://arxiv.org/html/2312.03147",
        "PDF": "https://arxiv.org/pdf/2312.03147"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research is centered on neural parameter calibration and uncertainty quantification for epidemic forecasting, lacking relevance to LLM data processing tasks."
      },
      "tasks": [
        "Uncertainty Quantification"
      ],
      "repo_urls": [
        "https://github.com/thgaskin/neuralabm"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.16537",
      "abstract": "Homomorphic encryption (HE) and secret sharing (SS) enable computations on encrypted data, providing significant privacy benefits for large transformer-based models (TBM) in sensitive sectors like medicine and finance. However, private TBM inference incurs significant costs due to the coarse-grained application of HE and SS. We present FASTLMPI, a new approach to accelerate private TBM inference through fine-grained computation optimization. Specifically, through the fine-grained co-design of homomorphic encryption and secret sharing, FASTLMPI achieves efficient protocols for matrix multiplication, SoftMax, LayerNorm, and GeLU. In addition, FASTLMPI introduces a precise segmented approximation technique for differentiable non-linear, improving its fitting accuracy while maintaining a low polynomial degree. Compared to solution BOLT (S&P'24), FASTLMPI shows a remarkable 54% to 64% decrease in runtime and an impressive 72.2% reduction in communication costs.",
      "authors": [
        "Yuntian Chen",
        "Zhanyong Tang",
        "Tianpei Lu",
        "Bingsheng Zhang",
        "Zhiying Shi and Zheng Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-21T08:33:12+00:00",
          "link": "https://arxiv.org/abs/2412.16537v1",
          "size": "4752kb",
          "version": "v1"
        },
        {
          "date": "2025-01-25T14:10:34+00:00",
          "link": "https://arxiv.org/abs/2412.16537v2",
          "size": "4752kb",
          "version": "v2"
        }
      ],
      "title": "Accelerating Private Large Transformers Inference through Fine-grained Collaborative Computation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.16537",
        "HTML": "https://arxiv.org/html/2412.16537",
        "PDF": "https://arxiv.org/pdf/2412.16537"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on optimizing computations for private inference in large transformer-based models using homomorphic encryption and secret sharing, without addressing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2402.11322",
      "abstract": "Embedded AI systems are expected to incur low power/energy consumption for solving machine learning tasks, as these systems are usually power constrained (e.g., object recognition task in autonomous mobile agents with portable batteries). These requirements can be fulfilled by Spiking Neural Networks (SNNs), since their bio-inspired spike-based operations offer high accuracy and ultra low-power/energy computation. Currently, most of SNN architectures are derived from Artificial Neural Networks whose neurons' architectures and operations are different from SNNs, and/or developed without considering memory budgets from the underlying processing hardware of embedded platforms. These limitations hinder SNNs from reaching their full potential in accuracy and efficiency. Toward this, we propose SpikeNAS, a novel fast memory-aware neural architecture search (NAS) framework for SNNs that quickly finds an appropriate SNN architecture with high accuracy under the given memory budgets from targeted embedded systems. To do this, our SpikeNAS employs several key steps: analyzing the impacts of network operations on the accuracy, enhancing the network architecture to improve the learning quality, developing a fast memory-aware search algorithm, and performing quantization. The experimental results show that our SpikeNAS improves the searching time and maintains high accuracy compared to state-of-the-art while meeting the given memory budgets (e.g., 29x, 117x, and 3.7x faster search for CIFAR10, CIFAR100, and TinyImageNet200 respectively, using an Nvidia RTX A6000 GPU machine), thereby quickly providing the appropriate SNN architecture for the memory-constrained embedded AI systems.",
      "authors": [
        "Rachmad Vidya Wicaksana Putra",
        "Muhammad Shafique"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-17T16:33:54+00:00",
          "link": "https://arxiv.org/abs/2402.11322v1",
          "size": "1107kb",
          "version": "v1"
        },
        {
          "date": "2024-04-04T13:55:05+00:00",
          "link": "https://arxiv.org/abs/2402.11322v2",
          "size": "1804kb",
          "version": "v2"
        },
        {
          "date": "2024-04-05T11:51:58+00:00",
          "link": "https://arxiv.org/abs/2402.11322v3",
          "size": "1804kb",
          "version": "v3"
        },
        {
          "date": "2025-07-02T15:13:42+00:00",
          "link": "https://arxiv.org/abs/2402.11322v4",
          "size": "2226kb",
          "version": "v4"
        }
      ],
      "title": "SpikeNAS: A Fast Memory-Aware Neural Architecture Search Framework for Spiking Neural Network-based Embedded AI Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.11322",
        "HTML": "https://arxiv.org/html/2402.11322",
        "PDF": "https://arxiv.org/pdf/2402.11322"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "SpikeNAS is focused on improving neural architecture search for spiking neural networks in embedded systems. The study does not address tasks involved in processing training data for LLMs."
      },
      "tasks": [
        "Neural Architecture Search",
        "Object Recognition"
      ],
      "source": "arXiv"
    }
  ],
  "subjects": [
    "Logic in Computer Science (cs.LO)",
    "Computer Vision and Pattern Recognition (cs.CV)",
    "Optics (physics.optics)",
    "Statistics Theory (stat.TH)",
    "Networking and Internet Architecture (cs.NI)",
    "Multimedia (cs.MM)",
    "Optimization and Control (math.OC)",
    "Quantum Physics (quant-ph)",
    "Physics and Society (physics.soc-ph)",
    "Computer Science and Game Theory (cs.GT)",
    "Cell Behavior (q-bio.CB)",
    "Populations and Evolution (q-bio.PE)",
    "Computational Engineering, Finance, and Science (cs.CE)",
    "Computation and Language (cs.CL)",
    "Databases (cs.DB)",
    "Other Quantitative Biology (q-bio.OT)",
    "Sound (cs.SD)",
    "Image and Video Processing (eess.IV)",
    "Performance (cs.PF)",
    "Methodology (stat.ME)",
    "Systems and Control (eess.SY)",
    "Statistical Mechanics (cond-mat.stat-mech)",
    "Cryptography and Security (cs.CR)",
    "Robotics (cs.RO)",
    "Materials Science (cond-mat.mtrl-sci)",
    "Information Retrieval (cs.IR)",
    "Portfolio Management (q-fin.PM)",
    "Strongly Correlated Electrons (cond-mat.str-el)",
    "Artificial Intelligence (cs.AI)",
    "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
    "Computational Geometry (cs.CG)",
    "Atmospheric and Oceanic Physics (physics.ao-ph)",
    "Neurons and Cognition (q-bio.NC)",
    "Fluid Dynamics (physics.flu-dyn)",
    "Applications (stat.AP)",
    "Applied Physics (physics.app-ph)",
    "Adaptation and Self-Organizing Systems (nlin.AO)",
    "Data Analysis, Statistics and Probability (physics.data-an)",
    "High Energy Physics - Phenomenology (hep-ph)",
    "Analysis of PDEs (math.AP)",
    "Solar and Stellar Astrophysics (astro-ph.SR)",
    "Quantitative Methods (q-bio.QM)",
    "Computational Complexity (cs.CC)",
    "Logic (math.LO)",
    "Superconductivity (cond-mat.supr-con)",
    "Plasma Physics (physics.plasm-ph)",
    "Statistical Finance (q-fin.ST)",
    "General Relativity and Quantum Cosmology (gr-qc)",
    "High Energy Physics - Experiment (hep-ex)",
    "Systems and Control (cs.SY)",
    "Programming Languages (cs.PL)",
    "Trading and Market Microstructure (q-fin.TR)",
    "Category Theory (math.CT)",
    "Mathematical Software (cs.MS)",
    "Symbolic Computation (cs.SC)",
    "Biological Physics (physics.bio-ph)",
    "Probability (math.PR)",
    "High Energy Astrophysical Phenomena (astro-ph.HE)",
    "Information Theory (math.IT)",
    "Mathematical Physics (math.MP)",
    "Discrete Mathematics (cs.DM)",
    "Emerging Technologies (cs.ET)",
    "Medical Physics (physics.med-ph)",
    "Signal Processing (eess.SP)",
    "Number Theory (math.NT)",
    "Computation (stat.CO)",
    "Spectral Theory (math.SP)",
    "Audio and Speech Processing (eess.AS)",
    "Social and Information Networks (cs.SI)",
    "Chaotic Dynamics (nlin.CD)",
    "Combinatorics (math.CO)",
    "Differential Geometry (math.DG)",
    "Mesoscale and Nanoscale Physics (cond-mat.mes-hall)",
    "Machine Learning (stat.ML)",
    "Information Theory (cs.IT)",
    "Physics Education (physics.ed-ph)",
    "Computers and Society (cs.CY)",
    "Mathematical Physics (math-ph)",
    "Biomolecules (q-bio.BM)",
    "Tissues and Organs (q-bio.TO)",
    "Group Theory (math.GR)",
    "Functional Analysis (math.FA)",
    "Multiagent Systems (cs.MA)",
    "Numerical Analysis (cs.NA)",
    "Statistics Theory (math.ST)",
    "Pattern Formation and Solitons (nlin.PS)",
    "High Energy Physics - Theory (hep-th)",
    "Hardware Architecture (cs.AR)",
    "Risk Management (q-fin.RM)",
    "Neural and Evolutionary Computing (cs.NE)",
    "General Finance (q-fin.GN)",
    "Soft Condensed Matter (cond-mat.soft)",
    "Computational Physics (physics.comp-ph)",
    "Computational Finance (q-fin.CP)",
    "Software Engineering (cs.SE)",
    "Distributed, Parallel, and Cluster Computing (cs.DC)",
    "Human-Computer Interaction (cs.HC)",
    "Econometrics (econ.EM)",
    "Data Structures and Algorithms (cs.DS)",
    "Theoretical Economics (econ.TH)",
    "Graphics (cs.GR)",
    "Digital Libraries (cs.DL)",
    "Operating Systems (cs.OS)",
    "Machine Learning (cs.LG)",
    "General Economics (econ.GN)",
    "Chemical Physics (physics.chem-ph)",
    "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
    "Formal Languages and Automata Theory (cs.FL)",
    "Dynamical Systems (math.DS)",
    "Genomics (q-bio.GN)",
    "Numerical Analysis (math.NA)",
    "Economics (q-fin.EC)"
  ],
  "prompt": {
    "train_data": "\nYou are a computer science expert specializing in training data processing and data engineering for large language models (LLMs). You are skilled at identifying technical content in research papers that is related to **LLM training data**. I will provide you with a list of research papers from the arXiv (cs.\\*) domain.\n\n---\n\n### **Task Objective**\n\nFor each paper, determine whether it is directly related to the **processing of training data for LLMs**. Focus on identifying contributions in the following two areas:\n\n1. **Data Engineering Stage**:\n\n   * Includes tasks such as data collection, construction, cleaning, noise reduction, deduplication, filtering, format transformation, and data quality enhancement.\n\n2. **Training-Stage Data Processing**:\n\n   * Includes data preparation and processing for pre-training and post-training stages (e.g., fine-tuning, supervised fine-tuning (SFT), instruction tuning, etc.).\n\n---\n\n### **Relevance Level Classification Criteria**\n\n* `\"core\"`: The paper's primary contribution involves the design, construction, or processing of LLM training data\u2014for example, proposing a novel data pipeline, creating large-scale training data, or contributing new methods for improving data quality.\n* `\"partial\"`: The paper mentions data sources or preprocessing briefly in the background or experiments section, uses public datasets or existing tools, and does not propose new data-related methods.\n* `\"irrelevant\"`: The paper does not address any aspect of LLM training data collection, construction, or processing.\n\n---\n\n### **Output Format (strictly follow this JSON schema)**\n\n```json\n{\n  \"result\": [\n    {\n      \"id\": \"<paper id>\",\n      \"level\": \"core | partial | irrelevant\",\n      \"reason\": \"A 1-2 sentence explanation citing key parts of the abstract or methodology that justify the classification\"\n    }\n    // More papers...\n  ]\n}\n```\n"
  },
  "description": "Data source: https://arxiv.org/list/cs/new",
  "level_tatistics": {
    "irrelevant": 609,
    "partial": 138,
    "core": 27
  },
  "arxiv_update_date": "2025-07-04",
  "updated_at": "2025-07-05 23:55:29"
}